[{"title": "Differences between Morpho and Aave supply validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logics Note: Morpho re-implement the supply function as a mix of repay + supply operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Morpho is not checking that the Aave market has isFrozen == false, users could be able to supply in P2P even if the supply is paused on Aave (isFrozen == true) because Morpho would only call the aave.repay (where the frozen flag is not checked)  Morpho is not checking if remainingToSupply.rayDiv( poolIndexes[_poolToken].poolSupplyIndex ) === 0. Trying to supply that amount to Aave would make the whole tx revert 19 More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Morpho should avoid creating a new market when the underlying Aave market is frozen", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "In the current implementation of Aave MorphoGovernance.createMarket the function is only check- ing if the AToken is in active state. Morpho should also check if the AToken is not in a frozen state. When a market is frozen, many operations on the Aave side will be prevented (reverting the transaction).", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Compound liquidate validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. Note: Morpho liquidation does not directly call compound.liquidate but acts as a repay + withdraw operation. By reviewing both logic, we have noticed that there are some differences between the logic  Morpho does not check Compound seizeGuardianPaused because it is not implementing a \"real\" liquidate on compound, but it's emulating it as a \"repay\" + \"withdraw\".  Morpho should anyway monitor off-chain when the value of seizeGuardianPaused changes to true. Which are the scenarios for which Compound decides to block liquidations (across all cTokens)? When this happens, is Compound also pausing all the other operations?  [Open question] Should Morpho pause liquidations when the seizeGuardianPaused is true?  Morpho is not reverting if msg.sender === borrower  Morpho does not check if _amount > 0  Compound revert if amountToSeize > userCollateralBalance, Morpho does not revert and instead uses min(amountToSeize, userCollateralBalance) 20 More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "repayLogic in Compound PositionsManagershould revert if toRepay is equal to zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current implementation of repayLogic is correctly reverting if _amount == 0 but is not reverting if toRepay == 0. The value inside toRepay is given by the min value between _getUserBorrowBalanceInOf(_- poolToken, _onBehalf) and _amount. If the _onBehalf user has zero debt, toRepay will be initialized with zero.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Compound supply validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between them;  Compound is handling ERC20 tokens that could have transfer fees, Morpho is not doing it right now, see\"ERC20 with transfer's fee are not handled by PositionManager\".  Morpho is not checking if the underlying Compound market has been paused for the supply action (see mintGuardianPaused[token]). This means that even if the Compound supply is paused, Morpho could allow users to supply in the P2P.  Morpho is not checking if the market on both Morpho and Compound has been deprecated. If the deprecation flag is intended to be true for a market that will be removed in the next future, probably Morpho should not allow users to provide collateral for such a market. More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Compound\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider creating a documentation that covers all the Morpho own flags, lending protocol's flags and how they interact/override each other", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Both Morpho and Aave/Compound have their own flags to check before allowing a user to interact with the protocols. Usually, Morpho has decided to follow the logic to map 1:1 the implementation of the underlying protocol validation. There are some examples also where Morpho has decided to override some of their own internal flags For example, in the Aave aave-v2/ExitPositionsManager.liquidateLogic even if a Morpho market has been flagged as \"deprecated\" (user can be liquidated without being insolvent) the liquidator would not be able to liquidate the user if the liquidation logic has been paused.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Missing natspec or typos in natspec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "- Updated the natspec updateP2PIndexes replacing \"exchangeRatesStored()\" with \"exchangeRate- Stored()\"  Updated the natspec _updateP2PIndexes replacing \"exchangeRatesStored()\" with \"exchangeRateStored()\"  Updated the natspec for event MarketCreated replacing \"_poolToken\" with \"_p2pIndexCursor\"", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Removed unused \"named\" return parameters from functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Some functions in the codebase are defining \"named\" functions parameter that are not used explicitly inside the code. This could lead to future changes to return wrong values if the \"explicit return\" statement is removed and the function returns the \"default\" values (based on the variable type) of the \"named\" parameter.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider merging the code of CompoundMath libraries and use only one", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current codebase uses libraries/CompoundMath.sol but there's already an existing solidity library with the same name inside the package @morpho-dao/morpho-utils For better code clarity, consider merging those two libraries and only importing the one from the external pack- age. Be aware that the current implementation inside the @morpho-dao/morpho-utils CompoundMath mul and div function uses low-level yul and should be tested, while the library used right now in the code use \"high level\" solidity. the", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider reverting the creation of a deprecated market in Compound", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Compound has a mechanism that allows the Governance to set a specific market as \"deprecated\". Once a market is deprecated, all the borrows can be liquidated without checking whether the user is solvent or not. Compound currently allows users to enter (to supply and borrow) a market. In the current version of MorphoGovernance.createMarket, Morpho governance is not checking whether a market is already deprecated on compound before entering it and creating a new Morpho-market. This would allow a Morpho user to possibly supply or borrow on a market that has been already deprecated by compound.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Document HeapOrdering", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Morpho uses a non-standard Heap implementation for their Aave P2P matching engine. The im- plementation only correctly sorts _maxSortedUsers / 2 instead of the expected _maxSortedUsers. Once the _maxSortedUsers is reached, it halves the size of the heap, cutting the last level of leaves of the heap. This is done because a naive implementation that would insert new values at _maxSortedUsers (once the heap is full) and shift them up, then decrease the size to _maxSortedUsers - 1 again, would end up concentrating all new values on the same single path from the leaf to the root node. Cutting off the last level of nodes of the heap is a heuristic to remove low-value nodes (because of the heap property) while at the same time letting new values be shifted up from different leaf locations. In the end, the goal this tries to achieve is that more high-value nodes are stored in the heap and can be used for the matching engine.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider removing the Aave-v2 reward management logic if it is not used anymore", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "If the current aave-v2 reward program has ended and the Aave protocol is not re-introducing it anytime soon (if not at all) consider removing the code that currently is handling all the logic behind claiming rewards from the Aave lending pool for the supplied/borrow assets. Removing that code would make the codebase cleaner, reduce the attack surface and possibly revert in case some of the state variables are incorrectly miss configured (rewards management on Morpho is activated but Aave is not distributing rewards anymore).", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Avoid shadowing state variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Shadowing state or global variables could lead to potential bugs if the developer does not treat them carefully. To avoid any possible problem, every local variable should avoid shadowing a state or global variable name.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational aave-"]}, {"title": "Governance setter functions do not check current state before updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "In MorphoGovernance.sol, many of the setter functions allow the state to be changed even if it is already set to the passed-in argument. For example, when calling setP2PDisabled, there are no checks to see if the _poolToken is already disabled, or does not allow unnecessary state changes.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Emit event for amount of dust used to cover withdrawals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Consider emitting an event that includes the amount of dust that was covered by the contract balance. A couple of ways this could be used:  Trigger an alert whenever it exceeds a certain threshold so you can inspect it, and pause if a bug is found or a threshold is exceeded.  Use this value as part of your overall balance accounting to verify everything adds up.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Break up long functions into smaller composable functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "A few functions are 100+ lines of code which makes it more challenging to initially grasp what the function is doing. You should consider breaking these up into smaller functions which would make it easier to grasp the logic of the function, while also enabling you to easily unit test the smaller functions.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Remove unused struct members", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The HealthFactorVars struct contains three attributes, but only the userMarkets attribute is ever set or used. These should be removed to increase code readability.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Remove unused struct", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "There is an unused struct BorrowAllowedVars. This should be removed to improve code readability.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "No validation check on prices fetched from the oracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Currently in the liquidateLogic function when fetching the borrowedTokenPrice and collateral- Price from the oracle, the return value is not validated. This is due to the fact that the underlying protocol does not do this check either, but the fact that the underlying protocol does not do validation should not deter Morpho from performing validation checks on prices fetched from oracles. Also, this check is done in the Compound PositionsManager.sol here so for code consistency, it should also be done in Aave-v2.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "onBehalf argument can be set as the Morpho protocols address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When calling the supplyLogic function, currently the _onBehalf argument allows a user to supply funds on behalf of the Morpho protocol itself. While this does not seem exploitable, it can still be a cause for user error and should not be allowed.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "maxSortedUsers has no upper bounds validation and is not the same in Compound/Aave-2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "In MorphoGovernance.sol, the maxSortedUsers function has no upper bounds limit put in place. The maxSortedUsers is the number of users to sort in the data structure. Also, while this function has the MaxSorte- dUsersCannotBeZero() check in Aave-v2, the Compound version is missing this same error check.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider adding the compound revert error code inside Morpho custom error to better track the revert reason", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "On Compound, when an error condition occurs, usually (except in extreme cases) the transaction is not reverted, and instead an error code (code !== 0) is returned. Morpho correctly reverts with a custom error when this happens, but is not reporting the error code returned by Compound. By tracking, as an event parameter, the error code, Morpho could better monitor when and why interactions with Compound are failing.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "liquidationThreshold variable name can be misleading", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The liquidationThreshold name in Aave is a percentage. The values.liquidationThreshold variable used in Morpho's _getUserHealthFactor is in \"value units\" like debt: values.liquidationThreshold = assetCollateralValue.percentMul(assetData.liquidationThreshold);.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Users can be liquidated on Morpho at any time when the deprecation flag is set by governance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Governance can set a deprecation flag on Compound and Aave markets, and users on this mar- ket can be liquidated by anyone even if they're sufficiently over-collateralized. Note that this deprecation flag is independent of Compound's own deprecation flags and can be applied to any market.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Refactor _computeP2PIndexes to use InterestRateModel's functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The InterestRatesManager contracts' _computeP2PIndexes functions currently reimplement the interest rate model from the InterestRatesModel functions.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Permitting Multiple Drip Calls Per Block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "state.config.interval is 0. We are currently unaware of use cases where this is desirable. The inline comments correctly note that reentrancy is possible and permitted when Reentrancy is one risk, flashbot bundles are a similar risk where the drip may be called multiple times by the same actor in a single block. A malicious actor may abuse this ability, especially if interval is misconfigured as 0 due to JavaScript type coercion. A reentrant call or flashbot bundle may be used to frontrun an owner attempting to archive a drip or attempting to withdraw assets.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Medium Risk"]}, {"title": "Version Bump to Latest", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "During the review, a new version of solidity was released with an important bugfix.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "DOS from External Calls in Drippie.executable / Drippie.drip", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "In both the executable and drip (which also calls executable) functions, the Drippie contract interacts with some external contract via low-level calls. The external call could revert or fail with an Out of Gas exception causing the entire drip to fail. The severity is low beacuse in the case where a drip reverts due to a misconfigured or malicious dripcheck or target, the drip can still be archived and a new one can be created by the owner.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Use call.value over transfer in withdrawETH", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "transfer is no longer recommended as a default due to unpredictable gas cost changes in future evm hard forks (see here for more background.) While useful to use transfer in some cases (such as sending to EOA or contract which does not process data in the fallback or receiver functions), this particular contract does not benefit: withdrawETH is already owner gated and is not at risk of reentrancy as owner already has permission to drain the contracts ether in a single call should they choose.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Input Validation Checks for Drippie.create", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drippie.create does not validate input potentially leading to unintended results. The function should check:  _name is not an empty string to avoid creating drip that would be able to read on frontend UI.  _config.dripcheck should not be address(0) otherwise executable will always revert.  _config.actions.length should be at least one (_config.actions.length > 0) to prevent creating drips that do nothing when executed.  DripAction.target should not be address(0) to prevent burning ETH or interacting with the zero address during drips execution.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Ownership Initialization and Transfer Safety on Owned.setOwner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Consider the following scenarios.  Scenario 1 Drippie allows the owner to be both initialized and set to address(0). If this scenario happens nobody will be able to manage the Drippie contract, thus preventing any of the following operations:  Creating a new drip  Updating a drips status (pausing, activating or archiving a drip) If set to the zero address, all the onlyOwner operations in AssetReceiver and Transactor will be uncallable. This scenario where the owner can be set to address(0) can occur when address(0) is passed to the construc- tor or setOwner.  Scenario 2 owner may be set to address(this). Given the static nature of DripAction.target and DripAction.data there is no benefit of setting owner to address(this), and all instances can be assumed to have been done so in error.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Unchecked Return and Handling of Non-standard Tokens in AssetReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The current AssetReceiver contract implement \"direct\" ETH and ERC20 token transfers, but does not cover edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers  adhere to ERC20 interface (i.e. no return value) An ERC20 token that does not revert on failure would cause the WithdrewERC20 event to emit even though no transfer took place. An ERC20 token that does not have a return value will revert even if the call would have otherwise been successful. Solmate libraries already used inside the project offer a utility library called SafeTransferLib.sol which covers such edge cases. Be aware of the developer comments in the natspec: /// @dev Use with caution! Some functions in this library knowingly create dirty bits at the destination of the free memory pointer. /// @dev Note that none of the functions in this library check that a token has code at all! That responsibility is delegated to the caller.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "AssetReceiver Allows Burning ETH, ERC20 and ERC721 Tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver contains functions that allow the owner of the contract to withdraw ETH, ERC20 and ERC721 tokens. Those functions allow specifying the receiver address of ETH, ERC20 and ERC721 tokens but they do not check that the receiver address is not address(0). By not doing so, those functions allow to:  Burn ETH if sent to address(0).  Burn ERC20 tokens if sent to address(0) and the ERC20 _asset allow tokens to be burned via transfer (For example, Solmates ERC20 allow that, OpenZeppelin instead will revert if the recipient is address(0)).  Burn ERC721 tokens if sent to address(0) and the ERC721 _asset allow tokens to be burned via trans- ferFrom (For example, both Solmate and OpenZeppelin implementations prevent to send the _id to the address(0) but you dont know if that is still true about custom ERC721 contract that does not use those libraries).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "AssetReceiver Not Implementing onERC721Received Callback Required by safeTransferFrom.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver contains the function withdrawERC721 that allow the owner to withdraw ERC721 tokens. As stated in the EIP-721, the safeTransferFrom (used by the sender to transfer ERC721 tokens to the AssetRe- ceiver) will revert if the target contract (AssetReceiver in this case) is not implementing onERC721Received and returning the expected value bytes4(keccak256(\"onERC721Received(address,address,uint256,bytes)\")).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Emit Events", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Transactor contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both of those functions are executing delegatecall and call without emitting any events. Because of the general- purpose nature of these function, it would be considered a good security measure to emit events to track the functions usage. Those events could be then used to monitor and track usage by external monitoring services.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Check the Result of the Execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both functions return the delegatecall and call result back to the caller without checking whether execution was successful or not. By not implementing such check, the transaction could fail silently. Another side effect is that the ETH sent along with the execution (both functions are payable) would remain in the Drippie contract and not transferred to the _target. Test example showcasing the issue: contract Useless { // A contract that have no functions // No fallback functions // Will not accept ETH (only from selfdestruct/coinbase) } function test_transactorCALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them 8 (success, ) = drippie.CALL{value: 1 ether}(address(useless), \"\", 100000, 1 ether); assertEq(success, false); vm.prank(deployer); // Perform a `call` to a not existing target's function (success, ) = drippie.CALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000, 1 ether); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! } function test_transactorDELEGATECALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `delegatecall` to a contract that cannot receive them (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), \"\", 100000); assertEq(success, false); vm.prank(deployer); // Perform a `delegatecall` to a not existing target's function (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Transactor.DELEGATECALL Data Overwrite and selfdestruct Risks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL function that allow the owner to execute a delegatecall toward a target address passing an arbitrary payload. Consider the following scenarios:  Scenario 1 A malicious target contract could selfdestruct the Transactor contract and as a consequence the contract that is inheriting from Transactor. Test example showcasing the issue: 9 contract SelfDestroyer { function destroy(address receiver) external { selfdestruct(payable(receiver)); } } function test_canOwnerSelftDestructDrippie() public { // Assert that Drippie exist assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); assertGt(getContractSize(address(drippie)), 0); // set it to active vm.prank(deployer); drippie.status(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); // fund the drippie with 1 ETH vm.deal(address(drippie), 1 ether); uint256 deployerBalanceBefore = deployer.balance; uint256 drippieBalanceBefore = address(drippie).balance; // deploy the destroyer SelfDestroyer selfDestroyer = new SelfDestroyer(); vm.prank(deployer); drippie.DELEGATECALL(address(selfDestroyer), abi.encodeWithSignature(\"destroy(address)\", deployer), gasleft()); ,! uint256 deployerBalanceAfter = deployer.balance; uint256 drippieBalanceAfter = address(drippie).balance; // assert that the deployer has received the balance that was present in Drippie assertEq(deployerBalanceAfter, deployerBalanceBefore + drippieBalanceBefore); assertEq(drippieBalanceAfter, 0); // Weird things happens with forge // Because we are in the same block the code of the contract is still > 0 so // Cannot use assertEq(getContractSize(address(drippie)), 0); // Known forge issue // 1) Forge resets storage var to 0 after self-destruct (before tx ends) 2654 -> https://github.com/foundry-rs/foundry/issues/2654 // 2) selfdestruct has no effect in test 1543 -> https://github.com/foundry-rs/foundry/issues/1543 assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); ,! }  Scenario 2 The delegatecall allows the owner to intentionally, or accidentally, overwrite the content of the drips mapping. By being able to modify the drips mapping, a malicious user would be able to execute a series of actions like: Changing drips status:  Activating an archived drip  Deleting a drip by changing the status to NONE (this allows the owner to override entirely the drip by calling again create)  Switching an active/paused drip to paused/active 10  etc.. Change drips interval:  Prevent a drip from being executed any more by setting interval to a very high value  Allow a drip to be executed more frequently by lowering the interval value  Enable reentrancy by setting interval to 0 Change drips actions:  Override an action to send drips contract balance to an arbitrary address  etc.. Test example showcasing the issue: contract ChangeDrip { address public owner; mapping(string => Drippie.DripState) public drips; function someInnocentFunction() external { drips[\"FUND_BRIDGE_WALLET\"].config.actions[0] = Drippie.DripAction({ target: payable(address(1024)), data: new bytes(0), value: 1 ether }); } } 11 function test_canDELEGATECALLAllowReplaceAction() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Create an action with name \"FUND_BRIDGE_WALLET\" that have the function // To fund a wallet vm.startPrank(deployer); string memory fundBridgeWalletName = \"FUND_BRIDGE_WALLET\"; Drippie.DripAction[] memory actions = new Drippie.DripAction[](1); // The first action will send Bob 1 ether actions[0] = Drippie.DripAction({ target: payable(address(alice)), data: new bytes(0), value: 1 ether ,! }); Drippie.DripConfig memory config = createConfig(100, IDripCheck(address(checkTrue)), new bytes(0), actions); drippie.create(fundBridgeWalletName, config); drippie.status(fundBridgeWalletName, Drippie.DripStatus.ACTIVE); vm.stopPrank(); // Deploy the malicius contract vm.prank(attacker); ChangeDrip changeDripContract = new ChangeDrip(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(changeDripContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Now the drip action should have changed, anyone can execute it and funds would be sent to // the attacker and not to the bridge wallet drippie.drip(fundBridgeWalletName); // Assert we have drained Drippie assertEq(attacker.balance, 1 ether); assertEq(address(drippie).balance, 9 ether); }  Scenario 3 Calling a malicious contract or accidentally calling a contract which does not account for Drippies storage layout can result in owner being overwritten. Test example showcasing the issue: contract GainOwnership { address public owner; function someInnocentFunction() external { owner = address(1024); } } 12 function test_canDELEGATECALLAllowOwnerLoseOwnership() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Deploy the malicius contract vm.prank(attacker); GainOwnership gainOwnershipContract = new GainOwnership(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(gainOwnershipContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Assert that the attacker has gained onwership assertEq(drippie.owner(), attacker); // Steal all the funds vm.prank(attacker); drippie.withdrawETH(payable(attacker)); // Assert we have drained Drippie assertEq(attacker.balance, 10 ether); assertEq(address(drippie).balance, 0 ether); }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Use calldata over memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Some gas savings if function arguments are passed as calldata instead of memory.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Avoid String names in Events and Mapping Key", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drip events emit an indexed nameref and the name as a string. These strings must be passed into every drip call adding to gas costs for larger strings.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Avoid Extra sloads on Drippie.status", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Information for emitting event can be taken from calldata instead of reading from storage. Can skip repeat drips[_name].status reads from storage.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Use Custom Errors Instead of Strings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Increment In The For Loop Post Condition In An Unchecked Block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "This is only relevant if you are using the default solidity checked arithmetic. i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "DripState.count Location and Use", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "DripState.count is recorded and never used within the Drippie or IDripCheck contracts. DripState.count is also incremented after all external calls, inconsistent with Checks, Effects, Interactions con- vention.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Type Checking Foregone on DripCheck", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Passing params as bytes makes for a flexible DripCheck, however, type checking is lost.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Confirm Blind ERC721 Transfers are Intended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver uses transferFrom instead of safeTransferFrom. The callback on safeTransferFrom often poses a reentrancy risk but in this case the function is restricted to onlyOwner.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Code Contains Empty Blocks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Its best practice that when there is an empty block, to add a comment in the block explaining why its empty. While not technically errors, they can cause confusion when reading code.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Code Structure Deviates From Best-Practice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The best-practice layout for a contract should follow this order:  State variables.  Events.  Modifiers.  Constructor.  Functions. Function ordering helps readers identify which functions they can call and find constructor and fallback functions easier. Functions should be grouped according to their visibility and ordered as: constructor, receive function (if ex- ists), fallback function (if exists), external, public, internal, private. Some constructs deviate from this recommended best-practice: structs and mappings after events.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Missing or Incomplete NatSpec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Some functions are missing @notice/@dev NatSpec comments for the function, @param for all/some of their parameters and @return for return values. Given that NatSpec is an important part of code documentation, this affects code comprehension, auditability and usability.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Checking Boolean Against Boolean", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "executable returns a boolean in which case the comparison to true is unnecessary. executable also reverts if any precondition check fails in which case false will never be returned.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Drippie.executable Never Returns false Only true or Reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "executable(string memory _name) public view returns (bool). The executable implemented in the Drippie contract has the following signature From the signature and the natspec documentation @return True if the drip is executable, false other- wise. Without reading the code, a user/developer would expect that the function returns true if all the checks passes otherwise false but in reality the function will always return true or revert. Because of this behavior, a reverting drip that do not pass the requirements inside executable will never revert with the message present in the following code executed by the drip function require( executable(_name) == true, \"Drippie: drip cannot be executed at this time, try again later\" );", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Drippie Use Case Notes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drippie intends to support use cases outside of the initial hot EOA top-up use case demonstrated by Optimism. To further clarify, weve noted that drips support:  Sending eth  External function calls with fixed params  Preconditions Examples include, conditionally transferring eth or tokens. Calling an admin function iff preconditions are met. Drips do not support:  Updating the drip contract storage  Altering params  Postconditions Examples include, vesting contracts or executing Uniswap swaps based on recent moving averages (which are not without their own risks). Where dynamic params or internal accounting is needed, a separate contract needs to be paired with the drip.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Augment Documentation for dripcheck.check Indicating Precondition Check Only Performed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Before executing the whole batch of actions the drip function call executable that check if the drip can be executed. Inside executable an external contract is called by this instruction require( state.config.dripcheck.check(state.config.checkparams), \"Drippie: dripcheck failed so drip is not yet ready to be triggered\" ); Optimism provided some examples like checking if a target balance is below a specific threshold or above that threshold, but in general, the dripcheck.check invocation could perform any kind of checks. The important part that should be clear in the natspec documentation of the drip function is that that specific check is performed only once before the execution of the bulk of actions.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Considerations on the drip state.last and state.config.interval values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "When the drip function is called by an external actor, the executable is executed to check if the drip meets all the needed requirements to be executed. The only check that is done regarding the drip state.last and state.config.interval is this require( state.last + state.config.interval <= block.timestamp, \"Drippie: drip interval has not elapsed since last drip\" ); The state.time is never really initialized when the create function is called, this means that it will be automatically initialized with the default value of the uint256 type: 0.  Consideration 1: Drips could be executed as soon as created Depending on the value set to state.config.interval the executables logic implies that as soon as a drip is created, the drip can be immediately (even in the same transaction) executed via the drip function.  Consideration 2: A very high value for interval could make the drip never executable block.timestamp represents the number of seconds that passed since Unix Time (1970-01-01T00:00:00Z). When the owner of the Drippie want to create a \"one shot\" drip that can be executed immediately after creation but only once (even if the owner forgets to set the drips status to ARCHIVED) he/she should be aware that the max value that he/she can use for the interval is at max block.timestamp. This mean that the second time the drip can be executed is after block.timestamp seconds have been passed. If, for example, the owner create right now a drip with interval = block.timestamp it means that after the first execution the same drip could be executed after ~52 years (~2022-1970).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Support ERC1155 in AssetReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver support ERC20 and ERC721 interfaces but not ERC1155.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Reorder DripStatus Enum for Clarity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The current implementation of Drippie contract has the following enum type: enum DripStatus { NONE, // uint8(0) ACTIVE, PAUSED, ARCHIVED } When a drip is created via the create function, its status is initialized to PAUSED (equal to uint8(2)) and when it gets activated its status is changed to ACTIVE (equal to uint8(1)) So, the status change from 0 (NONE) to 2 (PAUSED) to 1 (ACTIVE). Switching the order inside the enum DripStatus definition between PAUSED and ACTIVE would make it more clean and easier to understand.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "_gas is Unneeded as Transactor.CALL and Transactor.DELEGATECALL Function Argument", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The caller (i.e. contract owner) can control desired amount of gas at the transaction level.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Licensing Conflict on Inherited Dependencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Solmate contracts are AGPL Licensed which is incompatible with the MIT License of Drippie related contracts.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Rename Functions for Clarity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "status The status(string memory _name, DripStatus _status) function allows the owner to update the status of a drip. The purpose of the function, based on the name, is not obvious at first sight and could confuse a user into believing that its a view function to retrieve the status of a drip instead of mutating its status. executable The executable(string memory _name) public view returns (bool) function returns true if the drip with name _name can be executed.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Owner Has Permission to Drain Value from Drippie Contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Consider the following scenarios.  Scenario 1 Owner may create arbitrary drips, including a drip to send all funds to themselves.  Scenario 2 AssetReceiver permits owner to withdraw ETH, ERC20 tokens, and ERC721 tokens.  Scenario 3 Owner may execute arbitrary calls. Transactor.CALL function is a function that allows the owner of the contract to execute a \"general purpose\" low- level call. function CALL( address _target, bytes memory _data, uint256 _gas, uint256 _value ) external payable onlyOwner returns (bool, bytes memory) { return _target.call{ gas: _gas, value: _value }(_data); } The function will transfer _value ETH present in the contract balance to the _target address. The function is also payable and this mean that the owner can send along with the call some funds. Test example showcasing the issue: 23 function test_transactorCALLAllowOwnerToDrainDrippieContract() public { bool success; vm.deal(deployer, 0 ether); vm.deal(bob, 0 ether); vm.deal(address(drippie), 1 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them (success, ) = drippie.CALL{value: 0 ether}(bob, \"\", 100000, 1 ether); assertEq(success, true); assertEq(address(drippie).balance, 0 ether); assertEq(bob.balance, 1 ether); }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Receiver doesn't always reset allowance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _swapAndCompleteBridgeTokens() of Receiver reset the approval to the executor at the end of an ERC20 transfer. However it there is insufficient gas then the approval is not reset. This allows the executor to access any tokens (of the same type) left in the Receiver. function _swapAndCompleteBridgeTokens(...) ... { ... if (LibAsset.isNativeAsset(assetId)) { ... } else { // case 2: ERC20 asset ... token.safeIncreaseAllowance(address(executor), amount); if (reserveRecoverGas && gasleft() < _recoverGas) { token.safeTransfer(receiver, amount); ... return; // no safeApprove 0 } try executor.swapAndCompleteBridgeTokens{...} ... token.safeApprove(address(executor), 0); } }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: High Risk"]}, {"title": "CelerIMFacet incorrectly sets RelayerCelerIM as receiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "When assigning a bytes memory variable to a new variable, the new variable points to the same memory location. Changing any one variable updates the other variable. Here is a PoC as a foundry test function testCopy() public { Pp memory x = Pp({ a: 2, b: address(2) }); Pp memory y = x; y.b = address(1); assertEq(x.b, y.b); } Thus, when CelerIMFacet._startBridge() updates bridgeDataAdjusted.receiver, _bridgeData.receiver is implicitly updated too. This makes the receiver on the destination chain to be the relayer address. // case 'yes': bridge + dest call - send to relayer ILiFi.BridgeData memory bridgeDataAdjusted = _bridgeData; bridgeDataAdjusted.receiver = address(relayer); (bytes32 transferId, address bridgeAddress) = relayer .sendTokenTransfer{ value: msgValue }(bridgeDataAdjusted, _celerIMData); // call message bus via relayer incl messageBusFee relayer.forwardSendMessageWithTransfer{value: _celerIMData.messageBusFee}( _bridgeData.receiver, uint64(_bridgeData.destinationChainId), bridgeAddress, transferId, _celerIMData.callData );", "labels": ["Spearbit", "LIFI-retainer1", "Severity: High Risk"]}, {"title": "Max approval to any address is possible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "HopFacetOptimized.setApprovalForBridges() can be called by anyone to give max approval to any address for any ERC20 token. Any ERC20 token left in the Diamond can be stolen. function setApprovalForBridges(address[] calldata bridges,address[] calldata tokensToApprove) external { ... LibAsset.maxApproveERC20(..., type(uint256).max); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: High Risk"]}, {"title": "Return value of low-level .call() not checked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Low-level primitive .call() doesn't revert in caller's context when the callee reverts. value is not checked, it can lead the caller to falsely believe that the call was successful. Receiver.sol uses .call() to transfer the native token to receiver. If receiver reverts, this can lead to locked ETH in Receiver contract.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: High Risk"]}, {"title": "Limits in LIFuelFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The facet LIFuelFacet is meant for small amounts, however, it doesn't have any limits on the funds sent. This might result in funds getting stuck due to insufficient liquidity on the receiving side. function _startBridge(...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { serviceFeeCollector.collectNativeGasFees{...}(...); } else { LibAsset.maxApproveERC20(...); serviceFeeCollector.collectTokenGasFees(...); ... } }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "The optimal version _depositAndSwap() isn't always used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _depositAndSwap() of SwapperV2 has two versions. The second version keeps _- nativeReserve that is meant for fees. Several facets don't use this version although their bridge does require native fees. This could result in calls reverting due to insufficient native tokens left. function _depositAndSwap(...) ... // 4 parameter version /// @param _nativeReserve Amount of native token to prevent from being swept back to the caller function _depositAndSwap(..., uint256 _nativeReserve) ... // 5 parameter version", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "setContractOwner() is insufficient to lock down the owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function transferOwnershipToZeroAddress() is meant to make the Diamond immutable. It sets the contract owner to 0. However, the contract owner can still be changed if there happens to be a pendingOwner. In that case confirmOwnershipTransfer() can still change the contract owner. function transferOwnershipToZeroAddress() external { // transfer ownership to 0 address LibDiamond.setContractOwner(address(0)); } function setContractOwner(address _newOwner) internal { DiamondStorage storage ds = diamondStorage(); address previousOwner = ds.contractOwner; ds.contractOwner = _newOwner; emit OwnershipTransferred(previousOwner, _newOwner); } function confirmOwnershipTransfer() external { Storage storage s = getStorage(); address _pendingOwner = s.newOwner; if (msg.sender != _pendingOwner) revert NotPendingOwner(); emit OwnershipTransferred(LibDiamond.contractOwner(), _pendingOwner); LibDiamond.setContractOwner(_pendingOwner); s.newOwner = LibAsset.NULL_ADDRESS; }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Receiver does not verify address from the originator chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The Receiver contract is designed to receive the cross-chain call from libDiamond address on the destination chain. However, it does not verify the source chain address. An attacker can build a malicious _- callData. An attacker can steal funds if there are left tokens and there are allowances to the Executor. Note that the tokens may be lost in issue: \"Arithemetic underflow leading to unexpected revert and loss of funds in Receiver contract\". And there may be allowances to Executor in issue \"Receiver doesn't always reset allowance\"", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Arithemetic underflow leading to unexpected revert and loss of funds in Receiver contract.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The Receiver contract is designed to gracefully return the funds to users. It reserves the gas for recovering gas before doing swaps via executor.swapAndCompleteBridgeTokens. The logic of reserving gas for recovering funds is implemented at Receiver.sol#L236-L258 contract Receiver is ILiFi, ReentrancyGuard, TransferrableOwnership { // ... if (reserveRecoverGas && gasleft() < _recoverGas) { // case 1a: not enough gas left to execute calls receiver.call{ value: amount }(\"\"); // ... } // case 1b: enough gas left to execute calls try executor.swapAndCompleteBridgeTokens{ value: amount, gas: gasleft() - _recoverGas }(_transactionId, _swapData, assetId, receiver) {} catch { receiver.call{ value: amount }(\"\"); } // ... } 10 The gasleft() returns the remaining gas of a call. It is continuously decreasing. The second query of gasleft() is smaller than the first query. Hence, if the attacker tries to relay the transaction with a carefully crafted gas where gasleft() >= _recoverGas at the first quiry and gasleft() - _recoverGas reverts. This results in the token loss in the Receiver contract.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Use of name to identify a token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "startBridgeTokensViaCelerIM() uses the token name to identify cfUSDC token. Another token with the same name can pass this check. An attacker can create a scam token with the name \"cfUSDC\" and a function canonical() returning a legit ERC20 token address, say WETH. If this token is passed as _bridge- Data.sendingAssetId, CelerIMFacet will transfer WETH. 11 if ( keccak256( abi.encodePacked( ERC20(_bridgeData.sendingAssetId).symbol() ) ) == keccak256(abi.encodePacked((\"cfUSDC\"))) ) { // special case for cfUSDC token asset = IERC20( CelerToken(_bridgeData.sendingAssetId).canonical() ); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Unvalidated destination address in Gravity faucet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Data.destinationAddress address. The code does not validate if the provided destination address is in the valid bech32 format. there is an issue related to the validation of In the Gravity faucet, This can potentially cause issues when sending tokens to the destination address. If the provided address is not in the bech32 format, the tokens can be locked. Also, it can lead to confusion for the end-users as they might enter an invalid address and lose their tokens without any warning or error message. it is recommended to add a validation check for the _gravity-", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Hardcode or whitelist the Thorswap vault address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The issue with this code is that the depositWithExpiry function allows the user to enter any arbitrary vault address, which could potentially lead to a loss of tokens. If a user enters an incorrect or non-existent vault address, the tokens could be lost forever. There should be some validation on the vault address to ensure that it is a valid and trusted address before allowing deposits to be made to it.  Router 12 // Deposit an asset with a memo. ETH is forwarded, ERC-20 stays in ROUTER function deposit(address payable vault, address asset, uint amount, string memory memo) public payable nonReentrant{ ,! uint safeAmount; if(asset == address(0)){ safeAmount = msg.value; bool success = vault.send(safeAmount); require(success); } else { require(msg.value == 0, \"THORChain_Router: unexpected eth\"); // protect user from ,! accidentally locking up eth if(asset == RUNE) { safeAmount = amount; iRUNE(RUNE).transferTo(address(this), amount); iERC20(RUNE).burn(amount); } else { safeAmount = safeTransferFrom(asset, amount); // Transfer asset _vaultAllowance[vault][asset] += safeAmount; // Credit to chosen vault } } emit Deposit(vault, asset, safeAmount, memo); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Check enough native assets for fee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _startBridge() of SquidFacet adds _squidData.fee to _bridgeData.minAmount. It has verified there is enough native asset for _bridgeData.minAmount, but not for _squidData.fee. So this could use native assets present in the Diamond, although there normally shouldn't be any native assets left. A similar issue occurs in:  CelerIMFacet  DeBridgeFacet function _startBridge(...) ... { ... uint256 msgValue = _squidData.fee; if (LibAsset.isNativeAsset(address(sendingAssetId))) { msgValue += _bridgeData.minAmount; } ... ... squidRouter.bridgeCall{ value: msgValue }(...); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "No check on native assets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The functions startBridgeTokensViaHopL1Native() , startBridgeTokensViaXDaiBridge() and startBridgeTokensViaMultichain() don't check _bridgeData.minAmount <= msg.value. So this could use na- tive assets that are still in the Diamond, although that normally shouldn't happen. This might be an issue in combination with reentrancy. function startBridgeTokensViaHopL1Native(...) ... { _hopData.hopBridge.sendToL2{ value: _bridgeData.minAmount }( ... ); ... } function startBridgeTokensViaXDaiBridge(...) ... { _startBridge(_bridgeData); } function startBridgeTokensViaMultichain(...) ... { if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) LibAsset.depositAsset(_bridgeData.sendingAssetId,_bridgeData.minAmount); } // no check for native assets _startBridge(_bridgeData, _multichainData); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Missing doesNotContainDestinationCalls()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The functions startBridgeTokensViaLIFuel() and swapAndStartBridgeTokensViaLIFuel() doesn't have doesNotContainDestinationCalls(). function startBridgeTokensViaLIFuel(...) external payable nonReentrant refundExcessNative(payable(msg.sender)) doesNotContainSourceSwaps(_bridgeData) validateBridgeData(_bridgeData) { ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Race condition in _startBridge of LIFuelFacet.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "If the mapping for FEE_COLLECTOR_NAME hasn't been set up yet, then serviceFeeCollector will be address(0) in function _startBridge of LIFuelFacet. This might give unexpected results. function _startBridge(...) ... ( ... ServiceFeeCollector serviceFeeCollector = ServiceFeeCollector( LibMappings.getPeripheryRegistryMappings().contracts[FEE_COLLECTOR_NAME] ); ... } function getPeripheryContract(string calldata _name) external view returns (address) { return LibMappings.getPeripheryRegistryMappings().contracts[_name]; }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Sweep tokens from Hopfacets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The Hop bridges HopFacet and HopFacetOptimized don't check that _bridgeData.sendingAssetId is the same as the bridge token. So this could be used to sweep tokens out of the Diamond contract. Normally there shouldn't be any tokens left at the Diamond, however, in this version there are small amounts left: Etherscan LiFiDiamond.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Missing emit in _swapAndCompleteBridgeTokens of Receiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "In function _swapAndCompleteBridgeTokens the catch of ERC20 tokens does an emit, while the comparable catch of native assets doesn't do an emit. function _swapAndCompleteBridgeTokens(...) ... { ... if (LibAsset.isNativeAsset(assetId)) { .. try ... {} catch { receiver.call{ value: amount }(\"\"); // no emit } ... } else { // case 2: ERC20 asset ... try ... {} catch { token.safeTransfer(receiver, amount); emit LiFiTransferRecovered(...); } } }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Spam events in ServiceFeeCollector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The contract ServiceFeeCollector has several functions that collect fees and are permissionless. This could result in spam events, which might confuse the processing of the events. function collectTokenGasFees(...) ... { ... emit GasFeesCollected(tokenAddress, receiver, feeAmount); } function collectNativeGasFees(...) ... { ... emit GasFeesCollected(LibAsset.NULL_ADDRESS, receiver, feeAmount); } function collectTokenInsuranceFees(...) ... { ... emit InsuranceFeesCollected(tokenAddress, receiver, feeAmount); } function collectNativeInsuranceFees(...) ... { ... emit InsuranceFeesCollected(LibAsset.NULL_ADDRESS,receiver,feeAmount); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Function depositAsset() allows 0 amount of native assets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function depositAsset() disallows amount == 0 for ERC20, however it does allow amount == 0 for native assets. function depositAsset(address assetId, uint256 amount) internal { if (isNativeAsset(assetId)) { if (msg.value < amount) revert InvalidAmount(); } else { if (amount == 0) revert InvalidAmount(); ... } }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Inadequate expiration time check in ThorSwapFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "According to Thorchain, the expiration time for certain operations should be set to +60 minutes. How- ever, there is currently no check in place to enforce this requirement. This oversight may lead to users inadvertently setting incorrect expiration times, potentially causing unexpected behavior or issues within the ThorSwapFacet.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Insufficient validation of bridgedTokenSymbol and sendingAssetId", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "During the code review, It has been noticed that the facet does not adequately check the corre- spondence between the bridgedTokenSymbol and sendingAssetId parameters. This oversight could allow for a random token to be sent to the Diamond, while still bridging another available token within the Diamond, even when no tokens should typically be left in the Diamond.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Check for destinationChainId in CBridgeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Function _startBridge() of CBridgeFacet contains a check on destinationChainId and contains conversions to uint64. If both block.chainid and _bridgeData.destinationChainId) fit in an uint64 then the checks of modifier val- idateBridgeData are already sufficient. When _bridgeData.destinationChainId > type(uint64).max then this never reverts: if (uint64(block.chainid) == _bridgeData.destinationChainId) revert CannotBridgeToSameNetwork(); Then in the rest of the code it takes the truncated varion of the destinationChainId via uint64(_bridge- Data.destinationChainId), which can be any value, including block.chainid. So you can still bridge to the same chain. function _startBridge(ILiFi.BridgeData memory _bridgeData,CBridgeData memory _cBridgeData) private { if (uint64(block.chainid) == _bridgeData.destinationChainId) revert CannotBridgeToSameNetwork(); if (...) { cBridge.sendNative{ value: _bridgeData.minAmount }(... , ,! uint64(_bridgeData.destinationChainId),...); } else { ... cBridge.send(..., uint64(_bridgeData.destinationChainId), ...); } } modifier validateBridgeData(ILiFi.BridgeData memory _bridgeData) { ... if (_bridgeData.destinationChainId == block.chainid) { revert CannotBridgeToSameNetwork(); } ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Absence of nonReentrant in HopFacetOptimized facet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "HopFacetOptimized is a facet-based smart contract implementation that aims to optimize gas usage and streamline the execution of certain functions. It doesn't have the checks that other facets have: nonReentrant refundExcessNative(payable(msg.sender)) containsSourceSwaps(_bridgeData) doesNotContainDestinationCalls(_bridgeData) validateBridgeData(_bridgeData) Most missing checks are done on purpose to save gas. However, the most important check is the nonReentrant modifier. On several places in the Diamond it is possible to trigger a reentrant call, for example via ERC777 18 tokens, custom tokens, native tokens transfers. In combination with the complexity of the code and the power of ERC20Proxy.sol it is difficult to make sure no attacks can occur.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Revert for excessive approvals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Certain tokens, such as UNI and COMP, undergo a reversal if the value input for approval or transfer surpasses uint96. Both aforementioned tokens possess unique logic in their approval process that sets the allowance to the maximum value of uint96 when the approval amount equals uint256(-1). Note: Hop currently doesn't support these token so set to low risk.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Inconsistent transaction failure/stuck due to missing validation of global fixed native fee rate and execution fee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current implementation of the facet logic does not validate the global fixed native fee rate and execution fee, which can lead to inconsistent transaction failures or getting stuck in the process. This issue can arise when the fee rate is not set correctly or there are discrepancies between the fee rate used in the smart contract and the actual fee rate. This can result in transactions getting rejected or stuck, causing inconvenience to users and affecting the overall user experience.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Incorrect value emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "LibSwap.swap() emits the following emit AssetSwapped( transactionId, _swap.callTo, _swap.sendingAssetId, _swap.receivingAssetId, _swap.fromAmount, newBalance > initialReceivingAssetBalance // toAmount ? newBalance - initialReceivingAssetBalance : newBalance, block.timestamp ); It will be difficult to interpret the value emitted for toAmount as the observer won't know which of the two values has been emitted.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Storage slots derived from hashes are prone to pre-image attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Storage slots manually constructed using keccak hash of a string are prone to storage slot collision as the pre-images of these hashes are known. Attackers may find a potential path to those storage slots using the keccak hash function in the codebase and some crafted payload.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Incorrect arguments compared in SquidFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "startBridgeTokensViaSquid () reverts if (_squidData.sourceCalls.length > 0) != _bridge- Data.hasSourceSwaps. Here, _squidData.sourceCalls is an argument passed to Squid Router, and _bridge- Data.hasSourceSwaps refers to source swaps done by SquidFacet. Ideally, _bridgeData.hasSourceSwaps should be false for this function (though it's not enforced) which means _squidData.sourceCalls.length has to be 0 for it to successfully execute.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Unsafe casting of bridge amount from uint256 to uint128", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The issue with the code is that it performs an unsafe cast from a uint256 value to a uint128 value in the call to initiateTeleport() function. The _bridgeData.minAmount parameter passed to this function is of type uint256, but it is cast to uint128 without any checks, which may result in a loss of precision or even an overflow. function _startBridge(ILiFi.BridgeData memory _bridgeData) internal { LibAsset.maxApproveERC20( IERC20(dai), address(teleportGateway), _bridgeData.minAmount ); teleportGateway.initiateTeleport( l1Domain, _bridgeData.receiver, uint128(_bridgeData.minAmount) + );", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Cache s.anyTokenAddresses[_bridgeData.sendingAssetId]", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _startBridge() of MultichainFacet contains the following expresssion. This retrieves the value for s.anyTokenAddresses[_bridgeData.sendingAssetId] twice. It might save some gas to first store this in a tmp variable. s.anyTokenAddresses[_bridgeData.sendingAssetId] != address(0) ? ,! s.anyTokenAddresses[_bridgeData.sendingAssetId]: ...", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "DeBridgeFacet permit seems unusable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function deBridgeGate.send() takes a parameter permit. This can only be used if it's signed by the Diamond, see DeBridgeGate.sol#L654-L662. As there is no code to let the Diamond sign a permit, this function doesn't seem usable. function _startBridge(...) ... { ... deBridgeGate.send{ value: nativeAssetAmount }(..., _deBridgeData.permit, ...); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Redundant checks in CircleBridgeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function swapAndStartBridgeTokensViaCircleBridge() contains both noNativeAsset() and onlyAllowSourceToken(). The check noNativeAsset() is not necessary as onlyAllowSourceToken() already verifies the sendingAssetId isn't a native token. 22 function swapAndStartBridgeTokensViaCircleBridge(...) ... { ... noNativeAsset(_bridgeData) onlyAllowSourceToken(_bridgeData, usdc) { ... } modifier noNativeAsset(ILiFi.BridgeData memory _bridgeData) { if (LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { revert NativeAssetNotSupported(); } _; } modifier onlyAllowSourceToken(ILiFi.BridgeData memory _bridgeData, address _token) { if (_bridgeData.sendingAssetId != _token) { revert InvalidSendingToken(); } _; }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Redundant check on _swapData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "This check is not present in the majority of the facets if (_swapData.length == 0) { revert NoSwapDataProvided(); } Ultimately, it's not required as _depositAndSwap() reverts when length is 0.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Duplicate checks done", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "In highlighted cases, a check has been done multiple times at different places:  validateBridgeData modifier on ArbitrumBridgeFacet. _startBridge() does checks already done by functions from which it's called.  depositAsset() does some checks already done by AmarokFacet.startBridgeTokensViaAmarok().", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "calldata can be used instead of memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "When the incoming argument is constant, calldata can be used instead of memory to save gas on copying it to memory. This remains true for individual array elements.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Further gas optimizations for HopFacetOptimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "For the contract HopFacetOptimized it is very important to be gas optimized. Especially on Arbritrum, it is relatively expensive due to the calldata. 24 struct HopData { uint256 bonderFee; uint256 amountOutMin; uint256 deadline; uint256 destinationAmountOutMin; uint256 destinationDeadline; IHopBridge hopBridge; } struct BridgeData { bytes32 transactionId; string bridge; string integrator; address referrer; address sendingAssetId; address receiver; uint256 minAmount; uint256 destinationChainId; bool hasSourceSwaps; bool hasDestinationCall; } function startBridgeTokensViaHopL1ERC20( ILiFi.BridgeData calldata _bridgeData, HopData calldata _hopData ) external { // Deposit assets LibAsset.transferFromERC20(...); _hopData.hopBridge.sendToL2(...); emit LiFiTransferStarted(_bridgeData); } function transferFromERC20(...) ... { if (assetId == NATIVE_ASSETID) revert NullAddrIsNotAnERC20Token(); if (to == NULL_ADDRESS) revert NoTransferToNullAddress(); IERC20 asset = IERC20(assetId); uint256 prevBalance = asset.balanceOf(to); SafeERC20.safeTransferFrom(asset, from, to, amount); if (asset.balanceOf(to) - prevBalance != amount) revert InvalidAmount(); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "payable keyword can be removed for some bridge functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "For the above highlighted functions, the native token is never forwarded to the underlying bridge. In these cases, payable keyword and related modifier refundExcessNative(payable(msg.sender)) can be re- moved to save gas.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "AmarokData.callTo can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "AmarokFacet's final receiver can be different from _bridgeData.receiver address receiver = _bridgeData.hasDestinationCall ? _amarokData.callTo : _bridgeData.receiver; Since both _amarokData.callTo and _bridgeData.receiver are passed by the caller, AmarokData.callTo can be removed, and _bridgeData.receiver can be assumed as the final receiver.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Use requiredEther variable instead of adding twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The cost and nativeAmount are added twice to calculate the requiredEther variable, which can lead to increased gas consumption.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "refundExcessNative modifier can be gas-optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The highlighted code above can be gas-optimized by removing 1 if condition.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "BridgeData.hasSourceSwaps can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The field hasSourceSwaps can be removed from the struct BridgeData. _swapData is enough to identify if source swaps are needed.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Unnecessary validation argument for native token amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Since both msg.value and feeAmount is controlled by the caller, you can remove feeAmount as an argument and assume msg.value is what needs to be collected. This will save gas on comparing these two values and refunding the extra.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Restrict access for cBridge refunds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "cBridge refunds need to be triggered from the contract that sent the transaction to cBridge. This can be done using the executeCallAndWithdraw function. As the function is not cBridge specific it can do any calls for the Diamond contract. Restricting what that function can call would allow more secure automation of refunds.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Stargate now supports multiple pools for the same token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The Stargate protocol now supports multiple pools for the same token on the same chain, each pool may be connected to one or many other chains. It is not possible to store a one-to-one token-to-pool mapping.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Expose receiver in GenericSwapFacet facet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Other than the bridge facets the swap facet does not emit the receiver of a transaction yet.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Track the destination chain on ServiceFeeCollector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "ServiceFeeCollector collects gas fees to send to the destination chain. For example /// @param receiver The address to send gas to on the destination chain function collectTokenGasFees( address tokenAddress, uint256 feeAmount, address receiver ) However, the destination chain is never tracked in the contract.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Executor can reuse SwapperV2 functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Executor.sol's noLeftOvers and _fetchBalances() is copied from SwapperV2.sol.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Consider adding onERC1155Received", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "In addition to ERC721, NFTs can be created using ERC1155 standard. Since, the use case of purchasing an NFT has to be supported, support for ERC1155 tokens can be added.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "SquidFacet uses a different string encoding library", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "SquidFacet uses an OZ library to convert address to string, whereas the underlying bridge uses a different library. Fuzzing showed that these implementations are equivalent.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Assembly in StargateFacet can be replaced with Solidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function toBytes() contains assembly code that can also be replaced with solidity code. Also, see how-to-convert-an-address-to-bytes-in-solidity. 30 function toBytes(address _address) private pure returns (bytes memory) { bytes memory tempBytes; assembly { let m := mload(0x40) _address := and(_address,0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF) mstore(add(m, 20),xor(0x140000000000000000000000000000000000000000, _address) ) mstore(0x40, add(m, 52)) tempBytes := m } return tempBytes; }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Doublecheck quoteLayerZeroFee()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function quoteLayerZeroFee uses msg.sender to determine a fee, while _startBridge() uses _bridgeData.receiver to execute  router.swap. This might give different results. function quoteLayerZeroFee(...) ... { return router.quoteLayerZeroFee( ... , toBytes(msg.sender) ); } function _startBridge(...) ... router.swap{ value: _stargateData.lzFee }(..., toBytes(_bridgeData.receiver), ... ); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Missing modifier refundExcessNative()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function swapAndStartBridgeTokensViaXDaiBridge() of GnosisBridgeFacet() and Gnosis- BridgeL2Facet() don't have the modifier refundExcessNative(). While other Facets have such a modifier.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Special case for cfUSDC tokens in CelerIMFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function startBridgeTokensViaCelerIM() has a special case for cfUSDC tokens, whereas swapAndStartBridgeTokensViaCelerIM() doesn't have this. function startBridgeTokensViaCelerIM(...) ... { if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { if (...) { // special case for cfUSDC token asset = IERC20(CelerToken(_bridgeData.sendingAssetId).canonical()); } else { ... } } ... } function swapAndStartBridgeTokensViaCelerIM(...) ... { ... if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { // no special case for cfUSDC token } ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "External calls of SquidFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The functions CallBridge and CallBridgeCall do random external calls. This is done via a sepa- rate contract multicall SquidMulticall. This might be used to try reentrancy attacks. function _startBridge(...) ... { ... squidRouter.bridgeCall{ value: msgValue }(...); ... squidRouter.callBridgeCall{ value: msgValue }(...); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Missing test coverage for triggerRefund Function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current test suite does not include test cases for the triggerRefund function. This oversight may lead to undetected bugs or unexpected behavior in the function's implementation.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Implicit assumption in MakerTeleportFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _startBridge() of MakerTeleportFacet has the implicit assumption that dai is an ERC20 token. However on GnosisChain the native asset is (x)dai. Note: DAI on GnosisChain is an ERC20, so unlikely this would be a problem in practice. function _startBridge(ILiFi.BridgeData memory _bridgeData) internal { LibAsset.maxApproveERC20( IERC20(dai),...); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Robust allowance handling in maxApproveERC20()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Some tokens, like USDT, require setting the approval to 0 before setting it to another value. The function SafeERC20.safeIncreaseAllowance() doesn't do this. Luckily maxApproveERC20() sets the allowance so high that in practice this never has to be increased. function maxApproveERC20(...) ... { ... uint256 allowance = assetId.allowance(address(this), spender); if (allowance < amount) SafeERC20.safeIncreaseAllowance(IERC20(assetId), spender, MAX_UINT - allowance); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Unused re-entrancy guard", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The RelayerCelerIM.sol#L21 includes a redundant re-entrancy guard, which adds an extra layer of protection against re-entrancy attacks. While re-entrancy guards are crucial for securing contracts, this particular guard is not used.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Redundant duplicate import in the LIFuelFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current LIFuelFacet.sol contains a redundant duplicate import. Identifying and removing dupli- cate imports can streamline the contract and improve maintainability.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Extra checks in executeMessageWithTransfer()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function executeMessageWithTransfer() of RelayerCelerIM ignore the first parameter. seems this could be used to verify the origin of the transaction, which could be an extra security measure. It * @param * (unused) The address of the source app contract function executeMessageWithTransfer(address, ...) ... { }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Variable visibility is not uniform", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "In the current facets, state variables like router/messenger visibilities are not uniform, with some variables declared as public while others are private. thorchainRouter => is defined as public. synapseRouter => is defined as public. deBridgeGate => is defined as private", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Library LibMappings not used everywhere", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The library LibMappings is used in several facets. However, it is not used in the following facets  ReentrancyGuard  AxelarFacet  HopFacet.sol  MultichainFacet  OptimismBridgeFacet  OwnershipFacet", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "transferERC20() doesn't have a null address check for receiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "LibAsset.transferFromERC20() has a null address check on the receiver, but transferERC20() does not.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "LibBytes can be improved", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The following functions are not used  concat()  concatStorage()  equal()  equalStorage()  toBytes32()  toUint128()  toUint16()  toUint256()  toUint32()  toUint64()  toUint8()  toUint96() The call to function slice() for calldata arguments (as done in AxelarExecutor) can be replaced with the in-built slicing provided by Solidity. Refer to its documentation.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Keep generic errors in the GenericErrors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "During the code review, It has been noticed that some of the contracts are re-defined errors. The generic errors like a WithdrawFailed can be kept in the GenericErrors.sol", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Attention points for making the Diamond immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "There are additional attention points to decide upon when making the Diamond immutable: After removing the Owner, the following functions won't work anymore:  AccessManagerFacet.sol - setCanExecute()  AxelarFacet.sol - setChainName()  HopFacet.sol - registerBridge()  MultichainFacet.sol - updateAddressMappings() & registerRouters()  OptimismBridgeFacet.sol - registerOptimismBridge()  PeripheryRegistryFacet.sol - registerPeripheryContract()  StargateFacet.sol - setStargatePoolId() & setLayerZeroChainId()  WormholeFacet.sol - setWormholeChainId() & setWormholeChainIds() There is another authorization mechanism via LibAccess, which arranges access to the functions of  DexManagerFacet.sol  WithdrawFacet.sol Several Periphery contracts also have an Owner:  AxelarExecutor.sol  ERC20Proxy.sol  Executor.sol  FeeCollector.sol  Receiver.sol  RelayerCelerIM.sol  ServiceFeeCollector.sol Additionally ERC20Proxy has an authorization mechanism via authorizedCallers[]", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Check on the final asset in _swapData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "MakerTeleportFacet verifies that the final received asset in _swapData is DAI. This check is not present in majority of the facets (including CircleBridgeFacet). Ideally, every facet should have the check that the final receivingAssetId is equal to sendingAssetId.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Discrepancies in pragma versioning across faucet implementations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The use of different pragma versions in facet implementations can present several implications, with potential risks and compliance concerns that need to be addressed to maintain robust and compliant contracts.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Inconsistent use of validateDestinationCallFlag()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Highlighted code can be replaced with a call to validateDestinationCallFlag() function as done in other Facets.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Inconsistent utilization of the isNativeAsset function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The isNativeAsset function is designed to distinguish native assets from other tokens within facet- based smart contract implementations. However, it has been observed that the usage of the isNativeAsset function is not consistent across various facets. Ensuring uniform application of this function is crucial for maintaining the accuracy and reliability of the asset identification and processing within the facets.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Unused events/errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The contracts contain several events and error messages that are not used anywhere in the contract code. These unused events and errors add unnecessary code to the contract, increasing its size.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Make bridge parameters dynamic by keeping them as a parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current implementation has some bridge parameters hardcoded within the smart contract. This approach limits the flexibility of the contract and may cause issues in the future when upgrades or changes to the bridge parameters are required. It would be better to keep the bridge parameters as a parameter to make them dynamic and easily changeable in the future. HopFacetOptimized.sol => Relayer & RelayerFee MakerTeleportFacet.sol's => Operator person (or specified third party) responsible for initiating minting process on destination domain by providing (in the fast path) Oracle attestations.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Incorrect comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The highlighted comment incorrectly refers USDC address as DAI address.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Redundant console log", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The contract includes Console.sol from test file, which is only used for debugging purposes. In- cluding it in the final version of the contract can increase the contract size and consume more gas, making it more expensive to deploy and execute.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "SquidFacet doesn't revert for incorrect routerType", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "If _squidData.routeType passed by the user doesn't match BridgeCall, CallBridge, or Call- BridgeCall, SquidFacet just takes the funds from the user and returns without calling the bridge. This, when the combined with the issue \"Max approval to any address is possible\", lets anyone steal those funds. Note: Solidity enum checks should prevent this issue, but it is safer to do an extra check.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Operators._hasFundableKeys returns true for operators that do not have fundable keys", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Because _hasFundableKeys uses operator.stopped in the check, an operator without fundable keys be validated and return true. Scenario: Op1 has  keys = 10  limit = 10  funded = 10  stopped = 10 This means that all the keys got funded, but also \"exited\". Because of how _hasFundableKeys is made, when you call _hasFundableKeys(op1) it will return true even if the operator does not have keys available to be funded. By returning true, the operator gets wrongly included in getAllFundable returned array. That function is critical because it is the one used by pickNextValidators that picks the next validator to be selected and stake delegate user ETH. Because of this issue in _hasFundableKeys also the issue OperatorsRegistry._getNextValidatorsFromActive- Operators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys) can happen DOSing the contract that will always make pickNextValidators return empty. Check Appendix for a test case to reproduce this issue.", "labels": ["Spearbit", "LiquidCollective", "Severity: Critical Risk"]}, {"title": "OperatorsRegistry._getNextValidatorsFromActiveOperators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "This issue is also related to OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator . Consider a scenario where we have Op at index 0 name op1 active true limit 10 funded 10 stopped 10 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 In this case,  Op1 got all 10 keys funded and exited. Because it has keys=10 and limit=10 it means that it has no more keys to get funded again.  Op2 instead has still 10 approved keys to be funded. Because of how the selection of the picked validator works uint256 selectedOperatorIndex = 0; for (uint256 idx = 1; idx < operators.length;) { if ( operators[idx].funded - operators[idx].stopped < operators[selectedOperatorIndex].funded - operators[selectedOperatorIndex].stopped ) { selectedOperatorIndex = idx; } unchecked { ++idx; } } When the function finds an operator with funded == stopped it will pick that operator because 0 < operators[selectedOperatorIndex].funded - operators[selectedOperatorIndex].stopped. After the loop ends, selectedOperatorIndex will be the index of an operator that has no more validators to be funded (for this scenario). Because of this, the following code uint256 selectedOperatorAvailableKeys = Uint256Lib.min( operators[selectedOperatorIndex].keys, operators[selectedOperatorIndex].limit ) - operators[selectedOperatorIndex].funded; when executed on Op1 it will set selectedOperatorAvailableKeys = 0 and as a result, the function will return return (new bytes[](0), new bytes[](0));. 13 In this scenario when stopped==funded and there are no keys available to be funded (funded == min(limit, keys)) the function will always return an empty result, breaking the pickNextValidators mechanism that won't be able to stake user's deposited ETH anymore even if there are operators with fundable validators. Check the Appendix for a test case to reproduce this issue.", "labels": ["Spearbit", "LiquidCollective", "Severity: Critical Risk"]}, {"title": "Oracle.removeMember could, in the same epoch, allow members to vote multiple times and other members to not vote at all", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of removeMember is introducing an exploit that allows an oracle member to vote again and again (in the same epoch) and an oracle that has never voted is prevented from voting (in the same epoch). Because of how OracleMembers.deleteItem is implemented, it will swap the last item of the array with the one that will be deleted and pop the last element. Let's make an example: 1) At T0 m0 to the list of members  members[0] = m0. 2) At T1 m1 to the list of members  members[1] = m1. 3) At T3 m0 call reportBeacon(...). By doing that, ReportsPositions.register(uint256(0)); will be called, registering that the member at index 0 has registered the vote. 4) At T4, the oracle admin call removeMember(m0). This operation, as we said, will swap the member's address from the last position of the array of members with the position of the member that will be deleted. After doing that will pop the last position of the array. The state changes from members[0] = m0; members[1] = m1 to members[0] = m1;. At this point, the oracle member m1 will not be able to vote during this epoch because when he/she will call reportBeacon(...) the function will enter inside the check. if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(_epochId, msg.sender); } This is because int256 memberIndex = OracleMembers.indexOf(msg.sender); will return 0 (the position of the m0 member that have already voted) and ReportsPositions.get(uint256(0)) will return true. At this point, if for whatever reason an admin of the contract add again the deleted oracle, it would be added to the position 1 of the array of the members, allowing the same member that have already voted, to vote again. Note: while the scenario where a removed member can vote multiple time would involve a corrupted admin (that would re-add the same member) the second scenario that prevent a user to vote would be more common. Check the Appendix for a test case to reproduce this issue. 14", "labels": ["Spearbit", "LiquidCollective", "Severity: High Risk"]}, {"title": "Order of calls to removeValidators can affect the resulting validator keys set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "If two entities A and B (which can be either the admin or the operator O with the index I) send a call to removeValidators with 2 different set of parameters:  T1 : (I, R1)  T2 : (I, R2) Then depending on the order of transactions, the resulting set of validators for this operator might be different. And since either party might not know a priori if any other transaction is going to be included on the blockchain after they submit their transaction, they don't have a 100 percent guarantee that their intended set of validator keys are going to be removed. This also opens an opportunity for either party to DoS the other party's transaction by frontrunning it with a call to remove enough validator keys to trigger the InvalidIndexOutOfBounds error: OperatorsRegistry.1.sol#L324-L326: if (keyIndex >= operator.keys) { revert InvalidIndexOutOfBounds(); } to removeValidators and compare it", "labels": ["Spearbit", "LiquidCollective", "Severity: High Risk"]}, {"title": "Non-zero operator.limit should always be greater than or equal to operator.funded", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "For the subtraction operation in OperatorsRegistry.1.sol#L428-L430 to not underflow and revert, there should be an assumption that operators[selectedOperatorIndex].limit >= operators[selectedOperatorIndex].funded Perhaps this is a general assumption, but it is not enforced when setOperatorLimits is called with a new set of limits.", "labels": ["Spearbit", "LiquidCollective", "Severity: High Risk"]}, {"title": "Decrementing the quorum in Oracle in some scenarios can open up a frontrunning/backrunning opportunity for some oracle members", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Assume there are 2 groups of oracle members A, B where they have voted for report variants Va and Vb respectively. Let's also assume the count for these variants Ca and Cb are equal and are the highest variant vote counts among all possible variants. If the Oracle admin changes the quorum to a number less than or equal to Ca + 1 = Cb + 1, any oracle member can backrun this transaction by the admin to decide which report variant Va or Vb gets pushed to the River. This is because when a lower quorum is submitted by the admin and there exist two variants that have the highest number of votes, in the _getQuorumReport function the returned isQuorum parameter would be false since repeat == 0 is false: Oracle.1.sol#L369: return (maxval >= _quorum && repeat == 0, variants[maxind]); Note that this issue also exists in the commit hash 030b52feb5af2dd2ad23da0d512c5b0e55eb8259 and can be triggered by the admin either by calling setQuorum or addMember when the abovementioned conditions are met. Also, note that the free oracle member agent can frontrun the admin transaction to decide the quorum earlier in the scenario above. Thus this way _getQuorumReport would actually return that it is a quorum.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "_getNextValidatorsFromActiveOperators can be tweaked to find an operator with a better validator pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Assume for an operator: (A, B) = (funded - stopped, limit - funded) The current algorithm finds the first index in the cached operators array with the minimum value for A and tries to gather as many publicKeys and signatures from this operator's validators up to a max of _requestedAmount. But there is also the B cap for this amount. And if B is zero, the function returns early with empty arrays. Even though there could be other approved and non-funded validators from other operators. Related: OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator , OperatorsRegistry._getNextValidatorsFromActiveOperators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys) , _hasFundableKeys marks operators that have no more fundable validators as fundable.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Dust might be trapped in WlsETH when burning one's balance.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "It is not possible to burn the exact amount of minted/deposited lsETH back because of the _value provided to burn is in ETH. Assume we've called mint(r,v) with our address r, then to get the v lsETH back to our address, we need to find an x where v = bx S B c and call burn(r, x) (Here S represents the total share of lsETH and B the total underlying value.). It's not always possible to find the exact x. So there will always be an amount locked in this contract ( v (cid:0) bx S B c ). These dust amounts can accumulate from different users and turn into a big number. To get the full amount back, the user needs to mint more wlsETH tokens so that we can find an exact solution to v = bx S B c. The extra amount to get the locked-up fees back can be engineered. The same problem exists for transfer and transferFrom. Also note, if you have minted x amount of shares, the balanceOf would tell you that you own b = b xB S c wlsETH. Internally wlsETH keeps track of the shares x. So users think they can only burn b amount, plug that in for the _value and in this case, the number of shares burnt would be b xB S cS B % $ which has even more rounding errors. wlsETH could internally track the underlying but that would not appropriate value like lsETH, which would basically be kind of wETH. We think the issue of not being able to transfer your full amount of shares is not as serious as not being able to burn back your shares into lsETH. On the same note, we think it would be beneficial to expose the wlsETH share amount to the end user: function sharesBalanceOf(address _owner) external view returns (uint256 shares) { return BalanceOf.get(_owner); }", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "BytesLib.concat can potentailly return results with dirty byte paddings.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "concat does not clean the potential dirty bytes that might have been copied from _postBytes (nor does it clean the padding). The dirty bytes from _postBytes are carried over to the padding for tempBytes.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "The reportBeacon is prone to front-running attacks by oracle members", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "There could be a situation where the oracle members are segmented into 2 groups A and B , and members of the group A have voted for the report variant Va and the group B for Vb . Also, let's assume these two variants are 1 vote short of quorum. Then either group can try to front-run the other to push their submitted variant to river.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Shares distributed to operators suffer from rounding error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "_rewardOperators distribute a portion of the overall shares distributed to operators based on the number of active and funded validators that each operator has. The current number of shares distributed to a validator is calculated by the following code _mintRawShares(operators[idx].feeRecipient, validatorCounts[idx] * rewardsPerActiveValidator); where rewardsPerActiveValidator is calculated as uint256 rewardsPerActiveValidator = _reward / totalActiveValidators; This means that in reality each operator receives validatorCounts[idx] * (_reward / totalActiveValida- tors) shares. Such share calculation suffers from a rounding error caused by division before multiplication.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Note that  limited  number of validators (already pushed by op) that have been approved by Alluvial and can be selected to be funded.  funded  number of validators funded.  stopped  number of validators exited (so that were funded at some point but for any reason they have exited the staking). The implementation of the function should favor operators that have the highest number of available validators to be funded. Nevertheless functions favor validators that have stopped value near the funded value. Consider the following example: Op at index 0 name op1 active true limit 10 funded 5 stopped 5 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 1) op1 and op2 have 10 validators whitelisted. 2) op1 at time1 get 5 validators funded. 3) op1 at time2 get those 5 validators exited, this mean that op.stopped == 5. In this scenario, those 5 validators would not be used because they are \"blacklisted\". At this point  op1 have 5 validators that can be funded. 24  op2 have 10 validators that can be funded. pickNextValidators logic should favor operators that have the higher number of available keys (not funded but approved) to be funded. If we run operatorsRegistry.pickNextValidators(5); the result is this Op at index 0 name op1 active true limit 10 funded 10 stopped 5 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 Op1 gets all the remaining 5 validators funded, the function (from the specification of the logic) should instead have picked Op2. Check the Appendix for a test case to reproduce this issue.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "approve() function can be front-ran resulting in token theft", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The approve() function has a known race condition that can lead to token theft. If a user calls the approve function a second time on a spender that was already allowed, the spender can front-run the transaction and call transferFrom() to transfer the previous value and still receive the authorization to transfer the new value.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Add missing input validation on constructor/initializer/setters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Allowlist.1.sol  initAllowlistV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level.  allow should check _accounts[i] to be not equal to address(0). Firewall.sol  constructor should check that: governor_ != address(0). executor_ != address(0). destination_ != address(0).  setGovernor should check that newGovernor != address(0).  setExecutor should check that newExecutor != address(0). OperatorsRegistry.1.sol  initOperatorsRegistryV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level.  addOperator should check: _name to not be an empty string. _operator to not be address(0). _feeRecipi- ent to not be address(0).  setOperatorAddress should check that _newOperatorAddress is not address(0).  setOperatorFeeRecipientAddress should check that _newOperatorFeeRecipientAddress is not address(0).  setOperatorName should check that _newName is not an empty string. Oracle.1.sol  initOracleV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level. Consider also adding some min and max limit to the values of _annualAprUpperBound and _relativeLowerBound and be sure that _epochsPerFrame, _slotsPerEpoch, _secondsPerSlot and _genesisTime matches the values expected.  addMember should check that _newOracleMember is not address(0).  setBeaconBounds: Consider adding min/max value that _annualAprUpperBound and _relativeLowerBound should respect. River.1.sol  initRiverV1: _globalFee should follow the same validation done in setGlobalFee. Note that client said that 0 is a valid _- globalFee value \"The revenue redistributuon would be computed off-chain and paid by the treasury in that case. It's still an on-going discussion they're having at Alluvial.\" _operatorRewardsShare should follow the same validation done in setOperatorRewardsShare. Note that client said that 0 is a valid _operatorRewardsShare value \"The revenue redistributuon would be computed off-chain and paid by the treasury in that case. It's still an on-going discussion they're having at Alluvial.\" ConsensusLayerDepositManager.1.sol  initConsensusLayerDepositManagerV1: _withdrawalCredentials should not be empty and follow the re- quirements expressed in the following official Consensus Specs document. 26", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "LibOwnable._setAdmin allows setting address(0) as the admin of the contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "While other contracts like RiverAddress (for example) do not allow address(0) to be used as set input parameter, there is no similar check inside LibOwnable._setAdmin. Because of this, contracts that call LibOwnable._setAdmin with address(0) will not revert and functions that should be callable by an admin cannot be called anymore. This is the list of contracts that import and use the LibOwnable library  AllowlistV1  OperatorsRegistryV1  OracleV1  RiverV1", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "OracleV1.getMemberReportStatus returns true for non existing oracles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "memberIndex will be equal to -1 for non-existing oracles, which will cause the mask to be equal to 0, which will cause the function to return true for non-existing oracles.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Operators might add the same validator more than once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Operators can use OperatorsRegistryV1.addValidators to add the same validator more than once. Depositors' funds will be directed to these duplicated addresses, which in turn, will end up having more than 32 eth. This act will damage the capital efficiency of the entire deposit pool and thus will potentially impact the pool's APY.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "OracleManager.setBeaconData possible front running attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The system is designed in a way that depositors receive shares (lsETH) in return for their eth de- posit. A share represents a fraction of the total eth balance of the system in a given time. Investors can claim their staking profits by withdrawing once withdrawals are active in the system. Profits are being pulled from ELFeeRe- cipient to the River contract when the oracle is calling OracleManager.setBeaconData. setBeaconData updates BeaconValidatorBalanceSum which might be increased or decreased (as a result of slashing for instance). Investors have the ability to time their position in two main ways:  Investors might time their deposit just before profits are being distributed, thus harvesting profits made by others.  Investors might time their withdrawal / sell lsETH on secondary markets just before the loss is realized. By doing this, they will effectively avoid the loss, escaping the intended mechanism of socializing losses.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "SharesManager._mintShares - Depositors may receive zero shares due to front-running", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The number of shares minted to a depositor is determined by (_underlyingAssetValue * _total- Supply()) / oldTotalAssetBalance. Potential attackers can spot a call to UserDepositManagerV1._deposit and front-run it with a transaction that sends wei to the contract (by self-destructing another contract and sending the funds to it), causing the victim to receive fewer shares than what he expected. More specifically, In case old- TotalAssetBalance() is greater than _underlyingAssetValue * _totalSupply(), then the number of shares the depositor receives will be 0, although _underlyingAssetValue will be still pulled from the depositors balance. An attacker with access to enough liquidity and to the mem-pool data can spot a call to UserDepositManagerV1._- deposit and front-run it by sending at least totalSupplyBefore * (_underlyingAssetValue - 1) + 1 wei to the contract . This way, the victim will get 0 shares, but _underlyingAssetValue will still be pulled from its account balance. In this case, the attacker does not necessarily have to be a whitelisted user, and it is important to mention that the funds that were sent by him can not be directly claimed back, rather, they will increase the price of the share. The attack vector mentioned above is the general front runner case, the most profitable attack vector will be the case where the attacker is able to determine the share price (for instance if the attacker mints the first share). In this scenario, the attacker will need to send at least attackerShares * (_underlyingAssetValue - 1) + 1 to the contract, (attackerShares is completely controlled by the attacker, and thus can be 1). In our case, depositors are whitelisted, which makes this attack harder for a foreign attacker.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Orphaned (index, values) in SlotOperator storage slots in operatorsRegistry", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "If !opExists corresponds to an operator which has OperatorResolution.active set to false, the line below can leave some orphaned (index, values) in SlotOperator storage slots: _setOperatorIndex(name, newValue.active, r.value.length - 1);", "labels": ["Spearbit", "LiquidCollective", "Severity: Low Risk"]}, {"title": "OperatorsRegistry.setOperatorName Possible front running attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "1. setOperatorName reverts for an already used name, which means that a call to setOperatorName might be front-ran using the same name. The front-runner can launch the same attack again and again thus causing a DoS for the original caller. 2. setOperatorName can be called either by an operator (to edit his own name) or by the admin. setOpera- torName will revert for an already used _newName. setOperatorName caller might be front-ran by the identical transaction transmitted by someone else, which will lead to failure for his transaction, where in practice this failure is a \"false failure\" since the desired change was already made.", "labels": ["Spearbit", "LiquidCollective", "Severity: Low"]}, {"title": "Prevent users from burning token via lsETH/wlsETH transfer or transferFrom functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of both lsETH (SharesManager component of River contract) and wlsETH allow the user to \"burn\" tokens, sending them directly to the address(0) via the transfer and transferFrom function. By doing that, it would bypass the logic of the existing burn functions present right now (or in the future when withdrawals will be enabled in River) in the protocol.", "labels": ["Spearbit", "LiquidCollective", "Severity: Low Risk"]}, {"title": "In addOperator when emitting an event use stack variables instead of reading from memory again", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In OperatorsRegistry's addOperator function when emitting the AddedOperator event we read from memory all the event parameters except operatorIndex. emit AddedOperator(operatorIndex, newOperator.name, newOperator.operator, newOperator.feeRecipient); We can avoid reading from memory to save gas.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Rewrite pad64 so that it doesn't use BytesLib.concat and BytesLib.slice to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "We can avoid using the BytesLib.concat and BytesLib.slice and write pad64 mostly in assembly. Since the current implementation adds more memory expansion than needed (also not highly optimized).", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Cache r.value.length used in a loop condition to avoid reading from the storage multiple times.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In a loop like the one below, consider caching r.value.length value to avoid reading from storage on every round of the loop. for (uint256 idx = 0; idx < r.value.length;) {", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Rewrite the for loop in ValidatorKeys.sol::getKeys to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Rewrite the for loop in ValidatorKeys.sol::getKeys to save gas", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Operators.get in _getNextValidatorsFromActiveOperators can be replaced by Opera- tors.getByIndex to avoid extra operations/gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Operators.get in _getNextValidatorsFromActiveOperators performs multiple checks that have been done before when Operators.getAllFundable() was called. This includes finding the index, and checking if OperatorResolution.active is set. These are all not necessary.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Avoid unnecessary equality checks with true in if statements", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Statements of the type if( condition == true) can be replaced with if(condition). The extra comparison with true is redundant.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Rewrite OperatorRegistry.getOperatorDetails to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In getOperatorDetails the 1st line is: _index = Operators.indexOf(_name); Since we already have the _index from this line we can use that along with getByIndex to retrieve the _opera- torAddress. This would reduce the gas cost significantly, since Operators.get(_name) calls Operators._getOp- eratorIndex(name) to find the _index again. testExecutorCanSetOperatorLimit() (gas: -1086 (-0.001%)) testGovernorCanSetOperatorLimit() (gas: -1086 (-0.001%)) testUserDepositsForAnotherUser() (gas: -2172 (-0.001%)) testDeniedUser() (gas: -2172 (-0.001%)) testELFeeRecipientPullFunds() (gas: -2172 (-0.001%)) testUserDepositsUnconventionalDeposits() (gas: -2172 (-0.001%)) testUserDeposits() (gas: -2172 (-0.001%)) testNoELFeeRecipient() (gas: -2172 (-0.001%)) testUserDepositsTenPercentFee() (gas: -2172 (-0.001%)) testUserDepositsFullAllowance() (gas: -2172 (-0.001%)) testValidatorsPenaltiesEqualToExecLayerFees() (gas: -2172 (-0.001%)) testValidatorsPenalties() (gas: -2172 (-0.001%)) testUserDepositsOperatorWithStoppedValiadtors() (gas: -3258 (-0.002%)) testMakingFunctionGovernorOnly() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorLimit() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorStatus() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorStoppedValidatorCount() (gas: -1086 (-0.005%)) testExecutorCanSetOperatorStoppedValidatorCount() (gas: -1086 (-0.006%)) testGovernorCanSetOperatorStatus() (gas: -1086 (-0.006%)) testGovernorCanSetOperatorStoppedValidatorCount() (gas: -1086 (-0.006%)) testGovernorCanAddOperator() (gas: -1086 (-0.006%)) testExecutorCanSetOperatorStatus() (gas: -1086 (-0.006%)) Overall gas change: -36924 (-0.062%) Also note, when the operator is not OperatorResolution.active, _index becomes -1 in both cases. With the change suggested if _index is -1, uint256(_index) == type(uint256).max which would cause getByIndex to revert with OperatorNotFoundAtIndex(index). But with the current code, it will revert with an index out-of-bound type of error. _operatorAddress = Operators.getByIndex(uint256(_index)).operator;", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Rewrite/simplify OracleV1.isMember to save gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "OracleV1.isMember can be simplified to save gas.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Cache beaconSpec.secondsPerSlot * beaconSpec.slotsPerEpoch multiplication in to save gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The calculation for _startTime and _endTime uses more multiplication than is necessary.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "_rewardOperators could save gas by skipping operators with no active and funded validators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "_rewardOperators is the River function that distribute the earning rewards to each active operator based on the amount of active validators. The function iterate over the list of active operators returned by OperatorsRegistryV1.listActiveOperators calculating the total amount of active and funded validators (funded-stopped) and the number of active and funded validators (funded-stopped) for each operator. Because of current code, the final temporary array validatorCounts could have some item that contains 0 if the operator in the index position had no more active validators. This mean that: 1) gas has been wasted during the loop 2) gas will be wasted in the second loop, distributing 0 shares to an operator without active and funded valida- tors 3) _mintRawShares will be executed without minting any shares but emitting a Transfer event", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Consider adding a strict check to prevent Oracle admin to add more than 256 members", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "At the time of writing this issue in the latest commit at 030b52feb5af2dd2ad23da0d512c5b0e55eb8259, in the natspec docs of OracleMembers there is a @dev comment that says @dev There can only be up to 256 oracle members. This is due to how report statuses are stored in Reports Positions If we look at ReportsPositions.sol the natspec docs explains that Each bit in the stored uint256 value tells if the member at a given index has reported But both Oracle.addMember and OracleMembers.push do not prevent the admin to add more than 256 items to the list of oracle members. If we look at the result of the test (located in Appendix), we can see that:  It's possible to add more than 256 oracle members.  The result of oracle.getMemberReportStatus(oracleMember257) return true even if the oracle member has not reported yet.  Because of that, oracle.reportConsensusLayerData (executed by oracleMember257) reverts correctly.  If we remove a member from the list (for example oracle member with index 1) the oracleMember257 it will be able to vote because will be swapped with the removed member and at oracle.getMemberReportStatus(oracleMember257) return false. this point 45", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "ApprovalsPerOwner.set does not check if owner or spender is address(0).", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "When ApprovalsPerOwner value is set for an owner and a spender, the addresses of the owner and the spender are not checked against address(0).", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Quorum could be higher than the number of oracles, DOSing the Oracle contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of Oracle.setQuorum only checks if the _newQuorum input parameter is not 0 or equal to the current quorum value. By setting a quorum higher than the number of oracle members, no quorum could be reached for the current or future slots.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "ConsensusLayerDepositManager.depositToConsensusLayer should be called only after a quorum has been reached to avoid rewarding validators that have not performed during the frame", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Alluvial is not tracking timestamps or additional information of some actions that happen on-chain like  when operator validator is funded on the beacon chain.  when an operator is added.  when validators are added or removed.  when a quorum is reached.  when rewards/penalties/slashes happen and which validator is involved.  and so on... 46 By not having these enriched informations it could happen that validators that have not contributed to a frame will still get rewards and this could be not fair to other validators that have contributed to the overall balance by working and bringing rewards. Let's make an example: we have 10 operators with 1k validators each at the start of a frame. At some point during the very end of the frame validato_10 get approved 9k validators and all of them get funded. Those validators only participated a small fraction in the production of the rewards. But because there's no way to track these timing and because oracles do not know anything about these (they just need to report the balance and the number of validators during the frame) they will report and arrive to a quorum of reportBeacon(correctEpoch, correctAmountOfBalance, 21_000) that will trigger the OracleManagerV1.setBeaconData. The contract check that 21_000 > DepositedValidatorCount.get() will pass and _onEarnings is called. Let's not consider the math involved in the process of calculating the number of shares to be distributed based on the staked balance delta, let's say that because of all the increase in capital Alluvial will call _rewardOperators(1_- 000_000); distributing 1_000_000 shares to operators based on the number of validators that produced that reward. Because as we said we do not know how much each validator has contributed, those shares will be contributed in the same way to operators that could have not contributed at all to the epoch. This is true for both scenarios where validators that have joined or exited the beacon chain not at the start of the epoch where the last quorum was set.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Document the decision to include executionLayerFees in the logic to trigger _onEarnings to dis- tribute rewards to Operators and Treasury", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The setBeaconData function from OracleManager contract is called when oracle members have reached a quorum. The function after checking that the report data respects some integrity check performs a check to distribute rewards to operators and treasury if needed: uint256 executionLayerFees = _pullELFees(); if (previousValidatorBalanceSum < _validatorBalanceSum + executionLayerFees) { _onEarnings((_validatorBalanceSum + executionLayerFees) - previousValidatorBalanceSum); } The delta between _validatorBalanceSum and previousValidatorBalanceSum is the sum of all the rewards, penalties and slashes that validators have accumulated during the validation work of one or multiple frames. By adding executionLayerFees to the check, it means that even if the validators have performed poorly (the sum of rewards is less than the sum of penalties+slash) they could still get rewards if executionLayerFees is greater than the negative delta of newSum-prevSum. If we look at the natspec of the _onEarnings it seems that only the validator's balance (without fees) should be used in the if check. 47 /// @notice Handler called if the delta between the last and new validator balance sum is positive /// @dev Must be overriden /// @param _profits The positive increase in the validator balance sum (staking rewards) function _onEarnings(uint256 _profits) internal virtual;", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider documenting how and if funds from the execution layer fee recipient are considered inside the annualAprUpperBound and relativeLowerBound boundaries.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "When oracle members reach a quorum, the _pushToRiver function is called. Alluvial is performing some sanity check to prevent malicious oracle member to report malicious beacon data. Inside the function, uint256 prevTotalEth = IRiverV1(payable(address(riverAddress))).totalUnderlyingSupply(); riverAddress.setBeaconData(_validatorCount, _balanceSum, bytes32(_epochId)); uint256 postTotalEth = IRiverV1(payable(address(riverAddress))).totalUnderlyingSupply(); uint256 timeElapsed = (_epochId - LastEpochId.get()) * _beaconSpec.slotsPerEpoch * _beaconSpec.secondsPerSlot; ,! _sanityChecks(postTotalEth, prevTotalEth, timeElapsed); function _sanityChecks(uint256 _postTotalEth, uint256 _prevTotalEth, uint256 _timeElapsed) internal ,! view { if (_postTotalEth >= _prevTotalEth) { uint256 annualAprUpperBound = BeaconReportBounds.get().annualAprUpperBound; if ( uint256(10000 * 365 days) * (_postTotalEth - _prevTotalEth) > annualAprUpperBound * _prevTotalEth * _timeElapsed ) { revert BeaconBalanceIncreaseOutOfBounds(_prevTotalEth, _postTotalEth, _timeElapsed, ,! annualAprUpperBound); } } else { uint256 relativeLowerBound = BeaconReportBounds.get().relativeLowerBound; if (uint256(10000) * (_prevTotalEth - _postTotalEth) > relativeLowerBound * _prevTotalEth) { revert BeaconBalanceDecreaseOutOfBounds(_prevTotalEth, _postTotalEth, _timeElapsed, relativeLowerBound); } ,! } } Both prevTotalEth and postTotalEth call SharesManager.totalUnderlyingSupply() that returns the value from Inside those balance is also included the amount of fees that are pulled from the River._assetBalance(). ELFeeRecipient (Execution Layer Fee Recipient). Alluvial should document how and if funds from the execution layer fee recipient are also considered inside the annualAprUpperBound and relativeLowerBound boundaries. 48", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Allowlist.allow allows arbitrary values for _statuses input", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of allow does not check if the value inside each _statuses item is a valid value or not. The function can be called by both the administrator or the allower (roles authorized to manage the user permissions) that can specify arbitrary values to be assigned to the corresponding _accounts item. The user's permissions handled by Allowlist are then used by the River contract in different parts of the code. Those permissions inside the River contracts are a limited set of permissions that could not match what the allower /admin of the Allowlist has used to update a user's permission when the allow function was called.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider exploring a way to update the withdrawal credentials and document all the possible scenarios", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The withdrawal credentials is currently set when River.initRiverV1 is called. The func- tion will internally call ConsensusLayerDepositManager.initConsensusLayerDepositManagerV1 that will perform WithdrawalCredentials.set(_withdrawalCredentials); After initializing the withdrawal credentials, there's no way to update it and change it. The withdrawal cre- dentials is a key part of the whole protocol and everything that concern it should be well documented including all the worst-case scenario  What if the withdrawal credentials is lost?  What if the withdrawal credentials is compromised?  What if the withdrawal credentials must be changed (lost, compromised or simply the wrong one has been submitted)? What should be implemented inside the Alluvial logic to use the new withdrawal creden- tials for the operator's validators that have not been funded yet (the old withdrawal credentials has not been sent to the Deposit contract)? Note that currently there's seem to be no way to update the withdrawal credentials for a validator already submitted to the Deposit contract.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Oracle contract allows members to skip frames and report them (even if they are past) one by one or all at once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of reportBeacon allows oracle members to skip frames (255 epochs) and report them (even if they are past) one by one or all at once. Let's assume that members arrived to a quorum for epochId_X. When quorum is reached, _pushToRiver is called, and it will update the following properties:  clean all the storage used for member reporting.  set ExpectedEpochId to epochId_X + 255.  set LastEpochId to epochId_X. With this context, let's assume that members decide to wait 30 frames (30 days) or that for 30 days they cannot arrive at quorum. At the new time, the new epoch would be epochId_X + 255 * 30 The following scenarios can happen:  1) Report at once all the missed epochs Instead of reporting only the current epoch (epochId_X + 255 * 30), they will report all the previous \"skipped\" epochs that are in the past. In this scenario, ExpectedEpochId contains the number of the expected next epoch assigned 30 days ago from the previous call to _pushToRiver. In reportBeacon if the _epochId is what the system expect (equal to Expect- edEpochId) the report can go on. So to be able to report all the missing reports of the \"skipped\" frames the member just need to call in a se- quence reportBeacon(epochId_X + 255, ...), reportBeacon(epochId_X + 255 + 255, ...) + .... + report- Beacon(epochId_X + 255 * 30, ...)  2) Report only the last epoch In this scenario, they would call directly reportBeacon(epochId_X + 255 * 30, ...). _pushToRiver call _sani- tyChecks to perform some checks as do not allow changes in the amount of staked ether that are below or above some bounds. The call that would be made is _sanityChecks(oracleReportedStakedBalance, prevTotalEth, timeElapsed) where timeElapsed is calculated as uint256 timeElapsed = (_epochId - LastEpochId.get()) * _beacon- Spec.slotsPerEpoch * _beaconSpec.secondsPerSlot; So, time elapsed is the number of seconds between the reported epoch and the LastEpochId. But in this scenario, LastEpochId has the old value from the previous call to _pushToRiver made 30 days ago that will be epochId_X. Because of this, the check made inside _sanityChecks for the upper bound would be more relaxed, allowing a wider spread between oracleReportedStakedBalance and prevTotalEth", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider renaming OperatorResolution.active to a more meaningful name", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The name active in the struct OperatorResolution could be misleading because it can be confused with the fact that an operator (the struct containing the real operator information is Operator ) is active or not. The value of OperatorResolution.active does not represent if an operator is active, but is used to know if the index associated to the struct's item (OperatorResolution.index) is used or not.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "lsETH and WlsETH's name() functions return inconsistent name.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "lsETH.name() is River Ether, while WlsETH.name() is Wrapped Alluvial Ether.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Rename modifiers to have consistent naming and patterns only<ROLE>.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The modifiers ifGovernor and ifGovernorOrExecutor in Firewall.sol have a different naming conventions and also logical patterns.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "OperatorResolution.active might be a redundant struct field which can be removed.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The value of active stays true once it has been set true for a given index. This is especially true since the only call to Operators.set is from OperatorsRegistryV1.addOperator which does not override values for already registered names.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "The expression for selectedOperatorAvailableKeys in OperatorsRegistry can be simplified.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "tors[selectedOperatorIndex].keys. Since the places that the limit has been set with a value other than 0 has checks against going above keys bound: operators[selectedOperatorIndex].limit is always less than or equal OperatorsRegistry.1.sol#L250-L252 if (_newLimits[idx] > operator.keys) { revert OperatorLimitTooHigh(_newLimits[idx], operator.keys); } OperatorsRegistry.1.sol#L324-L326 if (keyIndex >= operator.keys) { revert InvalidIndexOutOfBounds(); } OperatorsRegistry.1.sol#L344-L346 52 if (_indexes[_indexes.length - 1] < operator.limit) { operator.limit = _indexes[_indexes.length - 1]; }", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "The unused constant DELTA_BASE can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The constant DELTA_BASE in BeaconReportBounds is never used.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Remove unused modifiers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The modifier active(uint256 _index) is not used in the project.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Modifier names do not follow the same naming patterns", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The modifier names do not follow the same naming patterns in OperatorsRegistry.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "In AllowlistV1.allow the input variable _statuses can be renamed to better represent that values it holds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In AllowlistV1.allow the input variable _statuses can be renamed to better represent the values it holds. _statuses is a bitmap where each bit represents a particular action that a user can take.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "riverAddress can be renamed to river and we can avoid extra interface casting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "riverAddress's name suggest that it is only an address. Although it is an address with the IRiverV1 attached to it. Also, we can avoid unnecessary casting of interfaces.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Define named constants for numeric literals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In _sanitychecks there 2 numeric literals 10000 and 365 days used: uint256(10000 * 365 days) * (_postTotalEth - _prevTotalEth) ... if (uint256(10000) * (_prevTotalEth - _postTotalEth) > relativeLowerBound * _prevTotalEth) {", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Move memberIndex and ReportsPositions checks at the beginning of the OracleV1.reportBeacon function.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The checks for memberIndex == -1 and ReportsPositions.get(uint256(memberIndex)) happen in the middle of reportBeacon after quite a few calculations are done.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Document what incentivizes the operators to run their validators when globalFee is zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "If GlobalFee could be 0, then neither the treasury nor the operators earn rewards. What factor would motivate the operators to keep their validators running?", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Document how Alluvial plans to prevent institutional investors and operators get into business directly and bypass using the River protocol.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Since the list of operators and also depositors can be looked up from the information on-chain, what would prevent Institutional investors (users) and the operators to do business outside of River? Is there going to be an off-chain legal contract between Alluvial and these other entities to prevent this scenario?", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Document how operator rewards will be distributed if OperatorRewardsShare is zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "If OperatorRewardsShare could be 0, then the operators won't earn rewards. What factor would motivate the operators to keep their validators running? Sidenote: Other incentives for the operators to keep their validators running (if their reward share portion is 0) would be some sort of MEV or block proposal/attestation bribes. Related: Avoid to waste gas distributing rewards when the number of shares to be distributed is zero", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Current operator reward distribution does not favor more performant operators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Reward shares are distributed based on the fraction of the active funded non-stopped validators owned by an operator. This distribution of shares does not promote the honest operation of validators to the fullest extent. Since the oracle members don't report the delta in the balance of each validator, it is not possible to reward operators/validators that have been performing better than the rest. Also if a high-performing operator or operators were the main source of the beacon balance sum and if they had enough ETH to initially deposit into the ETH2.0 deposit contract on their own, they could have made more profit that way versus joining as an operator in the River protocol.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "TRANSFER_MASK == 0 which causes a no-op.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "TRANSFER_MASK is a named constant defined as 0 (River.1.sol#L37). Like the other masks DEPOSIT_- MASK and DENY_MASK which supposed to represent a bitmask, on the first look, you would think TRANSFER_MASK would need to also represent a bitmask. But if you take a look at _onTransfer: function _onTransfer(address _from, address _to) internal view override { IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_from, TRANSFER_MASK); // this call reverts if unauthorized or denied IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_to, TRANSFER_MASK); // this call reverts if unauthorized or denied ,! ,! } This would translate into calling onlyAllowed with the: IAllowlistV1(AllowlistAddress.get()).onlyAllowed(x, 0); Now if we look at the onlyAllowed function with these parameters: function onlyAllowed(x, 0) external view { uint256 userPermissions = Allowlist.get(x); if (userPermissions & DENY_MASK == DENY_MASK) { revert Denied(_account); } if (userPermissions & 0 != 0) { // <--- ( x & 0 != 0 ) == false revert Unauthorized(_account); } } Thus if the _from, _to addresses don't have their DENY_MASK set to 1 they would not trigger a revert since we would never step into the 2nd if block above when TRANSFER_MASK is passed to these functions. The TRANSFER_MASK is also used in _onDeposit: IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_depositor, DEPOSIT_MASK + TRANSFER_MASK); // DEPOSIT_MASK + TRANSFER_MASK == DEPOSIT_MASK ,! IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_recipient, TRANSFER_MASK); // like above in ,! `_onTransfer`", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Reformat numeric literals with many digits for better readability.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Reformat numeric literals with many digits into a more readable form.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Firewall should follow the two-step approach present in River when transferring govern address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Both River and OperatorsRegistry follow a two-step approach to transfer the ownership of the contract. 1) Propose a new owner storing the address in a pendingAdmin variable 2) The pending admins accept the new role by actively calling acceptOwnership This approach makes this crucial action much safer because 1) Prevent the admin to transfer ownership to address(0) given that address(0) cannot call acceptOwnership 2) Prevent the admin to transfer ownership to an address that cannot \"admin\" the contract if they cannot call acceptOwnership. For example, a contract do not have the implementation to at least call acceptOwnership. 3) Allow the current admin to stop the process by calling transferOwnership(address(0)) if the pending admin has not called acceptOwnership yet The current implementation does not follow this safe approach, allowing the governor to directly transfer the gov- ernor role to a new address.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "OperatorRegistry.removeValidators is resetting the limit (approved validators) even when not needed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of removeValidators allow an admin or node operator to remove val- idators, passing to the function the list of validator's index to be removed. Note that the list of indexes must be ordered DESC. At the end of the function, we can see these checks if (_indexes[_indexes.length - 1] < operator.limit) { operator.limit = _indexes[_indexes.length - 1]; } That reset the operator's limit to the lower index value (this to prevent that a not approved key get swapped to a position inside the limit). The issue with this implementation is that it is not considering the case where all the operator's validators are already approved by Alluvial. In this case, if an operator removes the validator with the lower index, all the other validators get de-approved because the limit will be set to the lower limit. Consider this scenario: 59 op.limit = 10 op.keys = 10 op.funded = 0 This mean that all the validators added by the operator have been approved by Alluvial and are safe (keys == limit). If the operator or Alluvial call removeValidators([validatorIndex], [0]) removing the validator at index 0 this will  swap the validator_10 with validator_0.  set the limit to 0 because 0 < 10 (_indexes[_indexes.length - 1] < operator.limit). The consequence is that even if all the validators present before calling removeValidators were \"safe\" (because approved by Alluvial) the limit is now 0 meaning that all the validators are not \"safe\" anymore and cannot be selected by pickNextValidators.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider renaming transferOwnership to better reflect the function's logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of transferOwnership is not really transferring the ownership from the current admin to the new one. The function is setting the value of the Pending Admin that must subsequently call acceptOwnership to accept the role and confirm the transfer of the ownership.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Wrong return name used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The min function returns the minimum of the 2 inputs, but the return name used is max.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Discrepancy between architecture and code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The architecture diagram states that admin triggers deposits on the Consensus Layer Deposit Man- ager, but the depositToConsensusLayer() function allows anyone to trigger such deposits.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider replacing the remaining require with custom errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In the vast majority of the project contracts have defined and already use Custom Errors that provide a better UX, DX and gas saving compared to require statements. There are still some instances of require usage in ConsensusLayerDepositManager and BytesLib contracts that could be replaced with custom errors.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Both wlsETH and lsETH transferFrom implementation allow the owner of the token to use trans- ferFrom like if it was a \"normal\" transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of transferFrom allow the msg.sender to use the function like if it was a \"normal\" transfer. In this case, the allowance is checked only if the msg.sender is not equal to _from if (_from != msg.sender) { uint256 currentAllowance = ApprovalsPerOwner.get(_from, msg.sender); if (currentAllowance < _value) { revert AllowanceTooLow(_from, msg.sender, currentAllowance, _value); } ApprovalsPerOwner.set(_from, msg.sender, currentAllowance - _value); } This implementation diverge from what is usually implemented in both Solmate and OpenZeppelin.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Both wlsETH and lsETH tokens are reducing the allowance when the allowed amount is type(uint256).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of the function transferFrom in both SharesManager.1.sol and WLSETH.1.sol is not taking into consideration the scenario where a user has approved a spender the maximum possible allowance type(uint256).max. The Alluvial transferFrom acts differently from standard ERC20 implementations like the one from Solmate and OpenZeppelin. In their implementation, they check and reduce the spender allowance if and only if the allowance is different from type(uint256).max.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Missing, confusing or wrong natspec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In the current implementation not all the constructors, functions, events, custom errors, variables or struct are covered by natspec comments. Some of them are only partially covered (missing @param, @return and so on). Note that the contracts listed in the context section of the issue have inside of them complete or partial missing natspec.  Natspec Fixes / Typos: River.1.sol#L38-L39 Swap the empty line with the NatSpec @notice - /// @notice Prevents unauthorized calls - + + /// @notice Prevents unauthorized calls OperatorsRegistry.1.sol#L44, OperatorsRegistry.1.sol#L61, OperatorsRegistry.1.sol#L114 Replace name with index. - /// @param _index The name identifying the operator + /// @param _index The index identifying the operator OperatorsRegistry.1.sol#L218 Replace cound with count. - /// @notice Changes the operator stopped validator cound + /// @notice Changes the operator stopped validator count  Expand the natspec explanation: We also suggest expanding some function's logic inside the natspec OperatorsRegistry.1.sol#L355-L358 Expand the natspec documentation and add a @return natspec comment clarifying that the returned value is the number of total operator and not the active/fundable one. ReportsVariants.sol#L5 Add a comment that explains the COUNT_OUTMASK's assignment. This will mask beaconValidators and beacon- Balance in the designed packing. xx...xx <beaconBalance> <beaconValidators> xxxx & COUNT_OUTMASK == 00...00 <beaconBalance> <beaconValidators> 0000 ReportsVariants.sol ReportsVariants should have a documentation regarding the packing used for ReportsVariants in an uint256: [ 0, 16) : <voteCount> oracle member's total vote count for the numbers below (uint16, 2 bytes) ,! [16, [48, 112) : <beaconBalance> 48) : <beaconValidators> total number of beacon validators (uint32, 4 bytes) total balance of all the beacon validators (uint64, 6 bytes) OracleMembers.sol Leave a comment/warning that only there could a maximum of 256 oracle members. This is due to the Report- sPosition setup where in an uint256, 1 bit is reserved for each oracle member's index. ReportsPositions.sol 63 Leave a comment/warning for the ReportsPosition setup that the ith bit in the uint256 represents whether or not there has been a beacon report by the ith oracle member. Oracle.1.sol#L202-L205 Leave a comment/warning that only there could a maximum of 256 oracle members. This is due to the Report- sPosition setup where in an uint256, 1 bit is reserved for each oracle member's index. Allowlist.1.sol#L46-L49 Leave a comment, warning that the permission bitmaps will be overwritten instead of them getting updated. OracleManager.1.sol#L44 Add more comment for _roundId to mention that when the setBeaconData is called by Oracle.1.sol:_push- ToRiver and that the value passed to it for this parameter is always the 1st epoch of a frame. OperatorsRegistry.1.sol#L304-L310 _indexes parameter, mentioning that this array: 1) needs to be duplicate-free and sorted (DESC) 2) each element in the array needs to be in a specific range, namely operator.[funded, keys). OperatorsRegistry.1.sol#L60-L62 Better rephrase the natspec comment to avoid further confusion. Oracle.1.sol#L284-L289 Update the reportBeacon natspec documentation about the _beaconValidators parameter to avoid further con- fusion. Client answer to the PR comment The docs should be updated to also reflect our plans for the Shanghai fork. Basically we can't just have the same behavior for a negative delta in validator count than with a positive delta (where we just assume that each validator that was in the queue only had 32 eth). Now when we exit validator we need to know how much was exited in order to compute the proper revenue value for the treasury and operator fee. This probably means that there will be an extra arg with the oracle to keep track of the exited eth value. But as long as the spec is not final, we'll stick to the validator count always growing. We should definitely add a custom error to explain that in case a report provides a smaller validator count.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Remove unused imports from code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The codebase has unused imports across the code base. If they are not used inside the contract, it would be better to remove them to avoid confusion.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Missing event emission in critical functions, init functions and setters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Some critical functions like contract's constructor, contract's init*(...)function (upgradable con- tracts) and some setter or in general critical functions are missing event emission. Event emissions are very useful for external web3 applications, but also for monitoring the usage and security of your protocol when paired with external monitoring tools. Note: in the init*(...)/constructor function, consider if adding a general broad event like ContractInitial- ized or split it in more specific events like QuorumUpdated+OwnerChanged+... 65 Note: in general, consider adding an event emission to all the init*(...) functions used to initialize the upgrad- able contracts, passing to the event the relevant args in addition to the version of the upgrade.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Freeze Redeems if bonds too Large", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "Issuing too many bonds can result in users being unable to redeem. This is caused by arithmetic overow in previewRedeemAtMaturity. If a users bonds andpaidAmounts (or bonds * nonPaidAmount) product is greater than 2**256, it will overow, reverting all attempts to redeem bonds.", "labels": ["Spearbit", "Porter", "Severity: Medium Risk"]}, {"title": "Reentrancy in withdrawExcessCollateral() and withdrawExcessPayment() functions.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "withdrawExcessCollateral() and withdrawExcessPayment() enable the caller to withdraw excess collateral and payment tokens respectively. Both functions are guarded by an onlyOwner modier, limiting their access to the owner of the contract. function withdrawExcessCollateral(uint256 amount, address receiver) external onlyOwner function withdrawExcessPayment(address receiver) external onlyOwner When transferring tokens, execution ow is handed over to the token contract. Therefore, if a malicious token manages to call the owners address it can also call these functions again to withdraw more tokens than required. As an example consider the following case where the collateral tokens transferFrom() function calls the owners address: 4 function transferFrom( address from, address to, uint256 amount ) public virtual override returns (bool) { if (reenter) { reenter = false; owner.attack(bond, amount); } address spender = _msgSender(); _spendAllowance(from, spender, amount); _transfer(from, to, amount); return true; } and the owner contract has a function: function attack(address _bond, uint256 _amount) external { IBond(_bond).withdrawExcessCollateral(_amount, address(this)); } When withdrawExcessCollateral() is called by owner, it allows it to withdraw double the amount via reentrancy.", "labels": ["Spearbit", "Porter", "Severity: Medium Risk"]}, {"title": "burn() and burnFrom() allow users to lose their bonds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "The Bond contract inherits from ERC20BurnableUpgradeable. contract Bond is IBond, OwnableUpgradeable, ERC20BurnableUpgradeable, This exposes the burn() and burnFrom() functions to users who could get their bonds burned due to an error or a front-end attack.", "labels": ["Spearbit", "Porter", "Severity: Low Risk"]}, {"title": "Missing two-step transfer ownership pattern", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "After a bond is created its ownership is transferred to the wallet which invoked the createBond function, but it can be later transferred to anyone at any time or the renounceOwnership function can be called. The Bond contract uses the Ownable Openzeppelin contract, which is a simple mechanism to transfer ownership without supporting a two-step ownership transfer pattern. OpenZeppelin describes Ownable as: Ownable is a simpler mechanism with a single owner \"role\" that can be assigned to a single account. This simpler mechanism can be useful for quick tests but projects with production concerns are likely to outgrow it. Ownership transfer is a critical operation and transferring it to an inaccessible wallet or renouncing ownership by mistake can effectively lock the collateral in the contract forever.", "labels": ["Spearbit", "Porter", "Severity: Low Risk"]}, {"title": "Inefcient initialization of minimal proxy implementation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "The Bond contract uses a minimal proxy pattern when deployed by BondFactory. The proxy pattern requires a special initialize method to be called to set the state of each cloned contract. Nevertheless, the implementation contract can be left uninitialized, giving an attacker the opportunity to invoke the initialization. constructor() { tokenImplementation = address(new Bond()); _grantRole(DEFAULT_ADMIN_ROLE, _msgSender()); } After the reporting the issue it was discovered that a separate (not merged) development branch implements a deployment script which initializes the Bond implementation contract after the main deployment of BondFactory, leaving a narrow window for the attacker to leverage this issue and reducing impact signicantly. deploy_bond_factory.ts#L24 6 const implementationContract = (await ethers.getContractAt( \"Bond\", await factory.tokenImplementation() )) as Bond; try { await waitUntilMined( await implementationContract.initialize( \"Placeholder Bond\", \"BOND\", deployer, THREE_YEARS_FROM_NOW_IN_SECONDS, \"0x0000000000000000000000000000000000000000\", \"0x0000000000000000000000000000000000000001\", ethers.BigNumber.from(0), ethers.BigNumber.from(0), 0 ) ); } catch (e) { console.log(\"Is the contract already initialized?\"); console.log(e); } Due to the fact that the initially reviewed code did not have the proper initialization for the Bond implementation (as it was an unmerged branch) and because in case of a successful exploitation the impact on the system remains minimal, this nding is marked as low risk. It is not necessary to create a separate transaction and initialize the storage of the implementation contract to prevent unauthorized initialization.", "labels": ["Spearbit", "Porter", "Severity: Low Risk"]}, {"title": "Verify amount is greater than 0 to avoid unnecessarily safeTransfer() calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "Balance should be checked to avoid unnecessary safeTransfer() calls with an amount of 0.", "labels": ["Spearbit", "Porter", "Severity: Gas Optimization"]}, {"title": "Improve checks for token allow-list", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "The BondFactory contract has two enabled allow-lists by default, which require the teams approval for issuers and tokens to create bonds. However, the screening process was not properly dened before the assessment. In case a malicious token and issuer slip through the screening process the protocol can be used by malicious actors to perform mass scam attacks. In such scenario, tokens and issuers would be able to create bonds, sell those anywhere and later on exploit those tokens, leading to loss of user funds. /// @inheritdoc IBondFactory function createBond( string memory name, string memory symbol, uint256 maturity, address paymentToken, address collateralToken, uint256 collateralTokenAmount, uint256 convertibleTokenAmount, uint256 bonds ) external onlyIssuer returns (address clone)", "labels": ["Spearbit", "Porter", "Severity: Informational"]}, {"title": "Incorrect revert message", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "error BondBeforeGracePeriodOrPaid() is used to revert when !isAfterGracePeriod() && amountPaid() > 0, which means the bonds is before the grace period and not paid for. Therefore, the error description is incorrect. if (isAfterGracePeriod() || amountUnpaid() == 0) { _; } else { revert BondBeforeGracePeriodOrPaid(); }", "labels": ["Spearbit", "Porter", "Severity: Informational"]}, {"title": "Non-existent bonds naming/symbol restrictions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "The issuer can dene any name and symbol during bond creation. Naming is neither enforced nor constructed by the contract and may result in abusive or misleading names which could have a negative impact on the PR of the project. /// @inheritdoc IBondFactory function createBond( string memory name, string memory symbol, uint256 maturity, address paymentToken, address collateralToken, uint256 collateralTokenAmount, uint256 convertibleTokenAmount, uint256 bonds ) external onlyIssuer returns (address clone) A malicious user could hypothetically use arbitrary names to:  Mislead users into thinking they are buying bonds consisting of different tokens.  Use abusive names to discredit the team.  Attempt to exploit the frontend application by injecting arbitrary HTML data. The team had a discussion regarding naming conventions in the past. However, not all the abovementioned scenarios were brought up during that conversation. Therefore, this nding is reported as informational to revisit and estimate its potential impact, or add it as a test case during the web application implementation.", "labels": ["Spearbit", "Porter", "Severity: Informational"]}, {"title": "Needles variable initialization for default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "uint256 variable are initialized to a default value of zero per Solidity docs. Setting a variable to the default value is unnecessary.", "labels": ["Spearbit", "Porter", "Severity: Informational"]}, {"title": "Deationary payment tokens are not handled in the pay() function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf", "body": "The pay() function does not support rebasing/deflationary/inflationary payment tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.", "labels": ["Spearbit", "Porter", "Severity: Informational"]}, {"title": "Lack of transferId Verification Allows an Attacker to Front-Run Bridge Transfers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The onReceive() function does not verify the integrity of transferId against all other parameters. Although the onlyBridgeRouter modifier checks that the call originates from another BridgeRouter (assuming a correct configuration of the whitelist) to the onReceive() function, it does not check that the call originates from another Connext Diamond. Therefore, allowing anyone to send arbitrary data to BridgeRouter.sendToHook(), which is later interpreted as the transferId on Connexts NomadFacet.sol contract. This can be abused by a front-running attack as described in the following scenario:  Alice is a bridge user and makes an honest call to transfer funds over to the destination chain.  Bob does not make a transfer but instead calls the sendToHook() function with the same _extraData but passes an _amount of 1 wei.  Both Alice and Bob have their tokens debited on the source chain and must wait for the Nomad protocol to optimistically verify incoming TransferToHook messages.  Once the messages have been replicated onto the destination chain, Bob processes the message before Alice, causing onReceive() to be called on the same transferId.  However, because _amount is not verified against the transferId, Alice receives significantly less tokens and the s.reconciledTransfers mapping marks the transfer as reconciled. Hence, Alice has effectively lost all her tokens during an attempt to bridge them. function onReceive( uint32, // _origin, not used uint32, // _tokenDomain, not used bytes32, // _tokenAddress, of canonical token, not used address _localToken, uint256 _amount, bytes memory _extraData ) external onlyBridgeRouter { bytes32 transferId = bytes32(_extraData); // Ensure the transaction has not already been handled (i.e. previously reconciled). if (s.reconciledTransfers[transferId]) { revert NomadFacet__reconcile_alreadyReconciled(); } // Mark the transfer as reconciled. s.reconciledTransfers[transferId] = true; Note: the same issues exists with _localToken. As a result a malicious user could perform the same attack by using a malicious token contract and transferring the same amount of tokens in the call to sendToHook().", "labels": ["Spearbit", "Connext", "Severity: Critical Risk"]}, {"title": "swapOut allows overwrite of token balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The StableSwapFacet has the function swapExactOut() where a user could supply the same as- setIn address as assetOut, which means the TokenIndexes for tokenIndexFrom and tokenIndexTo function swapOut() are the same. In function swapOut() a temporay array is used to store balances. When updating such balances, first self.balances[tokenIndexFrom] is updated and then self.balances[tokenIndexTo] is updated afterwards. However when tokenIndexFrom == tokenIndexTo the second update overwrites the first update, causing token balances to be arbitrarily lowered. This also skews the exchange rates, allowing for swaps where value can be extracted. Note: the protection against this problem is location in function getY(). However, this function is not called from swapOut(). Note: the same issue exists in swapInternalOut(), which is called from swapFromLocalAssetIfNeededForEx- actOut() via _swapAssetOut(). However, via this route it is not possible to specify arbitrary token indexes. There- fore, there isnt an immediate risk here. 7 contract StableSwapFacet is BaseConnextFacet { ... function swapExactOut(... ,address assetIn, address assetOut, ... ) ... { return s.swapStorages[canonicalId].swapOut( getSwapTokenIndex(canonicalId, assetIn), getSwapTokenIndex(canonicalId, assetOut), amountOut, maxAmountIn // assetIn could be same as assetOut ); } ... } library SwapUtils { function swapOut(..., uint8 tokenIndexFrom, uint8 tokenIndexTo, ... ) ... { ... uint256[] memory balances = self.balances; ... self.balances[tokenIndexFrom] = balances[tokenIndexFrom].add(dx).sub(dxAdminFee); self.balances[tokenIndexTo] = balances[tokenIndexTo].sub(dy); // overwrites previous update if ,! From==To ... } function getY(..., uint8 tokenIndexFrom, uint8 tokenIndexTo, ... ) ... { ... require(tokenIndexFrom != tokenIndexTo, \"compare token to itself\"); // here is the protection ... } } Below is a proof of concept which shows that the balances of index 3 can be arbitrarily reduced. //SPDX-License-Identifier: MIT pragma solidity 0.8.14; import \"hardhat/console.sol\"; contract test { uint[] balances = new uint[](10); function swap(uint8 tokenIndexFrom,uint8 tokenIndexTo,uint dx) public { uint dy=dx; // simplified uint256[] memory mbalances = balances; balances[tokenIndexFrom] = mbalances[tokenIndexFrom] + dx; balances[tokenIndexTo] = mbalances[tokenIndexTo] - dy; } constructor() { balances[3] = 100; swap(3,3,10); console.log(balances[3]); // 90 } }", "labels": ["Spearbit", "Connext", "Severity: Critical Risk"]}, {"title": "Use of spot price in SponsorVault leads to sandwich attack.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "There is a special role sponsor in the protocol. Sponsors can cover the liquidity fee and transfer fee for users, making it more favorable for users to migrate to the new chain. Sponsors can either provide liquidity for each adopted token or provide the native token in the SponsorVault. If the native token is provided, the SponsorVault will swap to the adopted token before transferring it to users. contract SponsorVault is ISponsorVault, ReentrancyGuard, Ownable { ... function reimburseLiquidityFees( address _token, uint256 _liquidityFee, address _receiver ) external override onlyConnext returns (uint256) { ... uint256 amountIn = tokenExchange.getInGivenExpectedOut(_token, _liquidityFee); amountIn = currentBalance >= amountIn ? amountIn : currentBalance; // sponsored fee may end being less than _liquidityFee due to slippage sponsoredFee = tokenExchange.swapExactIn{value: amountIn}(_token, msg.sender); ... } } The spot AMM price is used when doing the swap. Attackers can manipulate the value of getInGivenExpectedOut and make SponsorVault sell the native token at a bad price. By executing a sandwich attack the exploiters can drain all native tokens in the sponsor vault. For the sake of the following example, assume that _token is USDC and native token is ETH, the sponsor tries to sponsor 100 usdc to the users:  Attacker first manipulates the DEX and makes the exchange of 1 ETH = 0.1 USDC.  getInGivenExpectedOut returns 100 / 0.1 = 1000.  tokenExchange.swapExactIn buys 100 USDC with 1000 ETH, causing the ETH price to decrease even lower.  Attacker buys ETH at a lower prices and realizes a profit.", "labels": ["Spearbit", "Connext", "Severity: Critical Risk"]}, {"title": "Configuration is crucial (both Nomad and Connext)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The Connext and Nomad protocol rely heavily on configuration parameters. These parameters are configured during deployment time and are updated afterwards. Configuration errors can have major conse- quences. Examples of important configurations are:  BridgeFacet.sol: s.promiseRouter.  BridgeFacet.sol: s.connextions.  BridgeFacet.sol: s.approvedSequencers.  Router.sol: remotes[].  xAppConnectionManager.sol: home .  xAppConnectionManager.sol: replicaToDomain[].  xAppConnectionManager.sol: domainToReplica[].", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Deriving price with balanceOf is dangerous", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "getPriceFromDex derives the price by querying the balance of AMMs pools. function getPriceFromDex(address _tokenAddress) public view returns (uint256) { PriceInfo storage priceInfo = priceRecords[_tokenAddress]; ... uint256 rawTokenAmount = IERC20Extended(priceInfo.token).balanceOf(priceInfo.lpToken); ... uint256 rawBaseTokenAmount = IERC20Extended(priceInfo.baseToken).balanceOf(priceInfo.lpToken); ... } Deriving the price with balanceOf is dangerous as balanceOf may be gamed. Consider univ2 as an example; Exploiters can first send tokens into the pool and pump the price, then absorb the tokens that were previously donated by calling mint.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Routers can sybil attack the sponsor vault to drain funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When funds are bridged from source to destination chain messages must first go through optimistic verification before being executed on the destination BridgeFacet.sol contract. Upon transfer processing the contract checks if the domain is sponsored. If such is the case then the user is reimbursed for both liquidity fees paid when the transfer was initiated and for the fees paid to the relayer during message propagation. There currently isnt any mechanism to detect sybil attacks. Therefore, a router can perform several large value transfers in an effort to drain the sponsor vault of its funds. Because liquidity fees are paid to the router by a user connected to the router, there isnt any value lost in this type of attack.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Routers are exposed to extreme slippage if they attempt to repay debt before being reconciled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When routers are reconciled, the local asset may need to be exchanged for the adopted asset in order to repay the unbacked Aave loan. AssetLogic.swapFromLocalAssetIfNeededForExactOut() takes two key arguments:  _amount representing exactly how much of the adopted asset should be received.  _maxIn which is used to limit slippage and limit how much of the local asset is used in the swap. Upon failure to swap, the protocol will reset the values for unbacked Aave debt and distribute local tokens to the router. However, if this router partially paid off some of the unbacked Aave debt before being reconciled, _maxIn will diverge from _amount, allowing value to be extracted in the form of slippage. As a result, routers may receive less than the amount of liquidity they initially provided, leading to router insolvency.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Malicious call data can DOS execute", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "An attacker can DOS the executor contract by giving infinite allowance to normal users. Since the executor increases allowance before triggering an external call, the tx will always revert if the allowance is already infinite. 11 function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes ,! memory) { ... if (!isNative && hasValue) { SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); // reverts if set to `infinite` before } ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(...) // can set to `infinite` allowance ... ,! ,! }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "DOS attack on the Nomad Home.sol Contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Upon calling xcall(), a message is dispatched via Nomad. A hash of this message is inserted into the merkle tree and the new root will be added at the end of the queue. Whenever the updater of Home.sol commits to a new root, improperUpdate() will check that the new update is not fraudulent. In doing so, it must iterate through the queue of merkle roots to find the correct committed root. Because anyone can dispatch a message and insert a new root into the queue it is possible to impact the availability of the protocol by preventing honest messages from being included in the updated root. function improperUpdate(..., bytes32 _newRoot, ... ) public notFailed returns (bool) { ... // if the _newRoot is not currently contained in the queue, // slash the Updater and set the contract to FAILED state if (!queue.contains(_newRoot)) { _fail(); ... } ... } function contains(Queue storage _q, bytes32 _item) internal view returns (bool) { for (uint256 i = _q.first; i <= _q.last; i++) { if (_q.queue[i] == _item) { return true; } } return false; }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Upon failing to back unbacked debt _reconcileProcessPortal() will leave the converted asset in the contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When routers front liquidity for the protocols users they are later reconciled once the bridge has optimistically verified transfers from the source chain. Upon being reconciled, the _reconcileProcessPortal() attempts to first pay back Aave debt before distributing the rest back to the router. However, _reconcileProcess- Portal() will not convert the adopted asset back to the local asset in the case where the call to the Aave pool fails. Instead, the function will set amountIn = 0 and continue to distribute the local asset to the router. if (success) { emit AavePortalRepayment(_transferId, adopted, backUnbackedAmount, portalFee); } else { // Reset values s.portalDebt[_transferId] += backUnbackedAmount; s.portalFeeDebt[_transferId] += portalFee; // Decrease the allowance SafeERC20.safeDecreaseAllowance(IERC20(adopted), s.aavePool, totalRepayAmount); // Update the amount repaid to 0, so the amount is credited to the router amountIn = 0; emit AavePortalRepaymentDebt(_transferId, adopted, s.portalDebt[_transferId], s.portalFeeDebt[_transferId]); ,! }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "_handleExecuteTransaction() doesnt handle native assets correctly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function _handleExecuteTransaction() sends any native tokens to the executor contract first, and then calls s.executor.execute(). This means that within that function msg.value will always be 0. So the associated logic that uses msg.value doesnt work as expected and the function doesnt handle native assets correctly. Note: also see issue \"Executor reverts on receiving native tokens from BridgeFacet\" contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(...)... { ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); (bool success, bytes memory returnData) = s.executor.execute(...); // no native tokens send } } contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... if (isNative && msg.value != _args.amount) { // msg.value is always 0 ... } } }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Add checks to xcall()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function xcall() does some sanity checks, nevertheless more checks should be added to prevent issues later on in the use of the protocol. If _args.recovery== 0 then _sendToRecovery() will send funds to the 0 address, effectively losing them. If _params.agent == 0 the forceReceiveLocal cant be used and funds might be locked forever. The _args.params.destinationDomain should never be s.domain, although this is also implicitly checked via _mustHaveRemote() assuming a correct configuration. If _args.params.slippageTol is set to something greater than s.LIQUIDITY_FEE_DENOMINATOR then funds can be locked as xcall() allows for the user to provide the local asset, avoiding any swap while _handleExecuteLiquid- ity() in execute() may attempt to perform a swap on the destination chain. function xcall(XCallArgs calldata _args) external payable nonReentrant whenNotPaused returns (bytes32) { // Sanity checks. ... } 14", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Executor and AssetLogic deals with the native tokens inconsistently that breaks execute()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When dealing with an external callee the BridgeFacet will transfer liquidity to the Executor before calling Executor.execute. In order to send the native token:  The Executor checks for _args.assetId == address(0).  AssetLogic.transferAssetFromContract() disallows address(0). Note: also see issue Executor reverts on receiving native tokens from BridgeFacet. 15 contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction() ...{ ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); // _asset may not ,! be 0 (bool success, bytes memory returnData) = s.executor.execute( IExecutor.ExecutorArgs( // assetId parameter from ExecutorArgs // must be 0 for Native asset ... _asset, ... ) ); ... } } library AssetLogic { function transferAssetFromContract( address _assetId, ... ) { ... // No native assets should ever be stored on this contract if (_assetId == address(0)) revert AssetLogic__transferAssetFromContract_notNative(); if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } } } contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... bool isNative = _args.assetId == address(0); ... } } The BridgeFacet cannot handle external callees when using native tokens.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Executor reverts on receiving native tokens from BridgeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When doing an external call in execute(), the BridgeFacet provides liquidity into the Executor contract before calling Executor.execute. The BridgeFacet transfers native token when address(wrapper) is provided. The Executor however does not have a fallback/ receive function. Hence, the transaction will revert when the BridgeFacet tries to send the native token to the Executor contract. function _handleExecuteTransaction( ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); (bool success, bytes memory returnData) = s.executor.execute(...); ... } function transferAssetFromContract(...) ... { ... if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } else { ... } }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "SponsorVault sponsors full transfer amount in reimburseLiquidityFees()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The BridgeFacet passes args.amount as _liquidityFee when calling reimburseLiquidityFees. Instead of sponsoring liquidityFee, the sponsor vault would sponsor full transfer amount to the reciever. Note: Luckily the amount in reimburseLiquidityFees is capped by relayerFeeCap. function _handleExecuteTransaction(...) ... { ... (bool success, bytes memory data) = address(s.sponsorVault).call( abi.encodeWithSelector(s.sponsorVault.reimburseLiquidityFees.selector, _asset, _args.amount, _args.params.to) ); ,! } 17", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Tokens can get stuck in Executor contract if the destination doesnt claim them all", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function execute() increases allowance and then calls the recipient (_args.to). When the recipient does not use all tokens, these could remain stuck inside the Executor contract. Note: the executor can have excess tokens, see: kovan executor. Note: see issue \"Malicious call data can DOS execute or steal unclaimed tokens in the Executor contract\". function execute(...) ... { ... if (!isNative && hasValue) { SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); } ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, ... ); ... }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "reimburseLiquidityFees send tokens twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function reimburseLiquidityFees() is called from the BridgeFacet, making the msg.sender within this function to be BridgeFacet. When using tokenExchanges via swapExactIn() tokens are sent to msg.sender, which is the BridgeFacet. Then, tokens are sent again to msg.sender via safeTransfer(), which is also the BridgeFacet. Therefore, tokens end up being sent to the BridgeFacet twice. Note: the check ...balanceOf(...) != starting + sponsored should fail too. Note: The fix in C4 seems to introduce this issue: code4rena-246 18 contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(... ) ... { ... uint256 starting = IERC20(_asset).balanceOf(address(this)); ... (bool success, bytes memory data) = address(s.sponsorVault).call( abi.encodeWithSelector(s.sponsorVault.reimburseLiquidityFees.selector, _asset, _args.amount, ,! _args.params.to) ); if (success) { uint256 sponsored = abi.decode(data, (uint256)); // Validate correct amounts are transferred if (IERC20(_asset).balanceOf(address(this)) != starting + sponsored) { // this should revert BridgeFacet__handleExecuteTransaction_invalidSponsoredAmount(); ,! fail now } ... } ... } } contract SponsorVault is ISponsorVault, ReentrancyGuard, Ownable { function reimburseLiquidityFees(... ) { if (address(tokenExchanges[_token]) != address(0)) { ... sponsoredFee = tokenExchange.swapExactIn{value: amountIn}(_token, msg.sender); // send to ,! msg.sender } else { ... } ... IERC20(_token).safeTransfer(msg.sender, sponsoredFee); // send again to msg.sender } } interface ITokenExchange { /** * @notice Swaps the exact amount of native token being sent for a given token. * @param token The token to receive * @param recipient The recipient of the token * @return The amount of tokens resulting from the swap */ function swapExactIn(address token, address recipient) external payable returns (uint256); }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Anyone can repay the portalDebt with different tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Routers can provide liquidity in the protocol to improve the UX of cross-chain transfers. Liquidity is sent to users under the routers consent before the cross-chain message is settled on the optimistic message protocol, i.e., Nomad. The router can also borrow liquidity from AAVE if the router does not have enough of it. It is the routers responsibility to repay the debt to AAVE. contract PortalFacet is BaseConnextFacet { function repayAavePortalFor( address _adopted, uint256 _backingAmount, uint256 _feeAmount, bytes32 _transferId ) external payable { address adopted = _adopted == address(0) ? address(s.wrapper) : _adopted; ... // Transfer funds to the contract uint256 total = _backingAmount + _feeAmount; if (total == 0) revert PortalFacet__repayAavePortalFor_zeroAmount(); (, uint256 amount) = AssetLogic.handleIncomingAsset(_adopted, total, 0); ... // repay the loan _backLoan(adopted, _backingAmount, _feeAmount, _transferId); } } The PortalFacet does not check whether _adopted is the correct token in debt. Assume that the protocol borrows ETH for the current _transferId, therefore Router should repay ETH to clear the debt. However, the Router can provide any valid tokens, e.g. DAI, USDC, to clear the debt. This results in the insolvency of the protocol. Note: a similar issue is also present in repayAavePortal().", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Malicious call data can steal unclaimed tokens in the Executor contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Users can provide a destination contract args.to and arbitrary data _args.callData when doing a cross-chain transfer. The protocol will provide the allowance to the callee contract and triggers the function call through ExcessivelySafeCall.excessivelySafeCall. 20 contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); ... // Try to execute the callData // the low level call will return `false` if its execution reverts (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, gas, isNative ? _args.amount : 0, MAX_COPY, _args.callData ); ... } } Since there arent restrictions on the destination contract and calldata, exploiters can steal the tokens from the executor. Note: the executor does have excess tokens, see: see: kovan executor. Note: see issue Tokens can get stuck in Executor contract. Tokens can be stolen by granting an allowance. Setting calldata = abi.encodeWithSelector(ERC20.approve.selector, exploiter, type(uint256).max); and args.to = tokenAddress allows the exploiter to get an infinite allowance of any token, effectively stealing any unclaimed tokens left in the executor.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Fee-On-Transfer tokens are not explicitly denied in swap()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The swap() function is used extensively within the Connext protocol, primarily when swapping be- tween local and adopted assets. When a swap is performed, the function will check the actual amount transferred. However, this is not consistent with other swap functions which check that the amount transferred is equal to dx. As a result, overwriting dx with tokenFrom.balanceOf(address(this)).sub(beforeBalance) allows for fee-on- transfer tokens to work as intended.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "xcall() may erroneously overwrite prior calls to bumpTransfer()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The bumpTransfer() function allows users to increment the relayer fee on any given transferId without checking if the unique transfer identifier exists. As a result, a subsequent call to xcall() will overwrite the s.relayerFees mapping, leading to lost funds.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "_handleExecuteLiquidity doesnt consistently check for receiveLocalOverrides", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function _handleExecuteLiquidity() initially checks for receiveLocal but does not check for receiveLocalOverrides. Later on it does check for both of values. function _handleExecuteLiquidity(... ) ... { ... if ( !_args.params.receiveLocal && // doesn't check for receiveLocalOverrides s.routerBalances[_args.routers[0]][_args.local] < toSwap && s.aavePool != address(0) ) { ... if (_args.params.receiveLocal || s.receiveLocalOverrides[_transferId]) { // extra check return (toSwap, _args.local); } } 22 As a result, the portal may pay the bridge user in the adopted asset when they opted to override this behaviour to avoid slippage conditions outside of their boundaries, potentially leading to an unwarranted reception of funds denominated in the adopted asset.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Router signatures can be replayed when executing messages on the destination domain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Connext bridge supports near-instant transfers by allowing users to pay a small fee to routers for providing them with liquidity. Gelato relayers are tasked with taking in bids from liquidity providers who sign a message consisting of the transferId and path length. The path length variable only guarantees that the message they signed will only be valid if _args.routers.length - 1 routers are also selected. However, it does not prevent Gelato relayers from re-using the same signature multiple times. As a result, routers may unintentionally provide more liquidity than expected.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "diamondCut() allows re-execution of old updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function diamondCut() of LibDiamond verifies the signed version of the update parameters. It checks the signed version is available and a sufficient amount of time has passed. However it doesnt prevent multiple executions and the signed version stays valid forever. This allows old updates to be executed again. Assume the following:  facet_x (or function_y) has value: version_1.  then: replace facet_x (or function_y) with version_2.  then a bug is found in version_2 and it is rolled back with: replace facet_x (or function_y) with ver- sion_1. 23  then a (malicious) owner could immediately do: replace facet_x (or function_y) with version_2 (be- cause it is still valid). Note: the risk is limited because it can only executed by the contract owner, however this is probably not how the mechanism should work. library LibDiamond { function diamondCut(...) ... { ... uint256 time = ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))]; require(time != 0 && time < block.timestamp, \"LibDiamond: delay not elapsed\"); ... } }", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Not always safeApprove(..., 0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Some functions like _reconcileProcessPortal of BaseConnextFacet and _swapAssetOut of As- setLogic do safeApprove(..., 0) first. contract NomadFacet is BaseConnextFacet { function _reconcileProcessPortal( ... ) ... { ... // Edge case with some tokens: Example USDT in ETH Mainnet, after the backUnbacked call there ,! could be a remaining allowance if not the whole amount is pulled by aave. // Later, if we try to increase the allowance it will fail. USDT demands if allowance is not 0, ,! it has to be set to 0 first. // Example: ,! ,! [ParaSwapRepayAdapter.sol#L138-L140](https://github.com/aave/aave-v3-periphery/blob/ca184e5278bcbc1 0d28c3dbbc604041d7cfac50b/contracts/adapters/paraswap/ParaSwapRepayAdapter.sol#L138-L140) c SafeERC20.safeApprove(IERC20(adopted), s.aavePool, 0); SafeERC20.safeIncreaseAllowance(IERC20(adopted), s.aavePool, totalRepayAmount); ... } } While the following functions dont do this:  xcall of BridgeFacet.  _backLoan of PortalFacet.  _swapAsset of AssetLogic.  execute of Executor. This could result in problems with tokens like USDT. 24 contract BridgeFacet is BaseConnextFacet { ,! function xcall(XCallArgs calldata _args) external payable nonReentrant whenNotPaused returns (bytes32) { ... SafeERC20.safeIncreaseAllowance(IERC20(bridged), address(s.bridgeRouter), bridgedAmt); ... } } contract PortalFacet is BaseConnextFacet { function _backLoan(...) ... { ... SafeERC20Upgradeable.safeIncreaseAllowance(IERC20Upgradeable(_asset), s.aavePool, _backing + ,! _fee); ... } } library AssetLogic { function _swapAsset(...) ... { ... SafeERC20.safeIncreaseAllowance(IERC20(_assetIn), address(pool), _amount); ... } } contract Executor is IExecutor { function execute( ... ) ... { ... SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); ... } }", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "_slippageTol does not adjust for decimal differences", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Users set the slippage tolerance in percentage. The assetLogic calculates: minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR Then assetLogic uses minReceived in the swap functions. The minReceived, however, does not adjust for the decimal differences between assetIn and assetOut. Users will either always hit the slippage or suffer huge slippage when assetIn and assetOut have a different number of decimals. Assume the number of decimals of assetIn is 6 and the decimal of assetOut is 18. The minReceived will be set to 10-12 smaller than the correct value. Users would be vulnerable to sandwich attacks in this case. Assume the number of decimals of assetIn is 18 and the number of decimals of assetOut is 6. The minReceived will be set to 1012 larger than the correct value. Users would always hit the slippage and the cross-chain transfer will get stuck. 25 library AssetLogic { function _swapAsset(... ) ... { // Swap the asset to the proper local asset uint256 minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR; ... return (pool.swapExact(_amount, _assetIn, _assetOut, minReceived), _assetOut); ... } }", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Canonical assets should be keyed on the hash of domain and id", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "A canonical asset is a tuple of a (domain, id) pair. TokenRegistrys owner has the power to regis- ter new tokens in the system (See TokenRegistry.ensureLocalToken() and TokenRegistry.enrollCustom()). A canonical asset is registered using the hash of its domain and id (See TokenRegistry._setCanonicalToRepre- sentation()). Connext uses only the id of a canonical asset to uniquely identify. Here are a few references:  swapStorages  canonicalToAdopted It is an issue if TokenRegistry registers two canonical assets with the same id. canonical asset an unintended one might be transferred to the destination chain, of the transfers may revert. If this id fetches the incorrect", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Missing checks for Chainlink oracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "ConnextPriceOracle.getTokenPrice() function goes through a series of oracles. At each step, it has a few validations to avoid incorrect price. If such validations succeed, the function returns the non-zero oracle price. For the Chainlink oracle, getTokenPrice() ultimately calls getPriceFromChainlink() which has the following validation  if (answer == 0 || answeredInRound < roundId || updateAt == 0) { // answeredInRound > roundId ===> ChainLink Error: Stale price // updatedAt = 0 ===> ChainLink Error: Round not complete return 0; } updateAt refers to the timestamp of the round. This value isnt checked to make sure it is recent. 26 Additionally, it is important to be aware of the minAnswer and maxAnswer of the Chainlink oracle, these values are not allowed to be reached or surpassed. See Chainlink API reference for documentation on minAnswer and maxAnswer as well as this piece of code: OffchainAggregator.sol", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Same params.SlippageTol is used in two different swaps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The Connext protocol does a cross-chain transfer with the help of the Nomad protocol. to use the Nomad protocol, Connext has to convert the adopted token into the local token. For a cross-chain transfer, users take up two swaps. Adopted -> Local at the source chain and Local -> Adopted at the destination chain. BridgeFacet.sol#L299-L304 function xcall(XCallArgs calldata _args) external payable whenNotPaused nonReentrant returns (bytes32) { ... // Swap to the local asset from adopted if applicable. (uint256 bridgedAmt, address bridged) = AssetLogic.swapToLocalAssetIfNeeded( canonical, transactingAssetId, amount, _args.params.slippageTol ); ... } BridgeFacet.sol#L637 function _handleExecuteLiquidity( bytes32 _transferId, bytes32 _canonicalId, bool _isFast, ExecuteArgs calldata _args ) private returns (uint256, address) { ... // swap out of mad* asset into adopted asset if needed return AssetLogic.swapFromLocalAssetIfNeeded(_canonicalId, _args.local, toSwap, _args.params.slippageTol); ,! } The same slippage tolerance _args.params.slippageTol is used in two swaps. In most cases users cannot set the correct slippage tolerance to protect two swaps. Assume the Nomad asset is slightly cheaper in both chains. 1 Nomad asset equals 1.01 adopted asset. An expected swap would be:1 adopted -> 1.01 Nomad asset -> 1 adopted. The right slippage tolerance should be set at 1.01 and 0.98 respectively. Users cannot set the correct tolerance with a single parameter. This makes users vulnerable to MEV searchers. Also, user transfers get stuck during periods of instability.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "getTokenPrice() returns stale token prices", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "getTokenPrice() reads from the assetPrices[tokenAddress].price mapping which stores the latest price as configured by the protocol admin in setDirectPrice(). However, the check for a stale token price will never fallback to other price oracles as tokenPrice != 0. Therefore, the stale token price will be unintentionally returned.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Potential division by zero if gas token oracle is faulty", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "In the event that the gas token oracle is faulty and returns malformed values, the call to reim- burseRelayerFees() in _handleExecuteTransaction() will fail. Fortunately, the low-level call() function will not prevent the transfer from being executed, however, this may lead to further issues down the line if changes are made to the sponsor vault.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Burn does not lower allowance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function _takeTokens() of BridgeRouter takes in the tokens from the sender. Sometimes it transfers them and sometimes it burns them. In the case of burning the tokens, the allowance isnt \"used up\". 28 function _takeTokens(... ) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount); ... } else { ... _t.burn(msg.sender, _amount); ... } ... // doesn't use up the allowance } contract BridgeToken is Version0, IBridgeToken, OwnableUpgradeable, ERC20 { ... function burn(address _from, uint256 _amnt) external override onlyOwner { _burn(_from, _amnt); } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Two step ownership transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function setAdmin() transfer ownership to a new address. In case a wrong address is supplied ownership is inaccessible. The same issue occurs with transferOwnership of OwnableUpgradeable in several Nomad contracts. Additionally the Nomad contract try to prevent renounceOwnership, however, this can also be accomplished with transferOwnership to a non existing address. Relevant Nomad contracts:  TokenRegistry.sol  NomadBase.sol  UpdaterManager.sol  XAppConnectionManager.sol 29 contract ConnextPriceOracle is PriceOracle { ... function setAdmin(address newAdmin) external onlyAdmin { address oldAdmin = admin; admin = newAdmin; emit NewAdmin(oldAdmin, newAdmin); } } contract BridgeRouter is Version0, Router { ... /** * @dev should be impossible to renounce ownership; * * */ we override OpenZeppelin OwnableUpgradeable's implementation of renounceOwnership to make it a no-op function renounceOwnership() public override onlyOwner { // do nothing } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Function removeRouter does not clear approvedForPortalRouters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function removeRouter() clears most of the fields of the struct RouterPermissionsManagerInfo except for approvedForPortalRouters. However, it is still good to also remove approvedForPortalRouters in removeRouter() because if the router were to be added again later (via setupRouter() ) or _isRouterOwnershipRenounced is set in the future, the router would still have the old approvedForPortalRouters. 30 struct RouterPermissionsManagerInfo { mapping(address => bool) approvedRouters; // deleted mapping(address => bool) approvedForPortalRouters; // not deleted mapping(address => address) routerRecipients; // deleted mapping(address => address) routerOwners; // deleted mapping(address => address) proposedRouterOwners; // deleted mapping(address => uint256) proposedRouterTimestamp; // deleted } contract RoutersFacet is BaseConnextFacet { function removeRouter(address router) external onlyOwner { ... s.routerPermissionInfo.approvedRouters[router] = false; ... s.routerPermissionInfo.routerOwners[router] = address(0); ... s.routerPermissionInfo.routerRecipients[router] = address(0); ... delete s.routerPermissionInfo.proposedRouterOwners[router]; delete s.routerPermissionInfo.proposedRouterTimestamp[router]; } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Anyone can self burn lp token of the AMM", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When providing liquidity into the AMM pool, users get LP tokens. Users can redeem their shares of the liquidity by redeeming LP to the AMM pool. The current LPToken contract inherits Openzepplins ERC20BurnableUpgradeable. Users can burn their tokens by calling burn without notifying the AMM pools. ERC20BurnableUpgradeable.sol#L26-L28. Although users do not profit from this action, it brings up concerns such as:  An exploiter has an easy way to pump the LP price. Burning LP is similar to donating value to the pool. While its good for the pool, this gives the exploiter another tool to break other protocols. After the cream finance attack many protocols started to take extra caution and made this a restricted function (absorbing donation) github.com/yearn/yearn-security/blob/master/disclosures/2021-10-27.md.  Against the best practice. Every state of an AMM is related to price. Allowing external actors to change the AMM states without notifying the main contract is dangerous. Its also harder for a developer to build other novel AMM based on the same architecture. Note: the burn function is also not protected by nonReentrant or whenNotPaused.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Skip timeout in diamondCut() (edge case)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Edge case: If someone manages to get an update through which deletes all facets then the next update skips the delay (because ds.facetAddresses.length will be 0). library LibDiamond { function diamondCut(...) ... { ... if (ds.facetAddresses.length != 0) { uint256 time = ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))]; require(time != 0 && time < block.timestamp, \"LibDiamond: delay not elapsed\"); } // Otherwise, this is the first instance of deployment and it can be set automatically ... } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Limit gas for s.executor.execute()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The call to s.executor.execute() in BridgeFacet might use up all available gas. In that case, the call to callback to report to the originator might not be called because the execution stops due an out of gas error. Note: the execute() function might be retried by the relayer so perhaps this will fix itself eventually. Note: excessivelySafeCall in Executor does limit the amount of gas. contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(...) ... { ... (bool success, bytes memory returnData) = s.executor.execute(...); // might use all available ,! gas ... // If callback address is not zero, send on the PromiseRouter if (_args.params.callback != address(0)) { s.promiseRouter.send(...); // might not have enough gas } ... } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Several external functions missing whenNotPaused mofifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The following functions dont have a whenNotPaused modifier while most other external functions do.  bumpTransfer of BridgeFacet.  forceReceiveLocal of BridgeFacet.  repayAavePortal of PortalFacet.  repayAavePortalFor of PortalFacet. Without whenNotPaused these functions can still be executed when the protocol is paused.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Gas griefing attack on callback execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When the callback is executed on the source chain the following line can revert or consume all forwarded gas. In this case, the relayer wastes gas and doesnt get the callback fee. ICallback(callbackAddress).callback(transferId, _msg.returnSuccess(), _msg.returnData());", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Callback fails when returnData is empty", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "If a transfer involves a callback, PromiseRouter reverts if returnData is empty. if (_returnData.length == 0) revert PromiseRouter__send_returndataEmpty(); However, the callback should be allowed in case the user wants to report the calldata execution success on the destination chain (_returnSuccess).", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Redundant fee on transfer logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function repayAavePortalFor() has logic for fee on transfer tokens. However, handleIncomin- gAsset() doesnt allow fee on transfer tokens. So this extra code shouldnt be necessary in repayAavePortal- For(). function repayAavePortalFor(...) ... { ... (, uint256 amount) = AssetLogic.handleIncomingAsset(_adopted, total, 0); ... // If this was a fee on transfer token, reduce the total if (amount < total) { uint256 missing; unchecked { missing = total - amount; } if (missing < _feeAmount) { // Debit fee amount unchecked { _feeAmount -= missing; } } else { // Debit backing amount unchecked { missing -= _feeAmount; } _feeAmount = 0; _backingAmount -= missing; } } ... } library AssetLogic { function handleIncomingAsset(...) ... { ... // Transfer asset to contract trueAmount = transferAssetToContract(_assetId, _assetAmount); .... } function transferAssetToContract(address _assetId, uint256 _amount) internal returns (uint256) { ... // Validate correct amounts are transferred uint256 starting = IERC20(_assetId).balanceOf(address(this)); SafeERC20.safeTransferFrom(IERC20(_assetId), msg.sender, address(this), _amount); // Ensure this was not a fee-on-transfer token if (IERC20(_assetId).balanceOf(address(this)) - starting != _amount) { revert AssetLogic__transferAssetToContract_feeOnTransferNotSupported(); } ... } } 34", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "Some gas can be saved in reimburseLiquidityFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Some gas can be saved by assigning tokenExchange before the if statement. This also improves readability. function reimburseLiquidityFees(...) ... { ... if (address(tokenExchanges[_token]) != address(0)) { // could use `tokenExchange` ITokenExchange tokenExchange = tokenExchanges[_token]; // do before the if }", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "LIQUIDITY_FEE_DENOMINATOR could be a constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The value of LIQUIDITY_FEE_DENOMINATOR seems to be constant. However, it is currently stored in s and requires an SLOAD operation to retrieve it, increasing gas costs. upgrade-initializers/DiamondInit.sol: BridgeFacet.sol: BridgeFacet.sol: PortalFacet.sol: AssetLogic.sol: s.LIQUIDITY_FEE_DENOMINATOR = 10000; toSwap = _getFastTransferAmount(..., s.LIQUIDITY_FEE_DENOMINATOR); s.portalFeeDebt[_transferId] = ... / s.LIQUIDITY_FEE_DENOMINATOR; if (_aavePortalFeeNumerator > s.LIQUIDITY_FEE_DENOMINATOR) ... uint256 minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR;", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "Access elements from storage array instead of loading them in memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "SwapUtils.removeLiquidityOneToken() function only needs the length and one element of the storage array self.pooledTokens. For this, the function reads the entire array in memory which costs extra gas. IERC20[] memory pooledTokens = self.pooledTokens; ... uint256 numTokens = pooledTokens.length; ... pooledTokens[tokenIndex].safeTransfer(msg.sender, dy); 35", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "Send information through calldata instead of having callee query Executor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Executor.originSender(), Executor.origin(), and Executor.amount() to permission crosschain calls. This costs extra gas because of staticcalls made to an external contract.", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "AAVE portal debt might not be repaid in full if debt is converted to interest paying", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The Aave portal mechanism gives routers access to a limited amount of unbacked debt which is to be used when fronting liquidity for cross-chain transfers. The process for receiving unbacked debt is as follows:  During message execution, the protocol checks if a single liquidity provider has bid on a liquidity auction which is handled by the relayer network.  If the provider has insufficient liquidity, the protocol attempts to utilize AAVE unbacked debt by minting uncol- lateralised aTokens and withdrawing them from the pool. The withdrawn amount is immediately used to pay out the recipient of the bridge transfer.  Currently the debt is fixed fee, see arc-whitelist-connext-for-v3-portals, however this might be changed in the future out of band.  Incase this would be changed: upon repayment, AAVE will actually expect unbackedDebt + fee + aToken interest. The current implementation will only track unbackedDebt + fee, hence, the protocol will accrue bad debt in the form of interest. Eventually, the extent of this bad debt will reach a point where the unbacked- MintCap has been reached and noone is able to pay off this debt. I consider this to be a long-term issue that could be handled in a future upgrade, however, it is important to highlight and address these issues early.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Routers pay the slippage cost for users when using AAVE credit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When routers do the fast of adopted token and _fastTransferAmount = * _fastTransferAmount /s.LIQUIDITY_FEE_DENOMINATOR _args.amount * s.LIQUIDITY_FEE_NUMERATOR / s.LIQUIDITY_FEE_DENOMINATOR. The routers get reimbursed _args.amount of local tokens afterward. Thus, the routers lose money if the slippage of swapping between local tokens and adopted tokens are larger than the liquidityFee. function _executePortalTransfer( bytes32 _transferId, bytes32 _canonicalId, uint256 _fastTransferAmount, address _router ) internal returns (uint256, address) { // Calculate local to adopted swap output if needed address adopted = s.canonicalToAdopted[_canonicalId]; ,! ,! ,! IAavePool(s.aavePool).mintUnbacked(adopted, _fastTransferAmount, address(this), AAVE_REFERRAL_CODE); // Improvement: Instead of withdrawing to address(this), withdraw directly to the user or executor to save 1 transfer uint256 amountWithdrawn = IAavePool(s.aavePool).withdraw(adopted, _fastTransferAmount, address(this)); if (amountWithdrawn < _fastTransferAmount) revert BridgeFacet__executePortalTransfer_insufficientAmountWithdrawn(); // Store principle debt s.portalDebt[_transferId] = _fastTransferAmount; // Store fee debt s.portalFeeDebt[_transferId] = (s.aavePortalFeeNumerator * _fastTransferAmount) / s.LIQUIDITY_FEE_DENOMINATOR; ,! emit AavePortalMintUnbacked(_transferId, _router, adopted, _fastTransferAmount); return (_fastTransferAmount, adopted); }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Optimize max checks in initializeSwap()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function initializeSwap() reverts if a value is >= ...MAX.... Probably should revert when > ...MAX.... function initializeSwap(...) ... { ... // Check _a, _fee, _adminFee, _withdrawFee parameters if (_a >= AmplificationUtils.MAX_A) revert SwapAdminFacet__initializeSwap_aExceedMax(); if (_fee >= SwapUtils.MAX_SWAP_FEE) revert SwapAdminFacet__initializeSwap_feeExceedMax(); if (_adminFee >= SwapUtils.MAX_ADMIN_FEE) revert SwapAdminFacet__initializeSwap_adminFeeExceedMax(); ... }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "All routers share the same AAVE debt", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The mintUnbacked amount is allocated to the calling contract (eg the Connext Diamond that has the BRIDGE role permission). Thus it is not separated to different routers, if one router does not payback its debt (in time) and has the max debt then this facility cannot be used any more. function _executePortalTransfer( ... ) ... { ... IAavePool(s.aavePool).mintUnbacked(adopted, _fastTransferAmount, address(this), AAVE_REFERRAL_CODE); ... }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Careful with fee on transfer tokens on AAVE loans", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The Aave function backUnbacked() does not account for fee on transfer tokens. If these happen to be used then the accounting might not be right. function _backLoan(...) ... { ... // back loan IAavePool(s.aavePool).backUnbacked(_asset, _backing, _fee); ... } library BridgeLogic { function executeBackUnbacked(... ) ... { ... reserve.unbacked -= backingAmount.toUint128(); reserve.updateInterestRates(reserveCache, asset, added, 0); IERC20(asset).safeTransferFrom(msg.sender, reserveCache.aTokenAddress, added); ... } }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Let getTokenPrice() also return the source of the price info", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function getTokenPrice() can get its prices information from multiple sources. For the caller it might be important to know which source was used. function getTokenPrice(address _tokenAddress) public view override returns (uint256) { }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Typos in the comments of _swapAsset() and _swapAssetOut()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "There are typos in the comments of _swapAsset() and _swapAssetOut(): * @notice Swaps assetIn t assetOut using the stored stable swap or internal swap pool function _swapAsset(... ) ... * @notice Swaps assetIn t assetOut using the stored stable swap or internal swap pool function _swapAssetOut(...) ...", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Consistently delete array entries in PromiseRouter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "In function process() of PromiseRouter.sol two different ways are used to clear a value: one with delete and the other with = 0. Although technically the same it better to use the same method to maintain consistency. function process(bytes32 transferId, bytes calldata _message) public nonReentrant { ... // remove message delete messageHashes[transferId]; // remove callback fees callbackFees[transferId] = 0; ... }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "getTokenPrice() will revert if setDirectPrice() is set in the future", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The setDirectPrice() function allows the protocol admin to update the price up to two seconds in the future. This impacts the getTokenPrice() function as the updated value may be slightly incorrect.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Roundup in words not optimal", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function words, which is used in the Nomad code base, tries to do a round up. Currently it adds 1 to the len. /** * @notice * @param memView * @return */ The number of memory words this memory view occupies, rounded up. The view uint256 - The number of memory words function words(bytes29 memView) internal pure returns (uint256) { return uint256(len(memView)).add(32) / 32; }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "callback could have capped returnData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function execute() caps the result of the call to excessivelySafeCall to a maximum of MAX_- COPY bytes, making sure the result is small enough to fit in a message sent back to the originator. However, when the callback is done the originator needs to be aware that the data can be capped and this fact is not clearly documented. 41 function execute(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, gas, isNative ? _args.amount : 0, MAX_COPY, _args.callData ); } function process(bytes32 transferId, bytes calldata _message) public nonReentrant { ... // execute callback ICallback(callbackAddress).callback(transferId, _msg.returnSuccess(), _msg.returnData()); // returnData is capped ... ,! }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Several external functions are not nonReentrant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The following functions dont have nonReentrant, while most other external functions do have such modifier.  bumpTransfer of BridgeFacet.  forceReceiveLocal of BridgeFacet.  repayAavePortal of PortalFacet.  repayAavePortalFor of PortalFacet.  initiateClaim of RelayerFacet. There are many swaps in the protocol and some of them should be conducted in an aggregator (not yet imple- mented). A lot of the aggregators use the difference between pre-swap balance and post-swap balance. (e.g. uniswap v3 router , 1inch, etc.. ). While this isnt exploitable yet, there is a chance that future updates might open up an issue to exploit.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "NomadFacet.reconcile() has an unused argument canonicalDomain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "NomadFacet.reconcile() has an unused argument canonicalDomain.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "SwapUtils._calculateSwap() returns two values with different precision", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "SwapUtils._calculateSwap() returns (uint256 dy, uint256 dyFee). dy is the amount of tokens a user will get from a swap and dyFee is the associated fee. To account for the different token decimal precision between the two tokens being swapped, a multipliers mapping is used to bring the precision to the same value. To return the final values, dy is changed back to the original token precision but dyFee is not. This is an internal function and the callers adjust the fee precision back to normal, therefore severity is informa- tional. But without documentation it is easy to miss.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Multicall.sol not compatible with Natspec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Multicall.sol Natspec comment specifies: /// @title Multicall - Aggregate results from multiple read-only function calls However, to call those functions it uses a low level call() method which can call write functions as well. (bool success, bytes memory ret) = calls[i].target.call(calls[i].callData);", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "reimburseRelayerFees only what is necessary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function reimburseRelayerFees() gives a maximum of relayerFeeCap to a receiver, unless it already has a balance of relayerFeeCap. This implicitly means that a balance relayerFeeCap is sufficient. So if a receiver already has a balance only relayerFeeCap - _to.balance is required. This way more recipients can be reimbursed with the same amount of funds in the SponsorVault. function reimburseRelayerFees(...) ... { ... if (_to.balance > relayerFeeCap || Address.isContract(_to)) { // Already has fees, and the address is a contract return; } ... sponsoredFee = sponsoredFee >= relayerFeeCap ? relayerFeeCap : sponsoredFee; ... }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "safeIncreaseAllowance and safeDecreaseAllowance can be replaced with safeApprove in _recon- cileProcessPortal", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The NomadFacet uses safeIncreaseAllowance after clearing the allowance. creaseAllowance to clear the allowance. Using safeApprove is potentially safer in this case. Some non-standard tokens only allow the allowance to change from zero, or change to zero. Using safeDecreaseAllowance would potentially break the contract in a future update. Note that SafeApprove has been deprecated for the concern of a front-running attack. It is only supported when setting an initial allowance or setting the allowance to zero SafeERC20.sol#L38", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Event not emitted when ERC20 and native asset is transferred together to SponsorVault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Any ERC20 token or native asset can be transferred to SponsorVault contract by calling the de- posit() function. It emits a Deposit() event logging the transferred asset and the amount. However, if the native asset and an ERC20 token are transferred in the same call only a single event corresponding to the ERC20 transfer is emitted.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "payable keyword can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "If a function does not need to have the native asset sent to it it is recommended to not mark it as payable and avoid any funds getting. StableSwapFacet.sol has two payable functions: swapExact() and swapExactOut, which only swap ERC20 tokens and are not expected to receive the native asset.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Improve variable naming", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Two different variables/functions with an almost identical name are prone to error. Variable names like _routerOwnershipRenounced and _assetOwnershipRenounced do not correctly reflect their meaning as they actually refer to the ownership whitelist being renounced. 45 function _isRouterOwnershipRenounced() internal view returns (bool) { return LibDiamond.contractOwner() == address(0) || s._routerOwnershipRenounced; } /** * @notice Indicates if the ownership of the asset whitelist has * been renounced */ function _isAssetOwnershipRenounced() internal view returns (bool) { ... bool _routerOwnershipRenounced; ... // 27 bool _assetOwnershipRenounced; The constant EMPTY is defined twice with different values. This is confusing and could lead to errors. contract BaseConnextFacet { ... bytes32 internal constant EMPTY = hex\"c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470\"; ... ,! } library LibCrossDomainProperty { ... bytes29 public constant EMPTY = hex\"ffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\"; ... } The function xcall() uses both _args.transactingAssetId and transactingAssetId. two, but they each have a very specific meaning and missing it introduces problems. It is easy to mix these function xcall(...) ... { ... address transactingAssetId = _args.transactingAssetId == address(0) ? address(s.wrapper) : _args.transactingAssetId; ... (, uint256 amount) = AssetLogic.handleIncomingAsset( _args.transactingAssetId, ... ); ... (uint256 bridgedAmt, address bridged) = AssetLogic.swapToLocalAssetIfNeeded( ..., transactingAssetId, ... ); ... } In the _handleExecuteTransaction function of BridgeFacet, _args.amount and _amount are used. In this func- tion:  _args.amount is equal to bridged_amount; 46  _amount is equal to bridged_amount - liquidityFee (and potentially swapped amount).", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "onlyRemoteRouter can be circumvented", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "BaseConnextFacet-fix. However, the change has not been applied to Router.sol#L56-L58 which is currently in use. The modifier onlyRemoteRouter() can be mislead if the sender parameter has the value 0. The modifier uses _m.sender() from the received message by Nomad. Assuming all checks of Nomad work as expected this value cannot be 0 as it originates from a msg.sender in Home.sol. contract Replica is Version0, NomadBase { function process(bytes memory _message) public returns (bool _success) { ... bytes29 _m = _message.ref(0); ... // ensure message has been proven bytes32 _messageHash = _m.keccak(); require(acceptableRoot(messages[_messageHash]), \"!proven\"); ... IMessageRecipient(_m.recipientAddress()).handle( _m.origin(), _m.nonce(), _m.sender(), _m.body().clone() ); ... } } contract BridgeRouter is Version0, Router { function handle(uint32 _origin,uint32 _nonce,bytes32 _sender,bytes memory _message) external override onlyReplica onlyRemoteRouter(_origin, _sender) { ... } } abstract contract Router is XAppConnectionClient, IMessageRecipient { ... modifier onlyRemoteRouter(uint32 _origin, bytes32 _router) { require(_isRemoteRouter(_origin, _router), \"!remote router\"); _; } function _isRemoteRouter(uint32 _domain, bytes32 _router) internal view returns (bool) { return remotes[_domain] == _router; // if _router == 0 then this is true for random _domains } }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Some dust not accounted for in reconcile()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function _handleExecuteLiquidity() in BridgeFacet takes care of rounding issues in toSwap / pathLen. However, the inverse function reconcile() in NomadFacet() does not do that. So, tiny amounts of tokens (dust) are not accounted for in reconcile(). contract BridgeFacet is BaseConnextFacet { ... function _handleExecuteLiquidity(...) ... { ... // For each router, assert they are approved, and deduct liquidity. uint256 routerAmount = toSwap / pathLen; for (uint256 i; i < pathLen - 1; ) { s.routerBalances[_args.routers[i]][_args.local] -= routerAmount; unchecked { ++i; } } // The last router in the multipath will sweep the remaining balance to account for remainder ,! dust. uint256 toSweep = routerAmount + (toSwap % pathLen); s.routerBalances[_args.routers[pathLen - 1]][_args.local] -= toSweep; } } } contract NomadFacet is BaseConnextFacet { ... function reconcile(...) ... { ... uint256 routerAmt = toDistribute / pathLen; for (uint256 i; i < pathLen; ) { s.routerBalances[routers[i]][localToken] += routerAmt; unchecked { ++i; } } } }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Careful with the decimals of BridgeTokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The BridgeRouter sends token details including the decimals() over the nomad bridge to configure a new deployed token. After setting the hash with setDetailsHash() anyone can call setDetails() on the token to set the details. The decimals() are mainly used for user interfaces so it might not be a large problem when the setDetails() is executed at later point in time. However initializeSwap() also uses decimals(), this is called via offchain code. In the example code of initializeSwap.ts it retrieves the decimals() from the deployed token on the destination chain. This introduces a race condition between setDetails() and initializeSwap.ts, depending on which is executed first, the swaps will have different results. Note: It could also break the ConnextPriceOracle contract BridgeRouter is Version0, Router { ... function _send( ... ) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... // query token contract for details and calculate detailsHash _detailsHash = BridgeMessage.getDetailsHash(_t.name(), _t.symbol(), _t.decimals()); } else { ... } } function _handleTransfer(...) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... } else { ... IBridgeToken(_token).setDetailsHash(_action.detailsHash()); // so hash is set now } } } contract BridgeToken is Version0, IBridgeToken, OwnableUpgradeable, ERC20 { ... function setDetails(..., uint8 _newDecimals) ... { // can be called by anyone ... require( _isFirstDetails || BridgeMessage.getDetailsHash(..., _newDecimals) == detailsHash, \"!committed details\" ); ... token.decimals = _newDecimals; ... } } Example script: initializeSwap.ts 49 const decimals = await Promise.all([ (await ethers.getContractAt(\"TestERC20\", local)).decimals(), (await ethers.getContractAt(\"TestERC20\", adopted)).decimals(), // setDetails might not have ,! been done ]); const tx = await connext.initializeSwap(..., decimals, ... ); ); contract SwapAdminFacet is BaseConnextFacet { ... function initializeSwap(..., uint8[] memory decimals, ... ) ... { ... for (uint8 i; i < numPooledTokens; ) { ... precisionMultipliers[i] = 10**uint256(SwapUtils.POOL_PRECISION_DECIMALS - decimals[i]); ... } } }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Incorrect comment about ERC20 approval to zero-address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The linked code notes in a comment: // NOTE: if pool is not registered here, then the approval will fail // as it will approve to the zero-address SafeERC20.safeIncreaseAllowance(IERC20(_assetIn), address(pool), _amount); This is not always true. The ERC20 spec doesnt have this restriction and ERC20 tokens based on solmate also dont revert on approving to zero-address. There is no risk here as the following line of code for zero-address pools will revert. return (pool.swapExact(_amount, _assetIn, _assetOut, minReceived), _assetOut);", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Native asset is delivered even if the wrapped asset is transferred", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Connext delivers the native asset on the destination chain even if the wrapped asset was transferred. This is because on the source chain the native asset is converted to the wrapped asset, and then the distinction is lost. On the destination chain it is not possible to know which of these two assets was transferred, and hence a choice is made to transfer the native asset. if (_assetId == address(0)) revert AssetLogic__transferAssetFromContract_notNative(); if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } else { ...", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Entire transfer amount is borrowed from AAVE Portal when a router has insufficient balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "If the router picked by the Sequencer doesnt have enough balance to transfer the required amount, it can borrow the entire amount from Aave Portal. For a huge amount, it will block borrowing for other routers since there is a limit on the total maximum amount that can be borrowed.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Unused variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The variable message is not used after declaration. bytes memory message;", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Incorrect Natspec for adopted and canonical asset mappings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "adoptedToCanonical maps adopted assets to canonical assets, but is described as a \"Mapping of canonical to adopted assets\"; canonicalToAdopted maps canonical assets to adopted assets, but is described as a \"Mapping of adopted to canonical assets\". // /** // * @notice Mapping of canonical to adopted assets on this domain // * @dev If the adopted asset is the native asset, the keyed address will // * be the wrapped asset address // */ // 12 mapping(address => TokenId) adoptedToCanonical; // /** // * @notice Mapping of adopted to canonical on this domain // * @dev If the adopted asset is the native asset, the stored address will be the // * wrapped asset address // */ // 13 mapping(bytes32 => address) canonicalToAdopted;", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Use of SafeMath for solc >= 0.8", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "AmplificationUtils, SwapUtils, ConnextPriceOracle, GovernanceRouter.sol use SafeMath. Since 0.8.0, arithmetic in solidity reverts if it overflows or underflows, hence there is no need to use open- zeppelins SafeMath library.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "First pool depositor can be front-run and have part of their deposit stolen", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The first deposit with a totalSupply of zero shares will mint shares equal to the deposited amount. This makes it possible to deposit the smallest unit of a token and profit off a rounding issue in the computation for the minted shares of the next depositor: (shares_ * totalAssets()) / totalSupply_ Example:  The first depositor (victim) wants to deposit 2M USDC (2e12) and submits the transaction.  The attacker front runs the victim's transaction by calling deposit(1) to get 1 share. They then transfer 1M USDC (1e12) to the contract, such that totalAssets = 1e12 + 1, totalSupply = 1.  When the victim's transaction is mined, they receive 2e12 / (1e12 + 1) * totalSupply = 1 shares (rounded down from 1.9999...).  The attacker withdraws their 1 share and gets 3M USDC * 1 / 2 = 1.5M USDC, making a 0.5M profit. During the migration, an _initialSupply of shares to be airdropped are already minted at initialization and are not affected by this attack.", "labels": ["Spearbit", "MapleV2.pd", "Severity: High Risk"]}, {"title": "Users depositing to a pool with unrealized losses will take on the losses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The pool share price used for deposits is always the totalAssets() / totalSupply, however the pool share price when redeeming is totalAssets() - unrealizedLosses() / totalSupply. The unrealized- Losses value is increased by loan impairments (LM.impairLoan) or when starting triggering a default with a liq- uidation (LM.triggerDefault). The totalAssets are only reduced by this value when the loss is realized in LM.removeLoanImpairment or LM.finishCollateralLiquidation. This leads to a time window where deposits use a much higher share price than current redemptions and future deposits. Users depositing to the pool during this time window are almost guaranteed to make losses when they In the worst case, a Pool.deposit might even be (accidentally) front-run by a loan impairment or are realized. liquidation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "TransitionLoanManager.add does not account for accrued interest since last call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The TransitionLoanManager.add advances the domain start but the accrued interest since the last domain start is not accounted for. If add is called several times, the accounting will be wrong. It therefore wrongly tracks the _accountedInterest variable.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Unaccounted collateral is mishandled in triggerDefault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The control flow of triggerDefault is partially determined by the value of MapleLoanLike(loan_- ).collateral() == 0. The code later assumes there are 0 collateral tokens in the loan if this value is true, which is incorrect in the case of unaccounted collateral tokens. In non-liquidating repossessions, this causes an overes- timation of the number of fundsAsset tokens repossessed, leading to a revert in the _disburseLiquidationFunds function. Anyone can trigger this revert by manually transferring 1 Wei of collateralAsset to the loan itself. In liq- uidating repossessions, a similar issue causes the code to call the liquidator's setCollateralRemaining function with only accounted collateral, meaning unaccounted collateral will be unused/stuck in the liquidator.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Initial cycle time is wrong when queuing several config updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The initial cycle time will be wrong if there's already an upcoming config change that changes the cycle duration. Example: currentCycleId: 100 config[0] = currentConfig = {initialCycleId: 1, cycleDuration = 1 days} config[1] = {initialCycleId: 101, cycleDuration = 7 days} Now, scheduling will create a config with initialCycleId: 103 and initialCycleTime = now + 3 * 1 days, but the cycle durations for cycles (100, 101, 102) are 1 days + 7 days + 7 days.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Users cannot resubmit a withdrawal request as per the wiki", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "As per Maple's wiki: pool-v2::PoolManager.sol#371-L382, withdrawal-  Refresh: The withdrawal request can be resubmitted with the same amount of shares by calling pool.requestRedeem(0). However, the current implementation prevents Pool.requestRedeem() from being called where the shares_ pa- rameter is zero.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Accrued interest may be calculated on an overstated payment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The checkTotalAssets() function is a useful helper that may be used to make business decisions in the protocol. However, if there is a late loan payment, the total interest is calculated on an incorrect payment interval, causing the accrued interest to be overstated. It is also important to note that late interest will also be excluded from the total interest calculation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "No deadline when liquidating a borrower's collateral", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "A loan's collateral is liquidated in the event of a late payment or if the pool delegate impairs a loan If the loan contains any amount of collateral (assuming it is different to the due to insolvency by the borrower. funds' asset), the liquidation process will attempt to sell the collateral at a discounted amount. Because a liquidation is considered active as long as there is remaining collateral in the liquidator contract, a user can knowingly liquidate all but 1 wei of collateral. As there is no incentive for others to liquidate this dust amount, it is up to the loan manager to incur the cost and responsibility of liquidating this amount before they can successfully call LoanManager.finishCollateralLiquidation().", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Loan impairments can be unavoidably unfair for borrowers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "When a pool delegate impairs a loan, the loan's _nextPaymentDueDate will be set to the min of If the pool delegate later decides to remove the im- block.timestamp and the current _nextPaymentDueDate. pairment, the original _nextPaymentDueDate is restored to its correct value. The borrower can also remove an impairment themselves by making a payment. In this case, the _nextPaymentDueDate is not restored, which is always worse for the borrower. This can be unfair since the borrower would have to pay late interest on a loan that was never actually late (according to the original payment due date). Another related consequence is that a borrower can be liquidated before the original payment due date even passes (this is possible as long as the loan is impaired more than gracePeriod seconds away from the original due date).", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "withdrawCover() vulnerable to reentrancy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "withdrawCover() allows for reentrancy and could be abused to withdraw below the minimum cover amount and avoid having to cover protocol insolvency through a bad liquidation or loan default. The moveFunds() function could transfer the asset amount to the recipient specified by the pool delegate. Some In this case, the pool delegate could reenter the tokens allow for callbacks before the actual transfer is made. withdrawCover() function and bypass the balance check as it is made before tokens are actually transferred. This can be repeated to empty out required cover balance from the contract. It is noted that the PoolDelegateCover contract is a protocol controlled contract, hence the low severity.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Bad parameter encoding and deployment when using wrong initializers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The initializers used to encode the arguments, when deploying a new pool in PoolDeployer, might not be the initializers that the proxy factory will use for the default version and might lead to bad parameter encoding & deployments if a wrong initializer is passed.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Event LoanClosed might be emitted with the wrong value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "In function closeLoan function, the fees are got by the getClosingPaymentBreakdown function and it is not adding refinances fees after in code are paid all fee by payServiceFees which may include refinances fees. The event LoanClose might be emitted with the wrong fee value.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Bug in makePayment() reverts when called with small amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "When makePayment() is called with an amount which is less than the fees payable, then the trans- action will always revert, even if there is an adequate amount of drawable funds. The revert happens due to an underflow in getUnaccountedAmount() because the token balance is decremented on the previous line without updating drawable funds.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Pool.previewWithdraw always reverts but Pool.withdraw can succeed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Pool.previewWithdraw => PM. previewWithdraw => WM.previewWithdraw function call se- quence always reverts in the WithdrawalManager. However, the Pool.withdraw function can succeed. This behavior might be unexpected, especially, as integrators call previewWithdraw before doing the actual withdraw call.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Setting a new WithdrawalManager locks funds in old one", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The WithdrawalManager only accepts calls from a PoolManager. When setting a new withdrawal manager with PoolManager.setWithdrawalManager, the old one cannot be accessed anymore. Any user shares locked for withdrawal in the old one are stuck.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Use whenProtocolNotPaused on migrate() instead of upgrade() for more complete protection", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "whenProtocolNotPaused is added to migrate() for the Liquidator, MapleLoan, and Withdrawal- Manager contracts in order to protect the protocol by preventing it from upgrading while the protocol is paused. However, this protection happens only during upgrade, and not during instantiation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Missing post-migration check in PoolManager.sol could result in lost funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The protocol employs an upgradeable/migrateable system that includes upgradeable initializers for factory created contracts. For the most part, a storage value that was left uninitialized due to an erroneous initializer would not be affect protocol funds. For example forgetting to initialize _locked would cause all nonReentrant functions to revert, but no funds lost. However, if the poolDelegateCover address were unset and depositCover() were called, the funds would be lost as there is no to != address(0) check in transferFrom.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Globals.poolDelegates[delegate_].ownedPoolManager mapping can be overwritten", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Globals.poolDelegates[delegate_].ownedPoolManager keeps track of a single pool manager for a pool delegate. It can happen that the same pool delegate is registered for a second pool manager and the mapping is overwritten, by calling PM.acceptPendingPoolDelegate -> Globals.transferOwnedPoolManager or Globals.activatePoolManager.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Pool withdrawals can be kept low by non-redeeming users", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "In the current pool design, users request to exit the pool and are scheduled for a withdrawal window in the withdrawal manager. If the pool does not have enough liquidity, their share on the available pool liquidity is proportionate to the total shares of all users who requested to withdraw in that withdrawal window. It's possible for griefers to keep the withdrawals artificially low by requesting a withdrawal but not actually withdraw- ing during the withdrawal window. These griefers are not penalized but their behavior leads to worse withdrawal amounts for every other honest user.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "_getCollateralRequiredFor should round up", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The _getCollateralRequiredFor rounds down the collateral that is required from the borrower. This benefits the borrower.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Use the cached variable in makePayment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The claim function is called using _nextPaymentDueDate instead of nextPaymentDueDate_", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "No need to explicitly initialize variables with default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "By default a value of a variable is set to 0 for uint, false for bool, address(0) for address. . . Explicitly initializing/setting it with its default value wastes gas.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Cache calculation in getExpectedAmount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The decimal precision calculation is used twice in the getExpectedAmount function, if you cache into a new variable would save some gas.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "For-Loop Optmization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The for-loop can be optimized in 4 ways: 1. Removing initialization of loop counter if the value is 0 by default. 2. Caching array length outside the loop. 3. Prefix increment (++i) instead of postfix increment (i++). 4. Unchecked increment. - for (uint256 i_ = 0; i_ < loans_.length; i_++) { + uint256 length = loans_.length; + for (uint256 i_; i_ < length; ) { ... + unchecked { ++i; } }", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Pool._divRoundUp can be more efficient", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The gas cost of Pool._divRoundUp can be reduced in the context that it's used in.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Liquidator uses different reentrancy guards than rest of codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "All other reentrancy guards of the codebase use values 1/2 instead of 0/1 to indicate NOT_- LOCKED/LOCKED.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Use block.timestamp instead of domainStart in removeLoanImpairment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The removeLoanImpairment function adds back all interest from the payment's start date to domain- Start. The _advanceGlobalPaymentAccounting sets domainStart to block.timestamp.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "setTimelockWindows checks isGovernor multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Globals.setTimelockWindows function calls setTimelockWindow in a loop and each time set- TimelockWindow's isGovernor is checked.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "fullDaysLate computation can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The fullDaysLate computation can be optimized.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Users can prevent repossessed funds from being claimed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The DebtLocker.sol contract dictates an active liquidation by the following two conditions:  The _liquidator state variable is a non-zero address.  The current balance of the _liquidator contract is non-zero. If an arbitrary user sends 1 wei of funds to the liquidator's address, the borrower will be unable to claim repos- sessed funds as seen in the _handleClaimOfRepossessed() function. While the scope of the audit only covered the diff between v3.0.0 and v4.0.0-rc.0, the audit team decided it was important to include this as an informational issue. The Maple team will be addressing this in their V2 release.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "MEV whenever totalAssets jumps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "An attack users can try to capture large interest payments is sandwiching a payment with a deposit and a withdrawal. The current codebase tries to mostly eliminate this attack by:  Optimistically assuming the next interest payment will be paid back and accruing the interest payment linearly over the payment interval.  Adding a withdrawal period. However, there are still circumstances where the totalAssets increase by a large amount at once:  Users paying back their payment early. The jump in totalAssets will be the paymentAmount - timeE- lapsedSincePaymentStart / paymentInterval * paymentAmount.  Users paying back their entire loan early (closeLoan).  Late payments increase it by the late interest fees and the accrued interest for the next payment from its start date to now. 21", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Use ERCHelper approve() as best practice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The ERC20 approve function is being used by fundsAsset in fundLoan() to approve the max amount which does not check the return value.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification in removeLoanImpairment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Currently, if removeLoanImpairment is called after the loan's original due date, there will be no issues because the loan's removeLoanImpairment function will revert. It would be good to add a comment about this logic or duplicate the check explicitly in the loan manager. If the loan implementation is upgraded in the future to have a non-reverting removeLoanImpairment function, then the loan manager as-is would account for the interest incorrectly.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Can check msg.sender != collateralAsset/fundsAsset for extra safety", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Some old ERC tokens (e.g. the Sandbox's SAND token) allow arbitrary calls from the token address itself. This odd behavior is usually a result of implementing the ERC677 approveAndCall and transferAndCall functions incorrectly. With these tokens, it is technically possible for the low-level msg.sender.call(...) in the liquidator to be executing arbitrary code on one of the tokens, which could let an attacker drain the funds.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "IERC426 Implementation of preview and max functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "For the preview functions, EIP 4626 states: MAY revert due to other conditions that would also cause the deposit [mint/redeem, etc.] to revert. But the comments in the interface currently state: MUST NOT revert. In addition to the comments, there is the actual behavior of the preview functions. A commonly accepted interpreta- tion of the standard is that these preview functions should revert in the case of conditions such as protocolPaused, !active, !openToPublic totalAssets > liquidityCap etc. The argument basically states that the max functions should return 0 under such conditions and the preview functions should revert whenever the amount exceeds the max.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Set domainEnd correctly in intermediate _advanceGlobalPaymentAccounting steps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "pay- ments[paymentWithEarliestDueDate].paymentDueDate, which is possibly zero if the last payment has just been accrued past. This is currently not an issue, because in this scenario domainEnd would never be used before it is set back to its correct value in _updateIssuanceParams. However, for increased readability, it is recommended to prevent this odd intermediate state from ever occurring. domainEnd function, set to is", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Replace hard-coded value with PRECISION constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The constant PRECISION is equal to 1e30. The hard-coded value 1e30 is used in the _queueNext- Payment function, which can be replaced by PRECISION.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Use of floating pragma version", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Contracts should be deployed using a fixed pragma version. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example, an outdated compiler version that might introduce bugs that affect the contract system negatively.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager has low-level shares computation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager has low-level shares computation logic that should ideally only be in the ERC4626 Pool to separate the concerns.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Add additional checks to prevent refinancing/funding a closed loan", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "It's important that an already liquidated loan is not reused by refinancing or funding again as it would break a second liquidation when the second liquidator contract is deployed with the same arguments and salt.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager.removeLoanManager errors with out-of-bounds if loan manager not found", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager.removeLoanManager errors with an out-of-bounds error if the loan manager is not found.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager.removeLoanManager does not clear loanManagers mapping", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager.removeLoanManager does not clear the reverse loanManagers[mapleLoan] = loanManager mapping.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Pool._requestRedeem reduces the wrong approval amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The requestRedeem function transfers escrowShares_ from owner but reduces the approval by shares_. Note that in the current code these values are the same but for future PoolManager upgrades this could change.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Issuance rate for double-late claims does not need to be updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The previousRate_ for the 8c) case in claim is always zero because the payment (!onTimePayment_). The subtraction can be removed is late I'd suggest removing the subtraction here as it's confusing. The first payment's IR was reduced in _advanceGlob- alPaymentAccounting, the newly scheduled one that is also past due date never increased the IR.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification that paymentIdOf[loan_] is not 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Most functions in the loan manager use the value paymentIdOf[loan_] without first checking if it's the default value of 0. Anyone can pay off a loan at any time to cause the claim function to set paymentIdOf[loan_] to 0, so even the privileged functions could be front-run to call on a loan with paymentIdOf 0. This is not an issue in the current codebase because each function would revert for some other reasons, but it is recommended to add an explicit check so future upgrades on other modules don't make this into a more serious issue.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "LoanManager redundant check on late payment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "block.timestamp <= nextPaymentDueDate_ in one of the if statements. The payment is already known to be late at this point in the code, so block.timestamp > previousPaymentDueDate_ is always true.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Add encodeArguments/decodeArguments to WithdrawalManagerInitializer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Unlike the other Initializers, the WithdrawalManagerInitializer.sol does not have public en- codeArguments/decodeArguments functions, and PoolDeployer need to be changed to use these functions cor- rectly", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Reorder WM.processExit parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "All other WM and Pool function signatures start with (uint256 shares/assets, address owner) parameters but the WM.processExit has its parameters reversed (address, uint256).", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification in MapleLoanInitializer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The MapleLoanInitializer could verify additional arguments to avoid bad pool deployments.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Clean up updatePlatformServiceFee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The updatePlatformServiceFee can be cleaned up to use an existing helper function", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Document restrictions on Refinancer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The refinancer may not set unexpected storage slots, like changing the _fundsAsset because _- drawableFunds, _refinanceInterest are still measured in the old fund's asset.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Typos / Incorrect documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The code and comments contain typos or are sometimes incorrect.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Balancer Read-Only Reentrancy Vulnerability (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Balancer's read-only reentrancy vulnerability potentially effects the following Cron-Fi TWAMM func- tions:  getVirtualReserves  getVirtualPriceOracle  executeVirtualOrdersToBlock A mitigation was provided by the Balancer team that uses a minimum amount of gas to trigger a reentrancy check. The Balancer vulnerability is discussed in greater detail here:  reentrancy-vulnerability-scope-expanded/4345", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "Overpayment of one side of LP Pair onJoinPool due to sandwich or user error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Only one of the two incoming tokens are used to determine the amount of pool tokens minted (amountLP) on join amountLP = Math.min( _token0InU112.mul(supplyLP).divDown(_token0ReserveU112), _token1InU112.mul(supplyLP).divDown(_token1ReserveU112) ); In the event the price moves between the time a minter sends their transaction and when it is included in a block, they may overpay for one of _token0InU112 or _token1InU112. This can occur due to user error, or due to being sandwiched. Concrete example: pragma solidity ^0.7.0; pragma experimental ABIEncoderV2; import \"forge-std/Test.sol\"; import \"../HelperContract.sol\"; import { C } from \"../../Constants.sol\"; import { ExecVirtualOrdersMem } from \"../../Structs.sol\"; contract JoinSandwich is HelperContract { uint256 WAD = 10**18; function testManualJoinSandwich() public { 5 address userA = address(this); address userB = vm.addr(1323); // Add some base liquidity from the future attacker. addLiquidity(pool, userA, userA, 10**7 * WAD, 10**7 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userA), 10**7 * WAD - C.MINIMUM_LIQUIDITY); // Give userB some tokens to LP with. token0.transfer(userB, 1_000_000 * WAD); token1.transfer(userB, 1_000_000 * WAD); addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userB), 10**6 * WAD); exit(10**6 * WAD, ICronV1Pool.ExitType(0), pool, userB); assertEq(CronV1Pool(pool).balanceOf(userB), 0); // Full amounts are returned b/c the exit penalty has been removed (as is being done anyway). assertEq(token0.balanceOf(userB), 1_000_000 * WAD); assertEq(token1.balanceOf(userB), 1_000_000 * WAD); // Now we'll do the same thing, simulating a sandwich from userA. uint256 swapProceeds = swapPoolAddr(5 * 10**6 * WAD, /* unused */ 0, ICronV1Pool.SwapType(0), address(token0), pool, ,! userA); // Original tx from userB is sandwiched now... addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); // Sell back what was gained from the first swap. swapProceeds = swapPoolAddr(swapProceeds, /* unused */ 0, ICronV1Pool.SwapType(0), address(token1), pool, userA); emit log_named_uint(\"swapProceeds 1 to 0\", swapProceeds); // allows seeing what userA lost to fees // Let's see what poor userB gets back of their million token0 and million token1... assertEq(token0.balanceOf(userB), 0); assertEq(token1.balanceOf(userB), 0); exit(ICronV1Pool(pool).balanceOf(userB), ICronV1Pool.ExitType(0), pool, userB); emit log_named_uint(\"userB token0 after\", token0.balanceOf(userB)); emit log_named_uint(\"userB token1 after\", token1.balanceOf(userB)); } } Output: Logs: swapProceeds 1 to 0: 4845178856516554015932796 userB token0 after: 697176321467715374004199 userB token1 after: 687499999999999999999999 1. We have a pool where the attacker is all of the liquidity (107 of each token) 2. A LP tries to deposit another 106 in equal proportions 3. The attacker uses a swap of 5 (cid:3) 106 of one of the tokens to distort the pool. They lose about 155k in the process, but the LP loses far more, nearly all of which goes to the attacker--about 615,324 (sum of the losses of the two tokens since they're equally priced in this example). The attacker could be a significantly smaller proportion of the pool and still find this attack profitable. They could also JIT the liquidity since the early withdrawal penalty has been removed. The attack becomes infeasible for very large pools (has to happen over multiple TXs so can't flash loan --need own capital), but is relevant in practice.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "Loss of Long-Term Swap Proceeds Likely in Pools With Decimal or Price Imbalances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "This TWAMM implementation tracks the proceeds of long-term swaps efficiently via accumulated values called \"scaled proceeds\" for each token. In every order block interval (OBI), the scaled proceeds for e.g. the sale of token 0 are incremented by (quantity of token 1 purchased during the OBI) (cid:3)264= (sales rate of token 0 during the OBI) Then the proceeds of any specific long-term swap can be computed as the product of the difference between the scaled proceeds at the current block (or the expiration block of the order if filled) and the last block for which proceeds were claimed for the order and the order's sales rate, divided by 264: last := min(currentBlock, orderExpiryBlock) prev := block of last proceeds collection, or block order was placed in if this is the first withdrawal LT swap proceeds = (scaledProceedsl ast (cid:0) scaledProceedsprev ) (cid:3) (ordersalesrate)=264 The value 264 is referred to as the \"scaling factor\" and is intended to reduce precision loss in the division to determine the increment to the scaled proceeds. The addition to increment the scaled proceeds and the subtraction to compute its net change is both intentionally done with unchecked arithmetic--since only the difference matters, so long as at most one overflow occurs between claim-of-proceeds events for any given order, the computed proceeds will be correct (up to rounding errors). If two or more overflows occur, however, funds will be lost by the swapper (unclaimable and locked in the contract). Additionally, to cut down on gas costs, the scaled proceeds for the two tokens are packed into a single storage slot, so that only 128 bits are available for each value. This makes multiple overflows within the lifetime of a single order more likely. The CronFi team was aware of this at the start of the audit and specifically requested it be investigated, though they expected a maximum order length of 5 years to be sufficient to avoid the issue in practice. The scaling factor of 264 is approximately 1.8 (cid:3) 1019, close to the unit size of an 18-decimal token. It indeed works well if both pool tokens have similar decimals and relative prices that do not differ by too many orders of magnitude, as the quantity purchased and the sales rate will then be of similar magnitude, canceling to within a few powers of ten (2128 3.4 (cid:3) 1038, leaving around 19 orders of magnitude after accounting for the scaling factor). However, in pools with large disparities in price, decimals, or both, numerical issues are easy to encounter. The most extreme, realistic example would be a DAI-GUSD pool. DAI has 18 decimals while GUSD has only 2. We will treat the price of DAI and GUSD as equal for this analysis, as they are both stablecoins, and arbitrage of the TWAMM pool should prevent large deviations. Selling GUSD at a rate of 1000 per block, with an OBI of 64 (the stable pool order block interval in the audited commit) results in an increment of the scaled proceeds per OBI of: increment = (64 (cid:3) 1000 (cid:3) 1018) (cid:3) 264=(1000 (cid:3) 102) = 1.18 (cid:3) 1037 7 This will overflow an unsigned 128 bit integer after 29 OBIs; at 12 seconds per block, this means the first overflow occurs after 12 (cid:3) 64 (cid:3) 29 = 22272 seconds or about 6.2 hours, and thus the first double overflow (and hence irrevocable loss of proceeds if a withdrawal is not executed in time) will occur within about 12.4 hours (slightly but not meaningfully longer if the price is pushed a bit below 1:1, assuming a deep enough pool or reasonably efficient arbitrage). Since the TWAMM is intended to support swaps that take days, weeks, months, or even years to fill, without requiring constant vigilance from every long-term swapper, this is a strong violation of safety. A less extreme but more market-relevant example would be a DAI-WBTC pool. WBTC has 8 instead of 2 decimals, but it is also more than four orders of magnitude more valuable per token than DAI, making it only about 2 orders of magnitude \"safer\" than a DAI-GUSD pool. Imitating the above calculation with 20_000 DAI = 1 WBTC and selling 0.0025 WBTC (~$50) per block with a 257 block OBI yields: increment = (257 (cid:3) 50 (cid:3) 1018) (cid:3) 264=(0.0025 (cid:3) 108) = 9.48 (cid:3) 1035 OBI to overflow = ceiling(2128=(9.48 (cid:3) 1035)) = 359 time to overflow = 12 (cid:3) 257 (cid:3) 359 = 1107156 seconds = 307 hours = 12.8 days , or a little more than a day to encounter the second overflow. While less bad than the DAI-GUSD example, this is still likely of significant concern given that the CronFi team indicated these are parameters under which the TWAMM should be able to function safely and DAI-WBTC is a pair of interest for the v1 product. It is worth noting that these calculations are not directly dependent on the quantity being sold so long as the price stays roughly constant--any change in the selling rate will be compensated by a proportional change in the proceeds quantity as their ratio is determined by price. Thus the analysis depends only on relative price and relative decimals, to a good approximation--so a WBTC-DAI pool can be expected to experience an overflow roughly every two weeks at prevailing market prices, so long as the net selling rate is non-zero.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "An attacker can block any address from joining the Pool and minting BLP Tokens by filling the joinEventMap mapping.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "An attacker can block any address from minting BLP Tokens. This occurs due to the MAX_JOIN_- EVENTS limit, which is present in the JoinEventLib library. The goal for an attacker is to block a legitimate user from minting BLP Tokens, by filling the joinEventMap mapping. The attacker can fill the joinEventMap mapping by performing the following steps:  The attacker mints BLP Tokens from 50 different addresses.  Each address transfers the BLP Tokens, alongside the join events, to the user targeted with a call to the CronV1Pool(pool).transfer and CronV1Pool(pool).transferJoinEvent functions respectively. Those transfers should happen in different blocks. After 50 blocks (50 * 12s = 10 minutes) the attacker has blocked the legitimate user from minting _BLP Tokens_, as the maximum size of the joinEventMap mapping has been reached. 8 The impact of this vulnerability can be significant, particularly for smart contracts that allow users to earn yield by providing liquidity in third-party protocols. For example, if a governance proposal is initiated to generate yield by providing liquidity in a CronV1Pool pool, the attacker could prevent the third-party protocol from integrating with the CronV1Pool protocol. A proof-of-concept exploit demonstrating this vulnerability can be found below: function testGriefingAttack() public { console.log(\"-----------------------------\"); console.log(\"Many Users mint BLP tokens and transfer the join events to the user 111 in order to fill the array!\"); ,! for (uint j = 1; j < 51; j++) { _addLiquidity(pool, address(j), address(j), 2_000, 2_000, 0); vm.warp(block.timestamp + 12); vm.startPrank(address(j)); //transfer the tokens CronV1Pool(pool).transfer(address(111), CronV1Pool(pool).balanceOf(address(j))); //transfer the join events to the address(111) CronV1Pool(pool).transferJoinEvent(address(111), 0 , CronV1Pool(pool).balanceOf(address(j))); vm.stopPrank(); } console.log(\"Balance of address(111) before minting LP Tokens himself\", ,! ICronV1Pool(pool).balanceOf(address(111))); //user(111) wants to enter the pool _addLiquidity(pool, address(111), address(111), 5_000, 5_000, 0); console.log(\"Join Events of user address(111): \", ICronV1Pool(pool).getJoinEvents(address(111)).length); console.log(\"Balance of address(111) after adding the liquidity: \", ICronV1Pool(pool).balanceOf(address(111))); ,! ,! }", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "The executeVirtualOrdersToBlock function updates the oracle with the wrong block.number", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The executeVirtualOrdersToBlock is external, meaning anyone can call this function to execute virtual orders. The _maxBlock parameter can be lower block.number which will make the oracle malfunction as the oracle update function _updateOracle uses the block.timestamp and assumes that the update was called with the reserves at the current block. This will make the oracle update with an incorrect value when _maxBlock can be lower than block.number.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "The _join function does not check if the recipient is address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "As stated within the Balancer's PoolBalances.sol // The Vault ignores the `recipient` in joins and the `sender` in exits: it is up to the Pool to keep track of ,! // their participation. The recipient is not checked if it's the address(0), that should happen within the pool implementation. Within the Cron implementation, this check is missing which can cause losses of LPs if the recipient is sent as address(0). This can have a high impact if a 3rd party integration happens with the Cron pool and the \"joiner\" is mistakenly sending an address(0). This becomes more dangerous if the 3rd party is a smart contract implementation that connects with the Cron pool, as the default value for an address is the address(0), so the probability of this issue occurring increases.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Canonical token pairs can be griefed by deploying new pools with malicious admins", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "function create( address _token0, address _token1, string memory _name, string memory _symbol, uint256 _poolType, address _pauser ) external returns (address) { CronV1Pool.PoolType poolType = CronV1Pool.PoolType(_poolType); requireErrCode(_token0 != _token1, CronErrors.IDENTICAL_TOKEN_ADDRESSES); (address token0, address token1) = _token0 < _token1 ? (_token0, _token1) : (_token1, _token0); requireErrCode(token0 != address(0), CronErrors.ZERO_TOKEN_ADDRESSES); requireErrCode(getPool[token0][token1][_poolType] == address(0), CronErrors.EXISTING_POOL); address pool = address( new CronV1Pool(IERC20(_token0), IERC20(_token1), getVault(), _name, _symbol, poolType, ,! address(this), _pauser) ); //... Anyone can permissionlessly deploy a pool, with it then becoming the canonical pool for that pair of tokens. An attacker is able to pass a malicious _pauser the twamm pool, preventing the creation of a legitimate pool of the same type and tokens. This results in race conditions between altruistic and malicious pool deployers to set the admin for every token pair. 10 Malicious actors may grief the protocol by attempting to deploy token pairs with and exploiting the admin address, either deploying the pool in a paused state, effectively disabling trading for long-term swaps with the pool, pausing the pool at an unknown point in the future, setting fee and holding penalty parameters to inappropriate values, or setting illegitimate arbitrage partners and lists. This requires the factory owner to remove the admin of each pool individually and to set a new admin address, fee parameters, holding periods, pause state, and arbitrage partners in order to recover each pool to a usable condition if the griefing is successful.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Refund Computation in _withdrawLongTermSwap Contains A Risky Underflow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Nothing prevents lastVirtualOrderBlock from advancing beyond the expiry of any given long-term swap, so the unchecked subtraction here is unsafe and can underflow. Since the resulting refund value will be extremely large due to the limited number of blocks that can elapse and the typical prices and decimals of tokens, the practical consequence will be a revert due to exceeding the pool and order balances. However, this could be used to steal funds if the value could be maliciously tuned, for example via another hypothetical bug that allowed the last virtual order block or the sales rate of an order to be manipulated to an arbitrary value.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Function transferJoinEvent Permits Transfer-to-Self", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Though the error code indicates the opposite intent, this check will permit transfer-to-self (|| used instead of &&).", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "One-step owner change for factory owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The factory owner can be changed with a single transaction. As the factory owner is critical to managing the pool fees and other settings an incorrect address being set as the owner may result in unintended behaviors.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Factory owner may front run large orders in order to extract fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The factory owner may be able to front-run large trades in order to extract more fees if compromised or becomes malicious in one way or another. Similarly, pausing may also allow for skipping the execution of virtual orders before exiting.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Join Events must be explicitly transfered to recipient after transfering Balancer Pool Tokens in order to realize the full value of the tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Any user receiving LP tokens transferred to them must be explicitly transferred with a join event in order to redeem the full value of the LP tokens on exit, otherwise the address transferred to will automatically get the holding penalty when they try to exit the pool. Unless a protocol specifically implements transferJoinEvent function compatibility all LP tokens going through that protocol will be worth a fraction of their true value even after the holding period has elapsed.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Order Block Intervals(OBI) and Max Intervals are calculated with 14 second instead of 12 second block times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The CronV1Pool contract calculates both the Order Block Intervals (OBI) and the Max Intervals of the Stable/Liquid/Volatile pairs with 14 second block times. However, after the merge, 12 second block time is enforced by the Beacon Chain.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "One-step status change for pool Admins", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Admin status can be changed in a single transaction. This may result in unintended behaviour if the incorrect address is passed.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Incomplete token simulation in CronV1Pool due to missing queryJoin and queryExit functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "he CronV1Pool contract is missing the queryJoin and queryExit functions, which are significant for calculating maxAmountsIn and/or minBptOut on pool joins, and minAmountsOut and/or maxBptIn on pool exits, respectively. The ability to calculate these values is very important in order to ensure proper enforcement of slippage tolerances and mitigate the risk of sandwich attacks.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "A partner can trigger ROC update", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A partner can trigger rook update if they return rook's current list within an update.  Scenario A partner calls updateArbitrageList, the IArbitrageurList(currentList).nextList() returns rook's rook- PartnerContractAddr and gets updated, the partner calls updateArbitrageList again, so this time isRook will be true.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Approved relayer can steal cron's fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A relayer within Balancer is set per vault per address. If feeAddr will ever add a relayer within the balancer vault, the relayer can call exitPool with a recipient of their choice, and the check on line 225 will pass as the sender will still be feeAddr but the true msg.sender is the relayer.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Price Path Due To Long-Term Orders Neglected In Oracle Updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The _updateOracle() function takes its price sample as the final price after virtual order execution for whatever time period has elapsed since the last join/exit/swap. Since the price changes continuously during that interval if there are long-term orders active (unlike in Uniswap v2 where the price is constant between swaps), this is inaccurate - strictly speaking, one should integrate over the price curve as defined by LT orders to get a correct sample. The longer the interval, the greater the potential for inaccuracy.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Vulnerabilities noted from npm audit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "npm audit notes: 76 vulnerabilities (5 low, 16 moderate, 27 high, 28 critical).", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Optimization: Merge CronV1Pool.sol & VirtualOrders.sol (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A lot of needless parameter passing is done to accommodate the file barrier between CronV1Pool & VirtualOrdersLib, which is an internal library. Some parameters are actually immutable variables.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Receive sorted tokens at creation to reduce complexity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Currently, when a pool is created, within the constructor, logic is implemented to determine if the to- kens are sorted by address. A requirement that is needed for Balancer Pool creation. This logic adds unnecessary gas consumption and complexity throughout the contract as every time amounts are retrieved from balancer, the Cron Pool must check the order of the tokens and make sure that the difference between sorted (Balancer) and unsorted (Cron) token addresses is handled. An example can be seen in onJoinPool uint256 token0InU112 = amountsInU112[TOKEN0_IDX]; uint256 token1InU112 = amountsInU112[TOKEN1_IDX]; Where the amountsInU112 are retrieved from the balancer as a sorted array, index 0 == token0 and index 1 == token1, but on the Cron side, we must make sure that we retrieved the correct amount based on the tokens being sent as sorted or not when the pool was created.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Remove double reentrancy checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A number of CronV1Pool functions include reentrancy checks, however, they are only callable from a Balancer Vault function that already has a reentrancy check.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "TWAMM Formula Computation Can Be Made Correct-By-Construction and Optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The linked lines are the core calculation of TWAMM virtual order execution. They involve checked arithmetic in the form of underflow-checked subtractions; there is thus a theoretical risk that rounding error could lead to a \"freezing\" of a TWAMM pool. One of the subtractions, that for token1OutU112, is already \"correct-by- construction\", i.e. it can never underflow. The calculation of token0OutU112 can be reformulated to be explicitly safe as well; the following overall refactoring is suggested: uint256 ammEndToken0 = (token1ReserveU112 * sum0) / sum1; uint256 ammEndToken1 = (token0ReserveU112 * sum1) / sum0; token0ReserveU112 = ammEndToken0; token1ReserveU112 = ammEndToken1; token0OutU112 = sum0 - ammEndToken0; token1OutU112 = sum1 - ammEndToken1; Both output calculations are now of the form x (cid:0) (x (cid:3) y)=(y + z) for non-negative x, y , and z, allowing subtraction operations to be unchecked, which is both a gas optimization and gives confidence the calculation cannot freeze up unexpectedly due to an underflow. Replacement of divDown by / gives equivalent semantics with lower overhead. An additional advantage of this formulation is its manifest symmetry under 0 < (cid:0) > 1 interchange; this serves as a useful heuristic check on the computation, as it should possess the same symmetry as the invariant.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Gas Optimizations In Bit Packing Functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The bit packing operations are heavily used throughout the gas-critical swap code path, the opti- mization of which was flagged as high-priority by the CronFi team. Thus they were carefully reviewed not just for correctness, but also for gas optimization. L119: unnecessary & due to check on L116 L175: could hardcode clearMask L203: could hardcode clearMask L240: could hardcode clearMask L241: unnecessary & due to check on line 237 L242: unnecessary & due to check on line 238 L292: could hardcode clearMask L328: could hardcode clearMask L343: unnecessary to mask when _isWord0 == true L359: unnecessary & operations due to checks on lines 356 and 357 L372: unnecessary masking L389: could hardcode clearMask L390: unnecessary & due to check on L387 L415: could 16 hardcode clearMask L416: unnecessary & operation due to check on line 413 L437: unnecessary clearMask L438: unnecessary & due to check on line 435 L464: could hardcode clearMask L465: unnecessary & due to check on line 462 Additionally, the following code pattern appears in multiple places: requireErrCode(increment <= CONST, CronErrors.INCREMENT_TOO_LARGE); value += increment; requireErrCode(value <= CONST, CronErrors.OVERFLOW); Unless there's a particular reason to want to detect a too-large increment separately from an overflow, these patterns could all be simplified to requireErrCode(CONST - value >= increment, CronErrors.OVERFLOW); value += increment; as any increment greater than CONST will cause overflow anyway and value is always in the correct range by construction. This allows CronErrors.INCREMENT_TOO_LARGE to be removed as well.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Using extra storage slot to store two mappings of the same information", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A second storage slot is used to store a duplicate mapping of the same token pair but in reverse order. If the tokens are sorted in a getter function then the second mapping does not need to be used.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Gas optimizations within _executeVirtualOrders function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Within the _executeVirtualOrders function there are a few gas optimizations that can be applied to reduce the contract size and gas consumed while the function is called. (!(virtualOrders.lastVirtualOrderBlock < _maxBlock && _maxBlock < block.number)) Is equivalent with: (virtualOrders.lastVirtualOrderBlock >= _maxBlock || _maxBlock >= block.number) This means that this always enters if _maxBlock == block.number which will result in unnecessary gas consump- tion. If cron fee is enabled, evoMem.feeShiftU3 will have a value meaning that the check on line 1536 is obsolete. Removing that check and the retrieve from storage will save gas.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Initializing with default value is consuming unnecessary gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Every variable declaration followed by initialization with a default value is gas consuming and obso- lete. The provided line within the context is just an example.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Factory requirement can be circumvented within the constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The constructor checks if the _factory parameter is the msg.sender. This behavior was, at first, created so that only the factory would be able to deploy pools. The check on line 484 is obsolete as pools deployed via the factory, will always have msg.sender == factory address, making the _factory parameter obsolete as well.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Usability: added remove, set pool functionality to CronV1PoolFactory (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Conversations with the audit team indicated functions were needed to manage pool mappings post- creation in the event that a pool needed to be deprecated or replaced.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Virtual oracle getter--gets oracle value at block > lvob (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Through the audit process, sufficient contract space became available to add an oracle getter con- venience that returns the oracle values and timestamps. However, this leaves the problem of not being able to get the oracle price at the current block in a pool with low volume but virtual orders active.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Loss of assets due to rounding during _longTermSwap", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "When a long term swap (LT) is created, the selling rate for that LT is set based on the amount and the number of blocks that order will be traded for. uint256 lastExpiryBlock = block.number - (block.number % ORDER_BLOCK_INTERVAL); uint256 orderExpiry = ORDER_BLOCK_INTERVAL * (_orderIntervals + 1) + lastExpiryBlock; // +1 protects from div 0 ,! uint256 tradeBlocks = orderExpiry - block.number; uint256 sellingRateU112 = _amountInU112 / tradeBlocks; During the computation of the number of blocks, the order must trade for, defined as tradeBlocks, the order expiry is computed from the last expiry block based on the OBI (Order Block Interval). If tradeBlocks is big enough (it can be a max of 176102 based on the STABLE_MAX_INTERVALS ), then sellingRa- teU112 will suffer a loss due to solidity rounding down behavior. This is a manageable loss for tokens with big decimals but for tokens with low decimals, will create quite an impact. E.g. wrapped BTC has 8 decimals. the MAX_ORDER_INTERVALS can be max 176102 as per stable max intervals defined within the constants. that being said a user can lose quite a significant value of BTC: 0.00176101 This issue is marked as Informational severity as the amount lost might not be that significant. This can change in the future if the token being LTed has a big value and a small number of decimals.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Inaccuracies in Comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A number of minor inaccuracies were discovered in comments that could impact the comprehensi- bility of the code to future maintainers, integrators, and extenders. [1] bit-0 should be bit-1 [2] less than should be at most [3] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [4] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [5] on these lines unsold should be sold [6] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop 19 on line 54. [7] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop on line 111. [8] omitted should be emitted", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The Balancer protocol utilizes two types of swaps for its functionality - GIVEN_IN and GIVEN_OUT.  GIVEN_IN specifies the minimum amount of tokens a user would accept to receive from the swap.  GIVEN_OUT specifies the maximum amount of tokens a user would accept to send for the swap. However, the onSwap function of the CronV1Pool contract only accepts the IVault.SwapKind.GIVEN_IN value as the IVault.SwapKind field of the SwapRequest struct. The unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer on the Batch Swaps and the Smart Order Router functionality, as a single SwapKind is given as an argument.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "A pool's first LP will always take a minor loss on the value of their liquidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The first liquidity provider for a pool will always take a small loss on the value of their tokens deposited into the pool because 1000 balancer pool tokens are minted to the zero address on the initial deposit. As most tokens have 18 decimal places, this value would be negligible in most cases, however, for tokens with a high value and small decimals the effects may be more apparent.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "The _withdrawCronFees functions should revert if no fees to withdraw", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The _withdrawCronFees checks if there are any Cron Fees that need to be withdrawn, currently, this function does not revert in case there are no fees.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "The spent offer amounts provided to OrderFulfilled for collection of (advanced) orders is not the actual amount spent in general", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, the OrderFulfilled is called before applying fulfillments and executing transfers. The offer and consideration items have the following forms: C = (It , T , i, acurr , R, acurr ) O = (It , T , i, acurr , acurr ) Where parameter description It T i acurr R O C itemType token identifier the interpolation of startAmount and endAmount depending on the time and the fraction of the order. consideration item's recipient offer item. consideration item. The SpentItems and ReceivedItem items provided to OrderFulfilled event ignore the last component of the offer/consideration items in the above form since they are redundant. Seaport enforces that all consideration items are used. But for the endpoints in this context, we might end up with offer items with only a portion of their amounts being spent. So in the end O.acurr might not be the amount spent for this offer item, but OrderFulfilled emits O.acurr as the amount spent. This can cause discrepancies in off-chain bookkeeping by agents listening for this event. The fulfillOrder and fulfillAdvancedOrder do not have this issue, since all items are enforced to be used. These two endpoints also differ from when there are collections of (advanced) orders, in that they would emit the OrderFulfilled at the of their call before clearing the reentrancy guard.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, there are scenarios where not all offer items will be used. When not all the current amount of an offer item is used and if this offer item belongs to an order which is of either CONTRACT order type or it is restricted order (and the caller is not the zone), then the spent amount shared with either the contract offerer or zone through their respective endpoints (validateOrder for zones and ratifyOrder for contract offerers) does not reflect the actual amount spent. When Seaport is called through one of its more complex endpoints to match or fulfill orders, the offer items go through a few phases: parameter description It T i as ae acurr O itemType token identifier startAmount endAmount the interpolation of startAmount and endAmount depending on the time and the fraction of the order. offer item.  Let's assume an offer item is originally O = (It , T , i, as, ae)  In _validateOrdersAndPrepareToFulfill, O gets transformed into (It , T , i, acurr , acurr )  Then depending on whether the order is part of a match (1, 2. 3) or fulfillment (1, 2) order and there is a corresponding fulfillment data pointing at this offer item, it might transform into (It , T , i, b, acurr ) where b 2 [0, 1). For fulfilling a collection of orders b 2 {0, acurr } depending on whether the offer item gets used or not, but for match orders, it can be in the more general range of b 2 [0, 1).  And finally for restricted or CONTRACT order types before calling _assertRestrictedAdvancedOrderValidity, the offer item would be transformed into (It , T , i, acurr , acurr ). So the startAmount of an offer item goes through the following flow: as ! acurr ! b 2 [0, 1) ! acurr 7 And at the end acurr is the amount used when Seaport calls into the validateOrder of a zone or ratifyOrder of a contract offerer. acurr does not reflect the actual amount that this offer item has contributed to a combined amount used for an execution transfer.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Empty criteriaResolvers for criteria-based contract orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There is a deviation in how criteria-based items are resolved for contract orders. For contract orders which have offers with criteria, the _compareItems function checks that the contract offerer returned a corresponding non-criteria based itemType when identifierOrCriteria for the original item is 0, i.e., offering from an entire collection. Afterwards, the orderParameters.offer array is replaced by the offer array returned by the contract offerer. For other criteria-based orders such as offers with identifierOrCriteria = 0, the itemType of the order is only updated during the criteria resolution step. This means that for such offers there should be a corresponding CriteriaResolver struct. See the following test: 8 modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Replacing by `const criteriaResolvers = []` will revert const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, []), ]; const { order, orderHash, value } = await createOrder( However, in case of contract offers with identifierOrCriteria = 0, Seaport 1.2 does not expect a corresponding CriteriaResolver struct and will revert if one is provided as the itemType was updated to be the corresponding non-criteria based itemType. See advanced.spec.ts#L510 for a test case. Note: this also means that the fulfiller cannot explicitly provide the identifier when a contract order is being fulfilled. A malicious contract may use this to their advantage. For example, assume that a contract offerer in Seaport only accepts criteria-based offers. The fulfiller may first call previewOrder where the criteria is always resolved to a rare NFT, but the actual execution would return an uninteresting NFT. If such offers also required a corresponding resolver (similar behaviour as regular criteria based orders), then this could be fixed by explicitly providing the identifier--akin to a slippage check. In short, for regular criteria-based orders with identifierOrCriteria = 0 the fulfiller can pick which identifier to receive by providing a CriteriaResolver (as long as it's valid). For contract orders, fulfillers don't have this option and contracts may be able to abuse this.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Advance orders of CONTRACT order types can generate orders with less consideration items that would break the aggregation routine", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide fewer consideration items for this order. So the total number of consideration items might be less than the ones provided by the caller. But since the caller would need to provide the fulfillment data beforehand to Seaport, they might use indices that would turn to be out of range for the consideration in question after the modification applied for the contract offerer above. If this happens, the whole call will be reverted. This issue is in the same category as Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT or- der type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "For most advanced order types, we have the following check: // Read numerator and denominator from memory and place on the stack. uint256 numerator = uint256(advancedOrder.numerator); uint256 denominator = uint256(advancedOrder.denominator); // Ensure that the supplied numerator and denominator are valid. if (numerator > denominator || numerator == 0) { _revertBadFraction(); } For CONTRACT order types this check is skipped. For later calculations (calculating the current amount) Seaport uses the numerator and denominator returned by _getGeneratedOrder which as a pair it's either (1, 1) or (0, 0). advancedOrder.numerator is only used to skip certain operations in some loops when it is 0:  Skip applying criteria resolvers. 10  Skip aggregating the amount for executions.  Skip the final validity check. Skipping the above operations would make sense. But when for an advancedOrder with CONTRACT order type _get- GeneratedOrder returns (h, 1, 1) and advancedOrder.numerator == 0, we would skip applying criteria resolvers, aggregating the amounts from offer or consideration amounts for this order and skip the final validity check that would call into the ratifyOrder endpoint of the offerer. But emiting the following OrderFulfilled will not be skipped, even though this advancedOrder will not be used. // Emit an OrderFulfilled event. _emitOrderFulfilledEvent( orderHash, orderParameters.offerer, orderParameters.zone, recipient, orderParameters.offer, orderParameters.consideration ); This can create discrepancies between what happens on chain and what off-chain agents index/record.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Calls to PausableZone's executeMatchAdvancedOrders and executeMatchOrders would revert if un- used native tokens would need to be returned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In match (advanced) orders, one can provide native tokens as offer and consideration items. So a PausableZone would need to provide msg.value to call the corresponding Seaport endpoints. There are a few scenarios where not all the msg.value native tokens amount provided to the Seaport marketplace will be used: 1. Rounding errors in calculating the current amount of offer or consideration items. The zone can prevent send- ing extra native tokens to Seaport by pre-calculating these values and making sure to have its transaction to be included in the specific block that these values were calculated for (this is important when the start and end amount of an item are not equal). 2. The zone (un)intentionally sends more native tokens that it is necessary to Seaport. 3. The (advanced) orders sent for matching in Seaport include order type of CONTRACT offerer order and the of- ferer contract provides different amount for at least one item that would eventually make the whole transaction not use the full amount of msg.value provided to it. In all these cases, since PausableZone does not have a receive or fallback endpoint to accept native tokens, when Seaport tries to send back the unsued native token amount the transaction may revert. PausableZone not accepting native tokens: $ export CODE=$(jq -r '.deployedBytecode' artifacts/contracts/zones/PausableZone.sol/PausableZone.json | tr -d '\\n') ,! $ evm --code $CODE --value 1 --prestate genesis.json --sender ,! 0xb4d0000000000000000000000000000000000000 --nomemory=false --debug run $ evm --input $(echo $CODE | head -c 44 - | sed -E s/0x//) disasm 6080806040526004908136101561001557600080fd 00000: PUSH1 0x80 00002: DUP1 00003: PUSH1 0x40 00005: MSTORE 00006: PUSH1 0x04 00008: SWAP1 00009: DUP2 0000a: CALLDATASIZE 0000b: LT 0000c: ISZERO 0000d: PUSH2 0x0015 00010: JUMPI 00011: PUSH1 0x00 00013: DUP1 00014: REVERT trace of evm ... --debug run error: execution reverted #### TRACE #### PUSH1 pc=00000000 gas=4700000 cost=3 DUP1 pc=00000002 gas=4699997 cost=3 12 Stack: 00000000 0x80 PUSH1 Stack: 00000000 00000001 MSTORE Stack: 00000000 00000001 00000002 PUSH1 Stack: 00000000 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 SWAP1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 DUP2 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000003 gas=4699994 cost=3 pc=00000005 gas=4699991 cost=12 pc=00000006 gas=4699979 cost=3 0x80 0x80 0x40 0x80 0x80 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000008 gas=4699976 cost=3 0x4 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000009 gas=4699973 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000010 gas=4699970 cost=2 0x4 0x80 0x4 CALLDATASIZE Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| 13 LT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 ISZERO Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH2 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 JUMPI Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 pc=00000011 gas=4699968 cost=3 0x0 0x4 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000012 gas=4699965 cost=3 0x1 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000013 gas=4699962 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000016 gas=4699959 cost=10 0x15 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000017 gas=4699949 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 14 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| DUP1 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 REVERT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000019 gas=4699946 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000020 gas=4699943 cost=0 0x0 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| #### LOGS #### genesis.json: { \"gasLimit\": \"4700000\", \"difficulty\": \"1\", \"alloc\": { \"0xb4d0000000000000000000000000000000000000\": { \"balance\": \"10000000000000000000000000\", \"code\": \"\", \"storage\": {} } } } // file: test/zone.spec.ts ... it(\"Fulfills an order with executeMatchAdvancedOrders with NATIVE Consideration Item\", async () => { const pausableZoneControllerFactory = await ethers.getContractFactory( \"PausableZoneController\", owner ); const pausableZoneController = await pausableZoneControllerFactory.deploy( owner.address ); // Deploy pausable zone const zoneAddr = await createZone(pausableZoneController); 15 // Mint NFTs for use in orders const nftId = await mintAndApprove721(seller, marketplaceContract.address); // Define orders const offerOne = [ getTestItem721(nftId, toBN(1), toBN(1), undefined, testERC721.address), ]; const considerationOne = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), seller.address ), ]; const { order: orderOne, orderHash: orderHashOne } = await createOrder( seller, zoneAddr, offerOne, considerationOne, 2 ); const offerTwo = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), undefined ), ]; const considerationTwo = [ getTestItem721( nftId, toBN(1), toBN(1), buyer.address, testERC721.address ), ]; const { order: orderTwo, orderHash: orderHashTwo } = await createOrder( buyer, zoneAddr, offerTwo, considerationTwo, 2 ); const fulfillments = [ [[[0, 0]], [[1, 0]]], [[[1, 0]], [[0, 0]]], ].map(([offerArr, considerationArr]) => toFulfillment(offerArr, considerationArr) ); // Perform the match advanced orders with zone const tx = await pausableZoneController .connect(owner) 16 .executeMatchAdvancedOrders( zoneAddr, marketplaceContract.address, [orderOne, orderTwo], [], fulfillments, { value: parseEther(\"0.01\").add(1) } // the extra 1 wei reverts the tx ); // Decode all events and get the order hashes const orderFulfilledEvents = await decodeEvents(tx, [ { eventName: \"OrderFulfilled\", contract: marketplaceContract }, ]); expect(orderFulfilledEvents.length).to.equal(fulfillments.length); // Check that the actual order hashes match those from the events, in order const actualOrderHashes = [orderHashOne, orderHashTwo]; orderFulfilledEvents.forEach((orderFulfilledEvent, i) => expect(orderFulfilledEvent.data.orderHash).to.be.equal( actualOrderHashes[i] ) ); }); ... This bug also applies to Seaport 1.1 and PausableZone (0x004C00500000aD104D7DBd00e3ae0A5C00560C00)", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "ABI decoding for bytes: memory can be corrupted by maliciously constructing the calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the code snippet below, size can be made 0 by maliciously crafting the calldata. In this case, the free memory is not incremented. assembly { mPtrLength := mload(0x40) let size := and( add( and(calldataload(cdPtrLength), OffsetOrLengthMask), AlmostTwoWords ), OnlyFullWordMask ) calldatacopy(mPtrLength, cdPtrLength, size) mstore(0x40, add(mPtrLength, size)) } This has two different consequences: 1. If the memory offset mPtrLength is immediately used then junk values at that memory location can be interpreted as the decoded bytes type. In the case of Seaport 1.2, the likelihood of the current free memory pointing to junk value is low. So, this case has low severity. 17 2. The consequent memory allocation will also use the value mPtrLength to store data in memory. This can lead to corrupting the initial memory data. In the worst case, the next allocation can be tuned so that the first bytes data can be any arbitrary data. To make the size calculation return 0: 1. Find a function call which has bytes as a (nested) parameter. 2. Modify the calldata field where the length of the above byte is stored to the new length 0xffffe0. 3. The calculation will now return size = 0. Note: there is an additional requirement that this bytes type should be inside a dynamic struct. Otherwise, for example, in case of function foo(bytes calldata signature) , the compiler will insert a check that calldata- size is big enough to fit signature.length. Since the value 0xffffe0 is too big to be fit into calldata, such an attack is impractical. However, for bytes type inside a dynamic type, for example in function foo(bytes[] calldata signature), this check is skipped by solc (likely because it's expensive). For a practical exploit we need to look for such function. In case of Seaport 1.2 this could be the matchAdvancedOrders(AdvancedOrder[] calldata orders, ...) function. The struct AdvancedOrder has a nested parameter bytes signature as well as bytes extraData. In the above exploit one would be able to maliciously modify the calldata in such a way that Seaport would interpret the data in extraData as the signature. Here is a proof of concept for a simplified case that showcases injecting an arbitrary value into a decoded bytes. As for severity, even though interpreting calldata differently may not fundamentally break the protocol, an attacker with enough effort may be able to use this for subtle phishing attacks or as a precursor to other attacks.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport receives a collection of advanced orders to match or fulfill, if one of the orders has a CONTRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. genera- teOrder(...) can provide new consideration item recipients for this order. These new recipients are going to be used for this order from this point on. In _getGeneratedOrder, there is no comparison between old or new consideration recipients. The provided new recipients can create an issue when aggregating consideration items. Since the fulfillment data is provided beforehand by the caller of the Seaport endpoint, the caller might have provided fulfillment aggregation data that would have aggregated/combined one of the consideration items of this changed advance order with another consideration item. But the aggregation had taken into consideration the original recipient of the order in question. Multiple consideration items can only be aggregated if they share the same itemType, token, identi- fier, and recipient (ref). The new recipients provided by the contract offerer can break this invariant and in turn cause a revert.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "CriteriaResolvers.criteriaProof is not validated in the identifierOrCriteria == 0 case", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the case of identifierOrCriteria == 0, the criteria resolver completely skips any validations on the Merkle proof and in particular is missing the validation that CriteriaResolvers.criteriaProof.length == 0. Note: This is also present in Seaport 1.1 and may be a known issue. Proof of concept: modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Add a junk criteria proof and the test still passes const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, ,! [\"0xdead000000000000000000000000000000000000000000000000000000000000\"]), ]; const { order, orderHash, value } = await createOrder(", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "Calls to TypehashDirectory will be successful", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "TypehashDirectory's deployed bytecode starts with 00 which corresponds to STOP opcode (SSTORE2 also uses this pattern). This choice for the 1st bytecode causes accidental calls to the contract to succeed silently.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "_isValidBulkOrderSize does not perform the signature length validation correctly.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In _isValidBulkOrderSize the signature's length validation is performed as follows: let length := mload(signature) validLength := and( lt(length, BulkOrderProof_excessSize), lt(and(sub(length, BulkOrderProof_minSize), AlmostOneWord), 2) ) The sub opcode in the above snippet wraps around. If this was the correct formula then it would actually simplify to: lt(and(sub(length, 3), AlmostOneWord), 2) The simplified and the current version would allow length to also be 3, 4, 35, 36, 67, 68 but _isValidBulkOrder- Size actually needs to check that length ( l ) has the following form: where x 2 f0, 1g and y 2 f1, 2, (cid:1) (cid:1) (cid:1) , 24g ( y represents the height/depth of the bulk order).", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the contract offerer through ratifyOrder would be smaller than the actual stored nonce", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the con- tract offerer through ratifyOrder would be smaller than the actual stored nonce: // Write contractNonce to calldata dstHead.offset(ratifyOrder_contractNonce_offset).write( uint96(uint256(orderHash)) ); This is due to the way the contractNonce and the offerer's address are mixed in the orderHash: assembly { orderHash := or(contractNonce, shl(0x60, offerer)) }", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "abi_decode_bytes does not mask the copied data length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When abi_decode_bytes decodes bytes, it does not mask the copied length of the data in memory (other places where the length is masked by OffsetOrLengthMask).", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "OrderHash in the context of contract orders need not refer to a unique order", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In Seaport 1.1 and in Seaport 1.2 for non-contract orders, order hashes have a unique correspon- dence with the order, i.e., it can be used to identify the status of an order on-chain and track it. However, in case of contract orders, this is not the case. It is simply the current nonce of the offerer, combined with the address. This cannot be used to uniquely track an order on-chain. uint256 contractNonce; unchecked { contractNonce = _contractNonces[offerer]++; } assembly { orderHash := or(contractNonce, shl(0x60, offerer)) } Here are some example scenarios where this can be problematic: Scenario 1: A reverted contract order and the adjacent succeeding contract order will have the same order hash, regardless of whether they correspond to the same order. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Assume that this transaction failed because enough gas was not provided for the generateOrder call. This tx would revert with a custom error InvalidContrac- tOrder, generated from OrderValidator.sol#L391. 22 2. Consider Bob calling fulfilledAdvancedOrder for a different contract order with offerer = X, same smart contract offerer. OrderFulfiller.sol#L124 This order will succeed and emit the OrderFulfilled event the from In the above scenario, there are two different orders, one that reverted on-chain and the other that succeeded, both having the same orderHash despite the orders only sharing the same contract offerer--the other parameters can be completely arbitrary. Scenario 2: Contract order hashes computed off-chain can be misleading. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Alice computed the orderHash of their order off-chain by simulating the transaction, sends the transaction and polls the OrderFulfilled event with the same orderHash to know if the order has been fulfilled. 2. Consider Bob calling fulfilledAdvancedOrder for any contract order with offerer = X, the same smart contract offerer. 3. Bob's transaction gets included first. An OrderFulfilled event is emitted, with the orderHash to be the same hash that Alice computed off-chain! Alice may believe that their order succeeded. for non-contract Orders, the above approach would be valid, i.e., one may generate and sign an order, Note: compute the order hash of an order off-chain and poll for an OrderFulfilled with the order hash to know that it was fulfilled. Note: even though there is an easier way to track if the order succeeded in these cases, in the general case, Alice or Bob need not be the one executing the orders on-chain. And an off-chain agent may send misleading notifications to either parties that their order succeeded due to this quirk with contract order hashes.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "When _contractNonces[offerer] gets updated no event is emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When _contractNonces[offerer] gets updated no event is emitted. This is in contrast to when a counter is updated. One might be able to extract the _contractNonces[offerer] (if it doesn't overflow 12 bytes to enter into the offerer region in the orderhash) from a later event when OrderFulfilled gets emited. OrderFulfilled only gets emitted for an order of CONTRACT type if the generateOrder(...)'s return data satisffies all the constraints.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "In general a contract offerer or a zone cannot draw a conclusion accurately based on the spent offer amounts or received consideration amounts shared with them post-trasnfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When one calls one of the Seaport endpoints that fulfills or matches a collection of (advanced) orders, the used offer or consideration items will go through different modification steps in the memory. In particular, the startAmount a of these items is an important parameter to inspect: a ! a0 ! b ! a0 a : original startAmount parameter shared to Seaport by the caller encoded in the memory. a0 : the interpolated value and for orders of CONTRACT order type it is the value returned by the contract offerer (interpolation does not have an effect in this case since the startAmount and endAmount are enforced to be equal). b : must be 0 for used consideration items, otherwise the call would revert. For offer items, it can be in [0, 1) (See The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general). a0 : is the final amount shared by Seaport to either a zone for restricted orders and a contract offerer for CONTRACT order types.  Offer Items For offer items, perhaps the zone or the contract offerer would like to check that the offerer has spent a maxi- mum a0 of that specific offer item. For the case of restricted orders where the zone's validateOrder(...) will be called, the offerer might end up spending more than a0 amount of a specific token with the same identifier if the collection of orders includes:  A mix of open and restricted orders.  Multiple zones for the same offerer, offering the same token with the same identifier.  Multiple orders using the same zone. In this case, the zone might not have a sense of the orders of the transfers or which orders are included in the transaction in question (unless the contexts used by the zone enforces the exact ordering and number of items that can be matched/fulfilled in the same transaction). Note the order of transfers can be manipulated/engineered by constructing specific fulfillment data. Given a fulfillment data to combine/aggregate orders, there could be permutations of it that create different ordering of the executions.  An order with an actor (a consideration recipient, contract offerer, weird token, ...) that has approval to transfer this specific offer item for the offerer in question. And when Seaport calls into (NATIVE, ERC1155 token transfers, ...) this actor, the actor would transfer the token to a different address than the offerer. There also is a special case where an order with the same offer item token and identifier is signed on a different instance of Seaport (1.0, 1.1, 1.2, ..., or other non-official versions) which an actor (a consideration recipient, con- tract offerer, weird token, ...) can cross-call into (related Cross-Seaport re-entrancy with the stateful validateOrder call). The above issue can be avoided if the offerer makes sure to not sign different transactions across different or the same instances of Seaport which 1. Share the same offer type, offer token, and offer identifier, 2. but differ in a mix of zone, and order type 24 3. can be active at a shared timestamp And/or the offerer does not give untrusted parties their token approvals. A similar issue can arise for a contract offerer if they use a mix of signed orders of non-CONTRACT order type and CONTRACT order types.  Consideration Items For consideration items, perhaps the zone or the contract offerer would like to check that the recipient of each consideration item has received a minimum of a0 of that specific consideration item. This case also is similar to the offer items issues above when a mix of orders has been used.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "Cross-Seaport re-entrancy with the stateful validateOrder call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The re-entrancy check in Seaport 1.2 will prevent the Zone from interacting with Seaport 1.2 again. However, an interesting scenario would happen when if the conduit has open channels to both Seaport 1.1 and Seaport 1.2 (or different deployments/forks of Seaport 1.2). This can lead to cross Seaport re-entrancy. This is not immediately problematic as Zones have limited functionality currently. But since Zones can be as flexible as possible, Zones need to be careful if they can interact with multiple versions of Seaport. Note: for Seaport 1.1's zone, the check _assertRestrictedBasicOrderValidity happens before the transfers, and it's also a staticcall. In the future, Seaport 1.3 could also have the same zone interaction, i.e., stateful calls to zones allowing for complex cross-Seaport re-entrancy between 1.2 and 1.3. Note: also see getOrderStatus and getContractOffererNonce are prone to view reentrancy for concerns around view-only re-entrancy.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "getOrderStatus and getContractOffererNonce are prone to view reentrancy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Nonces[offerer] gets updated if there is a mix of contract offerer orders and partial orders are used, Seaport would call into the offerer contracts (let's call one of these offerer contracts X ). In turn X can be a contract that would call into other contracts (let's call them Y ) that take into consideration _orderStatus[orderHash] or _contractNonces[offerer] in their codebase by calling getOrderStatus or getContractOffererNonce The values for _orderStatus[orderHash] or _contractNonces[offerer] might get updated after Y seeks those from Seaport due to for example multiple partial orders with the same orderHash or multiple offerer contract orders using the same offerer. Therefore Y would only take into consideration the mid-flight values and not the final ones after the whole transaction with Seaport is completed.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "The size calculation can be incorrect for large numbers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The maximum value of memory offset is defined in PointerLibraries.sol#L22 as OffsetOr- LengthMask = 0xffffffff, i.e., 232 (cid:0) 1. However, the mask OnlyFullWordMask = 0xffffe0; is defined to be a 24-bit number. Assume that the length of the bytes type where src points is 0xffffe0, then the following piece of code incorrectly computes the size as 0. function abi_encode_bytes( MemoryPointer src, MemoryPointer dst ) internal view returns (uint256 size) { unchecked { size = ((src.readUint256() & OffsetOrLengthMask) + AlmostTwoWords) & OnlyFullWordMask; ... This is because the constant OnlyFullWordMask does not have the two higher order bytes set (as a 32-bit type). Note: in practice, it can be difficult to construct bytes of length 0xffffe0 due to upper bound defined by the block gas limit. However, this length is still below Seaport's OffsetOrLengthMask, and therefore may be able to evade many checks. 26", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "_prepareBasicFulfillmentFromCalldata expands memory more than it's needed by 4 extra words", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In _prepareBasicFulfillmentFromCalldata , we have: // Update the free memory pointer so that event data is persisted. mstore(0x40, add(0x80, add(eventDataPtr, dataSize))) OrderFulfilled's event data is stored in the memory in the region [eventDataPtr, eventDataPtr + dataSize). It's important to note that eventDataPtr is an absolute memory pointer and not a relative one. So the above 4 words, 0x80, in the snippet are extra. example, For in test/basic.spec.ts the Seaport memory profile at tract.connect(buyer).fulfillBasicOrder(basicOrderParameters, {value,}) looks like: \"ERC721 <=> ETH (basic, minimal and verified on-chain)\" case the call of marketplaceCon- the end of test the in 28 0x000 23b872dd000000000000000000000000f372379f3c48ad9994b46f36f879234a ; transferFrom.selector(from, to, id) ,! 0x020 27b4556100000000000000000000000016c53175c34f67c1d4dd0878435964c1 ; ... 0x040 0000000000000000000000000000000000000000000000000000000000000440 ; free memory pointer 0x060 0000000000000000000000000000000000000000000000000000000000000000 ; ZERO slot 0x080 fa445660b7e21515a59617fcd68910b487aa5808b8abda3d78bc85df364b2c2f ; orderTypeHash 0x0a0 000000000000000000000000f372379f3c48ad9994b46f36f879234a27b45561 ; offerer 0x0c0 0000000000000000000000000000000000000000000000000000000000000000 ; zone 0x0e0 78d24b64b38e96956003ddebb880ec8c1d01f333f5a4bfba07d65d5c550a3755 ; h(ho) 0x100 81c946a4f4982cb7ed0c258f32da6098760f98eaf6895d9ebbd8f9beccb293e7 ; h(hc, ha[0], ..., ha[n]) 0x120 0000000000000000000000000000000000000000000000000000000000000000 ; orderType 0x140 0000000000000000000000000000000000000000000000000000000000000000 ; startTime 0x160 000000000000000000000000000000000000ff00000000000000000000000000 ; endTime 0x180 8f1d378d2acd9d4f5883b3b9e85385cf909e7ab825b84f5a6eba28c31ea5246a ; zoneHash > orderHash 0x1a0 00000000000000000000000016c53175c34f67c1d4dd0878435964c1c9b70db7 ; salt > fulfiller 0x1c0 0000000000000000000000000000000000000000000000000000000000000080 ; offererConduitKey > offerer array head ,! 0x1e0 0000000000000000000000000000000000000000000000000000000000000120 ; counter[offerer] > consideration array head ,! 0x200 0000000000000000000000000000000000000000000000000000000000000001 ; h[4]? > offer.length 0x220 0000000000000000000000000000000000000000000000000000000000000002 ; h[...]? > offer.itemType 0x240 000000000000000000000000c67947dc8d7fd0c2f25264f9b9313689a4ac39aa ; > offer.token 0x260 00000000000000000000000000000000c02c1411443be3c204092b54976260b9 ; > offer.identifierOrCriteria 0x280 0000000000000000000000000000000000000000000000000000000000000001 ; > offer's current interpolated amount ,! 0x2a0 0000000000000000000000000000000000000000000000000000000000000001 ; > totalConsiderationRecipients + 1 ,! 0x2c0 0000000000000000000000000000000000000000000000000000000000000000 ; > receivedItemType 0x2e0 0000000000000000000000000000000000000000000000000000000000000000 ; > consideration.token (NATIVE) 0x300 0000000000000000000000000000000000000000000000000000000000000000 ; > consideration.identifierOrCriteria ,! 0x320 0000000000000000000000000000000000000000000000000000000000000001 ; > consideration's current interpolated amount ,! 0x340 000000000000000000000000f372379f3c48ad9994b46f36f879234a27b45561 ; > offerer 0x360 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x380 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3a0 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3c0 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3e0 0000000000000000000000000000000000000000000000000000000000000040 ; sig.length 0x400 26aa4a333d4b615af662e63ce7006883f678068b8dc36f53f70aa79c28f2032c ; sig[ 0:31] 0x420 f640366430611c54bafd13314285f7139c85d69f423794f47ee088fc6bfbf43f ; sig[32:63] 0x440 0000000000000000000000000000000000000000000000000000000000000001 ; fulfilled = 1; // returns ,! (bool fulfilled) Notice that 4 unused memory slots.  Transaction Trace This is also a good example to see that certain memory slots that previously held values like zoneHash, salt, ... have been overwritten to due to the small number of consideration items (this actually happens inside _- prepareBasicFulfillmentFromCalldata).", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "TypehashDirectory's constructor code can be optimized.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "TypehashDirectory's deployed bytecode in its current form is: 00 3ca2711d29384747a8f61d60aad3c450405f7aaff5613541dee28df2d6986d32 ; h_00 bf8e29b89f29ed9b529c154a63038ffca562f8d7cd1e2545dda53a1b582dde30 ; h_01 53c6f6856e13104584dd0797ca2b2779202dc2597c6066a42e0d8fe990b0024d ; h_02 a02eb7ff164c884e5e2c336dc85f81c6a93329d8e9adf214b32729b894de2af1 ; h_03 39c9d33c18e050dda0aeb9a8086fb16fc12d5d64536780e1da7405a800b0b9f6 ; h_04 1c19f71958cdd8f081b4c31f7caf5c010b29d12950be2fa1c95070dc47e30b55 ; h_05 ca74fab2fece9a1d58234a274220ad05ca096a92ef6a1ca1750b9d90c948955c ; h_06 7ff98d9d4e55d876c5cfac10b43c04039522f3ddfb0ea9bfe70c68cfb5c7cc14 ; h_07 bed7be92d41c56f9e59ac7a6272185299b815ddfabc3f25deb51fe55fe2f9e8a ; h_08 d1d97d1ef5eaa37a4ee5fbf234e6f6d64eb511eb562221cd7edfbdde0848da05 ; h_09 896c3f349c4da741c19b37fec49ed2e44d738e775a21d9c9860a69d67a3dae53 ; h_10 bb98d87cc12922b83759626c5f07d72266da9702d19ffad6a514c73a89002f5f ; h_11 e6ae19322608dd1f8a8d56aab48ed9c28be489b689f4b6c91268563efc85f20e ; h_12 6b5b04cbae4fcb1a9d78e7b2dfc51a36933d023cf6e347e03d517b472a852590 ; h_13 d1eb68309202b7106b891e109739dbbd334a1817fe5d6202c939e75cf5e35ca9 ; h_14 1da3eed3ecef6ebaa6e5023c057ec2c75150693fd0dac5c90f4a142f9879fde8 ; h_15 eee9a1392aa395c7002308119a58f2582777a75e54e0c1d5d5437bd2e8bf6222 ; h_16 c3939feff011e53ab8c35ca3370aad54c5df1fc2938cd62543174fa6e7d85877 ; h_17 0efca7572ac20f5ae84db0e2940674f7eca0a4726fa1060ffc2d18cef54b203d ; h_18 5a4f867d3d458dabecad65f6201ceeaba0096df2d0c491cc32e6ea4e64350017 ; h_19 80987079d291feebf21c2230e69add0f283cee0b8be492ca8050b4185a2ff719 ; h_20 3bd8cff538aba49a9c374c806d277181e9651624b3e31111bc0624574f8bca1d ; h_21 5d6a3f098a0bc373f808c619b1bb4028208721b3c4f8d6bc8a874d659814eb76 ; h_22 1d51df90cba8de7637ca3e8fe1e3511d1dc2f23487d05dbdecb781860c21ac1c ; h_23 for height 24", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "ConsiderationItem.recipient's absolute memory offset can be cached and reused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "ConsiderationItem.recipient's absolute offset is calculated twice in the above context.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "currentAmount can potentially be reused when storing this value in memory in _validateOrdersAnd- PrepareToFulfill", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "We have considerationItem.startAmount = currentAmount; // 1 ... mload( // 2 add( considerationItem, ReceivedItem_amount_offset ) ) From 1 where considerationItem.startAmount is assigned till 2 its value is not modifed.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "Information packed in BasicOrderType and how receivedItemType and offeredItemType are derived", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Currently the way information is packed and unpacked in/from BasicOrderType is inefficient. Basi- cOrderType is only used for BasicOrderParameters and when unpacking to give an idea how diffferent parameters are packed into this field.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "invalidNativeOfferItemErrorBuffer calculation can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "We have: func sig ------------------------------------------------------------------------------ 0b10101000000101110100010 00 0000100 0b01010101100101000100101 00 1000010 0b11101101100110001010010 10 1110100 0b10000111001000000001101 10 1000001 ^ 9th bit matchOrders matchAdvancedOrders fulfillAvailableOrders fulfillAvailableAdvancedOrders", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "When accessing or writing to memory the value of an enum for a struct field, the enum's validation is performed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When accessing or writing to memory the value of an enum type for a struct field, the enum's validation is performed: enum Foo { f1, f2, ... fn } struct boo { Foo foo; ... } boo memory b; P(b.foo); // <--- validation will be performed to check whether the value of `b.foo` is out of range This would apply to OrderComponents.orderType, OrderParameters.orderType, CriteriaResolver.side, ReceivedItem.itemType, OfferItem.itemType, BasicOrderParameters.basicOrderType. ConsiderationItem.itemType, SpentItem.itemType,", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "The zero memory slot can be used when supplying no criteria to fulfillOrder, fulfillAvailable- Orders, and matchOrders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When the external functions in this context are called, no criteria is passed to _validateAndFulfil- lAdvancedOrder, _fulfillAvailableAdvancedOrders, or _matchAdvancedOrders: new CriteriaResolver[](0), // No criteria resolvers supplied. When this gets compiled into YUL, the compiler updates the free memory slot by a word and performs an out of range and overflow check for this value: 34 function allocate_memory_<ID>() -> memPtr { memPtr := mload(64) let newFreePtr := add(memPtr, 32) if or(gt(newFreePtr, 0xffffffffffffffff), lt(newFreePtr, memPtr)) { panic_error_0x41() } mstore(64, newFreePtr) }", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "matchOrders, matchAdvancedOrders, fulfillAvailableAdvancedOrders, fulfillAvailableOrders re- turns executions which is cleaned and validator by the compiler", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Currently, the return values of matchOrders, matchAdvancedOrders, fulfillAvailableAdvance- dOrders, fulfillAvailableOrders are cleaned and validator by the compiler.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "abi.encodePacked is used when only bytes/string concatenation is needed.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the context above, one is using abi.encodePacked like the following: 35 bytes memory B = abi.encodePacked( \"<B1>\", \"<B2>\", ... \"<Bn>\" ); For each substring, this causes the compiler to use an mstore (if the substring occupies more than 32 bytes, it will use the least amount of mstores which is the ceiling of the length of substring divided by 32), even though multiple substrings can be combined to fill in one memory slot and thus only use 1 mstore for those.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "solc ABI encoder is used when OrderFulfilled is emitted in _emitOrderFulfilledEvent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "solc's ABI encoder is used when OrderFulfilled is emitted in _emitOrderFulfilledEvent. That means all the parameters are cleaned and validated before they are provided to log3.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "The use of identity precompile to copy memory need not be optimal across chains", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The PointerLibraries contract uses a staticcall to identity precompile, i.e., address 4 to copy memory--poor man's memcpy. This is used as a cheaper alternative to copy 32-byte chunks of memory using mstore(...) in a for-loop. However, the gas efficiency of the identity precompile relies on the version of the EVM on the underlying chain. The base call cost for precompiles before Berlin hardfork was 700 (from Tangerine Wistle), and after Berlin, this was reduced to 100 (for warm accounts and precompiles). Many EVM compatible L1s, and even L2s are on old EVM versions. And using the identity precompile would be more expensive than doing mstores(...).", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "Use the zero memory slot for allocating empty data", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In cases where an empty data needs to be allocated, one can use the zero slot. This can also be used as initial values for offer and consideration in abi_decode_generateOrder_returndata.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "Some address fields are masked even though the ConsiderationDecoder wanted to skip this mask- ing", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When a field of address type from a struct in memory is used, the compiler masks (also: 2, 3) it. struct A { address addr; } A memory a; // P is either a statement or a function call // when compiled --> and(mload(a_addr_pos), 0xffffffffffffffffffffffffffffffffffffffff) P(a.addr); Also the compiler is making use of function cleanup_address(value) -> cleaned { cleaned := and(value, 0xffffffffffffffffffffffffffffffffffffffff) } function abi_encode_address(value, pos) { mstore(pos, and(value, 0xffffffffffffffffffffffffffffffffffffffff)) } in a few places", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "div(x, (1<<n)) can be transformed into shr(n, x)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The above context, one is dividing a number by a constant which is power of 2: div(x, c) // where c = 1 << n One can perform the same operation using shr which cost less gas.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "Use fallback() to circumvent Solidity's dispatcher mechanism", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Among other things, the optimization steps are adding extra byte codes that are unnecessary for the dispatching mechanism. For example the Expression Simplifer is transforming the following calldata size comparisons: // slt(sub(calldatasize(), 4), X) push1 0x4 calldatasize sub slt into: // slt(add(calldatasize(), 0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc), X) push32 0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc calldatasize add slt And this happens for each exposed endpoint. This particular optimization rule is helpful if one could reorder and combine the constant value with another one ( A + (X (cid:0) B) ! (A (cid:0) B) + X , here A, B are constants and X is a variable ). But in this particular instance, the dispatcher does not perform better or worse in regards to the runtime code gas (it stays the same) but the optimization grows the bytecode size.  Note: The final bytecode depends on the options provided to solc. For the above finding, the default hardhat settings is used without the NO_SPECIALIZER flag.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "The arithmetic in _validateOrderAndUpdateStatus can be simplified/optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "orderStatus.numerator and orderStatus.denominator contains multiple nested if/else blocks and for certain conditions/paths extra operations are performed. advancedOrder.numerator, arithmetic involving The variable description na advancedOrder.numerator 46 variable description da ns ds advancedOrder.denominator orderStatus.numerator orderStatus.denominator Depending on the case, the final outputs need to be:  Case 1. ds = 0 In this case na, da will be unmodified (besides the constraint checks)  Case 2. ds 6= 0, da = 1 In this case the remaining of the order will be filled and we would have (na, ns, da, ds) = (na, na, da, da) (na, ns, da, ds) = (ds (cid:0) ns, ds, ds, ds) Note that the invariant d (cid:21) n for new fractions and the combined ones is always guaranteed and so ds (cid:0) ns would not underflow.  Case 3. ds 6= 0, da 6= 1, da = ds Below (cid:15) = (na + ns > ds)(na + ns (cid:0) ds) is choosen so that order would not be overfilled. The parameters used in calculating (cid:15) are taken before they have been updated.  Case 4. ds 6= 0, da 6= 1, da 6= ds (na, ns, da, ds) = (na (cid:0) (cid:15), na + ns (cid:0) (cid:15), ds, ds) Below (cid:15) = (nads + nsda > dads)(nads + nsda (cid:0) dads) is choosen so that order would not be overfilled. And in case the new values go beyond 120 bits, G = gcd(nads (cid:0) (cid:15), nads + nsda (cid:0) (cid:15), dads), otherwise G will be 1. The parameters used in calculating (cid:15), G are taken before they have been updated. (na, ns, da, ds) = 1 G (nads (cid:0) (cid:15), nads + nsda (cid:0) (cid:15), dads, dads) If one of the updated values occupies more than 120 bits, the call will be reverted.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "The magic return value checks can be made stricter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The magic return value check for ZoneInteraction can be made stricter. 1. It does not check the lower 28 bytes of the return value. 2. It does not check if extcodesize() of the zone is non-zero. In particular, for the identity precompile, the magic check would pass. This is, however, a general issue with the pattern where magic values are the same as the function selector and not specific to the Zone.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Resolving additional offer items supplied by contract orders with criteria can be impractical", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Contract orders can supply additional offer amounts when the order is executed. However, if they supply extra offer items with criteria, on the fly, the fulfiller won't be able to supply the necessary criteria resolvers (the correct Merkle proofs). This can lead to flaky orders that are impractical to fulfill.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Use of confusing named constant SpentItem_size in a function that deals with only ReceivedItem", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The named constant SpentItem_size is used in the function copyReceivedItemsAsConsidera- tionItems, even though the context has nothing to do with SpentItem.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "The ABI-decoding of generateOrder returndata does not have sufficient checks to prevent out of bounds returndata reads", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There was some attempt to avoid out of bounds returndata access in the ConsiderationDecoder. However, the two returndatacopy(...) in ConsiderationDecoder.sol#L456-L461 can still lead to out of bounds access and therefore may revert. Assume that code reaches the line ConsiderationDecoder.sol#L456. We have the following constraints 1. returndatasize >= 4 * 32: ConsiderationDecoder.sol#L428 2. offsetOffer <= returndatasize: ConsiderationDecoder.sol#L444 3. offsetConsideration <= returndatasize: ConsiderationDecoder.sol#L445 If we pick a returndata that satisfies 1 and let offsetOffer == offsetConsideration == returndatasize, all the constraints are true. But the returndatacopy would be revert due to an out-of-bounds read. Note: High-level Solidity avoids reading from out of bounds returndata. This is usually done by checking if re- turndatasize() is large enough for static data types and always doing returndatacopy of the form returndata- copy(x, 0, returndatasize()).", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Consider renaming writeBytes to writeBytes32", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The function name writeBytes is not accurate in this context.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Missing test case for criteria-based contract orders and identifierOrCriteria != 0 case", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The only test case for criteria-based contract orders in advanced.spec.ts#L434. This tests the case for identifierOrCriteria == 0. For the other case, identifierOrCriteria != 0 tests are missing.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "NatSpec comment for conduitKey in bulkTransfer() says \"optional\" instead of \"mandatory\"", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The NatSpec comment says that conduitKey is optional but there is a check making sure that this value is always supplied.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Comparing the magic values returned by different contracts are inconsistent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In ZoneInteraction's _callAndCheckStatus we perform the following comparison for the returned magic value: let magic := shr(224, mload(callData)) magicMatch := eq(magic, shr(224, mload(0))) But the returned magic value comparison in _assertValidSignature without truncating the returned value: if iszero(eq(mload(0), EIP1271_isValidSignature_selector))", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document the structure of the TypehashDirectory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Instances of TypehashDirectory would act as storage contracts with runtime bytecode: [0x00 - 0x00] 00 [0x01 - 0x20] h(struct BulkOrder { OrderComponents[2] [0x21 - 0x40] h(struct BulkOrder { OrderComponents[2][2] ... [0xNN - 0xMM] h(struct BulkOrder { OrderComponents[2][2]...[2] tree }) tree }) tree }) 56 h calculates the eip-712 typeHash of the input struct. 0xMM would be mul(MaxTreeHeight, 0x20) and 0xNN = 0xMM - 0x1f.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document what twoSubstring encodes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "We have: bytes32 constant twoSubstring = 0x5B325D0000000000000000000000000000000000000000000000000000000000; which encodes: cast --to-ascii 0x5B325D0000000000000000000000000000000000000000000000000000000000 [2]", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Upper bits of the to parameter to call opcodes are stripped out by clients", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Upper bits of the to parameter to call opcodes are stripped out by clients. For example, geth would strip the upper bytes out:  instructions.go#L674  uint256.go#L114-L121 So even though the to parameters in this context can have dirty upper bits, the call opcodes can be successful, and masking these values in the contracts is not necessary for this context.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Remove unused functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The functions in the above context are not used in the codebase.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Fulfillment_itemIndex_offset can be used instead of OneWord", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the above context, one has: // Get the item index using the fulfillment pointer. itemIndex := mload(add(mload(fulfillmentHeadPtr), OneWord))", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document how the _pauser role is assigned for PausableZoneController", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The _pauser role is an important role for a PausableZoneController. It can pause any zone created by this controller and thus transfer all the native token funds locked in that zone to itself.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "_aggregateValidFulfillmentConsiderationItems's memory layout assumptions depend on _val- idateOrdersAndPrepareToFulfill's memory manipulation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "ceivedItem.recipient's offset of considerationItemPtr to write to receivedItem at offset (the same offset is also used here): _aggregateValidFulfillmentConsiderationItems are we In the Re- the same // Set the recipient on the received item. mstore( add(receivedItem, ReceivedItem_recipient_offset), mload(add(considerationItemPtr, ReceivedItem_recipient_offset)) ) looks buggy, This tion[i].endAmount with consideration[i].recipient: but in _validateOrdersAndPrepareToFulfill(...) we overwrite considera- mstore( add( considerationItem, ReceivedItem_recipient_offset // old endAmount ), mload( add( considerationItem, ConsiderationItem_recipient_offset ) ) ) in _fulfillAvailableAdvancedOrders and Also _validateOrdersAndPrepareToFulfill gets called first _matchAdvancedOrders. This is important since the memory for the consideration arrays needs to be updated before we reach _aggregateValidFulfillmentConsiderationItems. 59", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "recipient is provided as the fulfiller for the OrderFulfilled event", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the above context in general it is not true that the recipient is the fulfiller. Also note that recipient is address(0) for match orders.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "availableOrders[i] return values need to be explicitly assigned since they live in a region of memory which might have been dirtied before", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Seaport 1.1 did not have the following default assignment: if (advancedOrder.numerator == 0) { availableOrders[i] = false; continue; } But this is needed here since the current memory region which was previously used by the accumulator might be dirty.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Usage of MemoryPointer / formatting inconsistent in _getGeneratedOrder", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Usage of MemoryPointer / formatting is inconsistent between the loop used OfferItems and the loop used for ConsiderationItems.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "newAmount is not used in _compareItems", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "newAmount is unused in _compareItems. If originalItem points to I = (t, T , i, as, ae) and the newItem to Inew = (t 0, T 0, i 0, a0 s, a0 e) where parameter description t 0 t T , T 0 i 0 i as, a0 s ae, a0 e c then we have itemType itemType for I after the adjustment for restricted collection items token identifierOrCriteria identifierOrCriteria for I after the adjustment for restricted collection items startAmount endAmount _compareItems c(I, Inew ) = (t 6= t 0) _ (T 6= T 0) _ (i 6= i 0) _ (as 6= ae) and so we are not comparing either as to a0 enforced. In _getGeneratedOrder we have the following check: as > a0 errorBuffer. inequality is reversed for consideration items). And so in each loop (t 6= t 0) _ (T 6= T 0) _ (i 6= i 0) _ (as 6= ae) _ (as > a0 s or a0 s to a0 e. In abi_decode_generateOrder_returndata a0 s = a0 e is s (invalid case for offer items that contributes to s) is ored to errorBuffer.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "reformat validate so that its body is consistent with the other external functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "For consistency with other functions we can rewrite validate as: function validate( Order[] calldata /* orders */ ) external override returns (bool /* validated */ ) { return _validate(to_dyn_array_Order_ReturnType( abi_decode_dyn_array_Order )(CalldataStart.pptr())); } Needs to be checked if it changes code size or gas cost. Seaport: Fixed in PR 824. Spearbit: Verified.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Add commented parameter names (Type Location /* name */)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Add commented parameter names (Type Location /* name */) for validate: Order[] calldata /* orders */ Seaport: Fixed in commit 74de34. Spearbit: Verified.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document that the height provided to _lookupBulkOrderTypehash can only be in a certain range", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Need to have height h provided to _lookupBulkOrderTypehash such that: 1 + 32(h (cid:0) 1) 2 [0, min(0xffffffffffffffff, typeDirectory.codesize) (cid:0) 32] Otherwise typeHash := mload(0) would be 0 or would be padded by zeros. When extcodecopy gets executed extcodecopy(directory, 0, typeHashOffset, 0x20) clients like geth clamp typehashOffset to minimum of 0xffffffff_ffffffff and directory.codesize and pads the result with 0s if out of range. ref:  instructions.go#L373 62  common.go#L54", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Unused imports can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The imported contents in this context are unused.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "msg.sender is provided as the fulfiller input parameter in a few locations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "msg.sender is provided as the fulfiller input parameter.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Differences and similarities of ConsiderationDecoder and solc when decoding dynamic arrays of static/fixed base struct type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The way OfferItem[] in abi_decode_dyn_array_OfferItem and ConsiderationItem[] in abi_- decode_dyn_array_ConsiderationItem are decoded are consistent with solc regarding this:  For dynamic arrays of static/fixed base struct type, the memory region looks like: 63 [mPtrLength --------------------------------------------------- [mPtrLength + 0x20: mPtrLength + 0x40) : mPtrLength + 0x20) arrLength memberTail1 - a memory pointer to the array's 1st element ,! ... [mPtrLength + ...: mPtrLength + ...) memberTailN - a memory pointer to the array's Nth element ,! --------------------------------------------------- [memberTail1 ... [memberTailN : memberTailN + <STRUCT_SIZE>) elementN : memberTail1 + <STRUCT_SIZE>) element1 The difference is solc decodes and validates (checking dirty bytes) each field of the elements of the array (which are static struct types) separately (one calldataload and validation per field per element). ConsiderationDecoder skips all those validations for both OfferItems[] and ConsiderationItems[] by copying a chunk of calldata to memory (the tail parts): calldatacopy( mPtrTail, add(cdPtrLength, 0x20), mul(arrLength, OfferItem_size) ) That means for OfferItem[], itemType and token (and also recipient for ConsiderationItem[]) fields can potentially have dirty bytes.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "PointerLibraries's malloc skips some checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "malloc in PointerLibraries skips checking if add(mPtr, size) is OOR or wraps around. Solidity does the following when allocating memory: 64 function allocate_memory(size) -> memPtr { memPtr := allocate_unbounded() finalize_allocation(memPtr, size) } function allocate_unbounded() -> memPtr { memPtr := mload(<freeMemoryPointer>) } function finalize_allocation(memPtr, size) { let newFreePtr := add(memPtr, round_up_to_mul_of_32(size)) // protect against overflow if or(gt(newFreePtr, 0xffffffff_ffffffff), lt(newFreePtr, memPtr)) { // <-- the check that is skipped panic_error_<code>() } mstore(<freeMemoryPointer>, newFreePtr) } function round_up_to_mul_of_32(value) -> result { result := and(add(value, 31), not(31)) } function panic_error_<code>() { // <selector> = cast sig \"Panic(uint256)\" mstore(0, <selector>) mstore(4, <code>) revert(0, 0x24) } Also note, rounding up the size to the nearest word boundary is hoisted out of malloc.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "abi_decode_bytes can populate memory with dirty bytes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When abi_decode_bytes decodes bytes, it rounds its size and copies the rounded size from calldata to memory. This memory region might get populated with dirty bytes. So for example: For both signature and extraData we are using abi_decode_bytes. If the AdvancedOrder is tightly packed and:  If signature's length is not a multiple of a word (0x20) part of the extraData.length bytes will be copied/duplicated to the end of signature's last memory slot.  If extraData's length is not a multiple of a word (0x20) part of the calldata that comes after extraData's tail will be copied to memory. Even if AdvancedOrder is not tightly packed (tail offsets are multiple of a word relative to the head), the user can stuff the calldata with dirty bits when signature's or extraData's length is not a multiple of a word. And those dirty bits will be carried over to memory during decoding. Note, these extra bits will not be overridden or 65 cleaned during the decoding because of the way we use and update the free memory pointer (incremented by the rounded-up number to a multiple of a word).", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "abi_encode_validateOrder reuses a memory region", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "It is really important to note that before abi_encode_validateOrder is called, _prepareBasicFul- fillmentFromCalldata(...) needs to be called to populate the memory region that is used for event OrderFul- filled(...) which can be reused/copied in this function: MemoryPointer.wrap(offerDataOffset).copy( dstHead.offset(tailOffset), offerAndConsiderationSize ); From when the memory region for OrderFulfilled(...) is populated till we reach this point, care needs to be taken to not modified that region. accumulator data is written to the memory after that region and the current implementation does not touch that region during the whole call after the event has been emitted.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "abi_encode_validateOrder writes to a memory region that might have been potentially dirtied by accumulator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In abi_encode_validateOrder potentially (in the future), we might be writing in an area where accumulator was used. And since the book-keeping for the accumulator does not update the free memory pointer, we need to make sure all bytes in the memory in the range [dst, dst+size) are fully updated/written to in this function.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Reorder writing to memory in ConsiderationEncoder to follow the order in struct definitions.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Reorder the memory writes in ConsiderationEncoder to follow the order in struct definitions.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "The compiled YUL code includes redundant consecutive validation of enum types", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Half the location where an enum type struct field has been used/accessed, the validation function for this enum type is performed twice: validator_assert_enum_<ENUM_NAME>(memPtr) validator_assert_enum_<ENUM_NAME>(memPtr)", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Consider writing tests for revert functions in ConsiderationErrors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "ConsiderationErrors.sol is a new file and is untested. Writing test cases to make sure the revert functions are throwing the right errors is an easy way to prevent mistakes.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Typo in comment for the selector used in ConsiderationEncoder.sol#abi_encode_validateOrder()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Minor typo in comments: // Write ratifyOrder selector and get pointer to start of calldata dst.write(validateOrder_selector);", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "_contractNonces[offerer] gets incremented even if the generateOrder(...)'s return data does not satisfy all the constrainsts.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "_contractNonces[offerer] gets incremented even if the generateOrder(...)'s return data does not satisfy all the constraints. This is the case when errorBuffer !=0 and revertOnInvalid == false (ful- fillAvailableOrders, fulfillAvailableAdvancedOrders). In this case, Seaport would not call back into the contract offerer's ratifyOrder(...) endpoint. Thus, the next time this offerer receives a ratifyOrder(...) call from Seaport, the nonce shared with it might have incremented more than 1.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Users need to be cautious about what proxied/modified Seaport or Conduit instances they approve their tokens to", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Seaport ( S ) uses EIP-712 domain separator to make sure that when users sign orders, the signed orders only apply to that specific Seaport by pinpointing its name, version, the chainid, and its address. The domain separator is calculated and cached once the Seaport contract gets deployed. The domain separator only gets recalculated when/if the chainid changes (in the case of a hard fork for example). Some actors can take advantage of this caching mechanism by deploying a contract ( S0 ) that :  Delegates some of its endpoints to Seaport or it's just a proxy contract.  Its codebase is almost identical to Seaport except that the domain separator actually replicates what the original Seaport is using. This only requires 1 or 2 lines of code change (in this case the caching mechanism is not important) function _deriveDomainSeparator() { ... // Place the address of this contract in the next memory location. mstore(FourWords, MAIN_SEAPORT_ADDRESS) // <--- modified line and perhaps the actor can define a ,! named constant Assume a user approves either: 1. Both the original Seaport instance and the modified/proxied instance or, 2. A conduit that has open channels to both the original Seaport instance and the modified/proxied instance. And signs an order for the original Seaport that in the 1st case doesn't use any conduits or in the 2nd case the order uses the approved conduit with 2 open channels. Then one can use the same signature once with the original Seaport and once with the modified/proxied one to receive more tokens than offerer / user originally had intended to sell.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "ZoneInteraction contains logic for both zone and contract offerers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "ZoneInteraction contains logic for both zone and contract offerers.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Orders of CONTRACT order type can lower the value of a token offered", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Sometimes tokens have extra value because of the derived tokens owned by them (for example an accessory for a player in a game). With the introduction of contract offerer, one can create a contract offerer that automatically lowers the value of a token, for example, by transferring the derived connected token to a different item when Seaport calls the generateOrder(...). When such an order is included in a collection of orders the only way to ensure that the recipient of the item will hold a token which value hasn't depreciated during the transaction is that the recipient would also need to use a kind of mirrored order that incorporates either a CONTRACT or restricted order type that can do a post-transfer check.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Restricted order checks in case where offerer and the fulfiller are the same", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Seaport 1.2 disallowed skipping restricted order checks when offerrer and fulfiller are the same.  Remove special-casing for offerer-fulfilled restricted orders: Offerers may currently bypass restricted order checks when fulfilling their own orders. This complicates reasoning about restricted order validation, can aid in the deception of other offerers or fulfillers in some unusual edge cases, and serves little practical use. However, in the case of the offerer == fulfiller == zone, the check continues to be skipped.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Clean up inline documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The comments highlighted in Context need to be removed or updated.  Remove the following: 73 ConsiderationEncoder.sol:216: // @todo Dedupe some of this ConsiderationEncoder.sol:316: // @todo Dedupe some of this ZoneInteraction.sol:97: // bytes memory callData; ZoneInteraction.sol:100: // function(bytes32) internal view errorHandler; ZoneInteraction.sol:182: // let magicValue := shr(224, mload(callData))  ConsiderationStructs.sol#L167 and ZoneInteraction.sol#L82 contain an outdated comment about the extraData attribute. There is no longer a staticcall being done, and the function isValidOrderIn- cludingExtraData no longer exists.  The NatSpec comment for _assertRestrictedAdvancedOrderValidity mentions: /** * @dev Internal view function to determine whether an order is a restricted * * * * * order and, if so, to ensure that it was either submitted by the offerer or the zone for the order, or that the zone returns the expected magic value upon performing a staticcall to `isValidOrder` or `isValidOrderIncludingExtraData` depending on whether the order fulfillment specifies extra data or criteria resolvers. A few of the facts are not correct anymore: * This function is not a view function anymore and change the storage state either for a zone or a contract offerer. * It is not only for restricted orders but also applies to orders of CONTRACT order type. * It performs actuall calls and not staticcalls anymore. * it calls the isValidOrder endpoint of a zone or the ratifyOrder endpoint of a contract offerer depending on the order type. * If it is dealing with a restricted order, the check is only skipped if the msg.sender is the zone. Seaport is called by the offerer for a restricted order, the call to the zone is still performed. If  Same comments apply to _assertRestrictedBasicOrderValidity excluding the case when order is of CONTRACT order type.  Typos in TransferHelperErrors.sol - * @dev Revert with an error when a call to a ERC721 receiver reverts with + * @dev Revert with an error when a call to an ERC721 receiver reverts with  The @ NatSpec fields have an extra space in Consideration.sol: * @ <field> The extra space can be removed.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Consider writing tests for hard coded constants in ConsiderationConstants.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There are many hard coded constants, most being function selectors, that should be tested against.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Unused / Redundant imports in ZoneInteraction.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There are multiple unused / redundant imports.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Orders of CONTRACT order type do not enforce a usage of a specific conduit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "None of the endpoints (generateOrder and ratifyOrder) for an order of CONTRACT order type en- force using a specific conduit. A contract offerer can enforce the usage of a specific conduit or just Seaport by setting allowances or approval for specific tokens. If a caller calls into different Seaport endpoints and does not provide the correct conduit key, then the order would revert. Currently, the ContractOffererInterface interface does not have a specific endpoint to discover which conduits the contract offerer would prefer users to use. getMetadata() would be able to return a metadata that encodes the conduit key. For (advanced) orders of not CONTRACT order types, the offerer would sign the order and the conduit key is included in the signed hash. Thus, the conduit is enforced whenever that order gets included in a collection by an actor calling Seaport.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Calls to Seaport that would fulfill or match a collection of advanced orders can be front-ran to claim any unused offer items", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Calls to Seaport that would fulfill or match a collection of advanced orders can be front-ran to claim any unused offer items. These endpoints include:  fulfillAvailableOrders  fulfillAvailableAdvancedOrders  matchOrders  matchAdvancedOrders Anyone can monitor the mempool to find calls to the above endpoints and calculate if there are any unused offer item amounts. If there are unused offer item amounts, the actor can create orders with no offer items, but with consideration items mirroring the unused offer items and populate the fulfillment aggregation data to match the 84 unused offer items with the new mirrored consideration items. It is possible that the call by the actor would be successful under certain conditions. For example, if there are orders of CONTRACT order type involved, the contract offerer might reject this actor (the rejection might also happen by the zones used when validating the order). But in general, this strategy can be implemented by anyone.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Advance orders of CONTRACT order types can generate orders with more offer items and the extra offer items might not end up being used.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide extra offer items for this order. These extra offer items might have not been known beforehand by the caller. And if the caller would not incorporate the indexes for the extra items in the fulfillment aggregation data, the extra items would end up not being aggregated into any executions.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Typo for the index check comment in _aggregateValidFulfillmentConsiderationItems", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There is a typo in _aggregateValidFulfillmentConsiderationItems: // Retrieve item index using an offset of the fulfillment pointer. let itemIndex := mload( add(mload(fulfillmentHeadPtr), Fulfillment_itemIndex_offset) ) // Ensure that the order index is not out of range. <---------- the line with typo if iszero(lt(itemIndex, mload(considerationArrPtr))) { throwInvalidFulfillmentComponentData() } The itemIndex above refers to the index in consideration array and not the order.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document the unused parameters for orders of CONTRACT order type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "If an advance order advancedOrder is of CONTRACT order type, certain parameters are not being used in the code base, specifically:  numerator: only used for skipping certain operations (see AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT order type)  denominator: --  signature: --  parameters.zone: only used when emitting the OrderFulfilled event.  parameters.offer.endAmount: endAmount and startAmount for offer items will be set to the amount sent back by generateOrder for the corresponding item.  parameters.consideration.endAmount: endAmount and startAmount for consideration items will be set to the amount sent back by generateOrder for the corresponding item  parameters.consideration.recipient: the offerer contract returns new recipients when generateOrder gets called  parameters.zoneHash: --  parameters.salt: --  parameters.totalOriginalConsiderationItems: --", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "The check against totalOriginalConsiderationItems is skipped for orders of CONTRACT order type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "compares dOrder.parameters.consideration.length: The AdvancedOrder.parameters.totalOriginalConsiderationItems inequality following skipped orders for of is CONTRACT order with type which Advance- // Ensure supplied consideration array length is not less than the original. if (suppliedConsiderationItemTotal < originalConsiderationItemTotal) { _revertMissingOriginalConsiderationItems(); }", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "getOrderStatus returns the default values for orderHash that is derived for orders of CONTRACT order type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Since the _orderStatus[orderHash] does not get set for orders of CONTRACT order type, getOrder- Status would always returns (false, false, 0, 0) for those hashes (unless there is a hash collision with other types of orders)", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "validate skips CONTRACT order types but cancel does not", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When validating orders validate skips any order of CONTRACT order type, but cancel does not skip these order types. When fulfilling or matching orders for CONTRACT order types, _orderStatus does not get checked or populated. But in cancel the isValidated and the isCancelled fields get set. This is basically a no-op for these order types.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "The literal 0x1c used as the starting offset of a custom error in a revert statement can be replaced by the named constant Error_selector_offset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the context above, 0x1c is used to signal the start of a custom error block saved in the memory: revert(0x1c, _LENGTH_) For the above literal, we also have a named constant defined in ConsiderationConstants.sol#L410: uint256 constant Error_selector_offset = 0x1c; The named constant Error_selector_offset has been used in most places that a custom error is reverted in an assembly block.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Mint PerpetualYieldTokens for free by self-transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The PYT.transfer and transferFrom functions operate on cached balance values. When transfer- ring tokens to oneself the decreased balance is overwritten by an increased balance which makes it possible to mint PYT tokens for free. Consider the following exploit scenario:  Attacker A self-transfers by calling token.transfer(A, token.balanceOf(A)).  balanceOf[msg.sender] is rst set to zero but then overwritten by balanceOf[to] = toBalance + amount, doubling As balance.", "labels": ["Spearbit", "Timeless", "Severity: Critical Risk"]}, {"title": "xPYT auto-compound does not take pounder reward into account", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Conceptually, the xPYT.pound function performs the following steps: 1. Claims yieldAmount yield for itself, deposits the yield back to receive more PYT/NYT (Gate.claimYieldEnter). 2. Buys xPYT with the NYT. 3. Performs a ERC4626.redeem(xPYT) with the bought amount, burning xPYT and receiving pytAmountRedeemed PYT. 4. Performs a ERC4626.deposit(pytAmountRedeemed + yieldAmount = pytCompounded). 5. Pays out a reward in PYT to the caller. The assetBalance is correctly updated for the rst four steps but does not decrease by the pounder reward which is transferred out in the last step. The impact is that the contract has a smaller assets (PYT) balance than what is tracked in assetBalance. 1. Future depositors will have to make up for it as sweep computes the difference between these two values. 2. The xPYT exchange ratio is wrongly updated and withdrawers can redeem xPYT for more assets than they should until the last withdrawer is left holding valueless xPYT. Consider the following example and assume 100% fees for simplicity i.e. pounderReward = pytCompounded.  Vault total: 1k assets, 1k shares total supply.  pound with 100% fee:  claims Y PYT/NYT.  swaps Y NYT to X xPYT.  redeems X xPYT for X PYT by burning X xPYT (supply -= X, exchange ratio is 1-to-1 in example).  assetBalance is increased by claimed Y PYT  pounder receives a pounder reward of X + Y PYT but does not decrease assetBalance by pounder reward X+Y.  Vault totals should be 1k-X assets, 1k-X shares, keeping the same share price.  Nevertheless, vault totals actually are 1k+Y assets, 1k-X shares. Although pounder receives 100% of pound- ing rewards the xPYT price (assets / shares) increased.", "labels": ["Spearbit", "Timeless", "Severity: High Risk"]}, {"title": "Wrong yield accumulation in claimYieldAndEnter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The claimYieldAndEnter function does not accrue yield to the Gate contract itself (this) in case xPYT was specied. The idea is to accrue yield for the mint recipient rst before increasing/reducing their balance to not interfere with the yield rewards computation. However, in case xPYT is used, tokens are minted to the Gate before its yield is accrued. Currently, the transfer from this to xPYT through the xPYT.deposit call accrues yield for this after the tokens have been minted to it (userPYTBalance * (updatedYieldPerToken - actualUserYieldPerToken) / PRECI- SION) and its balance increased. This leads to it receiving a larger yield amount than it should have.", "labels": ["Spearbit", "Timeless", "Severity: High Risk"]}, {"title": "Swapper left-over token balances can be stolen", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The Swapper contract may never have any left-over token balances after performing a swap because token balances can be stolen by anyone in several ways:  By using Swapper.doZeroExSwap with useSwapperBalance and tokenOut = tokenToSteal  Arbitrary token approvals to arbitrary spenders can be set on behalf of the Swapper contract using UniswapV3Swapper.swapUnderlyingToXpyt.", "labels": ["Spearbit", "Timeless", "Severity: High Risk"]}, {"title": "TickMath might revert in solidity version 0.8", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "UniswapV3s TickMath library was changed to allow compilations for solidity version 0.8. However, adjustments to account for the implicit overow behavior that the contract relies upon were not performed. The In UniswapV3xPYT.sol is compiled with version 0.8 and indirectly uses this library through the OracleLibrary. the worst case, it could be that the library always reverts (instead of overowing as in previous versions), leading to a broken xPYT contract. The same pragma solidity >=0.5.0; instead of pragma solidity >=0.5.0 <0.8.0; adjustments have been made for the OracleLibrary and PoolAddress contracts. However, their code does not rely on implicit overow behavior.", "labels": ["Spearbit", "Timeless", "Severity: Medium Risk"]}, {"title": "Rounding issues when exiting a vault through shares", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "When exiting a vault through Gate.exitToVaultShares the user species a vaultSharesAmount. The amount of PYT&NYT to burn is determined by a burnAmount = _vaultSharesAmountToUnderlying- this function in derived YearnGate and ERC4626 Amount(vaultSharesAmount) call. All contracts round down the burnAmount. This means one needs to burn fewer amounts than the value of the received vault shares. implementations of This attack can be protable and lead to all vault shares being stolen If the gas costs of this attack are low. This can be the case with vault & underlying tokens with a low number of decimals, highly valuable shares, or cheap gas costs. Consider the following scenario: 7  Imagine the following vault assets: totalAssets = 1.9M, supply = 1M. Therefore, 1 share is theoretically worth 1.9 underlying.  Call enterWithUnderlying(underlyingAmount = 1900) to mint 1900 PYT/NYT (and the gate receives 1900 * supply / totalAssets = 1000 vault shares).  Call exitToVaultShares(vaultSharesAmount = 1), then burnAmount = shares.mulDivDown(totalAssets(), supply) = 1 * totalAssets / supply = 1. This burns 1 \"underlying\" (actually PYT/NYT but they are 1-to-1), but receive 1 vault share (worth 1.9 underlying). Repeat this for up to the minted 1900 PYT/NYT.  Can redeem the 1900 vault shares for 3610 underlying directly at the vault, making a prot of 3610 - 1900 = 1710 underlying.", "labels": ["Spearbit", "Timeless", "Severity: Medium Risk"]}, {"title": "Possible outstanding allowances from Gate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The vault parameter of Gate.enterWithUnderlying can be chosen by an attacker in such a way that underlying = vault.asset() is another vault token of the Gate itself. The subsequent _depositInto- Vault(underlying, underlyingAmount, vault) call will approve underlyingAmount of underlying tokens to the provided vault and could in theory allow stealing from other vault shares. This is currently only exploitable in very rare cases because the caller also has to transfer the underlyingAmount to the gate contract rst. For example, when transferring underlyingAmount = type(uint256).max is possible due to ashloans/ashmints and the vault shares implement approvals in a way that do not decrease anymore if the allowance is type(uint256).max, as is the case with ERC4626 vaults.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Factory.sol owner can change fees unexpectedly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The Factory.sol owner may be able to front run yield calculations in a gate implementation and change user fees unexpectedly.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Low uniswapV3TwapSecondsAgo may result in AMM manipulation in pound()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The lower the value of uniswapV3TwapSecondsAgo is set with at construction creation time the easier It becomes easier for attackers to it becomes for an attacker to manipulate the results of the pound() function. manipulate automated market maker price feeds with a lower time horizon, requiring less capital to manipulate prices, although users may simply not use an xPYT contract that sets uniswapV3TwapSecondsAgo too low.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "UniswapV3Swapper uses wrong allowance check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Before the UniswapV3Swapper can exit a gate, it needs to set an XPYT allowance to the gate. The following check determines if an approval needs to be set: if ( args.xPYT.allowance(address(this), address(args.gate)) < tokenAmountOut ) { args.xPYT.safeApprove(address(args.gate), type(uint256).max); } args.gate.exitToUnderlying( args.recipient, args.vault, args.xPYT, tokenAmountOut ); The tokenAmountOut is in an underlying token amount but A legitimate gate.exitToUnderlying address(swapper)) checks allowance[swapper][gate] >= previewWithdraw(tokenAmountOut). is compared against an xPYT shares amount. xPYT.withdraw(tokenAmountOut, address(gate), call will call", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Missing check that tokenIn and tokenOut are different", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The doZeroExSwap() function takes in two ERC20 addresses which are tokenIn and tokenOut. The problem is that the doZeroExSwap() function does not check if the two token addresses are different from one another. Adding this check can reduce possible attack vectors.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Gate.sol gives unlimitted ERC20 approval on pyt for arbitrary address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "A malicious contract may be passed into the claimYieldAndEnter() function as xPYT and given full control over any PYT the contract may ever hold. Even though PYT is validated to be a real PYT contract and the Gate.sol contract isnt expected to have any PYT in it, it would be safer to remove any unnecessary approvals.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Constructor function does not check for zero address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The constructor function does not check if the addresses passed in are zero addresses. This check can guard against errors during deployment of the contract.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Accruing yield to msg.sender is not required when minting to xPYT contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The _exit function always accrues yield to the msg.sender before burning new tokens. The idea is to accrue yield for the recipient rst before increasing/reducing their balance to not interfere with the yield rewards computation. However, in case xPYT is used, tokens are burned on the Gate and not msg.sender.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Unlocked solidity pragmas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Most of the implementation code uses a solidity pragma of 0.8.4. contracts that use different functions. Unlocked solidity pragmas can result in unexpected behaviors or errors with different compiler versions.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "No safeCast in UniswapV3Swappers _swap.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "It should be noted that solidity version 0.8.0 doesnt revert on overow when type-casting. For example, if you tried casting the value 129 from uint8 to int8, it would overow to -127 instead. This is because signed integers have a lower positive integer range compared to unsigned integers i.e -128 to 127 for int8 versus 0 to 255 for uint8.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "One step critical address change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Setting the owner in Ownable is a one-step transaction. This situation enables the scenario of contract functionality becoming inaccessible or making it so a malicious address that was accidentally set as owner could compromise the system.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Missing zero address checks in transfer and transferFrom functions.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The codebase uses solmates ERC-20 implementation. It should be noted that this library sacrices user safety for gas optimization. As a result, their ERC-20 implementation doesnt include zero address checks on transfer and transferFrom functions.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Should add indexed keyword to deployed xPYT event", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The DeployXPYT event only has the ERC20 asset_ marked as indexed while xPYT deployed can also have the indexed key word since you can use up to three per event and it will make it easier for bots to interact off chain with the protocol.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Missing check that tokenAmountIn is larger than zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "In doZeroExSwap() there is no check that the tokenAmountIn number is larger than zero. Adding this check can add more thorough validation within the function.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "ERC20 does not emit Approval event in transferFrom", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The ERC20 contract does not emit new Approval events with the updated allowance in transferFrom. This makes it impossible to track approvals solely by looking at Approval events.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Use the ofcial UniswapV3 0.8 branch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The current repositories create local copies of UniswapV3s codebase and manually migrate the contracts to Solidity 0.8.  For FullMath.sol this also leads to some small gas optimizations in this LOC as it uses 0 instead of type(uint256).max + 1.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "No checks that provided xPYT matches PYT of the provided vault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The Gate contracts has many functions that allow specifying vault and a xPYT addresses as pa- rameter. The underlying of the xPYT address is assumed to be the same as the vaults PYT but this check is not enforced. Users that call the Gate functions with an xPYT contract for the wrong vault could see their de- posit/withdrawals lost.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Protocol does not work with non-standard ERC20 tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Some ERC20 tokens make modications to their ERC20s transfer or balanceOf functions. One kind include deationary tokens that charge certain fee for every transfer or transferFrom. Others are rebasing tokens that increase in balance over time. Using these tokens in the protocol can lead to issues such as:  Entering a vault through the Gate will not work as it tries to deposit the pre-fee amount instead of the received post-fee amount.  The UniswapV3Swapper tries to enter a vault with the pre-fee transfer amount.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "The claimGobbler function does not enforce the MINTLIST_SUPPLY on-chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "There is a public constant MINTLIST_SUPPLY (2000) that is supposed to represent the number of gobblers that can be minted by using merkle proofs. However, this is not explicitly enforced in the claimGobbler function and will need to be verified off-chain from the list of merkle proof data. The risk lies in the possibility of having more than 2000 proofs.", "labels": ["Spearbit", "ArtGobblers", "Severity: Low Risk"]}, {"title": "Feeding a gobbler to itself may lead to an infinite loop in the off-chain renderer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The contract allows feeding a gobbler to itself and while we do not think such action causes any issues on the contract side, it will nevertheless cause potential problems with the off-chain rendering for the gob- blers. The project explicitly allows feeding gobblers to other gobblers. In such cases, if the off-chain renderer is designed to render the inner gobbler, it would cause an infinite loop for the self-feeding case. Additionally, when a gobbler is fed to another gobbler the user will still own one of the gobblers. However, this is not the case with self-feeding,.", "labels": ["Spearbit", "ArtGobblers", "Severity: Low Risk"]}, {"title": "The function toString() does not manage memory properly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "There are two issues with the toString() function: 1. It does not manage the memory of the returned string correctly. In short, there can be overlaps between memory allocated for the returned string and the current free memory. 2. It assumes that the free memory is clean, i.e., does not explicitly zero out used memory. Proof of concept for case 1: function testToStringOverwrite() public { string memory str = LibString.toString(1); uint freememptr; uint len; bytes32 data; uint raw_str_ptr; assembly { // Imagine a high level allocation writing something to the current free memory. // Should have sufficient higher order bits for this to be visible mstore(mload(0x40), not(0)) freememptr := mload(0x40) // Correctly allocate 32 more bytes, to avoid more interference mstore(0x40, add(mload(0x40), 32)) raw_str_ptr := str len := mload(str) data := mload(add(str, 32)) } emit log_named_uint(\"memptr: \", freememptr); emit log_named_uint(\"str: \", raw_str_ptr); emit log_named_uint(\"len: \", len); emit log_named_bytes32(\"data: \", data); } Logs: memptr: : 256 str: : 205 len: : 1 data: : 0x31000000000000000000000000000000000000ffffffffffffffffffffffffff The key issue here is that the function allocates and manages memory region [205, 269) for the return variable. However, the free memory pointer is set to 256. The memory between [256, 269) can refer to both the string and another dynamic type that's allocated later on. Proof of concept for case 2: 5 function testToStringDirty() public { uint freememptr; // Make the next 4 bytes of the free memory dirty assembly { let dirty := not(0) freememptr := mload(0x40) mstore(freememptr, dirty) mstore(add(freememptr, 32), dirty) mstore(add(freememptr, 64), dirty) mstore(add(freememptr, 96), dirty) mstore(add(freememptr, 128), dirty) } string memory str = LibString.toString(1); uint len; bytes32 data; assembly { freememptr := str len := mload(str) data := mload(add(str, 32)) } emit log_named_uint(\"str: \", freememptr); emit log_named_uint(\"len: \", len); emit log_named_bytes32(\"data: \", data); assembly { freememptr := mload(0x40) } emit log_named_uint(\"memptr: \", freememptr); } Logs: str: 205 len: : 1 data: : 0x31ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff memptr: : 256 In both cases, high level solidity will not have issues decoding values as this region in memory is meant to be empty. However, certain ABI decoders, notably Etherscan, will have trouble decoding them. Note: It is likely that the use of toString() in ArtGobblers will not be impacted by the above issues. However, these issues can become severe if LibString is used as a generic string library.", "labels": ["Spearbit", "ArtGobblers", "Severity: Low Risk"]}, {"title": "Consider migrating all require statements to Custom Errors for gas optimization, better UX, DX and code consistency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "There is a mixed usage of both require and Custom Errors to handle cases where the transaction must revert. We suggest replacing all require instances with Custom Errors in order to save gas and improve user / developer experience. The following is a list of contract functions that still use require statements:  ArtGobblers mintLegendaryGobbler  ArtGobblers safeBatchTransferFrom  ArtGobblers safeTransferFrom  SignedWadMath wadLn  GobblersERC1155B balanceOfBatch  GobblersERC1155B _mint  GobblersERC1155B _batchMint  PagesERC721 ownerOf  PagesERC721 balanceOf  PagesERC721 approve  PagesERC721 transferFrom  PagesERC721 safeTransferFrom  PagesERC721 safeTransferFrom (overloaded version)", "labels": ["Spearbit", "ArtGobblers", "Severity: Gas Optimization"]}, {"title": "Minting of Gobbler and Pages can be further gas optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "Currently, in order to mint a new Page or Gobbler users must have enough $GOO in their Goo contract balance. If the user does not have enough $GOO he/she must call ArtGobblers.removeGoo(amount) to remove the required amount from the Gobbler's balance and mint new $GOO. That $GOO will be successively burned to mint the Page or Gobbler. In the vast majority of cases users will never have $GOO in the Goo contract but will have their $GOO directly stacked inside their Gobblers to compound and maximize the outcome. Given these premises, it makes sense to implement a function that does not require users to make two distinct transactions to perform:  mint $GOO (via removeGoo).  burn $GOO + mint the Page/Gobbler (via mintFromGoo). 7 but rather use a single transaction that consumes the $GOO stacked on the Gobbler itself without ever minting and burning any $GOO from the Goo contract. By doing so, the user will perform the mint operation with only one transaction and the gas cost will be much lower because it does not require any interaction with the Goo contract.", "labels": ["Spearbit", "ArtGobblers", "Severity: Gas Optimization"]}, {"title": "Declare GobblerReserve artGobblers as immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The artGobblers in the GobblerReserve can be declared as immutable to save gas. - ArtGobblers public artGobblers; + ArtGobblers public immutable artGobblers;", "labels": ["Spearbit", "ArtGobblers", "Severity: Gas Optimization"]}, {"title": "Neither GobblersERC1155B nor ArtGobblers implement the ERC-165 supportsInterface function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "From the EIP-1155 documentation: Smart contracts implementing the ERC-1155 standard MUST implement all of the functions in the ERC1155 interface. Smart contracts implementing the ERC-1155 standard MUST implement the ERC- 165 supportsInterface function and MUST return the constant value true if 0xd9b67a26 is passed through the interfaceID argument. Neither GobblersERC1155B nor ArtGobblers are actually implementing the ERC-165 supportsInterface function. implementing the required ERC-165 supportsInterface function in the", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "LogisticVRGDA is importing wadExp from SignedWadMath but never uses it", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The LogisticVRGDA is importing the wadExp function from the SignedWadMath library but is never used.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Pages.tokenURI does not revert when pageId is the ID of an invalid or not minted token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The current implementation of tokenURI in Pages is returning an empty string if the pageId specified by the user's input has not been minted yet (pageId > currentId). Additionally, the function does not correctly handle the case of a special tokenId equal to 0, which is an invalid token ID given that the first mintable token would be the one with ID equal to 1. The EIP-721 documentation specifies that the contract should revert in this case: Throws if _tokenId is not a valid NFT. URIs are defined in RFC 3986.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Consider checking if the token fed to the Gobbler is a real ERC1155 or ERC721 token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The current implementation of ArtGobblers.feedArt function allows users to specify from the value of the bool isERC1155 input parameter if the id passed is from an ERC721 or ERC1155 type of token. Without checking if the passed nft address fully support ERC721 or ERC1155 these two problems could arise:  The user can feed to a Gobbler an arbitrary ERC20 token by calling gobblers.feedArt(1, address(goo), 100, false);. In this example, we have fed 100 $GOO to the gobbler.  By just implementing safeTransferFrom or transferFrom in a generic contract, the user can feed tokens that cannot later be rendered by a Dapp because they do not fully support ERC721 or ERC1155 standard.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Rounding down in legendary auction leads to legendaryGobblerPrice being zero earlier than the auction interval", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The expression below rounds down. startPrice * (LEGENDARY_AUCTION_INTERVAL - numMintedSinceStart)) / LEGENDARY_AUCTION_INTERVAL In particular, this expression has a value 0 when numMintedSinceStart is between 573 and 581 (LEGENDARY_- AUCTION_INTERVAL).", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Typos in code comments or natspec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "Below is a list of typos encountered in the code base and / or natspec comments:  In both Pages.sol#L179 and Pages.sol#L188 replace compromise with comprise  In Pages.sol#L205 replace pages's URI with page's URI  In LogisticVRGDA.sol#L23 replace effects with affects  In VRGDA.sol#L34 replace actions with auctions  In ArtGobblers.sol#L54, ArtGobblers.sol#L745 and ArtGobblers.sol#L754 replace compromise with comprise  In ArtGobblers.sol#L606 remove the double occurrence of the word state  In ArtGobblers.sol#L871 replace emission's with emission  In ArtGobblers.sol#L421 replace gobblers is minted with gobblers are minted and until all legen- daries been sold with until all legendaries have been sold  In ArtGobblers.sol#L435-L436 replace gobblers where minted with gobblers were minted and if auc- tion has not yet started with if the auction has not yet started  In ArtGobblers.sol#L518 replace overflow we've got bigger problems with overflow, we've got big- ger problems  In ArtGobblers.sol#L775 and ArtGobblers.sol#L781 replace get emission emissionMultiple with get emissionMultiple", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Missing natspec comments for contract's constructor, variables or functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "Some of the contract's constructor variables and functions are missing natespec comments. Here is the full list of them:  Pages constructor  Pages getTargetSaleDay function  LibString toString function  MerkleProofLib verify function  SignedWadMath toWadUnsafe function  SignedWadMath unsafeWadMul function  SignedWadMath unsafeWadDiv function  SignedWadMath wadMul function  SignedWadMath wadDiv function  SignedWadMath wadExp function  SignedWadMath wadLn function  SignedWadMath unsafeDiv function  VRGDA constructor  LogisticVRGDA constructor  LogisticVRGDA getTargetDayForNextSale  PostSwitchVRGDA constructor  PostSwitchVRGDA getTargetDayForNextSale  GobblerReserve artGobblers  GobblerReserve constructor  GobblersERC1155B contract is missing natspec's coverage for most of the variables and functions  PagesERC721 contract is missing natspec's coverage for most of the variables and functions  PagesERC721 isApprovedForAll should explicity document the fact that the ArtGobbler contract is always pre-approved  ArtGobblers chainlinkKeyHash variable  ArtGobblers chainlinkFee variable  ArtGobblers constructor  ArtGobblers gobblerPrice miss the @return natspec  ArtGobblers legendaryGobblerPrice miss the @return natspec  ArtGobblers requestRandomSeed miss the @return natspec  ArtGobblers fulfillRandomness miss both the @return and @param natspec  ArtGobblers uri miss the @return natspec  ArtGobblers gooBalance miss the @return natspec  ArtGobblers mintReservedGobblers miss the @return natspec  ArtGobblers getGobblerEmissionMultiple miss the @return natspec 11  ArtGobblers getUserEmissionMultiple miss the @return natspec  ArtGobblers safeBatchTransferFrom miss all natspec  ArtGobblers safeTransferFrom miss all natspec  ArtGobblers transferUserEmissionMultiple miss @notice natspec", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}]