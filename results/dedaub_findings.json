[
    {
        "title": "does not check if it is overwriting a previous queued oracle ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": " RESOLVED (not applicable as of e4fbfc30) In PriceFeed::addOracle, the queuedOracles entry for the token is wrien without checking whether it is zero. This is only a problem in case the controller makes a mistake, but the presence of a deleteQueuedOracle function suggests that the right behavior for a controller would be to delete a queued oracle if its no longer valid. function addOracle(address _token, address _chainlinkOracle, bool _isEthIndexed) external override isController { AggregatorV3Interface newOracle = AggregatorV3Interface(_chainlinkOracle); _validateFeedResponse(newOracle); if (registeredOracles[_token].exists) { uint256 timelockRelease = block.timestamp.add(_getOracleUpdateTimelock()); queuedOracles[_token] = OracleRecord(newOracle, timelockRelease, true, true, _isEthIndexed); } else { registeredOracles[_token] = OracleRecord(newOracle, block.timestamp, true, emit NewOracleRegistered(_token, _chainlinkOracle, _isEthIndexed); true, _isEthIndexed); } }  function deleteQueuedOracle(address _token) external override isController { delete queuedOracles[_token]; }",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "timelock for adding oracles can be circumvented by deleting the previous oracle RESOLVED (not applicable as of e4fbfc30) On the same code as issue L1, in the PriceFeed contract, the controller can always subvert the above timelock by just deleting the registered oracle. function deleteOracle(address _token) external override isController { delete registeredOracles[_token]; } Thus, the timelock can only prevent accidents in the controller, and not provide assurances of having a delay for review of changes to oracles.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "series of liquidations can cause the zeroing of totalStakes ACKNOWLEDGED The stake of a Vessel holding _asset as collateral is computed by the formula in VesselManager::_computeNewStake : stake = _coll.mul(totalStakesSnapshot[_asset]).div(totalCollateralSnapshot[_asset]); The stake is updated when the Vessel is adjusted and _coll is the new collateral amount of the Vessel and totalStakesSnapshot, totalCollateralSnapshot the total stakes and total collateral respectively right after the last liquidation. A liquidation followed by a redistribution of the debt and collateral to the other Vessels decreases the total stakes (the stake of the liquidated Vessel is just deleted and not shared among the others) and the total collateral (if we ignore the fees) does not change. Therefore the ratio in the above formula is constantly decreasing after each liquidation followed by redistribution and each new Vessel will get a relatively smaller  stake. The nite precision of the arithmetic operations can lead to a zeroing of totalStakes, if a series of liquidations of Vessels with high stakes occurs. If this happens, the total stakes will be zero forever and each new vessel will be assigned a zero stake. If this happens many functionalities of the protocol are blocked i.e. the VesselManager::redistributeDebtAndCollateral will revert every time, since the debt and collateral to distribute are computed dividing by the (zero) totalStakes. The probability of such a problem is higher in Gravita, compared to Liquity, because Gravita allows multiple collateral assets, some of them, in principle, more volatile compared to ETH.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "could return arbitrarily stale prices, if Chainlink Oracles response is not valid RESOLVED (e4fbfc30) The protocol uses the PriceFeed::fetchPrice to get the price of a _token, whenever it needs to. This function rst calls the Chainlink oracle to get the price for this _token and then checks the validity of the response. If it is valid, it stores the answer in lastGoodPrice[_token] and also returns it to the caller. If the Chainlink response is not valid, then the function returns the value stored in lastGoodPrice[_token]. The problem is that this value could have been stored a long time ago and there is no check about this in the contract. As an edge case, if the Chainlink oracle does not give a valid answer, upon its rst call for a _token, then the PriceFeed::fetchPrice function will return a zero price. Liquity uses a secondary oracle, if the response of Chainlink is not valid, and only if both oracles fail, the stored last good price is being used, but in Gravita there is no secondary oracle. L5 AdminContract::sanitizeParameters has no access control RESOLVED (58a41195) The function sets important collateral data (to default values) yet has no access control, unlike, e.g., the almost-equivalent setAsDefault, which is onlyOwner. 1 Although there are many other safeguards that ensure that collateral is valid, we recommend tightening the access control for sanitizeParameters as well. function sanitizeParameters(address _collateral) external { if (!collateralParams[_collateral].hasCollateralConfigured) { _setAsDefault(_collateral); } } function setAsDefault(address _collateral) external onlyOwner { _setAsDefault(_collateral); } CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) ",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Low"
        ]
    },
    {
        "title": "contracts can mint arbitrarily large amounts of debt tokens ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": " INFO (acknowledged) The role of the whitelisted contracts is not completely clear to us. There is only one related comment in DebtToken.sol : // stores SC addresses that are allowed to mint/burn the token (AMO strategies,",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "mapping(address => bool) public whitelistedContracts; 1 These contracts can mint debt tokens without depositing any collateral calling DebtToken::mintFromWhitelistedContract. This could be a serious problem if such a contract was malicious. Also, even if these contracts work as expected, minting debt tokens without providing any collateral could have a serious impact on the price of the debt token. N2 Protocol owners can set crucial parameters INFO (acknowledged) Key functionality is trusted to the owner of various contracts. Owners can set the kinds of collateral accepted, the oracles that are used to price collateral, etc. Thus, protocol owners should be trusted by users. OTHER / ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Low"
        ]
    },
    {
        "title": "struct Vessel (IVesselManager.sol), asset is unnecessary ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": " INFO Field asset of struct Vessel is currently unused. Vessel records are currently only used in a mapping that has the asset as the key, so there is no need to read the asset from the Vessel data. In FeeCollector::_decreaseDebt no need to check for",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "fees if the expiration time of the refunding is block.timestamp INFO 1 In the code below if (mRecord.to < NOW) { } _closeExpiredOrLiquidatedFeeRecord(_borrower, _asset, mRecord.amount); < can be replaced by <=, since when mRecord == NOW, there is nothing left for the user to refund.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "event INFO The following event is declared in IAdminContract.sol but not used anywhere: event MaxBorrowingFeeChanged(uint256 oldMaxBorrowingFee, uint256 newMaxBorrowingFee);",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "storage variables INFO The storage mapping StabilityPool::pendingCollGains and code accessing it are unnecessary since the information is never set to non-zero values. // Mapping from user address => pending collaterals to claim still // Must always be sorted by whitelist to keep leftSumColls functionality mapping(address => Colls) pendingCollGains; ... function getDepositorGains(address _depositor) public view returns (address[] memory, uint256[] memory) {  // Add pending gains to the current gains return ( collateralsFromNewGains, _leftSumColls( Colls(collateralsFromNewGains, amountsFromNewGains), pendingCollGains[_depositor].tokens, pendingCollGains[_depositor].amounts ) ); } ... function _sendGainsToDepositor( 1 address _to, address[] memory assets, uint256[] memory amounts ) internal { ... // Reset pendingCollGains since those were all sent to the borrower Colls memory tempPendingCollGains; pendingCollGains[_to] = tempPendingCollGains; } Also, StabilityPool::controller is unused and never set: IAdminContract public controller; Finally, variables activePool, defaultPool in GravitaBase seem unused and not set (at least for most subcontracts of GravitaBase). IActivePool public activePool; IDefaultPool internal defaultPool;",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "is really just a transfer INFO In StabilityPool::_sendGainsToDepositor, it is not clear why the transferFrom is not merely a transfer. function _sendGainsToDepositor( address _to, address[] memory assets, uint256[] memory amounts ) internal {  for (uint256 i = 0; i < assetsLen; ++i) {  IERC20Upgradeable(asset).safeTransferFrom(address(this), _to, amount); }  } 1",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "with more than 18 decimals are not supported INFO Tokens with more than 18 decimals are not supported, based on the SafetyTransfer library (outside the audit scope). function decimalsCorrection(address _token, uint256 _amount) internal view returns (uint256) if (_token == address(0)) return _amount; if (_amount == 0) return 0; uint8 decimals = ERC20Decimals(_token).decimals(); if (decimals < 18) { return _amount.div(10**(18 - decimals)); } return _amount; // Dedaub: more than 18 not supported correctly! { } We do not recommend trying to address this, as it may introduce other complexities for very lile practical benet. Instead, we recommend just being aware of the limitation.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "statement (consisting of a mere expression) INFO In BorrowingOperations::openVessel, the following expression (used as a statement!) is a no-op: vars.debtTokenFee;",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "external function, not called as expected INFO 1 BorrowerOperations::moveLiquidatedAssetToVessel appears to not be used in the protocol. // Send collateral to a vessel. Called by only the Stability Pool. function moveLiquidatedAssetToVessel( address _asset, uint256 _amountMoved, address _borrower, address _upperHint, address _lowerHint ) external override { _requireCallerIsStabilityPool(); _adjustVessel(_asset, _amountMoved, _borrower, 0, 0, false, _upperHint, _lowerHint); }",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "isInitialized flags INFO The following paern over storage variable isInitialized appears in several contracts but should be entirely unnecessary, due to the presence of the initializer modier. bool public isInitialized; function setAddresses(...) external initializer { require(!isInitialized);  isInitialized = true; } Contracts with the paern include FeeCollector, PriceFeed, ActivePool, CollSurplusPool, DefaultPool, SortedVessels, StabilityPool, VesselManager, VesselManagerOperations, CommunityIssuance, GRVTStaking.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "INFO 1 The codebase exhibits some old code paerns (which we do not recommend xing, since they directly mimick the Liquity trusted code):  The use of assert for condition checking (instead of require/ifrevert). (Some of the asserts have been replaced, but not all.)  The use of SafeMath instead of relying on Solidity 0.8.* checks.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "and error-prone use of this.* INFO Some same-contract function calls are made with the paern this.func(), which causes a new internal transaction and changes the msg.sender. This should be avoided for clarity and (gas) performance. In VesselManager: function isVesselActive(address _asset, address _borrower) public view override returns (bool) { return this.getVesselStatus(_asset, _borrower) == uint256(Status.active); } In PriceFeed (and also note the unusual convention of 0 = ETH): function _calcEthPrice(uint256 ethAmount) internal returns (uint256) { uint256 ethPrice = this.fetchPrice(address(0)); // Dedaub: Also, why the convention that 0 = ETH? return ethPrice.mul(ethAmount).div(1 ether); }  function _fetchNativeWstETHPrice() internal returns (uint256 price) { uint256 wstEthToStEthValue = _getWstETH_StETHValue(); OracleRecord storage stEth_UsdOracle = registeredOracles[stethToken]; price = stEth_UsdOracle.exists ? this.fetchPrice(stethToken) : _calcEthPrice(wstEthToStEthValue); _storePrice(wstethToken, price); } 1 Compatibility of PriceFeed::_fetchPrevFeedResponse,",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "with future versions of the Chainlink INFO Aggregator The roundId returned by the Chainlink AggregatorProxy contract is a uint80.The 16 most important bits keep the phaseId (incremented every time the underlying aggregator is updated) and the other 64 bits keep the roundId of the aggregator. As long as the underlying aggregator is the same, the roundId returned by the proxy will increase by one in each new round, but in an update of the aggregator contract the proxy roundId will increment not by 1, since the phaseId will also change. In this case the previous round is not current_roundId-1 and _fetchPrevFeedResponse will not return the price data from the previous round (which was a round of the previous aggregator). We mention this issue, although the probability that the protocol fetches a price at the time of an update of a Chainlink oracle is relatively small and each round lasts a few minutes to an hour. PriceFeed::_isValidResponse does all the validity checks necessary for the current Chainlink Aggregator version. Chaninlinks AggregatorProxy::latestRoundData returns also two extra values uint256 startedAt, uint80 answeredInRound, which, for the current version, do not hold extra information i.e. answeredInRound==roundId, but in past and possible future versions they could be used for some extra validity checks i.e. answeredInRound>=roundId.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "code In BorrowerOperations: function _requireNonZeroAdjustment( uint256 _collWithdrawal, uint256 _debtTokenChange, uint256 _assetSent ) internal view { require( INFO msg.value != 0 || _collWithdrawal != 0 || _debtTokenChange != 0 || 1 _assetSent != 0, \"BorrowerOps: There must be either a collateral change or a debt // Dedaub: `msg.value != 0` not possible change\" ); } the condition msg.value != 0 is not possible, as ensured in the single place where this function is called (_adjustVessel). The condition should be kept if the function is to be usable elsewhere in the future. Similarly, in VesselManager, the condition marked with a comment below seems unnecessary, given that the arithmetic is compiler-checked. function decreaseVesselDebt( address _asset, address _borrower, uint256 _debtDecrease ) external override onlyBorrowerOperations returns (uint256) { uint256 oldDebt = Vessels[_borrower][_asset].debt; if (_debtDecrease == 0) { return oldDebt; // no changes } uint256 paybackFraction = (_debtDecrease * 1 ether) / oldDebt; uint256 newDebt = oldDebt - _debtDecrease; Vessels[_borrower][_asset].debt = newDebt; if (paybackFraction > 0) { if (paybackFraction > 1 ether) { // Dedaub:Impossible. The \"-\" would have reverted, three lines above paybackFraction = 1 ether; } feeCollector.decreaseDebt(_borrower, _asset, paybackFraction); } return newDebt; } 1",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "ownable policy INFO Some contracts are dened to be Ownable (using the OZ libraries), yet do not use this capability (beyond initialization). These include:  StabilityPool initializes Ownable, relinquishes ownership, but never checks ownership in setAddresses, or elsewhere. function setAddresses( address _borrowerOperationsAddress, address _vesselManagerAddress, address _activePoolAddress, address _debtTokenAddress, address _sortedVesselsAddress, address _communityIssuanceAddress, address _adminContractAddress ) external initializer override {  __Ownable_init();  renounceOwnership(); // Dedaub: The function was onlyOwner in Liquity, here there's // no point of Ownable }  VesselManagerOperations inherits and initializes ownable functionality but is it used? function setAddresses( address _vesselManagerAddress, address _sortedVesselsAddress, address _stabilityPoolAddress, address _collSurplusPoolAddress, address _debtTokenAddress, address _adminContractAddress ) external initializer {  __Ownable_init(); // YS:! why? 2 }",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "explicit check in BorrowerOperations::openVessel that the collateral deposited by the user is approved INFO If a user aempts to open a Vessel with a collateral asset not approved by the owner, the transaction will fail, because there will be no price oracle registered for this asset. Therefore it is checked if the user deposits an approved collateral asset, but only indirectly. It would be beer if there was an explicit check.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "only partially initializes the collateralParams structure INFO We cannot nd a specic problem with the current only partial initialization, since even if the owner just adds a new _collateral and does not set all the elds of collateralParams[_collateral], upon opening a Vessel the protocol sets the default values for these. But, in general it is not a good practice to leave uninitialized variables and it would be beer if in addnewCollateral the owner also set the default values for the remaining collateralParams elements.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "internal functions INFO In StabilityPool, the following two functions are unused. function _requireUserHasVessel(address _depositor) internal view { address[] memory assets = adminContract.getValidCollateral(); uint256 assetsLen = assets.length; for (uint256 i; i < assetsLen; ++i) { if (vesselManager.getVesselStatus(assets[i], _depositor) == 1) { return; } } revert(\"StabilityPool: caller must have an active vessel to withdraw AssetGain to\"); 2 } function _requireUserHasAssetGain(address _depositor) internal view { (address[] memory assets, uint256[] memory amounts) = getDepositorGains(_depositor); for (uint256 i = 0; i < assets.length; ++i) { if (amounts[i] > 0) { return; } } revert(\"StabilityPool: caller must have non-zero gains\"); }",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "mistakes in names or comments INFO This issue collects several items, all supercial, but easy to x.  AdminContract: uint256 public constant PERCENT_DIVISOR_DEFAULT = 100; // dividing by 100 yields 0.5% // Dedaub: No, it yields 1%  AdminContract: function setAsDefaultWithRemptionBlock( // Dedaub: spelling  AdminContract: struct CollateralParams {  } uint256 redemptionBlock; // Dedaub: misnamed, its in seconds (We advise special caution, since the eld is set in two ways, so external callers may be confused by the name and pass a block number, whereas the calculation is in terms of seconds.)  StabilityPool: 2 // Internal function, used to calculcate ...  PriceFeed: * - If price decreased, the percentage deviation is in relation to the the  FeeCollector: function _createFeeRecord( address _borrower, address _asset, uint256 _feeAmount, FeeRecord storage _sRecord ) internal { uint256 from = block.timestamp + MIN_FEE_DAYS * 24 * 60 * 60; // Dedaub: `1 days` is the best way to write this, as done // elsewhere in the code",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "for gas optimization INFO Gas savings were not a focus of the audit, but there are some clear instances of repeat work or missed opportunities for immutable elds.  StabilityPool: function receivedERC20(address _asset, uint256 _amount) external override {   } totalColl.amounts[collateralIndex] += _amount; uint256 newAssetBalance = totalColl.amounts[collateralIndex]; The two highlighted lines (likely) perform two SLOADs and one SSTORE. Using an intermediate temporary variable for the sum will save an SLOAD.  DebtToken: the following variable is only set in constructor, could be declared immutable. address public timelockAddress; 2",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "constants INFO Our recommendation is for all numeric constants to be given a symbolic name at the top of the contract, instead of being interspersed in the code.  VesselManagerOperations::getRedemptionHints: collLot = collLot * REDEMPTION_SOFTENING_PARAM / 1000;  AdminContract::setAsDefaultWithRedemptionBlock: if (blockInDays > 14) { ...  BorrowerOperations::openVessel: contractsCache.vesselManager.setVesselStatus(vars.asset, msg.sender, 1); // Dedaub: 1 stands for \"active, but is obscure",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "inconsistent INFO Contract IDebtToken is not really an interface, since it contains full ER",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "functionality.",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Gravita/Gravita Audit, Apr. 23.pdf",
        "body": "allowed deviation between two consecutive oracle prices seems to be too high INFO In PriceFeed.sol there is a MAX_PRICE_DEVIATION_FROM_PREVIOUS_ROUND constant set to 5e17 i.e. 50%. If the percentage deviation of two consecutive Chainlink responses is greater than this constant, the protocol rejects the new price as invalid. But the value of this constant seems to be too high. Moreover, we think it would be beer if the protocol used a dierent MAX_PRICE_DEVIATION_FROM_PREVIOUS_ROUND for each collateral asset considering also the volatility of the asset. A23 Compiler bugs INFO 2 The code has the compile pragma ^0.8.10. For deployment, we recommend no floating pragmas, i.e., a xed version, for predictability. Solc version 0.8.10, specically, has some known bugs, which we do not believe to aect the correctness of the contracts. 2",
        "labels": [
            "Dedaub",
            "Gravita",
            "Severity: Informational"
        ]
    },
    {
        "title": "suggestions ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido on Kusama,Polkadot Delta Audit - Sep 22.pdf",
        "body": " INFO In the RelayEncoder.sol contract the function encode_withdraw_unbonded() uses several arithmetic operations with numbers that can be expressed as powers of 2. Thus, the multiplications and the divisions can be replaced with bitwise operations for more eiciency and maintainability. Furthermore, in Encoding.sol::scaleCompactUint:45 the 0xFF can be removed since the uint8() casting will give the same result even without the AND operation.",
        "labels": [
            "Dedaub",
            "Lido on Kusama,Polkadot Delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido on Kusama,Polkadot Delta Audit - Sep 22.pdf",
        "body": "for minor changes ACKNOWLEDGED The auditors appreciated the inclusion of tests for all major changes. It would be benecial to include tests also for smaller changes that seem to be missing (for instance we could not nd a test for the case totalXcKSMPoolShares == 0 and totalVirtualXcKSMAmount != 0). Although this check is minor, the fact that it was missing in the previous version makes it worthy of a test. A3 Compiler known issues INFO The code is compiled with Solidity 0.8.0 or higher. For deployment, we recommend no floating pragmas, i.e., a specic version, to be condent about the baseline guarantees 4 oered by the compiler. Version 0.8.0, in particular, has some known bugs, which we do not believe aect the correctness of the contracts",
        "labels": [
            "Dedaub",
            "Lido on Kusama,Polkadot Delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "his associates are not forced to remove their liquidity ",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Aug 2023.pdf",
        "body": " RESOLVED (8c905d) The owner can call Pool::setAllowed(user, false) to block the user from interacting with the protocol. This function also forces the user to remove his deposited 0 liquidity. Although not only the user but also his associates will not be able to interact with the protocol from now on, the associates are not forced to remove their liquidity.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Aug 2023.pdf",
        "body": "can take advantage of the non-symmetric conditions of transfer and transferFrom RESOLVED (8c905d) In LPToken::transfer the onlyAllowed modier is applied, which will revert the transaction if the owner has paused the trading. In LPToken::transferFrom this modier is not applied. The user can therefore call transferFrom, with his address as the from argument, to transfer tokens even if _tradingPaused == 1. M3 Minting and increasing the total supply are not executed in the right order RESOLVED (53a0452) The function LPToken::distributeFee executes the following operations (in this exact order):  Splits into two parts. One goes the fee amount to the protocol (protocolAmount) and the other to the LPs (lpAmount).  Mints protocolAmount of LP tokens for the protocolFeeRecipint  Increases the _totalSupply  Computes the new _ratio. The balanceOf(protocolFeeRecipient) immediately after the execution of this function will not be equal to protocolAmount, as someone would expect, but larger (new_ratio/old_rato*protocolAmount). The reason is that the new _ratio is computed after the LP tokens for the protocolFeeRecipient have been minted, therefore the lpAmount does not go exclusively to the LP providers but also part of it goes to the protocolFeeRecipient. LOW SEVERITY: [NO LOW SEVERITY ISSUES] 0 CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) [NO CENTRALISATION ISSUES] OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Medium"
        ]
    },
    {
        "title": "with more than 18 decimals are not supported ",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Aug 2023.pdf",
        "body": " RESOLVED (53a0452) The protocol uses 18 decimals for accounting. Whenever a computation involves an ER",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Aug 2023.pdf",
        "body": "with n decimals, its amount is multiplied by 10**(18-n), implicitly assuming that n will be less than 18. If n >18 the transaction will fail. Check was inserted to fail gracefully if n > 18. Potentially missing checks",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Aug 2023.pdf",
        "body": "(53a0452) 0  In Pool::stake/unstake one could check whether payAmount !=0 and revert otherwise.  In Pool::multiswap there is a missing check on the minReceiveAmounts array to ensure that it is the same length as the receiveTokens array. A3 Compiler bugs INFO The code is compiled with Solidity 0.8.19. Version 0.8.19, in particular, has some known bugs, which we do not believe aect the correctness of the contracts.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "already timed-up may not be taken into account if a preceding one hasnt expired ye ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Blur/Blur Finance delta Audit - Jan '23.pdf",
        "body": " RESOLVED The _computeUnlocked() function of the TokenLockup contract iterates over the schedules to calculate the unlocked amount of tokens based on the schedules which the contract has been initialized with. However, there is no guarantee that these schedules are in ascending order based on the endTime eld. As a result, a schedule which expires before its preceding one can lead to the amount of the schedule not being counted until the preceding one expires too. This happens due to the fact that the loop breaks once it reaches a schedule which hasnt expired yet. TokenLockup::_computeUnlocked() function _computeUnlocked( uint256 locked, uint256 time ) internal view returns (uint256) { ... for (uint i; i < scheduleLength; i++) { uint256 portion = schedule[i].portion; uint256 end = schedule[i].endTime; // Dedaub: Here the loop breaks once it finds a schedule // if (time < end) { that hasnt expired yet unlocked += locked * (time - start) * portion / ((end - start) * INVERSE_BASIS_POINTS); break; } else {  unlocked += locked * portion / INVERSE_BASIS_POINTS; start = end; } } return unlocked; } Hence, it could result in geing incorrect information about the unlocked tokens at any particular moment which can also lead to incorrect calculations of the voting power of the users. L2 Schedule portions are not checked whether they add up to 100% RESOLVED Every TokenLockup contract gets a list of schedules upon construction which will release portions of the unallocated tokens. However, there is no check to ensure that the provided portions add up to 100% so that the entire amount of tokens become claimable after an amount of time. TokenLockup::_computeUnlocked() function _computeUnlocked( uint256 locked, uint256 time ) internal view returns (uint256) { ... // Dedaub: This loop iterates over the schedules taking into account each schedules portion, but there is no check that they // all add up to 100% // for (uint i; i < scheduleLength; i++) { uint256 portion = schedule[i].portion; uint256 end = schedule[i].endTime; if (time < end) {  unlocked += locked * (time - start) * portion / ((end - start) * INVERSE_BASIS_POINTS); break; } else { unlocked += locked * portion / INVERSE_BASIS_POINTS; start = end; } } return unlocked; } CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) ",
        "labels": [
            "Dedaub",
            "Blur Finance delta",
            "Severity: Low"
        ]
    },
    {
        "title": "signicance of BlurToken::delegates should be clearly documented ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Blur/Blur Finance delta Audit - Jan '23.pdf",
        "body": " DISMISSED The issue was invalidated by the nal revision of the code. The delegates function was removed for gas savings. We reiterate our warning about counter-intuitive behavior (without the function) and the need for documentation and user awareness. The seemingly innocuous view function BlurToken::delegates is central to the correct functioning of the voting process. This should be documented, at least via a highly visible code comment (e.g., **WARN**). Specically, the function denition is:  BlurTokens::delegates() function delegates( address account ) public view override returns (address) { address _delegate = ERC20Votes.delegates(account); if (_delegate == address(0)) { _delegate = account; } return _delegate; } This seems to suggest the function is just a no-op convention: an account is itself its delegatee if it would otherwise have none. However, this logic is crucial ERC20Votes protocol. Specically, the protocol documentation warns: in the correct functioning of the OpenZeppelin * By default, token balance does not account for voting power. * This makes transfers cheaper. The downside is that it * requires users to delegate to themselves in order to activate * checkpoints and have their voting power tracked. The overridden delegates function in BlurToken achieves this exact purpose: causes every token transfer (which calls delegates() in the _afterTokenTransfer hook of the ERC20Votes contract) to update (checkpoint) the voting power of all parties. Without the denition of the delegates function, the behavior would be signicantly dierent:  a claim from a TokenLockup would result in lower votes than before (because the Blur token balanceOf would increase without being checkpointed into the votes), while the TokenLockup::balanceOf (which is accounted in BlurGovernor::getVotes) would decrease due to the higher totalClaimed;  correct updates of the voting power would require delegate calls;   gas consumption of BlurToken transfers would be lower.",
        "labels": [
            "Dedaub",
            "Blur Finance delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Blur/Blur Finance delta Audit - Jan '23.pdf",
        "body": "out-of-bounds access due to lack of length compatibility RESOLVED The fund() function of the TokenLockup.sol contract, iterates over the amounts[] array for sending the funds to the corresponding recipients. However, the two arrays provided as parameters are not checked for their length compatibility. Thus, if the amounts[] array is larger than the recipients[] one, the loop could try to access items out of bounds and revert.",
        "labels": [
            "Dedaub",
            "Blur Finance delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Blur/Blur Finance delta Audit - Jan '23.pdf",
        "body": "overrides RESOLVED The BlurGovernor.sol contract inherits from several other contracts and some functions should be overridden as they appear in more than one inherited contract. However, the following functions are not needed to be overridden:  votingDelay()  votingPeriod()  quorum(...)  propose(...) Moreover, the following contracts are also not needed to be declared in the inherited list as the rest of the contracts already inherit from them:  Governor  GovernorVotes",
        "labels": [
            "Dedaub",
            "Blur Finance delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Blur/Blur Finance delta Audit - Jan '23.pdf",
        "body": "number used in BlurExchange::setFeeRate() RESOLVED Ideally, numeric constants should be visible prominently at the top of a contract, instead of being buried in the code, for easier maintainability and readability. In this case: BlurExchange::setFeeRate() 1 function setFeeRate(uint256 _feeRate) external { require(msg.sender == governor, \"Fee rate can only be set by governor\"); // Dedaub: Magic constant require(feeRate <= 250, \"Fee cannot be more than 2.5%\"); ... } A5 Compiler bugs INFO The code is compiled with Solidity 0.8.17. Version 0.8.17, at the time of writing, hasnt any known bugs. 1",
        "labels": [
            "Dedaub",
            "Blur Finance delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "can be simplied from Uint32 to Bool ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Avely Finance/Avely Audit Report.pdf",
        "body": " RESOLVED In aZil, the eld tmp_buffer_exists_at_ssn is declared as Uint32: field tmp_buffer_exists_at_ssn: Uint32 = uint32_zero However, all writes to this eld are either 0 or 1, and all reads from it are followed up by an equality check with 0 and a match statement - the eld is a boolean  la C. It is recommended that the eld be declared Bool, in order to improve code readability and simplify the snippets that read from it.",
        "labels": [
            "Dedaub",
            "Avely",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Avely Finance/Avely Audit Report.pdf",
        "body": "assignment sequence can be simplied RESOLVED In the aZil.CalculateTotalWithdrawalBlock procedure, can be simplied: procedure CalculateTotalWithdrawalBlock(deleg_withdrawal: Pair ByStr20 Withdrawal) match deleg_withdrawal with | Pair delegator withdrawal => match withdrawal with | Withdrawal withdraw_token_amt withdraw_stake_amt => match withdrawal_unbonded_o with | Some (Withdrawal token stake) => updated_token = builtin add token withdraw_token_amt; updated_stake = builtin add stake withdraw_stake_amt; unbonded_withdrawal = Withdrawal updated_token updated_stake; withdrawal_unbonded[delegator] := unbonded_withdrawal | None => (* Dedaub: This branch can be simplified to withdrawal_unbonded[delegator] := withdrawal *) unbonded_withdrawal = Withdrawal withdraw_token_amt withdraw_stake_amt; withdrawal_unbonded[delegator] := unbonded_withdrawal end end end end The inner matchs None case can become: | None => withdrawal_unbonded[delegator] := withdrawal end",
        "labels": [
            "Dedaub",
            "Avely",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Avely Finance/Avely Audit Report.pdf",
        "body": "of multisig_wallet.RevokeSignature can be simplied DISMISSED In multisig_wallet, RevokeSignature can be simplied. The transition checks whether there are zero signatures through c_is_zero = builtin eq c zero; But for this line of code to execute exists signatures[transactionId][_sender]; must have already been true. Therefore it is guaranteed that there is at least one signature, and c_is_zero cannot be 0. Thus the following transition can be simplied: (* Revoke signature of existing transaction, if it has not yet been executed. *) transition RevokeSignature (transactionId : Uint32) sig <- exists signatures[transactionId][_sender]; match sig with | False => err = NotAlreadySigned; MakeError err | True => count <- signature_counts[transactionId]; match count with | None => err = IncorrectSignatureCount; MakeError err | Some c => c_is_zero = builtin eq c zero; match c_is_zero with | True => err = IncorrectSignatureCount; MakeError err | False => new_c = builtin sub c one; signature_counts[transactionId] := new_c; delete signatures[transactionId][_sender]; e = mk_signature_revoked_event transactionId; event e end end end end By replacing the Some c branch with the following: Some c => new_c = builtin sub c one; signature_counts[transactionId] := new_c; delete signatures[transactionId][_sender]; e = mk_signature_revoked_event transactionId; event e",
        "labels": [
            "Dedaub",
            "Avely",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Avely Finance/Avely Audit Report.pdf",
        "body": "of azil.DrainBuffer logic can be simplied RESOLVED Transition DrainBuffer of aZil also admits some simplication: a bind action can be factored out, since it occurs in both cases of a match, and another binding is redundant, both shown in comments below. transition DrainBuffer(buffer_addr: ByStr20) RequireAdmin; buffers_addrs <- buffers_addresses; is_buffer = is_buffer_addr buffers_addrs buffer_addr; match is_buffer with | True => FetchRemoteBufferExistsAtSSN buffer_addr; (* local_lastrewardcycle updated in FetchRemoteBufferExistsAtSSN *) lrc <- local_lastrewardcycle; RequireNotDrainedBuffer buffer_addr lrc; var_buffer_exists <- tmp_buffer_exists_at_ssn; is_exists = builtin eq var_buffer_exists uint32_one; match is_exists with | True => holder_addr <- holder_address; ClaimRewards buffer_addr; ClaimRewards holder_addr; RequestDelegatorSwap buffer_addr holder_addr; ConfirmDelegatorSwap buffer_addr holder_addr | False => holder_addr <- holder_address; (* Dedaub: This is also done in the True branch of the match *) ClaimRewards holder_addr end | False => e = BufferAddrUnknown; ThrowError e end; lrc <- local_lastrewardcycle; (* Dedaub: extraneous, it was already done above in the True case, and the False case is irrelevant *) buffer_drained_cycle[buffer_addr] := lrc; tmp_buffer_exists_at_ssn := uint32_zero end Buer/Holder have permissions for transitions they will never A5 execute DISMISSED As can be seen in the earlier transition graph, Buer is allowed to initiate aZil.CompleteWithdrawalSuccessCallBack but never will. Holder is allowed to initiate aZil.DelegateStakeSuccessCallBack but never will.",
        "labels": [
            "Dedaub",
            "Avely",
            "Severity: Informational"
        ]
    },
    {
        "title": "integration of ChickenBonds with BAMM allows limited nancial manipulation (aacker can get maximum discount ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/B.Protocol - Chicken Bonds Audit.pdf",
        "body": " RESOLVED (commit a55871ec takes the Curve LUSD, in virtual terms, also into account) BAMMSP holds not only LUSD, but also ETH from liquidations. Anyone can buy ETH at a discount, which depends on the relative amounts of LUSD and ETH of the BAMMSP. In essence, the larger the amount of ETH compared to LUSD, the larger the discount. An aacker could act as follows: call shiftLUSDFromSPToCurve of the Chicken Bond protocol, decrease the amount of LUSD in BAMMSP and then buy ETH at a greater discount. There are no restrictions on who can call the shiftLUSDFromSPToCurve function, but the shift of the LUSD amounts takes place only if the LUSD price in Curve is too high. If this condition is satised, the aacker can perform the aack in order to buy ETH at a maximum discount at no extra cost. If not, then the aacker should rst manipulate the price at Curve using a flashloan. The steps are the following: 1.Increase the price of LUSD in Curve pool - above the threshold which allows shift from the SP to Curve - possibly using a flashloan. 0 2. Call shiftLUSDFromSPToCurve and move as many LUSD as possible to increase the discount on ETH 3. Buy ETH from BAMMSP at a discount. 4. Repay the flashloan. This aack is protable in a specic price range for LUSD, close to the too high threshold (otherwise the cost of tilting the pool will likely outweigh any benet from the discount), and the discount is bounded (at 4%, based on the design documents we were supplied). Hence, we consider this only a medium-severity issue. A general consideration of the protability of the aack should consider: a) that the second step drops the price of LUSD in Curve, resulting in losses for the aacker when he repays the flashloan at the 4th step. the amount of ETH the aacker can buy from BAMMSP at discount is b) However, independent from the amounts in the Curve pool, therefore under some circumstances the discount may also compensate for the losses making the aack protable.",
        "labels": [
            "Dedaub",
            "B.Protocol - Chicken Bonds",
            "Severity: Medium"
        ]
    },
    {
        "title": "v3 TWAPs can be manipulated, and this will become much easier post-Merge DISMISSED A Uniswap v3 TWAP is expected to be used to price LQTY relative to ETH. Uniswap v3 TWAPs can be manipulated, especially for less-used pools. (There have been at least three instances of aacks already, for pools with liquidity in the low millions. The LQTY-ETH pool currently has $780K of liquidity.) Although currently manipulation for active pools is considered rarely protable, once Ethereum switches to proof-of-stake (colloquially, after the Merge) such manipulation will be much easier to perform with guaranteed prot. Specically, to manipulate a data point used for a Uniswap v3 TWAP, an aacker needs to control two consecutive pool transactions (i.e., transactions over the manipulated pool) that are in separate blocks. (This typically means the last pool transaction of a block and the rst of the next block.) Under Ethereum proof-of-stake, validators are known in advance (at the beginning of the epoch) hence an aacker 0 can know when they are guaranteed to control the validator of the next block. The aack is:  The aacker places the rst transaction as the last pool transaction of the previous block (either by being the validator of both blocks or using flashbots). The rst transaction tilts the pool.  The aacker is guaranteed to not suer any losses from swaps over the the tilted pool because the aacker controls the unrealistic price of immediately next block, prepending to it a transaction that restores the pool, while aecting a TWAP data point in this way. The issue is at most medium-severity, because it only concerns selling LQTY, not the principal assets of the contracts. M3 Values from Chainlink are not checked DISMISSED in The protocol does not check whether the LUSD-USD price is successfully returned from in Chainlink GemSeller::compensateForLusdDeviation. Since this price is used to adjust the amount of ETH or LQTY returned by a swap in BAMM and GemSeller respectively, it is important to ensure that the values from Chainlink are accurate and correct. BAMM::compensateForLusdDeviation and is This in contrast with how Chainlink ETH-USD prices are retrieved in BAMM::fetchPrice and GemSeller::fetchPrice, where each call to Chainlink is checked and any failures are reported using a return value of 0. LOW SEVERITY: [No low severity issues] CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with 0 a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have centralization threats.) ID Description N1 Owner can set parameters with nancial impact ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/B.Protocol - Chicken Bonds Audit.pdf",
        "body": " DISMISSED The owner of both the BAMM contract and the GemSeller contract can set several parameters with nancial impact. None is a major threat: the principal deposited by the Chicken Bonds protocol is safe, even if the owner of BAMM is malicious. However, some funds are at threat. Specically:  (BAMM) Owners can set the chicken address. The chicken address holds considerable control over the protocol, as it is the only address permied to withdraw or deposit funds in the system. However, since this address can only ever be set once, the risk posed is limited. Once this address is set to the ChickenBondManager contract from the LUSD Chicken Bonds Protocol, this will no longer be an issue, as ChickenBondManager is itself very decentralized.  (BAMM) Owners can set the gemSeller address. This is a centralization threat because gemSeller has innite approval for gem, in this case LQTY. However, this means that a malicious owner can only steal rewards, not principal. Furthermore, the gemSellerController makes use of a time lock system. This prevents the owner from immediately changing the address of the gemSeller. A new address will rst be stored as pending, and can only be set as the new gemSeller after a xed time period has elapsed. Once set, the gemSeller has maximum approval for all LQTY held in the B.AMM.  (BAMM and gemSeller) Owners can set parameters, including fee and A. The fee parameter is a threat, but is bounded by a maximum value (1% in BAMM, 10% in gemSeller). The A parameter only aects the discount given to buyers, which is bounded by a maximum, limiting the eect of any changes. 0 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "B.Protocol - Chicken Bonds",
            "Severity: Medium"
        ]
    },
    {
        "title": "in BAMM::constructor parameter ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/B.Protocol - Chicken Bonds Audit.pdf",
        "body": " RESOLVED Parameter address _fronEndTag should be address _frontEndTag.",
        "labels": [
            "Dedaub",
            "B.Protocol - Chicken Bonds",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/B.Protocol - Chicken Bonds Audit.pdf",
        "body": "function names when converting LUSD RESOLVED The functions gemSeller::gemToLUSD and gemSeller::LUSDToGem convert the given quantity of gem tokens to their LUSD value and vice versa. However, the functions both return the USD price of the gem asset, not the LUSD price (more accurately, the GEM-ETH and ETH-USD prices are used together). Although the protocol assumes that 1 LUSD is always equivalent to 1 USD, gemSeller::gemToUSD and gemSeller::USDToGem would be more accurate function names. A3 Compiler bugs INFO The code is compiled with Solidity 0.6.11. This version of the compiler has some known bugs, which we do not believe to aect the correctness of the contracts. 01",
        "labels": [
            "Dedaub",
            "B.Protocol - Chicken Bonds",
            "Severity: Informational"
        ]
    },
    {
        "title": "vulnerability in cancelOrde ",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": " OPEN OrderHandler::cancelOrder, which is an external function, is not protected by a reentrancy guard. Moreover, OrderUtils::cancelOrder (which performs the actual operation) transfers funds to the user (orderStore.transferOut) before updating its state. As a consequence, a malicious adversary could re-enter in cancelOrder, and execute an arbitrary number of transfers, eectively draining the contracts full balance in the corresponding token. function cancelOrder( DataStore dataStore, EventEmitter eventEmitter, OrderStore orderStore, bytes32 key, address keeper, uint256 startingGas ) internal { Order.Props memory order = orderStore.get(key); validateNonEmptyOrder(order); if (isIncreaseOrder(order.orderType()) || isSwapOrder(order.orderType())) { if (order.initialCollateralDeltaAmount() > 0) { orderStore.transferOut( EthUtils.weth(dataStore), order.initialCollateralToken(), order.initialCollateralDeltaAmount(), order.account(), order.shouldConvertETH() ); } } // Dedaub: state changed after the transfer, also idempotent orderStore.remove(key, order.account());  Note that the main re-entrancy method, namely the receive hook of an ETH transfer, is in fact protected by using payable(receiver).transfer which limits the gas available to the adversarys receive hook. Nevertheless, an ER",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Critical"
        ]
    },
    {
        "title": "transfer is an external contract call and should be assumed to potentially pass the execution to the adversary. For instance, an ERC777 token (which is ERC20 compatible) would implement transfer hooks that could easily be used to perform a reentrancy aack. Note also that the state update (orderStore.remove(key, order.account())) is idempotent, so it can be executed multiple times during a reentrancy aack without causing an error. To protect against reentrancy we recommend 1. Adding reentrancy guards, and 2. Execute all state updates before external contract calls (such as transfers). Note that (2) by itself is suicient, so reentrancy guards could be avoided if gas is an issue. In such a case, however, comments should be added to the code to clearly state that updates should be executed before external calls, to avoid a vulnerability being reintroduced in future restructuring of the code. HIGH SEVERITY: ID Description ",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "execution of orders using shouldConvertETH OPEN For all order types that involve ETH, a user can set the option shouldConvertETH =true to indicate that he wishes to receive ETH instead of WETH. Although convenient, this gives an adversary the opportunity to execute conditional orders in a very easy way. The adversary can simply use a smart contract as the receiver of the order, and set a receive function as follows:  contract Adversary { bool allow_execution = false; receive() { require(allow_execution); } } Then, in the time period between the order creation and its execution, the adversary can decide whether he wishes the order the allow_execution variable accordingly. If unset, the receive function will revert and the protocol will cancel the order. to succeed or not, and set The possibility of conditional executions could be exploited in a variety of dierent scenarios, a concrete example is given at the end of this item. Note that the use of payable(receiver).transfer (in Bank::_transferOutEth) does not protect against this aack. The 2300 gas sent by transfer are enough for a simple check like the one above. Note also that, although the case of ETH is the simplest to exploit, any tokens that use hooks to allow the receiver to reject transfers (eg ERC777) would enable the same aack. Note also that, if needed, the time period between creation and execution could be increased by simultaneously submiing a large number of orders for tiny amounts (see L2 below). One way to protect against conditional execution is to employ some manual procedure for recovering the funds in case of a failed execution (for instance, keeping the funds in an escrow account), instead of simply canceling the order. Since a failed execution should not happen under normal conditions, this would not aect the protocols normal operation. Concrete example of exploiting conditional executions: The adversary wants to take advantage of the volatility of ETH at a particular moment, but without any trading risk. Assume that the current price of ETH is 1000 USD, he proceeds as follows:  - He creates a market swap order A to buy ETH at the current price. In this order, he sets shouldConvertETH = true and the receive function above that conditionally allows the execution. - He also creates a limit order B to sell ETH at 1010 USD. He then monitors the price of ETH before the orders execution: - If ETH goes down, he does nothing. allow_execution is false so order A will fail, and order B will also fail since the price target is not met. - If ETH goes up, he sets allow_execution = true, which leads to both orders succeeding for a prot of 10 USD / ETH. 9 MEDIUM SEVERITY: ",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: High"
        ]
    },
    {
        "title": "handling of rebalancing token ",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": " OPEN StrictBank::recordTokenIn computes the number of received tokens by comparing the contract's current balance with the balance at the previous execution. However, this approach could lead to incorrect results in the case of ER",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "with non-standard behavior, for instance: - Tokens in which balances automatically increase (without any transfers) to include interest. - Tokens that allow interacting from multiple contract addresses To be more robust with respect to such types of tokens, we recommend comparing the balance before and after the current incoming transfer, and not between dierent transactions.",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "bad debt aack OPEN The protocol is susceptible to an aack involving opening a delta neutral position using Sybil accounts, with maximum leverage, on a volatile asset. Scenario: 1. Aacker controls Alice and Bob 2. Alice opens a large long position with maximum leverage 3. Bob opens a large short position with maximum leverage 4. Market moves 5. Alice liquidates their underwater position, causing bad debt 6. Bob closes their other position, proting on the slippage The reason why this aack is possible is that using the current design, it takes multiple blocks for a liquidator to react and by that time their order is executed it is possible that one of the positions is underwater. Secondly, when liquidating, Alice does not suer a bad price from the slippage incurred in the liquidation but Bob benets from the 1 slippage, when closing their position just after. Another factor that contributes towards this aack is that the liquidation penalty is linear, while the price impact advantage is higher-order, making the aack increasingly protable the larger the positions. To deter this, the protocol could support (i) partial liquidations for large positions and therefore force the positions to be closed gradually, making the aack non-viable, and, (ii) slippage open-interest calculations used to determine the price of the liquidation. LOW SEVERITY:",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "receive function OPEN OrderStore does not contain a receive function so it cannot receive ETH. However, this is needed by Bank::_transferOutEth, which withdraws ETH before sending it to the receiver. function _transferOutEth(address token, uint256 amount, address receiver) internal { require(receiver != address(this), \"Bank: invalid receiver\"); IWETH(token).withdraw(amount); payable(receiver).transfer(amount); _afterTransferOut(token); } WIthout a receive function any transaction with shouldConvertETH = true would fail. 1",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "lower bounds for swaps and positions OPEN Since there are no lower bounds for the size of a position, someone could in principle create a large number of tiny orders. Such a strategy would cost the adversary only the gas fees and the total amount of the requested positions, which can be as small as he wishes. In this 2-step procedure used in this version of the protocol, such a behavior could potentially create a problem, because the order keepers would have to execute a huge number of orders. We suggest seing a minimum size for positions and swaps. L3 Inconsistency in calculating liquidations OPEN The comment in PositionUtils::isPositionLiquidatable indicates that price impact is not used when computing whether a position is liquidatable. However, the price impact is in fact used in the code: // price impact is not factored into the liquidation calculation // if the user is able to close the position gradually, the impact // may not be as much as closing the position in one transaction function isPositionLiquidatable( DataStore dataStore, Position.Props memory position, Market.Props memory market, MarketUtils.MarketPrices memory prices ) internal view returns (bool) { ... int256 priceImpactUsd = PositionPricingUtils.getPriceImpactUsd(...)  int256 remainingCollateralUsd = collateralUsd.toInt256() + positionPnlUsd + priceImpactUsd + fees.totalNetCostAmount; 1 On the other hand, when the liquidation is executed, the price impact is not used. The comment in DecreasePositionUtils::processCollateral indicates that this is intentional: // the outputAmount does not factor in price impact // for example, if the market is ETH / USD and if a user uses USDC to long ETH // if the position is closed in profit or loss, USDC would be sent out from or // added to the pool without a price impact // this may unbalance the pool and the user could earn the positive price impact // through a subsequent action to rebalance the pool // price impact can be factored in if this is not desirable If this inconsistency is intentional, it should be properly documented in the comments. Note that, when deciding on a liquidation strategy, you should have in mind the possibility of cascading liquidations, namely the possibility that executing a liquidation causes other positions to become liquidatable. CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) 1 ",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "keepers can cause DoS in all operations OPEN Due to the two step execution system, any operation requires an order keeper to execute it. Trust is needed in that order keepers will timely execute all pending orders. If the order keeper does not submit execution transactions, all operations will cease to function, including closing positions and withdrawing funds. It would be benecial to implement fallback mechanisms that guarantee that users can at least withdraw their funds in case order keepers cease to function for any reason. For instance, the protocol could allow users to execute orders by providing oracle prices themselves, but only if an order is stale (a certain time has passed since its creation). N2 Order keepers can frontrun/reorder transactions There is nothing in the current system that prevents an order keeper from front-running or reordering transactions, for instance to exploit changes in the price impact. The protocol could include mechanisms that limit this possibility: for instance, the order keeper could be forced to execute orders in the same order they were created. OTHER / ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Informational"
        ]
    },
    {
        "title": "erroneous computation of price impact ",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": " INFO 1 imbalance) ^ (price impact exponent) * (price impact factor) - (next Price impact is calculated as (initial imbalance) ^ (price impact exponent) * (price impact factor) The values of exponent (e) and impact factor (f) are set by the protocol for each market. If the impact factor is simply a percentage, then the price impact will have units USD^(price impact exponent). But this seems erroneous, since price impact is treated as a USD amount which is nally added to the amount requested by the user. A problem arises in case that these two quantities are selected independently of each other but also of the pool's deposits and status. For example, consider a pool with tokens A and B of total USD value x and y respectively. Consider that x < y. Then the imbalance equals d = y - x. If a user swaps A tokens of worth d/2, then prior to the price impact he will get B tokens of the same value. The new deposits of the pool will now be x'=y'=(x+y)/2 and the pool will become balanced. The price impact for this transaction is f*d^e, which could be ( if the parameters are not chosen carefully) larger than d/2, which is the requested swap amount. Also, this fact could lead to a pool which is even more imbalanced than the previous state. We suggest that (total_deposits)^(e-1)*f always be less than 1 to avoid the above mentioned undesirable behavior.",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "in the submission time of dierent tokens INFO Price keepers are responsible for submiing prices for most of the protocol's tokens. The submied price should be the price retrieved from exchange markets at the time of each order's creation (the median of all these prices is nally used). However, for some tokens Chainlink oracles are used. In this case, the price at the time of the order execution is used.",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "user can liquidate its own position INFO there is nothing preventing a user ExchangeRouter::createLiquidation can be called only by liquidation keepers. However, from calling createOrder with orderType=Liquidation, eectively creating a liquidation order for their own position. Although this is not necessarily an issue, it is unclear whether this functionality is intentional or not. 1",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GMX/GMX Audit - Oct '22.pdf",
        "body": "price impacts on large markets INFO The price impact calculation is a function with an exponential factor of the absolute dierences between open long and short interests before and after a trade. This works well for the average market, but on a large market with large open interests, it is not more eicient to open large positions. Consider that in other AMM designs, it is possible to open large positions with minimal price impact if the market is large (e.g., Uniswap ETH-USDC). A5 Known compiler bugs INFO The code can be compiled with Solidity 0.8.0 or higher. For deployment, we recommend no floating pragmas, but a specic version, to be condent about the baseline guarantees oered by the compiler. Version 0.8.0, in particular, has some known bugs, which we do not believe aect the correctness of the contracts. 1",
        "labels": [
            "Dedaub",
            "GMX",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "may irreversibly delete essential data DISMISSED Oracle::setNodeIDList deletes reportsByEpochId[latestEpochId], i.e., the latest epoch data, as they might no longer be valid due to validators being removed from the list. The latest epoch data is supplied to the Oracle contract via the OracleManager, which calls the function Oracle::receiveFinalizedReport and marks that the report for that epoch has been nalized, meaning that it cannot be resubmied. This information, which might irreversibly get deleted by the Oracle::setNodeIDList, is essential for the ValidatorSelector contract to proceed with the validator selection process. Thus, care should be taken to ensure that Oracle::setNodeIDList isnt called after OracleManager::receiveMemberReport and before ValidatorSelector::getAvailableValidatorsWithCapacity, as such a sequence of calls would leave the system in an invalid state.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "may revert due to array out-of-bounds error in ValidatorSelector::getAvailableValidatorsWithCapacity RESOLVED Function ValidatorSelector::getAvailableValidatorsWithCapacity retrieves the latest epoch validators from the Oracle in the validators array, computes how 0 many of those satisfy the ltering criteria and then creates an array of that size, result, and traverses again the validators array to populate it. function getAvailableValidatorsWithCapacity(uint256 amount) public view returns (Validator[] memory) { Validator[] memory validators = oracle.getLatestValidators(); uint256 count = 0; for (uint256 index = 0; index < validators.length; index++) { // ... (filtering checks on validators[index]) count++; } Validator[] memory result = new Validator[](count); for (uint256 index = 0; index < validators.length; index++) { // ... (filtering checks on validators[index]) // Dedaub: index can get bigger than result.length. // Dedaub: a count variable needs to be used as in the above loop. result[index] = validators[index]; } return result; } However, there is a bug in the implementation that can cause an array out-of-bounds exception at line result[index] = validators[index]. Variable index is in the range [0, validators.length-1], while result.length will be strictly less than validators.length-1 if at least one validator has been ltered out of the initial validators array, thus index might be greater than result.length-1. Consider the scenario where validators = [1, 2] and count (or result.length) is 1 as the validator with id 1 has been ltered out. Then the second loop will traverse the whole validators array and will try to assign the validator with id 2 (array index 1) to result[1] causing an out-of-bounds exception, as result has a length of 1 (can only be assigned to index 0). Using a count variable, similarly to the rst loop, would be enough to solve this issue. 0",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "due to the ability of a group to conrm any public key RESOLVED A DoS aack could be possible due to the ability of a group to perform conrmations for any given public key. More specically, we think that a group with adversary members can front-run the reportGeneratedKey() using a public key which was requested by another group, via requestKeygen(). By doing so, this public key will be conrmed by and assigned to the adversary group. // MpcManager.sol::reportGeneratedKey:214 if (_generatedKeyConfirmedByAll(groupId, generatedPublicKey)) { info.groupId = groupId; info.confirmed = true; ... } This will DoS the system for the benevolent group which will not be able to perform any further conrmations for this public key. // MpcManager.sol::reportGeneratedKey:208 if (info.confirmed) revert AttemptToReconfirmKey(); The adversary group can then proceed with joining the staking request changing the threshold needed for starting the request (of course in the case where the adversary group has a smaller threshold than the original one). // MpcManager.sol::joinRequest:238 uint256 threshold = _groupThreshold[info.groupId]; However, they dont have to join the request and can leave it pending. Since multiple public keys can be requested for the same group, they can proceed with dierent keys and dierent stake requests if they wish to interact with the contracts benevolently for their own benet. 0 The MpcManager.sol contract has quite a bit of o-chain logic, but we believe that it is valid as an adversary model to assume that groups can not be entirely trusted and that they can act adversely against other benevolent groups. In the opposite scenario, considering all groups as trusted could lead to centralization issues while only the MPC manager can create the groups.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "can be called by a member of RESOLVED any group with any generated public key MpcManager::reportUTXO() does not contain any checks to ensure that the member which calls it is a member of the group that reported and conrmed the provided genPubKey. This means that a member of any group can call this function with any of the generated public keys even if the laer has been conrmed by and assigned to another group. By doing so, a group can run reportUTXO() changing the threshold needed for the report to be exported. It is not clear from the specication if allowing any member to call this function with any public key is the desired behaviour or if further checks should be applied.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Medium"
        ]
    },
    {
        "title": "number of remaining TODO items suggest certain functionality is not implemented RESOLVED There are a number of TODO items that spread across the entire codebase and test suite. Most of these TODOs are trivial and the test suite appears to be well developed. However, there is a small number of TODOs that concern checks and invariants and also unimplemented functionality like supporting more types of validator requests. This could mean that further development is needed, which could render the current security assessment partially insuicient. 010 LOW SEVERITY: ID Descriptio ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "claim of AVAX might result in rounding errors RESOLVED According to a note in the AvaLido::claim function, the protocol allows partial claims of unstake requests so that users don't need to wait for the entire request to be lled to get some liquidity. This is one of the reasons the exchange rate stAVAX:AVAX is set in function requestWithdrawal instead of in claim. The partial claim logic is implemented mainly in the following line: uint256 amountOfStAVAXToBurn = Math.mulDiv(request.stAVAXLocked, amount, request.amountRequested); The amount of stAVAX that are traded back, request.stAVAXLocked, is multiplied by the amount of AVAX claimed, amount, and the result is divided by the whole AVAX amount corresponding to the request, request.amountRequested to give us the corresponding amount of stAVAX that should be burned. This computation might suer from rounding errors depending on the amount parameter, leading to a small amount of stAVAX not being burned. We believe that these amounts would be too small to really aect the exchange rate of stAVAX:AVAX, still it would make sense to verify this or get rid of the rounding error altogether.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "might fail due to uninitialized variable RESOLVED Function Treasury::claim could be called while the avaLidoAddress storage variable might not have been set via the setAvaLidoAddress, leading to the transaction reverting due to msg.sender not being equal to address(0). This outcome can of course be considered desirable, but at the same time, the needed call to setAvaLidoAddresss adds unnecessary complexity. Currently, the setAvaLidoAddress function works practically as an initializer, as it cannot set the 01 avaLidoAddress storage variable more than once. If that is the intent, avaLidoAddress could be set in the initialize function, which would reduce the chances of claim and successively of AvaLido::claimUnstakedPrincipals and AvaLido::claimRewards calls reverting. L3 AvaLido::deposit check considers deposited amount twice RESOLVED The function AvaLido::deposit implements the following check: if (protocolControlledAVAX() + amount > maxProtocolControlledAVAX) revert ProtocolStakedAmountTooLarge(); However, the check should be changed to: if (protocolControlledAVAX() > maxProtocolControlledAVAX) revert ProtocolStakedAmountTooLarge(); as the function protocolControlledAVAX() uses address(this).balance, meaning that amount, which is equal to the msg.value, has already been taken into account once and if added to the value returned by protocolControlledAVAX(), it would be counted twice. Nevertheless, we expect that both conditions would never be satised as maxProtocolControlledAVAX is by default set to type(uint256).max. Still, we would advise addressing the issue just in case maxProtocolControlledAVAX is changed in the future. 01 CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) The protocol denes several admin/manager roles that serve to give access to specic functions of certain contracts only to the appropriate entities. The following roles are dened and used:  DEFAULT_ADMIN_ROLE  ROLE_PAUSE_MANAGER  ROLE_FEE_MANAGER  ROLE_ORACLE_ADMIN  ROLE_VALIDATOR_MANAGER  ROLE_MPC_MANAGER  ROLE_TREASURY_MANAGER  ROLE_PROTOCOL_MANAGER For example, the entity that is assigned the ROLE_MPC_MANAGER is able to call functions MpcManager::createGroup and MpcManager::requestKeygen that are essential for the correct functioning of the MPC component. Multiple roles allow for the distribution of power so that if one entity gets hacked all other functions of the protocol remain unaected. Of course, this assumes that the protocol team distributes the dierent roles to separate entities thoughtfully and does not completely alleviate centralization issues. The contract MpcManager.sol appears to build on/depend on a lot of o-chain logic that could make it suer from centralization issues as well. A possible aack scenario is described in issue M3 above that raises the question of credibility for the MPC groups even though they can only be created by the MPC manager. 01 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Low"
        ]
    },
    {
        "title": "array of public keys provided to MpcManager::createGroup needs to be sorted ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": " RESOLVED The array of public keys provided to MpcManager::createGroup by the MPC manager needs to be sorted otherwise the groupId produced by the keccak256 of the array might be dierent for the same sets of public keys. As sorting is tricky to perform on-chain and has not been implemented in this instance, the contracts API or documentation should make it clear that the array provided needs to be already sorted.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "in AvaLido::llUnstakeRequests is always true RESOLVED The following check in AvaLido::fillUnstakeRequests is expected to be always true, since the isFilled check right before guarantees that the request is not lled. if (isFilled(unstakeRequests[i])) { // This shouldn't happen, but revert if it does for clearer testing revert(\"Invalid state - filled request in queue\"); } // Dedaub: the following is expected to be always true if (unstakeRequests[i].amountFilled < unstakeRequests[i].amountRequested) { ... } 01",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "responsible for seing/updating numeric protocol parameters could dene bounds on these values INFO Functions like AvaLido::setStakePeriod and AvaLido::setMinStakeAmount could set lower and/or upper bounds for the accepted values. Such a change might require more initial thought but could protect against accidental mistakes when seing these parameters.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "might revert with ClaimTooLarge error INFO The function AvaLido::claim checks that the amount requested, amount, is not greater than request.amountFilled - request.amountClaimed. The user experience could be improved if in such cases instead of reverting the claimed amount was set to request.amountFilled - request.amountClaimed, i.e., the maximum amount that can be claimed at the moment. Such a change would require the claim function to return the claimed amount.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "storage variables RESOLVED There are a few storage variables that are not used:  ValidatorSelector::minimumRequiredStakeTimeRemaining  AvaLido::mpcManagerAddress",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "UnstakeRequest struct eld RESOLVED Field requestedAt of struct UnstakeRequest is not used.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "can be made external RESOLVED OracleManager::getWhitelistedOracles can be dened as external instead of public, as it is not called from any code inside the OracleManager contract.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "optimization RESOLVED 01 In function AvaLido::claimUnstakedPrincipals there is a conditional check that if true leads to the transaction reverting with InvalidStakeAmount(). function claimUnstakedPrincipals() external { uint256 val = address(pricipalTreasury).balance; if (val == 0) return; pricipalTreasury.claim(val); // Dedaub: the next line can be moved before the claim if (amountStakedAVAX == 0 || amountStakedAVAX < val) revert InvalidStakeAmount(); //  (rest of the functions logic) } This check could be moved before the principalTreasury.claim(val) as it is not aected by the call. This would lead to gas savings in cases where the transaction reverts, as the unnecessary call to treasury would be skipped.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "contradicts with ValidatorSelector::minimumRequiredStakeTimeRemaining RESOLVED Even though ValidatorSelector::minimumRequiredStakeTimeRemaining is not used, it is dened as 15 days, while AvaLido::stakePeriod is dened as 14 days.",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido Avalanche Audit - July 22.pdf",
        "body": "spelt function name RESOLVED Function name hasAcceptibleUptime of the Types.sol contract should be corrected to hasAcceptableUptime. A11 Compiler bugs INFO The code is compiled with Solidity 0.8.10, which, at the time of writing, has some known bugs, which we do not believe to aect the correctness of the contracts. 01",
        "labels": [
            "Dedaub",
            "Lido Avalanche",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Primitive Finance/Primitive Finance V2.pdf",
        "body": "margins mapping indexing in SwapManager::swap RESOLVED Method SwapManager::swap performs an internal balance deposit on the margins mapping when params.toMargin evaluates to true. The margins mapping is a double mapping, going from a PrimitiveEngine address to a user address to the users margin. Instead of indexing the rst mapping with params.engine and the second with msg.sender, indexing is implemented the other way around, leading to invalid PrimitiveHouse state. H2 Incorrect margin deposit value in SwapManager::swap RESOLVED There is a second issue with the margins mapping update operation in SwapManager::swap (the one discussed in issue H1). The deposited amount of tokens is deltaIn instead of deltaOut, which creates inconsistency between the states of PrimitiveEngine and PrimitiveHouse and in general is not consistent with the protocols logic. The following snippet addresses both this issue and issue H1: if (params.toMargin) { margins[params.engine][msg.sender].deposit( params.riskyForStable ? params.deltaOut : 0, params.riskyForStable ? 0 : params.deltaOut ); } 0 [After our report, the Primitive Finance team identied that the deltaOut amount was deposited in the wrong margin, i.e., deltaOut risky in stable margin and the other way around. Consequently, the above example has the ternary operator result expressions inverted in its nal form.] MEDIUM SEVERITY: [No medium severity issues] LOW SEVERITY: ",
        "labels": [
            "Dedaub",
            "Primitive Finance V2",
            "Severity: High"
        ]
    },
    {
        "title": "Flash-Loan Functionality ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Primitive Finance/Primitive Finance V2.pdf",
        "body": " DISMISSED PrimitiveEngine::swap can be actually used to get flash loans from the Primitive reserves. However, this functionality is not documented and may have been implemented by mistake. One can get flash loans by implementing a contract with the swapCallback function. When this gets called by the engine, the output ER",
        "labels": [
            "Dedaub",
            "Primitive Finance V2",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Primitive Finance/Primitive Finance V2.pdf",
        "body": "have already been transferred to the engine contract, and all that is required for the rest of the transaction to succeed is to transfer the input tokens back.",
        "labels": [
            "Dedaub",
            "Primitive Finance V2",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Primitive Finance/Primitive Finance V2.pdf",
        "body": "Multicall Error Handling OPEN The Multicall error handling mechanism assumes a xed ABI for error messages. This would have worked in Solidity 0.7.x for the default Error(string) ABI. However, Solidity has custom ABIs for 0.8.x that can encode valid errors with a shorter returndata. The correct way to propagate errors is to re-raise them (e.g., by copying the returndata to the revert input data). 0",
        "labels": [
            "Dedaub",
            "Primitive Finance V2",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Primitive Finance/Primitive Finance V2.pdf",
        "body": "Reserve Balance Mechanisms DISMISSED The balances of the two reserve tokens in the engine are sometimes tracked by incrementing/decrementing internal counters and sometimes by checking balanceOf(). This not only causes the system to read more storage locations, and thus consume more gas, but it also automatically disqualies tokens that have dynamic balances such as aTokens. Fixed Swap Fee Might Not Compensate Theta Decay For All L4 Asset Pairs SPEC CHANGED Options, manifesting themselves as asset pairs of dierent types will encode dierent proportions of intrinsic and extrinsic value. Although the swap fee is meant to compensate for theta decay, it seems strange that this cannot be set per curve or per token pair. We note however that other important parameters such as sigma are customizable. 0 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "Primitive Finance V2",
            "Severity: Low"
        ]
    },
    {
        "title": "always returns true ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Primitive Finance/Primitive Finance V2.pdf",
        "body": " RESOLVED Transfers::safeTransfer return value is always true (as noted in a comment), thus can be removed as an optimization.",
        "labels": [
            "Dedaub",
            "Primitive Finance V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Primitive Finance/Primitive Finance V2.pdf",
        "body": "zero liquidity check in PrimitiveEngine::remove RESOLVED PrimitiveEngine::remove does not revert in case of 0 provided liquidity, which leads to unnecessary computation and gas fee for the user. PrimitiveHouse::remove implements an early check for such a scenario.",
        "labels": [
            "Dedaub",
            "Primitive Finance V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Primitive Finance/Primitive Finance V2.pdf",
        "body": "Bookkeeping and Transfers DISMISSED The architecture as it currently stands, and the relationship between PrimitiveHouse and PrimitiveEngine causes multiple token transfers to intermediate contracts, and multiple layers of bookkeeping, with some redundancy. This causes the application to consume more gas. DISMISSED: The specic architecture is highly desired by the protocol developers. Nevertheless, a few transfer operations have been optimized. A4 No engine-risky-stable sanity check in PrimitiveHouse RESOLVED create and allocate methods In PrimitiveHouse::create and PrimitiveHouse::allocate the user has to provide the PrimitiveEngine address and the addresses of the risky and stable tokens, while there is no early check that ensures the pair of risky and stable tokens provided corresponds to the engine address. This check is implemented in the respective callback functions, maintaining the security of the protocol. However, the 0 execution of the contract will only revert at such a late point (i.e., in the callback) even if a user provides a wrong engine, risky and stable tokens triplet by mistake, leading to unnecessary gas consumption, which could have been avoided with an early check. 0",
        "labels": [
            "Dedaub",
            "Primitive Finance V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor arShield audit Jun 21.pdf",
        "body": "tokens conversion Status Resolved In the following code snippet taken from arShield::liqAmts amounts ethOwed and tokensOwed are supposed to represent equal value. ethOwed = covBases[_covId].getShieldOwed( address(this) ); if (ethOwed > 0) tokensOwed = oracle.getTokensOwed(ethOwed, address(pToken), uTokenLink); tokenFees = feesToLiq[_covId]; tokensOwed += tokenFees; require(tokensOwed > 0, \"No fees are owed.\"); uint256 ethFees = ethOwed > 0 ? ethOwed * tokenFees / tokensOwed : getEthValue(tokenFees); ethOwed += ethFees; However, code line tokensOwed += tokenFees; is misplaced resulting in an underpriced ethFees computation. We suggest that it be altered as follows: ethOwed = covBases[_covId].getShieldOwed( address(this) ); if (ethOwed > 0) tokensOwed = oracle.getTokensOwed(ethOwed, address(pToken), uTokenLink); tokenFees = feesToLiq[_covId]; require(tokensOwed + tokenFees > 0, \"No fees are owed.\"); 5 uint256 ethFees = ethOwed > 0 ? ethOwed * tokenFees / tokensOwed : getEthValue(tokenFees); ethOwed += ethFees; tokensOwed += tokenFees; for accuracy. H2 Duplicate subtraction of fees amount Resolved In arShield::payAmts the new ethValue is calculated as follows: // Ether value of all of the contract minus what we're liquidating. ethValue = (pToken.balanceOf( address(this) ) // Dedaub: _tokenFees amount is subtracted twice - _tokenFees - totalFeeAmts()) * _ethOwed / _tokensOwed totalFeeAmounts() also considers all liquidation fees, resulting in _tokenFees being subtracted twice. This can cause important harm to the protocol, as the total value of coverage purchased is underestimated. 6 Medium Severity ",
        "labels": [
            "Dedaub",
            "Armor arShield",
            "Severity: High"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor arShield audit Jun 21.pdf",
        "body": "variable name We suggest that variable totalCost Status Resolved // Current cost per second for all Ether on contract. uint256 public totalCost; is renamed to totalCostPerSec for clarity.",
        "labels": [
            "Dedaub",
            "Armor arShield",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor arShield audit Jun 21.pdf",
        "body": "version of SafeMath library Resolved The code of the SafeMath library included is of an old version of compiler (< 0.8.0) being set to pragma solidity 0.8.4. However, compiler versions of 0.8.* revert on overow or underow, so this library has no effect. We suggest ArmorCore.sol not use this library and substitute SafeMath operations to normal ones, as well as SafeMath.sol contract be completely removed.",
        "labels": [
            "Dedaub",
            "Armor arShield",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor arShield audit Jun 21.pdf",
        "body": "comment Resolved In arShield.sol function confirmHack has a misleading @dev comment: /** * Dedaub: used by governor, not controller * @dev Used by controller to confirm that a hack happened, which then locks the contract in anticipation of claims. **/ function confirmHack( uint256 _payoutBlock, uint256 _payoutAmt ) external isLocked onlyGov 9 A4 Extra protection of refunds in arShield Resolved Function CoverageBase::DisburseClaim is called by governance and transfers ETH amount to a selected _arShield, that is supposed to be used for claim refunds. /** * @dev Governance may disburse funds from a claim to the chosen shields. * @param _shield Address of the shield to disburse funds to. * @param _amount Amount of funds to disburse to the shield. **/ function disburseClaim( address payable _shield, uint256 _amount ) { external onlyGov require(shieldStats[_shield].lastUpdate > 0, \"Shield is not authorized to use this contract.\"); _shield.transfer(_amount); } We suggest that an extra requirement be added, checking that _shield is locked. In the opposite case the ETH amount transferred to the arShield contract as refunds can be immediately transferred to the beneciary. arShields contract locking/unlocking and disburseClaim() are all government-only actions, however this suggestion ensures security in case of false ordering of the governance transactions. 10",
        "labels": [
            "Dedaub",
            "Armor arShield",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Solid World/Solid World Audit - May '23.pdf",
        "body": "Stake event does not capture the msg.sender WONT FIX The SolidStaking Stake event captures the recipient account but not the msg.sender, thus this piece of information is not recorded if the recipient is not also the msg.sender. A2 LiquidityDeployer::getTokenDepositors can be optimized to save gas WONT FIX The function LiquidityDeployer::getTokenDepositors copies the depositors array from storage to memory by performing a loop over each element of the array instead of just returning the array. LiquidityDeployer::getTokenDepositors function getTokenDepositors() external view returns (address[] memory tokenDepositors) { } tokenDepositors = new address[](depositors.tokenDepositors.length); for (uint i; i < depositors.tokenDepositors.length; i++) { tokenDepositors[i] = depositors.tokenDepositors[i]; } By changing the code to:  function getTokenDepositors() external view returns (address[] memory tokenDepositors) { } return depositors.tokenDepositors; the cost of calling getTokenDepositors is reduced by 33% and the deployment cost of the LiquidityDeployer is reduced by ~1.5%.",
        "labels": [
            "Dedaub",
            "Solid World",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "adversary can alter the amount in Distributor.deposit Resolved (but since entire VestingNFTReceiver is removed, similar threats need to be considered in the context of the new architecture upon future audits) Distributor::deposit computes the withdrawAmount by comparing the balance before and after the transfer: uint256 initialBalance = _thisBalance(token); if (token == NATIVE_ASSET) { payable(receiver).sendValue(amount); } else { token.safeTransfer(receiver, amount); } uint256 finalBalance = _thisBalance(token); require(initialBalance > finalBalance, \"Distributor: did not withdraw\"); uint256 withdrawAmount = initialBalance - finalBalance; An adversary who controls the deposit of funds to the distributor can start withdrawing, and deposit funds back to the distributor from within his receive hook. This will cause the distributor to register a possibly much smaller withdrawAmount than the amount actually withdrawn. When used in combination with vestingNFTReceiver, an attack can be executed as follows:  First, the adversary withdraws an amount from vesting into the distributor, by calling VestingNFTReceiver::withdraw via Distributor::call  Then the adversary starts withdrawing the same amount from the distributor (even if the amount is larger than his own share)  From within his receive hook, the adversary releases an equal amount (minus 1 wei) from vesting to the distributor (again by calling VestingNFTReceiver::withdraw via Distributor::call)  As a result, the distributor registered a withdrawal of just 1 wei, and the adversary can withdraw again. Using the above procedure, an adversary with only 1% share can withdraw all funds from the distributor in a single transaction. An exploit of this vulnerability has been implemented and will be provided together with this report. 5 This vulnerability can be prevented by a cross-contract lock that prevents entering VestingNFTReceiver::withdraw while Distributor::withdraw is active. A lighter (but less robust) solution is to add the following check: require(withdrawAmount >= amount) One should also keep in mind a symmetric but harder to exploit vulnerability: if the victim calls Distributor::withdraw, and in his receive hook triggers some untrusted code (e.g., transfers the received funds), the adversary can do a nested Distributor::withdraw, causing the distributor to register a larger withdrawn amount for the victim that the real one (hence increasing the adversary's share). A nonReentrant guard in Distributor::withdraw prevents this. The general recommendation at the end of C2 also applies here. C2 The adversary can transferOwnership on Resolved vestingNFTReceiver change Via Distributor::call, an adversary can call VestingNFTReceiver::transferOwnership and call VestingNFTReceiver::withdraw directly (not via the distributor) and receive all vesting funds. himself, which ownership him to allows then the to This can be solved by removing the transferOwnership method and baking the owner into the VestingNFTReceiver during initialization. As a general recommendation, having a general-purpose Distributor contract which allows arbitrary interactions with VestingNFTReceiver via Distributor::call, makes it much harder to design a safe interface. We recommend using a distributor contract with exactly the needed functionality, possibly even merged with VestingNFTReceiver. This would easily solve C2, and would also make it easy to add a lock that solves C1. High Severity ",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "logic error in SumVesting combinator schedule Status Dismissed (intended behavior, assumptions on vesting schedules will be clearly stated) In combinator schedule SumVesting.sol it is implicitly assumed that the result of the sub-controllers for both getVested() and getWeight() is linearly dependant on the input amount function getVested(CommonParameters calldata input) external pure override returns (uint256 result) { [...] for (uint256 i; i < subControllers.length; i++) { IVestingController subController = subControllers[i]; uint256 share = subShares[i]; // Dedaub: should be input.amount * share/totalShares // Dedaub: but the division happens in the end nextInput.amount = share * input.amount; totalShares += share; [...] result += subController.getVested(nextInput); } result /= totalShares; } Thus the whole input amount is passed to all sub-controllers only to divide the accumulated result amount to the totalShares at the very end. While this assumption holds in the case of simple schedules, such as CliffVesting and LinearVesting, it may not hold for more complex ones that may be added in the future. 9 Similarly, an inaccurate input amount getContext(), createInitialState() and triggerEvent(). is passed to the sub-controllers in functions",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "testing that a transaction succeeded Resolved The following test is taken from test/commentary_tests.js : await expect(Notary.connect(Operator).submitCommentary(BYTES32_STRING)); await expect(Notary.connect(Operator).submitCommentary(BYTES32_ZERO)).to.be.reverted; It seems that the intention of the rst line is to test that submitCommentary succeeded without reverting. However this line does not really check anything, the test will pass even if submitCommentary reverts. The correct test would be: await expect(Notary.connect(Operator).submitCommentary(BYTES32_STRING)).not.to.be.rever ted; similar Many exist test/distributor_tests.js (and possibly elsewhere). commentary_tests.js, cases in contract_tests.js and In the following case, adding the .not.to.be.reverted revealed logic errors in the test: it(\"Validating the attestation on disclosed report `AFTER` ATTESTATION_DELAY\", async function () { await Notary.connect(Triager).attest(reportRoot, kk, commit) await expect(Notary.connect(Triager).disclose(reportRoot, key, salt, value, merkleProofval)) const increaseTime = ATTESTATION_DELAY * 60 * 60 // ATTESTION in `hour` format x 60 min x 60 sec await ethers.provider.send(\"evm_increaseTime\", [increaseTime]) // 1. increase block time await ethers.provider.send(\"evm_mine\") // 2. then mine the block ... Here, disclose is executed before the ATTESTATION_DELAY so it should fail, although the test makes it look like it should succeed. The reason why the test passes is that: 1. The await expect(...) line performs no checks 10 2. Moreover this line does not wait for the transaction to nish, so although disclose is launched before moving time forward, it is executed in the future block, after the time delay, and as a consequence it succeeds. So, if .not.to.be.reverted is added to the await expect(...) line, the test will fail, unless the line is moved after the time increase.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "variables Resolved There are some variables in contracts Distributor.sol and TokenMinter.sol that are assigned during contract construction and could never change thereafter. In Distributor.sol: /// Only settable by the initializer. bool public override callEnabled; address public override nftHolder; uint256 public override maxBeneficiaries In TokenMinter.sol: /// This initialized by the deployer. The token is completely trusted. IImmunefiToken public override token; We suggest these variables be declared immutable for clarity and gas efciency.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "receive hook Dismissed (hook needed by IVestingNFTFunder.vestingN FTCallback) The receive() hook in VestingNFT is not to be used intentionally, since ETH is received via mint(). It would be better to revert to avoid accidentally receiving ETH.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "need to construct a Merkle Tree can be easily avoided Open A large amount of code (MerkleTree.sol / QuickSort.sol) is aimed at constructing (rather than verifying) a MT. However, this is only used by BugReportNotary.assignNullCommentary to construct a tree for a trivial empty commentary. This can be easily avoided by having a hard-coded constant value NULL_COMMENTARY that denotes an empty commentary. The call to discloseCommentary can be omitted in this case 11 (or discloseCommentary can simply check that the value is empty) and NULL_COMMENTARY can be immediately set as canonical.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "code Partially resolved (dead code still present in LinearVesting.sol) In vesting schedule CliffVesting.sol function _decodeParams() is supposed to return a uint256 value function _decodeParams(bytes calldata params) internal pure returns (uint256 cliffTime) { cliffTime = abi.decode(params, (uint256)); } However, this schedule requires an empty parameter list function checkParams(CommonParameters calldata input) external pure override { require(input.params.length == 0); } All three internal functions _decodeParams(), _decodeState() and decodeContext() are never called for CliffVesting, while the later two are also never called for LinearVesting schedules. We suggest that all unused functions be removed for clarity and gas savings. Alternatively, the current body of CliffVesting::_decodeParams should be removed.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "function argument Resolved (argument is not redundant for code extensibility reasons) In KeeperRewards::keeperRewards the rst argument is redundant function keeperRewards(address, uint256 value) external pure override returns (uint256) { return value / 1000; } We suggest it be removed for clarity. Also, the constant 1000 in the same code is an arbitrary magic constant, best given a name to document intent.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "calling pattern Resolved 12 In BugReportNotary the MerkleProof::verify function is called with different syntax. Once as: merkleProof.verify(reportRoot, leafHash) and once as: MerkleProof.verify(merkleProof, commentaryRoot, leafHash) We recommend making uniform for consistency.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "in vestingNFT Info The README asks for possible ways to remove ReentrancyGuard from vestingNFT. We believe that these guards are critical and advise against trying to remove them (we see no safe way to do so, while keeping the dynamic way of computing the amount of transferred tokens). In particular, a reentrancy to mint from withdraw will directly lead to a severe loss of funds. Currently this is indirectly protected by the nonReentrant ag in _deposit and _beforeTokenTransferInner (we recommend clearly documenting the importance of these ags, to prevent them from getting accidentally removed).",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "funds in a single contract (VestingNFT) Info The architecture stores all ERC-20 tokens (assets) in a single contract (VestingNFT), and accounting for how they are shared among many different NFTs/bounties. This is a decision that puts a signicant burden on asset accounting. It should be simpler/safer to have a treasury contract that indexes assets by NFT and keeps assets entirely separate. However, the current design seems to exist in order to support ERC-20 tokens that change in number, with time. This certainly necessitates a shares model instead of a separate accounts model. It may be good to document exactly the behavior of tokens that the designer of the contract expects, with specic token examples. There are certainly token models that will not be supported by the current design, and others that are. A more radical approach could also be to use a clone of VestingNFT for each bounty (similarly to how clones of vestingNTFReceiver are used), so that funds for each bounty are kept in a separate contract. Apart from facilitating the accounting (no need for a \"shares\" model), this design would likely mitigate the losses from a critical bug (the adversary could drain a single bounty but not all of them).",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "code Resolved 13 The function QuickSort::sort admits some simplications/dead-code elimination. Some of these are only possible under the invariant left < right (which is true in the current uses of the function), others regardless. We highlight them in the four code comments below. function sort( bytes32[] memory arr, uint256 left, uint256 right // Dedaub: invariant: left < right ) internal pure { uint256 i = left; uint256 j = right; if (i == j) return; // Dedaub: dead code, under invariant bytes32 pivot = arr[left + (right - left) / 2]; while (i <= j) { // Dedaub: definitely true the first time, under invariant, // loop could be a do..while while (arr[i] < pivot) i++; while (pivot < arr[j]) j--; if (i <= j) { // Dedaub: always the case, no need to check (arr[i], arr[j]) = (arr[j], arr[i]); i++; j--; } } if (left < j) sort(arr, left, j); if (i < right) sort(arr, i, right); }",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "cannot recover from renouncing Dismissed (intended behavior) In the ImplOwnable contract (currently unused) if the owner calls renounceOwnership, no new owner can be installed. It is unclear whether this is intentional and whether the contract will be used in the future.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "for contract size Info 14 For the bytecode size issues of VestingNFT, our suggestion would be to create a VestingNFT library contract (containing all functions that do not heavily involve storage slots, such as pure functions, some views that only affect 1-2 storage slots) and have calls in VestingNFT delegate to the library versions. Shorter-term solutions might exist (e.g., removing one of the super-contracts, such as DelegateGuard, in some way) but they will not save a large contract from bumping against size limits for long.",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Immunefi/Immunefi audit Jul 21.pdf",
        "body": "pragma Open Use of a oating pragma: The oating pragma pragma solidity ^0.8.6; is used, allowing contracts to be compiled with any version of the Solidity compiler that is greater or equal to v0.8.6 and lower than v.0.9.0. Although the differences between these versions should be small, for deployment, oating pragmas should ideally be avoided and the pragma be xed. A15 Compiler known issues Info Solidity compiler v0.8.6, at the time of writing, has no known bugs. 15",
        "labels": [
            "Dedaub",
            "Immunefi",
            "Severity: Informational"
        ]
    },
    {
        "title": "Liquidations of Maker ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": " DISMISSED The crypto-economic design of this protocol can lead to force-liquidation of Makers through very small price movements. The following design elements make it easy to force liquidate makers: - Curve-Crypto AMM can yield the same price with dierent pool compositions - Spread limit is hard to trigger with single transactions Scenario: Bob wants to force liquidate Alices maker position to perform a liquidation slippage sandwich. [Note: the following gures are approximate] 1. With a small amount of margin, Alice opens a maker position: $3000 + 0.5ETH, when ETH is at $2000. Note that the pool is not perfectly balanced. 2. Bob opens a large short position, say 10ETH, moving ETH price to $1900. 3. The pools composition changed signicantly with one swap, but not the price. 4. Alices position is now around $1100 + 1.5ETH, so openNotional = 1900 and position = 1 5. Alices maker debt is $6000 6. Alices notionalPosition is $7900 0 The result is that with < 5% price change, Alices margin fraction has decreased by 25%",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "process is easily circumvented DISMISSED The unbonding process can be easily circumvented through a variation on the Sybil aack. Unbonding liquidity at will enables other aacks such as liquidity frontrunning. Scenario: Alice wants to add amount of liquidity, and be able to withdraw  /3 of her liquidity on any one day. We assume that the withdrawal period is N days and the unbonding period is M days. This means that using the following strategy, alice can always remove / liquidity, like so: 1. Alice deposits / each day for M days on M dierent addresses 2. After M days, Alice goes through each address where the withdrawal expired and requests unbonding again. 3. At any day, after the rst M days, alice can withdraw up to / of her liquidity.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "amount is not reset on liquidation RESOLVED A makers liquidation calls method AMM::forceRemoveLiquidity, which in turn calls AMM::_removeLiquidity and operates in the same manner as the regular removeLiquidity thereafter, but does not reset a pending unbonding amount that the maker might have. The function AMM::removeLiquidity on the other hand, deducts the unbonding amount accordingly: Maker storage _maker = _makers[maker]; _maker.unbondAmount -= amount;",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "Liquidations ACKNOWLEDGED 0 The risk of cascading liquidations in Hubble are relatively high, especially where maker liquidations are concerned. Takers are relatively protected from triggering liquidations of other takers due to the dual mode margin fraction mechanism (which uses oracle prices in cases of large divergences between mark and index prices). However, a taker liquidation can trigger a maker liquidation (see M1). In turn the removal of maker liquidity makes the price derived via Swap::get_dy and Swap::get_dx lower. The following are our inferred cascading liquidation risks: - Taker liquidation triggering a taker liquidation (low) - Maker liquidation triggering a taker liquidation (medium, eect of swap price movement in addition to the eect of removal of liquidity) - Maker liquidation triggering a maker liquidation (high, see M1) - Taker liquidation triggering a maker liquidation (high, see M1)",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "stakers who double as liquidators can increase their share of the pool RESOLVED [This issue was partially known to the developers] If an insurance staker also doubles as a liquidator, then they can: 1. Withdraw their insurance contribution 2. Liquidate bad debt 3. Sele bad debt using other users insurance stake 4. Re-deposit their stake again The liquidator/staker now owns a larger portion of the pool. This eect can be compounded. Opening multiple tiny positions to make liquidations",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "unprotable 0 There are no restrictions on the minimum size of the position a user can open and on the minimum amount of collateral he should deposit when an account is opened. A really small position will be unprotable for an arbitrageur to liquidate. An adversary could take advantage of this fact and open a huge number of tiny positions, using dierent accounts. The adversary might not be able to get a direct prot from such an approach, but since these positions are going to stay open for a long time, as no one will have a prot by liquidating them, they can signicantly shift the price of the vAMM with small risk. To safeguard against such aacks we suggest that a lower bound on the position size and collateral should be used. Liquidating own tiny maker position to prot from the xed",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "fee As discussed in issue M6, one can open a however small position they want. The same is true when providing liquidity. On the other hand the incentive fee for liquidating a maker, i.e., someone that provides liquidity, is xed and its 20 dollars as dened in ClearingHouse::fixedMakerLiquidationFee. Thus, one could provide really tiny amounts of liquidity (with tiny amounts of collateral backing it) and liquidate themselves with another account to make a prot from the liquidation fee. Networks with small transaction fees (e.g., Avalanche) or",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "could make such an aack really protable, especially if executed on a large scale. ClearingHouse::isMaker does not take into account makers",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "ignition share Method ClearingHouse::isMaker checks if a user is a maker by implementing the following check: function isMaker(address trader) override public view returns(bool) { uint numAmms = amms.length; for (uint i; i < numAmms; ++i) { IAMM.Maker memory maker = amms[i].makers(trader); if (maker.dToken > 0) { 0 return true; } } return false; } However, the AMM could still be in the ignition phase, meaning that the maker could have provided liquidity that in maker.ignition. This omission could allow liquidation of a users taker positions before its maker positions, which is something undesirable, as dened by the liquidate and liquidateTaker methods of ClearingHouse. reflected in maker.dToken but is not yet",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "Slippage Sandwich Attack ACKNOWLEDGED [The aack is related to already known issues, but is documented in more detail here] 1. Alice has a long position that is underwater 2. Bob opens a large short position 3. Bob liquidates Alice. This triggers a swap in the same direction as Bobs position and causes slippage. 4. Bob closes his position, and prots on the slippage at the expense of Alice. M10 Self close bad debt attack DISMISSED This is a non-specic aack on the economics of the protocol. 1. Alice opens a short position using account A 2. Alice opens a large long position using account B 3. In the meantime, the market moves up. 4. Alice closes her under-collateralized position A. Bad debt occurs. 5. Alice can now close position B and realize her prot 09 LOW SEVERITY: ",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Medium"
        ]
    },
    {
        "title": "neutra ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": " ACKNOWLEDGED Maker debt, calculated as the vUSD amount * 2 when the liquidity was added never changes. If the maker has gained out of her impermanent position, e.g., through fees, this is not accounted for, in certain kinds of liquidations (via oracle). However, if the maker now removes their liquidity, closes their impermanent position and adds the same amount of liquidity, the debt is reset to a dierent amount.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "blacklisting checks are incomplete RESOLVED The ClearingHouse contract can set and use a Blacklist contract to ban certain users from opening new positions. However, these same users are not blacklisted from providing liquidity to the protocol, i.e., having impermanent positions, which can be turned into permanent ones when the liquidity is removed. Although this form of opening positions is not controllable, it would be beer if blacklisted users were also banned from providing liquidity.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "could potentially be reentered RESOLVED VUSD::processWithdrawals of the VUSD contract calls method safeTransfer on the reserveToken dened in VUSD. 01 function processWithdrawals() external whenNotPaused { uint reserve = reserveToken.balanceOf(address(this)); require(reserve >= withdrawals[start].amount, 'Cannot process withdrawals at this time: Not enough balance'); uint i = start; while (i < withdrawals.length && (i - start) < maxWithdrawalProcesses) { Withdrawal memory withdrawal = withdrawals[i]; if (reserve < withdrawal.amount) { break; } reserve -= withdrawal.amount; reserveToken.safeTransfer(withdrawal.usr, withdrawal.amount); i += 1; } start = i; } In the unlikely scenario that the safeTransfer method (or a method safeTransfer calls internally) of reserveToken allows calling an arbitrary contract, then that contract can reenter the processWithdrawals method. As the start storage variable will not have been updated (it is updated at the very end of the method), the same withdrawal will be executed twice if the contracts reserveToken balance is suicient. Actually, if reentrancy is possible, the whole balance of the contract can be drained by reentering multiple times. It is easier to perform this aack if the aackers withdrawal is the rst to be executed, which is actually not hard to achieve. This vulnerability is highly unlikely, as it requires the execution reaching an untrusted contract, still we suggest adding a reentrancy guard (minor overhead) to completely remove the possibility of such a scenario. 01 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "usage increases quadratically to positions ACKNOWLEDGED Whenever a users position is modied, maintained or liquidated, all of the users token positions need to be queried (both maker and taker). For instance, this happens in ClearingHouse::getTotalNotionalPositionAndUnrealizedPnl for (uint i; i < numAmms; ++i) { if (amms[i].isOverSpreadLimit()) { (_notionalPosition, _unrealizedPnl) = amms[i].getOracleBasedPnl(trader, margin, mode); } else { (_notionalPosition, _unrealizedPnl,,) = amms[i].getNotionalPositionAndUnrealizedPnl(trader); } notionalPosition += _notionalPosition; unrealizedPnl += _unrealizedPnl; } Therefore, if we assume that a user with more positions and exposure to more tokens needs to tweak their positions from time to time, and the number of actions correlates the number of positions, the gas usage really scales quadratically to the number of positions for such a user.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "regarding the numerical methods of CurveMath.vy ACKNOWLEDGED [Below we use the notation of the curve crypto whitepaper] The CurveCrypto invariant in the case of pools with only two assets (N=2) can be simplied into a low degree polynomial, which could lead to a faster convergence of the numerical methods. 01 The coeicient K, when N=2 (we denote by x and y the deposits of the two assets in the pool), is given by the formula If we multiply both sides of the equation an equivalent equation, which is polynomial in all three variables x, y and D: by the denominator of K we get As you can see it is a cubic equation for x and y and you can use the formulas for cubic equations either to compute faster the solution or to get a beer initial value for the iterative method you are currently using. We believe it would be worth spending some time experimenting with the numerical methods to get the fastest possible convergence (and consequently reduced gas fees paid by the users).",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "functionality to remove AMMs ACKNOWLEDGED Governance has the ability to whitelist AMMs via ClearingHouse::whitelistAmm method, while there is no functionality to remove or blacklist an AMM.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "collateral index checks are missing ACKNOWLEDGED There are several external methods of MarginAccount, namely addMargin, addMarginFor, removeMargin, liquidateExactRepay and liquidateExactSeize that do not implement a check on the collateral index supplied, which can lead to the ungraceful termination of the transaction if an incorrect index has been supplied. A simple check such as: require(idx < supportedCollateral.length, \"Collateral not supported\"); could be used to also inform the user of the problem with their transaction. 01",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "event is missing timestamp eld ACKNOWLEDGED The AMM::PositionChanged event is potentially missing a timestamp eld that all related events (LiquidityAdded, LiquidityRemoved, Unbonded) other incorporate. trader",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "out code ACKNOWLEDGED In method MarginAccount::isLiquidatable the following line is commented out: _isLiquidatable = IMarginAccount.LiquidationStatus.IS_LIQUIDATABLE; This is because IMarginAccount.LiquidationStatus.IS_LIQUIDATABLE is equal to 0, which will be the default value of _isLiquidatable if no value is assigned to it, thus the above assignment is not necessary. Nevertheless, explicitly assigning the enum value makes the code much more readable and intiutive.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "constants ACKNOWLEDGED There are several magic constants throughout the codebase, many of them related to the precision of token amounts, making it diicult to reason about the correctness of certain computations. The developers of the protocol are aware of the issue and claim that they have developed extensive tests to make sure nothing is wrong in this regard.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "price decimals assumption ACKNOWLEDGED The Oracle contract code makes the assumption that the price value returned by the ChainLink oracle has 8 decimals. This assumption appears to be correct if the oracles used report the price in terms of USD. Nevertheless, using the oracles available decimals method and avoiding such a generic assumption would make the code much more robust.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "can be reused ACKNOWLEDGED 01 The following code shared by methods MarginAccount::liquidateExactRepay and MarginAccount::liquidateExactSeize can be factored out in a separate method and reused: clearingHouse.updatePositions(trader); // credits/debits funding LiquidationBuffer memory buffer = _getLiquidationInfo(trader, idx); if (buffer.status != IMarginAccount.LiquidationStatus.IS_LIQUIDATABLE) { revert NOT_LIQUIDATABLE(buffer.status); } In addition, all the code of AMM::isOverSpreadLimit: function isOverSpreadLimit() external view returns(bool) { if (ammState != AMMState.Active) return false; uint oraclePrice = uint(oracle.getUnderlyingPrice(underlyingAsset)); uint markPrice = lastPrice(); uint oracleSpreadRatioAbs; if (markPrice > oraclePrice) { oracleSpreadRatioAbs = markPrice - oraclePrice; } else { oracleSpreadRatioAbs = oraclePrice - markPrice; } oracleSpreadRatioAbs = oracleSpreadRatioAbs * 100 / oraclePrice; if (oracleSpreadRatioAbs >= maxOracleSpreadRatio) { return true; } return false; } except line uint markPrice = lastPrice(); can be factored out in another method, e.g., _isOverSpreadLimit(uint markPrice), which will have markPrice as an argument. Then method _isOverSpreadLimit can be reused in methods _short and _long. 01",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "modiers ACKNOWLEDGED Methods syncDeps of MarginAccount and InsuranceFund could be declared external instead of public.",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Hubble Exchange/Hubble Exchange Audit.pdf",
        "body": "code/contracts ACKNOWLEDGED tests/Executor.sol is not used. A12 Compiler known issues INFO The contracts were compiled with the Solidity compiler v0.8.9 which, at the time of writing, have some known bugs. We inspected the bugs listed for this version and concluded that the subject code is unaected. 01 CENTRALIZATION ASPECTS As is common in many new protocols, the owner of the smart contracts yields considerable power over the protocol, including changing the contracts holding the users funds, adding AMMs and tokens, which potentially means borrowing tokens using fake collateral, etc. In addition, the owner of the protocol can: - Blacklist any user. - Set important parameters in the vAMM which change the price of any assets: price_scale, price_oracle, last_prices. This allows the owner to potentially liquidate otherwise healthy positions or enter into bad debt positions. The computation of the Margin Fraction takes into account the weighted collateral, whose weights are going to be decided by governance. Currently the protocol uses NFTs for governance but in the future the decisions will be made through a DAO. Currently, there is no relevant implementation, i.e., the Hubble protocol does not yet oer a governance token. Still, even if the nal solution is decentralized, governance should be really careful and methodical when deciding the values of the weights. We believe that another, safer approach would be to alter these weights in a specic way dened by predetermined formulas and allow only small adjustments by the DAO. 01",
        "labels": [
            "Dedaub",
            "Hubble Exchange",
            "Severity: Informational"
        ]
    },
    {
        "title": "shares can be drained by the controller devalued via a reentrancy aack ",
        "html_url": "https://github.com/dedaub/audits/tree/main/GYSR/GYSR - Mar '23.pdf",
        "body": " RESOLVED This vulnerability arises from two separate issues in dierent parts of the code: 1. The TokenUtils::receiveAmount/receiveWithFee functions compute the amount of received tokens as the dierence in balance before and after the transfer. TokenUtils::receiveAmount() function receiveAmount( IERC20 token, uint256 shares, address sender, uint256 amount ) internal returns (uint256) { // transfer uint256 total = token.balanceOf(address(this)); token.safeTransferFrom(sender, address(this), amount); uint256 actual = token.balanceOf(address(this)) - total;  // mint shares at current rate uint256 minted = (total > 0) ? (shares * actual) / total : actual * INITIAL_SHARES_PER_TOKEN; require(minted > 0); return minted; } The goal is to support dierent types of tokens (e.g. tokens with transfer fees). This approach, however, introduces a possible aack vector: the code could miscalculate the amount of tokens transferred if some other action is executed in between the two balance readings. Note that token.safeTransferFrom() is an external call outside our control. As such, we cannot exclude the possibility that it returns execution to the adversary (e.g. via a transfer hook). 2. The fund() function, of all reward modules, has no reentrancy guards (likely due to the fact that funding sounds \"harmless\"; we send tokens to the contract without geing anything back). The possible aack: We assume a malicious controller that creates a pool with ERC20FixedRewardModule (for simplicity). His goal is to receive the benets of staking but without giving any rewards back. The reward token used in the pool is a legitimate trusted token. We only assume that it has some ERC777-type transfer hook (or any mechanism to notify the sender when a transferFrom happens). 1. The adversary funds the reward module and waits until several users have staked tokens (giving them rights to reward tokens).  2. He then initiates a number of k nested calls to ERC20FixedRewardModule::fund as follows: ERC20FixedRewardModule::fund() function fund(uint256 amount) external { require(amount > 0, \"xrm4\"); (address receiver, uint256 feeRate) = _config.getAddressUint96( keccak256(\"gysr.core.fixed.fund.fee\")); uint256 minted = _token.receiveWithFee( rewards, msg.sender, amount, receiver, feeRate ); rewards += minted; emit RewardsFunded(address(_token), amount, minted, block.timestamp); } a. He calls fund() with an innitesimal amount (say 1 wei). fund calls receiveWithFee which registers the initial total = balanceOf(this) and calls token.safeTransferFrom. TokenUtils::receiveWithFee() function receiveWithFee(...) internal returns (uint256) { uint256 total = token.balanceOf(address(this)); uint256 fee; if (feeReceiver != address(0) && feeRate > 0 && feeRate < 1e18) { fee = (amount * feeRate) / 1e18;  token.safeTransferFrom(sender, feeReceiver, fee); } token.safeTransferFrom(sender, address(this), amount - fee); uint256 actual = token.balanceOf(address(this)) - total; uint256 minted = (total > 0) ? (shares * actual) / total : actual * INITIAL_SHARES_PER_TOKEN; require(minted > 0); return minted; } b. The laer passes control to the adversary (via a send hook), which makes a nested call to fund, again with amount = 1 wei. Which again leads to a new token.safeTransferFrom. c. The process continues until the k-th call, which is now made with a larger amount = N. The adversary stops making nested calls so the previous calls nish their execution starting from the most nested one. d. The last (k-th) call computes actual as the dierence between the two balances which will be equal to N tokens. This causes rewards to be incremented by the corresponding amount of shares (= (rewards * N) / total). e. Now execution returns to the (k-1)-th call, for which the actual transferred amount was just 1 wei. However, the dierence of balances includes the nested k-th call, so actual will be found to be N (not 1 wei), causing rewards to be incremented again by the same amount of shares. f. The same happens with all outer calls, causing rewards to be incremented by k times more shares than they should!  3. The previous step essentially devalued each reward share, since we printed k times more shares than we should have. Note that the controller can withdraw all funds except those corresponding to the shares in debt. But these now are worth less, so the adversary can withdraw more reward tokens than he should. By picking k to be as large as the stack allows, and a large value of N (possibly using a flash loan), the controller can drain almost all reward tokens from the pool, leaving users with no rewards. Note that the other reward modules are also likely vulnerable since they all call receiveWithFee and have no reentrancy guard. To prevent this vulnerability reentrancy guards should be added to all fund methods. Moreover, TokenUtils::receiveAmount could check that the actual transferred amount is no larger than the expected one. This check would still support tokens with transfer fees, but would catch aacks like the one reported here. Resolution: This vulnerability was xed by addressing both issues that enabled it. Specically:  A check was added in TokenUtils::receiveAmount to ensure that the transferred amount is no larger than the expected one  Reentrancy guards were added to the fund function HIGH SEVERITY: [No high severity issues] MEDIUM SEVERITY: ",
        "labels": [
            "Dedaub",
            "GYSR - Mar '23",
            "Severity: Critical"
        ]
    },
    {
        "title": "use of the factory contracts is only enforced o-chain WONT FIX The proper way to deploy a pool and its modules is via the factory contracts. These contracts ensure that the pool is initialized with proper values that prevent a potentially malicious controller from stealing the investors funds. However, the use of factory contracts is only checked o-chain. PoolFactory keeps a list of contracts it created, and this list presumably is used by the GYSR UI to allow users to interact only with oicially created contracts. On the other hand, anyone could still create their own Pool contracts and manually initialize in any way. Such contracts would have identical source code as the legitimate ones, and it would be hard to recognize them. They would also be clearly unsafe: by using malicious staking and reward modules, or even a fake GYSR token, an adversary could easily steal all the funds deposited by investors. Although the o-chain checks would ensure that no user actually interacts with such contracts, such checks are inherently less reliable than on-chain ones. It would be preferable to ensure that contracts with bytecode identical to the oicial ones can never be improperly initialized, for instance by allowing their constructor to be called by a factory contract. Resolution: This issue largely concerns o-chain aspects and cannot be fully addressed on-chain. As a consequence, it will be addressed by adding clear documentation explaining how to verify the validity of a deployed contract. Unstaking in ERC20FixedRewardModule is inconsistent RESOLVED under dierent use cases M2  The ERC20FixedRewardModule was updated as part of the PR #38 mentioned in the ABSTRACT section. The fundamental functions for the users are stake, unstake and claim. When a user stakes, the pos.debt eld holds their potential rewards if they stake for the entire predened period. However, a user can always claim their rewards for the amount already vested. Here are two scenarios of the same logic that are treated dierently:  Case #1: The rst case assumes that the users will not stake more than once. This happens when this reward module is combined with the ERC20BondStaking module since users cant stake twice with a bond. However, if they unstake early, for recovering the remaining principal, their rewards earning ratio should also be reduced. In order for the reward module to achieve this, it treats the user shares as if they were vesting all together. So, when user unstakes early only a percentage of all user shares have vested resulting in losing portion of the earning power as indented.  Case #2: The second case is when users can stake more than once. This can happen when this module is combined with other staking modules like ERC20StakingModule for example. Then, when a user stakes again, the function calculates the rewards earned up to that point, updates their records and rolls over the remaining (unvested) amount with the newly added one to start vesting from that point forward. This approach treats the user shares as if they were vesting linearly and not all together which means that the user wont lose his earning power. A detailed example illustrating the inconsistency between the 2 cases is provided in the APPENDIX of this report. 1 Resolution: This issue was addressed by modifying the staking logic to remove the inconsistency. LOW SEVERITY: ID Description ",
        "html_url": "https://github.com/dedaub/audits/tree/main/GYSR/GYSR - Mar '23.pdf",
        "body": " L1 Approximation errors in ERC20BondStakingModule RESOLVED ERC20BondStakingModule needs to perform vesting and debt decay on multiple amounts which however have dierent vesting/decay periods. To perform this operation in O(1) an approximation method is used, where vesting/decay happens for the whole amount simultaneously, and the period is essentially restarted in every update. This method necessarily introduces an approximation error. If multiple updates happen the resulting values could be substantially lower than the actual ones. What is particularly problematic is that such delays can be produced by events that do not add new value to the system. For instance, vesting a large amount could be substantially delayed by staking (maliciously or coincidentally) small amounts. With just 5 updates the amount vested at the end of the period will be only 67% of the total. Note that there is also an \"opposite extreme\" strategy: instead of restarting the period on every update, we could choose to never restart until the current amount is fully vested. Of course, this method also introduces an error. If the newly deposited amounts are large, delaying them might introduce a larger error than restarting the period. So we propose to follow a hybrid approach, alternating between the two extremes: keep a pending amount whose vesting has not started yet, and will start no later than 1 at the end of the current period, but possibly earlier if it's preferable. When a new amount arrives, we will compute how much error will be introduced by starting a new vesting period, and how much error will be introduced if we delay the new amount, and we'll choose the approach of the smallest error. This report is accompanied by a Jupyter notebook with a discussion of this method, a prototype implementation and some simulations. The proposed method has the following properties:  It needs O(1) time and is only marginally more complicated than the simple method.  It is guaranteed to vest at least as much as the simple method, and never more than the maximum amount.  In order to introduce vesting delays one needs to add new funds to the system, larger than the ones currently being vested. Resolution: This issue was addressed by an improved logic that resets the time period only on stake operations, improving the accuracy while simplifying the code. OTHER / ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "GYSR - Mar '23",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GYSR/GYSR - Mar '23.pdf",
        "body": "is not correctly overridden in ERC20BondStakingModule RESOLVED The ERC20BondStakingModule contract overrides the ERC721::_beforeTokenTransfer() hook. However, the overridden hook hasnt the same signature as the original one causing the compilation to fail. The missing part is the 4th argument which should have been another uint256. ERC721::_beforeTokenTransfer() function _beforeTokenTransfer( address from, address to, uint256, /* firstTokenId */ uint256 batchSize ) internal virtual { if (batchSize > 1) { if (from != address(0)) { _balances[from] -= batchSize; } if (to != address(0)) { _balances[to] += batchSize; } } } ERC20BondStakingModule::_beforeTokenTransfer() function _beforeTokenTransfer( address from, address to, uint256 tokenId ) internal override { if (from != address(0)) _remove(from, tokenId); if (to != address(0)) _append(to, tokenId); } 1",
        "labels": [
            "Dedaub",
            "GYSR - Mar '23",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GYSR/GYSR - Mar '23.pdf",
        "body": "tests RESOLVED There are some cases in the test scripts that fail due to the grammar changes that OZ introduced at commit fbf235661e01e27275302302b86271a8ec136fea. They updated the revert messages of the approve(), transferFrom() and safeTransferFrom() functions from:  ERC721: caller is not token owner nor approved to:  ERC721: caller is not token owner or approved However, the tests haven't been updated to reflect the new changes, so they fail. The aected tests are the following:  aquarium.js  LoC:113 - when token transfer has not been approved  erc20bondstakingmodule.js  LoC: 1680 - when user transfers a bond position they do not own  LoC: 1689 - when user safe transfers a bond position they do not own  LoC: 1699 - when user transfers a bond position that they already transferred",
        "labels": [
            "Dedaub",
            "GYSR - Mar '23",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GYSR/GYSR - Mar '23.pdf",
        "body": "gas optimization RESOLVED Since the protocol tries to minimize the gas consumption to the minimum possible, we suggest here a minor optimization in ERC20FixedRewardModule. The pos.updated value could be updated inside the if statement above instead of having to check again whether the period has ended or not. 1 ERC20FixedRewardModule::claim() function claim( bytes32 account, address, address receiver, uint256, bytes calldata ) external override onlyOwner returns (uint256, uint256) { ... if (block.timestamp > end) { e = d; } else { uint256 last = pos.updated; e = (d * (block.timestamp - last)) / (end - last); } ... // Dedaub: This update could be transferred to the above if statement // pos.updated = uint128(block.timestamp < end ? block.timestamp : end); ... for avoiding rechecking whether the period has ended }",
        "labels": [
            "Dedaub",
            "GYSR - Mar '23",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/GYSR/GYSR - Mar '23.pdf",
        "body": "comment in OwnerController RESOLVED The OwnerController contract provides functionality for the rest of the protocol contracts to manage their owners and their controllers. However, while the comments of the transferOwnership() function state that the owner can renounce ownership by transferring to address(0), this is not possible with the current code as it reverts when the newOwner address is 0. OwnerController::transferOwnership() /** * @dev Transfers ownership of the contract to a new account (`newOwner`). * This can include renouncing ownership by transferring to the zero * address. Can only be called by the current owner. */ function transferOwnership(address newOwner) public virtual override { 1 requireOwner(); require(newOwner != address(0), \"oc3\"); emit OwnershipTransferred(_owner, newOwner); _owner = newOwner; } A5 Compiler bugs INFO The code is compiled with Solidity 0.8.18. Version 0.8.18, at the time of writing, has no known bugs. 1",
        "labels": [
            "Dedaub",
            "GYSR - Mar '23",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Oct '23.pdf",
        "body": " RESOLVED (2ac2ae) In the LPToken::approve function, one should check that the spender is not blocked, since a blocked spender with an approval could potentially still control tokens.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Oct '23.pdf",
        "body": "transferFrom should check whether spender is blocked RESOLVED (2ac2ae) In LPToken::transferFrom: one should check that the spender is not blocked, so as to avoid a blocked user from spending someone elses LP tokens. L3 A blocked user should not get a discount RESOLVED (2ac2ae) The Users::setDiscount function should check whether a user has been blocked, before awarding that user a discount. 0 CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) [NO CENTRALISATION ISSUES] OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Low"
        ]
    },
    {
        "title": "reset of _isBlocked array when seing Protocol Fee Recipient ",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Oct '23.pdf",
        "body": " RESOLVED (2ac2ae) The LPToken::setProtocolFeeRecipient function sets _isBlocked[recipient] = false at the end. But if one calls setProtocolFeeRecipient, and _isBlocked[recipient] == true, this line will be unreachable, because the function will revert beforehand. Hence this line is redundant and can be removed.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Oct '23.pdf",
        "body": "cleanup of discount when user is blocked RESOLVED (2ac2ae) The Pool::setIsAllowed function should set the discount to zero when a user is blocked so as to perform proper cleanup and give a correct view from the UI. 0 A3 Compiler bugs INFO The code is compiled with Solidity 0.8.19. Version 0.8.19, in particular, has some known bugs, which we do not believe aect the correctness of the contracts.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "code ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink Uniswap Anchored View.pdf",
        "body": " RESOLVED In UniswapLib.sol, the struct Slot0 denition is not being used. It is recommended that it be removed as it is dead code.",
        "labels": [
            "Dedaub",
            "Chainlink Uniswap Anchored View",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink Uniswap Anchored View.pdf",
        "body": "simplication RESOLVED In UniswapConfig.sol, all getTokenConfigBy* functions have a check that the index is not type(uint).max, however this is redundant as getTokenConfig already covers this case by checking that index < numTokens. For example: function getTokenConfigBySymbolHash(bytes32 symbolHash) public view returns (TokenConfig memory) { uint index = getSymbolHashIndex(symbolHash); // Dedaub: Redundant check; getTokenConfig checks that index < numTokens. That check covers the case where index == type(uint).max // if (index != type(uint).max) { return getTokenConfig(index); } revert(\"token config not found\"); } Can be simplied to: function getTokenConfigBySymbolHash(bytes32 symbolHash) public view returns (TokenConfig memory) { uint index = getSymbolHashIndex(symbolHash) return getTokenConfig(index); }",
        "labels": [
            "Dedaub",
            "Chainlink Uniswap Anchored View",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink Uniswap Anchored View.pdf",
        "body": "trailing modier parentheses DISMISSED There are a couple of instances where even zero-argument modiers are used with parentheses, even though they can be omied. For example, in UniswapAnchoredView::activateFailover: function activateFailover(bytes32 symbolHash) external onlyOwner() { ... } This paern can be found in:  UniswapAnchoredView::activateFailover  UniswapAnchoredView::deactivateFailover  Ownable::transferOwnership",
        "labels": [
            "Dedaub",
            "Chainlink Uniswap Anchored View",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink Uniswap Anchored View.pdf",
        "body": "sanity check for xed price assets RESOLVED In the UniswapAnchoredView constructor, xed price assets (either ETH or USD pegged) check that the provided uniswap market is zero, however the reporter eld is unchecked. It is recommended that the reporter be also required to be zero, for consistency: else { require(uniswapMarket == address(0), \"only reported prices utilize an anchor\"); // Dedaub: Check that reporter is also 0 require(config.reporter == address(0), \"only reported prices utilize a reporter\"); }",
        "labels": [
            "Dedaub",
            "Chainlink Uniswap Anchored View",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink Uniswap Anchored View.pdf",
        "body": "functionality is cryptic (fetchAnchorPrice) RESOLVED The correctness of the calculation in UniswapAnchoredView::fetchAnchorPrice is very hard to establish. More comments would help. Specically, the code reads function fetchAnchorPrice(TokenConfig memory config, uint conversionFactor) internal virtual view returns (uint) { uint256 twap = getUniswapTwap(config); uint rawUniswapPriceMantissa = twap; uint unscaledPriceMantissa = rawUniswapPriceMantissa * conversionFactor; uint anchorPrice = unscaledPriceMantissa * config.baseUnit / ethBaseUnit / expScale; return anchorPrice; } The correctness of this calculation depends on the following understanding, which should be documented in code comments, or the functionality is entirely cryptic. (We note that the original UAV code had similar comments, although the ones below are our own.)  getUniswapTwap returns the price between the baseUnits of the two tokens in a pair, scaled to e18  rawUniswapPriceMantissa * config.baseUnit : price of 1 token (instead of one baseUnit of token), relative to baseUnit of the other token. Still scaled at e18  unscaledPriceMantissa * config.baseUnit / expScale : (mathematically, not in integer arithmetic) price of 1 token relative to baseUnit of the other, scaled at 1  unscaledPriceMantissa * conversionFactor * config.baseUnit / ethBaseUnit / expScale :  in the case of ETH-USDC, conversionFactor is ethBaseUnit, and the above happens to return 1 ETH's price in USDC with 6 decimals of precision, just because the USDC unit has 6 decimals  in the case of other tokens, the conversionFactor is the 6-decimal ETH-USDC price, hence the result is the price of 1 token relative to 1 ETH, at 6-decimal precision.",
        "labels": [
            "Dedaub",
            "Chainlink Uniswap Anchored View",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink Uniswap Anchored View.pdf",
        "body": "warning RESOLVED The Solidity compiler is issuing a warning for the UniswapAnchoredView::priceInternal function, that the return variable may be unassigned. While this is a false warning, it can be easily suppressed with a simple refactoring of the form: function priceInternal(TokenConfig memory config) internal view returns (uint)  if (config.priceSource == PriceSource.REPORTER) return prices[config.symbolHash].price else if (config.priceSource == PriceSource.FIXED_USD) return config.fixedPrice; else { uint usdPerEth = prices[ethHash].price; require(usdPerEth > 0, \"ETH price not set, cannot convert to dollars\"); return usdPerEth * config.fixedPrice / ethBaseUnit; } }",
        "labels": [
            "Dedaub",
            "Chainlink Uniswap Anchored View",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink Uniswap Anchored View.pdf",
        "body": "code (UniswapConfig::getTokenConfig) RESOLVED The expression: ((isUniswapReversed >> i) & uint256(1)) == 1 ? true : false can be shortened to the more elegant: ((isUniswapReversed >> i) & uint256(1)) == 1",
        "labels": [
            "Dedaub",
            "Chainlink Uniswap Anchored View",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink Uniswap Anchored View.pdf",
        "body": "pragma RESOLVED The floating pragma pragma solidity ^0.8.7; is used in most contracts, allowing them to be compiled with any version of the Solidity compiler v0.8.* after, and including, v0.8.7. Although the dierences between these versions are small, floating pragmas should be avoided and the pragma should be xed to the version that will be used for the contract deployment (Solidity version 0.8.7 at the audit commit hash). A9 Compiler known issues INFO The contracts were compiled with the Solidity compiler v0.8.7 which, at the time of writing, have some known bugs. We inspected the bugs listed for version 0.8.7 and concluded that the subject code is unaected",
        "labels": [
            "Dedaub",
            "Chainlink Uniswap Anchored View",
            "Severity: Informational"
        ]
    },
    {
        "title": "validity of the index price, the funding rate and the mark price is not always checked by the calle ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": " OPEN Functions getIndexPrice, getFundingRate and getMarkPrice of the Exchange contract depend on the externally provided base asset price that could be invalid in some cases. Nevertheless, the aforementioned functions do not revert in case the base asset price is invalid but return a tuple with the derived value and a boolean that denotes the derived value is invalid due to the base asset price being invalid. The callers of the functions are responsible for checking the validity of the returned values, a design which is valid and flexible as long as it is appropriately implemented. However, the function Exchange::_updateFundingRate does not check the validity of the funding rate value returned by getFundingRate, which could lead to an invalid funding rate geing registered, messing up the protocols operation. At the same time ShortCollateral::liquidate does not check the validity of the mark price returned by Exchanges getMarkPrice. The chance that something will go wrong is signicantly smaller with liquidate because each call to it is preceded by a call to the function maxLiquidatableDebt that checks the validity of the mark price.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: High"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "LP token price might be incorrect OPEN LiquidityPool::getTokenPrice, the function that computes the price of one LP token, might return an incorrect price under certain circumstances. Specically, it is incorrectly assumed that if the skew is equal to 0 the totalMargin and usedFunds will always add up to 0.  LiquidityPool::getTokenPrice() function getTokenPrice() public view override returns (uint256) { if (totalFunds == 0) { return 1e18; } uint256 totalSupply = liquidityToken.totalSupply() + totalQueuedWithdrawals; int256 skew = _getSkew(); if (skew == 0) { // Dedaub: Incorrect assumption that if skew == 0 then // return totalFunds.divWadDown(totalSupply); totalMargin + usedFunds == 0 } (uint256 markPrice, bool isInvalid) = getMarkPrice(); require(!isInvalid); uint256 totalValue = totalFunds; uint256 amountOwed = markPrice.mulWadDown(powerPerp.totalSupply()); uint256 amountToCollect = markPrice.mulWadDown(shortToken.totalShorts()); uint256 totalMargin = _getTotalMargin(); totalValue += totalMargin + amountToCollect; totalValue -= uint256((int256(amountOwed) + usedFunds)); return totalValue.divWadDown(totalSupply); The accounting of LiquidityPools queued orders is OPEN incorrect }",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: High"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "does not set the queuedPerpSize storage variable to 0 when an order of size sizeDelta + queuedPerpSize is submied to the Synthetix Perpetual Market. Also, queuedPerpSize should also be accounted for in the SubmitDelayedOrder emied event. LiquidityPool::_placeDelayedOrder() function _placeDelayedOrder( int256 sizeDelta, bool isLiquidation ) internal { PerpsV2MarketBaseTypes.DelayedOrder memory order = perpMarket.delayedOrders(address(this)); (,,,,, IPerpsV2MarketBaseTypes.Status status) = perpMarket.postTradeDetails(sizeDelta, 0, IPerpsV2MarketBaseTypes.OrderType.Delayed, address(this)); int256 oldSize = order.sizeDelta; if (oldSize != 0 || isLiquidation || uint8(status) != 0) { queuedPerpSize += sizeDelta; return; } perpMarket.submitOffchainDelayedOrderWithTracking( sizeDelta + queuedPerpSize, perpPriceImpactDelta, synthetixTrackingCode ); // Dedaub: queuedPerpSize should be set to 0 // Dedaub: Below line should be: // emit SubmitDelayedOrder(sizeDelta); emit SubmitDelayedOrder(sizeDelta + queuedPerpSize); }",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: High"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "mark price is susceptible to manipulation OPEN The mark price depends on the total sizes of the long and short positions. ShortCollateraltoken::canLiquidate and maxLiquidatableDebt use the mark price to compute the value of the position and to check if the collateralization ratio is above the liquidation limit or not. An adversary could open a large short position to increase the mark price and therefore decrease the collateral ratio of all the positions and possibly make some of them undercollateralized. The adversary would then proceed by calling Exchanges liquidate function to liquidate the underwater position(s) and get the liquidation bonus before nally closing their short position.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: High"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "of usedFunds and totalFunds is incorrect OPEN The LiquidityPool contract uses two storage variables to track its available balance, usedFunds and totalFunds. As one would expect, these two variables get updated when a position is open or closed, i.e., when functions openLong, openShort, closeLong and closeShort are called. Incoming (openLong and closeShort) and outgoing (openShort and closeLong) funds for the position must be considered together with funds needed for fees. There are 3 types of fees, trading fees aributed to the LiquidityPool, fees required to open an oseing position in the Synthetix Perp Market, which are called hedgingFees, and a protocol fee, externalFee. The accounting of all these values is rather complex and ends up being incorrect in all the four aforementioned functions. Lets take the closeLong function as an example. In closeLong there are no incoming funds and the outgoing funds are the sum of the totalCost, the externalFee and the hedgingFees. However, the usedFunds are actually increased by tradeCost or totalCost+tradingFee+externalFee+hedgingFees, while hedgingFees are also added to usedFunds in the _hedge function. Thus, there are two issues: (1) hedgingFees are accounted for twice and (2) tradingFee is added when it should not.  LiquidityPool::closeLong() function closeLong(uint256 amount, address user, bytes32 referralCode) external override onlyExchange nonReentrant returns (uint256 totalCost) { } (uint256 markPrice, bool isInvalid) = getMarkPrice(); require(!isInvalid); uint256 tradeCost = amount.mulWadDown(markPrice); uint256 fees = orderFee(-int256(amount)); totalCost = tradeCost - fees; SUSD.safeTransfer(user, totalCost); uint256 hedgingFees = _hedge(-int256(amount), false); uint256 feesCollected = fees - hedgingFees; uint256 externalFee = feesCollected.mulWadDown(devFee); SUSD.safeTransfer(feeReceipient, externalFee); tradeCost = totalCost + fees fees = feesCollected + hedgingFees and feesCollected = tradingFee + externalFee // Dedaub: usedFunds is incremented by tradeCost // // // usedFunds += int256(tradeCost); emit RegisterTrade(referralCode, feesCollected, externalFee); emit CloseLong(markPrice, amount, fees); The functions openLong, openShort and closeShort suer from similar issues.  H6 There might not be enough incentives for liquidators to OPEN liquidate unhealthy positions Collateralized short positions opened via the Exchange can get liquidated. For a liquidatable position of size N the liquidator has to give up N PowerPerp tokens for an amount of short collateral tokens equaling the value of the position plus a liquidation bonus. Thus, a user/liquidator is incentivized to liquidate a losing position instead of just closing their position, as they will get a liquidation bonus on top of what they would get. However, the liquidator might not always get paid an amount of short collateral tokens equaling the value of the position plus a liquidation bonus according to the following condition in function ShortCollateral::liquidate: ShortCollateral::liquidate() totalCollateralReturned = liqBonus + collateralClaim; if (totalCollateralReturned > userCollateral.amount) totalCollateralReturned = userCollateral.amount; As can be seen, if the value of the position plus the liquidation bonus, or totalCollateralReturned, is greater than the positions collateral, the liquidator gets just the positions collateral. This means that if during a signicant price increase liquidations do not happen fast enough, certain losing positions will not be liquidatable for a prot, as the collaterals value will be less than that of the long position that needs to be closed. However, such a market is not healthy and this is reflected in the mark price, which lies in the center of the protocol. To avoid such scenarios (1) the collateralization ratios need to be chosen carefully while taking into account the squared nature of the perps and (2) an emergency fund should be implemented, which will be able to chip in when a position's collateral is not enough to incentivize its liquidation. 9 MEDIUM SEVERITY: ",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: High"
        ]
    },
    {
        "title": "are not able to set a minimum amount of collateral that they expect from a liquidatio ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": " OPEN Function Exchange::_liquidate does not require that totalCollateralReturned, i.e., the collateral awarded to the liquidator, is greater than a liquidator-specied minimum, thus in certain cases the liquidator might get back less than what they expected (as mentioned in issue H6). This might happen because the collateral of the position is not enough to cover the liquidations theoretical collateral claim (bad debt scenario) plus the liquidation bonus. As can be seen in the below snippet of the ShortCollaterals liquidate function, the totalCollateralReturned will be at most equal to the collateral of the specic position. ShortCollateral::liquidate() function liquidate(uint256 positionId, uint256 debt, address user) external override onlyExchange nonReentrant returns (uint256 totalCollateralReturned) // Dedaub: Code omitted for brevity uint256 collateralClaim = debt.mulDivDown(markPrice, collateralPrice); uint256 liqBonus = collateralClaim.mulWadDown(coll.liqBonus); totalCollateralReturned = liqBonus + collateralClaim; // Dedaub: This if statement can reduce totalCollateralReturned to // if (totalCollateralReturned > userCollateral.amount) totalCollateralReturned = userCollateral.amount; something smaller than expected by the liquidator { 1 userCollateral.amount -= totalCollateralReturned; // Dedaub: Code omitted for brevity }",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "funds are not optimally managed OPEN Function KangarooVault::_clearPendingOpenOrders determines if the previous open order has been successfully executed or has been canceled. In case the order has been canceled, the opposite exchange order is closed and the KangarooVault position data are adjusted to how they were before opening the order. However, the margin transferred to the Synthetix Perpetual Market, which was required for the position, is not revoked, meaning that the KangarooVault funds are not optimally managed. At the same time, when a pending close orders execution is conrmed in the function _clearPendingCloseOrders, the margin deposited to the Synthetix Perpetual Market is not reduced accordingly except when positionData.shortAmount == 0. The KangarooVault funds could also be suboptimally managed because the function KangarooVault::_openPosition does not take into account the already available margin when calculating the margin needed for a new open order. If the already opened position has available margin the KangarooVault could use part of that for its new order and transfer less than what would be needed if there was no margin available.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "and KangarooVault could be susceptible OPEN to bank runs The LiquidityPool and KangarooVault contracts could be susceptible to bank runs. As these two contracts can use up to their whole available balance, liquidity providers might rush to withdraw their deposits when they feel that they might not be able to withdraw for some time. At the same time, depositors would rush to withdraw if they 1 realized that the pools Synthetix position is in danger and their funds that have been deposited as margin could get lost. A buer of funds that are always available for withdrawal could increase the trust of liquidity providers to the system. Also, an emergency fund, which is built from fees and could help alleviate fund losses, could also help make the system more robust against bank run scenarios.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "users might be more vulnerable in a bank run OPEN In a bank run situation casual users of the LiquidityPool (i.e., users that interact with it through the web UI) might not be able to withdraw their funds. This is because the LiquidityPool oers dierent withdrawal functionality for dierent users. Power users (or protocols that integrate with the LiquidityPool) are expected to use the withdraw function, which oers immediate withdrawals for a small fee, while casual users that use the web UI will use the queueWithdraw function, which queues the withdrawal so it can be processed at a later time.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "ER",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "in LiquidityPool::withdraw OPEN Function LiquidityPool::withdraw uses a plain ERC20 transfer without checking the returned value, which is an unsafe practice. It is recommended to always either use OpenZeppelin's SafeERC20 library or at least to wrap each operation in a require statement.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "withdrawal calculations in KangarooVault OPEN Function processWithdrawalQueue processes the KangarooVaults queued withdrawals. It rst checks if the available funds are suicient to cover the withdrawal. If not, a partial withdrawal is made and the records are updated to reflect that. The QueuedWithdraw.returnedAmount eld holds the value that has been returned to the 1 user thus far. However, it doesn't correctly account for partial withdrawals as the partial amount is being assigned to instead of being added to the variable. KangarooVault::processWithdrawalQueue() function processWithdrawalQueue( uint256 idCount ) external nonReentrant { for (uint256 i = 0; i < idCount; i++) { // Dedaub: Code omitted for brevity // Partial withdrawals if not enough available funds in the vault // Queue head is not increased if (susdToReturn > availableFunds) { // Dedaub: The withdrawn amounts should be accumulated in // current.returnedAmount = availableFunds; ... returnedAmount instead of being directly assigned } else { // Dedaub: Although this branch is for full withdrawals, there // // current.returnedAmount = susdToReturn; ... may have been partial withdrawals before, so the accounting should also be cumulative here } queuedWithdrawalHead++; } }",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "exposure calculation may be inaccurate OPEN The Synthetix Perpetual Market has a two-step process for increasing/decreasing positions in which a request is submied and remains in a pending state until it is executed by a keeper. 1 LiquidityPool::_getExposure does not consider the queued Synthetix Perp position tracked by the queuedPerpSize storage variable meaning that LiquidityPool::getExposure will return an inaccurate value when called between the submission and the execution of an order. LiquidityPool::_getExposure() function _getExposure() internal view returns (int256 exposure) { // Dedaub: queuedPerpSize should be considered in currentPosition int256 currentPosition = _getTotalPerpPosition(); exposure = _calculateExposure(currentPosition); } LiquidityPool::rebalanceMargin does not consider queuedPerpSize too. The Polynomial team has mentioned that they plan to always call placeQueuedOrder before calling rebalanceMargin, thus adding a requirement that queuedPerpSize is equal to 0 would be enough to enforce that prerequisite. M8 LiquidityPool::_hedge always adds margin to OPEN Synthetix The function LiquidityPool::_hedge is responsible for hedging every position opened against the LiquidityPool by opening the opposite position in the Synthetix Perp Market. In doing so, _hedge transfers an amount of funds to the Synthetix Perp Market to be used as margin for the position. However, margin does not need to be increased always, e.g., it does not need to be increased when the Synthetix Perp position is decreased because the LiquidityPool is hedging a long Position and thus goes short. When the absolute position size of the LiquidityPool in the Synthetix Perp Market is decreased, the LiquidityPool could remove the unnecessary margin or abstain from increasing it to account for the rare case where a Synthetix order is not executed. This together with frequent calls to the rebalanceMargin function would help improve the capital eiciency of the LiquidityPool. 14 LOW SEVERITY: ",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Medium"
        ]
    },
    {
        "title": "that use invalid values could be avoide ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": " OPEN Functions getIndexPrice, getFundingRate and getMarkPrice of the Exchange contract depend on the externally provided base asset price that could be invalid in some cases. Even if the base asset price provided is invalid, a tuple (value, true) is returned where value is the value computed based on the invalid base asset price. However, if the base asset price is invalid, the tuple (0, true) could be returned while the whole computation is skipped to save gas unnecessarily spent on computing an invalid value.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "critical requirement is enforced by dependency code OPEN Function Exchange::_openTrade, when called with params.isLong set to false and params.positionId dierent from 0, does not check that the msg.sender is the owner of the params.positionId short token position. This necessary requirement is later checked when ShortToken::adjustPosition is called. Nevertheless, we would recommend adding the appropriate require statement also as part of the function _openTrade as it is the one querying the position. This would also add an extra safeguard against a future code change that accidentally removes the already existing require statement.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "critical requirement is enforced by the ER",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "OPEN In function LiquidityPool::closeLong, as in openShort, there is an outgoing flow of funds. However, there does not exist a require statement on the existence of the needed funds as in the openShort function. Of course, if there are not enough funds to be transferred out of the LiquidityPool contract the ERC20 transfer code will cause a revert. Still, requiring that usedFunds<=0 || totalFunds>=uint256(usedFunds) 1 makes the code more failproof. The same could be applied on function rebalanceMargin where there is an outgoing flow of funds towards the Synthetix Perp Market.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "critical requirement is enforced by callee code OPEN Function ShortCollateral::collectCollateral does not require that the provided collateral is approved (and matches the collateral of the already opened position). This could be problematic, i.e., a non-approved worthless collateral could be deposited instead, if every call to collectCollateral was not coupled with a call to getMinCollateral which enforces the aforementioned requirement. Implementing these requirements would constitute a step towards a more defensive approach, one that would make the system more bulletproof and robust even if the codebase continues to evolve and become more complicated.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "approvals cannot be revoked OPEN The ShortCollateral contract does not implement any functionality to revoke collateral approvals, meaning that the contract owner cannot undo even an incorrect approval and would need to redeploy the contract if that were to happen. Implementing such functionality would require a lot of care to ensure no funds (collateral) are trapped in the system, i.e., cannot be withdrawn, due to the collateral approval being revoked and the withdrawal functionality being operational only for approved collaterals.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "events are emied for several interactions OPEN  In LiquidityPool::processWithdrawals there is no event emied when a withdrawal is aempted but there are 0 funds available to be withdrawn.  In LiquidityPool::setFeeReceipient there is no event emied even though a relevant event is declared in the contract (event UpdateFeeReceipient) 1  In LiquidityPool::executePerpOrders there is no event emied when the admin executes an order  In KangarooVault::executePerpOrders there is no event emied when the admin executes an order  In KangarooVault::receive there is no event emied when the contract receives ETH in contrast to the LiquidityPool that emits an event for this",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "of minimum deposit and withdraw amount checks allow users to spam the queues with small requests OPEN In LiquidityPool, users can request to deposit or withdraw any amount of tokens by calling the queueDeposit and queueWithdraw functions. Although there are checks in place to avoid registering zero-amount requests, there are no checks to ensure that someone cannot spam the queue with requests for innitesimal amounts. LiquidityPool::queueDeposit() function queueDeposit(uint256 amount, address user) external override nonReentrant whenNotPaused(\"POOL_QUEUE_DEPOSIT\") { } require(amount > 0, \"Amount must be greater than 0\"); // Dedaub: Add a minDepositAmount check QueuedDeposit storage newDeposit = depositQueue[nextQueuedDepositId]; ... LiquidityPool::queueWithdraw() function queueWithdraw(uint256 tokens, address user) external 1 override nonReentrant whenNotPaused(\"POOL_QUEUE_WITHDRAW\") { } require(liquidityToken.balanceOf(msg.sender) >= tokens && tokens > 0); // Dedaub: Add a minWithdrawAmount check ... QueuedWithdraw storage newWithdraw = withdrawalQueue[nextQueuedWithdrawalId]; ... Even though there is no clear nancial incentive for someone to do this, an incentive would be to disrupt the normal flow of the protocol, and to annoy regular users, who would have to spend more gas until their requests were processed. However, the functions that process the queues can be called by anyone, including the admin, and users can also bypass the queues by directly depositing or withdrawing their tokens for a fee. KangarooVault suers from the same issue for withdrawals. For deposits, a minDepositAmount variable is dened and checked each time a new deposit call is made. KangarooVault::initiateDeposit() function initiateDeposit( address user, uint256 amount ) external nonReentrant { require(user != address(0x0)); require(amount >= minDepositAmount); ... } 1 KangarooVault::initiateWithdrawal() function initiateWithdrawal( address user, uint256 tokens ) external nonReentrant { require(user != address(0x0)); if (positionData.positionId == 0) { ... } else { require(tokens > 0, \"Tokens must be greater than 0\"); // Dedaub: Add a minWithdrawAmount check here QueuedWithdraw storage newWithdraw = withdrawalQueue[nextQueuedWithdrawalId]; ... } VAULT_TOKEN.burn(msg.sender, tokens); }",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "deposit and withdraw arguments are not OPEN validated LiquidityPools deposit and withdraw functions do not require that the specied user, which will receive the tokens, is dierent from address(0). The caller of the aforementioned functions might not set the parameter correctly or make the incorrect assumption that by seing it to address(0) it will default to msg.sender, leading to the tokens being sent to the wrong address. At the same time, the deposited/withdrawn amount is not required to be greater than 0.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "can be front-run OPEN The VaultToken contract declares the setVault function to solve the dual dependency problem between VaultToken and KangarooVault, as both require each 1 other's address for their initialisation. However, this function can be called by anyone, whereas the vault address can only be set once. As a result, we raise a warning here to emphasize that the VaultToken contract needs to be correctly initialized, as otherwise the call could be front-run or repeated (in case the initialization performed by the protocol team fails for some reason and the uninitialized variable remains unnoticed) to initialize the vault storage variable with a malicious Vault address. L10 LiquidityPool::closeShort should use mulWadUp too OPEN The closeShort function of the LiquidityPool contract has the same logic as openLong. openLong passes the rounding error cost to the user by using mulWadUp for the tradeCost calculation. However, closeShort does not adopt this behavior and uses mulWadDown for the same calculation. We recommend changing this to be the same as openLong. CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) ",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": " OPE In LiquidityPool, the admin has increased power over its position leverage and the margin that is deposited to or withdrawn from the Synthetix Perp Market. More specically: First of all, the admin can arbitrarily set the leverage through the LiquidityPools updateLeverage function. Essentially, the risk of the LiquidityPool can be arbitrarily increased. LiquidityPool::updateLeverage() function updateLeverage(uint256 _leverage) external requiresAuth { require(_leverage >= 1e18); emit UpdateLeverage(futuresLeverage, _leverage); futuresLeverage = _leverage; } LiquidityPool::_calculateMargin() function _calculateMargin( int256 size ) internal view returns (uint256 margin) { (uint256 spotPrice, bool isInvalid) = baseAssetPrice(); require(!isInvalid && spotPrice > 0); uint256 absSize = size.abs(); margin = absSize.mulDivDown(spotPrice, futuresLeverage); } The admin is also responsible for managing the margin of the pools Synthetix Perp position. Via the LiquidityPool::increaseMargin function, the admin can use up to the whole available balance of the pool. The logic that decides when the aforementioned function is called is o-chain. LiquidityPool::increaseMargin() function increaseMargin( 2 uint256 additionalMargin ) external requiresAuth nonReentrant { perpMarket.transferMargin(int256(additionalMargin)); usedFunds += int256(additionalMargin); require(usedFunds <= 0 || totalFunds >= uint256(usedFunds)); emit IncreaseMargin(additionalMargin); } Additionally, the LiquidityPool::rebalanceMargin function can be used to increase or decrease the pools margin inside the limits set by the pools leverage and the margin limits set by Synthetix. Again the logic that decides the marginDelta parameter and calls rebalanceMargin is o-chain. The KangarooVault suers from similar centralization issues. Nevertheless, the function setLeverage of the KangarooVault does not allow the admin to set the leverage to more than 5x. N2 LiquidityPool admin can drain all deposited funds by being able to arbitrarily set the fee percentages OPEN In LiquidityPool, there are several functions that only the admin can control and allow him to parameterise all fee variables, such as deposit and withdrawal fees. However, there are no limits imposed on the values set for these variables. LiquidityPool::setFees() function setFees( uint256 _depositFee, uint256 _withdrawalFee ) external requiresAuth { ... // Dedaub: We recommend adding checks for depositFee and withdrawalFee // to prevent unrestricted fee rates 2 depositFee = _depositFee; withdrawalFee = _withdrawalFee; } This means that the admin could change the deposit/withdrawal fee and have all the newly deposited/withdrawn funds moved to the feeRecipient address. Apart from the obvious centralisation issue, such checks could prevent huge losses in the event of a compromise of the admin account or the protocol itself. On the other hand, such checks have been used in the KangarooVault and thus we strongly recommend adding them to LiquidityPool as well. KangarooVault::setFees() function setFees( uint256 _performanceFee, uint256 _withdrawalFee ) external requiresAuth { require(_performanceFee <= 1e17 && _withdrawalFee <= 1e16); ... performanceFee = _performanceFee; withdrawalFee = _withdrawalFee; } The same applies for the following functions that also need limits on the possible values that can be set by the admin:  LiquidityPool::updateLeverage() (see also N1 for an example)  LiquidityPool::updateStandardSize()  LiquidityPool::setBaseTradingFee()  LiquidityPool::setDevFee()  LiquidityPool::setMaxSlippageFee() 2 OTHER / ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "requirements can be added ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": " INFO Functions _addCollateral and _removeCollateral of the Exchange contract do not require that amount > 0. Function _liquidate does not require that debtRepaying > 0.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "does not check if the collateral is already approved INFO Function ShortCollateral::approveCollateral does not require that collateral.isApproved == false to disallow approving the same collateral more than once.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "can return early in some cases INFO In LiquidityPool::hedgePositions there is no handling of the case where newPosition is equal to 0 and the execution can return early.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "pause logic used in KangarooVault INFO Core contracts of the protocol such as LiquidityPool and Exchange inherit the PauseModifier and use separate pause logic on several functions. In contrast, KangarooVault, which has an implemented logic similar to LiquidityPool, inherits the PauseModifier but it does not use the whenNotPaused modier on any function.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "logic can be optimized to save gas INFO 2 In the functions LiquidityPool::processWithdraws and KangarooVault::processWithdrawalQueue, the LP token price is calculated in every iteration of the loop that processes withdrawals when in fact it does not change. Thus, the computation could be performed once, before the loop, to save gas.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "calls to LiquidityPool from KangarooVault INFO The functions removeCollateral and _openPosition of the KangarooVault contract, call LiquidityPool::getMarkPrice to get the mark price. However, this function only calls Exchange::getMarkPrice without adding any extra functionality. Therefore, we recommend making a direct call to Exchange::getMarkPrice from KangarooVault instead, to save some gas.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "could be made external INFO The following functions could be made external instead of public, as they are not called by any of the contract functions: Exchange.sol  refresh  orderFee LiquidityPool.sol LiquidityToken.sol PowerPerp.sol ShortToken.sol  refresh ShortCollateral.sol SynthetixAdapter.sol  refresh  getMinCollateral  canLiquidate  maxLiquidatableDebt  getSynth  getCurrencyKey  getAssetPrice  getAssetPrice SystemManager.sol  init  setStatusFunction 2",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "overrides INFO All function and storage variable overrides in the Exchange, LiquidityPool, ShortCollateral and SynthetixAdapter contracts are redundant and can be removed.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "storage variables INFO There is a number of storage variables that are not used:  Exchange:SUSD  KangarooVault:maxDepositAmount  LiquidityPool:addressResolver",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "variables can be made immutable INFO The following storage variables can be made immutable: SystemManager.sol SynthetixAdapter.sol  addressResolver  futuresMarketManager  synthetix  exchangeRates",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "is not used INFO The function liquidate of the LiquidityPool contract is not called by the Exchange, which is the only contract that would be able to call it. At the same time, this means that the LiquidityPool::_hedge function is always called with its second argument being set to false. Furthermore, if this function is maintained for future use, we raise a warning here that hedgingFees are accounted for twice. Once by LiquidityPool::_hedge and another one directly inside liquidate function. LiquidityPool::liquidate() function liquidate( 2 uint256 amount ) external override onlyExchange nonReentrant { ... uint256 hedgingFees = _hedge(int256(amount), true); // Dedaub: hedgingFees are double counted here usedFunds += int256(hedgingFees); emit Liquidate(markPrice, amount); }",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "code comment INFO The code comment of KangarooVault::saveToken mentions Save ER",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "from the vault (not SUSD or UNDERLYING) when there is no notion of an UNDERLYING token.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "in the use of the word recipient INFO In LiquidityPool, KangarooVault and ILiquidityPool, all appearances of the word recipient word contain a typo and are wrien as receipient. For example, the fee recipient storage variable is wrien as feeReceipient instead of feeRecipient.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "duplication INFO The functions canLiquidate and maxLiquidatableDebt of ShortCollateral.sol share a large proportion of their code. For readability this part coud be included in a separate method.",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "large liquidation bonus percentage could lead to a decrease instead of the expected increase- of the collateral ratio INFO A liquidation of a part of an underwater position is expected to increase its collateralization ratio. In a partial liquidation, the liquidator deletes part of the position 2 and gets collateral of the same value, but also some extra collateral as liquidation bonus. If the liquidation bonus percentage is large, the collateral ratio after the liquidation could be lower compared to the one before. The parameters of the protocol should be chosen carefully to avoid this problem. For example: WIPEOUT_CUTOFF * coll.liqRatio > 1 + coll.liqBonus",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Polynomial/Polynomial Power Perp Contracts Audit - Apr '23.pdf",
        "body": "check that normalizationUpdate is positive INFO The functions getMarkPrice and updateFundingRate of the Exchange contract compute the normalizationUpdate variable using the formula: int256 totalFunding = wadMul(fundingRate, (currentTimeStamp - fundingLastUpdatedTimestamp)); int256 normalizationUpdate = 1e18 - totalFunding; Although the fundingRate is bounded (it takes values between -maxFunding and maxFunding), the dierence currentTimeStamp - fundingLastUpdatedTimestamp is not, therefore totalFunding can in principle have an arbitrarily large value, especially a value greater than 1e18 (using 18 decimals precision). The result would be a negative normalizationUpdate and negative mark price, which would mess all the computations of the protocol. A check that normalizationUpdate is positive could be added. Nevertheless, since the value of the maxFunding is 1e16, the protocol has to be inactive for at least 100 days, before this issue occurs. A17 Compiler version and possible bugs INFO The code can be compiled with Solidity 0.8.9 or higher. For deployment, we recommend no floating pragmas, but a specic version, to be condent about the baseline guarantees oered by the compiler. Version 0.8.9, in particular, has some known bugs, which we do not believe aect the correctness of the contracts. 2",
        "labels": [
            "Dedaub",
            "Polynomial Power Perp Contracts",
            "Severity: Informational"
        ]
    },
    {
        "title": "is susceptible to front-running RESOLVED The OptionExchange contracts redeem() function calls _swapExactInputSingle() with minimum output set to 0, making it susceptible to a front-running/sandwich aack when collateral is being liquidated. It is recommended that a minimum representing an acceptable loss on the swap is used instead. // OptionExchange::redeem function redeem(address[] memory _series) external { _onlyManager(); uint256 adLength = _series.length; for (uint256 i; i < adLength; i++) { // ... Dedaub: Code omied for brevity. if (otokenCollateralAsset == collateralAsset) { // ... Dedaub: Code omied for brevity. } else { // Dedaub: Minimum output set to 0. Susceptible to sandwich aacks. uint256 redeemableCollateral = _swapExactInputSingle(redeemAmount, 0, otokenCollateralAsset); SafeTransferLib.safeTransfer( ERC20(collateralAsset),address(liquidityPool),redeemableCollateral ); emit RedemptionSent( redeemableCollateral, collateralAsset, address(liquidityPool) );  } } } H2 VolatilityFeed updates are susceptible to front-running DISMISSED The VolatilityFeed contract uses the SABR model to compute the implied volatility of an option series. This model uses a number of parameters which are regularly updated by a keeper through the updateSabrParameters() function. It is possible for an aacker to front-run this update, transact with the LiquidityPool at the old price and then transact back with the LiquidityPool at the new price (computed in advance) if the dierence is protable. The Rysk team has indicated that trading will be paused for a few blocks to allow for parameter updates to happen and to eectively prevent this situation. MEDIUM SEVERITY: ID Description M1 No staleness check on the volatility feed ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": " ACKNOWLEDGED The function quoteOptionPrice of the BeyondPricer contract retrieves the implied volatility from the function VolatilityFeed::getImpliedVolatility(). However, the returned value is not accompanied by a timestamp that can be used by the quoteOptionPrice() function to determine whether the value is stale or not. Since the implied volatility returned is aected by a keeper, which is responsible for updating the parameters of the underlying SABR model, it is recommended that staleness checks are implemented in order to avoid providing wrong implied volatility values. 5 LOW SEVERITY: ",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: High"
        ]
    },
    {
        "title": "use of price feeds for the price of the underlyin ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": " DISMISSED The BeyondPrice contract gets the price of the underlying token via the function _getUnderlyingPrice(), which consults a Chainlink price feed for the price. // BeyondPrice::_getUnderlyingPrice function _getUnderlyingPrice(address underlying, address _strikeAsset) internal view returns (uint256) { } return PriceFeed(protocol.priceFeed()). getNormalizedRate(underlying, _strikeAsset); However, when trying to obtain the same price in the function _getCollateralRequirements(), the addressBook is used to get the price feed from an Oracle implementing the IOracle interface. // BeyondPrice::_getCollateralRequirements function getCollateralRequirements( Types.OptionSeries memory _optionSeries, uint256 _amount ) internal view returns (uint256) { IMarginCalculator marginCalc = IMarginCalculator(addressBook.getMarginCalculator()); return marginCalc.getNakedMarginRequired(  _optionSeries.underlying, _optionSeries.strikeAsset, _optionSeries.collateral, _amount / SCALE_FROM, _optionSeries.strike / SCALE_FROM, // assumes in e18 IOracle(addressBook.getOracle()).getPrice(_optionSeries.underlying), _optionSeries.expiration, 18, // always have the value return in e18 _optionSeries.isPut ); } The same addressBook technique is used in the getCollateral() function of the OptionRegistry contract and in the checkVaultHealth() function of the Option registry contract. It is recommended that this is refactored to use the Chainlink feed in order to avoid a situation where dierent prices for the underlying are obtained by dierent parts of the code. The Rysk team intends to keep the price close to what the Opyn system would quote, thus using the Opyn chainlink oracle is actually correct as it represents the actual situation that would occur for these given quotes L2 Multiple uses of div before mul in OptionExchanges _handleDHVBuyback() function RESOLVED In the OptionExchange contracts _handleDHVBuyback() function, a division is used before a multiplication operation at lines 925 and 932. It is recommended to use multiplication prior to division operations to avoid a possible loss of precision in the calculation. Alternatively, the mulDiv function of the PRBMath library could be used.  CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) ",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "reentrancy in OptionRegistry::redeem() ACKNOWLEDGED The OptionRegistrys redeem() function is not access controlled and calls the OpynInteractions library contracts redeem() function, which interacts with the GammaController and the option and collateral tokens. Dedaubs static analysis tools warned about a potential reentrancy risk. Our manual inspection identied no such immediate risk, but as the tokens supported are not strictly dened and a future version of the code could potentially make such an aack possible, it is advisable to add a reentrancy guard around OptionRegistrys redeem() function.",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "optimisation in OptionRegistrys open() function ACKNOWLEDGED The OptionRegistry::open() function performs the assignment vaultIds[series] = vaultId_ on line 271. But this can be moved into the if block starting at line 255, since the vaultId_ only changes value if this if block is executed. // OpenRegistry::open function open( address _series, uint256 amount, uint256 collateralAmount ) external returns (bool, uint256) { _isLiquidityPool(); // make sure the options are ok to open Types.OptionSeries memory series = seriesInfo[_series]; // assumes strike in e8 if (series.expiration <= block.timestamp) {  revert AlreadyExpired(); } // ... Dedaub: Code omied for brevity. if (vaultId_ == 0) { vaultId_ = (controller.getAccountVaultCounter(address(this))) + 1; vaultCount++; } // ... Dedaub: Code omied for brevity. // Dedaub: Below assignment can be moved inside the above block. vaultIds[_series] = vaultId_; // returns in collateral decimals return (true, collateralAmount); }",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "comment in OptionExchanges _swapExactInputSingle() function RESOLVED The OptionExchanges _swapExactInputSingle() function denition is annotated with several misleading comments. For instance, it mentions that _amountIn has to be in WETH when it can support any collateral token. It also mentions that _assetIn is the stablecoin that is bought, when it is in fact the collateral that is swapped. The description of the function, which reads function to sell exact amount of WETH to decrease delta is incorrect. // OptionExchange::_swapExactInputSingle /** @notice function to sell exact amount of wETH to decrease delta * @param _amountIn the exact amount of wETH to sell * @param _amountOutMinimum the min amount of stablecoin willing to receive. Slippage limit. * @param _assetIn the stablecoin to buy * @return the amount of usdc received */ function _swapExactInputSingle( 1 uint256 _amountIn, uint256 _amountOutMinimum, address _assetIn) internal returns (uint256) { // ... Dedaub: Code omied for brevity. }",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "comment in BeyondPricers _getSlippageMultiplier() function RESOLVED The division of the _amount by 2, mentioned in the code comment, does not appear in the code. It appears that this comment corresponds to a previous version of the codebase and it should be removed. //BeyondPricer::_getSlippageMultiplier function _getSlippageMultiplier( uint256 _amount, int256 _optionDelta, int256 _netDhvExposure, bool _isSell ) internal view returns (uint256 slippageMultiplier) { // divide _amount by 2 to obtain the average exposure throughout the tx. // Dedaub: The above comment is not relevant any more. // ... Dedaub: Code omied for brevity. }",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "librarys lognormalVol() can in principle return negative values ACKNOWLEDGED The formula of the SABR model that is responsible for computing the implied volatility (hps://web.math.ku.dk/~rolf/SABR.pdf formula (2.17a)) is an approximate one. It is not clear to us if this value will always be non-negative as it should be. For example, 1 for absolute values of  close to 1 and large values of v, the last term of this formula, and probably the whole value of the implied volatility will be negative. The execution of VolatilityFeed::getImpliedVolatility will revert if the value returned by lognormalVol() is non-negative, to protect the protocol from using this absurd value. Nevertheless, if this keeps happening for a while, the protocol will be unable to price the options and therefore will be unable to work. This issue could be avoided either by a careful choice of the SABR parameters by the protocols keepers or by using an alternative volatility feed in case this happens.",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "check in BeyondPricers quoteOptionprice() RESOLVED In BeyondPricer::quoteOptionPrice() a check that _optionseries.expiration >= block.timestamp is missing. If the function is called to price an option series with a past expiration date, it will return an absurd result. We suggest adding a check that would revert the execution with an appropriate message in case the condition is not satised.",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "is dened as public even though its name suggests otherwise RESOLVED Function OptionExchange::_checkHash, which returns if an option series is approved or not, is dened as public. However, the starting underscore in _checkHash implies that this functionality should not be exposed externally (via the public modier) creating an inconsistency, even though it is probably useful/necessary to the users of the protocol.",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "returns an incorrect value RESOLVED Whenever a user wants to buy an amount of options, rst it is checked if the long exposure of the protocol to this option series is positive. If this is the case, then the protocol rst sells the options it holds, to decrease its long exposure, and if they are not 1 enough, then the Liquidity pool writes extra options to reach the amount requested by the user. The problem is that the _buyOption function, in the case the Liquidity pool is called to write these extra options, returns only this extra amount, and not the total amount sold to the user.",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk Audit - Feb '23.pdf",
        "body": "of compiler versions RESOLVED The code of the BeyondPricer, OptionExchange and OptionCatalogue contracts is compiled with the floating pragma >=0.8.0, and the OptionRegistry contract is compiled with the floating pragma >=0.8.9. It is recommended that the compiler version is xed to a specic version and that this is kept consistent amongst source les. A10 Compiler bugs ACKNOWLEDGED The code of the BeyondPricer, OptionExchange and OptionCatalogue contracts is compiled with the floating pragma >=0.8.0, and the OptionRegistry contract is compiled with the floating pragma >=0.8.9. Versions 0.8.0 and 0.8.9 in particular, have some known bugs, which we do not believe aect the correctness of the contracts. 1",
        "labels": [
            "Dedaub",
            "Rysk",
            "Severity: Informational"
        ]
    },
    {
        "title": "out of gas situation in RewardDistributor and DecollateralisationManager contract ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Solid World/Solid World Audit - Feb '23.pdf",
        "body": " DISMISSED The RewardsDistributor::getAllUnclaimedRewardAmountsForUserAndAsset() function performs a nested loop that iterates over all possible rewards for all amounts staked by a given user. Since both of these amounts are potentially unbounded, an out of gas error may eventually occur. //RewardsDistributor.sol::getAllUnclaimedRewardAmountsForUserAndAsset function getAllUnclaimedRewardAmountsForUserAndAssets( address[] calldata assets, address user external view override returns (address[] memory rewardsList, uint[] memory unclaimedAmounts) RewardsDataTypes.AssetStakedAmounts[] memory assetStakedAmounts = _getAssetStakedAmounts(assets,user); rewardsList = new address[](_rewardsList.length); unclaimedAmounts = new uint[](rewardsList.length); ) {  for (uint i; i < assetStakedAmounts.length; i++) { for (uint r; r < rewardsList.length; r++) { rewardsList[r] = _rewardsList[r]; unclaimedAmounts[r] += _assetData[assetStakedAmounts[i].asset] .rewardDistribution[rewardsList[r]] .userReward[user] .accrued; if (assetStakedAmounts[i].userStake == 0) { continue; } unclaimedAmounts[r] += _computePendingRewardAmountForUser( user, rewardsList[r], assetStakedAmounts[i] ); } } return (rewardsList, unclaimedAmounts); } Similarly, the function getBatchesDecollateralisationInfo() of the contract DecollateralisationManager loops over all batchIds, the number of which could be unbounded. As already mentioned, this might eventually lead to an out of gas failure. //DecollateralisationManger.sol::getBatchesDecollateralisationInfo() function getBatchesDecollateralizationInfo( SolidWorldManagerStorage.Storage storage _storage, uint projectId, uint vintage external view returns (DomainDataTypes.TokenDecollateralizationInfo[] memory result) ) {  DomainDataTypes.TokenDecollateralizationInfo[] memory allInfos = new DomainDataTypes.TokenDecollateralizationInfo[]( _storage.batchIds.length ); uint infoCount; for (uint i; i < _storage.batchIds.length; i++) { uint batchId = _storage.batchIds[i]; if ( _storage.batches[batchId].vintage != vintage || _storage.batches[batchId].projectId != projectId ) { continue; } (uint amountOut, uint minAmountIn, uint minCbtDaoCut) = _simulateDecollateralization( _storage, batchId, DECOLLATERALIZATION_SIMULATION_INPUT ); // Dedaub: part of the code is omitted for brevity infoCount = infoCount + 1; } result = new DomainDataTypes.TokenDecollateralizationInfo[](infoCount); for (uint i; i < infoCount; i++) { result[i] = allInfos[i]; } } This issue was discussed with the Solid World team, who estimated that the protocol will not use enough reward tokens, stakes or batchIds to cause it to run out of gas. 7 LOW SEVERITY: ID Descriptio ",
        "labels": [
            "Dedaub",
            "Solid World",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Solid World/Solid World Audit - Feb '23.pdf",
        "body": "use of the override modier in several contracts RESOLVED In several contracts (most of which have been forked from Aave), many functions are marked with the override modier when no such function is actually inherited by the parent contract. These are probably leftovers from the time (prior to Solidity 0.8.8) when the override keyword was mandatory when a contract was implementing a function from a parent interface EmissionManager  congureAssets  setRewardOracle  setDistributionEnd  setEmissionPerSecond  updateCarbonRewardDistribution  setClaimer  setRewardsVault  setEmissionManager  setSolidStaking  setEmissionAdmin  setCarbonRewardsManager  getRewardsController  getEmissionAdmin  getCarbonRewardsManager RewardsController  getRewardsVault 1  getClaimer  getRewardOracle  congureAssets  setRewardOracle  setClaimer  setRewardsVault  setSolidStaking  handleUserStakeChange  claimAllRewards  claimAllRewardsOnBehalf  claimAllRewardsToSelf RewardsDistributor  getRewardDistributor  getDistributionEnd  getRewardsByAsset  getAllRewards  getUserIndex  getAccruedRewardAmountForUser  getUnclaimedRewardAmountForUserAndAssets  setDistributionEnd  setEmissionPerSecond  updateCarbonRewardDistribution SolidStaking  addToken  stake  withdraw  withdrawStakeAndClaimRewards  balanceOf  totalStaked  getTokensDistributor::getAllUnclaimedReward Resolved in commit 1ad958b6f0d74507c038bd49da281a572e170907. 1",
        "labels": [
            "Dedaub",
            "Solid World",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Solid World/Solid World Audit - Feb '23.pdf",
        "body": "events could incorporate additional information INFO Creation events, CategoryCreated, ProjectCreated, BatchCreated, could include more information related to the category, project or batch associated with them.",
        "labels": [
            "Dedaub",
            "Solid World",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Solid World/Solid World Audit - Feb '23.pdf",
        "body": "related gas optimization RESOLVED The elds of DomainDataTypes::Category struct can be reordered to be tighter packed in 4 instead of 5 storage slots. // DomainDataTypes.sol::Category struct Category { uint volumeCoefficient; uint40 decayPerSecond; uint16 maxDepreciation; uint24 averageTA; uint totalCollateralized; uint32 lastCollateralizationTimestamp; uint lastCollateralizationMomentum; } // Dedaub: tighter packed version struct Category { uint volumeCoefficient; uint40 decayPerSecond; uint16 maxDepreciation; uint24 averageTA; uint32 lastCollateralizationTimestamp; uint totalCollateralized; uint lastCollateralizationMomentum; } We measured that in certain test cases the use of less SLOAD and STORE instructions reduced the gas consumption by around 1.5-2% and did not cause any regression in 1 terms of gas consumption (and of course correctness). Resolved in commit b3e79c2456ecca913be0165fd49992eba8e6e1. A4 Compiler version and possible bugs RESOLVED The code is compiled with the floating pragma ^0.8.16. It is recommended that the pragma is xed to a specic version. Versions ^0.8.16 of Solidity in particular, have some known bugs, which we do not believe aect the correctness of the contracts. Resolved in commit d68cfaf512d5eb8da646780350713d6c98ad7da2. 1",
        "labels": [
            "Dedaub",
            "Solid World",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Furucombo/Furucombo smart wallet and gelato audit Sep 21.pdf",
        "body": "use of weak blacklists Furucombo Gelato makes use of a number of blacklists including: - Who can create a new task - What task can be created It is however trivial for any user to get around this blacklisting style. For instance, in the case of a task, one can simply add some additional calldata which does not aect the semantics of the task. Therefore, if there is a reason to blacklist users or tasks, a stronger mechanism needs to be designed. L2 delegateCallOnly methods not properly guarded in Actions CLOSED In TaskExecutor the delegateCallOnly() modier is dened to ensure that the batchExec() method is only called via delegate call, as intended by the deployers. This can be reused by the other Actions as well, to make sure that they are not misused. 0 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend addressing them. ",
        "labels": [
            "Dedaub",
            "Furucombo smart wallet and gelato",
            "Severity: Low"
        ]
    },
    {
        "title": "pragma ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Furucombo/Furucombo smart wallet and gelato audit Sep 21.pdf",
        "body": " CLOSED The floating pragma pragma solidity ^0.6.0; is used in most contracts, allowing them to be compiled with the 0.6.0 - 0.6.12 versions of the Solidity compiler. Although the dierences between these versions are small, floating pragmas should be avoided and the pragma should be xed to the version that will be used for the contracts deployment. A2 Compiler known issues INFO The contracts were compiled with the Solidity compiler 0.6.12 which, at the time of writing, has multiple issues related to memory arrays. Since furrucombo-smart-wallet makes heavy use of memory arrays, and sending and receiving these to third party contracts, it is worth considering switching to a newer version of the Solidity compiler. 0",
        "labels": [
            "Dedaub",
            "Furucombo smart wallet and gelato",
            "Severity: Informational"
        ]
    },
    {
        "title": "allows anyone with a seat to reach maxSeatScore for an arbitrary number of seats ",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": " RESOLVED (commit ccbf56c) This function mints as many 1-score seats as the current seat score of seatId function separateSeats(uint256 seatId) public { require(msg.sender == ownerOf(seatId)); uint256 currentSeatScore = seatScore[seatId]; for(uint i = 0; i < currentSeatScore; i++) { uint mintIndex = totalSupply(); _safeMint(msg.sender, mintIndex); seatScore[mintIndex] = 1; } }  However, AoriSeats::separateSeats does not burn the seatId that gets separated, allowing someone to call the function for the same seatId multiple times. For instance, a seat holder can get innitely many 1-score seats and combine them using AoriSeats::combineSeats to reach maxSeatScore. The user exploiting this will be able to receive the maximum amount of fee rewards when one of their seatIds gets used within the protocol. H2 AoriPut/AoriCall::setSettlementPrice() can be called multiple times, with counter-intuitive results RESOLVED (commit 0b6dd23) The function setSettlementPrice ensures neither that it is called atomically with the rst selement nor that it cannot be called again. function setSettlementPrice() public returns (uint256) { require(block.number >= endingBlock); settlementPrice = uint256(getPrice()); hasEnded = true; return settlementPrice; } As a result, a buyer or seller of an option can wait for an opportune moment to call the function. Indeed, some amount of the same option can be seled in-the-money with some other being seled out-of-the-money. Ideally, the selement price for the entire option should be set once and for all by the rst party that seles (as early as possible after the ending block, which is loosely ensured by at least one of the parties having a nancial incentive to sele at the current price). MEDIUM SEVERITY: 7 ",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: High"
        ]
    },
    {
        "title": "can reuse seatIds with surprising result ",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": " RESOLVED (commit d343c42) Function combineSeats burns two seat NFTs and mints another, at the totalSupply() index. function combineSeats(uint256 seatIdOne, uint256 seatIdTwo) public returns(uint256) {  _burn(seatIdOne); _burn(seatIdTwo); uint256 newSeatId = totalSupply(); _safeMint(msg.sender, newSeatId); seatScore[newSeatId] = seatScore[seatIdOne] + seatScore[seatIdTwo]; return seatScore[newSeatId]; } However, the totalSupply() index is not guaranteed to not have been seen before. The totalSupply of an OpenZeppelin ERC721Enumerable is just the length of the enumerability array. When a token is being burned, it is removed from that array, its empty slot swapped with the last element, and the array gets truncated. Therefore, the above code will return as newSeatId an id that was previously used for dierent purposes. Although the seatScore is overwrien in the code, other data (namely, the totalVolumeBySeat) are not, and their old values will be confused with new. The resolution of this issue (possibly by overriding function _beforeTokenTransfer to avoid reusing numbers) should be thoroughly tested, specically by checking the indexes of old/new seatIds. It is unclear to us where the enumerability of NFTs functionality is used anyway. (This may mean that we are missing a potential threat in external use of ids that relates to the above behavior or its x.)",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "probably erroneous, fees in a Bid DISMISSED  The calculation of fees in Bid::ll assumes that the caller (i.e., the option seller that agrees to the Bid) has already factored the cost of fees into the amountOfOPTION argument. Specically, the amount of options that the bid initiator/creator receives is exactly what the caller of fill has specied in amountOfOPTION but the Bid creators USDC is supposed to cover the cost of both these options (per the options OPTIONPerUSDC factor) and the fees. function fill(uint256 amountOfOPTION, uint256 seatId) public nonReentrant {  if(msg.sender == AORISEATSADD.ownerOf(seatId)) {  } else { //No taker fees are paid in option tokens, but rather USDC. OPTIONAfterFee = amountOfOPTION; //And the amount of the quote currency the msg.sender will receive USDCToReceive = mulDiv(OPTIONAfterFee, USDCDecimals, OPTIONPerUSDC);  USDC.transfer(Ownable(factory).owner(), ownerTxFee); USDC.transfer(AORISEATSADD.ownerOf(seatId), seatTxFee); USDC.transfer(msg.sender, USDCToReceive); //Tracking the liquidity mining rewards AORISEATSADD.addTakerPoints(feeMultiplier * (ownerTxFee / decimalDiff), msg.sender, factory); AORISEATSADD.addTakerPoints(feeMultiplier * (seatTxFee / decimalDiff), AORISEATSADD.ownerOf(seatId), factory); //Tracking the volume in the NFT AORISEATSADD.addTakerVolume(USDCToReceive, seatId, factory); }  } This can be argued to be a design decision, but it has several surprising/inconsistent consequences: - It puts a burden on external callers to do this calculation or risk reverting due to insuicient USDC in the contract.  - The taker of a Bid pays the fees, but the maker of a Bid gets the points, per the above addTakerPoints call! This is an asymmetry with Ask: whoever pays fees is likely expecting to get points. - Another asymmetry with Asks is that, in an Ask, the above addTakerVolume calculation includes the USDC spent on fees. Here it does not.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "fee distribution in Asks and Bids RESOLVED (commit ccbf56c) Bid::fill features the following logic (analogous logic can be found in Ask::fill):  if(msg.sender == AORISEATSADD.ownerOf(seatId)) {  } else { //No taker fees are paid in option tokens, but rather USDC. OPTIONAfterFee = amountOfOPTION; //And the amount of the quote currency the msg.sender will receive USDCToReceive = mulDiv(OPTIONAfterFee, USDCDecimals, OPTIONPerUSDC); //1eY = (1eX * 1eY) / 1eX //What the user will receive out of 100 percent in referral fees with a floor of 40 uint256 refRate = (AORISEATSADD.getSeatScore(seatId) * 5) + 35; //This means for Aori seat governance they should not allow more than 12 seats to be combined at once uint256 seatScoreFeeInBPS = mulDiv(fee, refRate, 100); uint256 ownerTxFee = mulDiv(USDCToReceive, seatScoreFeeInBPS, 10000); uint256 seatTxFee = mulDiv(USDCToReceive, fee - seatScoreFeeInBPS, 10000); respectively. //Transfers from the msg.sender OPTION.transferFrom(msg.sender, seller, OPTIONAfterFee); //Fee transfers are all in USDC, so for Bids they're routed here //These are to the Factory, the Aori seatholder, then the buyer USDC.transfer(Ownable(factory).owner(), ownerTxFee); USDC.transfer(AORISEATSADD.ownerOf(seatId), seatTxFee); 1 USDC.transfer(msg.sender, USDCToReceive);  } In principle, the higher the seat score, the larger the fee rewards that the seatId owner should receive. In the above case, however, a seatId with a higher score will receive fewer fees than a seatId with a lower seat score, simply because fee - seatScoreFeeInBPS will represent a larger value in the case of a lower seat score. Additionally, the owner of the Orderbook contract will be the one receiving the seat fees, while the owner of the seat will receive whatever is left. This is asymmetrical with the logic that AoriPut::mintPut and AoriCall::mintCall implement:  the fees //If the owner of the seat is not the caller, calculate and transfer mintingFee = putUSDCFeeCalculator(quantityOfUSDC, AORISEATSADD.getOptionMintingFee()); uint256 refRate = (AORISEATSADD.getSeatScore(seatId) * 5) + 35; // Calculating the fees out of 100 to go to the seat owner feeToSeat = (refRate * mintingFee) / 100; optionsToMint = ((quantityOfUSDC - mintingFee) * 10**USDC.decimals()) / strikeInUSDC; //(1e6*1e6) / 1e6 optionsToMintScaled = optionsToMint * decimalDiff; //transfer the USDC and route fees USDC.transferFrom(msg.sender, address(this), optionsToMint); USDC.transferFrom(msg.sender, Ownable(factory).owner(), mintingFee - USDC.transferFrom(msg.sender, AORISEATSADD.ownerOf(seatId), feeToSeat); feeToSeat);  The above-mentioned points imply that perhaps the fees of the seat owner and the owner of the Orderbook contract are inverted for both Ask::ll and Bid::ll. 1 M4 The functionality of AoriCall::sellerSettlementITM (and AoriPut::sellerSettlementITM) breaks under intended parameters RESOLVED (commit ccbf56c) Both implementations use the wrong inequality between optionsToSettle and optionsSold (>= should be used instead) function sellerSettlementITM(uint256 optionsToSettle) public nonReentrant returns (uint256) {  uint256 optionsSold = optionSellers[msg.sender];  require(optionsSold > 0 && optionsSold <= optionsToSettle); require(settlementPrice > strikeInUSDC && hasEnded == true); uint256 UNDERLYINGToReceive = ((strikeInUSDC * USDC.decimals()) / settlementPrice) * optionsSold; // (1e6*1e6/1e6) * 1e18 //store the settlement uint256 newOptionsSold = optionsSold - optionsToSettle; optionSellers[msg.sender] = newOptionsSold; //settle UNDERLYING.transfer(msg.sender, UNDERLYINGToReceive / 10**USDC.decimals());  } Both AoriCall::sellerSettlementITM and AoriPut::sellerSettlementITM will revert if the seller chooses to sele fewer options than his optionSellers balance, breaking part of the intended functionality. Additionally, AoriCall::sellerSettlementITM (the code snippet above) should be computing UNDERLYINGToReceive by multiplying with optionsToSettle and not optionsSold 12 LOW SEVERITY: ",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Medium"
        ]
    },
    {
        "title": "function can revert, possibly causing UI problem ",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": " PARTLY RESOLVED View functions Ask::getAmountFilled and Bid::getAmountFilled will revert if an aacker sends (even a tiny amount of) extra tokens to the contract (via a direct transfer). This is not a problem at the level of the contract, but could render an unsuspecting UI unusable until there is human intervention, thus causing an eective DoS for lile cost. function getCurrentBalance() public view returns (uint256) { return USDC.balanceOf(address(this)); } function getAmountFilled() public view returns (uint256) { return (USDCSize - getCurrentBalance()); } Similarly, the amounts that these functions return are not to be fully trusted by external agents, as they can be lower than actual.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "(and Bid::fundContract) feature a questionable design (LARGELY) RESOLVED While we did not nd direct consequences in terms of security, the implementation of Ask::fundContract (and Bid::fundContract) raises questions on whether the intended functionality behind the funding of an Ask or a Bid has been fully thought of. function fundContract() public nonReentrant { require(msg.sender == seller); require(OPTION.balanceOf(msg.sender) >= OPTIONSize); OPTION.transferFrom(msg.sender, address(this), OPTIONSize); startingBlock = block.number; endingBlock = block.number + duration; emit OfferFunded(seller, OPTIONSize, duration); 1 } We took note of the following points: - This function can be called multiple times - Anyone may fund an Ask by directly sending OPTION (or USDC in the case of a Bid) tokens to the contract. This has the additional eect of making OPTIONSize (and USDCSize) simply serve as a minimum.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Low"
        ]
    },
    {
        "title": "(and AoriPut::getPrice) do not perform staleness checks on the round data received by the Chainlink Aggregator RESOLVED (commits 5338e86, 8a74178) Even though the AggregatorV3::latestRoundData function provides various return values that can be used to check the staleness of an answer (e.g., as the result of oracle downtime or the update round being incomplete at the time of querying), no such checks are performed. function latestRoundData() external view returns ( uint80 roundId, int256 answer, uint256 startedAt, uint256 updatedAt, //will be 0 if the round is incomplete uint80 answeredInRound ); This can certainly undermine the experience of protocol users, as options will be seled based on stale prices. Prolonged periods of down-time for most of the USDC denominated data-feeds are not likely, but in that scenario there could be direct consequences in terms of the protocol security. L4 Data feed answers that are either negative or zero are not handled consistently RESOLVED (commits d343c42, 1 4aa163c) In principle, the answer that is provided by a Chainlink Aggregator can be  0, but this is not consistently handled throughout AoriCall and AoriPut contracts. Negative answers will cause the selement price to be extremely large because it will have been cast to an uint256. For AoriPut, price answers which are 0 will be silently accepted as selement prices if AoriPut::sellerSettlementITM gets called rst (it could be even called with optionsToSettle being 0) function sellerSettlementITM(uint256 optionsToSettle) public nonReentrant returns (uint256) { _setSettlementPrice(); uint256 optionsSold = optionSellers[msg.sender]; ... require(optionsSold > 0 && optionsSold <= optionsToSettle); require(strikeInUSDC > settlementPrice && hasEnded == true); uint256 USDCToReceive = ((optionsToSettle / decimalDiff) * settlementPrice) / 10**USDC.decimals(); //((1e18 / 1e12) * 1e6) / 1e6 ... uint256 newOptionsSold = optionsSold - optionsToSettle; optionSellers[msg.sender] = newOptionsSold; ... } In this scenario, the buyer will never be able to sele in-the-money as all calls to AoriPut::buyerSettlementITM will revert function buyerSettlementITM(uint256 optionsToSettle) public nonReentrant returns (uint256) { _setSettlementPrice(); require(block.number >= endingBlock && balanceOf[msg.sender] >= 0); 1 require(strikeInUSDC > settlementPrice && settlementPrice != 0); ... } CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) ID Description N1 Some entities are considered trusted ",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": " INFO The protocol has some centralization risks, with some owner entities considered trusted. For instance, the owner of an Orderbook can claim any tokens (including Options) from any Ask or Bid; the owner of an OrderbookFactory can change external contract addresses that implement signicant functionality. OTHER / ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. 16 ",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Low"
        ]
    },
    {
        "title": "may lose precisio ",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": " RESOLVED Although the problem is likely very limited, given the expected magnitudes of the numbers, the following arithmetic in AoriCall::mintCall will maintain higher precision with the multiplication performed before the division. AORISEATSADD.addPoints( feeMultiplier * ((mintingFee - feeToSeat) / decimalDiff), msg.sender); AORISEATSADD.addPoints( feeMultiplier * (feeToSeat / decimalDiff), AORISEATSADD.ownerOf(seatId)); same The AoriPut::sellerSettlementITM applies to the following arithmetic operation in ... uint256 USDCToReceive = ((optionsToSettle / decimalDiff) * settlementPrice) / 10**USDC.decimals(); ... ... uint256 newOptionsSold = optionsSold - optionsToSettle; optionSellers[msg.sender] = newOptionsSold; //settle USDC.transfer(msg.sender, USDCToReceive); In the last snippet, USDCToReceive can end up being zero when optionsToSettle < decimalDiff, in which case the optionSellers balance of the seller will be reduced but without the seller receiving any USDC in return.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "generality? RESOLVED In both AoriPut and AoriCall, it is not clear why the sellerSettlementITM function should allow seling fewer than all the sellers options. There is no nancial sense in doing so: the loss of the option seller is known and is independent of the specics of 1 each buyer. If the seller gets a refund for one buyers options, they might as well get it for all their options, as they stand to gain nothing more by waiting.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "storage variables RESOLVED In AoriSeats, storage variables seatPrice, startingIndex, and startingIndexBlock are unused. The same is true of storage variable ORDERBOOK, which is also misleading, since there will not be a single orderbook.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "storage dereferences RESOLVED Some references to storage can be avoided, for gas savings. For instance, in AoriSeats::combineSeats: function combineSeats(uint256 seatIdOne, uint256 seatIdTwo) public returns(uint256) {  require(seatScore[seatIdOne] + seatScore[seatIdTwo] <= maxSeatScore);  seatScore[newSeatId] = seatScore[seatIdOne] + seatScore[seatIdTwo]; } could be rewrien as: function combineSeats(uint256 seatIdOne, uint256 seatIdTwo) public returns(uint256) {  uint256 newSeatScore = seatScore[seatIdOne] + seatScore[seatIdTwo]; require(newSeatScore <= maxSeatScore);  seatScore[newSeatId] = newSeatScore; } The laer avoids three SLOAD instructions.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "term: seller RESOLVED 1 In the Bid contract, calling the initiator of a bid the seller is confusing and inconsistent with other uses of the term throughout. Specically, the initiator of a Bid is the eventual buyer of the option, not its seller.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "variables should be immutable, saving gas and preventing updates upon code changes PARTLY RESOLVED Many storage variables never change after construction and should be declared immutable, so they can be inlined as constants. (Some storage variables can even be declared constant, for compile-time inlining.) These include at least: - Optiontroller: USDC, AORISEATSADD - AoriCall: oracle, AORISEATSADD - AoriPut: USDC, AORISEATSADD - AoriAuctionHouse: weth, duration - Orderbook: USDC, fee_, OPTION - Ask/Bid: AORISEATSADD, USDC, OPTION, OPTIONDecimals, USDCDecimals, decimalDiff.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "(repeated) external calls can be eliminated for gas savings RESOLVED Some external calls can be optimized. - Calls to USDC.decimals() (AoriCall, AoriPut) can be performed once and stored in an immutable variable. - Calls to Ownable(factory).owner() (twice in Ask::withdrawTokens) can be performed once and stored in a local variable.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "handling is inelegant PARTLY RESOLVED 1 Several boolean operations are inelegant and can be simplied for a more professional code look. // AoriSeats::addTakerPoints require(OPTIONTROLLER.checkIsOrder(Orderbook_, msg.sender) == true); -> require(OPTIONTROLLER.checkIsOrder(Orderbook_, msg.sender)); // Ask::cancel, Bid::cancel // (This code is also unnecessary, covered in an earlier require) isFunded() == true -> isFunded() // Ask::isFunded, similar in Ask::isFundedOverOne, // Bid::isFunded, Bid::isFundedOverOne if (OPTION.balanceOf(address(this)) > 0) { return true; } else { return false; } -> return (OPTION.balanceOf(address(this)) > 0); // Optiontroller::checkIsOrder checkIsListedOrderbook(Orderbook_) == true -> checkIsListedOrderbook(Orderbook_)",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "constants in the code PARTLY RESOLVED Ideally, numeric constants should be visible prominently at the top of a contract, instead of being buried in the code, for easier maintainability and readability. 2 There are several instances in the code where we would recommend giving a name to the constant so that it is prominently visible. // AoriAuctionHouse::_safeTransferETH to.call{ value: value, gas: 30_000 }(new bytes(0)); // AoriCall::mintCall, AoriPut::mintPut refRate = (AORISEATSADD.getSeatScore(seatId) * 5) + 35; // AoriCall::callUNDERLYINGFeeCalculator require(UNDERLYING.decimals() == 18); uint256 txFee = (optionsToSettle * fee) / 10000; // AoriPut::putUSDCFeeCalculator uint256 txFee = (quantityOfUSDC * fee) / 10000; // AoriCall::getPrice return (uint256(price) / (10**8 - 10**USDC.decimals())); // AoriPut::getPrice return (uint256(price) / 1e2); // AoriSeats::mintSeat if (currentSeatId % 10 == 0) { // Ask::fill, Bid::fill uint256 refRate = (AORISEATSADD.getSeatScore(seatId) * 5) + 35;",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "code LARGELY RESOLVED Several pieces of code are logically unnecessary or even dead. In AoriPut::sellerSelementITM: 2 require(USDCToReceive <= USDC.balanceOf(address(this)), \"Not enough USDC in contract\"); No similar check occurs elsewhere in the code, and the check is unnecessary because the subsequent transfer would revert anyway. In Ask: function withdrawTokens(address token) public { require(msg.sender == Ownable(factory).owner()); if (token == 0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE) { payable(Ownable(factory).owner()).transfer(address(this).balance); } else { } } uint256 balance = IERC20(token).balanceOf(address(this)); safeTransfer(token, Ownable(factory).owner(), balance); function emergencyRetreival(address token) public { // YS:! spell require(msg.sender == Ownable(factory).owner()); IERC20(token).transfer(Ownable(factory).owner(), IERC20(token).balanceOf(address(this))); } The second function (also: misspelling in name) is unnecessary, since it is subsumed by the rst, and even more completely (handling the case of tokens that dont implement a modern transfer). In Ask::fundContract and Bid::fundContract, this assignment is dead code: startingBlock = block.number; 2 In Ask::ll (similarly in Bid::ll), if the code does not change, the introduction and use of an always-zero variable seems pointless: uint256 txFee = 0; USDCAfterFee = (amountOfUSDC - txFee);",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "functions return unnecessarily large arrays DISMISSED All Orderbook::getActive* view functions return arrays that are larger than necessary, with zero items at the end. For example: function getActiveBids() public view returns (Bid[] memory) { Bid[] memory activeBids = new Bid[](bids.length); uint256 count; for (uint256 i; i < bids.length; i++) { Bid bid = Bid(bids[i]); if (bid.isFunded() && !bid.hasEnded()) { activeBids[count++] = bid; } } return activeBids; } External callers should be aware of this convention and not rely on the array length.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "ER",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/AORI/Aori audit Jan'23.pdf",
        "body": "denitions do not handle old tokens RESOLVED In AoriCall the code uses calls to the IERC20 transfer and transferFrom functions, e.g., in: function sellerSettlementOTM() public nonReentrant returns (uint256) { 2 UNDERLYING.transfer(msg.sender, optionsSold);   } As well as in: function mintCall(uint256 quantityOfUNDERLYING, uint256 seatId) public nonReentrant returns (uint256) { ... UNDERLYING.transferFrom(msg.sender, address(this), quantityOfUNDERLYING); ... } The denition of the transfer and transferFrom functions used in the contract (from the OpenZeppelin libraries) expects a boolean return value: function transfer(address to, uint256 amount) external returns (bool); function transferFrom(address from, address to,uint256 amount) external returns (bool); However, old tokens (most notably USDTthe highest-capitalization ERC-20 token) predate the ERC-20 token specication and support a denition of transfer and transferFrom that does not return anything. Therefore, the current code will revert if used with USDT as the underlying token. However, because it is a stablecoin, we do not expect it to be used as the underlying token of call options. A13 Compiler bugs INFO The code has the compile pragmas 0.8.11^ or 0.8.13^. For deployment, we recommend no floating pragmas, i.e., a specic version, so as to be condent about the baseline guarantees oered by the compiler. Versions 0.8.11 and 0.8.13, in particular, have some 2 known bugs, which we do not believe to aect the correctness of the contracts.",
        "labels": [
            "Dedaub",
            "Aori",
            "Severity: Critical"
        ]
    },
    {
        "title": "does not remove the innite approval for _token given to the old fee distributor. ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Sep '22.pdf",
        "body": " RESOLVED SurplusBeneficiary::setFeeDistributor sets the new fee distributor contract and approves it to be able to transfer an innite amount of USDC. However, the approval of the old fee distributor is not revoked, allowing it to transfer any amount of USDC even though that contract might have been deemed obsolete or even vulnerable. 0 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them.",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Sep '22.pdf",
        "body": "might get called with amount set to 0 RESOLVED SurplusBeneciary::dispatch computes the amount of USDC that should be transferred to the treasury and executes the transfer without checking rst that the transferred amount is not 0. function dispatch() external override nonReentrant { // .. uint256 tokenAmountToTreasury = FullMath.mulDiv(tokenAmount, _treasuryPercentage, 1e6); // Dedaub: tokenAmountToTreasury might be 0 due to _treasuryPercentage // being 0 or due to rounding. SafeERC20.safeTransfer(IERC20(token), _treasury, tokenAmountToTreasury); // .. } oldBalance and newBalance are equal when",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Sep '22.pdf",
        "body": "can be declared immutable INFO Storage variable _token of the SurplusBeneciary contract could be declared immutable, which would reduce the gas required to access it, as it is only set in the contracts constructor.",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Sep '22.pdf",
        "body": "functions should ensure new value is not equal to old RESOLVED 0 Functions setFeeDistributor and setTreasury of the SurplusBeneciary contract could implement a check that ensures the new value, which is being set, is not equal to the old one.",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Sep '22.pdf",
        "body": "USDC approval given to the FeeDistributor contract RESOLVED When seing the FeeDistributor contract for the SurplusBeneciary, innite USDC approval is also given to it. An alternative approach would be to set the approval (in function SurplusBeneficiary::dispatch) to the amount transferred prior to every transfer happening to avoid the dangers that come with approving a contract for an innite amount. Of course, there is a tradeo; the extra approve call happening in every call of dispatch would translate in higher gas costs, which could be considered bearable as the protocol is deployed on Optimism.",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Sep '22.pdf",
        "body": "debt threshold can be set to lower than the default INFO There is no check to ensure the whitelist debt threshold cannot be set to a value that would be less than the default debt threshold. This might be intentional but the term whitelist could have users expect that their debt threshold can only increase from the default. A6 Compiler known issues INFO The contracts were compiled with the Solidity compiler v0.7.6 which, at the time of writing, has a few known bugs. We inspected the bugs listed for this version and concluded that the subject code is unaected. 0 CENTRALIZATION ASPECTS As is common in many new protocols, the owner of the smart contracts yields considerable power over the protocol, including changing the contracts holding the users funds, killing contracts (FeeDistributor), using emergency unlock (vePERP)etc. In addition, the owner of the protocol has total control of several protocol parameters: - the treasury contract address - the percentage of funds going to the treasury - the fee distributor contract address - the insurance fund surplus threshold - the insurance fund surplus beneciary contract - the whitelisted debt threshold 0",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "issue leads to operations being performed twic ",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": " RESOLVED (4697d3cd) The LPToken contract inherits from the ER",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: High"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": "It then overrides both its external functions such as transfer, as well as its internal functions such as _transfer. Both the overridden external and internal functions adjust the amounts they receive before calling the corresponding version in the super contract. Now, if a user invokes an external overridden function such as LPToken::transfer, the amount is adjusted and then ERC20::transfer is called. Then ERC20::transfer will try to call ERC20::_transfer, but seeing this has been overridden, will call LPToken::_transfer instead, where the amount is adjusted again. Finally LPToken::_transfer will call ERC20::_transfer to nalise the transfer operation. As a result, the amount has been adjusted twice instead of once. LPToken::approve and LPToken::_approve also suer from the same issue.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Critical"
        ]
    },
    {
        "title": "allows LPToken to appear on both sides of a multiswap RESOLVED (4697d3c) An error in the validation of Pool::multiswap fails to ensure that the LPToken only appears on one side of a multiswap. 0 The error occurs because the LPToken, unlike other tokens, is not tracked in the check_ array, and the isLP variable, which tracks that it has been seen among the payTokens, is reset before the receiveTokens are checked. Pool::multiswap function multiswap( address[] memory payTokens, uint256[] memory amounts, address[] memory receiveTokens, uint256[] memory allocations ) { public nonReentrant onlyInitialized onlyAllowed returns (uint256[] memory receiveAmounts) ... // Check duplicates { bool isLP; uint256 temp; bool[] memory check_ = new bool[](_assetAddress.length); for (uint256 i; i < payTokens.length; i++) { address token = payTokens[i]; if (token == address(0)) revert ZeroAddress(); if (address(this) == token) { if (isLP) revert DuplicateToken(token); isLP = true; if (i != 0) { payTokens[i] = payTokens[0]; payTokens[0] = address(this); temp = amounts[i]; amounts[i] = amounts[0]; amounts[0] = temp; 0 } //Dedaub: LPToken not added to check_ // because loop breaks early continue; } AssetState memory asset_ = _assetState[token]; if (asset_.token != token) revert AssetNotFound(token); if (check_[asset_.index]) revert DuplicateToken(token); check_[asset_.index] = true; } //Dedaub: presence of LP token is erased isLP = false; for (uint256 i; i < receiveTokens.length; i++) { address token = receiveTokens[i]; if (token == address(0)) revert ZeroAddress(); if (address(this) == token) { if (isLP) revert DuplicateToken(token); isLP = true; if (i != 0) { receiveTokens[i] = receiveTokens[0]; receiveTokens[0] = address(this); temp = allocations[i]; allocations[i] = allocations[0]; allocations[0] = temp; } continue; } AssetState memory asset_ = _assetState[token]; if (asset_.token != token) revert AssetNotFound(token); if (check_[asset_.index]) revert DuplicateToken(token); check_[asset_.index] = true; } 0 } ... } H3 Erroneous geometric mean updates RESOLVED (5db05fa) The functions _increaseBalance and _decreaseBalance of the Pool.sol contract updates the balance variable of _poolState structure and also the meanBalance, calling the _geometricMean function. _geometricMean computes the new geometric mean of the balance using the time elapsed (delta) since the last update. The problem is that _increaseBalance/_decreaseBalance has already updated the _poolState.lastUpdated before calling _geometricMean, therefore delta will be zero and the geometric mean will be not updated and always stay the same. MEDIUM SEVERITY: ID Description M1 Pool::removeAsset not cleaning up properly ",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": " RESOLVED (253a2a0) The Pool::removeAsset function does not delete the _assetState[token], but just sets some of the asset variables to 0. Other elds, such as _assetState[index] and _assetState[token] do not change. This can have a number of consequences. For instance, if an asset is removed, it cannot be added again later, because the token eld is already set. Also, swap and other functions will still work with the removed asset and transactions will only fail when a division by zero error is encountered due to a relevant eld being set to 0. 0 Pool::removeAsset function removeAsset( address token ) public nonReentrant onlyUninitialized onlyOwner { ... \\\\Dedaub: Only a subset of fields of the Asset struct are zeroed asset_.balance = 0; asset_.meanBalance = 0; asset_.scale = 0; asset_.meanScale = 0; asset_.lastUpdated = 0; ... } Pool::addAsset function addAsset( address payToken_, uint256 balance_, uint256 fee_, uint256 assetScale_ ) public nonReentrant onlyUninitialized onlyOwner { if (payToken_ == address(0)) revert ZeroAddress(); \\\\Dedaub: Adding an asset after removing it will cause a revert if (_assetState[payToken_].token == payToken_) revert DuplicateToken(payToken_); ... } 07 LOW SEVERITY: ",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: High"
        ]
    },
    {
        "title": "can also update users ",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": " INFO The LPToken::addUser function can also be used to update a user, and not just to add a user. We advise to separate these two functionalities for clarity. LPToken::addUser function addUser( address user, uint256 discount ) public nonReentrant onlyOwner { if (user == address(0)) revert InvalidUser(user); UserState memory state = _userState[user]; if (state.user != user) { _userAddress.push(user); } //Dedaub: User state is still updated if // user exists _userState[user] = UserState(user, true, discount); } 0",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": "Mistake in Error parameter INFO The Pool contract has an error called InvalidSwap which has a parameter called receiveToke instead of receiveToken.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": "minAmountOut for Pool::swap and Pool::multiswap INFO We recommend adding a minAmountOut parameter to Pool::swap and Pool::multiswap, so as to enable users to specify the minimum amount of received tokens they consider acceptable when invoking these operations.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": "and Pool::multiswap have a limit on the size of the payTokens but not on the size of the receiveTokens INFO Pool::multiswap and Pool:swap stop payTokens from amounting to more than 1/3 of the asset in the pool, but there is no corresponding requirement for receiveTokens. It is recommended to have a similar requirement for receiveTokens so as to avoid swaps and multiswaps from draining a particular asset of the pool.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": "updates of assets indices INFO In Pool::removeAsset after the removal of the asset, the indices of all assets are updated. But only one index has actually changed, the index of the last asset in _assetAdress[], and all the other assets are reassigned their previous indices.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Jul '23.pdf",
        "body": "nonReentrant modiers INFO Many functions of the LPToken.sol contract e.g. setProtocolFee, setProtocolFeeRecipient, addUser,... have a nonRentrant modier, although none of them makes external calls (and moreover they are only callable by the owner of the contract). 01 A7 Duplicate code INFO In Pool::multiswap there are two identical for-loops, checking if there are token repetitions in the set of payTokens and receiveTokens. The code could be refactored using a single method that will check for repetitions.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "(or consulting an oracle for pricing) can be front-run Status Open 4 There are many instances of Uniswap/Sushiswap swaps and oracle queries (mainly wrapped in calls to to the internal swapManager.safeGetAmountsOut, swapTokensForExactTokens, bestOutputFixedInput) that can be front-run or return biased results through tilted exchange pools. Fixing this requires careful thought, but the codebase has already started integrating a simple time-weighted average price oracle. function Strategy::_safeSwap, but also as direct calls calls and to We have warned about such swaps in past audits and the saving grace has been that the swapped amounts are small: typically interest/reward payments only. Thus, tilting the exchange pool is not protable for an attacker. In CompoundXYStrategy (which contains many of these calls), swaps are performed not just from the COMP rewards token but also from the collateral token. Similarly, in the Earn strategies, the _convertCollateralToDrip does an unrestricted collateral swap, on the default path (no swapSlippage dened). Swapping collateral (up to all available) should be ne if the only collateral token amounts held in the strategy at the time of the swap are from exchanging COMP or other rewards. Still, this seems like a dangerous practice. Standard background: The problem is that the swap can be sandwiched by an attacker collaborating with a miner. This is a very common pattern in recent months, with MEV (Maximum Extractable Value) attacks for total sums in the hundreds of millions. The current code complexity offers some small protection: typically attackers colluding with miners currently only attack the simplest, lowest-risk (to them) transactions. However, with small code analysis of the Vesper code, an attacker can recognize quickly the potential for sandwiching and issue an attack, rst tilting the swap pool and then restoring it, to retrieve most of the funds swapped by the Vesper code. In the current state of the code, the attacker will likely need to tilt two pools: both Uniswap and Sushiswap. However, this also offers little protection, since they both use similar on-chain price computations and near-identical APIs. In the short-term, deployed code should be closely monitored to ensure the swapped amounts are very small (under 0.3%) relative to the size of the pools involved. Also, if an attack is detected, the contract should be paused to avoid repeat attacks. However, the code should evolve to have an estimate of asset pricing at the earliest possible time! This can be achieved by using the TWAP functionality that is already being added, with some tolerance based on this expected price.",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: High"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "non-standard ERC20 Tokens can be stuck inside the Resolved VFRBuffer 5 The VFRBuffer does not use the safeERC20 library for the transfer of ERC20 tokens. This can cause non-standard tokens (for example USDT) to be unable to be transferred inside the Buffer and get stuck there. This issue would normally be ranked lower, but since USDT is actively used in past strategies, it seems likely to arise with upcoming instantiations of the VFR pool. Medium Severity Nr. Description",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: High"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "rewards might get stuck in CompoundLeverageStrategy Status Dismissed (Normal path: rebalance before migrate) CompoundLeverageStrategy does not offer a way to migrate COMP tokens that might have been left unclaimed by the strategy up to the point of migration. What is more, COMP is declared a reserved token by CompoundMakerStrategy making it impossible to sweep the strategys COMP balance even if a claim is made to Compound after the migration. The _beforeMigration hook should be extended to account for the claim and consequent transfer of COMP tokens to the new strategy as follows: function _beforeMigration(address _newStrategy) internal virtual override { require(IStrategy(_newStrategy).token() == address(cToken), \"wrong-receipt-token\"); minBorrowLimit = 0; // It will calculate amount to repay based on borrow limit and payback all _reinvest(); // Dedaub: Claim COMP and transfer to new strategy. _claimComp(); IERC20(COMP).safeTransfer(_newStrategy,IERC20(COMP).balanceOf(address(this))); }",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "rewards might get stuck in CompoundXYStrategy Dismissed (as above) 6 The _beforeMigration hook of CompoundXYStrategy calls _repay and lets it handle the claim of COMP and its conversion to collateral, thus no COMP needs to be transferred to the new strategy prior to migration. However, the claim in _repay happens only when the condition _repayAmount > _borrowBalanceHere evaluates to true, which might not always hold prior to migration, leading to COMP getting stuck in the strategy. This is because COMP is declared a reserved token and thus cannot be swept after migration.",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "Compound markets are never entered Dismissed (unnecessary) The CompoundLeverageStrategys CToken market Comptroller. This leaves the strategy unable to borrow from the specied CToken. is never entered via Compounds",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "The checkpoint method only considers proting strategies when computing the total prots of a pools strategies Resolved The checkpoint() method of the VFRStablePool iterates over the pools strategies to compute their total prots and update the pools predictedAPY state variable: address[] memory strategies = getStrategies(); uint256 profits; // SL: Is it ok that it doesn't consider strategies at a loss? for (uint256 i = 0; i < strategies.length; i++) { (, uint256 fee, , , uint256 totalDebt, , , ) = IPoolAccountant(poolAccountant).strategy(strategies[i]); uint256 totalValue = IStrategy(strategies[i]).totalValueCurrent(); if (totalValue > totalDebt) { uint256 totalProfits = totalValue - totalDebt; uint256 actualProfits = totalProfits - ((totalProfits * fee) / MAX_BPS); profits += actualProfits; } } The above computation disregards the losses of any strategies that are not proting. Due to that the predicted APY value will not be accurate. 7",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "CompoundXY strategy does not account for rapid rise of Resolved borrow token price (This issue was also used earlier as an example in our architectural recommendations.) The CompoundXY strategy seeks to repay a borrowed amount if its value rises more than expected. However, volatile assets can rise or drop in price dramatically. (E.g., a collateral stablecoin can lose its peg, or a tokens price can double in hours.) This means that the Compound loan may become undercollateralized. In this case, the borrowed amount may be worth more than the collateral, so it would be benecial for the strategy to not repay the loan. Furthermore, it might be the case that the collateral gets liquidated before the strategy rebalances. In this case the strategy will be left with borrow tokens that it can neither transfer nor swap. The strategy can be enhanced to account for the rst of these cases, and the overall architecture can adopt an emergency rescue mechanism for possibly stuck funds. This emergency rescue would be a centralization element, so it should only be authorized by governance. M6 CompoundXYStrategy, CompoundLeverageStrategy: Error code of Mostly Resolved Compound API calls ignored, can lead to silent failure of functionality The calls to many state-altering Compound API calls return an error code, with a 0-value indicating success. These error codes are often ignored, which can cause certain parts of the strategies functionality to fail, silently. The calls with their error status ignored are:  CompoundXYStrategy::constructor: Comptroller.enterMarkets()  CompoundXYStrategy::updateBorrowCToken: Comptroller.exitMarket(), Comptroller.enterMarkets(), CToken.borrow()  CompoundXYStrategy::_mint: CToken.mint() (is returned but not check by the callers of _mint())  CompoundXYStrategy::_reinvest: CToken.borrow()  CompoundXYStrategy::_repay: CToken.repayBorrow()  CompoundXYStrategy::_withdrawHere: CToken.redeemUnderlying()  CompoundLeverageStrategy::_mint: CToken.mint()  CompoundLeverageStrategy::_redeemUnderlying: CToken.redeemUnderlying() CToken.redeem(),  CompoundLeverageStrategy::_borrowCollateral: CToken.borrow()  CompoundLeverageStrategy::_repayBorrow: CToken.repayBorrow() 8 Low Severity Nr. Description",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "ALPHA rewards are not claimed on-chain Status Open The _claimRewardsAndConvertTo() method of the Alpha lend strategy does not do what its name and comments indicate it does. It only converts the claimed ALPHA tokens. The actual claiming of the funds does not appear to happen using an on-chain API.",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "storage eld Resolved In CompoundLeverageStrategy, eld borrowToken is unused. A comment mentions it but does not match the code. L3 Two swaps could be made one, for fee savings Dismissed, detailed consideration In CompoundXYStrategy::_repay, COMP is rst swapped into collateral, and then collateral (which should be primarily, if not exclusively, the swapped COMP) is swapped to the borrow token. This incurs double swap fees. Other/Advisory Issues This section details issues that are not thought to directly affect the functionality of the project, but we recommend addressing. Nr. Description",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "contract seems to serve no purpose Status Open This contract currently does nearly nothing. It is neither inherited nor exports functionality that makes it usable as part of a VFR strategy. 9",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "contract is there only for code reuse Open The VFR contract currently has the form: abstract contract VFR { function _transferProfit(...) internal virtual returns (uint256) {...} function _handleStableProfit(...) internal returns (uint256 _profit) {...} function _handleCoverageProfit(...) internal returns (uint256 _profit) {...} } It is, thus, a contract that merely denes internal functions, used via inheritance, for code reuse purposes. Inheritance for code reuse is often considered a bad, low-level coding practice. A similar effect may be more cleanly achieved via use of a library.",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "reserved tokens Open In most strategies the collateral token is part of those in isReservedToken. Not in AlphaLendStrategy.",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "COMP rewards can be triggered by anyone Dismissed, after review COMP Although we cannot see an issue with it, multiple public functions allow anyone to trigger a claim methods of totalValueCurrent/isLossMaking, and similarly in CompoundXYStrategy. It is worth revisiting whether the timing of rewards can confer a benet to a user. CompoundLeverageStrategy rewards, e.g., in",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "conventions Resolved often functionality Similar instance, between different CompoundXYStrategyETH and CompoundLeverageStrategyETH, we notice a difference in the _mint function (in one case it returns a value in the other not), and the presence of an _afterRedeem vs. full overriding of _redeemUnderlying. conventions. For follows",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Vesper Finance/Vesper Pools+Strategies September Audit.pdf",
        "body": "looser checks are performed on construction than on Resolved migrateFusePool() When the RariFuseStrategy is constructed, a CToken (assumed to belong to an instantiation of a Rari Fuse pool) is passed as an argument. However, when the strategy migrates to another Fuse pool, Fuses API is used to ensure the new CToken will be part of a Rari Fuse pool. The same checks should also take place during the contracts construction. 10 A7 Compiler bugs Info The contracts were compiled with the Solidity compiler v0.8.3 which, at the time of writing, has a known minor issue. We have reviewed the issue and do not believe it to affect the contracts. More specically the known compiler bug associated with Solidity compiler v0.8.3:  Memory layout corruption can happen when using abi.decode for the deserialization of two-dimensional arrays. 11",
        "labels": [
            "Dedaub",
            "Vesper Pools+Strategies September",
            "Severity: Informational"
        ]
    },
    {
        "title": "use of memory in uninitialize(). ",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Sep. 2022.pdf",
        "body": " INFO 0 In the function uninitialize(), the asset struct corresponding to a token address is copied in its entirety to memory, when only the balance and decimals elds need to be read, making the implementation gas-ineicient. function uninitialize(address token) public nonReentrant onlyOwner { if (_isInitialized == 1) revert AlreadyInitialized(); Asset memory x = _assets[token]; SafeERC20.safeTransfer( x.token, owner(), toCanonical(x.balance, x.decimals) ); } The balance and decimals elds can be read directly from the struct via a storage pointer, instead of a memory buer, and the token address is already available as a parameter. function uninitialize(address token) public nonReentrant onlyOwner { if (_isInitialized == 1) revert AlreadyInitialized(); Asset storage x = _assets[token]; SafeERC20.safeTransfer( IERC20(token), owner(), toCanonical(x.balance, x.decimals) ); }",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Sep. 2022.pdf",
        "body": "operations within loops inside multiswap() INFO 0 The multiswap operation performs a number of expensive writes into storage variables inside of loops. The resulting implementation is gas ineicient. Specically, the two loops below can improve gas-performance-wise: // Transfer tokens to the pool for (uint256 i; i < payTokens.length; i++) {  _assets[payToken].scale += delta; _scale += delta; } } // Transfer tokens to the receiving address for (uint256 i; i < receiveTokens.length; i++) {  _assets[receiveToken].scale += delta; _scale += delta; } } Instead of accumulating values directly into storage locations, one can instead accumulate into a local variable. The local variable can then be wrien once into _assets[*],scale and _scale at the end of each loop. (This x would also address another current ineiciency, of computing _assets[payToken] and _assets[receiveToken] twice within each loop, resulting in extraneous SLOADs.)",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Sep. 2022.pdf",
        "body": "check in stake() INFO The stake() function performs a redundant check to determine whether the token eld of the assetOut struct is the same as receiveToken. However this check will always yield false since assetOut must be the struct corresponding to that token address (or there is an internal error in the conguration of the pool). Asset storage assetOut = _assets[receiveToken]; // Check if unstake if (address(assetOut.token) != receiveToken) 0 revert InvalidUnstake(receiveToken);",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Sep. 2022.pdf",
        "body": "of toCanonical confusing INFO The toCanonical function should perhaps rather be called fromCanonical since it translates from a canonical precision, e18, to the decimals the token expects.",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Sep. 2022.pdf",
        "body": "constants are best avoided INFO Constants such as 10000, 3, 4, which appear inlined in the code, are best avoided, in favor of named constants that explain the intent and can be changed uniformly everywhere with a single, local edit. if (amounts[i] < 10000) revert TooSmall(amounts[i]);",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Sep. 2022.pdf",
        "body": "order of operations may lose precision INFO In swap, performing the ddiv operation before multiplications may lose precision. This is likely not a concern, since 18 digits are being kept, but we also see no danger of overflow for realistic protocol quantities. (Correctness should be ascertained by testing with extreme values after implementing this suggestion.) uint256 invGrowthOut = DMath.ONE + gamma.dmul(weightRatio).dmul(amountIn.ddiv(reserveIn)); Similarly in multiswap: factor = gamma.ddiv(weightOut).dmul(allocation).dmul(fracValueIn)",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/CavalRe/CavalRe Audit - Sep. 2022.pdf",
        "body": "loose condition INFO 0 In unstake, there is a condition restricting amountIn (the amount of pool tokens a user can burn and get back his stake) to a maximum value of 4/3*_balance. But, since this amount is subtracted from _balance,the maximum allowed value for amounIn should be equal to _balance or less. A8 Compiler bugs INFO The code is compiled with Solidity 0.8.16. Version 0.8.16, in particular, has some known bugs, which we do not believe to aect the correctness of the contracts. CENTRALIZATION ASPECTS The protocol is highly decentralized, with all owner privileges relinquished after pool deployment. 01",
        "labels": [
            "Dedaub",
            "CavalRe",
            "Severity: Informational"
        ]
    },
    {
        "title": "might misbehave if bufferedRedeems != fundRaisedBalanc ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido on Kusama,Polkadot Liquid Staking Delta Audit - Apr 2023.pdf",
        "body": " RESOLVED The intended procedure of forced unbond requires seing bufferedRedeems == fundRaisedBalance via a call to setBufferedRedeems. As a consequence, LidoUnbond::_processEnabled expects these two amounts to be equal during forced unbond. function _processEnabled(int256 _stake) internal { ... // Dedaub: This code will break if bufferedRedeems is not exactly // if (isUnbondForced && isRedeemDisabled && bufferedRedeems == fundRaisedBalance) equal to fundRaisedBalance { targetStake = 0; } else { targetStake = getTotalPooledKSM() / ledgersLength; } } However , the contract does not guarantee that these amounts will be exactly equal. For instance, setBufferedRedeems only contains an inequality check:  function setBufferedRedeems( uint256 _bufferedRedeems ) external redeemDisabled auth(ROLE_BEACON_MANAGER) { // Dedaub: Equality not guaranteed require(_bufferedRedeems <= fundRaisedBalance, \"LIDO: VALUE_TOO_BIG\"); bufferedRedeems = _bufferedRedeems; } It is also hard to verify that no other function modifying these amounts can be called after calling setBufferedRedeems. If, for any reason, the amounts are not exactly equal during forced unbond, the else branch in _processEnabled will be executed, causing targetState to be wrongly computed and likely leaving the contract in a problematic state. To make the contract more robust we recommend properly handling the case when the two amounts are dierent, possibly by reverting, instead of executing the wrong branch. For instance: function _processEnabled(int256 _stake) internal { ... // Dedaub: Modified code if (isUnbondForced && isRedeemDisabled) { require(bufferedRedeems == fundRaisedBalance); targetStake = 0; } else { targetStake = getTotalPooledKSM() / ledgersLength; } } Another to fundRaisedBalance within this function. approach could be actually set _bufferedRedeems = L2 Set bufferedRedeems = fundRaisedBalance and isUnbondForced in a single transaction RESOLVED Forced unbond is initiated by seing bufferedRedeems = fundRaisedBalance and isUnbondForced = true, via separate calls to setIsUnbondForced and setBufferedRedeems. If, however, only one of the two changes is performed, the 4 contract will likely misbehave. As a consequence, it would be safer to perform both updates in a single transaction OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend addressing them. ",
        "labels": [
            "Dedaub",
            "Lido on Kusama,Polkadot Liquid Staking Delta",
            "Severity: Low"
        ]
    },
    {
        "title": "and check all contracts before starting the forced unbond procedure ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido on Kusama,Polkadot Liquid Staking Delta Audit - Apr 2023.pdf",
        "body": " INFO The documented procedure for enabling forced unbond states to rst update the Ledger contract, then to chill all Ledgers, and afterwards to upgrade the Lido contract. Although this order can work, we nd it safer to rst nish all upgrades of all contracts, check that the upgraded contracts work by simulating calls to the corresponding methods, and only then perform any state updating calls.",
        "labels": [
            "Dedaub",
            "Lido on Kusama,Polkadot Liquid Staking Delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Lido/Lido on Kusama,Polkadot Liquid Staking Delta Audit - Apr 2023.pdf",
        "body": "function name in ILidoUnbond RESOLVED ILidoUnbond contains a function setIsRedeemEnabled, while the method in LidoUnbond is called setIsRedeemDisabled. A3 Compiler known issues INFO The code is compiled with Solidity 0.8.0 or higher. For deployment, we recommend no floating pragmas, i.e., a specic version, to be condent about the baseline guarantees oered by the compiler. Version 0.8.0, in particular, has some known bugs, which we do not believe aect the correctness of the contracts.",
        "labels": [
            "Dedaub",
            "Lido on Kusama,Polkadot Liquid Staking Delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pool deposits can be manipulated for possible gai ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/Chicken Bonds Audit.pdf",
        "body": " RESOLVED (mitigated by commit cf15a5ac: time delay for shifting, limited shift window) The Chicken Bonds protocol gives arbitrary callers the ability to shift liquidity out of the stability pool and into Curve, when the price of LUSD (on Curve) is too high. This can be abused for a nancial aack if the protocol (i.e., the B.AMMSP) becomes a major shareholder of stability pool liquidity, as expected. Consider a scenario where the aacker notices a large liquidation coming in. Stability pool shareholders stand to gain up to 10%. The aacker wants to eliminate the B.AMMSP share from the stability pool and receive a larger part of the gains. The aacker can tilt the Curve pool (e.g., via flashloan) to get the LUSD price to be outside the of subsequent (too shiftLUSDFromSPToCurve, liquidity gets removed from the stability pool. high). With acceptable threshold call a H2 An aack tilting the Curve pool before a redeem allows the aacker to draw funds from the permanent bucket RESOLVED (commit 900d481a makes all Curve accounting be in virtual/relative terms) There is a Curve-pool-tilt aack upon a redeem operation. The core of the issue is the maintaining between transactions of a storage variable, permanentLUSDInCurve: 0 uint256 private permanentLUSDInCurve; // Yearn Curve LUSD-3CRV vault  function shiftLUSDFromSPToCurve(uint256 _maxLUSDToShift) external { ... uint256 permanentLUSDCurveIncrease = (lusdInCurve - lusdInCurveBefore) * ratioPermanentToOwned / 1e18; permanentLUSDInCurve += permanentLUSDCurveIncrease; ... } function shiftLUSDFromCurveToSP(uint256 _maxLUSDToShift) external { ... uint256 permanentLUSDWithdrawn = lusdBalanceDelta * ratioPermanentToOwned / 1e18; permanentLUSDInCurve -= permanentLUSDWithdrawn; ... } The problem is that this quantity does not really reflect current amounts of LUSD in Curve, which are subject to fluctuations due to normal swaps or malicious pool manipulation. The permanentLUSDInCurve is then used in the computation of acquired LUSD in Curve: function getAcquiredLUSDInCurve() public view returns (uint256) { uint256 acquiredLUSDInCurve; // Get the LUSD value of the LUSD-3CRV tokens uint256 totalLUSDInCurve = getTotalLUSDInCurve(); if (totalLUSDInCurve > permanentLUSDInCurve) { acquiredLUSDInCurve = totalLUSDInCurve - permanentLUSDInCurve; } return acquiredLUSDInCurve; } A redeem computes the amount to return to the caller using the above function, as a proportion of the acquired LUSD in Curve: 0 function redeem(uint256 _bLUSDToRedeem, uint256 _minLUSDFromBAMMSPVault) external returns (uint256, uint256) {  uint256 acquiredLUSDInCurveToRedeem = getAcquiredLUSDInCurve() * uint256 lusdToWithdrawFromCurve = acquiredLUSDInCurveToRedeem * (1e18 - redemptionFeePercentage) / 1e18; fractionOfBLUSDToRedeem / 1e18; uint256 acquiredLUSDInCurveFee = acquiredLUSDInCurveToRedeem - lusdToWithdrawFromCurve; yTokensFromCurveVault = _calcCorrespondingYTokensInCurveVault(lusdToWithdrawFromCurve); if (yTokensFromCurveVault > 0) { yearnCurveVault.transfer(msg.sender, yTokensFromCurveVault); } As a result, the aack consists of lowering the price of LUSD in Curve, by swapping a lot of LUSD, so that the Curve pool has a much larger amount of LUSD. The permanentLUSDInCurve remains as stored from the previous transaction and gets subtracted, so that the acquired LUSD in Curve appears to be much higher. The aacker calls redeem and receives a proportion of that amount (minus fees), eectively stealing from the permanent LUSD. The general recommendation is to not store between transactions any amount reflecting Curve balances (either total or partial). If a partial balance is to be kept, it should be kept in relative terms (i.e., a proportion) not absolute token amounts. MEDIUM SEVERITY: [No medium severity issues] LOW SEVERITY: ",
        "labels": [
            "Dedaub",
            "Chicken Bonds",
            "Severity: High"
        ]
    },
    {
        "title": "in exponentiation ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/Chicken Bonds Audit.pdf",
        "body": " RESOLVED Iterative exponentiation by squaring (ChickenMath::decPow) could be simplied slightly from: while (n > 1) { if (n % 2 == 0) { x = decMul(x, x); 0 n = n / 2; } else { // if (n % 2 != 0) y = decMul(x, y); x = decMul(x, x); n = (n - 1) / 2; } } to: while (n > 1) { if (n % 2 != 0) { y = decMul(x, y); } x = decMul(x, x); n = n / 2; } We only recommend this change for reasons of elegance, not impact.",
        "labels": [
            "Dedaub",
            "Chicken Bonds",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/Chicken Bonds Audit.pdf",
        "body": "unnecessary RESOLVED There is an assert statement in _firstChickenIn that is currently unnecessary. function _firstChickenIn(...) internal returns (uint256) { assert(!migration); The function is currently only called under conditions that preclude the assert: if (bLUSDToken.totalSupply() == 0 && !migration) { lusdInBAMMSPVault = _firstChickenIn(bond.startTime, bammLUSDValue, lusdInBAMMSPVault); } More generally, although there is a long-standing software engineering practice encouraging asserts for circumstances that should never arise, we discourage their use in deployed blockchain code, since asserts in the EVM do have a run-time cost.",
        "labels": [
            "Dedaub",
            "Chicken Bonds",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/Chicken Bonds Audit.pdf",
        "body": "computation of minimum DISMISSED, INVALID 01 (will remove) The minimum computation in the code below has a pre-determined outcome: function shiftLUSDFromSPToCurve(uint256 _maxLUSDToShift) external {  (uint256 bammLUSDValue, uint256 lusdInBAMMSPVault) = _updateBAMMDebt(); uint256 lusdOwnedInBAMMSPVault = bammLUSDValue - pendingLUSD; // Make sure pending bucket is not moved to Curve, so it can be // withdrawn on chicken out uint256 clampedLUSDToShift = Math.min(_maxLUSDToShift, lusdOwnedInBAMMSPVault); // Make sure there's enough LUSD available in B.Protocol clampedLUSDToShift = Math.min(clampedLUSDToShift, lusdInBAMMSPVault); // Dedaub: the above is unnecessary. _updateBAMMDebt has its first // return value always be <= the second. So, clampedLUSTToShift // (which is <= _bammLUSDValue) will always be <= lusdInBAMMSPVault",
        "labels": [
            "Dedaub",
            "Chicken Bonds",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/Chicken Bonds Audit.pdf",
        "body": "in README.md INFO (RESOLVED) Under the section Shifter functions::Spot Price Thresholds, the conditions under which shifts are allowed are incorrect. The correct conditions should read:  Shifting from the Curve to SP is possible when the spot price is < x, and must not move the spot price above x.  Shifting from SP to the Curve is possible when the spot price is > y, and must not move the spot price below y. A5 Compiler bugs INFO (RESOLVED) The code is compiled with Solidity 0.8.10 or higher. For deployment, we recommend no floating pragmas, i.e., a specic version, so as to be condent about the baseline 01 guarantees oered by the compiler. Version 0.8.10, in particular, has some known bugs, which we do not believe to aect the correctness of the contracts. CENTRALIZATION ASPECTS The design of the protocol is highly decentralized. The creation of bonds, chickening in/out and redemption of bLUSD tokens is all carried out without any intervention from governance. The shifter functions, ChickenBondManager::shiftLUSDFromSPToCurve and ChickenBondManager::shiftLUSDFromCurveToSP, which move LUSD between the Liquity stability pool and the curve pool are also public and permissionless. The Yearn Governance address holds control of the protocols migration mode which prevents the creation of new bonds, among other changes. There is no way to deactivate migration mode. Although new users will not be able to join the protocol, all current users will still be able to retrieve their funds, either through ChickenBondManager::chickenOut or ChickenBondManager::redeem. Yearn governance decisions are voted on by all YFI token holders and are executed by a 6-of-9 Multisig address. 01",
        "labels": [
            "Dedaub",
            "Chicken Bonds",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "has unlimited spending approval RESOLVED In the GmxHedgingReactor constructor the gmxPositionRouter is approved to spend an innite amount of _collateralAsset. It appears that this is unneeded and potentially dangerous, as the transfer of _collateralAsset is actually handled by the 0 GMX router, which gets approved for the exact amount needed in the function _increasePosition, and not by the gmxPositionRouter.",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "returns in _changePosition RESOLVED The function GmxHedgingReactor::_changePosition is not consistent with the values it returns. Even though it should always return the resulting dierence in delta exposure, it does not do so at the end of the if-branch of the if (_amount > 0) {  } statement. If the control flow reaches that point, it jumps at the end of the function leading to 0 being returned, i.e., as if there was no change in delta. function _changePosition(int256 _amount) internal returns (int256) { // .. if (_amount > 0) { // .. // Dedaub: last statement is not a return increaseOrderDeltaChange[positionKey] += deltaChange; } else { // .. return deltaChange + closedPositionDeltaChange; } return 0; } We would suggest the following xes: function _changePosition(int256 _amount) internal returns (int256) { // .. if (_amount > 0) { // .. return deltaChange + closedPositionDeltaChange; } else if (_amount < 0) { // .. return deltaChange + closedPositionDeltaChange; } 0 return 0; } Currently the return value of _changePosition is further returned by the function hedgeDelta and remains unused by its callers. However, this could change in future versions of the protocol leading to bugs.",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "long and short positions could co-exist RESOLVED GMX treats longs and shorts as completely separate positions, and charges borrowing fees on both simultaneously, thus the reactor deals with positions in such a way that ensures only a single position is open at a certain time. Nevertheless, due to the two-step process that GMX uses to create positions and the fact that the reactor does not take into account that a new position might be created while another one is waiting to be nalized, there exists a scenario in which the reactor could end up with a long and a short position at the same time. The scenario is the following: 1. Initially, there are no open positions 2. A long or short position is opened on GMX but is not executed immediately, i.e., GmxHedgingReactor::gmxPositionCallback is not called. The LiquidityPool reckons that a counter position should be opened and calls GmxHedgingReactor::hedgeDelta to do so. 3. When the two position orders are nally executed by GMX the reactor will have a long and a short position open simultaneously. The above scenario might not be likely to happen as it requires the LiquidityPool to open two opposite positions in a very short period of time, i.e., before the rst position order is executed by a GMX keeper or a keeper of the protocol. Nevertheless, we believe it would be beer to also handle such a scenario, as it could mess up the reactors accounting and the x should be relatively easy. 0",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Medium"
        ]
    },
    {
        "title": "in some cases underestimates the extra collateral needed for an increase of a position ACKNOWLEDGED Whenever the hedging reactor asks for an increase of a position, _getCollateralSizeDeltaUsd() computes the extra collateral needed using collateralToTransfer (collateral needed to be added or removed from the position before its increase, to maintain the health to the desired value) and extraPositionCollateral (the extra collateral needed for the increase of the position).If isAboveMax==true and extraPositionCollateral > collateralToTransfer, then the collateral which is actually added is just totalCollateralToAdd= extraPositionCollateral - collateralToTransfer, which could be not suicient to collateralize the increased position. Let us try to explain this with an example. Suppose that initially there is a long position with position[0]=10_000, position[1]=5_000. Hedging reactor then asks for an increase of its position by 11_000. extraPositionCollateral will be 5_500. Suppose than in the meantime this position had substantial prots i.e. positive unrealised pnl=5_000. colateralToTransfer will be 5_000 and totalCollateralToAdd will be 5_500-5_000=500. Therefore the \"leverage without pnl\" of the new position will be (10_000+11_000)/(5_000+500)=21_000/5_500=3.8. If this scenario is repeated, it could lead to the liquidation of the position. We suggest adding a check that the total size of the position does not exceed its total collateral times maxLeverage, similar to the one used in the case of decreasing a position. 07 LOW SEVERITY: ID Descriptio ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "does not remove the old PositionRouter RESOLVED The function GmxHedgingReactor::setPositionRouter sets gmxPositionRouter to the new GMX PositionRouter contract that is provided and calls approvePlugin on the GMX Router contract to approve it. It does not revoke the approval to the old PositionRouter contract, which from now on is irrelevant to the reactor, by calling the function denyPlugin of the GMX Router contract. L2 Potential underflow in CheckVaultHealth RESOLVED If a position is in loss, the formula of the health variable is the following one: // GmxHedgingReactor.sol::_getCollateralSizeDeltaUsd():344 health=(uint256((int256(position[1])-int256(position[8])).div(int256(posit ion[0]))) * MAX_BIPS) / 1e18; There is no check if the dierence (int256(position[1])-int256(position[8])) in the above formula is positive or not. It is possible, under specic economic conditions (and if the GMX Liquidators are not fast enough), that the result of this dierence is negative. In such a case, the resulting value will be erroneous because of an underflow error. Even if this scenario is not expected to happen on a regular basis, we suggest adding a check that this dierence is indeed positive and if it is not extra measures should be taken to avoid liquidations. Note that the same issue appears in getPoolDenominatedValue, leading to the execution reverting if an underflow occurs. 0 CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) 0 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Low"
        ]
    },
    {
        "title": "wastes gas ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": " INFO The function GmxHedgingReactor::getPoolDenominatedValue wastes gas by calling the function checkVaultHealth to retrieve just the currently open GMX position instead of directly calling the _getPosition function.",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "can be made more gas eicient INFO The function GmxHedgingReactor::gmxPositionCallback is responsible for updating the internalDelta of the reactor with the values that are stored in the mappings increaseOrderDeltaChange and decreaseOrderDeltaChange. These mappings are essentially used as temporary storage before the change in delta is applied to the internalDelta storage variable. Thus, after a successful update the associated mapping element should be deleted to receive a gas refund for freeing up space on the blockchain.",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "can be made more gas eicient INFO The function GmxHedgingReactor::sync is implemented to consider the scenario where a long and a short position are open on GMX at the same time. function sync() external returns (int256) { _isKeeper(); uint256[] memory longPosition = _getPosition(true); uint256[] memory shortPosition = _getPosition(false); uint256 longDelta = longPosition[0] > 0 ? 01 (longPosition[0]).div(longPosition[2]) : 0; uint256 shortDelta = shortPosition[0] > 0 ? (shortPosition[0]).div(shortPosition[2]) : 0; internalDelta = int256(longDelta) - int256(shortDelta); return internalDelta; } However, the reactor in whole is implemented in a way that ensures that a long and a short position cannot co-exist. Thus, the sync function can be implemented to take into account only the current open position, making it more eicient in terms of gas usage.",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "computations INFO In GmxHedgingReactor::_getCollateralSizeDeltaUsd there is the following code: // GmxHedgingReactor.sol::_getCollateralSizeDeltaUsd():670 if ( int256(position[1] / 1e12) - int256(adjustedCollateralToRemove) < int256(((position[0] - _getPositionSizeDeltaUsd(_amount, position[0])) / 1e12) / (vault.maxLeverage() / 11000)) ) { adjustedCollateralToRemove = position[1] / 1e12 - ((position[0]-_getPositionSizeDeltaUsd(_amount,position[0])) / 1e12) / (vault.maxLeverage() / 11000); if (adjustedCollateralToRemove == 0) { return 0; } } Observe that the quantity (position[0]-_getPositionSizeDeltaUsd(_amount, position[0])) / 1e12) / (vault.maxLeverage() / 11000) is computed twice which can be avoided by computing it once and storing its value to a local variable. The same 01 is true for the quantity _amount.mul(position[2] / 1e12).div(position[0] / 1e12) that appears twice in the following computation: // GmxHedgingReactor.sol::_getCollateralSizeDeltaUsd():651 collateralToRemove = (1e18 - ( (int256(position[0]/1e12)+int256((leverageFactor.mul(position[8]))/1e12)) .mul(1e18-int256(_amount.mul(position[2]/1e12).div(position[0]/1e12))) .div(int256(leverageFactor.mul(position[1])/1e12)) )).mul(int256(position[1]/1e12)) - int256(_amount.mul(position[2]/1e12).div(position[0]/1e12) .mul(position[8]/1e12)); The above computation can be simplied even further by applying specic mathematical properties: uint256 d = _amount.mul(position[2]).div(position[0]); collateralToRemove = (int256(position[1] / 1e12) - ( ((int256(position[0]) + int256(leverageFactor.mul(position[8]))) / 1e12) .mul(1e18 - int256(d)).div(int256(leverageFactor)) )) - int256(d.mul(position[8] / 1e12));",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "calls INFO The functions _increasePosition and _decreasePosition of the reactor unnecessarily call gmxPositionRouters minExecutionFee function twice each instead of caching the returned value in a local variable after the rst call.",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "comment in _increasePosition INFO 01 The comment describing the parameter _collateralSize of the function _increasePosition should read amount of collateral to add instead of \"amount of collateral to remove.",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Rysk/Rysk GMX Hedging Reactor Audit.pdf",
        "body": "errors The following errors are dened but not used: INFO // GmxHedgingReactor.sol::_getCollateralSizeDeltaUsd():88 error ValueFailure(); error IncorrectCollateral(); error IncorrectDeltaChange(); error InvalidTransactionNotEnoughMargin(int256 accountMarketValue, int256 totalRequiredMargin); A8 Compiler bugs INFO The code is compiled with Solidity 0.8.9, which, at the time of writing, has some known bugs, which we do not believe to aect the correctness of the contracts. 01",
        "labels": [
            "Dedaub",
            "Rysk GMX Hedging Reactor",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consumer can be simplied ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink VRF v.2 audit.pdf",
        "body": " Resolved There is lile reason to keep subId both in the key and in the value of the s_consumers mapping. struct Consumer { uint64 subId; uint64 nonce; } mapping(address => mapping(uint64 => Consumer)) /* consumer */ /* subId */ private s_consumers; The information could be kept in a boolean, or encoded in the nonce eld. (E.g., start nonces from 1, to denote an allocated consumer with 0 requests.)",
        "labels": [
            "Dedaub",
            "Chainlink VRF v.2",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink VRF v.2 audit.pdf",
        "body": "code in getRandomnessFromProof Dismissed Under the current denition of the Chainlink blockhash store, the following is dead code (condition never true). The call to get the blochhash would have reverted. blockHash = BLOCKHASH_STORE.getBlockhash(rc.blockNum); if (blockHash == bytes32(0)) { revert BlockhashNotInStore(rc.blockNum); } Admiedly, it is good to code defensively relative to external calls, so the check is not without merit.",
        "labels": [
            "Dedaub",
            "Chainlink VRF v.2",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink VRF v.2 audit.pdf",
        "body": "check in fulfillRandomWords Resolved 0 The check if (gasPreCallback < rc.callbackGasLimit) { revert InsufficientGasForConsumer(gasPreCallback, rc.callbackGasLimit); } is unnecessary, given the stronger check that follows inside the call to callWithExactGas, with gasAmount being rc.callbackGasLimit: assembly { let g := gas() ... if iszero(gt(sub(g, div(g, 64)), gasAmount)) { revert(0, 0) } ...",
        "labels": [
            "Dedaub",
            "Chainlink VRF v.2",
            "Severity: Low"
        ]
    },
    {
        "title": "meaning of MIN_GAS_LIMIT is unclear Resolved Code comments describe MIN_GAS_LIMIT as: // The minimum gas limit that could be requested for a callback. // Set to 5k to ensure plenty of room to make the call itself. uint256 public constant MIN_GAS_LIMIT = 5_000; and /** ... * The minimum amount of gasAmount is MIN_GAS_LIMIT. (With gasAmount being the callbackGasLimit.) However, MIN_GAS_LIMIT is never compared against the callback gas limit, only against the currently available gas. Our interpretation was that it intends to account for the gas of other VRFCoordinatorV2 contract operations outside the client callback. If so, the limit of 5000 is too low. 0 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them. ID Description ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink VRF v.2 audit.pdf",
        "body": "",
        "labels": [
            "Dedaub",
            "Chainlink VRF v.2",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink VRF v.2 audit.pdf",
        "body": "s_fallbackWeiPerUnitLink left out of Config Dismissed It is unclear why variable s_fallbackWeiPerUnitLink is not included in the Config structure, since it is essentially handled as one of the variables therein. For example, the return statement of getConfig(): return ( config.minimumRequestConfirmations, config.fulfillmentFlatFeeLinkPPM, config.maxGasLimit, config.stalenessSeconds, config.gasAfterPaymentCalculation, config.minimumSubscriptionBalance, s_fallbackWeiPerUnitLink ); Is there some benet in keeping the size of Cong down to one word, given that it seems to be always read/wrien together with s_fallbackWeiPerUnitLink ?",
        "labels": [
            "Dedaub",
            "Chainlink VRF v.2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink VRF v.2 audit.pdf",
        "body": "optimizations using unchecked wrapper Dismissed In VRFCoordinatorV2.sol there are a number of safe mathematical operations that could be made more gas eicient if wrapped in unchecked{} In fulllRandomWords: s_subscriptions[rc.subId].balance -= payment; s_withdrawableTokens[s_provingKeys[keyHash]] += payment; In OracleWithdraw: 0 s_withdrawableTokens[msg.sender] -= amount; s_totalBalance -= amount; In defundSubscription: s_subscriptions[subId].balance -= amount; s_totalBalance -= amount In cancelSubscription: s_totalBalance -= balance However, this recommendation could slightly downgrade readability and clarity.",
        "labels": [
            "Dedaub",
            "Chainlink VRF v.2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink VRF v.2 audit.pdf",
        "body": "ordering inside contracts Dismissed Consider adopting the oicial style guide for function ordering within a contract. In order of priority: external > public > internal > private and view > pure within the same visibility group. hps://docs.soliditylang.org/en/v0.8.7/style-guide.html#order-of-functions",
        "labels": [
            "Dedaub",
            "Chainlink VRF v.2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Chainlink/Chainlink VRF v.2 audit.pdf",
        "body": "pragma INFO Use of a floating pragma: The floating pragma pragma solidity ^0.8.0; is used, allowing contracts to be compiled with any version of the Solidity compiler that is greater or equal to v0.8.0 and lower than v.0.9.0. Although the dierences between these versions should be small, for deployment, floating pragmas should ideally be avoided and the pragma be xed. A5 Compiler known issues INFO Solidity compiler v0.8.0, at the time of writing, has some known bugs (SignedImmutables, ABIDecodeTwoDimensionalArrayMemory, KeccakCaching). We believe that none of them aects the code: no immutable signed integer variables are declared, no multidimensional arrays seem to be used in the audited contracts, and no keccak hashing of constant memory arrays takes place. 0 0",
        "labels": [
            "Dedaub",
            "Chainlink VRF v.2",
            "Severity: Informational"
        ]
    },
    {
        "title": "owner could change priceFactor and drain the protocol RESOLVED The price of each token is computed in the getTokenPrice function as a dierence of two 3rd degree polynomials. The nal result is multiplied by the _priceFactor. This local variable equals either the alpha of the token (if the creator of the token has set it), or a standard value (the global variable priceFactor). Suppose that the user has not set the alpha of a token. Suppose also that we execute a buyToken operation, followed by a sellToken operation, with no change of supply or demand in between, and with the priceFactor remaining constant. In this case, the user will simply get back the money originally invested. However, if the _priceFactor changes between a buy and a sell operation, the symmetry between buying and selling is broken. 0 A malicious owner could drain the protocol, manipulating the price of the tokens through the priceFactor, as follows:  He sets a low, or even zero, priceFactor.  Creates a new token without seing its alpha (therefore the priceFactor will be used for the computations of the token price).  Buys a huge amount of this new token (the price will be extremely low or even zero).  Increase the priceFactor.  Sell all his tokens at the new increased value. The amount of native tokens (NaT) he will get back suspases his initial deposit and if the increase in the priceFactor was signicant he could get back even the total amount of NaT paid to the protocol for all the tokens. We suggest either making the priceFactor immutable or storing the priceFactor for all the tokens with no set alpha, at their creation and using this for all the price computations. C2 Users can take advantage of changes of the priceFactor and drain the protocol RESOLVED The impact of an increase in the priceFactor described above can also be taken advantage of by a malicious user as follows:  Frontrun an increase of the priceFactor and create a new token, without seing its alpha, and buy a large amount x of token using y native tokens.  The owner increases the priceFactor.  The aacker sells all his tokens (except of the last one, which is not allowed by the protocol) at a higher price (since the priceFactor has increased) and therefore should get back an amount of native tokens greater than y i.e. he gets also funds deposited for other tokens. If x was suiciently large, the aacker can drain the protocol. 0 Even if no one manages to frontrun a priceFactor change, a change in priceFactor is problematic per se. All the tokens bought before the change will have a dierent price after and therefore any user willing to sell his tokens will also get funds corresponding to other tokens. We suggest either making the priceFactor immutable or storing the priceFactor for all the tokens with no set alpha, at their creation and using this for all the price computations. HIGH SEVERITY: ID Description H1 Requirement that referrer be already invested in the protocol can be bypassed ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": " WONT FIX The addReferrer function currently requires a referrer to be invested in the protocol by having created a token with a certain supply. However a new user can easily circumvent this process by creating a new referrer account with just one token (which costs nothing) and then executing a buy or sell operation using that referrer account, pocketing the referrer fee himself. MEDIUM SEVERITY: ",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Critical"
        ]
    },
    {
        "title": "distribution logic can result in DoS ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": " WONT FIX 0 The functions buyToken and sellToken perform a number of call operations to transfer native tokens for the purpose of fee distribution. If the address on the receiving end of the call is a contract, then this will trigger its fallback function. There can be any code inside such a fallback function, including malicious code. One way this could be exploited by an aacker, is for the aacker to create a malicious referer contract. Once this contract has been registered as the referrer of a token, it will simply revert each time its fallback function is triggered. This will cause every buy and sell operation on that token to fail, causing a denial of service for that token. Due to the nature of the contract we could not nd another way of exploiting the call operations. However one would do well to keep this problem in mind when the contract is expanded in the future, especially when it comes to reentrancy aacks. In general, when funds need to be disbursed by a contract, the safest paern is to have users withdraw funds, instead of sending funds to them, as this avoids the problem with transfer of control. However this would require a more sophisticated accounting system than the one currently employed by the contract.",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "frontrunning protection in sellToken FIXED When a user wants to buy or sell tokens, he only species the amount of tokens and the protocol computes the amount of native tokens he should pay or get back. The user cannot explicitly set an acceptable maximum (when he is buying tokens) or minimum (when he is selling) amount of native tokens. He can only check the current price of the tokens using the getTokenBuy(Sell)PriceAfterFee functions, but the price he will get and the actual price he will pay when we will execute the action could be dierent 0 if the state of the contract has changed in between i.e. if the current supply of the tokens has changed. In buyToken there is an (indirect) protection of the users. There, the user does not only provide the amount of tokens he wants to buy, but also sends the corresponding amount of native tokens. If the price has increased, the transaction will revert. In sellToken there is no protection and a user trying to sell his tokens could get back less than the expected amount of native tokens. Moreover, an aacker could frontrun a sellToken action, selling his tokens before the victim, decreasing the price of the token. We suggest adding an extra variable minAmountOut in sellToken to mitigate this problem, allowing the user to specify a minimum sale price and to revert if this is not achieved. M3 Rounding errors could be exploited by users WONT FIX Even though the formulas for the computation of the price and the fees are additive i.e. the total amount a user should pay and the fees do not change if the user splits the transaction into smaller ones, this holds only in theory (innite accuracy). Rounding errors break this additive nature of the formulas. Therefore the total native tokens a user should pay and the corresponding total protocol fees are less if the user buys x tokens in several steps e.g. x buys of 1 token, compared to a single buy of x tokens. Users could exploit this issue if they buy several tokens one at the time and then sell them all together. An aack of this kind is probably not economically feasible, given that the user should pay extra transaction fees to execute these extra small transactions, but extra care and extensive simulations to identify the possibility of such an aack are needed. 0 A common mitigation for this type of issue is to set a minimum amount a user should be allowed to buy or sell. LOW SEVERITY: ",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Medium"
        ]
    },
    {
        "title": "should be a constructor parameter ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": " WONT FIX At the moment, the platformFeeDestination is set directly in the constructor, and there is a comment indicating that this assignment will be removed in the future. If this occurs, the result would be problematic. For instance, if a transaction takes place before the platformFeeDestination is set, the fees will be sent to address(0). We suggest that platformFeeDestination is provided as a parameter to the constructor. Inconsistency between prices returned by L2 getTokenSellPriceAfterFee and actual nal price FIXED charged by sellToken When selling tokens, the getTokenSellPriceAfterFee function charges a trader fee, but when sellToken is called, no trader fees are deducted. CENTRALIZATION ISSUES: It is often desirable for DeFi protocols to assume no trust in a central authority, including the protocols owner. Even if the owner is reputable, users are more likely to engage with a protocol that guarantees no catastrophic failure even in the case the owner gets hacked/compromised. We list issues of this kind below. (These issues should be 0 considered in the context of usage/deployment, as they are not uncommon. Several high-prole, high-value protocols have signicant centralization threats.) ",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Low"
        ]
    },
    {
        "title": "in getTokenPrice function parameter ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": " FIXED The getTokenPrice function has a parameter called currrentSupply instead of currentSupply (3 rs).",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "numbers in contract FIXED The contract makes use of a number of magic numbers such as 16000 and 10 when calculating the tokens price. We suggest that these be declared as constants with an appropriate name to enhance the transparency of the protocol. Code duplication",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "FIXED There are instances of code duplication in the code base which can be refactored out. For instance, the computation of the fees in getTokenBuyPriceAfterFee and getTokenSellPriceAfterFee are identical. There is also duplicated code relating to fee transfers between buyToken and sellToken. There is also duplicate code within buyToken and sellToken itself, between the if and else branches relating to fee transfers. We recommend that these be factored out to help in the future maintainability of the protocol, so that changes only need to happen in one place. Duplicated code related to fee computations was refactored.",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "fee charges and refunds WONT FIX 01 In buyToken, the user sends his trader fee as part of the call, and is then refunded the same amount at the end of the transaction. Similarly, when a user creates a token when calling buyToken, he rst gets charged a creator fee, which is then refunded again at the end of the transaction. After consulting with the team, we understand that this is part of the protocols marketing. However the fees could simply be computed and corresponding events emied, avoiding the actual transfer of funds, if so wished.",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "cases and sanity checks FIXED In sellToken the requirement that the amount is positive should be added, similarly to what is done in buyToken. In getTokenPrice the variable s2 should be directly assigned the 0 value not only whenever currentSupply == 0 but also when it equals 1 (for gas savings).",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "reentrancy guard in setAlpha FIXED We have thoroughly investigated the possibility of altering the alpha of a token after its creation and we were not able to nd any possible way to do so, but as an extra measure, and as a defense to possible future changes of the code of the contract, we suggest also adding a reentrancy guard in setAlpha.",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "the funds of each token WONT FIX Users can buy tokens by sending native tokens (NaT) to the protocol. The protocol does not distinguish between the funds invested in dierent tokens. Even though each individual user is not guaranteed that he will get back, when he is selling, the exact amount he had paid when he bought the token (the price could have changed due to changes in supply and demand), the total NaT paid for each type of token can be collectively withdrawn (minus the fees) and it should not be possible to withdraw 01 funds associated to holders of other tokens. This is an important invariant of the protocol. Under normal circumstances this invariant seems to hold (check",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "exceptions), but as an extra safety and a good practice we suggest explicitly storing, not only the current supply of each token, but also the total amount of NaT deposited for that token and checking that when a user sells his tokens, he does not get back more than the total deposited NaT corresponding to the type of token he is holding.",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Critical"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "getTokenSellPrice function does not check if amount is greater than supply FIXED The getTokenSellPrice function checks whether the supply is non-zero before returning the price, but does not check whether the amount is greater than the supply, thus returning a wrong price in this situation. function getTokenSellPrice address tokenAddress, uint256 amount ) internal view returns (uint256) { uint256 _supply = tokensSupply[tokenAddress].currentSupply; uint256 _priceFactor = tokensSupply[tokenAddress].alpha == 0 ? priceFactor : tokensSupply[tokenAddress].alpha; return } _supply == 0 ? 0 : getTokenPrice(_supply - amount, amount, _priceFactor); We recommend altering the last check before the return in the following way. 01 function getTokenSellPrice address tokenAddress, uint256 amount ) internal view returns (uint256) { uint256 _supply = tokensSupply[tokenAddress].currentSupply; uint256 _priceFactor = tokensSupply[tokenAddress].alpha == 0 ? priceFactor : tokensSupply[tokenAddress].alpha; return } _supply <= amount ? 0 : getTokenPrice(_supply - amount, amount, _priceFactor);",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Follows App/Follows.app Audit - Oct '23.pdf",
        "body": "getTokenPrice function can underflow and revert FIXED The getTokenPrice function can underflow if both supply and amount are equal to zero. In this case it would be beer if the function returned zero instead. A10 Compiler bugs INFO The code is compiled with Solidity 0.8.19. Version 0.8.19, in particular, has some known bugs, which we do not believe aect the correctness of the contracts.",
        "labels": [
            "Dedaub",
            "Follows.app",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Apr '22.pdf",
        "body": "allows any msg.sender to send Ether RESOLVED ETH deposited into the Vault contract is converted to WETH by being deposited into the WETH contract. A user wishing to withdraw their ETH needs to call the withdrawEther method, which in turn calls the withdraw method of the WETH contract. As part of the unwrapping procedure of WETH, ETH is sent back to the Vault contract, which needs to be able to receive it and thus denes the special receive() method. It is expected (mentioned in a comment) that the receive() method will only be used to receive funds sent by the WETH contract. However, there is no check enforcing this assumption, allowing practically anyone to send ETH to the contract. We believe that the current version of the code is not susceptible to any aacks that could try to manipulate the accounting of ETH performed by the Vault. Still, we cannot guarantee that no aack vectors will arise as the codebase evolves and thus suggest adding a check on the msg.sender as follows: receive() external payable { require(_msgSender() == _WETH9, \"msg.sender is not WETH\"); } 0 OTHER/ ADVISORY ISSUES: This section details issues that are not thought to directly aect the functionality of the project, but we recommend considering them.",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Apr '22.pdf",
        "body": "allows 0 value withdrawals ACKNOWLEDGED The Vault contract allows 0 value withdrawals through its external withdraw and withdrawEther methods. We believe that adding a requirement that a withdrawals amount should be greater than 0 would improve user experience and prevent the unnecessary spending of gas on user error. [The suggestion has been acknowledged by the protocol's team and might be implemented in a future release.]",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Apr '22.pdf",
        "body": "allows 0 value liquidations ACKNOWLEDGED The Vault contract allows 0 value liquidations through its liquidateCollateral method. Disallowing such liquidations will protect users from unnecessarily spending gas in case they make a mistake. [The suggestion has been acknowledged by the protocol's team and might be implemented in a future release.]",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Apr '22.pdf",
        "body": "gas optimization RESOLVED Internal method Vault::_modifyBalance allows the mount parameter to be 0. This behavior is intended, as it is clearly documented in a comment. Nevertheless, when amount is 0, no changes are applied to the contract's state, as can be seen below: function _modifyBalance( address trader, address token, int256 amount ) internal { 0 // Dedaub: code has no effects on storage, still consumes some gas int256 oldBalance = _balance[trader][token]; int256 newBalance = oldBalance.add(amount); _balance[trader][token] = newBalance; if (token == _settlementToken) { return; } // register/deregister non-settlement collateral tokens if (oldBalance != 0 && newBalance == 0) { // Dedaub: execution will not reach here when amount is 0 // .. } else if (oldBalance == 0 && newBalance != 0) { // Dedaub: execution will not reach here when amount is 0 // .. } } oldBalance and newBalance are equal when amount is 0, thus no state changes get applied. Still some gas is consumed, which can be avoided if the method is changed to return early if amount is 0.",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Perpetual Protocol/Perp.fi V2 Audit Report - Apr '22.pdf",
        "body": "gas optimization RESOLVED Method _getAccountValueAndTotalCollateralValue calls the AccountBalance contracts method getPnlAndPendingFee twice, once directly and once in the call to _getSettlementTokenBalanceAndUnrealizedPnl in _getTotalCollateralValue. The rst call to getPnlAndPendingFee to get the unrealized PnL could be removed if the code was restructured appropriately to reuse the same value returned by _getSettlementTokenBalanceAndUnrealizedPnl. A5 Compiler known issues INFO 0 The contracts were compiled with the Solidity compiler v0.7.6 which, at the time of writing, has a few known bugs. We inspected the bugs listed for this version and concluded that the subject code is unaected. 0 CENTRALIZATION ASPECTS As is common in many new protocols, the owner of the smart contracts yields considerable power over the protocol, including changing the contracts holding the users funds and adding tokens, which potentially means borrowing tokens using fake collateral, etc. In addition, the owner of the protocol has total control of several protocol parameters: - the collateral ratio of tokens - the discount ratio (applicable in liquidation) - the deposit cap of tokens - the maximum number of dierent collateral tokens for an account - the maintenance margin buer ratio - the allowed ratio of debt in non selement tokens - the liquidation ratio - the insurance fund fee ratio - the debt threshold - the collateral value lower (dust) limit In case the aforementioned parameters are decided by governance in future versions of the protocol, collateral ratios should be approached in a really careful and methodical way. We believe that a more decentralized approach would be to alter these weights in a specic way dened by predetermined formulas (taking into consideration the on-chain volatility and liquidity available on-chain) and allow only small adjustments by governance. 0",
        "labels": [
            "Dedaub",
            "Perp.fi V2",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "math operations Status Resolved 4 In contract vArmor.sol functions vArmorToArmor() and armorToVArmor() perform numerical operations without checking for overow. In vArmorToArmor() overow of multiplication is not checked: function vArmorToArmor(uint256 _varmor) public view returns(uint256) { if(totalSupply() == 0){ return 0; } return _varmor * armor.balanceOf(address(this)) / totalSupply(); } Similar for armorToVArmor(). These functions are called during deposit and withdraw for calculating token amounts to be transferred, so erroneous results will have a signicant impact on the correctness of the protocol. M2 DoS by proposing proposals that need to be voted out quickly Open Any governance token holder can DoS their peers by proposing many unfavorable proposals, which need to be voted out. Voting proposals out will incur more gas fees as these are subject to a deadline (and may be voted down by multiple participants) whereas a proposer can also wait for the optimal time to spend gas. Low Severity ",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Medium"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "and gov privileged users not checked for address zero Status Open In Timelock.sol the addresses of gov and admin are set during the construction of the contract. Requirements for checking non-zero addresses is suggested.",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "introduce opportunities for reentrancy during swaps Open 5 In vArmor.sol, governance through a simple proposal can add tokenHelpers that are executed whenever a token transfer takes place. Token transfers also take place during swaps or other activities like deposits or withdrawals. The opportunity for reentrancy may not be immediately visible but if this were to be possible, consequences may include the draining of LP pool funds. L3 Proposer can propose multiple proposals (Sybil attack) Open A proposal can propose multiple proposals at the same time, defeating checks to disallow this: 1) Deposit enough $armor in the vArmor pool 2) Propose a proposal 3) Withdraw $armor from vArmor pool 4) Transfer $armor to a different address 5) Repeat The protocol offers the function cancel(uint proposalId) public to mitigate this attack, which proceeds in canceling a proposal if the proposers votes have fallen below the required threshold. However, this requires some users or the mutlisig to constantly be in a state of readiness. Other/Advisory Issues This section details issues that are not thought to directly affect the functionality of the project, but we recommend addressing. ",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Low"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "type declarations Status Open In contract ArmorGovernor.sol the parameters of several functions are declared as uint256, whereas most numerical variables are declared as uint. We suggest that a single style of declaration is used for clarity and consistency.",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "code style regarding subtractions Resolved In contract ArmorGovernor.sol functions cancel() and propose() include same subtraction operation (block.number - 1) twice but with slightly different implementation. One is executed immediately, while the other uses a safety checking function sub256(). In propose(): 6 require(varmor.getPriorVotes(msg.sender, sub256(block.number, 1)) > proposalThreshold(block.number - 1), Similar in cancel(). Underow seems unlikely in this case, however we suggest that all subtractions are performed in the same way for consistency.",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "errors in error messages Partially resolved (error in AcceptGov() remains) In contract Timelock.sol functions acceptGov() and setPendingGov() contain a typo in the error messages of a requirement. In acceptGov(): require(msg.sender == address(this), \"Timelock::setPendingAdmin: Call must come from Timelock.\"); Should become: require(msg.sender == address(this), \"Timelock::setPendingGov: Call must come from Timelock.\"); Similar for setPendingGov().",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "event emitted Resolved In contract Timelock.sol the function setPendingGov() emits a wrong event. emit NewPendingAdmin(pendingGov); Should become emit NewPendingGov(pendingGov); 7",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "error messages Resolved In contract Timelock.sol the functions which are admin- or gov-only refer only to admin when it comes to authorization-related error messages. For example, in function queueTransaction() require(msg.sender == admin || msg.sender == gov, \"Timelock::queueTransaction: Call must come from admin.\"); Similar for functions cancelTransaction(), executeTransaction(). We suggest that the error messages are extended to include gov as well.",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Armor Finance/Armor Governance audit May 21.pdf",
        "body": "code reuse Info In contract vArmor.sol the Checkpoint struct is used to record both account votes (storage variable checkpoints) and the total token supply (storage variable checkpointsTotal) while the struct eld is named votes, making the code slightly harder to follow. For example, in function _writeCheckpointTotal we inspect the following checkpointsTotal[nCheckpoints - 1].votes = newTotal; A7 Floating pragma Info Use of a oating pragma: The oating pragma pragma solidity ^0.6.6; is used in the Timelock contract allowing it to be compiled with any version of the Solidity compiler that is greater or equal to v0.6.6 and lower than v.0.7.0. Although the differences between these versions are small, oating pragmas should be avoided and the pragma should be xed to the version that will be used for the contracts deployment. ArmorGovernance contract uses pragma solidity ^0.6.12; which can be altered to the identical and simpler pragma solidity 0.6.12;.",
        "labels": [
            "Dedaub",
            "Armor Governance",
            "Severity: Informational"
        ]
    },
    {
        "title": "gas behavior in BondExtraData ",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/Chicken Bonds Delta Audit (NFT additions).pdf",
        "body": " RESOLVED (commit a60f451f) The BondExtraData struct is designed to t in one storage word: struct BondExtraData { uint80 initialHalfDna; uint80 finalHalfDna; uint32 troveSize; // Debt in LUSD uint32 lqtyAmount; // Holding LQTY, staking or deposited into Pickle uint32 curveGaugeSlopes; // For 3CRV and Frax pools combined } (We note, in passing, that the uint32 amounts are rounded down, so dierent underlying amounts can map to the same recorded amount. This seems like an extremely minor inaccuracy but it also pertains to issue L1, of NFT manipulation.) The result of ing the struct in a single word is that the following code is highly suboptimal, gas-wise, requiring 4 separate SSTOREs, but also SLOADs of values before the SSTORE (so that unaected bits get preserved): function setFinalExtraData(address _bonder, uint256 _tokenID, uint256 _permanentSeed) external returns (uint80) {  0 idToBondExtraData[_tokenID].finalHalfDna = newDna;  idToBondExtraData[_tokenID].troveSize = _uint256ToUint32(troveManager.getTroveDebt(_bonder));  idToBondExtraData[_tokenID].lqtyAmount = _uint256ToUint32(lqtyToken.balanceOf(_bonder) + lqtyStaking.stakes(_bonder) + pickleLQTYAmount);  idToBondExtraData[_tokenID].curveGaugeSlopes = _uint256ToUint32((curveLUSD3CRVGaugeSlope + curveLUSDFRAXGaugeSlope) * CURVE_GAUGE_SLOPES_PRECISION); We recommend using a memory record of the struct, reading its original value from storage, updating the 4 elds in-memory, and storing back to idToBondExtraData[_tokenID]. The Solidity compiler could conceptually optimize the above paern, but current versions do not even aempt such an optimization in the presence of internal calls, let alone external calls. (We also ascertained that the resulting bytecode is suboptimal under the current build seings of the repo.)",
        "labels": [
            "Dedaub",
            "Chicken Bonds Delta",
            "Severity: Informational"
        ]
    },
    {
        "title": "",
        "html_url": "https://github.com/dedaub/audits/tree/main/Liquity/Chicken Bonds Delta Audit (NFT additions).pdf",
        "body": "extraneous check RESOLVED (commit f5fb7f16) Under the, relatively reasonable, assumption that MIN_BOND_AMOUNT is never zero, the rst of the following checks would be extraneous: function createBond(uint256 _lusdAmount) public returns (uint256) { _requireNonZeroAmount(_lusdAmount); _requireMinBond(_lusdAmount); A3 Compiler bugs INFO (RESOLVED) 0 The code is compiled with Solidity 0.8.10 or higher. For deployment, we recommend no floating pragmas, i.e., a specic version, so as to be condent about the baseline guarantees oered by the compiler. Version 0.8.10, in particular, has some known bugs, which we do not believe to aect the correctness of the contracts.",
        "labels": [
            "Dedaub",
            "Chicken Bonds Delta",
            "Severity: Informational"
        ]
    }
]