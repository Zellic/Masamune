[{"title": "5.2 Passing duplicate tokens to Redemptions and TokenRequest may have unintended consequences    Addressed", "body": "  Resolution  This was addressed in Redemptions commit 2b0034206a5b9cdf239da7a51900e89d9931554f by checking redeemableTokenAdded[token] == false for each subsequent token added during initialization. Note that ordering is not enforced.  Additionally, the issue in TokenRequest was addressed in commit eb4181961093439f142f2e74eb706b7f501eb5c0 by requiring that each subsequent token added during initialization has a value strictly greater than the previous token added.  Description  Both Redemptions and TokenRequest are initialized with a list of acceptable tokens to use with each app. For Redemptions, the list of tokens corresponds to an organization s treasury assets. For TokenRequest, the list of tokens corresponds to tokens accepted for payment to join an organization. Neither contract makes a uniqueness check on input tokens during initialization, which can lead to unintended behavior.  Examples  In Redemptions, each of an organization s assets are redeemed according to the sender s proportional ownership in the org. The redemption process iterates over the redeemableTokens list, paying out the sender their proportion of each token listed:  code/redemptions-app/contracts/Redemptions.sol:L112-L121  for (uint256 i = 0; i < redeemableTokens.length; i++) {  vaultTokenBalance = vault.balance(redeemableTokens[i]);  redemptionAmount = _burnableAmount.mul(vaultTokenBalance).div(burnableTokenTotalSupply);  totalRedemptionAmount = totalRedemptionAmount.add(redemptionAmount);  if (redemptionAmount > 0) {  vault.transfer(redeemableTokens[i], msg.sender, redemptionAmount);  If a token address is included more than once, the sender will be paid out more than once, potentially earning many times more than their proportional share of the token.  In TokenRequest, this behavior does not allow for any significant deviation from expected behavior. It was included because the initialization process is similar to that of Redemptions.  Recommendation  During initialization in both apps, check that input token addresses are unique. One simple method is to require that token addresses are submitted in ascending order, and that each subsequent address added is greater than the one before.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2019/12/dandelion-organizations/"}, {"title": "5.3 The Delay app allows scripts to be paused even after execution time has elapsed    Addressed", "body": "  Resolution                           This was addressed in   commit 46d8fa414cc3e68c68a5d9bc1174be5f32970611 by requiring that the current timestamp is before the delayed script s execution time.  Description  The Delay app is used to configure a delay between when an evm script is created and when it is executed. The entry point for this process is Delay.delayExecution, which stores the input script with a future execution date:  code/delay-app/contracts/Delay.sol:L153-L162  function _delayExecution(bytes _evmCallScript) internal returns (uint256) {  uint256 delayedScriptIndex = delayedScriptsNewIndex;  delayedScriptsNewIndex++;  delayedScripts[delayedScriptIndex] = DelayedScript(getTimestamp64().add(executionDelay), 0, _evmCallScript);  emit DelayedScriptStored(delayedScriptIndex);  return delayedScriptIndex;  An auxiliary capability of the Delay app is the ability to  pause  the delayed script, which sets the script s pausedAt value to the current block timestamp:  code/delay-app/contracts/Delay.sol:L80-L85  function pauseExecution(uint256 _delayedScriptId) external auth(PAUSE_EXECUTION_ROLE) {  require(!_isExecutionPaused(_delayedScriptId), ERROR_CAN_NOT_PAUSE);  delayedScripts[_delayedScriptId].pausedAt = getTimestamp64();  emit ExecutionPaused(_delayedScriptId);  A paused script cannot be executed until resumeExecution is called, which extends the script s executionTime by the amount of time paused. Essentially, the delay itself is paused:  code/delay-app/contracts/Delay.sol:L91-L100  function resumeExecution(uint256 _delayedScriptId) external auth(RESUME_EXECUTION_ROLE) {  require(_isExecutionPaused(_delayedScriptId), ERROR_CAN_NOT_RESUME);  DelayedScript storage delayedScript = delayedScripts[_delayedScriptId];  uint64 timePaused = getTimestamp64().sub(delayedScript.pausedAt);  delayedScript.executionTime = delayedScript.executionTime.add(timePaused);  delayedScript.pausedAt = 0;  emit ExecutionResumed(_delayedScriptId);  A delayed script whose execution time has passed and is not currently paused should be able to be executed via the execute function. However, the pauseExecution function still allows the aforementioned script to be paused, halting execution.  Recommendation  Add a check to pauseExecution to ensure that execution is not paused if the script s execution delay has already transpired.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2019/12/dandelion-organizations/"}, {"title": "5.4 Misleading intentional misconfiguration possible through misuse of newToken and newBaseInstance    Addressed", "body": "  Resolution                           This was addressed in   commit b68d89ab0deb22161987e19d1ff0bb9d7303f0a9 by making  Description  The instantiation process for a Dandelion organization requires two separate external calls to DandelionOrg. There are two primary functions: installDandelionApps, and newTokenAndBaseInstance.  installDandelionApps relies on cached results from prior calls to newTokenAndBaseInstance and completes the initialization step for a Dandelion org.  newTokenAndBaseInstance is a wrapper around two publicly accessible functions: newToken and newBaseInstance. Called together, the functions:  Deploy a new MiniMeToken used to represent shares in an organization, and cache the address of the created token:  code/dandelion-org/contracts/DandelionOrg.sol:L128-L137  /**  @dev Create a new MiniMe token and save it for the user  @param _name String with the name for the token used by share holders in the organization  @param _symbol String with the symbol for the token used by share holders in the organization  /  function newToken(string memory _name, string memory _symbol) public returns (MiniMeToken) {  MiniMeToken token = _createToken(_name, _symbol, TOKEN_DECIMALS);  _saveToken(token);  return token;  Create a new dao instance using Aragon s BaseTemplate contract:  code/dandelion-org/contracts/DandelionOrg.sol:L139-L160  /**  @dev Deploy a Dandelion Org DAO using a previously saved MiniMe token  @param _id String with the name for org, will assign `[id].aragonid.eth`  @param _holders Array of token holder addresses  @param _stakes Array of token stakes for holders (token has 18 decimals, multiply token amount `* 10^18`)  @param _useAgentAsVault Boolean to tell whether to use an Agent app as a more advanced form of Vault app  /  function newBaseInstance(  string memory _id,  address[] memory _holders,  uint256[] memory _stakes,  uint64 _financePeriod,  bool _useAgentAsVault  public  _validateId(_id);  _ensureBaseSettings(_holders, _stakes);  (Kernel dao, ACL acl) = _createDAO();  _setupBaseApps(dao, acl, _holders, _stakes, _financePeriod, _useAgentAsVault);  Set up prepackaged Aragon apps, like Vault, TokenManager, and Finance:  code/dandelion-org/contracts/DandelionOrg.sol:L162-L182  function _setupBaseApps(  Kernel _dao,  ACL _acl,  address[] memory _holders,  uint256[] memory _stakes,  uint64 _financePeriod,  bool _useAgentAsVault  internal  MiniMeToken token = _getToken();  Vault agentOrVault = _useAgentAsVault ? _installDefaultAgentApp(_dao) : _installVaultApp(_dao);  TokenManager tokenManager = _installTokenManagerApp(_dao, token, TOKEN_TRANSFERABLE, TOKEN_MAX_PER_ACCOUNT);  Finance finance = _installFinanceApp(_dao, agentOrVault, _financePeriod == 0 ? DEFAULT_FINANCE_PERIOD : _financePeriod);  _mintTokens(_acl, tokenManager, _holders, _stakes);  _saveBaseApps(_dao, finance, tokenManager, agentOrVault);  _saveAgentAsVault(_dao, _useAgentAsVault);  Note that newToken and newBaseInstance can be called separately. The token created in newToken is cached in _saveToken, which overwrites any previously-cached value:  code/dandelion-org/contracts/DandelionOrg.sol:L413-L417  function _saveToken(MiniMeToken _token) internal {  DeployedContracts storage senderDeployedContracts = deployedContracts[msg.sender];  senderDeployedContracts.token = address(_token);  Cached tokens are retrieved in _getToken:  code/dandelion-org/contracts/DandelionOrg.sol:L441-L447  function _getToken() internal returns (MiniMeToken) {  DeployedContracts storage senderDeployedContracts = deployedContracts[msg.sender];  require(senderDeployedContracts.token != address(0), ERROR_MISSING_TOKEN_CONTRACT);  MiniMeToken token = MiniMeToken(senderDeployedContracts.token);  return token;  By exploiting the overwriteable caching mechanism, it is possible to intentionally misconfigure Dandelion orgs.  Examples  installDandelionApps uses _getToken to associate a token with the DandelionVoting app. The value returned from _getToken depends on the sender s previous call to newToken, which overwrites any previously-cached value. The steps for intentional misconfiguration are as follows:  Sender calls newTokenAndBaseInstance, creating token m0 and DAO A.  The TokenManager app in A is automatically configured to be the controller of m0.  m0 is cached using _saveToken.  DAO A apps are cached for future use using _saveBaseApps and _saveAgentAsVault.  Sender calls newToken, creating token m1, and overwriting the cache of m0.  Future calls to _getToken will retrieve m1.  The DandelionOrg contract is the controller of m1.  Sender calls installDandelionApps, which installs Dandelion apps in DAO A  The DandelionVoting app is configured to use the current cached token, m1, rather than the token associated with A.TokenManager, m0  Many different misconfigurations are possible, and some may be underhandedly abusable.  Recommendation  Make newToken and newBaseInstance internal so they are only callable via newTokenAndBaseInstance.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2019/12/dandelion-organizations/"}, {"title": "5.5 Delay.execute can re-enter and re-execute the same script twice    Addressed", "body": "  Resolution                           This was addressed in   commit f049e978f93765e27783a3ecac4830498bb779ba by deleting the delayed script before it is run. 1Hive elected to keep an empty script blacklist in order to allow delayed actions to be taken on the  Description  Delay.execute does not follow the  checks-effects-interactions  pattern, and deletes a delayed script only after the script is run. Because the script being run executes arbitrary external calls, a script can be created that re-enters Delay and executes itself multiple times before being deleted:  code/delay-app/contracts/Delay.sol:L112-L123  /**  @notice Execute the script with ID `_delayedScriptId`  @param _delayedScriptId The ID of the script to execute  /  function execute(uint256 _delayedScriptId) external {  require(canExecute(_delayedScriptId), ERROR_CAN_NOT_EXECUTE);  runScript(delayedScripts[_delayedScriptId].evmCallScript, new bytes(0), new address[](0));  delete delayedScripts[_delayedScriptId];  emit ExecutedScript(_delayedScriptId);  Recommendation  Add the Delay contract address to the runScript blacklist, or delete the delayed script from storage before it is run.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2019/12/dandelion-organizations/"}, {"title": "5.6 Delay.cancelExecution should revert on a non-existent script id    Addressed", "body": "  Resolution                           This was addressed in   commit d99c94f5138a9af1fd5f0cd6990c140b46a55925 by adding the  Description  cancelExecution makes no existence check on the passed-in script ID, clearing its storage slot and emitting an event:  code/delay-app/contracts/Delay.sol:L102-L110  /**  @notice Cancel script execution with ID `_delayedScriptId`  @param _delayedScriptId The ID of the script execution to cancel  /  function cancelExecution(uint256 _delayedScriptId) external auth(CANCEL_EXECUTION_ROLE) {  delete delayedScripts[_delayedScriptId];  emit ExecutionCancelled(_delayedScriptId);  Recommendation  Add a check that the passed-in script exists.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2019/12/dandelion-organizations/"}, {"title": "5.7 ID validation check missing for installDandelionApps    Addressed", "body": "  Resolution                           This was addressed in   commit 8d1ecb1bc892d6ea1d34c7234e35de031db2bebd by removing the  Description  DandelionOrg allows users to kickstart an Aragon organization by using a dao template. There are two primary functions to instantiate an org: newTokenAndBaseInstance, and installDandelionApps. Both functions accept a parameter, string _id, meant to represent an ENS subdomain that will be assigned to the new org during the instantiation process. The two functions are called independently, but depend on each other.  In newTokenAndBaseInstance, a sanity check is performed on the _id parameter, which ensures the _id length is nonzero:  code/dandelion-org/contracts/DandelionOrg.sol:L155  _validateId(_id);  Note that the value of _id is otherwise unused in newTokenAndBaseInstance.  In installDandelionApps, this check is missing. The check is only important in this function, since it is in installDandelionApps that the ENS subdomain registration is actually performed.  Recommendation  Use _validateId in installDandelionApps rather than newTokenAndBaseInstance. Since the _id parameter is otherwise unused in newTokenAndBaseInstance, it can be removed.  Alternatively, the value of the submitted _id could be cached between calls and validated in newTokenAndBaseInstance, similarly to newToken.  6 Tool-Based Analysis  Several tools were used to perform automated analysis of the reviewed contracts. These issues were reviewed by the audit team, and relevant issues are listed in the Issue Details section.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2019/12/dandelion-organizations/"}, {"title": "6.1 Ethlint", "body": "  Ethlint is an open source project for linting Solidity code. Only security-related issues were reviewed by the audit team.  Below is the raw output of the Ethlint vulnerability scan:  $ solium -V  Solium version 1.2.5  $ solium -d .  dandelion-org/contracts/DandelionOrg.sol  86:1     warning    Line contains trailing whitespace           no-trailing-whitespace  226:8    warning    Line exceeds the limit of 145 characters    max-len  dandelion-voting-app/contracts/DandelionVoting.sol  272:8    warning    Line exceeds the limit of 145 characters    max-len  token-request-app/contracts/TokenRequest.sol  62:4      warning    Line exceeds the limit of 145 characters                 max-len  104:1     warning    Line contains trailing whitespace                        no-trailing-whitespace  token-request-app/contracts/lib/UintArrayLib.sol  6:3    error    Only use indent of 4 spaces.    indentation  \u2716 1 error, 5 warnings found.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2019/12/dandelion-organizations/"}, {"title": "6.2 Surya", "body": "  Surya is a utility tool for smart contract systems. It provides a number of visual outputs and information about the structure of smart contracts. It also supports querying the function call graph in multiple ways to aid in the manual inspection and control flow analysis of contracts.  Below is a complete list of functions with their visibility and modifiers:  Contracts Description Table  Function Name  Visibility  Mutability  Modifiers  AddressArrayLib  Library  deleteItem  Internal \ud83d\udd12  contains  Internal \ud83d\udd12  ArrayUtils  Library  deleteItem  Internal \ud83d\udd12  DandelionOrg  Implementation  BaseTemplate  <Constructor>  Public    BaseTemplate  newTokenAndBaseInstance  External    NO   installDandelionApps  External    NO   newToken  Public    NO   newBaseInstance  Public    NO   _setupBaseApps  Internal \ud83d\udd12  _installDandelionApps  Internal \ud83d\udd12  _installDandelionVotingApp  Internal \ud83d\udd12  _installDandelionVotingApp  Internal \ud83d\udd12  _createDandelionVotingPermissions  Internal \ud83d\udd12  _installRedemptionsApp  Internal \ud83d\udd12  _createRedemptionsPermissions  Internal \ud83d\udd12  _installTokenRequestApp  Internal \ud83d\udd12  _createTokenRequestPermissions  Internal \ud83d\udd12  _installTimeLockApp  Internal \ud83d\udd12  _installTimeLockApp  Internal \ud83d\udd12  _createTimeLockPermissions  Internal \ud83d\udd12  _installTokenBalanceOracle  Internal \ud83d\udd12  _createTokenBalanceOraclePermissions  Internal \ud83d\udd12  _setupBasePermissions  Internal \ud83d\udd12  _setupDandelionPermissions  Internal \ud83d\udd12  _saveToken  Internal \ud83d\udd12  _saveBaseApps  Internal \ud83d\udd12  _saveAgentAsVault  Internal \ud83d\udd12  _getDao  Internal \ud83d\udd12  _getToken  Internal \ud83d\udd12  _getBaseApps  Internal \ud83d\udd12  _getAgentAsVault  Internal \ud83d\udd12  _clearDeployedContracts  Internal \ud83d\udd12  _ensureBaseAppsDeployed  Internal \ud83d\udd12  _ensureBaseSettings  Private \ud83d\udd10  _ensureDandelionSettings  Private \ud83d\udd10  _registerApp  Private \ud83d\udd10  _setOracle  Private \ud83d\udd10  _paramsTo256  Private \ud83d\udd10  DandelionVoting  Implementation  IForwarder, IACLOracle, AragonApp  initialize  External    onlyInit  changeSupportRequiredPct  External    authP  changeMinAcceptQuorumPct  External    authP  changeBufferBlocks  External    auth  changeExecutionDelayBlocks  External    auth  newVote  External    auth  vote  External    voteExists  executeVote  External    NO   isForwarder  External    NO   forward  Public    NO   canForward  Public    NO   canPerform  External    NO   canExecute  Public    NO   canVote  Public    voteExists  getVote  Public    voteExists  getVoterState  Public    voteExists  _newVote  Internal \ud83d\udd12  _vote  Internal \ud83d\udd12  _canExecute  Internal \ud83d\udd12  voteExists  _votePassed  Internal \ud83d\udd12  _canVote  Internal \ud83d\udd12  _voterStake  Internal \ud83d\udd12  _isVoteOpen  Internal \ud83d\udd12  _isValuePct  Internal \ud83d\udd12  Delay  Implementation  AragonApp, IForwarder  initialize  External    onlyInit  setExecutionDelay  External    auth  delayExecution  External    auth  isForwarder  External    NO   pauseExecution  External    auth  resumeExecution  External    auth  cancelExecution  External    auth  execute  External    NO   canExecute  Public    NO   canForward  Public    NO   forward  Public    NO   _isExecutionPaused  Internal \ud83d\udd12  scriptExists  _delayExecution  Internal \ud83d\udd12  Redemptions  Implementation  AragonApp  initialize  External    onlyInit  addRedeemableToken  External    auth  removeRedeemableToken  External    auth  redeem  External    authP  getRedeemableTokens  External    NO   getToken  External    NO   getETHAddress  External    NO   TimeLock  Implementation  AragonApp, IForwarder, IForwarderFee  initialize  External    onlyInit  changeLockDuration  External    auth  changeLockAmount  External    auth  changeSpamPenaltyFactor  External    auth  withdrawAllTokens  External    NO   withdrawTokens  External    NO   forwardFee  External    NO   isForwarder  External    NO   canForward  Public    NO   forward  Public    NO   getWithdrawLocksCount  Public    NO   getSpamPenalty  Public    NO   _withdrawTokens  Internal \ud83d\udd12  TokenBalanceOracle  Implementation  AragonApp, IACLOracle  initialize  External    onlyInit  setToken  External    auth  setMinBalance  External    auth  canPerform  External    NO   TokenRequest  Implementation  AragonApp  initialize  External    onlyInit  setTokenManager  External    auth  setVault  External    auth  addToken  External    auth  removeToken  External    auth  createTokenRequest  External    NO   refundTokenRequest  External    nonReentrant tokenRequestExists  finaliseTokenRequest  External    nonReentrant tokenRequestExists auth  getAcceptedDepositTokens  Public    NO   getTokenRequest  Public    NO   getToken  Public    NO   UintArrayLib  Library  deleteItem  Internal \ud83d\udd12  Legend  Function can modify state  Function is payable  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2019/12/dandelion-organizations/"}, {"title": "6.1 Swap fees can be bypassed using redeemMasset    Addressed", "body": "  Resolution                           This issue was reported independently via the bug bounty program and was   fixed early during the audit. The fix has already been deployed on mainnet using the upgrade mechanism  Description  Part of the value proposition for liquidity providers is earning fees incurred for swapping between assets. However, traders can perform fee-less swaps by providing liquidity in one bAsset, followed by calling redeemMasset() to convert the resulting mAssets back into a proportional amount of bAssets. Since removing liquidity via  redeemMasset() does not incur a fee this is equivalent to doing a swap with zero fees.  As a very simple example, assuming a pool with 2 bAssets (say, DAI and USDT), it would be possible to swap 10 DAI to USDT as follows:  Add 20 DAI to the pool, receive 20 mUSD  call redeemMasset() to redeem 10 DAI and 10 USDT  Examples  The boolean argument applyFee is set to false in _redeemMasset:  code/contracts/masset/Masset.sol:L569  _settleRedemption(_recipient, _mAssetQuantity, props.bAssets, bAssetQuantities, props.indexes, props.integrators, false);  Recommendation  Charge a small redemption fee in redeemMasset().  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.2 Users can collect interest from SavingsContract by only staking mTokens momentarily    Addressed", "body": "  Resolution  The blocker on collecting interest more than once in 30 minute period. A new APY bounds check has been added to verify that supply isn t inflated by more than 0.1% within a 30 minutes window.  Description  The SAVE contract allows users to deposit mAssets in return for lending yield and swap fees. When depositing mAsset, users receive a  credit  tokens at the momentary credit/mAsset exchange rate which is updated at every deposit. However, the smart contract enforces a minimum timeframe of 30 minutes in which the interest rate will not be updated. A user who deposits shortly before the end of the timeframe will receive credits at the stale interest rate and can immediately trigger and update of the rate and withdraw at the updated (more favorable) rate after the 30 minutes window. As a result, it would be possible for users to benefit from interest payouts by only staking mAssets momentarily and using them for other purposes the rest of the time.  Examples  code/contracts/savings/SavingsManager.sol:L141-L143  // 1. Only collect interest if it has been 30 mins  uint256 timeSinceLastCollection = now.sub(previousCollection);  if(timeSinceLastCollection > THIRTY_MINUTES) {  Recommendation  Remove the 30 minutes window such that every deposit also updates the exchange rate between credits and tokens. Note that this issue was reported independently during the bug bounty program and a fix is currently being worked on.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.3 Internal accounting of vault balance may diverge from actual token balance in lending pool   ", "body": "  Resolution  After discussion with the team the risk of this invariant violation was considered negligible as the gas cost increase for querying constantly querying the lending pool would outweigh the size of the accounting error of only 1 base unit.  Description  It is possible that the vault balance for a given bAsset is greater than the corresponding balance in the lending pool. This violates one of the correctness properties stated in the audit brief. Our Harvey fuzzer was able to generate a transaction that mints a small amount (0xf500) of mAsset. Due to the way that the lending pool integration (Compound in this case) updates the vault balance it ends up greater than the available balance in the lending pool.  More specifically, the integration contract assumes that the amount deposited into the pool is equal to the amount received by the mAsset contract for the case where no transaction fees are charged for token transfers:  code/contracts/masset/platform-integrations/CompoundIntegration.sol:L45-L58  quantityDeposited = _amount;  if(_isTokenFeeCharged) {  // If we charge a fee, account for it  uint256 prevBal = _checkBalance(cToken);  require(cToken.mint(_amount) == 0, \"cToken mint failed\");  uint256 newBal = _checkBalance(cToken);  quantityDeposited = _min(quantityDeposited, newBal.sub(prevBal));  } else {  // Else just execute the mint  require(cToken.mint(_amount) == 0, \"cToken mint failed\");  emit Deposit(_bAsset, address(cToken), quantityDeposited);  For illustration, consider the following scenario: assume your current balance in a lending pool is 0. When you deposit some amount X into the lending pool your balance after the deposit may be less than X (even if the underlying token does not charge transfer fees). One reason for this is rounding, but, in theory, a lending pool could also charge fees, etc.  The vault balance is updated in function Masset._mintTo based on the amount returned by the integration.  code/contracts/masset/Masset.sol:L189  basketManager.increaseVaultBalance(bInfo.index, integrator, quantityDeposited);  code/contracts/masset/Masset.sol:L274  uint256 deposited = IPlatformIntegration(_integrator).deposit(_bAsset, quantityTransferred, _erc20TransferFeeCharged);  This violation of the correctness property is temporary since the vault balance is readjusted when interest is collected. However, the time frame of ca. 30 minutes between interest collections (may be longer if no continuous interest is distributed) means that it may be violated for substantial periods of time.  code/contracts/masset/BasketManager.sol:L243-L249  uint256 balance = IPlatformIntegration(integrations[i]).checkBalance(b.addr);  uint256 oldVaultBalance = b.vaultBalance;  // accumulate interest (ratioed bAsset)  if(balance > oldVaultBalance && b.status == BassetStatus.Normal) {  // Update balance  basket.bassets[i].vaultBalance = balance;  The regular updates due to interest collection should ensure that the difference stays relatively small. However, note that the following scenarios is feasible: assuming there is 0 DAI in the basket, a user mints X mUSD by depositing X DAI. While the interest collection hasn t been triggered yet, the user tries to redeem X mUSD for DAI. This may fail since the amount of DAI in the lending pool is smaller than X.  Recommendation  It seems like this issue could be fixed by using the balance increase from the lending pool to update the vault balance (much like for the scenario where transfer fees are charged) instead of using the amount received.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.4 Missing validation in Masset._redeemTo   ", "body": "  Resolution  An explicit check will be added with the next Masset proxy upgrade.  Description  In function _redeemTo the collateralisation ratio is not taken into account unlike in _redeemMasset:  code/contracts/masset/Masset.sol:L558-L561  uint256 colRatio = StableMath.min(props.colRatio, StableMath.getFullScale());  // Ensure payout is related to the collateralised mAsset quantity  uint256 collateralisedMassetQuantity = _mAssetQuantity.mulTruncate(colRatio);  It seems like _redeemTo should not be executed if the collateralisation ratio is below 100%. However, the contracts (that is, Masset and ForgeValidator) themselves don t seem to enforce this explicitly. Instead, the governor needs to ensure that the collateralisation ratio is only set to a value below 100% when the basket is not  healthy  (for instance, if it is considered  failed ). Failing to ensure this may allow an attacker to redeem a disproportionate amount of assets. Note that the functionality for setting the collateralisation ratio is not currently implemented in the audited code.  Recommendation  Consider enforcing the intended use of _redeemTo more explicitly. For instance, it might be possible to introduce additional input validation by requiring that the collateralisation ratio is not below 100%.  ", "labels": ["Consensys", "Medium", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.5 Removing a bAsset might leave some tokens stuck in the vault   ", "body": "  Resolution  The issue was acknowledged and downgraded to  minor  risk as only very small token amounts can be affected. A fix will be triaged for a future update.  Description  In function _removeBasset there is existing validation to make sure only  empty  vaults are removed:  code/contracts/masset/BasketManager.sol:L464  require(bAsset.vaultBalance == 0, \"bAsset vault must be empty\");  However, this is not necessarily sufficient since the lending pool balance may be higher than the vault balance. The reason is that the vault balance is usually slightly out-of-date due to the 30 minutes time span between interest collections. Consider the scenario: (1) a user swaps out an asset 29 minutes after the last interest collection to reduce its vault balance from 100 USD to 0, and (2) the governor subsequently remove the asset. During those 29 minutes the asset was collecting interest (according to the lending pool the balance was higher than 100 USD at the time of the swap) that is now  stuck  in the vault.  Recommendation  Consider adding additional input validation (for instance, by requiring that the lending pool balance to be 0) or triggering a swap directly when removing an asset from the basket.  ", "labels": ["Consensys", "Minor", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.6 Unused parameter in BasketManager._addBasset   ", "body": "  Resolution  While the parameter is not currently used it will be used in future mAssets such as mGOLD.  Description  It seems like the _measurementMultiple parameter is always StableMath.getRatioScale() (1e8). There is also some range validation code that seems unnecessary if the parameter is always 1e8.  code/contracts/masset/BasketManager.sol:L310  require(_measurementMultiple >= 1e6 && _measurementMultiple <= 1e10, \"MM out of range\");  Recommendation  Consider removing the parameter and the input validation to improve the readability of the code.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.7 Unused event BasketStatusChanged   ", "body": "  Resolution  This event will be used in future releases.  Description  It seems like the event BasketManager.BasketStatusChanged event is unused.  Recommendation  Consider removing the event declaration to improve the readability of the code.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.8 Assumptions are made about interest distribution   ", "body": "  Description  There is a mechanism that prevents interest collection if the extrapolated APY exceeds a threshold (MAX_APY).  code/contracts/savings/SavingsManager.sol:L174  require(extrapolatedAPY < MAX_APY, \"Interest protected from inflating past maxAPY\");  The extrapolation seems to assume that the interest is payed out frequently and continuously. It seems like a less frequent payout (for instance, once a month/year) could be rejected since the extrapolation considers the interest since the last time that collectAndDistributeInterest was called (potentially without interest being collected).  Recommendation  Consider revisiting or documenting this assumption. For instance, one could consider extrapolating between the current time and the last time that (non-zero) interest was actually collected.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.9 Assumptions are made about Aave and Compound integrations   ", "body": "  Resolution  it was acknowledged that unexpected changes in behaviour by the integrated lending pools could potentially cause issues; However, it was decided that the risk is minor since the current lending pool behaviour is known and the fact that lending pools might introduce severe changes is accounted for by keeping the integrations separate and upgradable such that governance can react these changes in time.  Description  The code makes several assumptions about the Aave and Compound integrations. A malicious or malfunctioning integration (or lending pool) might violate those assumptions. This might lead to unintended behavior in the system. Below are three such assumptions:  function checkBalance reverts if the token hasn t been added:  code/contracts/masset/BasketManager.sol:L317  IPlatformIntegration(_integration).checkBalance(_bAsset);  function withdraw is trusted to not fail when it shouldn t:  code/contracts/masset/Masset.sol:L611  IPlatformIntegration(_integrators[i]).withdraw(_recipient, bAsset, q, _bAssets[i].isTransferFeeCharged);  the mapping from mAssets to pTokens is fixed:  code/contracts/masset/platform-integrations/InitializableAbstractIntegration.sol:L119  require(bAssetToPToken[_bAsset] == address(0), \"pToken already set\");  The first assumption could be avoided by adding a designated function to check if the token was added.  The second assumption is more difficult to avoid, but should be considered when adding new integrations. The system needs to trust the lending pools to work properly; for instance, if the lending pool would blacklist the integration contract the system may behave in unintended ways.  The third assumption could be avoided, but it comes at a cost.  Recommendation  Consider revisiting or avoiding these assumptions. For any assumptions that are there by design it would be good to document them to facilitate future changes. One should also be careful to avoid coupling between external systems. For instance, if withdrawing from Aave fails this should not prevent withdrawing from Compound.  ", "labels": ["Consensys", "Minor", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.10 Assumptions are made about bAssets   ", "body": "  Description  The code makes several assumptions about the bAssets that can be used. A malicious or malfunctioning asset contract might violate those assumptions. This might lead to unintended behavior in the system. Below there are several such assumptions:  Decimals of a bAsset are constant where the decimals are used to derive the asset s ratio:  code/contracts/masset/BasketManager.sol:L319  uint256 bAsset_decimals = CommonHelpers.getDecimals(_bAsset);  Decimals must be in a range from 4 to 18:  code/contracts/shared/CommonHelpers.sol:L23  require(decimals >= 4 && decimals <= 18, \"Token must have sufficient decimal places\");  The governor is able to foresee when transfer fees are charged (which needs to be called if anything changes); in theory, assets could be much more flexible in when transfer fees are charged (for instance, during certain periods or for certain users)  code/contracts/masset/BasketManager.sol:L425  function setTransferFeesFlag(address _bAsset, bool _flag)  It seems like some of these assumptions could be avoided, but there might be a cost. For instance, one could retrieve the decimals directly instead of  caching  them and one could always enable the setting where transfer fees may be charged.  Recommendation  Consider revisiting or avoiding these assumptions. For any assumptions that are there by design it would be good to document them to facilitate future changes.  ", "labels": ["Consensys", "Minor", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.11 Unused field in ForgePropsMulti struct   ", "body": "  Resolution  The field is currently used but will be used in a future version.  Description  The ForgePropsMulti struct defines the field isValid which always seems to be true:  code/contracts/masset/shared/MassetStructs.sol:L78-L84  /** @dev All details needed to Forge with multiple bAssets */  struct ForgePropsMulti {  bool isValid; // Flag to signify that forge bAssets have passed validity check  Basset[] bAssets;  address[] integrators;  uint8[] indexes;  If it is indeed always true, one could remove the following line:  code/contracts/masset/Masset.sol:L518  if(!props.isValid) return 0;  Recommendation  If the field is indeed always true please consider removing it to simplify the code.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.12 BassetStatus enum defines multiple unused states   ", "body": "  Resolution  The states will potentially be used in future releases.  Description  The BassetStatus enum defines several values that do not seem to be assigned in the code:  Default (different from  Normal ?)  Blacklisted  Liquidating  Liquidated  Failed  code/contracts/masset/shared/MassetStructs.sol:L59-L69  /** @dev Status of the Basset - has it broken its peg? */  enum BassetStatus {  Default,  Normal,  BrokenBelowPeg,  BrokenAbovePeg,  Blacklisted,  Liquidating,  Liquidated,  Failed  Since some of these are used in the code there might be some dead code that can be removed as a result. For example:  code/contracts/masset/forge-validator/ForgeValidator.sol:L46-L47  _bAsset.status == BassetStatus.Liquidating ||  _bAsset.status == BassetStatus.Blacklisted  Recommendation  If those values are indeed never used please consider removing them to simplify the code.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.13 Potential gas savings by terminating early   ", "body": "  Resolution  acknowledged that gas savings are possible, might be moved changed in a future version.  Description  If a function invocation is bound to revert, one should try to revert as soon as possible to save gas. In ForgeValidator.validateRedemption it is possible to terminate more early:  code/contracts/masset/forge-validator/ForgeValidator.sol:L264  if(atLeastOneBecameOverweight) return (false, \"bAssets must remain below max weight\", false);  Recommendation  Consider moving the require-statement a few lines up (for instance, after assigning to atLeastOneBecameOverweight).  ", "labels": ["Consensys", "Minor", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.14 Discrepancy between code and comments    Addressed", "body": "  Resolution  The comments have been updated.  Description  There is a discrepancy between the code at:  code/contracts/masset/BasketManager.sol:L417  require(weightSum >= 1e18 && weightSum <= 4e18, \"Basket weight must be >= 100 && <= 400%\");  And the comment at:  code/contracts/masset/BasketManager.sol:L409  Recommendation  @dev Throws if the total Basket weight does not sum to 100  Recommendation  Update the code or the comment to be consistent.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "6.15 Outdated Solidity version   ", "body": "  Resolution                           the issue was deemed acceptable because an update to solc 0.5.17   would not fix any relevant security bugs.  Description  The codebase is using an outdated version of the Solidity compiler.  Recommendation  Please consider using an up-to-date version (ideally 0.6.12 or at least 0.5.17).  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/07/mstable-1.1/"}, {"title": "3.1 TribalChief - A wrong user.rewardDebt  value is calculated during the withdrawFromDeposit function call ", "body": "  Description  When withdrawing a single deposit, the reward debt is updated:  contracts/staking/TribalChief.sol:L468-L474  uint128 virtualAmountDelta = uint128( ( amount * poolDeposit.multiplier ) / SCALE_FACTOR );  // Effects  poolDeposit.amount -= amount;  user.rewardDebt = user.rewardDebt - toSigned128(user.virtualAmount * pool.accTribePerShare) / toSigned128(ACC_TRIBE_PRECISION);  user.virtualAmount -= virtualAmountDelta;  pool.virtualTotalSupply -= virtualAmountDelta;  Instead of the user.virtualAmount in reward debt calculation, the virtualAmountDelta  should be used. Because of that bug, the reward debt is much lower than it would be, which means that the reward itself will be much larger during the harvest. By making multiple deposit-withdraw actions, any user can steal all the Tribe tokens from the contract.  Recommendation  Use the virtualAmountDelta instead of the user.virtualAmount.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "3.2 TribalChief - Setting the totalAllocPoint to zero shouldn t be allowed ", "body": "  Description  TribalChief.updatePool will revert in the case totalAllocPoint = 0, which will essentially cause users  funds and rewards to be locked.  Recommendation  TribalChief.add and TribalChief.set should assert that totalAllocPoint > 0. A similar validation check should be added to TribalChief.updatePool as well.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "3.3 TribalChief - Unlocking users  funds in a pool where a multiplier has been increased is missing ", "body": "  Description  When a user deposits funds to a pool, the current multiplier in use for this pool is being stored locally for this deposit. The value that is used later in a withdrawal operation is the local one, and not the one that is changing when a governor calls governorAddPoolMultiplier. It means that a decrease in the multiplier value for a given pool does not affect users that already deposited, but an increase does. Users that had already deposited should have the right to withdraw their funds when the multiplier for their pool increases by the governor.  Examples  code/contracts/staking/TribalChief.sol:L143-L158  function governorAddPoolMultiplier(  uint256 _pid,  uint64 lockLength,  uint64 newRewardsMultiplier  ) external onlyGovernor {  PoolInfo storage pool = poolInfo[_pid];  uint256 currentMultiplier = rewardMultipliers[_pid][lockLength];  // if the new multplier is less than the current multiplier,  // then, you need to unlock the pool to allow users to withdraw  if (newRewardsMultiplier < currentMultiplier) {  pool.unlocked = true;  rewardMultipliers[_pid][lockLength] = newRewardsMultiplier;  emit LogPoolMultiplier(_pid, lockLength, newRewardsMultiplier);  Recommendation  Replace the < operator with > in TribalChief line 152.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "3.4 TribalChief - Unsafe down-castings ", "body": "  Description  TribalChief consists of multiple unsafe down-casting operations. While the usage of types that can be packed into a single storage slot is more gas efficient, it may introduce hidden risks in some cases that can lead to loss of funds.  Examples  Various instances in TribalChief, including (but not necessarily only) :  code/contracts/staking/TribalChief.sol:L429  user.rewardDebt = int128(user.virtualAmount * pool.accTribePerShare) / toSigned128(ACC_TRIBE_PRECISION);  code/contracts/staking/TribalChief.sol:L326  pool.accTribePerShare = uint128(pool.accTribePerShare + ((tribeReward * ACC_TRIBE_PRECISION) / virtualSupply));  code/contracts/staking/TribalChief.sol:L358  userPoolData.rewardDebt += int128(virtualAmountDelta * pool.accTribePerShare) / toSigned128(ACC_TRIBE_PRECISION);  Recommendation  Given the time constraints of this audit engagement, we could not verify the implications and provide mitigation actions for each of the unsafe down-castings operations. However, we do recommend to either use numeric types that use 256 bits, or to add proper validation checks and handle these scenarios to avoid silent over/under-flow errors. Keep in mind that reverting these scenarios can sometimes lead to a denial of service, which might be harmful in some cases.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "3.5 EthCompoundPCVDeposit - should provide means to recover ETH ", "body": "  Description  The CToken to be used is configured on EthCompoundPCVDeposit deployment. It is not checked, whether the provided CToken address is actually a valid CToken.  If the configured CToken ceases to work correctly (e.g.  CToken.mint|redeem* disabled or the configured CToken address is invalid), ETH held by the contract may be locked up.  Recommendation  In CompoundPCVDepositBase consider verifying, that the CToken constructor argument is actually a valid CToken by checking require(ctoken.isCToken(), \"not a valid CToken\").  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "3.6 TribalChief - Governor decrease of pool s allocation point should unlock depositors  funds ", "body": "  Description  When the TribalChief governor decreases the ratio between the allocation point (PoolInfo.allocPoint) and the total allocation point (totalAllocPoint) for a specific pool (either be directly decreasing PoolInfo.allocPoint of a given pool, or by increasing this value for other pools), the total reward for this pool is decreased as well. Depositors should be able to withdraw their funds immediately after this kind of change.  Examples  code/contracts/staking/TribalChief.sol:L252-L261  function set(uint256 _pid, uint128 _allocPoint, IRewarder _rewarder, bool overwrite) public onlyGovernor {  totalAllocPoint = (totalAllocPoint - poolInfo[_pid].allocPoint) + _allocPoint;  poolInfo[_pid].allocPoint = _allocPoint.toUint64();  if (overwrite) {  rewarder[_pid] = _rewarder;  emit LogSetPool(_pid, _allocPoint, overwrite ? _rewarder : rewarder[_pid], overwrite);  Recommendation  Make sure that depositors  funds are unlocked for pools that affected negatively by calling TribalChief.set.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "3.7 TribalChief - new block reward retrospectively takes effect on pools that have not been updated recently ", "body": "  Description  When the governor updates the block reward tribalChiefTribePerBlock the new reward is applied for the outstanding duration of blocks in updatePool. This means, if a pool hasn t updated in a while (unlikely) the new block reward is retrospectively applied to the pending duration instead of starting from when the block reward changed.  Examples  rewards calculation  code/contracts/staking/TribalChief.sol:L323-L327  if (virtualSupply > 0) {  uint256 blocks = block.number - pool.lastRewardBlock;  uint256 tribeReward = (blocks * tribePerBlock() * pool.allocPoint) / totalAllocPoint;  pool.accTribePerShare = uint128(pool.accTribePerShare + ((tribeReward * ACC_TRIBE_PRECISION) / virtualSupply));  updating the block reward  code/contracts/staking/TribalChief.sol:L111-L116  /// @notice Allows governor to change the amount of tribe per block  /// @param newBlockReward The new amount of tribe per block to distribute  function updateBlockReward(uint256 newBlockReward) external onlyGovernor {  tribalChiefTribePerBlock = newBlockReward;  emit NewTribePerBlock(newBlockReward);  Recommendation  It is recommended to update pools before changing the block reward. Document and make users aware that the new reward is applied to the outstanding duration when calling updatePool.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "3.8 TribalChief - duplicate import SafeERC20 ", "body": "  Description  Duplicate import for SafeERC20.  Examples  code/contracts/staking/TribalChief.sol:L7-L8  import \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\";  import \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\";  Recommendation  Remove duplicate import line.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "3.9 TribalChief - resetRewards should emit an event ", "body": "  Description  The method resetRewards silently resets a pools tribe allocation.  Examples  code/contracts/staking/TribalChief.sol:L263-L275  /// @notice Reset the given pool's TRIBE allocation to 0 and unlock the pool. Can only be called by the governor or guardian.  /// @param _pid The index of the pool. See `poolInfo`.  function resetRewards(uint256 _pid) public onlyGuardianOrGovernor {  // set the pool's allocation points to zero  totalAllocPoint = (totalAllocPoint - poolInfo[_pid].allocPoint);  poolInfo[_pid].allocPoint = 0;  // unlock all staked tokens in the pool  poolInfo[_pid].unlocked = true;  // erase any IRewarder mapping  rewarder[_pid] = IRewarder(address(0));  Recommendation  For transparency and to create an easily accessible audit trail of events consider emitting an event when resetting a pools allocation.  4 Recommendations  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "4.1 EthCompoundPCVDeposit - stick to upstream interface contract names", "body": "  Recommendation  Stick to the original upstream interface names to make clear with which external system the contract interacts with.  Rename CEth to CEther. See original upstream interface name.  code/contracts/pcv/compound/EthCompoundPCVDeposit.sol:L6-L8  interface CEth {  function mint() external payable;  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "4.2 CompoundPCVDepositBase - verify provided CToken address is actually a CToken", "body": "  Recommendation  The  ctoken address provided when deploying a new *CompoundPCVDeposit is never validated. Consider adding the following check: require(_cToken.isCToken, \"not a valid CToken\").  code/contracts/pcv/compound/CompoundPCVDepositBase.sol:L25-L30  constructor(  address _core,  address _cToken  ) CoreRef(_core) {  cToken = CToken(_cToken);  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "4.3 CompoundPCV - documentation & testing", "body": "  Recommendation  Currently, the PCV flavor is only unit-tested using a mocked CToken. Consider providing integration tests that actually integrate and operate it in a compound test environment.  Provide a specification. & documentation describing the roles and functionality of the contract. Who deployes the PCVDeposit contract? Who Deploys the CToken and therefore may be in control of certain adminOnly functions of the CToken? What are the requirements for a CToken to be usable with CompoundPCVDeposit (listed/unlisted, \u2026)? Who has the potential power to borrow assets on behalf of the collateral provided?  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "4.4 TribalChief - immutable vs constant", "body": "  Recommendation  Constant state variables that are not initialized with the constructor can be constant instead of immutable.  code/contracts/staking/TribalChief.sol:L88-L90  uint256 private immutable ACC_TRIBE_PRECISION = 1e12;  /// exponent for rewards multiplier  uint256 public immutable SCALE_FACTOR = 1e18;  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "4.5 TribalChief - governorAddPoolMultiplier should emit a PoolLocked event", "body": "  Description  Users should be notified if the pool gets unlocked during a call to governorAddPoolMultiplier. Consider emitting a PoolLocked(false) event.  code/contracts/staking/TribalChief.sol:L143-L158  function governorAddPoolMultiplier(  uint256 _pid,  uint64 lockLength,  uint64 newRewardsMultiplier  ) external onlyGovernor {  PoolInfo storage pool = poolInfo[_pid];  uint256 currentMultiplier = rewardMultipliers[_pid][lockLength];  // if the new multplier is less than the current multiplier,  // then, you need to unlock the pool to allow users to withdraw  if (newRewardsMultiplier < currentMultiplier) {  pool.unlocked = true;  rewardMultipliers[_pid][lockLength] = newRewardsMultiplier;  emit LogPoolMultiplier(_pid, lockLength, newRewardsMultiplier);  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "4.6 TribalChief - updatePool invocation inside _harvest should be moved to harvest instead", "body": "  Description  When TribalChief.withdrawAllAndHarvest is executed, there s a redundant invocation of TribalChief.updatePool that caused by TribalChief._harvest, that can be moved to TribalChief.harvest instead.  Examples  code/contracts/staking/TribalChief.sol:L485-L515  function _harvest(uint256 pid, address to) private {  updatePool(pid);  PoolInfo storage pool = poolInfo[pid];  UserInfo storage user = userInfo[pid][msg.sender];  // assumption here is that we will never go over 2^128 -1  int256 accumulatedTribe = int256( uint256(user.virtualAmount) * uint256(pool.accTribePerShare) ) / int256(ACC_TRIBE_PRECISION);  // this should never happen  require(accumulatedTribe >= 0 || (accumulatedTribe - user.rewardDebt) < 0, \"negative accumulated tribe\");  uint256 pendingTribe = uint256(accumulatedTribe - user.rewardDebt);  // if pending tribe is ever negative, revert as this can cause an underflow when we turn this number to a uint  require(pendingTribe.toInt256() >= 0, \"pendingTribe is less than 0\");  // Effects  user.rewardDebt = int128(accumulatedTribe);  // Interactions  if (pendingTribe != 0) {  TRIBE.safeTransfer(to, pendingTribe);  IRewarder _rewarder = rewarder[pid];  if (address(_rewarder) != address(0)) {  _rewarder.onSushiReward( pid, msg.sender, to, pendingTribe, user.virtualAmount);  emit Harvest(msg.sender, pid, pendingTribe);  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/07/fei-tribechief/"}, {"title": "5.1 Merkle.checkMembership allows existence proofs for the same leaf in multiple locations in the tree    Addressed", "body": "  Resolution                           This was addressed in   omisego/plasma-contracts#533 by including a check in  omisego/plasma-contracts#547 ensured the passed-in index satisfied the recommended criterion.  Description  checkMembership is used by several contracts to prove that transactions exist in the child chain. The function uses a leaf, an index, and a proof to construct a hypothetical root hash. This constructed hash is compared to the passed in rootHash parameter. If the two are equivalent, the proof is considered valid.  The proof is performed iteratively, and uses a pseudo-index (j) to determine whether the next proof element represents a  left branch  or  right branch :  code/plasma_framework/contracts/src/utils/Merkle.sol:L28-L41  uint256 j = index;  // Note: We're skipping the first 32 bytes of `proof`, which holds the size of the dynamically sized `bytes`  for (uint256 i = 32; i <= proof.length; i += 32) {  // solhint-disable-next-line no-inline-assembly  assembly {  proofElement := mload(add(proof, i))  if (j % 2 == 0) {  computedHash = keccak256(abi.encodePacked(NODE_SALT, computedHash, proofElement));  } else {  computedHash = keccak256(abi.encodePacked(NODE_SALT, proofElement, computedHash));  j = j / 2;  If j is even, the computed hash is placed before the next proof element. If j is odd, the computed hash is placed after the next proof element. After each iteration, j is decremented by j = j / 2.  Because checkMembership makes no requirements on the height of the tree or the size of the proof relative to the provided index, it is possible to pass in invalid values for index that prove a leaf s existence in multiple locations in the tree.  Examples  By modifying existing tests, we showed that for a tree with 3 leaves, leaf 2 can be proven to exist at indices 2, 6, and 10 using the same proof each time. The modified test can be found here: https://gist.github.com/wadeAlexC/01b60099282a026f8dc1ac85d83489fd#file-merkle-test-js-L40-L67  Conclusion  Exit processing is meant to bypass exits processed more than once. This is implemented using an  output id  system, where each exited output should correspond to a unique id that gets flagged in the ExitGameController contract as it s exited. Before an exit is processed, its output id is calculated and checked against ExitGameController. If the output has already been exited, the exit being processed is deleted and skipped. Crucially, output id is calculated differently for standard transactions and deposit transactions: deposit output ids factor in the transaction index.  By using the behavior described in this issue in conjunction with methods discussed in issue 5.8 and issue 5.10, we showed that deposit transactions can be exited twice using indices 0 and 2**16. Because of the distinct output id calculation, these exits have different output ids and can be processed twice, allowing users to exit double their deposited amount.  A modified StandardExit.load.test.js shows that exits are successfully enqueued with a transaction index of 65536: https://gist.github.com/wadeAlexC/4ad459b7510e512bc9556e7c919e0965#file-standardexit-load-test-js-L55  Recommendation  Use the length of the proof to determine the maximum allowed index. The passed-in index should satisfy the following criterion: index < 2**(proof.length/32). Additionally, ensure range checks on transaction position decoding are sufficiently restrictive (see https://github.com/ConsenSys/omisego-morevp-audit-2019-10/issues/20).  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/546  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.2 Improper initialization of spending condition abstraction allows  v2 transactions  to exit using PaymentExitGame    Addressed", "body": "  Resolution                           This was addressed in   omisego/plasma-contracts#478 by requiring that  Description  PaymentOutputToPaymentTxCondition is an abstraction around the transaction signature check needed for many components of the exit games. Its only function, verify, returns true if one transaction (inputTxBytes) is spent by another transaction (spendingTxBytes):  code/plasma_framework/contracts/src/exits/payment/spendingConditions/PaymentOutputToPaymentTxCondition.sol:L40-L69  function verify(  bytes calldata inputTxBytes,  uint16 outputIndex,  uint256 inputTxPos,  bytes calldata spendingTxBytes,  uint16 inputIndex,  bytes calldata signature,  bytes calldata /*optionalArgs*/  external  view  returns (bool)  PaymentTransactionModel.Transaction memory inputTx = PaymentTransactionModel.decode(inputTxBytes);  require(inputTx.txType == supportInputTxType, \"Input tx is an unsupported payment tx type\");  PaymentTransactionModel.Transaction memory spendingTx = PaymentTransactionModel.decode(spendingTxBytes);  require(spendingTx.txType == supportSpendingTxType, \"The spending tx is an unsupported payment tx type\");  UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.build(TxPosLib.TxPos(inputTxPos), outputIndex);  require(  spendingTx.inputs[inputIndex] == bytes32(utxoPos.value),  \"Spending tx points to the incorrect output UTXO position\"  );  address payable owner = inputTx.outputs[outputIndex].owner();  require(owner == ECDSA.recover(eip712.hashTx(spendingTx), signature), \"Tx in not signed correctly\");  return true;  Verification process  The verification process is relatively straightforward. The contract performs some basic input validation, checking that the input transaction s txType matches supportInputTxType, and that the spending transaction s txType matches supportSpendingTxType. These values are set during construction.  Next, verify checks that the spending transaction contains an input that matches the position of one of the input transaction s outputs.  Finally, verify performs an EIP-712 hash on the spending transaction, and ensures it is signed by the owner of the output in question.  Implications of the abstraction  code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L58-L78  /**  @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.  @dev Emits ExitGameRegistered event to notify clients  @param _txType The tx type where the exit game wants to register  @param _contract Address of the exit game contract  @param _protocol The transaction protocol, either 1 for MVP or 2 for MoreVP  /  function registerExitGame(uint256 _txType, address _contract, uint8 _protocol) public onlyFrom(getMaintainer()) {  require(_txType != 0, \"Should not register with tx type 0\");  require(_contract != address(0), \"Should not register with an empty exit game address\");  require(_exitGames[_txType] == address(0), \"The tx type is already registered\");  require(_exitGameToTxType[_contract] == 0, \"The exit game contract is already registered\");  require(Protocol.isValidProtocol(_protocol), \"Invalid protocol value\");  _exitGames[_txType] = _contract;  _exitGameToTxType[_contract] = _txType;  _protocols[_txType] = _protocol;  _exitGameQuarantine.quarantine(_contract);  emit ExitGameRegistered(_txType, _contract, _protocol);  Migration and initialization  The migration script seems to corroborate this interpretation:  code/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L109-L124  // handle spending condition  await deployer.deploy(  PaymentOutputToPaymentTxCondition,  plasmaFramework.address,  PAYMENT_OUTPUT_TYPE,  PAYMENT_TX_TYPE,  );  const paymentToPaymentCondition = await PaymentOutputToPaymentTxCondition.deployed();  await deployer.deploy(  PaymentOutputToPaymentTxCondition,  plasmaFramework.address,  PAYMENT_OUTPUT_TYPE,  PAYMENT_V2_TX_TYPE,  );  const paymentToPaymentV2Condition = await PaymentOutputToPaymentTxCondition.deployed();  The migration script then registers both of these contracts in SpendingConditionRegistry, and then calls renounceOwnership, freezing the spending conditions registered permanently:  code/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L126-L135  console.log(`Registering paymentToPaymentCondition (${paymentToPaymentCondition.address}) to spendingConditionRegistry`);  await spendingConditionRegistry.registerSpendingCondition(  PAYMENT_OUTPUT_TYPE, PAYMENT_TX_TYPE, paymentToPaymentCondition.address,  );  console.log(`Registering paymentToPaymentV2Condition (${paymentToPaymentV2Condition.address}) to spendingConditionRegistry`);  await spendingConditionRegistry.registerSpendingCondition(  PAYMENT_OUTPUT_TYPE, PAYMENT_V2_TX_TYPE, paymentToPaymentV2Condition.address,  );  await spendingConditionRegistry.renounceOwnership();  Finally, the migration script registers a single exit game contract in PlasmaFramework:  code/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L137-L143  // register the exit game to framework  await plasmaFramework.registerExitGame(  PAYMENT_TX_TYPE,  paymentExitGame.address,  config.frameworks.protocols.moreVp,  { from: maintainerAddress },  );  Note that the associated _txType is permanently associated with the deployed exit game contract:  code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L58-L78  /**  @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.  @dev Emits ExitGameRegistered event to notify clients  @param _txType The tx type where the exit game wants to register  @param _contract Address of the exit game contract  @param _protocol The transaction protocol, either 1 for MVP or 2 for MoreVP  /  function registerExitGame(uint256 _txType, address _contract, uint8 _protocol) public onlyFrom(getMaintainer()) {  require(_txType != 0, \"Should not register with tx type 0\");  require(_contract != address(0), \"Should not register with an empty exit game address\");  require(_exitGames[_txType] == address(0), \"The tx type is already registered\");  require(_exitGameToTxType[_contract] == 0, \"The exit game contract is already registered\");  require(Protocol.isValidProtocol(_protocol), \"Invalid protocol value\");  _exitGames[_txType] = _contract;  _exitGameToTxType[_contract] = _txType;  _protocols[_txType] = _protocol;  _exitGameQuarantine.quarantine(_contract);  emit ExitGameRegistered(_txType, _contract, _protocol);  Conclusion  Recommendation  Remove PaymentOutputToPaymentTxCondition and SpendingConditionRegistry  Implement checks for specific spending conditions directly in exit game controllers. Emphasize clarity of function: ensure it is clear when called from the top level that a signature verification check and spending condition check are being performed.  If the inferred relationship between txType and PaymentExitGame is correct, ensure that each PaymentExitGame router checks for its supported txType. Alternatively, the check could be made in PaymentExitGame itself.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/472  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.3 RLPReader - Leading zeroes allow multiple valid encodings and exit / output ids for the same transaction    Addressed", "body": "  Resolution                           This was addressed in   omisego/plasma-contracts#507 with the addition of checks to ensure primitive decoding functions in  omisego/plasma-contracts#476 rejects leading zeroes in  Description  The current implementation of RLP decoding can take 2 different txBytes and decode them to the same structure. Specifically, the RLPReader.toUint method can decode 2 different types of bytes to the same number. For example:  0x821234 is decoded to uint(0x1234)  0x83001234 is decoded to uint(0x1234)  0xc101 can decode to uint(1), even though the tag specifies a short list  0x01 can decode to uint(1), even though the tag specifies a single byte  As explanation for this encoding:  0x821234 is broken down into 2 parts:  0x82 - represents 0x80 (the string tag) + 0x02 bytes encoded  0x1234 - are the encoded bytes  The same for 0x83001234:  0x83 - represents 0x80 (the string tag) + 0x03 bytes encoded  0x001234 - are the encoded bytes  The current implementation casts the encoded bytes into a uint256, so these different encodings are interpreted by the contracts as the same number:  uint(0x1234) = uint(0x001234)  code/plasma_framework/contracts/src/utils/RLPReader.sol:L112  result := mload(memPtr)  Having different valid encodings for the same data is a problem because the encodings are used to create hashes that are used as unique ids. This means that multiple ids can be created for the same data. The data should only have one possible id.  The encoding is used to create ids in these parts of the code:  Outputid.sol  code/plasma_framework/contracts/src/exits/utils/OutputId.sol:L18  return keccak256(abi.encodePacked(_txBytes, _outputIndex, _utxoPosValue));  code/plasma_framework/contracts/src/exits/utils/OutputId.sol:L32  return keccak256(abi.encodePacked(_txBytes, _outputIndex));  ExitId.sol  code/plasma_framework/contracts/src/exits/utils/ExitId.sol:L41  bytes32 hashData = keccak256(abi.encodePacked(_txBytes, _utxoPos.value));  code/plasma_framework/contracts/src/exits/utils/ExitId.sol:L54  return uint160((uint256(keccak256(_txBytes)) >> 105).setBit(151));  TxFinalizationVerifier.sol  code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L55  bytes32 leafData = keccak256(data.txBytes);  Other methods that are affected because they rely on the return values of these methods:  ExitId.sol  getStandardExitId getInFlightExitId  OutputId.sol  computeDepositOutputId computeNormalOutputId  PaymentChallengeIFENotCanonical.sol  verifyAndDeterminePositionOfTransactionIncludedInBlock verifyCompetingTxFinalized  PaymentChallengeStandardExit.sol  verifyChallengeTxProtocolFinalized  PaymentStartInFlightExit.sol  verifyInputTransactionIsStandardFinalized  PaymentExitGame.sol  getStandardExitId getInFlightExitId  PaymentOutputToPaymentTxCondition.sol  verify  Recommendation  Enforce strict-length decoding for txBytes, and specify that uint is decoded from a 32-byte short string.  Enforcing a 32-byte length for uint means that 0x1234 should always be encoded as:  0xa00000000000000000000000000000000000000000000000000000000000001234  0xa0 represents the tag + the length: 0x80 + 32  0000000000000000000000000000000000000000000000000000000000001234 is the number 32 bytes long with leading zeroes  Unfortunately, using leading zeroes is against the RLP spec:  https://github.com/ethereum/wiki/wiki/RLP  positive RLP integers must be represented in big endian binary form with no leading zeroes  This means that libraries interacting with OMG contracts which are going to correctly and fully implement the spec will generate  incorrect  encodings for uints; encodings that are not going to be recognized by the OMG contracts.  Fully correct spec encoding: 0x821234. Proposed encoding in this solution: 0xa00000000000000000000000000000000000000000000000000000000000001234.  Similarly enforce restrictions where they can be added; this is possible because of the strict structure format that needs to be encoded.  Some other potential solutions are included below. Note that these solutions are not recommended for reasons included below:  Normalize the encoding that gets passed to methods that hash the transaction for use as an id:  This can be implemented in the methods that call keccak256 on txBytes and should decode and re-encode the passed txBytes in order to normalize the passed encoding.  a txBytes is passed  the txBytes are decoded into structure: tmpDecodedStruct = decode(txBytes)  the tmpDecodedStruct is re-encoded in order to normalize it: normalizedTxBytes = encode(txBytes)  This method is not recommended because it needs a Solidity encoder to be implemented and a lot of gas will be used to decode and re-encode the initial txBytes.  Correctly and fully implement RLP decoding  This is another solution that adds a lot of code and is prone to errors.  The solution would be to enforce all of the restrictions when decoding and not accept any encoding that doesn t fully follow the spec. This for example means that is should not accept uints with leading zeroes.  This is a problem because it needs a lot of code that is not easy to write in Solidity (or EVM).  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.4 Recommendation: Remove TxFinalizationModel and TxFinalizationVerifier. Implement stronger checks in Merkle ", "body": "  Resolution                           This was partially addressed in   omisego/plasma-contracts#503, with the removal of several unneeded branches of logic in  omisego/plasma-contracts#533 added a non-zero proof length check in  Description  TxFinalizationVerifier is an abstraction around the block inclusion check needed for many of the features of plasma exit games. It uses a struct defined in TxFinalizationModel as inputs to its two functions: isStandardFinalized and isProtocolFinalized.  isStandardFinalized returns the result of an inclusion proof. Although there are several branches, only the first is used:  code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L19-L32  /**  @notice Checks whether a transaction is \"standard finalized\"  @dev MVP: requires that both inclusion proof and confirm signature is checked  @dev MoreVp: checks inclusion proof only  /  function isStandardFinalized(Model.Data memory data) public view returns (bool) {  if (data.protocol == Protocol.MORE_VP()) {  return checkInclusionProof(data);  } else if (data.protocol == Protocol.MVP()) {  revert(\"MVP is not yet supported\");  } else {  revert(\"Invalid protocol value\");  isProtocolFinalized is unused:  code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L34-L47  /**  @notice Checks whether a transaction is \"protocol finalized\"  @dev MVP: must be standard finalized  @dev MoreVp: allows in-flight tx, so only checks for the existence of the transaction  /  function isProtocolFinalized(Model.Data memory data) public view returns (bool) {  if (data.protocol == Protocol.MORE_VP()) {  return data.txBytes.length > 0;  } else if (data.protocol == Protocol.MVP()) {  revert(\"MVP is not yet supported\");  } else {  revert(\"Invalid protocol value\");  Finally, the abstraction may have ramifications on the safety of Merkle.sol. As it stands now, Merkle.checkMembership should never be called directly by the exit game controllers, as it lacks an important check made in TxFinalizationVerifier.checkInclusionProof:  code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L49-L59  function checkInclusionProof(Model.Data memory data) private view returns (bool) {  if (data.inclusionProof.length == 0) {  return false;  (bytes32 root,) = data.framework.blocks(data.txPos.blockNum());  bytes32 leafData = keccak256(data.txBytes);  return Merkle.checkMembership(  leafData, data.txPos.txIndex(), root, data.inclusionProof  );  By introducing the abstraction of TxFinalizationVerifier, the input validation performed by Merkle is split across multiple files, and the reasonable-seeming decision of calling Merkle.checkMembership directly becomes unsafe. In fact, this occurs in one location in the contracts:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L187-L204  function verifyAndDeterminePositionOfTransactionIncludedInBlock(  bytes memory txbytes,  UtxoPosLib.UtxoPos memory utxoPos,  bytes32 root,  bytes memory inclusionProof  private  pure  returns(uint256)  bytes32 leaf = keccak256(txbytes);  require(  Merkle.checkMembership(leaf, utxoPos.txIndex(), root, inclusionProof),  \"Transaction is not included in block of Plasma chain\"  );  return utxoPos.value;  Recommendation  Remove TxFinalizationVerifier and TxFinalizationModel  Implement a proof length check in Merkle.sol  Call Merkle.checkMembership directly from exit controller contracts:  PaymentChallengeIFEOutputSpent.verifyInFlightTransactionStandardFinalized:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L91  require(controller.txFinalizationVerifier.isStandardFinalized(finalizationData), \"In-flight transaction not finalized\");  PaymentChallengeIFENotCanonical.verifyCompetingTxFinalized:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L244  require(self.txFinalizationVerifier.isStandardFinalized(finalizationData), \"Failed to verify the position of competing tx\");  PaymentStartInFlightExit.verifyInputTransactionIsStandardFinalized:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L307-L308  require(exitData.controller.txFinalizationVerifier.isStandardFinalized(finalizationData),  \"Input transaction is not standard finalized\");  If none of the above recommendations are implemented, ensure that PaymentChallengeIFENotCanonical uses the abstraction TxFinalizationVerifier so that a length check is performed on the inclusion proof.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/471  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.5 Merkle - The implementation does not enforce inclusion of leaf nodes.    Addressed", "body": "  Resolution                           This was addressed in   omisego/plasma-contracts#452 with the addition of leaf and node salts to the  Description  A observation with the current Merkle tree implementation is that it may be possible to validate nodes other than leaves. This is done by providing checkMembership with a reference to a hash within the tree, rather than a leaf.  code/plasma_framework/contracts/src/utils/Merkle.sol:L9-L42  /**  @notice Checks that a leaf hash is contained in a root hash  @param leaf Leaf hash to verify  @param index Position of the leaf hash in the Merkle tree  @param rootHash Root of the Merkle tree  @param proof A Merkle proof demonstrating membership of the leaf hash  @return True, if the leaf hash is in the Merkle tree; otherwise, False  /  function checkMembership(bytes32 leaf, uint256 index, bytes32 rootHash, bytes memory proof)  internal  pure  returns (bool)  require(proof.length % 32 == 0, \"Length of Merkle proof must be a multiple of 32\");  bytes32 proofElement;  bytes32 computedHash = leaf;  uint256 j = index;  // Note: We're skipping the first 32 bytes of `proof`, which holds the size of the dynamically sized `bytes`  for (uint256 i = 32; i <= proof.length; i += 32) {  // solhint-disable-next-line no-inline-assembly  assembly {  proofElement := mload(add(proof, i))  if (j % 2 == 0) {  computedHash = keccak256(abi.encodePacked(computedHash, proofElement));  } else {  computedHash = keccak256(abi.encodePacked(proofElement, computedHash));  j = j / 2;  return computedHash == rootHash;  The current implementation will validate the provided  leaf  and return true. This is a known problem of Merkle trees https://en.wikipedia.org/wiki/Merkle_tree#Second_preimage_attack.  Examples  Provide a hash from within the Merkle tree as the leaf argument. The index has to match the index of that node in regards to its current level in the tree. The rootHash has to be the correct Merkle tree rootHash. The proof has to skip the necessary number of levels because the nodes  underneath  the provided  leaf  will not be processed.  Recommendation  A remediation needs a fixed Merkle tree size as well as the addition of a byte prepended to each node in the tree. Another way would be to create a structure for the Merkle node and mark it as leaf or no leaf.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/425  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.6 Maintainer can bypass exit game quarantine by registering not-yet-deployed contracts    Addressed", "body": "  Resolution                           This was addressed in   commit 7669076be1dff47473ee877dcebef5989d7617ac by adding a check that registered contracts had nonzero  Description  The plasma framework uses an ExitGameRegistry to allow the maintainer to add new exit games after deployment. An exit game is any arbitrary contract. In order to prevent the maintainer from adding malicious exit games that steal user funds, the framework uses a  quarantine  system whereby newly-registered exit games have restricted permissions until their quarantine period has expired. The quarantine period is by default 3 * minExitPeriod, and is intended to facilitate auditing of the new exit game s functionality by the plasma users.  However, by registering an exit game at a contract which has not yet been deployed, the maintainer can prevent plasma users from auditing the game until the quarantine period has expired. After the quarantine period has expired, the maintainer can deploy the malicious exit game and immediately steal funds.  Explanation  Exit games are registered in the following function, callable only by the plasma contract maintainer:  code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L58-L78  /**  @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.  @dev Emits ExitGameRegistered event to notify clients  @param _txType The tx type where the exit game wants to register  @param _contract Address of the exit game contract  @param _protocol The transaction protocol, either 1 for MVP or 2 for MoreVP  /  function registerExitGame(uint256 _txType, address _contract, uint8 _protocol) public onlyFrom(getMaintainer()) {  require(_txType != 0, \"Should not register with tx type 0\");  require(_contract != address(0), \"Should not register with an empty exit game address\");  require(_exitGames[_txType] == address(0), \"The tx type is already registered\");  require(_exitGameToTxType[_contract] == 0, \"The exit game contract is already registered\");  require(Protocol.isValidProtocol(_protocol), \"Invalid protocol value\");  _exitGames[_txType] = _contract;  _exitGameToTxType[_contract] = _txType;  _protocols[_txType] = _protocol;  _exitGameQuarantine.quarantine(_contract);  emit ExitGameRegistered(_txType, _contract, _protocol);  Notably, the function does not check the extcodesize of the submitted contract. As such, the maintainer can submit the address of a contract which does not yet exist and is not auditable.  After at least 3 * minExitPeriod seconds pass, the submitted contract now has full permissions as a registered exit game and can pass all checks using the onlyFromNonQuarantinedExitGame modifier:  code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L33-L40  /**  @notice A modifier to verify that the call is from a non-quarantined exit game  /  modifier onlyFromNonQuarantinedExitGame() {  require(_exitGameToTxType[msg.sender] != 0, \"The call is not from a registered exit game contract\");  require(!_exitGameQuarantine.isQuarantined(msg.sender), \"ExitGame is quarantined\");  _;  Additionally, the submitted contract passes checks made by external contracts using the isExitGameSafeToUse function:  code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L48-L56  /**  @notice Checks whether the contract is safe to use and is not under quarantine  @dev Exposes information about exit games quarantine  @param _contract Address of the exit game contract  @return boolean Whether the contract is safe to use and is not under quarantine  /  function isExitGameSafeToUse(address _contract) public view returns (bool) {  return _exitGameToTxType[_contract] != 0 && !_exitGameQuarantine.isQuarantined(_contract);  These permissions allow a registered quarantine to:  Withdraw any users  tokens from ERC20Vault:  code/plasma_framework/contracts/src/vaults/Erc20Vault.sol:L52-L55  function withdraw(address payable receiver, address token, uint256 amount) external onlyFromNonQuarantinedExitGame {  IERC20(token).safeTransfer(receiver, amount);  emit Erc20Withdrawn(receiver, token, amount);  Withdraw any users  ETH from EthVault:  code/plasma_framework/contracts/src/vaults/EthVault.sol:L46-L54  function withdraw(address payable receiver, uint256 amount) external onlyFromNonQuarantinedExitGame {  // we do not want to block exit queue if transfer is unucessful  // solhint-disable-next-line avoid-call-value  (bool success, ) = receiver.call.value(amount)(\"\");  if (success) {  emit EthWithdrawn(receiver, amount);  } else {  emit WithdrawFailed(receiver, amount);  Activate and deactivate the ExitGameController reentrancy mutex:  code/plasma_framework/contracts/src/framework/ExitGameController.sol:L63-L66  function activateNonReentrant() external onlyFromNonQuarantinedExitGame() {  require(!mutex, \"Reentrant call\");  mutex = true;  code/plasma_framework/contracts/src/framework/ExitGameController.sol:L72-L75  function deactivateNonReentrant() external onlyFromNonQuarantinedExitGame() {  require(mutex, \"Not locked\");  mutex = false;  enqueue arbitrary exits:  code/plasma_framework/contracts/src/framework/ExitGameController.sol:L115-L138  function enqueue(  uint256 vaultId,  address token,  uint64 exitableAt,  TxPosLib.TxPos calldata txPos,  uint160 exitId,  IExitProcessor exitProcessor  external  onlyFromNonQuarantinedExitGame  returns (uint256)  bytes32 key = exitQueueKey(vaultId, token);  require(hasExitQueue(key), \"The queue for the (vaultId, token) pair is not yet added to the Plasma framework\");  PriorityQueue queue = exitsQueues[key];  uint256 priority = ExitPriority.computePriority(exitableAt, txPos, exitId);  queue.insert(priority);  delegations[priority] = exitProcessor;  emit ExitQueued(exitId, priority);  return priority;  Flag outputs as  spent :  code/plasma_framework/contracts/src/framework/ExitGameController.sol:L210-L213  function flagOutputSpent(bytes32 _outputId) external onlyFromNonQuarantinedExitGame {  require(_outputId != bytes32(\"\"), \"Should not flag with empty outputId\");  isOutputSpent[_outputId] = true;  Recommendation  registerExitGame should check that extcodesize of the submitted contract is non-zero.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/410  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.7 EthVault - Unused state variable    Addressed", "body": "  Resolution                           This was addressed in   commit ea36f5ff46ab72ec5c281fa0a3dffe3bcc83178b.  Description  The state variable withdrawEntryCounter is not used in the code.  code/plasma_framework/contracts/src/vaults/EthVault.sol:L8  uint256 private withdrawEntryCounter = 0;  Recommendation  Remove it from the contract.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.8 Recommendation: Add a tree height limit check to Merkle.sol ", "body": "  Description  Each plasma block has a maximum of 2 ** 16 transactions, which corresponds to a maximum Merkle tree height of 16. The Merkle library currently checks that the proof is comprised of 32-byte segments, but neglects to check the maximum height:  code/plasma_framework/contracts/src/utils/Merkle.sol:L17-L23  function checkMembership(bytes32 leaf, uint256 index, bytes32 rootHash, bytes memory proof)  internal  pure  returns (bool)  require(proof.length % 32 == 0, \"Length of Merkle proof must be a multiple of 32\");  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/467  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.9 Recommendation: remove IsDeposit and add a similar getter to BlockController    Addressed", "body": "  Resolution                           This was addressed in   commit 0fee13f7f084983139eb47636ff785ebea8a1c36 by removing the  Description  The IsDeposit library is used to check whether a block number is a deposit or not. The logic is simple - if blockNum % childBlockInterval is nonzero, the block number is a deposit.  By including this check in BlockController instead, the contract can perform an existence check as well. The function in BlockController would return the same result as the IsDeposit library, but would additionally revert if the block in question does not exist:  Note that this check is made at the cost of an external call. If the check needs to be made multiple times in a transaction, the result should be cached.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/466  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.10 Recommendation: Merge TxPosLib into UtxoPosLib and implement a decode function with range checks. ", "body": "  Resolution                           This was partially addressed in   omisego/plasma-contracts#515 with the merging of  omisego/plasma-contracts#533 implemented stricter range checks for block number and transaction index. Note that the maximum output index in  Description  TxPosLib and UtxoPosLib serve very similar functions. They both provide utility functions to access the block number and tx index of a packed utxo position variable. UtxoPosLib, additionally, provides a function to retrieve the output index of a packed utxo position variable.  What they both lack, though, is sanity checks on the values packed inside a utxo position variable. By implementing a function UtxoPosLib.decode(uint _utxoPos) returns (UtxoPos), each exit controller contract can ensure that the values it is using make logical sense. The decode function should check that:  txIndex is between 0 and 2**16  outputIndex is between 0 and 3  Currently, neither of these restrictions is explicitly enforced. As for blockNum, the best check is that it exists in the PlasmaFramework contract with a nonzero root. Since UtxoPosLib is a pure library, that check is better performed elsewhere (See https://github.com/ConsenSys/omisego-morevp-audit-2019-10/issues/21).  Once implemented, all contracts should avoid casting values directly to the UtxoPos struct, in favor of using the decode function. Merging the two files will help with this.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/465  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.11 Recommendation: Implement additional existence and range checks on inputs and storage reads ", "body": "  Resolution                           This was partially addressed in   omisego/plasma-contracts#524 and  omisego/plasma-contracts#483. Not all recommended checks were included.  Description  Many input validation and storage read checks are made implicitly, rather than explicitly. The following compilation notes each line of code in the exit controller contracts where an additional check should be added.  Examples  1. PaymentChallengeIFEInputSpent:  Check that inFlightTx has a nonzero input at the provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L96  require(ife.isInputPiggybacked(args.inFlightTxInputIndex), \"The indexed input has not been piggybacked\");  Check that each transaction is nonzero and is correctly formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L98-L101  require(  keccak256(args.inFlightTx) != keccak256(args.challengingTx),  \"The challenging transaction is the same as the in-flight transaction\"  );  Check that resulting outputId is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L123  bytes32 ifeInputOutputId = data.ife.inputs[data.args.inFlightTxInputIndex].outputId;  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L125  UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.UtxoPos(data.args.inputUtxoPos);  See issue 5.9  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L126  bytes32 challengingTxInputOutputId = data.controller.isDeposit.test(utxoPos.blockNum())  Check that inputTx is nonzero and well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L127-L128  ? OutputId.computeDepositOutputId(data.args.inputTx, utxoPos.outputIndex(), utxoPos.value)  : OutputId.computeNormalOutputId(data.args.inputTx, utxoPos.outputIndex());  Check that output is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L149  WireTransaction.Output memory output = WireTransaction.getOutput(data.args.challengingTx, data.args.challengingTxInputIndex);  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L156  UtxoPosLib.UtxoPos memory inputUtxoPos = UtxoPosLib.UtxoPos(data.args.inputUtxoPos);  Check that challengingTx has a nonzero input at provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEInputSpent.sol:L163  data.args.challengingTxInputIndex,  2. PaymentChallengeIFENotCanonical:  Check that each transaction is nonzero and is correctly formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L98-L101  require(  keccak256(args.inFlightTx) != keccak256(args.competingTx),  \"The competitor transaction is the same as transaction in-flight\"  );  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L104  UtxoPosLib.UtxoPos memory inputUtxoPos = UtxoPosLib.UtxoPos(args.inputUtxoPos);  See issue 5.9  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L107  if (self.isDeposit.test(inputUtxoPos.blockNum())) {  Check that inputTx is nonzero and well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L108-L110  outputId = OutputId.computeDepositOutputId(args.inputTx, inputUtxoPos.outputIndex(), inputUtxoPos.value);  } else {  outputId = OutputId.computeNormalOutputId(args.inputTx, inputUtxoPos.outputIndex());  Check that inFlightTx has a nonzero input at the provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L112-L113  require(outputId == ife.inputs[args.inFlightTxInputIndex].outputId,  \"Provided inputs data does not point to the same outputId from the in-flight exit\");  Check that output is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L115  WireTransaction.Output memory output = WireTransaction.getOutput(args.inputTx, args.inFlightTxInputIndex);  Check that competingTx has a nonzero input at provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L126  args.competingTxInputIndex,  Check that resulting position is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L133  uint256 competitorPosition = verifyCompetingTxFinalized(self, args, output);  Check that inFlightTxPos is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L171-L173  require(  ife.oldestCompetitorPosition > inFlightTxPos,  \"In-flight transaction must be younger than competitors to respond to non-canonical challenge\");  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L175  UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.UtxoPos(inFlightTxPos);  Check that block root is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L176  (bytes32 root, ) = self.framework.blocks(utxoPos.blockNum());  Check that inFlightTx is nonzero and well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L178  inFlightTx, utxoPos, root, inFlightTxInclusionProof  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L218  UtxoPosLib.UtxoPos memory competingTxUtxoPos = UtxoPosLib.UtxoPos(args.competingTxPos);  3. PaymentChallengeIFEOutputSpent:  Check that inFlightTx is nonzero and is well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L54  uint160 exitId = ExitId.getInFlightExitId(args.inFlightTx);  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L58  UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.UtxoPos(args.outputUtxoPos);  Check that inFlightTx has a nonzero output at the provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L60-L63  require(  ife.isOutputPiggybacked(outputIndex),  \"Output is not piggybacked\"  );  Check that bond size is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L70  uint256 piggybackBondSize = ife.outputs[outputIndex].piggybackBondSize;  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L83  UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.UtxoPos(args.outputUtxoPos);  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L101  UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.UtxoPos(args.outputUtxoPos);  Check that challengingTx is nonzero and is well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L102  uint256 challengingTxType = WireTransaction.getTransactionType(args.challengingTx);  Check that output is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L103  WireTransaction.Output memory output = WireTransaction.getOutput(args.challengingTx, utxoPos.outputIndex());  Check that challengingTx has a nonzero input at provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L116  args.challengingTxInputIndex,  4. PaymentChallengeStandardExit:  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeStandardExit.sol:L110  UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.UtxoPos(data.exitData.utxoPos);  Check that exitingTx is nonzero and well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeStandardExit.sol:L112  .decode(data.args.exitingTx)  Check that output is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeStandardExit.sol:L111-L113  PaymentOutputModel.Output memory output = PaymentTransactionModel  .decode(data.args.exitingTx)  .outputs[utxoPos.outputIndex()];  Check that challengeTx is nonzero and well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeStandardExit.sol:L128  uint256 challengeTxType = WireTransaction.getTransactionType(data.args.challengeTx);  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeStandardExit.sol:L134  txPos: TxPosLib.TxPos(data.args.challengeTxPos),  See issue 5.9  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeStandardExit.sol:L157  bytes32 outputId = data.controller.isDeposit.test(utxoPos.blockNum())  Check that challengeTx has a nonzero input at provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeStandardExit.sol:L166  args.inputIndex,  5. PaymentPiggybackInFlightExit:  Check that inFlightTx is nonzero and well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentPiggybackInFlightExit.sol:L93  uint160 exitId = ExitId.getInFlightExitId(args.inFlightTx);  Check that inFlightTx has a nonzero input at provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentPiggybackInFlightExit.sol:L99  require(!exit.isInputPiggybacked(args.inputIndex), \"Indexed input already piggybacked\");  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentPiggybackInFlightExit.sol:L108  enqueue(self, withdrawData.token, UtxoPosLib.UtxoPos(exit.position), exitId);  Check that inFlightTx is nonzero and is well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentPiggybackInFlightExit.sol:L130  uint160 exitId = ExitId.getInFlightExitId(args.inFlightTx);  Check that inFlightTx has a nonzero output at provided index:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentPiggybackInFlightExit.sol:L136  require(!exit.isOutputPiggybacked(args.outputIndex), \"Indexed output already piggybacked\");  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentPiggybackInFlightExit.sol:L147  enqueue(self, withdrawData.token, UtxoPosLib.UtxoPos(exit.position), exitId);  6. PaymentStartInFlightExit:  Check that inFlightTx is nonzero and is well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L146  exitData.exitId = ExitId.getInFlightExitId(args.inFlightTx);  Check that the length of inputTxs is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L150  exitData.inputTxs = args.inputTxs;  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L167  utxosPos[i] = UtxoPosLib.UtxoPos(inputUtxosPos[i]);  See issue 5.9  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L180  bool isDepositTx = controller.isDeposit.test(utxoPos[i].blockNum());  Check that each inputTxs is nonzero and well-formed:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L181-L183  outputIds[i] = isDepositTx  ? OutputId.computeDepositOutputId(inputTxs[i], utxoPos[i].outputIndex(), utxoPos[i].value)  : OutputId.computeNormalOutputId(inputTxs[i], utxoPos[i].outputIndex());  Check that each output is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L200  WireTransaction.Output memory output = WireTransaction.getOutput(inputTxs[i], outputIndex);  Check that inFlightTx has nonzero inputs for all i:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L327-L328  exitData.inFlightTxRaw,  i,  Check that each output is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L407  PaymentOutputModel.Output memory output = exitData.inFlightTx.outputs[i];  7. PaymentStartStandardExit:  See issue 5.10  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartStandardExit.sol:L119  UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.UtxoPos(args.utxoPos);  Check that output is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartStandardExit.sol:L121  PaymentOutputModel.Output memory output = outputTx.outputs[utxoPos.outputIndex()];  Check that timestamp is nonzero:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartStandardExit.sol:L124  (, uint256 blockTimestamp) = controller.framework.blocks(utxoPos.blockNum());  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/463  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.12 Recommendation: Remove optional arguments and clean unused code    Addressed", "body": "  Resolution                           This was addressed in   omisego/plasma-contracts#496 and  omisego/plasma-contracts#503 with the removal of the output guard handler pattern, the simplification of the tx finalization check via  Description  Several locations in the codebase feature unused arguments, functions, return values, and more. There are two primary reasons to remove these artifacts from the codebase:  Mass exits are the primary safeguard against a byzantine operator. The biggest bottleneck of a mass exit is transaction throughput, so plasma rootchain implementations should strive to be as efficient as possible. Many unused features require external calls, memory allocation, unneeded calculation, and more.  The contracts are set up to be extensible by way of the addition of new exit games to the system.  Optional  or unimplemented features in current exit games should be removed for simplicity s sake, as they currently make up a large portion of the codebase.  Examples  Output guard handlers  These offer very little utility in the current contracts. The main contract, PaymentOutputGuardHandler, has three functions:  isValid enforces that some  preimage  value passed in via calldata has a length of zero. This could be removed along with the unused  preimage  parameter. getExitTarget converts a bytes20 to address payable (with the help of AddressPayable.sol). This could be removed in favor of using AddressPayable directly where needed. getConfirmSigAddress simply returns an empty address. This should be removed wherever used - empty fields should be a rare exception or an error, rather than being injected as unused values into critical functions.   The minimal utility offered comes at the price of using an external call to the OutputGuardHandlerRegistry, as well as an external call for each of the functions mentioned above. Overall, the existence of output guard handlers adds thousands of gas to the exit process. Referenced contracts: IOutputGuardHandler, OutputGuardModel, PaymentOutputGuardHandler, OutputGuardHandlerRegistry  Payment router arguments  Several fields in the exit router structs are marked  optional,  and are not used in the contracts. While this is not particularly impactful, it does clutter and confuse the contracts. Many  optional  fields are referenced and passed into functions which do not use them. Of note is the crucially-important signature verification function, PaymentOutputToPaymentTxCondition.verify, where StartExitData.inputSpendingConditionOptionalArgs resolves to an unnamed parameter:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L323-L332  bool isSpentByInFlightTx = condition.verify(  exitData.inputTxs[i],  exitData.inputUtxosPos[i].outputIndex(),  exitData.inputUtxosPos[i].txPos().value,  exitData.inFlightTxRaw,  i,  exitData.inFlightTxWitnesses[i],  exitData.inputSpendingConditionOptionalArgs[i]  );  require(isSpentByInFlightTx, \"Spending condition failed\");  code/plasma_framework/contracts/src/exits/payment/spendingConditions/PaymentOutputToPaymentTxCondition.sol:L40-L47  function verify(  bytes calldata inputTxBytes,  uint16 outputIndex,  uint256 inputTxPos,  bytes calldata spendingTxBytes,  uint16 inputIndex,  bytes calldata signature,  bytes calldata /*optionalArgs*/  The additional fields clutter the namespace of each struct, confusing the purpose of the other fields. For example, PaymentInFlightExitRouterArgs.StartExitArgs features two fields, inputTxsConfirmSigs and inFlightTxsWitnesses, the former of which is marked  optional . In fact, the inFlightTxsWitnesses field ends up containing the signatures passed to the spending condition verifier and ECDSA library:  code/plasma_framework/contracts/src/exits/payment/routers/PaymentInFlightExitRouterArgs.sol:L4-L24  /**  @notice Wraps arguments for startInFlightExit.  @param inFlightTx RLP encoded in-flight transaction.  @param inputTxs Transactions that created the inputs to the in-flight transaction. In the same order as in-flight transaction inputs.  @param inputUtxosPos Utxos that represent in-flight transaction inputs. In the same order as input transactions.  @param outputGuardPreimagesForInputs (Optional) Output guard pre-images for in-flight transaction inputs. Length must always match that of the inputTxs  @param inputTxsInclusionProofs Merkle proofs that show the input-creating transactions are valid. In the same order as input transactions.  @param inputTxsConfirmSigs (Optional) Confirm signatures for the input txs. Should be empty bytes if the input tx is MoreVP. Length must always match that of the inputTxs  @param inFlightTxWitnesses Witnesses for in-flight transaction. In the same order as input transactions.  @param inputSpendingConditionOptionalArgs (Optional) Additional args for the spending condition for checking inputs. Should provide empty bytes if nothing is required. Length must always match that of the inputTxs  /  struct StartExitArgs {  bytes inFlightTx;  bytes[] inputTxs;  uint256[] inputUtxosPos;  bytes[] outputGuardPreimagesForInputs;  bytes[] inputTxsInclusionProofs;  bytes[] inputTxsConfirmSigs;  bytes[] inFlightTxWitnesses;  bytes[] inputSpendingConditionOptionalArgs;  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/457  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.13 Recommendation: Remove WireTransaction and PaymentOutputModel. Fold functionality into an extended PaymentTransactionModel ", "body": "  Description  RLP decoding is performed on transaction bytes in each of WireTransaction, PaymentOutputModel, and PaymentTransactionModel. The latter is the primary decoding function for transactions, while the former two contracts deal with outputs specifically.  Both WireTransaction and PaymentOutputModel make use of RLPReader to decode transaction objects, and both implement very similar features. Rather than having a codebase with two separate definitions for struct Output, PaymentTransactionModel should be extended to implement all required functionality.  Examples  PaymentTransactionModel should include three distinct decoding functions:  decodeDepositTx decodes a deposit transaction, which has no inputs and exactly 1 output. decodeSpendTx decodes a spend transaction, which has exactly 4 inputs and 4 outputs. decodeOutput decodes an output, which is a long list with 4 fields (uint, address, address, uint)  A mock implementation including decodeSpendTx and decodeOutput is shown here: https://gist.github.com/wadeAlexC/7820c0cd82fd5fdc11a0ad58a84165ae  OmiseGo may want to consider enforcing restrictions on the ordering of empty and nonempty fields here as well.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/456  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.14 ECDSA error value is not handled    Addressed", "body": "  Resolution                           This was addressed in   commit 32288ccff5b867a7477b4eaf3beb0587a4684d7a by adding a check that the returned value is nonzero.  Description  The OpenZeppelin ECDSA library returns address(0x00) for many cases with malformed signatures:  contracts/cryptography/ECDSA.sol:L57-L63  if (uint256(s) > 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0) {  return address(0);  if (v != 27 && v != 28) {  return address(0);  The PaymentOutputToPaymentTxCondition contract does not explicitly handle this case:  code/plasma_framework/contracts/src/exits/payment/spendingConditions/PaymentOutputToPaymentTxCondition.sol:L65-L68  address payable owner = inputTx.outputs[outputIndex].owner();  require(owner == ECDSA.recover(eip712.hashTx(spendingTx), signature), \"Tx in not signed correctly\");  return true;  Recommendation  Adding a check to handle this case will make it easier to reason about the code.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/454  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.15 No existence checks on framework block and timestamp reads    Addressed", "body": "  Resolution                           This was addressed in   commit c5e5a460a2082b809a2c45b2d6a69b738b34937a by adding checks that block root and timestamp reads return nonzero values.  Description  The exit game libraries make several queries to the main PlasmaFramework contract where plasma block hashes and timestamps are stored. In multiple locations, the return values of these queries are not checked for existence.  Examples  PaymentStartStandardExit.setupStartStandardExitData:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartStandardExit.sol:L124  (, uint256 blockTimestamp) = controller.framework.blocks(utxoPos.blockNum());  PaymentChallengeIFENotCanonical.respond:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L176  (bytes32 root, ) = self.framework.blocks(utxoPos.blockNum());  PaymentPiggybackInFlightExit.enqueue:  code/plasma_framework/contracts/src/exits/payment/controllers/PaymentPiggybackInFlightExit.sol:L167  (, uint256 blockTimestamp) = controller.framework.blocks(utxoPos.blockNum());  TxFinalizationVerifier.checkInclusionProof:  code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L54  (bytes32 root,) = data.framework.blocks(data.txPos.blockNum());  Recommendation  Although none of these examples seem exploitable, adding existence checks makes it easier to reason about the code. Each query to PlasmaFramework.blocks should be followed with a check that the returned value is nonzero.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/463  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.16 BondSize - effectiveUpdateTime should be uint64 ", "body": "  Description  In BondSize, the mechanism to update the size of the bond has a grace period after which the new bond size becomes active.  When updating the bond size, the time is casted as a uint64 and saved in a uint128 variable.  code/plasma_framework/contracts/src/exits/utils/BondSize.sol:L24  uint128 effectiveUpdateTime;  code/plasma_framework/contracts/src/exits/utils/BondSize.sol:L11  uint64 constant public WAITING_PERIOD = 2 days;  code/plasma_framework/contracts/src/exits/utils/BondSize.sol:L57  self.effectiveUpdateTime = uint64(now) + WAITING_PERIOD;  There s no need to use a uint128 to save the time if it never will take up that much space.  Recommendation  Change the type of the effectiveUpdateTime to uint64.  uint128 effectiveUpdateTime;  + uint64 effectiveUpdateTime;  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.17 PaymentExitGame contains several redundant plasmaFramework declarations ", "body": "  Description  PaymentExitGame inherits from both PaymentInFlightExitRouter and PaymentStandardExitRouter. All three contracts declare and initialize their own PlasmaFramework variable. This pattern can be misleading, and may lead to subtle issues in future versions of the code.  Examples  PaymentExitGame declaration:  code/plasma_framework/contracts/src/exits/payment/PaymentExitGame.sol:L18  PlasmaFramework private plasmaFramework;  PaymentInFlightExitRouter declaration:  code/plasma_framework/contracts/src/exits/payment/routers/PaymentInFlightExitRouter.sol:L53  PlasmaFramework private framework;  PaymentStandardExitRouter declaration:  code/plasma_framework/contracts/src/exits/payment/routers/PaymentStandardExitRouter.sol:L45  PlasmaFramework private framework;  Each variable is initialized in the corresponding file s constructor.  Recommendation  Introduce an inherited contract common to PaymentStandardExitRouter and PaymentInFlightExitRouter with the PlasmaFramework variable. Make the variable internal so it is visible to inheriting contracts.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.18 BlockController - inaccurate description of childBlockInterval for submitDepositBlock ", "body": "  Description  code/plasma_framework/contracts/src/framework/BlockController.sol:L96-L114  /**  @notice Submits a block for deposit  @dev Block number adds 1 per submission; it's possible to have at most 'childBlockInterval' deposit blocks between two child chain blocks  @param _blockRoot Merkle root of the Plasma block  @return The deposit block number  /  function submitDepositBlock(bytes32 _blockRoot) public onlyFromNonQuarantinedVault returns (uint256) {  require(isChildChainActivated == true, \"Child chain has not been activated by authority address yet\");  require(nextDeposit < childBlockInterval, \"Exceeded limit of deposits per child block interval\");  uint256 blknum = nextDepositBlock();  blocks[blknum] = BlockModel.Block({  root : _blockRoot,  timestamp : block.timestamp  });  nextDeposit++;  return blknum;  However, the comment at line 98 mentions the following:  [..] it s possible to have at most  childBlockInterval  deposit blocks between two child chain blocks [..]  This comment is inaccurate, as a childBlockInterval of 1 would not allow deposits at all (Note how nextDeposit is always >=1).  Remediation  The comment should read: [..] it s possible to have at most  childBlockInterval -1  deposit blocks between two child chain blocks [..]. Make sure to properly validate inputs for these values when deploying the contract to avoid obvious misconfiguration.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.19 PlasmaFramework - Can omit inheritance of VaultRegistry ", "body": "  Description  The contract PlasmaFramework inherits VaultRegistry even though it does not use any of the methods directly. Also BlockController inherits VaultRegistry effectively adding all of the needed functionality in there.  Remediation  PlasmaFramework does not need to inherit VaultRegistry, thus the import and the inheritance can be removed from PlasmaFramework.sol.  import \"./BlockController.sol\";  import \"./ExitGameController.sol\";  import \"./registries/VaultRegistry.sol\";  import \"./registries/ExitGameRegistry.sol\";  contract PlasmaFramework is VaultRegistry, ExitGameRegistry, ExitGameController, BlockController {  +contract PlasmaFramework is ExitGameRegistry, ExitGameController, BlockController {  uint256 public constant CHILD_BLOCK_INTERVAL = 1000;  /**  All tests still pass after removing the inheritance.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "5.20 BlockController - maintainer should be the only entity to set new authority    Addressed", "body": "  Resolution                           This was addressed in   commit 25c2560e3b2e40ce9a10c40da97c3f79afc2c641 with the removal of the  Description  code/plasma_framework/contracts/src/framework/BlockController.sol:L69-L72  function setAuthority(address newAuthority) external onlyFrom(authority) {  require(newAuthority != address(0), \"Authority address cannot be zero\");  authority = newAuthority;  security specification notes that the  Authority: EOA used exclusively to submit plasma block hashes to the root chain. The child chain assumes at deployment that the authority account has nonce zero and no transactions have been sent from it.  However, no transactions might not be possible as authority is the only one to activateChildChain. Once activated, the child chain cannot be de-activated but the authority can change.  elixir-omg#managing-the-operator-address notes the following for operator aka authority:  As a consequence, the operator address must never send any other transactions, if it intends to continue submitting blocks. (Workarounds to this limitation are available, if there s such requirement.)  Additionally, setAuthority should emit an event to allow participants to react to this change in the system and have an audit trial.  Remediation  Remove the setAuthority function, or clarify its intended purpose and add an event so it can be detected by users.  Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/403  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/01/omisego-morevp/"}, {"title": "6.1 Ether temporarily held during transactions can be stolen via reentrancy    ", "body": "  Resolution  This is addressed in 0xProject/protocol@437a3b0 by transferring exactly msg.value in sellToLiquidityProvider(). This adequately protects against this specific vulnerability.  The client team decided to leave the accounting in MetaTransactionsFeature as-is due to the complexity/expense of tracking ether consumption more strictly.  Description  The exchange proxy typically holds no ether balance, but it can temporarily hold a balance during a transaction. This balance is vulnerable to theft if the following conditions are met:  No check at the end of the transaction reverts if ether goes missing,  reentrancy is possible during the transaction, and  a mechanism exists to spend ether held by the exchange proxy.  We found one example where these conditions are met, but it s possible that more exist.  Example  MetaTransactionsFeature.executeMetaTransaction() accepts ether, which is used to pay protocol fees. It s possible for less than the full amount in msg.value to be consumed, which is why the function uses the refundsAttachedEth modifier to return any remaining ether to the caller:  code/contracts/zero-ex/contracts/src/features/MetaTransactionsFeature.sol:L98-L106  /// @dev Refunds up to `msg.value` leftover ETH at the end of the call.  modifier refundsAttachedEth() {  _;  uint256 remainingBalance =  LibSafeMathV06.min256(msg.value, address(this).balance);  if (remainingBalance > 0) {  msg.sender.transfer(remainingBalance);  Notice that this modifier just returns the remaining ether balance (up to msg.value). It does not check for a specific amount of remaining ether. This meets condition (1) above.  It s impossible to reenter the system with a second metatransaction because executeMetaTransaction() uses the modifier nonReentrant, but there s nothing preventing reentrancy via a different feature. We can achieve reentrancy by trading a token that uses callbacks (e.g. ERC777 s hooks) during transfers. This meets condition (2).  LiquidityProviderFeature.sellToLiquidityProvider() provides such a mechanism. By passing  code/contracts/zero-ex/contracts/src/features/LiquidityProviderFeature.sol:L114-L115  if (inputToken == ETH_TOKEN_ADDRESS) {  provider.transfer(sellAmount);  This meets condition (3).  The full steps to exploit this vulnerability are as follows:  A maker/attacker signs a trade where one of the tokens will invoke a callback during the trade.  A taker signs a metatransaction to take this trade.  A relayer sends in the metatransaction, providing more ether than is necessary to pay the protocol fee. (It s unclear how likely this situation is.)  During the token callback, the attacker invokes LiquidityProviderFeature.sellToLiquidityProvider() to transfer the excess ether to their account.  The metatransaction feature returns the remaining ether balance, which is now zero.  Recommendation  In general, we recommend using strict accounting of ether throughout the system. If there s ever a temporary balance, it should be accurately resolved at the end of the transaction, after any potential reentrancy opportunities.  For the example we specifically found, we recommend doing strict accounting in the metatransactions feature. This means features called via a metatransaction would need to return how much ether was consumed. The metatransactions feature could then refund exactly msg.value - <consumed ether>. The transaction should be reverted if this fails because it means ether went missing during the transaction.  We also recommend limiting sellToLiquidityProvider() to only transfer up to msg.value. This is a form of defense in depth in case other vectors for a similar attack exist.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/12/0x-exchange-v4/"}, {"title": "6.2 UniswapFeature: Non-static call to ERC20.allowance()    ", "body": "  Resolution                           This is fixed in   0xProject/protocol@437a3b0.  Description  In the case where a token is possibly  greedy  (consumes all gas on failure), UniswapFeature makes a call to the token s allowance() function to check whether the user has provided a token allowance to the protocol proxy or to the AllowanceTarget. This call is made using call(), potentially allowing state-changing operations to take place before control of the execution returns to UniswapFeature.  code/contracts/zero-ex/contracts/src/features/UniswapFeature.sol:L373-L377  // `token.allowance()``  mstore(0xB00, ALLOWANCE_CALL_SELECTOR_32)  mstore(0xB04, caller())  mstore(0xB24, address())  let success := call(gas(), token, 0, 0xB00, 0x44, 0xC00, 0x20)  Recommendation  Replace the call() with a staticcall().  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/12/0x-exchange-v4/"}, {"title": "6.3 UniswapFeature: Unchecked returndatasize in low-level external calls    ", "body": "  Resolution                           This is fixed in   0xProject/protocol@437a3b0.  Description  UniswapFeature makes a number of external calls from low-level assembly code. Two of these calls rely on the CALL opcode to copy the returndata to memory without checking that the call returned the expected amount of data. Because the CALL opcode does not zero memory if the call returns less data than expected, this can lead to usage of dirty memory under the assumption that it is data returned from the most recent call.  Examples  Call to UniswapV2Pair.getReserves()  code/contracts/zero-ex/contracts/src/features/UniswapFeature.sol:L201-L205  // Call pair.getReserves(), store the results at `0xC00`  mstore(0xB00, UNISWAP_PAIR_RESERVES_CALL_SELECTOR_32)  if iszero(staticcall(gas(), pair, 0xB00, 0x4, 0xC00, 0x40)) {  bubbleRevert()  Call to ERC20.allowance()  code/contracts/zero-ex/contracts/src/features/UniswapFeature.sol:L372-L377  // Check if we have enough direct allowance by calling  // `token.allowance()``  mstore(0xB00, ALLOWANCE_CALL_SELECTOR_32)  mstore(0xB04, caller())  mstore(0xB24, address())  let success := call(gas(), token, 0, 0xB00, 0x44, 0xC00, 0x20)  Recommendation  Instead of providing a memory range for call() to write returndata to, explicitly check returndatasize() after the call is made and then copy the data into memory using returndatacopy().  if lt(returndatasize(), EXPECTED_SIZE) {  revert(0, 0)  returndatacopy(0xC00, 0x00, EXPECTED_SIZE)  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/12/0x-exchange-v4/"}, {"title": "6.4 Rollback functionality can lead to untested combinations   ", "body": "  Resolution  From the client team:  Just like our migrations, we batch our rollbacks by release, which enforces rolling back to known good configurations.  The documentation now includes an emergency playbook that describes how rollbacks should be done.  Description  SimpleFunctionRegistry maps individual function selectors to implementation contracts. As features are newly deployed or upgraded, functions are registered in logical groups after a timelock enforced by the owning multisig wallet. This gives users time to evaluate upcoming changes and stop using the contract if they don t like the changes.  Once deployed, however, any function can individually be rolled back without a timelock to any previous version of that function. Users are given no warning, functions can be rolled back to any previous implementation (regardless of how old), and the per-function granularity means that the configuration after rollback may be a never-before-seen combination of functions.  The combinatorics makes it impossible for a user (or auditor) to be comfortable with all the possible outcomes of rollbacks. If there are n versions each of m functions, there are n^m combinations that could be in effect at any moment. Some functions depend on other onlySelf functions, so the behavior of those combinations is not at all obvious.  This presents a trust problem for users.  Recommendation  Rollback makes sense as a way to rapidly recover from a bad deployment, but we recommend limiting its scope. The following ideas are in preferred order (our favorite first):  Disallow rollback altogether except to an implementation of address(0). This way broken functionality can be immediately disabled, but no old version of a function can be reinstated.  Limit rollback by number of versions, e.g. only allowing rollback to the immediately previous version of a function.  Limit rollback by time, e.g. only allowing rollback to versions in the past n weeks.  ", "labels": ["Consensys", "Minor", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/12/0x-exchange-v4/"}, {"title": "6.1 Funds Refunded From Celer Bridge Might Be Stolen ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#144 by adding checks to see if the refund is received and equal to the expected amount.  Description  The function refundCelerUser from CelerImpl.sol allows a user that deposited into the Celer pool on the source chain, to be refunded for tokens that were not bridged to the destination chain. The tokens are reimbursed to the user by calling the withdraw method on the Celer pool. This is what the refundCelerUser function is doing.  src/bridges/cbridge/CelerImpl.sol:L413-L415  if (!router.withdraws(transferId)) {  router.withdraw(_request, _sigs, _signers, _powers);  From the point of view of the Celer bridge, the initial depositor of the tokens is the SocketGateway. As a consequence, the Celer contract transfers the tokens to be refunded to the gateway. The gateway is then in charge of forwarding the tokens to the initial depositor. To achieve this, it keeps a mapping of unique transfer IDs to depositor addresses. Once a refund is processed, the corresponding address in the mapping is reset to the zero address.  Looking at the withdraw function of the Celer pool, we see that for some tokens, it is possible that the reimbursement will not be processed directly, but only after some delay. From the gateway point of view, the reimbursement will be marked as successful, and the address of the original sender corresponding to this transfer ID will be reset to address(0).  It is then the responsibility of the user, once the locking delay has passed, to call another function to claim the tokens. Unfortunately, in our case, this means that the funds will be sent back to the gateway contract and not to the original sender. Because the gateway implements rescueEther, and rescueFunds functions, the admin might be able to send the funds back to the user. However, this requires manual intervention and breaks the trustlessness assumptions of the system. Also, in that case, there is no easy way to trace back the original address of the sender, that corresponds to this refund.  src/bridges/cbridge/CelerImpl.sol:L120-L127  function bridgeAfterSwap(  uint256 amount,  bytes calldata bridgeData  ) external payable override {  CelerBridgeData memory celerBridgeData = abi.decode(  bridgeData,  (CelerBridgeData)  );  src/bridges/stargate/l2/Stargate.sol:L183-L186  function swapAndBridge(  uint32 swapId,  bytes calldata swapData,  StargateBridgeDataNoToken calldata stargateBridgeData  Note that this violates the security assumption:  The contracts are not supposed to hold any funds post-tx execution.   Recommendation  Make sure that CelerImpl supports also the delayed withdrawals functionality and that withdrawal requests are deleted only if the receiver has received the withdrawal in a single transaction.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.2 Calls Made to Non-Existent/Removed Routes or Controllers Will Not Result in Failure ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#145 by adding a  Description  This issue was found in commit hash a8d0ad1c280a699d88dc280d9648eacaf215fb41.  In the Ethereum Virtual Machine (EVM), delegatecall will succeed for calls to externally owned accounts and more specifically to the zero address, which presents a potential security risk. We have identified multiple instances of delegatecall being used to invoke smart contract functions.  This, combined with the fact that routes can be removed from the system by the owner of the SocketGateway contract using the disableRoute function, makes it possible for the user s funds to be lost in case of an executeRoute transaction (for instance) that s waiting in the mempool is eventually being front-ran by a call to disableRoute.  Examples  src/SocketGateway.sol:L95  (bool success, bytes memory result) = addressAt(routeId).delegatecall(  src/bridges/cbridge/CelerImpl.sol:L208  .delegatecall(swapData);  src/bridges/stargate/l1/Stargate.sol:L187  .delegatecall(swapData);  src/bridges/stargate/l2/Stargate.sol:L190  .delegatecall(swapData);  src/controllers/BaseController.sol:L50  .delegatecall(data);  Even after the upgrade to commit hash d0841a3e96b54a9d837d2dba471aa0946c3c8e7b, the following bug is still present:  src/SocketGateway.sol:L411-L428  function addressAt(uint32 routeId) public view returns (address) {  if (routeId < 513) {  if (routeId < 257) {  if (routeId < 129) {  if (routeId < 65) {  if (routeId < 33) {  if (routeId < 17) {  if (routeId < 9) {  if (routeId < 5) {  if (routeId < 3) {  if (routeId == 1) {  return  0x822D4B4e63499a576Ab1cc152B86D1CFFf794F4f;  } else {  return  0x822D4B4e63499a576Ab1cc152B86D1CFFf794F4f;  } else {  src/SocketGateway.sol:L2971-L2972  if (routes[routeId] == address(0)) revert ZeroAddressNotAllowed();  return routes[routeId];  Recommendation  Consider adding a check to validate that the callee of a delegatecall is indeed a contract, you may refer to the Address library by OZ.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.3 Owner Can Add Arbitrary Code to Be Executed From the SocketGateway Contract ", "body": "  Resolution  The client team has responded with the following note:  Noted, we will setup tests and rigorous processes around adding new routes.  Description  Since these routes are called via delegatecall(), they don t hold any storage variables that would be used in the Socket systems. However, as Socket aggregates more solutions, unexpected complexities may arise that could require storing and accessing variables through additional contracts. Those contracts would be access control protected to only have the SocketGateway contract have the privileges to modify its variables.  This together with the Owner of the SocketGateway being able to add routes with arbitrary code creates an attack vector where a compromised address with Owner privileges may add a route that would contain code that exploits the special privileges assigned to the SocketGateway contract for their benefit.  For example, the Celer bridge needs extra logic to account for its refund mechanism, so there is an additional CelerStorageWrapper contract that maintains a mapping between individual bridge transfer transactions and their associated msg.sender:  src/bridges/cbridge/CelerImpl.sol:L145  celerStorageWrapper.setAddressForTransferId(transferId, msg.sender);  src/bridges/cbridge/CelerStorageWrapper.sol:L6-L12  /**  @title CelerStorageWrapper  @notice handle storageMappings used while bridging ERC20 and native on CelerBridge  @dev all functions ehich mutate the storage are restricted to Owner of SocketGateway  @author Socket dot tech.  /  contract CelerStorageWrapper {  Consequently, this contract has access-protected functions that may only be called by the SocketGateway to set and delete the transfer IDs:  src/bridges/cbridge/CelerStorageWrapper.sol:L32  function setAddressForTransferId(  src/bridges/cbridge/CelerStorageWrapper.sol:L52  function deleteTransferId(bytes32 transferId) external {  A compromised Owner of SocketGateway could then create a route that calls into the CelerStorageWrapper contract and updates the transfer IDs associated addresses to be under their control via deleteTransferId() and setAddressForTransferId() functions. This could create a significant drain of user funds, though, it depends on a compromised privileged Owner address.  Recommendation  Although it may indeed be unlikely, for aggregating solutions it is especially important to try and minimize compromised access issues. As future solutions require more complexity, consider architecting their integrations in such a way that they require as few administrative and SocketGateway-initiated transactions as possible. Through conversations with the Socket team, it appears that solutions such as timelocks on adding new routes are being considered as well, which would help catch the problem before it appears as well.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.4 Dependency on Third-Party APIs to Create the Right Payload ", "body": "  Resolution  The client team has responded with the following note:  We offset this risk by following 2 approaches - verifying oneinch calldata on our api before making full calldata for SocketGateway and making verifier contracts/libs that integrators can use to verify our calldata on their side before making actual transaction.  Description  The Socket system of routes and controllers integrates swaps, bridges, and potentially other solutions that are vastly different from each other. The function arguments that are required to execute them may often seem like a black box of a payload for a typical end user. In fact, even when users explicitly provide a destination token with an associated amount for a swap, these arguments themselves might not even be fully (or at all) used in the route itself. Instead, often the routes and controllers accept a bytes payload that contains all the necessary data for its action. These data payloads are generated off-chain, often via centralized APIs provided by the integrated systems themselves, which is understandable in isolation as they have to be generated somewhere at some point. However, the provided bytes do not get checked for their correctness or matching with the other arguments that the user explicitly provided. Even the events that get emitted refer to the individual arguments of functions as opposed to what actually was being used to execute the logic.  src/swap/oneinch/OneInchImpl.sol:L59-L63  // additional data is generated in off-chain using the OneInch API which takes in  // fromTokenAddress, toTokenAddress, amount, fromAddress, slippage, destReceiver, disableEstimate  (bool success, bytes memory result) = ONEINCH_AGGREGATOR.call(  swapExtraData  );  Even the event at the end of the transaction partially refers to the explicitly provided arguments instead of those that actually facilitated the execution of logic  src/swap/oneinch/OneInchImpl.sol:L84-L91  emit SocketSwapTokens(  fromToken,  toToken,  returnAmount,  amount,  OneInchIdentifier,  receiverAddress  );  As Socket aggregates other solutions, it naturally incurs the trust assumptions and risks associated with its integrations. In some ways, they even stack on top of each other, especially in those Socket functions that batch several routes together   all of them and their associated API calls need to return the correct payloads. So, there is an opportunity to minimize these risks by introducing additional checks into the contracts that would verify the correctness of the payloads that are passed over to the routes and controllers. In fact, creating these payloads within the contracts would allow other systems to integrate Socket more simpler as they could just call the functions with primary logical arguments such as the source token, destination token, and amount.  Recommendation  Consider allocating additional checks within the route implementations that ensure that the explicitly passed arguments match what is being sent for execution to the integrated solutions, like in the above example with the 1inch implementation.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.5 NativeOptimismImpl - Events Will Not Be Emitted in Case of Non-Native Tokens Bridging ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#146 by moving the event above the bridging code, making sure events are emitted for all cases, and adding the fix to other functions that had a similar issue.  Description  In the case of the usage of non-native tokens by users, the SocketBridge event will not be emitted since the code will return early.  Examples  src/bridges/optimism/l1/NativeOptimism.sol:L110  function bridgeAfterSwap(  src/bridges/optimism/l1/NativeOptimism.sol:L187  function swapAndBridge(  src/bridges/optimism/l1/NativeOptimism.sol:L283  function bridgeERC20To(  Recommendation  Make sure that the SocketBridge event is emitted for non-native tokens as well.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.6 Inconsistent Comments ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#147.  Description  Some of the contracts in the code have incorrect developer comments annotated for them. This could create confusion for future readers of this code that may be trying to maintain, audit, update, fork, integrate it, and so on.  Examples  src/bridges/stargate/l2/Stargate.sol:L174-L183  /**  @notice function to bridge tokens after swap. This is used after swap function call  @notice This method is payable because the caller is doing token transfer and briding operation  @dev for usage, refer to controller implementations  encodedData for bridge should follow the sequence of properties in Stargate-BridgeData struct  @param swapId routeId for the swapImpl  @param swapData encoded data for swap  @param stargateBridgeData encoded data for StargateBridgeData  /  function swapAndBridge(  This is the same comment as bridgeAfterSwap, whereas it instead does swapping and bridging together  src/bridges/cbridge/CelerStorageWrapper.sol:L24-L32  /**  @notice function to store the transferId and message-sender of a bridging activity  @notice This method is payable because the caller is doing token transfer and briding operation  @dev for usage, refer to controller implementations  encodedData for bridge should follow the sequence of properties in CelerBridgeData struct  @param transferId transferId generated during the bridging of ERC20 or native on CelerBridge  @param transferIdAddress message sender who is making the bridging on CelerBridge  /  function setAddressForTransferId(  This comment refers to a payable property of this function when it isn t.  src/bridges/cbridge/CelerStorageWrapper.sol:L45-L52  /**  @notice function to store the transferId and message-sender of a bridging activity  @notice This method is payable because the caller is doing token transfer and briding operation  @dev for usage, refer to controller implementations  encodedData for bridge should follow the sequence of properties in CelerBridgeData struct  @param transferId transferId generated during the bridging of ERC20 or native on CelerBridge  /  function deleteTransferId(bytes32 transferId) external {  This comment is copied from the above function when it does the opposite of storing - it deletes the transferId  Recommendation  Adjust comments so they reflect what the functions are actually doing.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.7 Ether Might Be Sent to Routes by Mistake, and Can Be Stolen ", "body": "  Resolution  The client team has responded with the following note:  This can happen only if there is an error in API or integration. There are test cases to verify value on API side and we also run an automated testing suite using small amounts after each upgrade to the API before releasing to public. We also work with integrators to test out the flow covering all edge cases before they release. Overall we are fine with taking this risk and relying on rescue function to recover funds while testing.  Description  Most functions of SocketGateway are payable, and can receive ether, which is processed in different ways, depending on the routes. A user might send ether to a payable function of SocketGateway with a wrong payload, either by mistake or because of an API bug.  Let s illustrate the issue with the performAction of the 1inch route. However, this can be generalized to other routes.  src/SocketGateway.sol:L90-L97  function executeRoute(  uint32 routeId,  bytes calldata routeData,  bytes calldata eventData  ) external payable returns (bytes memory) {  (bool success, bytes memory result) = addressAt(routeId).delegatecall(  routeData  );  function performAction(  address fromToken,  address toToken,  uint256 amount,  address receiverAddress,  bytes calldata swapExtraData  ) external payable override returns (uint256) {  uint256 returnAmount;  if (fromToken != NATIVE_TOKEN_ADDRESS) {  ...  ...  (bool success, bytes memory result) = ONEINCH_AGGREGATOR.call(  swapExtraData //<-- here we do not use the value  );  ...  } else {  ....  (bool success, bytes memory result) = ONEINCH_AGGREGATOR.call{  value: amount  //<-- here we use the value  }(swapExtraData);  ...  ...  Assume the user sent some ETH,  but sent a payload with fromToken != NATIVE_TOKEN_ADDRESS (and the user has already approved the gateway for fromToken).  Then, the ether is not used in the transaction and remains stuck in the SocketGateway contract. This is because the function only executes the part of the code that transfers and swaps ERC-20 tokens, but not the part that handles ether.  Now,  suppose another user calls the performAction function with fromToken == NATIVE_TOKEN_ADDRESS and provides enough gas to execute the function. Since there is ether stuck in the contract, this user can force the contract to use the stuck ether to execute the swap by sending the exact amount of ether stuck in the contract as the value of the transaction, effectively stealing the funds.  This is why it s important to ensure that ether is only accepted when it is needed and not left stuck in the contract, as it can be vulnerable to theft in future transactions.  One could be tempted to fix the issue by requiring that the gateway balance always equals 0 at the end of the transaction. However, this is not a good idea, as anyone could cause a Denial of Service in the gateway by sending a tiny amount of ETH.  One might also be tempted to fix this issue by requiring that msg.value == 0 iff  fromToken != NATIVE_TOKEN_ADDRESS. However, this also poses a problem, as the gateway might execute multiple routes in a  for  loop. This could lead to reverting valid transactions (when both native and non-native tokens are involved).  The best way to solve this issue might be to compare the balance of the gateway before and after the transaction in all relevant functions. The balance should stay the same otherwise, something wrong happened, and we should revert the transaction. This could be implemented by adding a modifier in SocketGateway, that compares the balance of the gateway before and after the function call. Below is an example to illustrate the idea.  modifier checkGatewayBalance() {  uint256 initialBalance = address(this).balance;  _;  uint256 finalBalance = address(this).balance;  require(initialBalance == finalBalance, \"Gateway balance changed during execution\");  issue 6.1)  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.8 No Event Is Emitted When Invoking a Route Through the socketGateway Fallback Function ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#152. Further discussion about the scope of events in these cases is still ongoing.  Description  When a route is invoked through executeRoute,  or executeRoutes functions, a SocketRouteExecuted event is emitted. However, a route can also be executed by invoking the fallback function of the socketGateway. And in that case, no event is emitted. This might impact off-chain systems that rely on those events.  Recommendation  Consider also emitting a SocketRouteExecuted event in case the route is invoked through the fallback function  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.9 Unused Error Codes. ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#148.  Description  SocketErrors.sol has errors that are defined but are not used:  error RouteAlreadyExist();  error ContractContainsNoCode();  error ControllerAlreadyExist();  error ControllerAddressIsZero();  It seems that they were created as errors that may have been expected to occur during the early stages of development, but the resulting architecture doesn t seem to have a place for them currently.  Examples  src/errors/SocketErrors.sol:L12-L19  error RouteAlreadyExist();  error SwapFailed();  error UnsupportedInterfaceId();  error ContractContainsNoCode();  error InvalidCelerRefund();  error CelerAlreadyRefunded();  error ControllerAlreadyExist();  error ControllerAddressIsZero();  Recommendation  Consider revisiting these errors and identifying whether they need to remain or can be removed.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.10 Inaccurate Interface. ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#149.  Description  ISocketGateway implies a bridge(uint32 routeId, bytes memory data) function, but there is no socket contract with a function like that, including the SocketGateway contract.  Examples  src/interfaces/ISocketGateway.sol:L32-L35  function bridge(  uint32 routeId,  bytes memory data  ) external payable returns (bytes memory);  Recommendation  Adjust the interface.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.11 Validate Array Length Matching Before Execution to Avoid Reverts ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#150 by adding the necessary array length checks.  Description  The Socket system not only aggregates different solutions via its routes and controllers but also allows to batch calls between them into one transaction. For example, a user may call swaps between several DEXs and then perform a bridge transfer.  As a result, the SocketGateway contract has many functions that accept multiple arrays that contain the necessary data for execution in their respective routes. However, these arrays need to be of the same length because individual elements in the arrays are intended to be matched at the same indices:  src/SocketGateway.sol:L196-L218  function executeRoutes(  uint32[] calldata routeIds,  bytes[] calldata dataItems,  bytes[] calldata eventDataItems  ) external payable {  uint256 routeIdslength = routeIds.length;  for (uint256 index = 0; index < routeIdslength; ) {  (bool success, bytes memory result) = addressAt(routeIds[index])  .delegatecall(dataItems[index]);  if (!success) {  assembly {  revert(add(result, 32), mload(result))  emit SocketRouteExecuted(routeIds[index], eventDataItems[index]);  unchecked {  ++index;  Note that in the above example function, all 3 different calldata arrays routeIds, dataItems, and eventDataItems were utilizing the same index to retrieve the correct element. A common practice in such cases is to confirm that the sizes of the arrays match before continuing with the execution of the rest of the transaction to avoid costly reverts that could happen due to  Index out of bounds  error.  Due to the aggregating and batching nature of the Socket system that may have its users rely on 3rd party offchain APIs to construct these array payloads, such as from APIs of the systems that Socket is integrating, a mishap in just any one of them could cause this issue.  Recommendation  Implement a check on the array lengths so they match.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.12 Destroyed Routes Eth Balances Will Be Left Locked in SocketDeployFactory ", "body": "  Resolution                           Remediated as per the client team in   SocketDotTech/socket-ll-contracts#151 by adding rescue functions.  Description  SocketDeployFactory.destroy calls the killme function which in turn self-destructs the route and sends back any eth to the factory contract. However, these funds can not be claimed from the SocketDeployFactory contract.  Examples  src/deployFactory/SocketDeployFactory.sol:L170  function destroy(uint256 routeId) external onlyDisabler {  Recommendation  Make sure that these funds can be claimed.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.13 Possible Double Spends of msg.value in Code Paths That Include More Than One Delegatecall ", "body": "  Resolution  The client team has responded with the following note:  Adding the recommended CI/CD task to verify that future routes are delegate safe.  Description  The usage of msg.value multiple times in the context of a single transaction is dangerous and may lead to loss of funds as previously seen (in a different variation) in the Opyn hack. We were not able to find any concrete instance of the described issue, however, we do see how this pitfall may become an issue in future delegatee contracts.  Examples  Every code path that includes multiple delegatecalls, including:  SocketGateway.swapAndMultiBridge  the swapAndBridge function in all the different route contracts.  Recommendation  Consider implementing this recommendation.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/02/socket/"}, {"title": "6.1 ERC20Lockable - inconsistent locking status    ", "body": "  Resolution  Issue was fixed by completely removing the unlock date mechanism.  Description  Vega_Token.is_tradable() will incorrectly return false if the token is never manually unlocked by the owner but unlock_time has passed, which will automatically unlock trading.  Examples  code/ERC20Lockable.sol:L48-L67  /**  @dev locked status, only applicable before unlock_date  /  bool public _is_locked = true;  /**  @dev Modifier that only allows function to run if either token is unlocked or time has expired.  Throws if called while token is locked.  /  modifier onlyUnlocked() {  require(!_is_locked || now > unlock_date);  _;  /**  @dev Internal function that unlocks token. Can only be ran before expiration (give that it's irrelevant after)  /  function _unlock() internal {  require(now <= unlock_date);  _is_locked = false;  Recommendation  declare _is_locked as private instead of public  create a getter method that correctly returns the locking status  function _isLocked() internal view {  return !_is_locked || now > unlock_date;  make modifier onlyUnlocked() use the newly created getter (_isLocked())  make Vega_Token.is_tradeable() use the newly created getter (_isLocked())  _unlock() should raise an errorcondition when called on an already unlocked contract  it could make sense to emit a  contract hast been unlocked  event for auditing purposes  7 Tool-Based Analysis  Several tools were used to perform automated analysis of the reviewed contracts. These issues were reviewed by the audit team, and relevant issues are listed in the Issue Details section.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/01/vega-vegatoken/"}, {"title": "7.1 MythX", "body": "  MythX is a security analysis API for Ethereum smart contracts. It performs multiple types of analysis, including fuzzing and symbolic execution, to detect many common vulnerability types. The tool was used for automated vulnerability discovery for all audited contracts and libraries. More details on MythX can be found at mythx.io.  The output of a MythX Full Mode analysis was reviewed by the audit team and no relevant issues were raised as part of the process.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2020/01/vega-vegatoken/"}, {"title": "7.2 Ethlint", "body": "  Ethlint is an open source project for linting Solidity code. Only security-related issues were reviewed by the audit team.  Below is the raw output of the Ethlint vulnerability scan:  Solium version 1.2.5  contracts/Address.sol  22:8    warning    Line contains trailing whitespace    no-trailing-whitespace  29:8    error      Avoid using Inline Assembly.         security/no-inline-assembly  contracts/ERC20Lockable.sol  58:8     warning    Provide an error message for require()             error-reason  58:31    warning    Avoid using 'now' (alias to 'block.timestamp').    security/no-block-members  66:8     warning    Provide an error message for require()             error-reason  66:16    warning    Avoid using 'now' (alias to 'block.timestamp').    security/no-block-members  contracts/ERC20StaticSupply.sol  15:4    warning    Line exceeds the limit of 145 characters    max-len  contracts/SafeERC20.sol  33:16    error      Only use indent of 12 spaces.             indentation  67:65    warning    Avoid using low-level function 'call'.    security/no-low-level-calls  contracts/Vega_Token.sol  9:1    warning    Line contains trailing whitespace    no-trailing-whitespace  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2020/01/vega-vegatoken/"}, {"title": "7.3 Surya", "body": "  Surya is a utility tool for smart contract systems. It provides a number of visual outputs and information about the structure of smart contracts. It also supports querying the function call graph in multiple ways to aid in the manual inspection and control flow analysis of contracts.  Below is a complete list of functions with their visibility and modifiers:  S\u016brya s Description Report  Files Description Table  contracts/Vega_Token.sol  b92b3c54b2f47a88fa9e84534046b462dbaee9aa  contracts/Address.sol  1213b0f150dd5e3f694c3721c44cb5cc3202b743  contracts/ERC20Detailed.sol  7e4d00c462120565201f28361b29201d1bfe0a34  contracts/IERC20.sol  72c15b6a16b7dc92e69ff97ccfe1958d9948e200  contracts/ERC20Lockable.sol  377447995444beee2b3c5342bfa9b1bbc1d08356  contracts/SafeMath.sol  c8bda5eb19c16d34bc48bf115229a9b967feb6ef  contracts/ERC20StaticSupply.sol  bf3e66af74470eed08d0e0f82b9a98705a745c7c  contracts/Ownable.sol  12ec51ec8a3b4eed6326434fd0f5926b40602778  contracts/Roles.sol  2c85acf184ae36f96ebafd8f6e26232ea459a711  contracts/SafeERC20.sol  ebd65ea9a0cdcb29bbbbf651a1076d51be031443  Contracts Description Table  Function Name  Visibility  Mutability  Modifiers  Vega_Token  Implementation  Ownable, ERC20StaticSupply  Public    ERC20StaticSupply  unlock_token  Public    onlyOwner  is_tradable  Public    NO   Address  Library  isContract  Internal \ud83d\udd12  toPayable  Internal \ud83d\udd12  ERC20Detailed  Implementation  IERC20  Public    NO   name  Public    NO   symbol  Public    NO   decimals  Public    NO   IERC20  Interface  totalSupply  External    NO   balanceOf  External    NO   transfer  External    NO   allowance  External    NO   approve  External    NO   transferFrom  External    NO   ERC20Lockable  Implementation  IERC20  _unlock  Internal \ud83d\udd12  totalSupply  Public    NO   balanceOf  Public    NO   transfer  Public    onlyUnlocked  allowance  Public    NO   approve  Public    NO   transferFrom  Public    onlyUnlocked  increaseAllowance  Public    NO   decreaseAllowance  Public    NO   _transfer  Internal \ud83d\udd12  _mint  Internal \ud83d\udd12  _burn  Internal \ud83d\udd12  _approve  Internal \ud83d\udd12  _burnFrom  Internal \ud83d\udd12  SafeMath  Library  add  Internal \ud83d\udd12  sub  Internal \ud83d\udd12  sub  Internal \ud83d\udd12  mul  Internal \ud83d\udd12  div  Internal \ud83d\udd12  div  Internal \ud83d\udd12  mod  Internal \ud83d\udd12  mod  Internal \ud83d\udd12  ERC20StaticSupply  Implementation  ERC20Detailed, Ownable, ERC20Lockable  Public    ERC20Detailed  issue  Public    onlyOwner  Ownable  Implementation  Internal \ud83d\udd12  owner  Public    NO   isOwner  Public    NO   renounceOwnership  Public    onlyOwner  transferOwnership  Public    onlyOwner  _transferOwnership  Internal \ud83d\udd12  Roles  Library  add  Internal \ud83d\udd12  remove  Internal \ud83d\udd12  has  Internal \ud83d\udd12  SafeERC20  Library  safeTransfer  Internal \ud83d\udd12  safeTransferFrom  Internal \ud83d\udd12  safeApprove  Internal \ud83d\udd12  safeIncreaseAllowance  Internal \ud83d\udd12  safeDecreaseAllowance  Internal \ud83d\udd12  callOptionalReturn  Private \ud83d\udd10  Legend  Function can modify state  Function is payable  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2020/01/vega-vegatoken/"}, {"title": "2.1 Accounts that claim incentives immediately before the migration will be stuck ", "body": "  Description  For accounts that existed before the migration to the new incentive calculation, the following happens when they claim incentives for the first time after the migration: First, the incentives that are still owed from before the migration are computed according to the old formula; the incentives since the migration are calculated according to the new logic, and the two values are added together. The first part   calculating the pre-migration incentives according to the old formula   happens in function MigrateIncentives.migrateAccountFromPreviousCalculation; the following lines are of particular interest in the current context:  code-582dc37/contracts/external/MigrateIncentives.sol:L39-L50  uint256 timeSinceMigration = finalMigrationTime - lastClaimTime;  // (timeSinceMigration * INTERNAL_TOKEN_PRECISION * finalEmissionRatePerYear) / YEAR  uint256 incentiveRate =  timeSinceMigration  .mul(uint256(Constants.INTERNAL_TOKEN_PRECISION))  // Migration emission rate is stored as is, denominated in whole tokens  .mul(finalEmissionRatePerYear).mul(uint256(Constants.INTERNAL_TOKEN_PRECISION))  .div(Constants.YEAR);  // Returns the average supply using the integral of the total supply.  uint256 avgTotalSupply = finalTotalIntegralSupply.sub(lastClaimIntegralSupply).div(timeSinceMigration);  The division in the last line will throw if  finalMigrationTime and lastClaimTime are equal. This will happen if an account claims incentives immediately before the migration happens   where  immediately  means in the same block. In such a case, the account will be stuck as any attempt to claim incentives will revert.  Recommendation  The function should return 0 if finalMigrationTime and lastClaimTime are equal. Moreover, the variable name timeSinceMigration is misleading, as the variable doesn t store the time since the migration but the time between the last incentive claim and the migration.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2022/03/notional-protocol-v2.1/"}, {"title": "2.2 type(T).max is inclusive ", "body": "  Description  Throughout the codebase, there are checks whether a number can be represented by a certain type.  Examples  code-582dc37/contracts/internal/nToken/nTokenSupply.sol:L71  require(accumulatedNOTEPerNToken < type(uint128).max); // dev: accumulated NOTE overflow  code-582dc37/contracts/internal/nToken/nTokenSupply.sol:L134  require(blockTime < type(uint32).max); // dev: block time overflow  code-582dc37/contracts/external/patchfix/MigrateIncentivesFix.sol:L86-L87  require(totalSupply <= type(uint96).max);  require(blockTime <= type(uint32).max);  Sometimes these checks use <=, sometimes they use <.  Recommendation  type(T).max is inclusive, i.e., it is the greatest number that can be represented with type T. Strictly speaking, it can and should therefore be used consistently with <= instead of <.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2022/03/notional-protocol-v2.1/"}, {"title": "2.3  mathematical mistake in comment ", "body": "  Description  In nTokenSupply.sol, there is a comment explaining why 18 decimal places for the accumulation precision is a good choice. There is a minor mistake in the calculation. It does not invalidate the reasoning, but as it is confusing for a reader, we recommend correcting it.  code-582dc37/contracts/internal/nToken/nTokenSupply.sol:L85-L88  // If we use 18 decimal places as the accumulation precision then we will overflow uint128 when  // a single nToken has accumulated 3.4 x 10^20 NOTE tokens. This isn't possible since the max  // NOTE that can accumulate is 10^17 (100 million NOTE in 1e8 precision) so we should be safe  // using 18 decimal places and uint128 storage slot  100 million NOTE in 1e8 precision is 10^16.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2022/03/notional-protocol-v2.1/"}, {"title": "6.1 Unexpected response in an assimilator s external call can lock-up the whole system    ", "body": "  Resolution  Comment from the development team:  When this was brought to our attention, it made the most sense to look at it from a bird s eye view. In the event that an assimilator does seize up either due to smart contract malfunctioning or to some type of governance decision in one of our dependencies, then depending on the severity of the event, it could either make it so that that particular dependency is unable to be transacted with or it could brick the pool altogether.  In the case of the latter severity  where the pool is bricked altogether for an extended period of time, then this means the end of that particular pool s life. In this case, we find it prudent to allow for the withdrawal of any asset still functional from the pool. Should such an event transpire, we have instituted functionality to allow users to withdraw individually from the pool s assets according to their Shell balances without being exposed to the inertia of the incapacitated assets.  In such an event, the owner of the pool can now trigger a partitioned state which is an end of life state for the pool in which users send Shells as normal until they decide to redeem any portion of them, after which they will only be able to redeem the portion of individual asset balances their Shell balance held claims on.  Description  The assimilators, being the  middleware  between a shell and all the external DeFi systems it interacts with, perform several external calls within their methods, as would be expected.  An example of such a contract is mainnetSUsdToASUsdAssimilator.sol (the contract can be found here).  The problem outlined in the title arises from the fact that Solidity automatically checks for the successful execution of the underlying message call (i.e., it bubbles up assertions and reverts) and, therefore, if any of these external systems changes in unexpected ways the call to the shell will revert itself.  This problem is immensely magnified by the fact that all the external methods in Loihi dealing with deposits, withdraws, and swaps rebalance the pool and, as a consequence, all of the assimilators for the reserve tokens get called at some point.  In summary, if any of the reserve tokens start, for some reason, refusing to complete a call to some of their methods, the whole protocol stops working, and the tokens are locked in forever (this is assuming the development team removes the safeApprove function from Loihi, v. https://github.com/ConsenSys/shell-protocol-audit-2020-06/issues/10).  Recommendation  There is no easy solution to this problem since calls to these external systems cannot simply be ignored. Shell needs successful responses from the reserve assimilators to be able to function properly.  One possible mitigation is to create a trustless mechanism based on repeated misbehavior by an external system to be able to remove a reserve asset from the pool.  Such a design could consist of an external function accessible to all actors that needs X confirmations over a period of Y blocks (or days, for that matter) with even spacing between them to be able to remove a reserve asset.  This means that no trust to the owners is implied (since this would require the extreme power to take user s tokens) and still maintains the healthy option of being able to remove faulty tokens from the pool.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.2 Certain functions lack input validation routines    ", "body": "  Resolution  Comment from the development team:  Now all functions in the Orchestrator revert on incorrect arguments.  All functions in Loihi in general revert on incorrect arguments.  Description  The functions should first check if the passed arguments are valid first. The checks-effects-interactions pattern should be implemented throughout the code.  These checks should include, but not be limited to:  uint should be larger than 0 when 0 is considered invalid  uint should be within constraints  int should be positive in some cases  length of arrays should match if more arrays are sent as arguments  addresses should not be 0x0  Examples  The function includeAsset does not do any checks before changing the contract state.  src/Loihi.sol:L59-L61  function includeAsset (address _numeraire, address _nAssim, address _reserve, address _rAssim, uint256 _weight) public onlyOwner {  shell.includeAsset(_numeraire, _nAssim, _reserve, _rAssim, _weight);  The internal function called by the public method includeAsset again doesn t check any of the data.  src/Controller.sol:L77-L97  function includeAsset (Shells.Shell storage shell, address _numeraire, address _numeraireAssim, address _reserve, address _reserveAssim, uint256 _weight) internal {  Assimilators.Assimilator storage _numeraireAssimilator = shell.assimilators[_numeraire];  _numeraireAssimilator.addr = _numeraireAssim;  _numeraireAssimilator.ix = uint8(shell.numeraires.length);  shell.numeraires.push(_numeraireAssimilator);  Assimilators.Assimilator storage _reserveAssimilator = shell.assimilators[_reserve];  _reserveAssimilator.addr = _reserveAssim;  _reserveAssimilator.ix = uint8(shell.reserves.length);  shell.reserves.push(_reserveAssimilator);  shell.weights.push(_weight.divu(1e18).add(uint256(1).divu(1e18)));  Similar with includeAssimilator.  src/Loihi.sol:L63-L65  function includeAssimilator (address _numeraire, address _derivative, address _assimilator) public onlyOwner {  shell.includeAssimilator(_numeraire, _derivative, _assimilator);  Again no checks are done in any function.  src/Controller.sol:L99-L106  function includeAssimilator (Shells.Shell storage shell, address _numeraire, address _derivative, address _assimilator) internal {  Assimilators.Assimilator storage _numeraireAssim = shell.assimilators[_numeraire];  shell.assimilators[_derivative] = Assimilators.Assimilator(_assimilator, _numeraireAssim.ix);  // shell.assimilators[_derivative] = Assimilators.Assimilator(_assimilator, _numeraireAssim.ix, 0, 0);  Not only does the administrator functions not have any checks, but also user facing functions do not check the arguments.  For example swapByOrigin does not check any of the arguments if you consider it calls MainnetDaiToDaiAssimilator.  src/Loihi.sol:L85-L89  function swapByOrigin (address _o, address _t, uint256 _oAmt, uint256 _mTAmt, uint256 _dline) public notFrozen returns (uint256 tAmt_) {  return transferByOrigin(_o, _t, _dline, _mTAmt, _oAmt, msg.sender);  It calls transferByOrigin and we simplify this example and consider we have _o.ix == _t.ix  src/Loihi.sol:L181-L187  function transferByOrigin (address _origin, address _target, uint256 _dline, uint256 _mTAmt, uint256 _oAmt, address _rcpnt) public notFrozen nonReentrant returns (uint256 tAmt_) {  Assimilators.Assimilator memory _o = shell.assimilators[_origin];  Assimilators.Assimilator memory _t = shell.assimilators[_target];  // TODO: how to include min target amount  if (_o.ix == _t.ix) return _t.addr.outputNumeraire(_rcpnt, _o.addr.intakeRaw(_oAmt));  In which case it can call 2 functions on an assimilatior such as MainnetDaiToDaiAssimilator.  The first called function is intakeRaw.  src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L42-L49  // transfers raw amonut of dai in, wraps it in cDai, returns numeraire amount  function intakeRaw (uint256 _amount) public returns (int128 amount_, int128 balance_) {  dai.transferFrom(msg.sender, address(this), _amount);  amount_ = _amount.divu(1e18);  And its result is used in outputNumeraire that again does not have any checks.  src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L83-L92  // takes numeraire amount of dai, unwraps corresponding amount of cDai, transfers that out, returns numeraire amount  function outputNumeraire (address _dst, int128 _amount) public returns (uint256 amount_) {  amount_ = _amount.mulu(1e18);  dai.transfer(_dst, amount_);  return amount_;  Recommendation  Implement the checks-effects-interactions as a pattern to write code. Add tests that check if all of the arguments have been validated.  Consider checking arguments as an important part of writing code and developing the system.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.3 Remove Loihi methods that can be used as backdoors by the administrator    ", "body": "  Resolution  Issue was partly addressed by the development team. However, the feature to add new assimilators is still present and that ultimately means that the administrators have power to run arbitrary bytecode.  Updated remediation response Since the development team still hadn t fully settled on a strategy for a mainnet launch, this was left as a residue even after the audit mitigation phase. However, at launch time, this issue was no longer present and all the assimilators are now defined at deploy-time, it is fully resolved.  Description  There are several functions in Loihi that give extreme powers to the shell administrator. The most dangerous set of those is the ones granting the capability to add assimilators.  Since assimilators are essentially a proxy architecture to delegate code to several different implementations of the same interface, the administrator could, intentionally or unintentionally, deploy malicious or faulty code in the implementation of an assimilator. This means that the administrator is essentially totally trusted to not run code that, for example, drains the whole pool or locks up the users  and LPs  tokens.  In addition to these, the function safeApprove allows the administrator to move any of the tokens the contract holds to any address regardless of the balances any of the users have.  This can also be used by the owner as a backdoor to completely drain the contract.  src/Loihi.sol:L643-L649  function safeApprove(address _token, address _spender, uint256 _value) public onlyOwner {  (bool success, bytes memory returndata) = _token.call(abi.encodeWithSignature(\"approve(address,uint256)\", _spender, _value));  require(success, \"SafeERC20: low-level call failed\");  Recommendation  Remove the safeApprove function and, instead, use a trustless escape-hatch mechanism like the one suggested in issue 6.1.  For the assimilator addition functions, our recommendation is that they are made completely internal, only callable in the constructor, at deploy time.  Even though this is not a big structural change (in fact, it reduces the attack surface), it is, indeed, a feature loss. However, this is the only way to make each shell a time-invariant system.  This would not only increase Shell s security but also would greatly improve the trust the users have in the protocol since, after deployment, the code is now static and auditable.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.4 Assimilators should implement an interface    ", "body": "  Resolution  Comment from the development team:  They now implement the interface in  src/interfaces/IAssimilator.sol .  Description  The Assimilators are one of the core components within the application. They are used to move the tokens and can be thought of as a  middleware  between the Shell Protocol application and any other supported tokens.  The methods attached to the assimilators are called throughout the application and they are a critical component of the whole system. Because of this fact, it is extremely important that they behave correctly.  A suggestion to restrict the possibility of errors when implementing them and when using them is to make all of the assimilators implement a unique specific interface. This way, any deviation would be immediately observed, right when the compilation happens.  Examples  Consider this example. The user calls swapByOrigin.  src/Loihi.sol:L85-L89  function swapByOrigin (address _o, address _t, uint256 _oAmt, uint256 _mTAmt, uint256 _dline) public notFrozen returns (uint256 tAmt_) {  return transferByOrigin(_o, _t, _dline, _mTAmt, _oAmt, msg.sender);  Which calls transferByOrigin. In transferByOrigin, if the origin index matches the target index, a different execution branch is activated.  src/Loihi.sol:L187  if (_o.ix == _t.ix) return _t.addr.outputNumeraire(_rcpnt, _o.addr.intakeRaw(_oAmt));  In this case we need the output of _o.addr.intakeRaw(_oAmt).  If we pick a random assimilator and check the implementation, we see the function intakeRaw needs to return the transferred amount.  src/assimilators/mainnet/daiReserves/mainnetCDaiToDaiAssimilator.sol:L52-L67  // takes raw cdai amount, transfers it in, calculates corresponding numeraire amount and returns it  function intakeRaw (uint256 _amount) public returns (int128 amount_) {  bool success = cdai.transferFrom(msg.sender, address(this), _amount);  if (!success) revert(\"CDai/transferFrom-failed\");  uint256 _rate = cdai.exchangeRateStored();  _amount = ( _amount * _rate ) / 1e18;  cdai.redeemUnderlying(_amount);  amount_ = _amount.divu(1e18);  However, with other implementations, the returns do not match. In the case of MainnetDaiToDaiAssimilator, it returns 2 values, which will make the Loihi contract work in this case but can misbehave in other cases, or even fail.  src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L42-L49  // transfers raw amonut of dai in, wraps it in cDai, returns numeraire amount  function intakeRaw (uint256 _amount) public returns (int128 amount_, int128 balance_) {  dai.transferFrom(msg.sender, address(this), _amount);  amount_ = _amount.divu(1e18);  Making all the assimilators implement one unique interface will enforce the functions to look the same from the outside.  Recommendation  Create a unique interface for the assimilators and make all the contracts implement that interface.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.5 Assimilators do not conform to the ERC20 specification    ", "body": "  Resolution  Comment from the development team:  All calls to compliant ERC20s now check for return booleans. Non compliant ERC20s are called with a function that checks for the success of the call.  Description  The assimilators in the codebase make heavy usage of both the transfer and transferFrom methods in the ERC20 standard.  Quoting the relevant parts of the specification of the standard:  Transfers _value amount of tokens to address _to, and MUST fire the Transfer event. The function SHOULD throw if the message caller s account balance does not have enough tokens to spend.  The transferFrom method is used for a withdraw workflow, allowing contracts to transfer tokens on your behalf. This can be used for example to allow a contract to transfer tokens on your behalf and/or to charge fees in sub-currencies. The function SHOULD throw unless the _from account has deliberately authorized the sender of the message via some mechanism.  We can see that, even though it is suggested that ERC20-compliant tokens do throw on the lack of authorization from the sender or lack of funds to complete the transfer, the standard does not enforce it.  This means that, in order to make the system both more resilient and future-proof, code in each implementation of current and future assimilators should check for the return value of both transfer and transferFrom call instead of just relying on the external contract to revert execution.  The extent of this issue is only mitigated by the fact that new assets are only added by the shell administrator and could, therefore, be audited prior to their addition.  Non-exhaustive Examples  src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L45  dai.transferFrom(msg.sender, address(this), _amount);  src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L64  dai.transfer(_dst, _amount);  Recommendation  Add a check for the return boolean of the function.  Example:  require(dai.transferFrom(msg.sender, address(this), _amount) == true);  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.6 Access to assimilators does not check for existence and allows delegation to the zeroth address    ", "body": "  Resolution  Comment from the development team:  All retrieval of assimilators now check that the assimilators address is not the zeroth address.  Description  For every method that allows to selectively withdraw, deposit, or swap tokens in Loihi, the user is allowed to specify addresses for the assimilators of said tokens (by inputting the addresses of the tokens themselves).  The shell then performs a lookup on a mapping called assimilators inside its main structure and uses the result of that lookup to delegate call the assimilator deployed by the shell administrator.  However, there are no checks for prior instantiation of a specific, supported token, effectively meaning that we can do a lookup on an all-zeroed-out member of that mapping and delegate call execution to the zeroth address.  The only thing preventing execution from going forward in this unwanted fashion is the fact that the ABI decoder expects a certain return data size from the interface implemented in Assimilator.sol.  For example, the 32 bytes expected as a result of this call:  src/Assimilators.sol:L58-L66  function viewNumeraireAmount (address _assim, uint256 _amt) internal returns (int128 amt_) {  // amount_ = IAssimilator(_assim).viewNumeraireAmount(_amt); // for production  bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, _amt); // for development  amt_ = abi.decode(_assim.delegate(data), (int128)); // for development  This is definitely an insufficient check since the interface for the assimilators might change in the future to include functions that have no return values.  Recommendation  Check for the prior instantiation of assimilators by including the following requirement:  require(shell.assimilators[<TOKEN_ADDRESS>].ix != 0);  In all the functions that access the assimilators mapping and change the indexes to be 1-based instead pf 0-based.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.7 Math library s fork has problematic changes    ", "body": "  Description  The math library ABDK Libraries for Solidity was forked and modified to add a few unsafe_* functions.  unsafe_add  unsafe_sub  unsafe_mul  unsafe_div  unsafe_abs  The problem which was introduced is that unsafe_add ironically is not really unsafe, it is as safe as the original add function. It is, in fact, identical to the safe add function.  src/ABDKMath64x64.sol:L102-L113  /**  Calculate x + y.  Revert on overflow.  @param x signed 64.64-bit fixed point number  @param y signed 64.64-bit fixed point number  @return signed 64.64-bit fixed point number  /  function add (int128 x, int128 y) internal pure returns (int128) {  int256 result = int256(x) + y;  require (result >= MIN_64x64 && result <= MAX_64x64);  return int128 (result);  src/ABDKMath64x64.sol:L115-L126  /**  Calculate x + y.  Revert on overflow.  @param x signed 64.64-bit fixed point number  @param y signed 64.64-bit fixed point number  @return signed 64.64-bit fixed point number  /  function unsafe_add (int128 x, int128 y) internal pure returns (int128) {  int256 result = int256(x) + y;  require (result >= MIN_64x64 && result <= MAX_64x64);  return int128 (result);  Fortunately, unsafe_add is not used anywhere in the code.  However, unsafe_abs was changed from this:  src/ABDKMath64x64.sol:L322-L331  /**  Calculate |x|.  Revert on overflow.  @param x signed 64.64-bit fixed point number  @return signed 64.64-bit fixed point number  /  function abs (int128 x) internal pure returns (int128) {  require (x != MIN_64x64);  return x < 0 ? -x : x;  To this:  src/ABDKMath64x64.sol:L333-L341  /**  Calculate |x|.  Revert on overflow.  @param x signed 64.64-bit fixed point number  @return signed 64.64-bit fixed point number  /  function unsafe_abs (int128 x) internal pure returns (int128) {  return x < 0 ? -x : x;  The check that was removed, is actually an important check:  require (x != MIN_64x64);  src/ABDKMath64x64.sol:L19  int128 private constant MIN_64x64 = -0x80000000000000000000000000000000;  The problem is that for an int128 variable that is equal to -0x80000000000000000000000000000000, there is no absolute value within the constraints of int128.  Recommendation  Remove unused unsafe_* functions and try to find other ways of doing unsafe math (if it is fundamentally important) without changing existing, trusted, already audited code.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.8 Use one file for each contract or library    ", "body": "  Resolution  Issue fixed by the development team.  Description  The repository contains a lot of contracts and libraries that are added in the same file as another contract or library.  Organizing the code in this manner makes it hard to navigate, develop and audit. It is a best practice to have each contract or library in its own file. The file also needs to bear the name of the hosted contract or library.  Examples  src/Shells.sol:L20  library SafeERC20Arithmetic {  src/Shells.sol:L32  library Shells {  src/Loihi.sol:L26-L28  contract ERC20Approve {  function approve (address spender, uint256 amount) public returns (bool);  src/Loihi.sol:L30  contract Loihi is LoihiRoot {  src/Assimilators.sol:L19  library Delegate {  src/Assimilators.sol:L33  library Assimilators {  Recommendation  Split up contracts and libraries in single files.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.9 Remove debugging code from the repository    ", "body": "  Resolution  Issue fixed but he development team.  Description  Throughout the repository, there is source code from the development stage that was used for debugging the functionality and was not removed.  This should not be present in the source code and even if they are used while functionality is developed, they should be removed after the functionality was implemented.  Examples  src/Shells.sol:L63-L67  event log(bytes32);  event log_int(bytes32, int256);  event log_ints(bytes32, int256[]);  event log_uint(bytes32, uint256);  event log_uints(bytes32, uint256[]);  src/Assimilators.sol:L44-L46  event log(bytes32);  event log_uint(bytes32, uint256);  event log_int(bytes32, int256);  src/Controller.sol:L33-L37  event log(bytes32);  event log_int(bytes32, int128);  event log_int(bytes32, int);  event log_uint(bytes32, uint);  event log_addr(bytes32, address);  src/LoihiRoot.sol:L53  event log(bytes32);  src/Shells.sol:L63-L67  event log(bytes32);  event log_int(bytes32, int256);  event log_ints(bytes32, int256[]);  event log_uint(bytes32, uint256);  event log_uints(bytes32, uint256[]);  src/Loihi.sol:L470-L474  event log_int(bytes32, int);  event log_ints(bytes32, int128[]);  event log_uint(bytes32, uint);  event log_uints(bytes32, uint[]);  event log_addrs(bytes32, address[]);  src/assimilators/mainnet/cdaiReserves/mainnetDaiToCDaiAssimilator.sol:L35-L36  event log_uint(bytes32, uint256);  event log_int(bytes32, int256);  src/assimilators/mainnet/cusdcReserves/mainnetUsdcToCUsdcAssimilator.sol:L38  event log_uint(bytes32, uint256);  src/Loihi.sol:L51  shell.testHalts = true;  src/LoihiRoot.sol:L79-L83  function setTestHalts (bool _testOrNotToTest) public {  shell.testHalts = _testOrNotToTest;  src/Shells.sol:L60  bool testHalts;  Recommendation  Remove the debug functionality at the end of the development cycle of each functionality.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.10 Tests should not fail    ", "body": "  Resolution  Comment from the development team:  The failing tests are because we made minute changes to our present model (changes in applying the base fee -  epsilon ), so in a sense, rather than failing they just need updating. Many of them are also an artifact of architecting the tests in such a way that they can be run against arbitrary parameter sets - or in different  suites .  Description  The role of the tests should be to make sure the application behaves properly. This should include positive tests (functionality that should be implemented) and negative tests (behavior stopped or limited by the application).  The test suite should pass 100% of the tests. After spending time with the development team, we managed to ask for the changes that allowed us to run the tests suite. This revealed that out of the 555 tests, 206 are failing. This staggering number does not allow us to check what the problem is and makes anybody running tests ignore them completely.  Tests should be an integral part of the codebase, and they should be considered as important (or even more important) than the code itself. One should be able to recreate the whole codebase by just having the tests.  Recommendation  Update tests in order for the whole of the test suite to pass.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.11 Remove commented out code from the repository    ", "body": "  Description  Having commented out code increases the cognitive load on an already complex system. Also, it hides the important parts of the system that should get the proper attention, but that attention gets to be diluted.  There is no code that is important enough to be left commented out in a repository. Git branching should take care of having different code versions or diffs should show what was before.  If there is commented out code, this also has to be maintained; it will be out of date if other parts of the system are changed, and the tests will not pick that up.  The main problem is that commented code adds confusion with no real benefit. Code should be code, and comments should be comments.  Examples  Commented out code should be removed or dealt with in a separate branch that is later included in the master branch.  src/Assimilators.sol:L48-L56  function viewRawAmount (address _assim, int128 _amt) internal returns (uint256 amount_) {  // amount_ = IAssimilator(_assim).viewRawAmount(_amt); // for production  bytes memory data = abi.encodeWithSelector(iAsmltr.viewRawAmount.selector, _amt.abs()); // for development  amount_ = abi.decode(_assim.delegate(data), (uint256)); // for development  src/Assimilators.sol:L58-L66  function viewNumeraireAmount (address _assim, uint256 _amt) internal returns (int128 amt_) {  // amount_ = IAssimilator(_assim).viewNumeraireAmount(_amt); // for production  bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, _amt); // for development  amt_ = abi.decode(_assim.delegate(data), (int128)); // for development  src/Assimilators.sol:L58-L66  function viewNumeraireAmount (address _assim, uint256 _amt) internal returns (int128 amt_) {  // amount_ = IAssimilator(_assim).viewNumeraireAmount(_amt); // for production  bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, _amt); // for development  amt_ = abi.decode(_assim.delegate(data), (int128)); // for development  src/Controller.sol:L99-L106  function includeAssimilator (Shells.Shell storage shell, address _numeraire, address _derivative, address _assimilator) internal {  Assimilators.Assimilator storage _numeraireAssim = shell.assimilators[_numeraire];  shell.assimilators[_derivative] = Assimilators.Assimilator(_assimilator, _numeraireAssim.ix);  // shell.assimilators[_derivative] = Assimilators.Assimilator(_assimilator, _numeraireAssim.ix, 0, 0);  src/Loihi.sol:L596-L618  function transfer (address _recipient, uint256 _amount) public nonReentrant returns (bool) {  // return shell.transfer(_recipient, _amount);  function transferFrom (address _sender, address _recipient, uint256 _amount) public nonReentrant returns (bool) {  // return shell.transferFrom(_sender, _recipient, _amount);  function approve (address _spender, uint256 _amount) public nonReentrant returns (bool success_) {  // return shell.approve(_spender, _amount);  function increaseAllowance(address _spender, uint256 _addedValue) public returns (bool success_) {  // return shell.increaseAllowance(_spender, _addedValue);  function decreaseAllowance(address _spender, uint256 _subtractedValue) public returns (bool success_) {  // return shell.decreaseAllowance(_spender, _subtractedValue);  function balanceOf (address _account) public view returns (uint256) {  // return shell.balances[_account];  src/test/deposits/suiteOne.t.sol:L15-L29  // function test_s1_selectiveDeposit_noSlippage_balanced_10DAI_10USDC_10USDT_2p5SUSD_NO_HACK () public logs_gas {  //     uint256 newShells = super.noSlippage_balanced_10DAI_10USDC_10USDT_2p5SUSD();  //     assertEq(newShells, 32499999216641686631);  // }  // function test_s1_selectiveDeposit_noSlippage_balanced_10DAI_10USDC_10USDT_2p5SUSD_HACK () public logs_gas {  //     uint256 newShells = super.noSlippage_balanced_10DAI_10USDC_10USDT_2p5SUSD_HACK();  //     assertEq(newShells, 32499999216641686631);  // }  src/test/deposits/depositsTemplate.sol:L40-L56  // function noSlippage_balanced_10DAI_10USDC_10USDT_2p5SUSD_HACK () public returns (uint256 shellsMinted_) {  //     uint256 startingShells = l.proportionalDeposit(300e18);  //     uint256 gas = gasleft();  //     shellsMinted_ = l.depositHack(  //         address(dai), 10e18,  //         address(usdc), 10e6,  //         address(usdt), 10e6,  //         address(susd), 2.5e18  //     );  //     emit log_uint(\"gas for deposit\", gas - gasleft());  // }  Recommendation  Remove all the commented out code or transform it into comments.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.12 Should check if the asset already exists when adding a new asset    ", "body": "  Resolution  Comment from the development team:  We have decided not to have dynamic adding/removing of assets in this release.  Description  The public function includeAsset  src/Loihi.sol:L128-L130  function includeAsset (address _numeraire, address _nAssim, address _reserve, address _rAssim, uint256 _weight) public onlyOwner {  shell.includeAsset(_numeraire, _nAssim, _reserve, _rAssim, _weight);  Calls the internal includeAsset implementation  src/Controller.sol:L72  function includeAsset (Shells.Shell storage shell, address _numeraire, address _numeraireAssim, address _reserve, address _reserveAssim, uint256 _weight) internal {  But there is no check to see if the asset already exists in the list. Because the check was not done, shell.numeraires can contain multiple identical instances.  src/Controller.sol:L80  shell.numeraires.push(_numeraireAssimilator);  Recommendation  Check if the _numeraire already exists before invoking includeAsset.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.13 Check return values for both internal and external calls    ", "body": "  Resolution  Comment from the development team:  This doesn t seem feasible. Checking how much was transferred to/from the contract would pose unacceptable gas costs. Because of these constraints, the value returned by the assimilator methods never touches the outside world. They are just converted into numeraire format and returned, so checking these values would not provide any previously unknown information.  Description  There are some cases where functions which return values are called throughout the source code but the return values are not processed, nor checked.  The returns should in principle be handled and checked for validity to provide more robustness to the code.  Examples  The function intakeNumeraire receives a number of tokens and returns how many tokens were transferred to the contract.  src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L51-L59  // transfers numeraire amount of dai in, wraps it in cDai, returns raw amount  function intakeNumeraire (int128 _amount) public returns (uint256 amount_) {  // truncate stray decimals caused by conversion  amount_ = _amount.mulu(1e18) / 1e3 * 1e3;  dai.transferFrom(msg.sender, address(this), amount_);  Similarly, the function outputNumeraire receives a destination address and an amount of token for withdrawal and returns a number of transferred tokens to the specified address.  src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L83-L92  // takes numeraire amount of dai, unwraps corresponding amount of cDai, transfers that out, returns numeraire amount  function outputNumeraire (address _dst, int128 _amount) public returns (uint256 amount_) {  amount_ = _amount.mulu(1e18);  dai.transfer(_dst, amount_);  return amount_;  However, the results are not handled in the main contract.  src/Loihi.sol:L497  shell.numeraires[i].addr.intakeNumeraire(_shells.mul(shell.weights[i]));  src/Loihi.sol:L509  shell.numeraires[i].addr.intakeNumeraire(_oBals[i].mul(_multiplier));  src/Loihi.sol:L586  shell.reserves[i].addr.outputNumeraire(msg.sender, _oBals[i].mul(_multiplier));  A sanity check can be done to make sure that more than 0 tokens were transferred to the contract.  unit intakeAmount = shell.numeraires[i].addr.intakeNumeraire(_shells.mul(shell.weights[i]));  require(intakeAmount > 0, \"Must intake a positive number of tokens\");  Recommendation  Handle all return values everywhere returns exist and add checks to make sure an expected value was returned.  If the return values are never used, consider not returning them at all.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.14 Interfaces do not need to be implemented for the compiler to access their selectors.    ", "body": "  Resolution  Comment from the development team:  This is the case for the version we used, solc 0.5.15. Versions 0.5.17 and 0.6.* do not require it.  Description  In Assimilators.sol the interface for the assimilators is implemented in a state variable constant as an interface to the zeroth address in order to make use of it s selectors.  src/Assimilators.sol:L37  IAssimilator constant iAsmltr = IAssimilator(address(0));  This pattern is unneeded since you can reference selectors by using the imported interface directly without any implementation. It hinders both gas costs and readability of the code.  Examples  Recommendation  Delete line 37 in Assimilators.sol and instead of getting selectors through:  src/Assimilators.sol:L62  bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, _amt); // for development  use the expression:  IAssimilator.viewRawAmount.selector  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.15 Use consistent interfaces for functions in the same group    ", "body": "  Description  In the file Shells.sol, there also is a library that is being used internally for safe adds and subtractions.  This library has 2 functions.  add which receives 2 arguments, x and y.  src/Shells.sol:L22-L24  function add(uint x, uint y) internal pure returns (uint z) {  require((z = x + y) >= x, \"add-overflow\");  sub which receives 3 arguments x, y and _errorMessage.  src/Shells.sol:L26-L28  function sub(uint x, uint y, string memory _errorMessage) internal pure returns (uint z) {  require((z = x - y) <= x, _errorMessage);  In order to reduce the cognitive load on the auditors and developers alike, somehow-related functions should have coherent logic and interfaces. Both of the functions either need to have 2 arguments, with an implied error message passed to require, or both functions need to have 3 arguments, with an error message that can be specified.  Recommendation  Update the functions to be coherent with other related functions.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.16 Code coverage should be close to 100%    ", "body": "  Resolution  Comment from the development team:  This is true for all aspects of the bonding curve.  Things that have been tested on Kovan with the frontend dapp but could use a unit test are things relevant to sending shell tokens - issuing approvals, transfers and transferfroms.  The adding of assets and assimilators are tested by proxy because they are dependencies for the entire behavior of the bonding surface.  For this release, we plan on having the assets and the assimilators frozen at launch, so there is not much to test regarding continuous updating/changing of assets and assimilators.  We have, however, considered allowing for the dynamic adjustment of weights in addition to parameters.  Description  Code coverage is a measure used to describe how much of the source code is executed during the automated test suite. A system with high code coverage, measured as lines of code executed, has a lower chance to contain undiscovered bugs.  The codebase does not have any information about the code coverage.  Recommendation  Make the test suite output code coverage and add more tests to handle the lines of code that are not touched by any tests.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.17 Consider emitting an event when changing the frozen state of the contract    ", "body": "  Description  The function freeze allows the owner to freeze and unfreeze the contract.  src/Loihi.sol:L144-L146  function freeze (bool _freeze) public onlyOwner {  frozen = _freeze;  The common pattern when doing actions important for the outside of the blockchain is to emit an event when the action is successful.  It s probably a good idea to emit an event stating the contract was frozen or unfrozen.  Recommendation  Create an event that displays the current state of the contract.  event Frozen(bool frozen);  And emit the event when frozen is called.  function freeze (bool _freeze) public onlyOwner {  frozen = _freeze;  emit Frozen(_freeze);  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.18 Function supportsInterface can be restricted to pure    ", "body": "  Description  The function supportsInterface returns a bool stating that the contract supports one of the defined interfaces.  src/Loihi.sol:L140-L142  function supportsInterface (bytes4 interfaceID) public returns (bool) {  return interfaceID == ERC20ID || interfaceID == ERC165ID;  The function does not access or change the state of the contract, this is why it can be restricted to pure.  Recommendation  Restrict the function definition to pure.  function supportsInterface (bytes4 interfaceID) public pure returns (bool) {  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "6.19 Use more consistent function naming (includeAssimilator / excludeAdapter)    ", "body": "  Description  The function includeAssimilator adds a new assimilator to the list  src/Controller.sol:L98  shell.assimilators[_derivative] = Assimilators.Assimilator(_assimilator, _numeraireAssim.ix);  The function excludeAdapter removes the specified assimilator from the list  src/Loihi.sol:L137  delete shell.assimilators[_assimilator];  Recommendation  Consider renaming the function excludeAdapter to removeAssimilator and moving the logic of adding and removing in the same source file.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/06/shell-protocol/"}, {"title": "5.1 Tokens with no decimals can be locked in Niftyswap   ", "body": "  Resolution  This will be addressed by only listing tokens with at least 2 decimals. This should be well documented in the Niftyswap repository and code comments.  Description  Assume the Niftyswap exchange has:  wrapped DAI as the base currency, and  it s ERC1155 contract has a token called  Blue Dragons , which are a  low fungibility  token, with zero decimals, and a total supply of 100.  Consider the following scenario on the Niftyswap exchange:  10 people each add 1,000 DAI, and 1 BlueDragon. They get 1,000 pool tokens each.  Someone buys 1 BlueDragon, at a price of 1,117 base Tokens (per the constant product pricing model).  Niftyswap s balances are now 11,117 baseTokens, 9 Blue Dragons.  Someone removes liquidity by burning 1,000 pool tokens:  They would get 1111 base tokens (1000 * 11,117/ 10000). They would get 0 Blue Dragons due to the rounding on integer math.  Recommendation  Through conversation with the developers, we agreed the right approach is for tokens to have at least 2 decimals to minimize the negative effects of rounding down.  ", "labels": ["Consensys", "Major", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/02/horizon-games/"}, {"title": "5.2 Incorrect response from price feed if called during an onERC1155Received callback   ", "body": "  Resolution  The design will not be modified. Horizon Games should clearly document this risk for 3rd parties seeking to use Niftyswap as a price feed.  Description  The ERC 1155 standard requires that smart contracts must implement onERC1155Received and onERC1155BatchReceived to accept transfers.  This means that on any token received, code run on the receiving smart contract.  In NiftyswapExchange when adding / removing liquidity or buying tokens, the methods mentioned above are called when the tokens are sent. When this happens, the state of the contract is changed but not completed, the tokens are sent to the receiving smart contract but the state is not completely updated.  This happens in these cases  _baseToToken (when buying tokens)  code/niftyswap/contracts/exchange/NiftyswapExchange.sol:L163-L169  // // Refund Base Token if any  if (totalRefundBaseTokens > 0) {  baseToken.safeTransferFrom(address(this), _recipient, baseTokenID, totalRefundBaseTokens, \"\");  // Send Tokens all tokens purchased  token.safeBatchTransferFrom(address(this), _recipient, _tokenIds, _tokensBoughtAmounts, \"\");  _removeLiquidity  code/niftyswap/contracts/exchange/NiftyswapExchange.sol:L485-L487  // Transfer total Base Tokens and all Tokens ids  baseToken.safeTransferFrom(address(this), _provider, baseTokenID, totalBaseTokens, \"\");  token.safeBatchTransferFrom(address(this), _provider, _tokenIds, tokenAmounts, \"\");  _addLiquidity  code/niftyswap/contracts/exchange/NiftyswapExchange.sol:L403-L407  // Mint liquidity pool tokens  _batchMint(_provider, _tokenIds, liquiditiesToMint, \"\");  // Transfer all Base Tokens to this contract  baseToken.safeTransferFrom(_provider, address(this), baseTokenID, totalBaseTokens, abi.encode(DEPOSIT_SIG));  Each of these examples send some tokens to the smart contract, which triggers calling some code on the receiving smart contract.  While these methods have the nonReentrant modifier which protects them from re-netrancy, the result of the methods getPrice_baseToToken and getPrice_tokenToBase is affected. These 2 methods do not have the nonReentrant modifier.  The price reported by the getPrice_baseToToken and getPrice_tokenToBase methods is incorrect (until after the end of the transaction) because they rely on the number of tokens owned by the NiftyswapExchange; which between the calls is not finalized. Hence the price reported will be incorrect.  This gives the smart contract which receives the tokens, the opportunity to use other systems (if they exist) that rely on the result of getPrice_baseToToken and getPrice_tokenToBase to use the returned price to its advantage.  It s important to note that this is a bug only if other systems rely on the price reported by this NiftyswapExchange. Also the current contract is not affected, nor its balances or internal ledger, only other systems relying on its reported price will be fooled.  Recommendation  Because there is no way to enforce how other systems work, a restriction can be added on NiftyswapExchange to protect other systems (if any) that rely on NiftyswapExchange for price discovery.  Adding a nonReentrant modifier on the view methods getPrice_baseToToken and getPrice_tokenToBase will add a bit of protection for the ecosystem.  ", "labels": ["Consensys", "Medium", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/02/horizon-games/"}, {"title": "4.1 Unhandled return values of transfer and transferFrom    ", "body": "  Resolution                           The issue was fixed by using OpenZeppelin s   ERC20 implementations are not always consistent. Some implementations of transfer and transferFrom could return  false  on failure instead of reverting. It is safer to wrap such calls into require() statements to these failures.  code/contracts/stake/StakedToken.sol:L92  IERC20(STAKED_TOKEN).transferFrom(msg.sender, address(this), amount);  code/contracts/stake/StakedToken.sol:L156  REWARD_TOKEN.transferFrom(REWARDS_VAULT, to, amountToWithdraw);  code/contracts/stake/StakedToken.sol:L125  IERC20(STAKED_TOKEN).transfer(to, amount);  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/09/aave-safety-module/"}, {"title": "4.2 Staking cooldown can be avoided for a part of the funds    ", "body": "  Resolution  The cooldown window will be set to much higher value (to the order of days) in production. The mechanism is sufficient to prevent stakers from withdrawing if the cooldown window is long enough while also being larger than the withdrawal window.  Aave is planning to introduce a slashing mechanism for the staking system in the future. In order to prevent stakers from withdrawing their stake immediately, the team has added a  cooldown  mechanism. The idea is that whenever stakers want to redeem the stake, they should call the cooldown function and wait for COOLDOWN_SECONDS. After that, a time period called UNSTAKE_WINDOW starts during which the stake can be withdrawn.  However, depending on the settings ( COOLDOWN_SECONDS  and  UNSTAKE_WINDOW  values), various algorithms exist that would allow users to optimize their withdrawal tactics. By using such tactics, stakers may be able to withdraw at least a part of the stake immediately.  Let s assume that the values are the same as in tests: COOLDOWN_SECONDS == 1 hour and UNSTAKE_WINDOW == 30 minutes. Stakers can split their stake into 3 parts and call cooldown for one of them every 30 minutes. That would ensure that at least 1/3 of the stake can be withdrawn immediately at any time. And on average, more than 1/2 of the stake can be withdrawn immediately.  Remediation:  Make sure that the COOLDOWN_SECONDS value is much larger than the UNSTAKE_WINDOW. This will make any cooldown optimization techniques less effective.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/09/aave-safety-module/"}, {"title": "4.3  code quality issues    ", "body": "  Resolution  all issues have been fixed in production.  We recommend the following improvements:  Fix todos  Clean up all TODOs before going into production:  code/contracts/stake/AaveDistributionManager.sol:L44-L46  function configureAssets(DistributionTypes.AssetConfigInput[] calldata assetsConfigInput)  external  //    override TODO: create interface  Fix incorrect NatSpec comments  Clean up NatSpec comments to improve readability.  The function claimRewards() in StakedToken has the same description as the stake() function:  code/contracts/stake/StakedToken.sol:L141-L145  One function argument is missing from the docstrings for claimRewards() in AaveIncentivesController:  @dev Stakes tokens to start earning rewards  @param to Address to stake for  @param amount Amount to stake  **/  function claimRewards(address to, uint256 amount) external override {  One function argument is missing from the docstrings for claimRewards() in AaveIncentivesController:  code/contracts/stake/AaveIncentivesController.sol:L97-L107  /**  @dev Claims reward for an user, on all the assets of the lending pool, accumulating the pending rewards  @param amount Amount of rewards to claim  @param to Address that will be receiving the rewards  @return Rewards claimed  **/  function claimRewards(  uint256 amount,  address to,  bool stake  ) external override returns (uint256) {  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/09/aave-safety-module/"}, {"title": "4.1 StableSwapOperatorV1 - resistantFei value is not correct in the resistantBalanceAndFei function ", "body": "  Description  The resistantBalanceAndFei function of a PCVDeposit contract is supposed to return the amount of funds that the contract controls; it is then used to evaluate the total value of PCV (collateral in the protocol). Additionally, this function returns the number of FEI tokens that are protocol-controlled. These FEI tokens are  temporarily minted ; they are not backed up by the collateral and shouldn t be used in calculations that determine the collateralization of the protocol.  Ideally, the amount of these FEI tokens should be the same during the deposit, withdrawal, and the resistantBalanceAndFei function call. In the StableSwapOperatorV1  contract, all these values are totally different:  during the deposit, the amount of required FEI tokens is calculated. It s done in a way so the values of FEI and 3pool tokens in the metapool should be equal after the deposit. So if there is the initial imbalance of FEI and 3pool tokens, the deposit value of these tokens will be different: code/contracts/pcv/curve/StableSwapOperatorV1.sol:L156-L171 // get the amount of tokens in the pool (uint256 _3crvAmount, uint256 _feiAmount) = (     IStableSwap2(pool).balances(_3crvIndex),     IStableSwap2(pool).balances(_feiIndex) ); // ... and the expected amount of 3crv in it after deposit uint256 _3crvAmountAfter = _3crvAmount + _3crvBalanceAfter;  // get the usd value of 3crv in the pool uint256 _3crvUsdValue = _3crvAmountAfter * IStableSwap3(_3pool).get_virtual_price() / 1e18;  // compute the number of FEI to deposit uint256 _feiToDeposit = 0; if (_3crvUsdValue > _feiAmount) {     _feiToDeposit = _3crvUsdValue - _feiAmount; }  during the withdrawal, the FEI and 3pool tokens are withdrawn in the same proportion as they are present in the metapool: code/contracts/pcv/curve/StableSwapOperatorV1.sol:L255-L258 uint256[2] memory _minAmounts; // [0, 0] IERC20(pool).approve(pool, _lpToWithdraw); uint256 _3crvBalanceBefore = IERC20(_3crv).balanceOf(address(this)); IStableSwap2(pool).remove_liquidity(_lpToWithdraw, _minAmounts);  in the resistantBalanceAndFei function, the value of protocol-controlled FEI tokens and the value of 3pool tokens deposited are considered equal: code/contracts/pcv/curve/StableSwapOperatorV1.sol:L348-L349 resistantBalance = _lpPriceUSD / 2; resistantFei = resistantBalance;  Some of these values may be equal under some circumstances, but that is not enforced. After one of the steps (deposit or withdrawal), the total PCV value and collateralization may be changed significantly.  Recommendation  Make sure that deposit, withdrawal, and the resistantBalanceAndFei are consistent and won t instantly change the PCV value significantly.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.2 CollateralizationOracle - Fei in excluded deposits contributes to userCirculatingFei ", "body": "  Description  CollateralizationOracle.pcvStats iterates over all deposits, queries the resistant balance and FEI for each deposit, and accumulates the total value of the resistant balances and the total resistant FEI. Any Guardian or Governor can exclude (and re-include) a deposit that has become problematic in some way, for example, because it is reporting wrong numbers. Finally, the pcvStats function computes the userCirculatingFei as the total FEI supply minus the accumulated resistant FEI balances; the idea here is to determine the amount of  free  FEI, or FEI that is not PCV. However, the FEI balances from excluded deposits contribute to the userCirculatingFei, although they are clearly not  free  FEI. That leads to a wrong protocolEquity and a skewed collateralization ratio and might therefore have a significant impact on the economics of the system.  It should be noted that even the exclusion from the total PCV leads to a protocolEquity and a  collateralization ratio that could be considered skewed (again, it  might depend on the exact reasons for exclusion), but  adding  the missing FEI to the userCirculatingFei distorts these numbers even more.  In the extreme scenario that all deposits have been excluded, the entire Fei supply is currently reported as userCirculatingFei.  code/contracts/oracle/CollateralizationOracle.sol:L278-L328  /// @notice returns the Protocol-Controlled Value, User-circulating FEI, and  ///         Protocol Equity.  /// @return protocolControlledValue : the total USD value of all assets held  ///         by the protocol.  /// @return userCirculatingFei : the number of FEI not owned by the protocol.  /// @return protocolEquity : the difference between PCV and user circulating FEI.  ///         If there are more circulating FEI than $ in the PCV, equity is 0.  /// @return validityStatus : the current oracle validity status (false if any  ///         of the oracles for tokens held in the PCV are invalid, or if  ///         this contract is paused).  function pcvStats() public override view returns (  uint256 protocolControlledValue,  uint256 userCirculatingFei,  int256 protocolEquity,  bool validityStatus  ) {  uint256 _protocolControlledFei = 0;  validityStatus = !paused();  // For each token...  for (uint256 i = 0; i < tokensInPcv.length(); i++) {  address _token = tokensInPcv.at(i);  uint256 _totalTokenBalance  = 0;  // For each deposit...  for (uint256 j = 0; j < tokenToDeposits[_token].length(); j++) {  address _deposit = tokenToDeposits[_token].at(j);  // ignore deposits that are excluded by the Guardian  if (!excludedDeposits[_deposit]) {  // read the deposit, and increment token balance/protocol fei  (uint256 _depositBalance, uint256 _depositFei) = IPCVDepositBalances(_deposit).resistantBalanceAndFei();  _totalTokenBalance += _depositBalance;  _protocolControlledFei += _depositFei;  // If the protocol holds non-zero balance of tokens, fetch the oracle price to  // increment PCV by _totalTokenBalance * oracle price USD.  if (_totalTokenBalance != 0) {  (Decimal.D256 memory _oraclePrice, bool _oracleValid) = IOracle(tokenToOracle[_token]).read();  if (!_oracleValid) {  validityStatus = false;  protocolControlledValue += _oraclePrice.mul(_totalTokenBalance).asUint256();  userCirculatingFei = fei().totalSupply() - _protocolControlledFei;  protocolEquity = int256(protocolControlledValue) - int256(userCirculatingFei);  Recommendation  It is unclear how to fix this. One might want to exclude the FEI in excluded deposits entirely from the calculation, but not knowing the amount was the reason to exclude the deposit in the first place. One option could be to let the entity that excludes a deposit specify substitute values that should be used instead of querying the numbers from the deposit. However, it is questionable whether this approach is practical if the numbers we d like to see as substitute values change quickly or repeatedly over time. Ultimately, the querying function itself should be fixed. Moreover, as the substitute values can dramatically impact the system economics, we d only like to trust the Governor with this and not give this permission to a Guardian. However, the original intention was to give a role with less trust than the Governor the possibility to react quickly to a deposit that reports wrong numbers; if the exclusion of deposits becomes the Governor s privilege, such a quick and lightweight intervention isn t possible anymore.  Independently, we recommend taking proper care of the situation that all deposits   or just too many   have been excluded, for example, by setting the returned validityStatus to false, as in this case, there is not enough information to compute the collateralization ratio even as a crude approximation.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.3 StableSwapOperatorV1 - the _minLpOut value is not accurate ", "body": "  Description  When depositing, the expected minimum amount of the output LP tokens is calculated:  code/contracts/pcv/curve/StableSwapOperatorV1.sol:L194-L200  // slippage check on metapool deposit  uint256 _balanceDeposited = IERC20(pool).balanceOf(address(this)) - _balanceBefore;  uint256 _metapoolVirtualPrice = IStableSwap2(pool).get_virtual_price();  uint256 _minLpOut = (_feiToDeposit + _3crvBalanceAfter) * 1e18 / _metapoolVirtualPrice * (Constants.BASIS_POINTS_GRANULARITY - depositMaxSlippageBasisPoints) / Constants.BASIS_POINTS_GRANULARITY;  require(_balanceDeposited >= _minLpOut, \"StableSwapOperatorV1: metapool deposit slippage too high\");  The problem is that the get_virtual_price function returns a valid price only if the tokens in the pool are expected to have a price equal to $1 which is not the case. Also, the balances of deposited FEI and 3pool lp tokens are just added to each other while they have a different price: _feiToDeposit + _3crvBalanceAfter.  The price of the 3pool lp tokens is currently very close to 1$ so this difference is not that visible at the moment, but this can slowly change over time.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.4 StableSwapOperatorV1 - FEI tokens in the contract are not considerred as protocol-owned ", "body": "  Description  Every PCVDeposit contract should return the amount of PCV controlled by this contract in the resistantBalanceAndFei. In addition to that, this function returns the amount of protocol-controlled FEI, which is not supposed to be collateralized. These values are crucial for evaluating the collateralization of the protocol.  Unlike some other PCVDeposit contracts, protocol-controlled FEI is not minted during the deposit and not burnt during the withdrawal. These FEI tokens are transferred beforehand, so when depositing, all the FEI that are instantly becoming protocol-controlled and heavily impact the collateralization rate. The opposite impact, but as much significant, happens during the withdrawal.  The amount of FEI needed for the deposited is calculated dynamically, it is hard to predict the exact amount beforehand. There may be too many FEI tokens in the contract and the leftovers will be considered as the user-controlled FEI.  Recommendation  There may be different approaches to solve this issue. One of them would be to make sure that the Fei transfers to/from the contract and the deposit/withdraw calls are happening in a single transaction. These FEI should be minted, burnt, or re-used as the protocol-controlled FEI in the same transaction. Another option would be to consider all the FEI balance in the contract as the protocol-controlled FEI.  If the intention is to have all these FEI collateralized, the other solution is needed: make sure that resistantBalanceAndFei always returns resistantFei equals zero.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.5 BalancerLBPSwapper - init() can be front-run to potentially steal tokens ", "body": "  Description  The deployment process for BalancerLBPSwapper appears to be the following:  deploy BalancerLBPSwapper.  run ILiquidityBootstrappingPoolFactory.create() proving the newly deployed swapper address as the owner of the pool.  initialize BalancerLBPSwapper.init() with the address of the newly created pool.  This process may be split across multiple transactions as in the v2Phase1.js deployment scenario.  Between step (1) and (3) there is a window of opportunity for someone to maliciously initialize contract. This should be easily detectable because calling init() twice should revert the second transaction. If this is not caught in the deployment script this may have more severe security implications. Otherwise, this window can be used to grief the deployment initializing it before the original initializer does forcing them to redeploy the contract or to steal any tokenSpent/tokenReceived that are owned by the contract at this time.  Note: It is assumed that the contract will not own a lot of tokens right after deployment rendering the scenario of stealing tokens more unlikely. However, that highly depends on the deployment script for the contract system.  Examples  code/contracts/pcv/balancer/BalancerLBPSwapper.sol:L107-L117  function init(IWeightedPool _pool) external {  require(address(pool) == address(0), \"BalancerLBPSwapper: initialized\");  pool = _pool;  IVault _vault = _pool.getVault();  vault = _vault;  // Check ownership  require(_pool.getOwner() == address(this), \"BalancerLBPSwapper: contract not pool owner\");  code/contracts/pcv/balancer/BalancerLBPSwapper.sol:L159-L160  IERC20(tokenSpent).approve(address(_vault), type(uint256).max);  IERC20(tokenReceived).approve(address(_vault), type(uint256).max);  Recommendation  protect BalancerLBPSwapper.init() and only allow a trusted entity (e.g. the initial deployer) to call this method.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.6 PCVEquityMinter and BalancerLBPSwapper - desynchronisation race ", "body": "  Description  There is nothing that prevents other actors from calling BalancerLBPSwapper.swap() afterTime but right before PCVEquityMinter.mint() would as long as the minAmount required for the call to pass is deposited to BalancerLBPSwapper.  instead of taking the newly minted FEI from PCVEquityMinter, existing FEI from the malicious user will be used with the pool. (instead of inflating the token the malicious actor basically pays for it)  the Timed modifiers of both contracts will be out of sync with BalancerLBPSwapper.swap() being reset (and failing until it becomes available again) and PCVEquityMinter.mint() still being available. Furthermore, keeper-scripts (or actors that want to get the incentive) might continue to attempt to mint() while the call will ultimately fail in .swap() due to the resynchronization of timed (unless they simulate the calls first).  Note: There are not a lot of incentives to actually exploit this other than preventing protocol inflation (mint) and potentially griefing users. A malicious user will lose out on the incentivized call and has to ensure that the minAmount required for .swap() to work is available. It is, however, in the best interest of security to defuse the unpredictable racy character of the contract interaction.  Examples  code/contracts/token/PCVEquityMinter.sol:L91-L93  function _afterMint() internal override {  IPCVSwapper(target).swap();  code/contracts/pcv/balancer/BalancerLBPSwapper.sol:L172-L181  function swap() external override afterTime whenNotPaused {  uint256 spentReserves,  uint256 receivedReserves,  uint256 lastChangeBlock  ) = getReserves();  // Ensures no actor can change the pool contents earlier in the block  require(lastChangeBlock < block.number, \"BalancerLBPSwapper: pool changed this block\");  Recommendation  If BalancerLBPSwapper.swap() is only to be called within the flows of action from a PCVEquityMinter.mint() it is suggested to authenticate the call and only let PCVEquityMinter call .swap()  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.7 CollateralizationOracleWrapper - the deviation threshold check in update() always returns false ", "body": "  Description  A call to update() returns a boolean flag indicating whether the update was performed on outdated data. This flag is being checked in updateIfOutdated() which is typically called by an incentivized keeper function.  There may currently be no incentive (e.g. from the keeper side) to call update() if the values are not outdated but they deviated too much from the target. However, anyone can force an update by calling the non-incentivized public update() method instead.  Examples  code/contracts/oracle/CollateralizationOracleWrapper.sol:L156-L177  require(_validityStatus, \"CollateralizationOracleWrapper: CollateralizationOracle is invalid\");  // set cache variables  cachedProtocolControlledValue = _protocolControlledValue;  cachedUserCirculatingFei = _userCirculatingFei;  cachedProtocolEquity = _protocolEquity;  // reset time  _initTimed();  // emit event  emit CachedValueUpdate(  msg.sender,  cachedProtocolControlledValue,  cachedUserCirculatingFei,  cachedProtocolEquity  );  return outdated  || _isExceededDeviationThreshold(cachedProtocolControlledValue, _protocolControlledValue)  || _isExceededDeviationThreshold(cachedUserCirculatingFei, _userCirculatingFei);  Recommendation  Add unit tests to check for all three return conditions (timed, deviationA, deviationB)  Make sure to compare the current to the stored value before updating the cached values when calling _isExceededDeviationThreshold.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.8 ChainlinkOracleWrapper - latestRoundData might return stale results ", "body": "  Description  The oracle wrapper calls out to a chainlink oracle receiving the latestRoundData(). It then checks freshness by verifying that the answer is indeed for the last known round. The returned updatedAt timestamp is not checked.  If there is a problem with chainlink starting a new round and finding consensus on the new value for the oracle (e.g. chainlink nodes abandon the oracle, chain congestion, vulnerability/attacks on the chainlink system) consumers of this contract may continue using outdated stale data (if oracles are unable to submit no new round is started)  Examples  code/contracts/oracle/ChainlinkOracleWrapper.sol:L49-L58  /// @notice read the oracle price  /// @return oracle price  /// @return true if price is valid  function read() external view override returns (Decimal.D256 memory, bool) {  (uint80 roundId, int256 price,,, uint80 answeredInRound) = chainlinkOracle.latestRoundData();  bool valid = !paused() && price > 0 && answeredInRound == roundId;  Decimal.D256 memory value = Decimal.from(uint256(price)).div(oracleDecimalsNormalizer);  return (value, valid);  code/contracts/oracle/ChainlinkOracleWrapper.sol:L42-L47  /// @notice determine if read value is stale  /// @return true if read value is stale  function isOutdated() external view override returns (bool) {  (uint80 roundId,,,, uint80 answeredInRound) = chainlinkOracle.latestRoundData();  return answeredInRound != roundId;  Recommendation  Consider checking the oracle responses updatedAt  value after calling out to chainlinkOracle.latestRoundData() verifying that the result is within an allowed margin of freshness.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.9 CollateralizationOracle - missing events and incomplete event information ", "body": "  Description  The CollateralizationOracle.setDepositExclusion function is used to exclude and re-include deposits from collateralization calculations. Unlike the other state-changing functions in this contract, it doesn t emit an event to inform about the exclusion or re-inclusion.  code/contracts/oracle/CollateralizationOracle.sol:L111-L113  function setDepositExclusion(address _deposit, bool _excluded) external onlyGuardianOrGovernor {  excludedDeposits[_deposit] = _excluded;  The DepositAdd event emits not only the deposit address but also the deposit s token. Despite the symmetry, the DepositRemove event does not emit the token.  code/contracts/oracle/CollateralizationOracle.sol:L25-L26  event DepositAdd(address from, address indexed deposit, address indexed token);  event DepositRemove(address from, address indexed deposit);  Recommendation  setDepositInclusion should emit an event that informs about the deposit and whether it was included or excluded.  For symmetry reasons and because it is indeed useful information, the DepositRemove event could include the deposit s token.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.10 RateLimited - Contract starts with a full buffer at deployment ", "body": "  Description  A contract that inherits from RateLimited starts out with a full buffer when it is deployed.  code/contracts/utils/RateLimited.sol:L35  _bufferStored = _bufferCap;  That means the full bufferCap is immediately available after deployment; it doesn t have to be built up over time. This behavior might be unexpected.  Recommendation  We recommend starting with an empty buffer, or   if there are valid reasons for the current implementation   at least document it clearly.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.11 StableSwapOperatorV1 - the contract relies on the 1$ price of every token in 3pool ", "body": "  Description  To evaluate the price of the 3pool lp token, the built-in get_virtual_price function is used.  This function is supposed to be a manipulation-resistant pricing function that works under the assumption that all the tokens in the pool are worth 1$. If one of the tokens is broken and is priced less, the price is harder to calculate. For example, Chainlink uses the following function to calculate at least the lower boundary of the lp price: https://blog.chain.link/using-chainlink-oracles-to-securely-utilize-curve-lp-pools/  The withdrawal and the controlled value calculation are always made in DAI instead of other stablecoins of the 3pool. So if DAI gets compromised but other tokens aren t, there is no way to switch to them.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.12 BalancerLBPSwapper - tokenSpent and tokenReceived should be immutable ", "body": "  Description  Acc. to the inline comment both tokenSpent and tokenReceived should be immutable but they are not declared as such.  Examples  code/contracts/pcv/balancer/BalancerLBPSwapper.sol:L92-L94  // tokenSpent and tokenReceived are immutable  tokenSpent = _tokenSpent;  tokenReceived = _tokenReceived;  code/contracts/pcv/balancer/BalancerLBPSwapper.sol:L40-L44  /// @notice the token to be auctioned  address public override tokenSpent;  /// @notice the token to buy  address public override tokenReceived;  Recommendation  Declare both variable immutable.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.13 CollateralizationOracle - potentially unsafe casts ", "body": "  Description  protocolControlledValue is the cumulative USD token value of all tokens in the PCV. The USD value is determined using external chainlink oracles. To mitigate some effects of attacks on chainlink to propagate to this protocol it is recommended to implement a defensive approach to handling values derived from the external source.  Arithm. overflows are checked by the compiler (0.8.4), however, it does not guarantee safe casting from unsigned to signed integer. The scenario of this happening might be rather unlikely, however, there is no guarantee that the external price-feed is not taken over by malicious actors and this is when every line of defense counts.  //solidity 0.8.7  \u00bb  int(uint(2**255))  57896044618658097711785492504343953926634992332820282019728792003956564819968  \u00bb  int(uint(2**255-2))  57896044618658097711785492504343953926634992332820282019728792003956564819966  Examples  code/contracts/oracle/CollateralizationOracle.sol:L327-L327  protocolEquity = int256(protocolControlledValue) - int256(userCirculatingFei);  code/contracts/oracle/CollateralizationOracle.sol:L322-L322  protocolControlledValue += _oraclePrice.mul(_totalTokenBalance).asUint256();  Recommendation  Perform overflow checked SafeCast as another line of defense against oracle manipulation.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.14 FeiTimedMinter - constructor does not enforce the same boundaries as setter for frequency ", "body": "  Description  The setter method for frequency enforced upper and lower bounds while the constructor does not. Users cannot trust that the frequency is actually set to be within bounds on deployment.  Examples  code/contracts/token/FeiTimedMinter.sol:L32-L48  constructor(  address _core,  address _target,  uint256 _incentive,  uint256 _frequency,  uint256 _initialMintAmount  CoreRef(_core)  Timed(_frequency)  Incentivized(_incentive)  RateLimitedMinter((_initialMintAmount + _incentive) / _frequency, (_initialMintAmount + _incentive), true)  _initTimed();  _setTarget(_target);  _setMintAmount(_initialMintAmount);  code/contracts/token/FeiTimedMinter.sol:L82-L87  function setFrequency(uint256 newFrequency) external override onlyGovernorOrAdmin {  require(newFrequency >= MIN_MINT_FREQUENCY, \"FeiTimedMinter: frequency low\");  require(newFrequency <= MAX_MINT_FREQUENCY, \"FeiTimedMinter: frequency high\");  _setDuration(newFrequency);  Recommendation  Perform the same checks on frequency in the constructor as in the setFrequency method.  This contract is also inherited by a range of contracts that might specify different boundaries to what is hardcoded in the FeiTimedMinter. A way to enforce bounds-checks could be to allow overriding the setter method and using the setter in the constructor as well ensuring that bounds are also checked on deployment.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.15 CollateralizationOracle - swapDeposit should call internal functions to remove/add deposits ", "body": "  Description  Examples  code/contracts/oracle/CollateralizationOracle.sol:L191-L198  /// @notice Swap a PCVDeposit with a new one, for instance when a new version  ///         of a deposit (holding the same token) is deployed.  /// @param _oldDeposit : the PCVDeposit to remove from the list.  /// @param _newDeposit : the PCVDeposit to add to the list.  function swapDeposit(address _oldDeposit, address _newDeposit) external onlyGovernor {  removeDeposit(_oldDeposit);  addDeposit(_newDeposit);  Recommendation  Call the internal functions instead. addDeposit s and removeDeposit s visibility can then be changed from public to external.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "4.16 CollateralizationOracle - misleading comments ", "body": "  Description  According to an inline comment in isOvercollateralized, the validity status of pcvStats is ignored, while it is actually being checked.  Similarly, a comment in pcvStats mentions that the returned protocolEquity is 0 if there is less PCV than circulating FEI, while in reality, pcvStats always returns the difference between the former and the latter, even if it is negative.  Examples  code/contracts/oracle/CollateralizationOracle.sol:L332-L339  ///         Controlled Value) than the circulating (user-owned) FEI, i.e.  ///         a positive Protocol Equity.  ///         Note: the validity status is ignored in this function.  function isOvercollateralized() external override view whenNotPaused returns (bool) {  (,, int256 _protocolEquity, bool _valid) = pcvStats();  require(_valid, \"CollateralizationOracle: reading is invalid\");  return _protocolEquity > 0;  code/contracts/oracle/CollateralizationOracle.sol:L283-L284  /// @return protocolEquity : the difference between PCV and user circulating FEI.  ///         If there are more circulating FEI than $ in the PCV, equity is 0.  code/contracts/oracle/CollateralizationOracle.sol:L327  protocolEquity = int256(protocolControlledValue) - int256(userCirculatingFei);  Recommendation  Revise the comments.  5 Recommendations  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "5.1 Update Natspec", "body": "  Examples  token is not in natspec  code/contracts/pcv/utils/ERC20Splitter.sol:L6-L28  /// @notice a contract to split token held to multiple locations  contract ERC20Splitter is PCVSplitter {  /// @notice token to split  IERC20 public token;  /**  @notice constructor for ERC20Splitter  @param _core the Core address to reference  @param _pcvDeposits the locations to send tokens  @param _ratios the relative ratios of how much tokens to send each location, in basis points  /  constructor(  address _core,  IERC20 _token,  address[] memory _pcvDeposits,  uint256[] memory _ratios  CoreRef(_core)  PCVSplitter(_pcvDeposits, _ratios)  token = _token;  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "5.2 TribeReserveStabilizer - different minting procedures", "body": "  Description  The TRIBE token doesn t have a burn functionality. TRIBE that is supposed to be taken out of circulation is sent to the TribeReserveStabilizer contract, and when that contract has to mint new TRIBE in exchange for FEI, it will first use up the currently held TRIBE balance before actually minting new tokens.  code/contracts/stabilizer/TribeReserveStabilizer.sol:L117-L133  // Transfer held TRIBE first, then mint to cover remainder  function _transfer(address to, uint256 amount) internal override {  _depleteBuffer(amount);  uint256 _tribeBalance = balance();  uint256 mintAmount = amount;  if(_tribeBalance != 0) {  uint256 transferAmount = Math.min(_tribeBalance, amount);  _withdrawERC20(address(token), to, transferAmount);  mintAmount = mintAmount - transferAmount;  assert(mintAmount + transferAmount == amount);  if (mintAmount != 0) {  _mint(to, mintAmount);  The contract also has a mint function that allows the Governor to mint new TRIBE. Unlike the exchangeFei function described above, this function does not first utilize TRIBE held in the contract but directly instructs the token contract to mint the entire amount.  code/contracts/stabilizer/TribeReserveStabilizer.sol:L102-L107  /// @notice mints TRIBE to the target address  /// @param to the address to send TRIBE to  /// @param amount the amount of TRIBE to send  function mint(address to, uint256 amount) external override onlyGovernor {  _mint(to, amount);  code/contracts/stabilizer/TribeReserveStabilizer.sol:L135-L138  function _mint(address to, uint256 amount) internal {  ITribe _tribe = ITribe(address(token));  _tribe.mint(to, amount);  Recommendation  It would make sense and be more consistent with exchangeFei if the mint function first used TRIBE held in the contract before actually minting new tokens.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/09/fei-protocol-v2-phase-1/"}, {"title": "5.1 TokenStaking.recoverStake allows instant stake undelegation    Addressed", "body": "  Resolution                           Addressed with   keep-network/keep-core#1521 by adding a non-zero check for the undelegation block.  Description  TokenStaking.recoverStake is used to recover stake that has been designated to be undelegated. It contains a single check to ensure that the undelegation period has passed:  keep-core/contracts/solidity/contracts/TokenStaking.sol:L182-L187  function recoverStake(address _operator) public {  uint256 operatorParams = operators[_operator].packedParams;  require(  block.number > operatorParams.getUndelegationBlock().add(undelegationPeriod),  \"Can not recover stake before undelegation period is over.\"  );  However, if an undelegation period is never set, this will always return true, allowing any operator to instantly undelegate stake at any time.  Recommendation  Require that the undelegation period is nonzero before allowing an operator to recover stake.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.2 Improper length validation in BLS signature library allows RNG manipulation    Addressed", "body": "  Resolution                           Addressed with   keep-network/keep-core#1523 by adding input length checks to  Description  KeepRandomBeaconOperator.relayEntry(bytes memory _signature) is used to submit random beacon results:  keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L418-L433  function relayEntry(bytes memory _groupSignature) public nonReentrant {  require(isEntryInProgress(), \"Entry was submitted\");  require(!hasEntryTimedOut(), \"Entry timed out\");  bytes memory groupPubKey = groups.getGroupPublicKey(signingRequest.groupIndex);  require(  BLS.verify(  groupPubKey,  signingRequest.previousEntry,  _groupSignature  ),  \"Invalid signature\"  );  emit RelayEntrySubmitted();  The function calls BLS.verify, which validates that the submitted signature correctly signs the previous recorded random beacon entry. BLS.verify calls AltBn128.g1Unmarshal(signature):  keep-core/contracts/solidity/contracts/cryptography/BLS.sol:L31-L37  function verify(  bytes memory publicKey,  bytes memory message,  bytes memory signature  ) public view returns (bool) {  AltBn128.G1Point memory _signature = AltBn128.g1Unmarshal(signature);  AltBn128.g1Unmarshal(signature) reads directly from memory without making any length checks:  keep-core/contracts/solidity/contracts/cryptography/AltBn128.sol:L214-L228  /**  @dev Unmarshals a point on G1 from bytes in an uncompressed form.  /  function g1Unmarshal(bytes memory m) internal pure returns(G1Point memory) {  bytes32 x;  bytes32 y;  /* solium-disable-next-line */  assembly {  x := mload(add(m, 0x20))  y := mload(add(m, 0x40))  return G1Point(uint256(x), uint256(y));  There are two potential issues with this:  g1Unmarshal may be reading out-of-bounds of the signature from dirty memory.  g1Unmarshal may not be reading all of the signature. If more than 64 bytes are supplied, they are ignored for the purposes of signature validation.  These issues are important because the hash of the signature is the  random number  supplied to user contracts:  keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L435-L448  // Spend no more than groupSelectionGasEstimate + 40000 gas max  // This will prevent relayEntry failure in case the service contract is compromised  signingRequest.serviceContract.call.gas(groupSelectionGasEstimate.add(40000))(  abi.encodeWithSignature(  \"entryCreated(uint256,bytes,address)\",  signingRequest.relayRequestId,  _groupSignature,  msg.sender  );  if (signingRequest.callbackFee > 0) {  executeCallback(signingRequest, uint256(keccak256(_groupSignature)));  An attacker can use this behavior to game random number generation by frontrunning a valid signature submission with additional byte padding.  Recommendation  Ensure each function in BLS.sol properly validates input lengths for all parameters; the same length validation issue exists in BLS.verifyBytes.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.3 tbtc - the tecdsa keep is never closed, signer bonds are not released    Addressed", "body": "  Resolution  Addressed with https://github.com/keep-network/tbtc/issues/473, https://github.com/keep-network/tbtc/issues/490, keep-network/tbtc#534, and keep-network/tbtc#520.  failed_setup:  notifySignerSetupFailure \u2705closed by seizing funds with issue 5.10 notifyFundingTimeout \u2705closed with keep-network/tbtc#534 provideFundingECDSAFraudProof, \u2705slashes stake, distributes signer bonds to funder (push payment -> should be pull or funder may block), closes keep. provideFraudBTCFundingProof \u2705 removed with keep-network/tbtc#534 notifyFraudFundingTimeout  \u2705 removed with keep-network/tbtc#534  liquidated:  provideSPVFraudProof \u2705removed purchaseSignerBondsAtAuction  \u2705 via startSignerAbortLiquidation, \u2705 via startSignerFraudLiquidation (implicitly via seizebonds)  redeemed:  provideRedemptionProof  \u2705  Description  At the end of the TBTC deposit lifecycle happy path, the deposit is supposed to close the keep in order to release the signer bonds. However, there is no call to closeKeep in any of the code-bases under audit.  Recommendation  Close the keep releasing the signer bonds.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.4 tbtc - No access control in TBTCSystem.requestNewKeep    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/tbtc#514. Each call to  Description  TBTCSystem.requestNewKeep is used by each new Deposit contract on creation. It calls BondedECDSAKeepFactory.openKeep, which sets the Deposit contract as the  owner,  a permissioned role within the created keep. openKeep also automatically allocates bonds from members registered to the application. The  application  from which member bonds are allocated is the tbtc system itself.  Because requestNewKeep has no access controls, anyone can request that a keep be opened with msg.sender as the  owner,  and arbitrary signing threshold values:  tbtc/implementation/contracts/system/TBTCSystem.sol:L231-L243  /// @notice Request a new keep opening.  /// @param _m Minimum number of honest keep members required to sign.  /// @param _n Number of members in the keep.  /// @return Address of a new keep.  function requestNewKeep(uint256 _m, uint256 _n, uint256 _bond)  external  payable  returns (address)  IBondedECDSAKeepVendor _keepVendor = IBondedECDSAKeepVendor(keepVendor);  IBondedECDSAKeepFactory _keepFactory = IBondedECDSAKeepFactory(_keepVendor.selectFactory());  return _keepFactory.openKeep.value(msg.value)(_n, _m, msg.sender, _bond);  Given that the owner of a keep is able to seize signer bonds, close the keep, and more, having control of this role could be detrimental to group members.  Recommendation  Add access control to requestNewKeep, so that it can only be called as a part of the Deposit creation and initialization process.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.5 Unpredictable behavior due to front running or general bad timing    Addressed", "body": "  Resolution  This issue has been addressed with https://github.com/keep-network/tbtc/issues/493 and the following set of PRs:  https://github.com/keep-network/tbtc/issues/493  https://github.com/keep-network/keep-tecdsa/issues/296 - note: initializeImplementation should be done in completeUpgrade otherwise this could be used as a backdoor.  fixed by keep-network/keep-ecdsa#327 - fixed: initialization moved to complete upgrade step  https://github.com/keep-network/keep-core/issues/1423 - note: initializeImplementationshould be done incompleteUpgrade` otherwise this could be used as a backdoor.  fixed by keep-network/keep-core#1517 - fixed: initialization moved to complete upgrade step  The client also provided the following statements:  In general, our current stance on frontrunning proofs that lead to rewards is that as long as it doesn t significantly compromise an incentive on the primary actors of the system, we re comfortable with having it present. In particular, frontrunnable actions that include rewards in several cases have additional incentives\u2014for tBTC deposit owners, for example, claiming bonds in case of misbehavior; for signers, reclaiming bonds in case of deposit owner absence or other misbehavior. We consider signer reclamation of bonds to be a strong incentive, as bond value is expected to be large enough that there is ongoing expected value to having the bond value liquid rather than bonded.  Some of the frontrunning cases (e.g. around beacon signing) did not have this additional incentive, and in those cases we ve taken up the recommendations in the audit.  Description  In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.  Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.  Some instances of this are more important than others, but in general users of the system should have assurances about the behavior of the action they re about to take.  Examples  System Parameters  The owner of the TBTCSystem contract can change system parameters at any time with changes taking effect immediately.  setSignerFeeDivisor - stored in the deposit contract when creating a new deposit. emits an event.  setLotSizes - stored in the deposit contract when creating a new deposit. emits an event.  setCollateralizationThresholds - stored in the deposit contract when creating a new deposit. emits an event.  This also opens up an opportunity for malicious owner to:  interfere with other participants deposit creation attempts (front-running transactions)  craft a series of transactions that allow the owner to set parameters that are more beneficial to them, then create a deposit and reset the parameters to the systems  initial settings.  tbtc/implementation/contracts/system/TBTCSystem.sol:L113-L121  /// @notice Set the system signer fee divisor.  /// @param _signerFeeDivisor The signer fee divisor.  function setSignerFeeDivisor(uint256 _signerFeeDivisor)  external onlyOwner  require(_signerFeeDivisor > 9, \"Signer fee divisor must be greater than 9, for a signer fee that is <= 10%.\");  signerFeeDivisor = _signerFeeDivisor;  emit SignerFeeDivisorUpdated(_signerFeeDivisor);  Upgradables  The proxy pattern used in many places throughout the system allows the operator to set a new implementation which takes effect immediately.  keep-core/contracts/solidity/contracts/KeepRandomBeaconService.sol:L67-L80  /**  @dev Upgrade current implementation.  @param _implementation Address of the new implementation contract.  /  function upgradeTo(address _implementation)  public  onlyOwner  address currentImplementation = implementation();  require(_implementation != address(0), \"Implementation address can't be zero.\");  require(_implementation != currentImplementation, \"Implementation address must be different from the current one.\");  setImplementation(_implementation);  emit Upgraded(_implementation);  keep-tecdsa/solidity/contracts/BondedECDSAKeepVendor.sol:L57-L71  /// @notice Upgrades the current vendor implementation.  /// @param _implementation Address of the new vendor implementation contract.  function upgradeTo(address _implementation) public onlyOwner {  address currentImplementation = implementation();  require(  _implementation != address(0),  \"Implementation address can't be zero.\"  );  require(  _implementation != currentImplementation,  \"Implementation address must be different from the current one.\"  );  setImplementation(_implementation);  emit Upgraded(_implementation);  Registry  keep-tecdsa/solidity/contracts/BondedECDSAKeepVendorImplV1.sol:L43-L50  function registerFactory(address payable _factory) external onlyOperatorContractUpgrader {  require(_factory != address(0), \"Incorrect factory address\");  require(  registry.isApprovedOperatorContract(_factory),  \"Factory contract is not approved\"  );  keepFactory = _factory;  Recommendation  The underlying issue is that users of the system can t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.  We recommend giving the user advance notice of changes with a time lock. For example, make all upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.6 keep-core - reportRelayEntryTimeout creates an incentive for nodes to race for rewards potentially wasting gas and it creates an opportunity for front-running    Addressed", "body": "  Resolution                           Following the discussion at   https://github.com/keep-network/keep-core/issues/1404 it was verified that the method throws as early as possible in an attempt to safe gas in case many nodes call out the timeout in the same block. The client is currently comfortable with this tradeoff. We would like to note that this issue cannot easily be addressed (e.g. allowing nodes to disable calling out timeouts impacts the security of the system; a commit/reveal proxy adds overhead and is unlikely to make the situation better as nodes are programmed to call out timeouts) and we therefore recommend to monitor the network for this scenario.  Description  The incentive on reportRelayEntryTimeout for being rewarded with 5% of the seized amount creates an incentive to call the method but might also kick off a race for front-running this call. This method is being called from the keep node which is unlikely to adjust the gasPrice and might always lose the race against a front-running bot collecting rewards for all timeouts and fraud proofs (issue 5.7)  Examples  keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L600-L626  /**  @dev Function used to inform about the fact the currently ongoing  new relay entry generation operation timed out. As a result, the group  which was supposed to produce a new relay entry is immediately  terminated and a new group is selected to produce a new relay entry.  All members of the group are punished by seizing minimum stake of  their tokens. The submitter of the transaction is rewarded with a  tattletale reward which is limited to min(1, 20 / group_size) of the  maximum tattletale reward.  /  function reportRelayEntryTimeout() public {  require(hasEntryTimedOut(), \"Entry did not time out\");  groups.reportRelayEntryTimeout(signingRequest.groupIndex, groupSize, minimumStake);  // We could terminate the last active group. If that's the case,  // do not try to execute signing again because there is no group  // which can handle it.  if (numberOfGroups() > 0) {  signRelayEntry(  signingRequest.relayRequestId,  signingRequest.previousEntry,  signingRequest.serviceContract,  signingRequest.entryVerificationAndProfitFee,  signingRequest.callbackFee  );  Recommendation  Make sure that reportRelayEntryTimeout throws as early as possible if the group was previously terminated (isGroupTerminated) to avoid that keep-nodes spend gas on a call that will fail. Depending on the reward for calling out the timeout this might create a front-running opportunity that cannot be resolved.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.7 keep-core - reportUnauthorizedSigning fraud proof is not bound to reporter and can be front-run    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/keep-core/issues/1405 by binding the proof to  Description  An attacker can monitor reportUnauthorizedSigning() for fraud reports and attempt to front-run the original call in an effort to be the first one reporting the fraud and be rewarded 5% of the total seized amount.  Examples  keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L742-L755  /**  @dev Reports unauthorized signing for the provided group. Must provide  a valid signature of the group address as a message. Successful signature  verification means the private key has been leaked and all group members  should be punished by seizing their tokens. The submitter of this proof is  rewarded with 5% of the total seized amount scaled by the reward adjustment  parameter and the rest 95% is burned.  /  function reportUnauthorizedSigning(  uint256 groupIndex,  bytes memory signedGroupPubKey  ) public {  groups.reportUnauthorizedSigning(groupIndex, signedGroupPubKey, minimumStake);  Recommendation  Require the reporter to include msg.sender in the signature proving the fraud or implement a two-step commit/reveal scheme to counter front-running opportunities by forcing a reporter to secretly commit the fraud parameters in one block and reveal them in another.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.8 keep-core - operator contracts disabled via panic button can be re-enabled by RegistryKeeper    Addressed", "body": "  Resolution  Addressed by https://github.com/keep-network/keep-core/issues/1406 with changes from keep-network/keep-core#1463:  the contract is now using enums instead of int literals  only new operator contracts can be approved  only approved contracts can be disabled  disabled contracts cannot be re-enabled  disabling an operator contract does not yield an event  changes take effect immediately  Description  The keep specification states the following:  Panic Button The Panic Button can disable malicious or malfunctioning contracts that have been previously approved by the Registry Keeper. When a contract is disabled by the Panic Button, its status on the registry changes to reflect this, and it becomes ineligible to penalize operators. Contracts disabled by the Panic Button can not be reactivated. The Panic Button can be rekeyed by Governance.  With the current implementation of the Registry the registryKeeper account can re-enable an operator contract that has previously been disabled by the panicButton account.  We would also like to note the following:  The contract should use enums instead of integer literals when working with contract states.  Changes to the contract take effect immediately, allowing an administrative account to selectively front-run calls to the Registry ACL and interfere with user activity.  The operator contract state can be set to the current value without raising an error.  The panic button can be called for operator contracts that are not yet active.  Examples  keep-core/contracts/solidity/contracts/Registry.sol:L67-L75  function approveOperatorContract(address operatorContract) public onlyRegistryKeeper {  operatorContracts[operatorContract] = 1;  function disableOperatorContract(address operatorContract) public onlyPanicButton {  operatorContracts[operatorContract] = 2;  Recommendation  The keep specification states:  The Panic Button can be used to set the status of an APPROVED contract to DISABLED. Operator Contracts disabled with the Panic Button cannot be re-enabled, and disabled contracts may not punish operators nor be selected by service contracts to perform work.  All three accounts are typically trusted. We recommend requiring the Governance or paniceButton accounts to reset the contract operator state before registryKeeper can change the state or disallow re-enabling of disabled operator contracts as stated in the specification.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.9 tbtc - State transitions are not always enforced    Addressed", "body": "  Resolution  This issue was addressed with https://github.com/keep-network/tbtc/issues/494 and accepted by the client with the following statement. Deposits that are timed out can still be pushed to an active state.  For 5.7 around state transitions, our stance (specifically for the upcoming release) is that a skipped state is acceptable as long as it does not result in data loss or incentive skew. Taken in turn, the listed examples:   A TDT holder can choose not to call out notifySignerSetupFailure hoping that the signing group still forms after the signer setup timeout passes.  -> we consider this fine. If the TDT holder wishes to hold out hope, it is their choice. Signers should be incentivized to call notifySignerSetupFailure in case of actual failure to release their bond.   The deposit can be pushed to active state even after notifySignerSetupFailure, notifyFundingTimeout have passed but nobody called it out.  -> again, we consider this fine. A deposit that is funded and proven past its timeout is still a valid deposit, since the two players in question (the depositor and the signing group) were willing to wait longer to complete the flow. The timeouts in question are largely a matter of allowing signers to release their bond in case there is an issue setting up the deposit.   Members of the signing group might decide to call notifyFraudFundingTimeout in a race to avoid late submissions for provideFraudBTCFundingProof to succeed in order to contain funds lost due to fraud.  -> We are intending to change the mechanic here so that signers lose their whole bond in either case.   A malicious signing group observes BTC funding on the bitcoin chain in an attempt to commit fraud at the time the provideBTCFundingProof transition becomes available to front-run provideFundingECDSAFraudProof forcing the deposit into active state.  -> this one is tough, and we re working on changing the liquidation initiator reward so it is no longer a useful attack. In particular, we re looking at the suggestion in 2.4 for this.   If oracle price slippage occurs for one block (flash-crash type of event) someone could call an undercollateralization transition.  -> We are still investigating this possibility.   A deposit term expiration courtesy call can be exit in the rare case where _d.fundedAt + TBTCConstants.getDepositTerm() == block.timestamp  -> Deposit term expiration courtsey calls should no longer apply; see keep-network/tbtc@6344892 . Courtesy call after deposit term is identical to courtsey call pre-term.  Description  State transitions from one deposit state to another require someone calling the corresponding transition method on the deposit and actually spend gas on it. The incentive to call a transition varies and is analyzed in more detail in the security-specification section of this report.  This issue assumes that participants are not always pushing forward through the state machine as soon as a new state becomes available, opening up the possibility of having multiple state transitions being a valid option for a deposit (e.g. pushing a deposit to active state even though a timeout should have been called on it).  Examples  A TDT holder can choose not to call out notifySignerSetupFailure hoping that the signing group still forms after the signer setup timeout passes.  there is no incentive for the TDT holder to terminate its own deposit after a timeout.  the deposit might end up never being in a final error state.  there is no incentive for the signing group to terminate the deposit.  This affects all states that can time out.  The deposit can be pushed to active state even after notifySignerSetupFailure, notifyFundingTimeout have passed but nobody called it out.  There is no timeout check in retrieveSignerPubkey, provideBTCFundingProof.  tbtc/implementation/contracts/deposit/DepositFunding.sol:L108-L117  /// @notice             we poll the Keep contract to retrieve our pubkey  /// @dev                We store the pubkey as 2 bytestrings, X and Y.  /// @param  _d          deposit storage pointer  /// @return             True if successful, otherwise revert  function retrieveSignerPubkey(DepositUtils.Deposit storage _d) public {  require(_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");  bytes memory _publicKey = IBondedECDSAKeep(_d.keepAddress).getPublicKey();  require(_publicKey.length == 64, \"public key not set or not 64-bytes long\");  tbtc/implementation/contracts/deposit/DepositFunding.sol:L263-L278  function provideBTCFundingProof(  DepositUtils.Deposit storage _d,  bytes4 _txVersion,  bytes memory _txInputVector,  bytes memory _txOutputVector,  bytes4 _txLocktime,  uint8 _fundingOutputIndex,  bytes memory _merkleProof,  uint256 _txIndexInBlock,  bytes memory _bitcoinHeaders  ) public returns (bool) {  require(_d.inAwaitingBTCFundingProof(), \"Not awaiting funding\");  bytes8 _valueBytes;  bytes memory  _utxoOutpoint;  Members of the signing group might decide to call notifyFraudFundingTimeout in a race to avoid late submissions for provideFraudBTCFundingProof to succeed in order to contain funds lost due to fraud.  It should be noted that even after the fraud funding timeout passed the TDT holder could provideFraudBTCFundingProof as it does not check for the timeout.  A malicious signing group observes BTC funding on the bitcoin chain in an attempt to commit fraud at the time the provideBTCFundingProof transition becomes available to front-run provideFundingECDSAFraudProof forcing the deposit into active state.  The malicious users of the signing group can then try to report fraud, set themselves as liquidationInitiator to be awarded part of the signer bond (in addition to taking control of the BTC collateral).  The TDT holders fraud-proof can be front-run, see issue 5.15  If oracle price slippage occurs for one block (flash-crash type of event) someone could call an undercollateralization transition.  For severe oracle errors deposits might be liquidated by calling notifyUndercollateralizedLiquidation. The TDT holder cannot exit liquidation in this case.  For non-severe under collateralization someone could call notifyCourtesyCall to impose extra effort on TDT holders to exitCourtesyCall deposits.  A deposit term expiration courtesy call can be exit in the rare case where _d.fundedAt + TBTCConstants.getDepositTerm() == block.timestamp  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L289-L298  /// @notice     Goes from courtesy call to active  /// @dev        Only callable if collateral is sufficient and the deposit is not expiring  /// @param  _d  deposit storage pointer  function exitCourtesyCall(DepositUtils.Deposit storage _d) public {  require(_d.inCourtesyCall(), \"Not currently in courtesy call\");  require(block.timestamp <= _d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit is expiring\");  require(getCollateralizationPercentage(_d) >= _d.undercollateralizedThresholdPercent, \"Deposit is still undercollateralized\");  _d.setActive();  _d.logExitedCourtesyCall();  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L318-L327  /// @notice     Notifies the contract that its term limit has been reached  /// @dev        This initiates a courtesy call  /// @param  _d  deposit storage pointer  function notifyDepositExpiryCourtesyCall(DepositUtils.Deposit storage _d) public {  require(_d.inActive(), \"Deposit is not active\");  require(block.timestamp >= _d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit term not elapsed\");  _d.setCourtesyCall();  _d.logCourtesyCalled();  _d.courtesyCallInitiated = block.timestamp;  Allow exiting the courtesy call only if the deposit is not expired: block.timestamp < _d.fundedAt + TBTCConstants.getDepositTerm()  Recommendation  Ensure that there are no competing interests between participants of the system to favor one transition over the other, causing race conditions, front-running opportunities or stale deposits that are not pushed to end-states.  Note: Please find an analysis of incentives to call state transitions in the security section of this document.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.10 tbtc - Funder loses payment to keep if signing group is not established in time   Pending", "body": "  Resolution  This issue was addressed with https://github.com/keep-network/tbtc/issues/495 by refunding the cost of creating a new keep. We recommend using the pull instead of a push payment pattern to avoid that the funder can block the call.  Additionally, the client provided the following statement:  The remaining push vs pull question is being tracked in https://github.com/keep-network/tbtc/issues/551, part of recommendation 2.7.  Description  The funder had to provide payment for the keep but the signing group failed to establish. Payment for the keep is not returned even though one could assume that the signing group tried to play unfairly. The signing group might intentionally try to cause this scenario to interfere with the system.  Examples  retrieveSignerPubkey fails if keep provided pubkey is empty or of an unexpected length  tbtc/implementation/contracts/deposit/DepositFunding.sol:L108-L127  /// @notice             we poll the Keep contract to retrieve our pubkey  /// @dev                We store the pubkey as 2 bytestrings, X and Y.  /// @param  _d          deposit storage pointer  /// @return             True if successful, otherwise revert  function retrieveSignerPubkey(DepositUtils.Deposit storage _d) public {  require(_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");  bytes memory _publicKey = IBondedECDSAKeep(_d.keepAddress).getPublicKey();  require(_publicKey.length == 64, \"public key not set or not 64-bytes long\");  _d.signingGroupPubkeyX = _publicKey.slice(0, 32).toBytes32();  _d.signingGroupPubkeyY = _publicKey.slice(32, 32).toBytes32();  require(_d.signingGroupPubkeyY != bytes32(0) && _d.signingGroupPubkeyX != bytes32(0), \"Keep returned bad pubkey\");  _d.fundingProofTimerStart = block.timestamp;  _d.setAwaitingBTCFundingProof();  _d.logRegisteredPubkey(  _d.signingGroupPubkeyX,  _d.signingGroupPubkeyY);  notifySignerSetupFailure can be called by anyone after a timeout of 3hrs  tbtc/implementation/contracts/deposit/DepositFunding.sol:L93-L106  /// @notice     Anyone may notify the contract that signing group setup has timed out  /// @dev        We rely on the keep system punishes the signers in this case  /// @param  _d  deposit storage pointer  function notifySignerSetupFailure(DepositUtils.Deposit storage _d) public {  require(_d.inAwaitingSignerSetup(), \"Not awaiting setup\");  require(  block.timestamp > _d.signingGroupRequestedAt + TBTCConstants.getSigningGroupFormationTimeout(),  \"Signing group formation timeout not yet elapsed\"  );  _d.setFailedSetup();  _d.logSetupFailed();  fundingTeardown(_d);  Recommendation  It should be ensured that a keep group always establishes or otherwise the funder is refunded the fee for the keep.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.11 tbtc - Ethereum block gas limit imposes a fundamental limitation on SPV proofs    Addressed", "body": "  Resolution                           SPV fraud proofs were removed in   keep-network/tbtc#521. Remember to continue exploring this limitation of the EVM with benchmarking and gas estimates in the tBTC UI.  Description  Several components of the tBTC system rely on SPV proofs to prove the existence of transactions on Bitcoin. Because an SPV proof must provide the entire Bitcoin transaction to the proving smart contract, the Ethereum block gas limit imposes an upper bound on the size of the transaction in question. Although an exact upper bound is subject to several variables, reasonable estimates show that even a moderately-sized Bitcoin transaction may not be able to be successfully validated on Ethereum.  This limitation is significant for two reasons:  Depositors may deposit BTC to the signers by way of a legitimate Bitcoin transaction, only to find that this transaction is unable to be verified on Ethereum. Although the depositor in question was not acting maliciously, they may lose their deposit entirely.  In case signers collude to spend a depositor s BTC unprompted, the system allows depositors to prove a fraudulent spend occurred by way of SPV fraud proof. Given that signers can easily spend BTC with a transaction that is too large to validate by way of SPV proof, this method of fraud proof is unreliable at best. Deposit owners should instead prove fraud by using an ECDSA fraud proof, which operates on a hash of the signed message.  Recommendation  It s important that prospective depositors are able to guarantee that their deposit transaction will be verified successfully. To that end, efforts should be made to provide a deposit UI that checks whether or not a given transaction will be verified successfully before it is submitted. Several variables can affect transaction verification:  Current Ethereum block gas limits  Number of zero-bytes in the Bitcoin transaction in question  Size of the merkle proof needed to prove the transaction s existence  Given that not all of these can be calculated before the transaction is submitted to the Bitcoin blockchain, calculations should attempt to provide a margin of error for the process. Additionally, users should be well-educated about the process, including how to perform a deposit with relatively low risk.  Understanding the relative limitations of the EVM will help this process significantly. Consider benchmarking the gas cost of verifying Bitcoin transactions of various sizes.  Finally, because SPV fraud proofs can be gamed by colluding signers, they should be removed from the system entirely. Deposit owners should always be directed towards ECDSA fraud proofs, as these require relatively fewer assumptions and stronger guarantees.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.12 bitcoin-spv - SPV proofs do not support transactions with larger numbers of inputs and outputs   Pending", "body": "  Resolution  The client provided the following statement:  Benchmarks and takeaways are being tracked in issue https://github.com/keep-network/tbtc/issues/556.  Description  There is no explicit restriction on the number of inputs and outputs a Bitcoin transaction can have - as long as the transaction fits into a block. The number of inputs and outputs in a transaction is denoted by a leading  varint  - a variable length integer. In BTCUtils.validateVin and BTCUtils.validateVout, the value of this varint is restricted to under 0xFD, or 253:  bitcoin-spv/solidity/contracts/BTCUtils.sol:L404-L415  /// @notice      Checks that the vin passed up is properly formatted  /// @dev         Consider a vin with a valid vout in its scriptsig  /// @param _vin  Raw bytes length-prefixed input vector  /// @return      True if it represents a validly formatted vin  function validateVin(bytes memory _vin) internal pure returns (bool) {  uint256 _offset = 1;  uint8 _nIns = uint8(_vin.slice(0, 1)[0]);  // Not valid if it says there are too many or no inputs  if (_nIns >= 0xfd || _nIns == 0) {  return false;  Transactions that include more than 252 inputs or outputs will not pass this validation, leading to some legitimate deposits being rejected by the tBTC system.  Examples  The 252-item limit exists in a few forms throughout the system, outside of the aforementioned BTCUtils.validateVin and BTCUtils.validateVout:  BTCUtils.determineOutputLength:  bitcoin-spv/solidity/contracts/BTCUtils.sol:L294-L303  /// @notice          Determines the length of an output  /// @dev             5 types: WPKH, WSH, PKH, SH, and OP_RETURN  /// @param _output   The output  /// @return          The length indicated by the prefix, error if invalid length  function determineOutputLength(bytes memory _output) internal pure returns (uint256) {  uint8 _len = uint8(_output.slice(8, 1)[0]);  require(_len < 0xfd, \"Multi-byte VarInts not supported\");  return _len + 8 + 1; // 8 byte value, 1 byte for _len itself  DepositUtils.findAndParseFundingOutput:  tbtc/implementation/contracts/deposit/DepositUtils.sol:L150-L154  function findAndParseFundingOutput(  DepositUtils.Deposit storage _d,  bytes memory _txOutputVector,  uint8 _fundingOutputIndex  ) public view returns (bytes8) {  DepositUtils.validateAndParseFundingSPVProof:  tbtc/implementation/contracts/deposit/DepositUtils.sol:L181-L191  function validateAndParseFundingSPVProof(  DepositUtils.Deposit storage _d,  bytes4 _txVersion,  bytes memory _txInputVector,  bytes memory _txOutputVector,  bytes4 _txLocktime,  uint8 _fundingOutputIndex,  bytes memory _merkleProof,  uint256 _txIndexInBlock,  bytes memory _bitcoinHeaders  ) public view returns (bytes8 _valueBytes, bytes memory _utxoOutpoint){  DepositFunding.provideFraudBTCFundingProof:  tbtc/implementation/contracts/deposit/DepositFunding.sol:L213-L223  function provideFraudBTCFundingProof(  DepositUtils.Deposit storage _d,  bytes4 _txVersion,  bytes memory _txInputVector,  bytes memory _txOutputVector,  bytes4 _txLocktime,  uint8 _fundingOutputIndex,  bytes memory _merkleProof,  uint256 _txIndexInBlock,  bytes memory _bitcoinHeaders  ) public returns (bool) {  DepositFunding.provideBTCFundingProof:  tbtc/implementation/contracts/deposit/DepositFunding.sol:L263-L273  function provideBTCFundingProof(  DepositUtils.Deposit storage _d,  bytes4 _txVersion,  bytes memory _txInputVector,  bytes memory _txOutputVector,  bytes4 _txLocktime,  uint8 _fundingOutputIndex,  bytes memory _merkleProof,  uint256 _txIndexInBlock,  bytes memory _bitcoinHeaders  ) public returns (bool) {  DepositLiquidation.provideSPVFraudProof:  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L150-L160  function provideSPVFraudProof(  DepositUtils.Deposit storage _d,  bytes4 _txVersion,  bytes memory _txInputVector,  bytes memory _txOutputVector,  bytes4 _txLocktime,  bytes memory _merkleProof,  uint256 _txIndexInBlock,  uint8 _targetInputIndex,  bytes memory _bitcoinHeaders  ) public {  Recommendation  Incorporate varint parsing in BTCUtils.validateVin and BTCUtils.validateVout. Ensure that other components of the system reflect the removal of the 252-item limit.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.13 bitcoin-spv - multiple integer under-/overflows    Addressed", "body": "  Resolution  This was partially addressed in summa-tx/bitcoin-spv#118, summa-tx/bitcoin-spv#119, and summa-tx/bitcoin-spv#122.  Summa opted not to fix the underflow in extractTarget.  In summa-tx/bitcoin-spv#118, the determineOutputLength overflow was addressed by casting _len to a uint256 before addition.  In summa-tx/bitcoin-spv#119, the extractHash underflow was addressed by returning an empty bytes array if the extracted length would cause underflow. Note that an explicit error and transaction revert is favorable in these cases, in order to avoid returning unusable data to the calling function.  Underflow and overflow in BytesLib was addressed in summa-tx/bitcoin-spv#122. Multiple requires were added to the mentioned functions, ensuring memory reads stayed in-bounds for each array. A later change in summa-tx/bitcoin-spv#128 added support for slice with a length of 0.  Description  The bitcoin-spv library allows for multiple integer under-/overflows while processing or converting potentially untrusted or user-provided data.  Examples  uint8 underflow uint256(uint8(_e - 3))  Note: _header[75] will throw consuming all gas if out of bounds while the majority of the library usually uses slice(start, 1) to handle this more gracefully.  bitcoin-spv/solidity/contracts/BTCUtils.sol:L483-L494  /// @dev             Target is a 256 bit number encoded as a 3-byte mantissa and 1 byte exponent  /// @param _header   The header  /// @return          The target threshold  function extractTarget(bytes memory _header) internal pure returns (uint256) {  bytes memory _m = _header.slice(72, 3);  uint8 _e = uint8(_header[75]);  uint256 _mantissa = bytesToUint(reverseEndianness(_m));  uint _exponent = _e - 3;  return _mantissa * (256 ** _exponent);  uint8 overflow uint256(uint8(_len + 8 + 1))  Note: might allow a specially crafted output to return an invalid determineOutputLength <= 9.  Note: while type VarInt is implemented for inputs, it is not for the output length.  bitcoin-spv/solidity/contracts/BTCUtils.sol:L295-L304  /// @dev             5 types: WPKH, WSH, PKH, SH, and OP_RETURN  /// @param _output   The output  /// @return          The length indicated by the prefix, error if invalid length  function determineOutputLength(bytes memory _output) internal pure returns (uint256) {  uint8 _len = uint8(_output.slice(8, 1)[0]);  require(_len < 0xfd, \"Multi-byte VarInts not supported\");  return _len + 8 + 1; // 8 byte value, 1 byte for _len itself  uint8 underflow uint256(uint8(extractOutputScriptLen(_output)[0]) - 2)  bitcoin-spv/solidity/contracts/BTCUtils.sol:L366-L378  /// @dev             Determines type by the length prefix and validates format  /// @param _output   The output  /// @return          The hash committed to by the pk_script, or null for errors  function extractHash(bytes memory _output) internal pure returns (bytes memory) {  if (uint8(_output.slice(9, 1)[0]) == 0) {  uint256 _len = uint8(extractOutputScriptLen(_output)[0]) - 2;  // Check for maliciously formatted witness outputs  if (uint8(_output.slice(10, 1)[0]) != uint8(_len)) {  return hex\"\";  return _output.slice(11, _len);  } else {  bytes32 _tag = _output.keccak256Slice(8, 3);  BytesLib input validation multiple start+length overflow  Note: multiple occurrences. should check start+length > start && bytes.length >= start+length  bitcoin-spv/solidity/contracts/BytesLib.sol:L246-L248  function slice(bytes memory _bytes, uint _start, uint _length) internal  pure returns (bytes memory res) {  require(_bytes.length >= (_start + _length), \"Slice out of bounds\");  BytesLib input validation multiple start overflow  bitcoin-spv/solidity/contracts/BytesLib.sol:L280-L281  function toUint(bytes memory _bytes, uint _start) internal  pure returns (uint256) {  require(_bytes.length >= (_start + 32), \"Uint conversion out of bounds.\");  bitcoin-spv/solidity/contracts/BytesLib.sol:L269-L270  function toAddress(bytes memory _bytes, uint _start) internal  pure returns (address) {  require(_bytes.length >= (_start + 20), \"Address conversion out of bounds.\");  bitcoin-spv/solidity/contracts/BytesLib.sol:L246-L248  function slice(bytes memory _bytes, uint _start, uint _length) internal  pure returns (bytes memory res) {  require(_bytes.length >= (_start + _length), \"Slice out of bounds\");  bitcoin-spv/solidity/contracts/BytesLib.sol:L410-L412  function keccak256Slice(bytes memory _bytes, uint _start, uint _length) pure internal returns (bytes32 result) {  require(_bytes.length >= (_start + _length), \"Slice out of bounds\");  Recommendation  We believe that a general-purpose parsing and verification library for bitcoin payments should be very strict when processing untrusted user input. With strict we mean, that it should rigorously validate provided input data and only proceed with the processing of the data if it is within a safe-to-use range for the method to return valid results. Relying on the caller to provide pre-validate data can be unsafe especially if the caller assumes that proper input validation is performed by the library.  Given the risk profile for this library, we recommend a conservative approach that balances security instead of gas efficiency without relying on certain calls or instructions to throw on invalid input.  For this issue specifically, we recommend proper input validation and explicit type expansion where necessary to prevent values from wrapping or processing data for arguments that are not within a safe-to-use range.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.14 tbtc - Unreachable state LIQUIDATION_IN_PROGRESS    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/tbtc/issues/497 with commits from  keep-network/tbtc#517 changing all non-fraud transitions to end up in  Description  According to the specification (overview, states, version 2020-02-06), a deposit can be in one of two liquidation_in_progress states.  LIQUIDATION_IN_PROGRESS  LIQUIDATION_IN_PROGRESS Liquidation due to undercollateralization or an abort has started Automatic (on-chain) liquidation was unsuccessful  FRAUD_LIQUIDATION_IN_PROGRESS  FRAUD_LIQUIDATION_IN_PROGRESS Liquidation due to fraud has started Automatic (on-chain) liquidation was unsuccessful  However, LIQUIDATION_IN_PROGRESS is unreachable and instead, FRAUD_LIQUIDATION_IN_PROGRESS is always called. This means that all non-fraud state transitions end up in the fraud liquidation path and will perform actions as if fraud was detected even though it might be caused by an undercollateralized notification or courtesy timeout.  Examples  startSignerAbortLiquidation transitions to FRAUD_LIQUIDATION_IN_PROGRESS on non-fraud events notifyUndercollateralizedLiquidation and notifyCourtesyTimeout  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L96-L108  /// @notice         Starts signer liquidation due to abort or undercollateralization  /// @dev            We first attempt to liquidate on chain, then by auction  /// @param  _d      deposit storage pointer  function startSignerAbortLiquidation(DepositUtils.Deposit storage _d) internal {  _d.logStartedLiquidation(false);  // Reclaim used state for gas savings  _d.redemptionTeardown();  _d.seizeSignerBonds();  _d.liquidationInitiated = block.timestamp;  // Store the timestamp for auction  _d.liquidationInitiator = msg.sender;  _d.setFraudLiquidationInProgress();  Recommendation  Verify state transitions and either remove LIQUIDATION_IN_PROGRESS if it is redundant or fix the state transitions for non-fraud liquidations.  Note that Deposit states can be simplified by removing redundant states by setting a flag (e.g. fraudLiquidation) in the deposit instead of adding a state to track the fraud liquidation path.  According to the specification, we assume the following state transitions are desired:  LIQUIDATION_IN_PROGRESS  In case of liquidation due to undercollateralization or abort, the remaining bond value is split 50-50 between the account which triggered the liquidation and the signers.  FRAUD_LIQUIDATION_IN_PROGRESS  In case of liquidation due to fraud, the remaining bond value in full goes to the account which triggered the liquidation by proving fraud.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.15 tbtc - various deposit state transitions can be front-run (e.g. fraud proofs, timeouts)   ", "body": "  Resolution  Addressed with the discussion at https://github.com/keep-network/tbtc/issues/498. It is accepted that a malicious entity may be able to front-run certain fraud proofs as long as fraud is being called out. It is also accepted that calls to certain timeouts may be front-run which could lead to a scenario where the client implementation is always front-run by a malicious actor.  Additionally, the client provided the following statement:  In general, we are comfortable with front-runnable interactions that ensure system integrity, as long as such front-running does not remove the original incentive of the submitter. We believe remaining front-runnable interactions have clear benefits to system actors, such that even if they are front-run, they have reason to submit the transaction.  Description  An entity that can provide proof for fraudulent ECDSA signatures or SPV proofs in the liquidation flow is rewarded with part of the deposit contract ETH value.  Specification: Liquidation Any signer bond left over after the deposit owner is compensated is distributed to the account responsible for reporting the misbehavior (for fraud) or between the signers and the account that triggered liquidation (for collateralization issues).  However, the methods under which proof is provided are not protected from front-running allowing anyone to observe transactions to provideECDSAFraudProof/ provideSPVFraudProof and submit the same proofs with providing a higher gas value.  Please note that a similar issue exists for timeout states providing rewards for calling them out (i.e. they set the liquidationInitiator address).  Examples  provideECDSAFraudProof verifies the fraudulent proof  r,s,v,signedDigest appear to be the fraudulent signature. _preimage is the correct value.  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L117-L137  /// @param _preimage        The sha256 preimage of the digest  function provideECDSAFraudProof(  DepositUtils.Deposit storage _d,  uint8 _v,  bytes32 _r,  bytes32 _s,  bytes32 _signedDigest,  bytes memory _preimage  ) public {  require(  !_d.inFunding() && !_d.inFundingFailure(),  \"Use provideFundingECDSAFraudProof instead\"  );  require(  !_d.inSignerLiquidation(),  \"Signer liquidation already in progress\"  );  require(!_d.inEndState(), \"Contract has halted\");  require(submitSignatureFraud(_d, _v, _r, _s, _signedDigest, _preimage), \"Signature is not fraud\");  startSignerFraudLiquidation(_d);  startSignerFraudLiquidation sets the address that provides the proof as the beneficiary  tbtc/implementation/contracts/deposit/DepositFunding.sol:L153-L179  function provideFundingECDSAFraudProof(  DepositUtils.Deposit storage _d,  uint8 _v,  bytes32 _r,  bytes32 _s,  bytes32 _signedDigest,  bytes memory _preimage  ) public {  require(  _d.inAwaitingBTCFundingProof(),  \"Signer fraud during funding flow only available while awaiting funding\"  );  bool _isFraud = _d.submitSignatureFraud(_v, _r, _s, _signedDigest, _preimage);  require(_isFraud, \"Signature is not fraudulent\");  _d.logFraudDuringSetup();  // If the funding timeout has elapsed, punish the funder too!  if (block.timestamp > _d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {  address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)  _d.setFailedSetup();  } else {  /* NB: This is reuse of the variable */  _d.fundingProofTimerStart = block.timestamp;  _d.setFraudAwaitingBTCFundingProof();  purchaseSignerBondsAtAuction pays out the funds  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L260-L276  uint256 contractEthBalance = address(this).balance;  address payable initiator = _d.liquidationInitiator;  if (initiator == address(0)){  initiator = address(0xdead);  if (contractEthBalance > 1) {  if (_wasFraud) {  initiator.transfer(contractEthBalance);  } else {  // There will always be a liquidation initiator.  uint256 split = contractEthBalance.div(2);  _d.pushFundsToKeepGroup(split);  initiator.transfer(split);  Recommendation  For fraud proofs, it should be required that the reporter uses a commit/reveal scheme to lock in a proof in one block, and reveal the details in another.  ", "labels": ["Consensys", "Major", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.16 tbtc - Anyone can emit log events due to missing access control    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/tbtc/issues/477,  keep-network/tbtc#467 and  keep-network/tbtc#537 by restricting log calls to known  Description  Examples  tbtc/implementation/contracts/DepositLog.sol:L95-L99  function approvedToLog(address _caller) public pure returns (bool) {  /* TODO: auth via system */  _caller;  return true;  Recommendation  Log events are typically initiated by the Deposit contract. Make sure only Deposit contracts deployed by an approved factory can emit logs on TBTCSystem.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.17 DKGResultVerification.verify unsafe packing in signed data    Addressed", "body": "  Resolution                           Addressed with   keep-network/keep-core#1525 by adding additional checks for  Description  DKGResultVerification.verify allows the sender to arbitrarily move bytes between groupPubKey and misbehaved:  keep-core/contracts/solidity/contracts/libraries/operator/DKGResultVerification.sol:L80  bytes32 resultHash = keccak256(abi.encodePacked(groupPubKey, misbehaved));  Recommendation  Validate the expected length of both and add a salt between the two.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.18 keep-core - Service contract callbacks can be abused to call into other contracts    Addressed", "body": "  Resolution  Addressed with keep-network/keep-core#1532 by hardcoding the callback method signature and the following statement:  We still allow specifying an address of the callback contract. This could be beneficial in a situations where one contract pays for a random number for another contract.  A subsequent change in keep-network/keep-ecdsa#339 updated keep-tecdsa to use the new, hardcoded callback function: __beaconCallback(uint256).  Description  KeepRandomBeaconServiceImplV1 allows senders to specify an arbitrary method and contract that will receive a callback once the beacon generates a relay entry:  keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L228-L245  /**  @dev Creates a request to generate a new relay entry, which will include  a random number (by signing the previous entry's random number).  @param callbackContract Callback contract address. Callback is called once a new relay entry has been generated.  @param callbackMethod Callback contract method signature. String representation of your method with a single  uint256 input parameter i.e. \"relayEntryCallback(uint256)\".  @param callbackGas Gas required for the callback.  The customer needs to ensure they provide a sufficient callback gas  to cover the gas fee of executing the callback. Any surplus is returned  to the customer. If the callback gas amount turns to be not enough to  execute the callback, callback execution is skipped.  @return An uint256 representing uniquely generated relay request ID. It is also returned as part of the event.  /  function requestRelayEntry(  address callbackContract,  string memory callbackMethod,  uint256 callbackGas  ) public nonReentrant payable returns (uint256) {  Once an operator contract receives the relay entry, it calls executeCallback:  keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L314-L335  /**  @dev Executes customer specified callback for the relay entry request.  @param requestId Request id tracked internally by this contract.  @param entry The generated random number.  @return Address to receive callback surplus.  /  function executeCallback(uint256 requestId, uint256 entry) public returns (address payable surplusRecipient) {  require(  _operatorContracts.contains(msg.sender),  \"Only authorized operator contract can call execute callback.\"  );  require(  _callbacks[requestId].callbackContract != address(0),  \"Callback contract not found\"  );  _callbacks[requestId].callbackContract.call(abi.encodeWithSignature(_callbacks[requestId].callbackMethod, entry));  surplusRecipient = _callbacks[requestId].surplusRecipient;  delete _callbacks[requestId];  Arbitrary callbacks can be used to force the service contract to execute many functions within the keep contract system. Currently, the KeepRandomBeaconOperator includes an onlyServiceContract modifier:  keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L150-L159  /**  @dev Checks if sender is authorized.  /  modifier onlyServiceContract() {  require(  serviceContracts.contains(msg.sender),  \"Caller is not an authorized contract\"  );  _;  The functions it protects cannot be targeted by the aforementioned service contract callbacks due to Solidity s CALLDATASIZE checking. However, the presence of the modifier suggests that the service contract is expected to be a permissioned actor within some contracts.  Recommendation  Stick to a constant callback method signature, rather than allowing users to submit an arbitrary string. An example is __beaconCallback__(uint256).  Consider disallowing arbitrary callback destinations. Instead, rely on contracts making requests directly, and default the callback destination to msg.sender. Ensure the sender is not an EOA.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.19 tbtc - Disallow signatures with high-s values in DepositRedemption.provideRedemptionSignature    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/tbtc#518  Description  DepositRedemption.provideRedemptionSignature is used by signers to publish a signature that can be used to redeem a deposit on Bitcoin. The function accepts a signature s value in the upper half of the secp256k1 curve:  tbtc/implementation/contracts/deposit/DepositRedemption.sol:L183-L202  function provideRedemptionSignature(  DepositUtils.Deposit storage _d,  uint8 _v,  bytes32 _r,  bytes32 _s  ) public {  require(_d.inAwaitingWithdrawalSignature(), \"Not currently awaiting a signature\");  // If we're outside of the signature window, we COULD punish signers here  // Instead, we consider this a no-harm-no-foul situation.  // The signers have not stolen funds. Most likely they've just inconvenienced someone  // The signature must be valid on the pubkey  require(  _d.signerPubkey().checkSig(  _d.lastRequestedDigest,  _v, _r, _s  ),  \"Invalid signature\"  );  Although ecrecover accepts signatures with these s values, they are no longer used in Bitcoin. As such, the signature will appear to be valid to the Ethereum smart contract, but will likely not be accepted on Bitcoin. If no users watching malleate the signature, the redemption process will likely enter a fee increase loop, incurring a cost on the deposit owner.  Recommendation  Ensure the passed-in s value is restricted to the lower half of the secp256k1 curve, as done in BondedECDSAKeep:  keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L333-L340  // Validate `s` value for a malleability concern described in EIP-2.  // Only signatures with `s` value in the lower half of the secp256k1  // curve's order are considered valid.  require(  uint256(_s) <=  0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0,  \"Malleable signature - s should be in the low half of secp256k1 curve's order\"  );  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.20 Consistent use of SafeERC20 for external tokens    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/keep-core/issues/1407 and  https://github.com/keep-network/keep-tecdsa/issues/272.  Description  Use SafeERC20 features to interact with potentially broken tokens used in the system. E.g. TokenGrant.receiveApproval() is using safeTransferFrom while other contracts aren t.  Examples  TokenGrant.receiveApproval using safeTransferFrom  keep-core/contracts/solidity/contracts/TokenGrant.sol:L200-L200  token.safeTransferFrom(_from, address(this), _amount);  TokenStaking.receiveApproval not using safeTransferFrom while safeTransfer is being used.  keep-core/contracts/solidity/contracts/TokenStaking.sol:L75-L75  token.transferFrom(_from, address(this), _value);  keep-core/contracts/solidity/contracts/TokenStaking.sol:L103-L103  token.safeTransfer(owner, amount);  keep-core/contracts/solidity/contracts/TokenStaking.sol:L193-L193  token.transfer(tattletale, tattletaleReward);  distributeERC20ToMembers not using safeTransferFrom  keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L459-L463  token.transferFrom(  msg.sender,  tokenStaking.magpieOf(members[i]),  dividend  );  Recommendation  Consistently use SafeERC20 to support potentially broken tokens external to the system.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.21 Initialize implementations for proxy contracts and protect initialization methods    Addressed", "body": "  Resolution                           This issue is addressed with the following changesets that ensure that the logic contracts cannot be used by other parties by initializing them in the constructor:   https://github.com/keep-network/keep-tecdsa/issues/297,  https://github.com/keep-network/keep-core/issues/1424, and  https://github.com/keep-network/tbtc/issues/500.  Description  It should be avoided that the implementation for proxy contracts can be initialized by third parties. This can be the case if the initialize function is unprotected. Since the implementation contract is not meant to be used directly without a proxy delegate-calling it is recommended to protect the initialization method of the implementation by initializing on deployment.  Changing the proxies implementation (upgradeTo()) to a version that does not protect the initialization method may allow someone to front-run and initialize the contract if it is not done within the same transaction.  Examples  KeepVendor delegates to KeepVendorImplV1. The implementations initialization method is unprotected.  keep-tecdsa/solidity/contracts/BondedECDSAKeepVendorImplV1.sol:L22-L32  /// @notice Initializes Keep Vendor contract implementation.  /// @param registryAddress Keep registry contract linked to this contract.  function initialize(  address registryAddress  public  require(!initialized(), \"Contract is already initialized.\");  _initialized[\"BondedECDSAKeepVendorImplV1\"] = true;  registry = Registry(registryAddress);  KeepRandomBeaconServiceImplV1 and KeepRandomBeaconServiceUpgradeExample  keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L118-L137  function initialize(  uint256 priceFeedEstimate,  uint256 fluctuationMargin,  uint256 dkgContributionMargin,  uint256 withdrawalDelay,  address registry  public  require(!initialized(), \"Contract is already initialized.\");  _initialized[\"KeepRandomBeaconServiceImplV1\"] = true;  _priceFeedEstimate = priceFeedEstimate;  _fluctuationMargin = fluctuationMargin;  _dkgContributionMargin = dkgContributionMargin;  _withdrawalDelay = withdrawalDelay;  _pendingWithdrawal = 0;  _previousEntry = _beaconSeed;  _registry = registry;  _baseCallbackGas = 18845;  Deposit is deployed via cloneFactory delegating to a masterDepositAddress in DepositFactory. The masterDepositAddress (Deposit) might be left uninitialized.  tbtc/implementation/contracts/system/DepositFactoryAuthority.sol:L3-L14  contract DepositFactoryAuthority {  bool internal _initialized = false;  address internal _depositFactory;  /// @notice Set the address of the System contract on contract initialization  function initialize(address _factory) public {  require(! _initialized, \"Factory can only be initialized once.\");  _depositFactory = _factory;  _initialized = true;  Recommendation  Initialize unprotected implementation contracts in the implementation s constructor. Protect initialization methods from being called by unauthorized parties or ensure that deployment of the proxy and initialization is performed in the same transaction.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.22 keep-tecdsa - If caller sends more than is contained in the signer subsidy pool, the value is burned    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/keep-ecdsa#306. The  Description  The signer subsidy pool in BondedECDSAKeepFactory tracks funds sent to the contract. Each time a keep is opened, the subsidy pool is intended to be distributed to the members of the new keep:  keep-tecdsa/solidity/contracts/BondedECDSAKeepFactory.sol:L312-L320  // If subsidy pool is non-empty, distribute the value to signers but  // never distribute more than the payment for opening a keep.  uint256 signerSubsidy = subsidyPool < msg.value  ? subsidyPool  : msg.value;  if (signerSubsidy > 0) {  subsidyPool -= signerSubsidy;  keep.distributeETHToMembers.value(signerSubsidy)();  The tracking around subsidy pool increases is inconsistent, and can lead to sent value being burned. In the case that subsidyPool contains less Ether than is sent in msg.value, msg.value is unused and remains in the contract. It may or may not be added to subsidyPool, depending on the return status of the random beacon:  keep-tecdsa/solidity/contracts/BondedECDSAKeepFactory.sol:L347-L357  (bool success, ) = address(randomBeacon).call.gas(400000).value(msg.value)(  abi.encodeWithSignature(  \"requestRelayEntry(address,string,uint256)\",  address(this),  \"setGroupSelectionSeed(uint256)\",  callbackGas  );  if (!success) {  subsidyPool += msg.value; // beacon is busy  Recommendation  Rather than tracking the subsidyPool individually, simply distribute this.balance to each new keep s members.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.23 keep-core - TokenGrant and TokenStaking allow staking zero amount of tokens and front-running    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/keep-core/issues/1425 and  keep-network/keep-core#1461 by requiring a hardcoded minimum amount of tokens to be staked.  Description  Tokens are staked via the callback receiveApproval() which is normally invoked when calling approveAndCall(). The method is not restricting who can initiate the staking of tokens and relies on the fact that the token transfer to the TokenStaking contract is pre-approved by the owner, otherwise, the call would revert.  However, receiveApproval() allows the staking of a zero amount of tokens. The only check performed on the number of tokens transferred is, that the token holders balance covers the amount to be transferred. This check is both relatively weak - having enough balance does not imply that tokens are approved for transfer - and does not cover the fact that someone can call the method with a zero amount of tokens.  This way someone could create an arbitrary number of operators staking no tokens at all. This passes the token balance check, token.transferFrom() will succeed and an operator struct with a zero stake and arbitrary values for operator, from, magpie, authorizer can be set. Finally, an event is emitted for a zero stake.  An attacker could front-run calls to receiveApproval to block staking of a legitimate operator by creating a zero stake entry for the operator before she is able to. This vector might allow someone to permanently inconvenience an operator s address. To recover from this situation one could be forced to cancelStake terminating the zero stake struct in order to call the contract with the correct stake again.  The same issue exists for TokenGrant.  Examples  keep-core/contracts/solidity/contracts/TokenStaking.sol:L54-L81  /**  @notice Receives approval of token transfer and stakes the approved amount.  @dev Makes sure provided token contract is the same one linked to this contract.  @param _from The owner of the tokens who approved them to transfer.  @param _value Approved amount for the transfer and stake.  @param _token Token contract address.  @param _extraData Data for stake delegation. This byte array must have the  following values concatenated: Magpie address (20 bytes) where the rewards for participation  are sent, operator's (20 bytes) address, authorizer (20 bytes) address.  /  function receiveApproval(address _from, uint256 _value, address _token, bytes memory _extraData) public {  require(ERC20Burnable(_token) == token, \"Token contract must be the same one linked to this contract.\");  require(_value <= token.balanceOf(_from), \"Sender must have enough tokens.\");  require(_extraData.length == 60, \"Stake delegation data must be provided.\");  address payable magpie = address(uint160(_extraData.toAddress(0)));  address operator = _extraData.toAddress(20);  require(operators[operator].owner == address(0), \"Operator address is already in use.\");  address authorizer = _extraData.toAddress(40);  // Transfer tokens to this contract.  token.transferFrom(_from, address(this), _value);  operators[operator] = Operator(_value, block.number, 0, _from, magpie, authorizer);  ownerOperators[_from].push(operator);  emit Staked(operator, _value);  Recommendation  Require tokens to be staked and explicitly disallow the zero amount of tokens case. The balance check can be removed.  Note: Consider checking the calls return value or calling the contract via SafeERC20 to support potentially broken tokens that do not revert in error cases (token.transferFrom).  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.24 tbtc - Inconsistency between increaseRedemptionFee and provideRedemptionProof may create un-provable redemptions    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/tbtc#522  Description  DepositRedemption.increaseRedemptionFee is used by signers to approve a signable bitcoin transaction with a higher fee, in case the network is congested and miners are not approving the lower-fee transaction.  Fee increases can be performed every 4 hours:  tbtc/implementation/contracts/deposit/DepositRedemption.sol:L225  require(block.timestamp >= _d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");  In addition, each increase must increment the fee by exactly the initial proposed fee:  tbtc/implementation/contracts/deposit/DepositRedemption.sol:L260-L263  // Check that we're incrementing the fee by exactly the redeemer's initial fee  uint256 _previousOutputValue = DepositUtils.bytes8LEToUint(_previousOutputValueBytes);  _newOutputValue = DepositUtils.bytes8LEToUint(_newOutputValueBytes);  require(_previousOutputValue.sub(_newOutputValue) == _d.initialRedemptionFee, \"Not an allowed fee step\");  Outside of these two restrictions, there is no limit to the number of times increaseRedemptionFee can be called. Over a 20-hour period, for example, increaseRedemptionFee could be called 5 times, increasing the fee to initialRedemptionFee * 5. Over a 24-hour period, increaseRedemptionFee could be called 6 times, increasing the fee to initialRedemptionFee * 6.  Eventually, it is expected that a transaction will be submitted and mined. At this point, anyone can call DepositRedemption.provideRedemptionProof, finalizing the redemption process and rewarding the signers. However, provideRedemptionProof will fail if the transaction fee is too high:  tbtc/implementation/contracts/deposit/DepositRedemption.sol:L308  require((_d.utxoSize().sub(_fundingOutputValue)) <= _d.initialRedemptionFee * 5, \"Fee unexpectedly very high\");  In the case that increaseRedemptionFee is called 6 times and the signers provide a signature for this transaction, the transaction can be submitted and mined but provideRedemptionProof for this will always fail. Eventually, a redemption proof timeout will trigger the deposit into liquidation and the signers will be punished.  Recommendation  Because it is difficult to say with certainty that a 5x fee increase will always ensure a transaction s redeemability, the upper bound on fee bumps should be removed from provideRedemptionProof.  This should be implemented in tandem with issue 5.37, so that signers cannot provide a proof that bypasses increaseRedemptionFee flow to spend the highest fee possible.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.25 keep-tecdsa - keep cannot be closed if a members bond was seized or fully reassigned    Addressed", "body": "  Description  A keep cannot be closed if the bonds have been completely reassigned or seized before, leaving at least one member with zero lockedBonds. In this case closeKeep() will throw in freeMembersBonds() because the requirement in keepBonding.freeBond is not satisfied anymore (lockedBonds[bondID] > 0). As a result of this, none of the potentially remaining bonds (reassign) are freed, the keep stays active even though it should be closed.  Examples  keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L373-L396  /// @notice Closes keep when owner decides that they no longer need it.  /// Releases bonds to the keep members. Keep can be closed only when  /// there is no signing in progress or requested signing process has timed out.  /// @dev The function can be called by the owner of the keep and only is the  /// keep has not been closed already.  function closeKeep() external onlyOwner onlyWhenActive {  require(  !isSigningInProgress() || hasSigningTimedOut(),  \"Requested signing has not timed out yet\"  );  isActive = false;  freeMembersBonds();  emit KeepClosed();  /// @notice Returns bonds to the keep members.  function freeMembersBonds() internal {  for (uint256 i = 0; i < members.length; i++) {  keepBonding.freeBond(members[i], uint256(address(this)));  keep-tecdsa/solidity/contracts/KeepBonding.sol:L173-L190  /// @notice Releases the bond and moves the bond value to the operator's  /// unbounded value pool.  /// @dev Function requires that caller is the holder of the bond which is  /// being released.  /// @param operator Address of the bonded operator.  /// @param referenceID Reference ID of the bond.  function freeBond(address operator, uint256 referenceID) public {  address holder = msg.sender;  bytes32 bondID = keccak256(  abi.encodePacked(operator, holder, referenceID)  );  require(lockedBonds[bondID] > 0, \"Bond not found\");  uint256 amount = lockedBonds[bondID];  lockedBonds[bondID] = 0;  unbondedValue[operator] = amount;  Recommendation  Make sure the keep can be set to an end-state (closed/inactive) indicating its end-of-life even if the bond has been seized before. Avoid throwing an exception when freeing member bonds to avoid blocking the unlocking of bonds.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.26 tbtc - provideFundingECDSAFraudProof attempts to burn non-existent funds    Addressed", "body": "  Resolution                           Addressed as   https://github.com/keep-network/tbtc/issues/502 and fixed with  keep-network/tbtc#523.  Description  The funding flow was recently changed from requiring the funder to provide a bond that stays in the Deposit contract to forwarding the funds to the keep, paying for the keep setup.  So at a high level, the funding bond was designed to ensure that funders had some minimum skin in the game, so that DoSing signers/the system was expensive. The upside was that we could refund it in happy paths. Now that we ve realized that opening the keep itself will cost enough to prevent DoS, the concept of refunding goes away entirely. We definitely missed cleaning up the funder handling in provideFundingECDSAFraudProof though.  Examples  tbtc/implementation/contracts/deposit/DepositFunding.sol:L170-L173  // If the funding timeout has elapsed, punish the funder too!  if (block.timestamp > _d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {  address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)  _d.setFailedSetup();  Recommendation  Remove the line that attempts to punish the funder by burning the Deposit contract balance which is zero due to recent changes in how the payment provided with createNewDepositis handled.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.27 bitcoin-spv - Bitcoin output script length is not checked in wpkhSpendSighash   ", "body": "  Resolution                           Summa opted not to make this change. See   https://github.com/summa-tx/bitcoin-spv/issues/112 for details.  Description  CheckBitcoinSigs.wpkhSpendSighash calculates the sighash of a Bitcoin transaction. Among its parameters, it accepts bytes memory _outpoint, which is a 36-byte UTXO id consisting of a 32-byte transaction hash and a 4-byte output index.  The function in question should not accept an _outpoint that is not 36-bytes, but no length check is made:  bitcoin-spv/solidity/contracts/CheckBitcoinSigs.sol:L130-L159  function wpkhSpendSighash(  bytes memory _outpoint,  // 36 byte UTXO id  bytes20 _inputPKH,       // 20 byte hash160  bytes8 _inputValue,      // 8-byte LE  bytes8 _outputValue,     // 8-byte LE  bytes memory _outputScript    // lenght-prefixed output script  ) internal pure returns (bytes32) {  // Fixes elements to easily make a 1-in 1-out sighash digest  // Does not support timelocks  bytes memory _scriptCode = abi.encodePacked(  hex\"1976a914\",  // length, dup, hash160, pkh_length  _inputPKH,  hex\"88ac\");  // equal, checksig  bytes32 _hashOutputs = abi.encodePacked(  _outputValue,  // 8-byte LE  _outputScript).hash256();  bytes memory _sighashPreimage = abi.encodePacked(  hex\"01000000\",  // version  _outpoint.hash256(),  // hashPrevouts  hex\"8cb9012517c817fead650287d61bdd9c68803b6bf9c64133dcab3e65b5a50cb9\",  // hashSequence(00000000)  _outpoint,  // outpoint  _scriptCode,  // p2wpkh script code  _inputValue,  // value of the input in 8-byte LE  hex\"00000000\",  // input nSequence  _hashOutputs,  // hash of the single output  hex\"00000000\",  // nLockTime  hex\"01000000\"  // SIGHASH_ALL  );  return _sighashPreimage.hash256();  Recommendation  Check that _outpoint.length is 36.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.28 tbtc - liquidationInitiator can block purchaseSignerBondsAtAuction indefinitely    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/tbtc/issues/503 and commits from  keep-network/tbtc#524 switching from  Description  When reporting a fraudulent proof the deposits liquidationInitiator is set to the entity reporting and proofing the fraud. The deposit that is in a *_liquidation_in_progress state can be bought by anyone at an auction calling purchaseSignerBondsAtAuction.  Instead of receiving a share of the funds the liquidationInitiator can decide to intentionally reject the funds by raising an exception causing initiator.transfer(contractEthBalance) to throw, blocking the auction and forcing the liquidation to fail. The deposit will stay in one of the *_liquidation_in_progress states.  Examples  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L224-L276  /// @notice     Closes an auction and purchases the signer bonds. Payout to buyer, funder, then signers if not fraud  /// @dev        For interface, reading auctionValue will give a past value. the current is better  /// @param  _d  deposit storage pointer  function purchaseSignerBondsAtAuction(DepositUtils.Deposit storage _d) public {  bool _wasFraud = _d.inFraudLiquidationInProgress();  require(_d.inSignerLiquidation(), \"No active auction\");  _d.setLiquidated();  _d.logLiquidated();  // send the TBTC to the TDT holder. If the TDT holder is the Vending Machine, burn it to maintain the peg.  address tdtHolder = _d.depositOwner();  TBTCToken _tbtcToken = TBTCToken(_d.TBTCToken);  uint256 lotSizeTbtc = _d.lotSizeTbtc();  require(_tbtcToken.balanceOf(msg.sender) >= lotSizeTbtc, \"Not enough TBTC to cover outstanding debt\");  if(tdtHolder == _d.VendingMachine){  _tbtcToken.burnFrom(msg.sender, lotSizeTbtc);  // burn minimal amount to cover size  else{  _tbtcToken.transferFrom(msg.sender, tdtHolder, lotSizeTbtc);  // Distribute funds to auction buyer  uint256 _valueToDistribute = _d.auctionValue();  msg.sender.transfer(_valueToDistribute);  // Send any TBTC left to the Fee Rebate Token holder  _d.distributeFeeRebate();  // For fraud, pay remainder to the liquidation initiator.  // For non-fraud, split 50-50 between initiator and signers. if the transfer amount is 1,  // division will yield a 0 value which causes a revert; instead,  // we simply ignore such a tiny amount and leave some wei dust in escrow  uint256 contractEthBalance = address(this).balance;  address payable initiator = _d.liquidationInitiator;  if (initiator == address(0)){  initiator = address(0xdead);  if (contractEthBalance > 1) {  if (_wasFraud) {  initiator.transfer(contractEthBalance);  } else {  // There will always be a liquidation initiator.  uint256 split = contractEthBalance.div(2);  _d.pushFundsToKeepGroup(split);  initiator.transfer(split);  Recommendation  Use a pull vs push funds pattern or use address.send instead of address.transfer which might leave some funds locked in the contract if it fails.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.29 bitcoin-spv - verifyHash256Merkle allows existence proofs for the same leaf in multiple locations in the tree   ", "body": "  Resolution                           Summa opted not to make this change, citing inconsistencies in Bitcoin s merkle implementation. See   https://github.com/summa-tx/bitcoin-spv/issues/108 for details.  Description  BTCUtils.verifyHash256Merkle is used by ValidateSPV.prove to validate a transaction s existence in a Bitcoin block. The function accepts as input a _proof and an _index. The _proof consists of, in order: the transaction hash, a list of intermediate nodes, and the merkle root.  The proof is performed iteratively, and uses the _index to determine whether the next proof element represents a  left branch  or a  right branch:   bitcoin-spv/solidity/contracts/BTCUtils.sol:L574-L586  uint _idx = _index;  bytes32 _root = _proof.slice(_proof.length - 32, 32).toBytes32();  bytes32 _current = _proof.slice(0, 32).toBytes32();  for (uint i = 1; i < (_proof.length.div(32)) - 1; i++) {  if (_idx % 2 == 1) {  _current = _hash256MerkleStep(_proof.slice(i * 32, 32), abi.encodePacked(_current));  } else {  _current = _hash256MerkleStep(abi.encodePacked(_current), _proof.slice(i * 32, 32));  _idx = _idx >> 1;  return _current == _root;  If _idx is even, the computed hash is placed before the next proof element. If _idx is odd, the computed hash is placed after the next proof element. After each iteration, _idx is decremented by _idx /= 2.  Because verifyHash256Merkle makes no requirements on the size of _proof relative to _index, it is possible to pass in invalid values for _index that prove a transaction s existence in multiple locations in the tree.  Examples  By modifying existing tests, we showed that any transaction can be proven to exist at least one alternate index. This alternate index is calculated as (2 ** treeHeight) + prevIndex - though other alternate indices are possible. The modified test is below:  Recommendation  Use the length of _proof to determine the maximum allowed _index. _index should satisfy the following criterion: _index < 2 ** (_proof.length.div(32) - 2).  Note that subtraction by 2 accounts for the transaction hash and merkle root, which are assumed to be encoded in the proof along with the intermediate nodes.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.30 keep-core - stake operator should not be eligible if undelegatedAt is set    Addressed", "body": "  Resolution  Addressed with https://github.com/keep-network/keep-core/issues/1433 by enforcing that stake must be canceled in initialization period.  undelegatedAt is intended to support undelegation in advance at any given time. Whether we do < or <= is not actually significant, as transaction reordering also means ability to include/not include transactions arbitrarily, but changing the check to operator.UndelegatedAt == 0 would ruin e.g. the use-case where Alice wants to delegate to Bob for 12 months. If we don t currently need that use-case, the check can be simplified to == 0.  Description  An operator s stake should not be eligible if they stake an amount and immediately call undelegate in an attempt to indicate that they are going to recover their stake soon.  Examples  keep-core/contracts/solidity/contracts/TokenStaking.sol:L232-L236  bool notUndelegated = block.number <= operator.undelegatedAt || operator.undelegatedAt == 0;  if (isAuthorized && isActive && notUndelegated) {  balance = operator.amount;  Recommendation  A stake that is entering undelegation is indicated by operator.undelegatedAt being non-zero. Change the notUndelegated check block.number <= operator.undelegatedAt || operator.undelegatedAt == 0 to operator.undelegatedAT == 0 as any value being set indicates that undelegation is in progress.  Enforce that within the initialization period stake is canceled instead of being undelegated.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.31 keep-core - Specification inconsistency: TokenStaking amount to be slashed/seized    Addressed", "body": "  Resolution                           Partially addressed with   https://github.com/keep-network/keep-core/issues/1428 by ensuring that at least some stack is slashed. As noted in the issue, the case where less than the minimum stake was slashed from an operator is left unhandled with this fix.  Description  The keep specification states that slash and seize affect at least the amount specified or the remaining stake of a member.  Slash each operator in the list misbehavers by the specified amount (or their remaining stake, whichever is lower).  Punish each operator in the list misbehavers by the specified amount or their remaining stake.  The implementation, however, bails if one of the accounts does not have enough stake to be slashed or seized because of the use of SafeMath.sub(). This behavior is inconsistent with the specification which states that min(amount, misbehaver.stake) stake should be affected. The call to slash/seize will revert and no stakes are affected. At max, the staked amount of the lowest staker can be slashed/seized from every staker.  Implementing this method as stated in the specification using min(amount, misbehaver.stake) will cover the fact that slashing/seizing was only partially successful. If misbehaver.stake is zero no error might be emitted even though no stake was slashed/seized.  Examples  keep-core/contracts/solidity/contracts/TokenStaking.sol:L151-L195  /**  @dev Slash provided token amount from every member in the misbehaved  operators array and burn 100% of all the tokens.  @param amount Token amount to slash from every misbehaved operator.  @param misbehavedOperators Array of addresses to seize the tokens from.  /  function slash(uint256 amount, address[] memory misbehavedOperators)  public  onlyApprovedOperatorContract(msg.sender) {  for (uint i = 0; i < misbehavedOperators.length; i++) {  address operator = misbehavedOperators[i];  require(authorizations[msg.sender][operator], \"Not authorized\");  operators[operator].amount = operators[operator].amount.sub(amount);  token.burn(misbehavedOperators.length.mul(amount));  /**  @dev Seize provided token amount from every member in the misbehaved  operators array. The tattletale is rewarded with 5% of the total seized  amount scaled by the reward adjustment parameter and the rest 95% is burned.  @param amount Token amount to seize from every misbehaved operator.  @param rewardMultiplier Reward adjustment in percentage. Min 1% and 100% max.  @param tattletale Address to receive the 5% reward.  @param misbehavedOperators Array of addresses to seize the tokens from.  /  function seize(  uint256 amount,  uint256 rewardMultiplier,  address tattletale,  address[] memory misbehavedOperators  ) public onlyApprovedOperatorContract(msg.sender) {  for (uint i = 0; i < misbehavedOperators.length; i++) {  address operator = misbehavedOperators[i];  require(authorizations[msg.sender][operator], \"Not authorized\");  operators[operator].amount = operators[operator].amount.sub(amount);  uint256 total = misbehavedOperators.length.mul(amount);  uint256 tattletaleReward = (total.mul(5).div(100)).mul(rewardMultiplier).div(100);  token.transfer(tattletale, tattletaleReward);  token.burn(total.sub(tattletaleReward));  Recommendation  Require that minimumStake has been provided and can be seized/slashed. Update the documentation to reflect the fact that the solution always seizes/slashes minimumStake. Ensure that stakers cannot cancel their stake while they are actively participating in the network.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.32 keep-tecdsa - Change state-mutability of checkSignatureFraud to view    Addressed", "body": "  Resolution                           Addressed as part of   https://github.com/keep-network/keep-tecdsa/issues/254 with commits from  keep-network/keep-tecdsa#283 splitting the method into two parts:  Description  BondedECDSAKeep.sol.submitSignatureFraud is not state-changing and should, therefore, be declared with the function state-mutability view.  Examples  keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L265-L290  function submitSignatureFraud(  uint8 _v,  bytes32 _r,  bytes32 _s,  bytes32 _signedDigest,  bytes calldata _preimage  ) external returns (bool _isFraud) {  require(publicKey.length != 0, \"Public key was not set yet\");  bytes32 calculatedDigest = sha256(_preimage);  require(  _signedDigest == calculatedDigest,  \"Signed digest does not match double sha256 hash of the preimage\"  );  bool isSignatureValid = publicKeyToAddress(publicKey) ==  ecrecover(_signedDigest, _v, _r, _s);  // Check if the signature is valid but was not requested.  require(  isSignatureValid && !digests[_signedDigest],  \"Signature is not fraudulent\"  );  return true;  Recommendation  Declare method as view. Consider renaming submitSignatureFraud to e.g. checkSignatureFraud to emphasize that it is only checking the signature and not actually changing state.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.33 keep-core - Specification inconsistency: TokenStaking.slash() is never called    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/keep-tecdsa/issues/254 and changesets from  keep-network/keep-tecdsa#283 by slashing the signer stakes when signature fraud is proven.  Description  According to the keep specification stake should be slashed if a staker violates the protocol:  Slashing If a staker violates the protocol of an operation in a way which can be proven on-chain, they will be penalized by having their stakes slashed.  While this functionality can only be called by the approved operator contract, it is not being used throughout the system. In contrast seize() is being called when reporting unauthorized signing or relay entry timeout.  Examples  keep-core/contracts/solidity/contracts/TokenStaking.sol:L151-L167  /**  @dev Slash provided token amount from every member in the misbehaved  operators array and burn 100% of all the tokens.  @param amount Token amount to slash from every misbehaved operator.  @param misbehavedOperators Array of addresses to seize the tokens from.  /  function slash(uint256 amount, address[] memory misbehavedOperators)  public  onlyApprovedOperatorContract(msg.sender) {  for (uint i = 0; i < misbehavedOperators.length; i++) {  address operator = misbehavedOperators[i];  require(authorizations[msg.sender][operator], \"Not authorized\");  operators[operator].amount = operators[operator].amount.sub(amount);  token.burn(misbehavedOperators.length.mul(amount));  Recommendation  Implement slashing according to the specification.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.34 tbtc - Remove notifyDepositExpiryCourtesyCall and allow exitCourtesyCall exiting the courtesy call at term    Addressed", "body": "  Resolution                           Addressed with   keep-network/tbtc#476 following the recommendation.  Description  Following a deep dive into state transitions with the client it was agreed that notifyDepositExpiryCourtesyCall should be removed from the system as it is a left-over of a previous version of the deposit contract.  Additionally, exitCourtesyCall should be callable at any time.  Examples  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L289-L298  /// @notice     Goes from courtesy call to active  /// @dev        Only callable if collateral is sufficient and the deposit is not expiring  /// @param  _d  deposit storage pointer  function exitCourtesyCall(DepositUtils.Deposit storage _d) public {  require(_d.inCourtesyCall(), \"Not currently in courtesy call\");  require(block.timestamp <= _d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit is expiring\");  require(getCollateralizationPercentage(_d) >= _d.undercollateralizedThresholdPercent, \"Deposit is still undercollateralized\");  _d.setActive();  _d.logExitedCourtesyCall();  Recommendation  Remove the notifyDepositExpiryCourtesyCall state transition and remove the requirement on exitCourtesyCall being callable only before the deposit expires.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.35 keep-tecdsa - withdraw should check for zero value transfer    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/keep-tecdsa/issues/280 by denying zero value withdrawals.  Description  Requesting the withdrawal of zero ETH in KeepBonding.withdraw should fail as this would allow the method to succeed, calling the user-provided destination even though the sender has no unbonded value.  Examples  keep-tecdsa/solidity/contracts/KeepBonding.sol:L78-L88  function withdraw(uint256 amount, address payable destination) public {  require(  unbondedValue[msg.sender] >= amount,  \"Insufficient unbonded value\"  );  unbondedValue[msg.sender] -= amount;  (bool success, ) = destination.call.value(amount)(\"\");  require(success, \"Transfer failed\");  And a similar instance in BondedECDSAKeep:  keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L487-L498  /// @notice Withdraws amount of ether hold in the keep for the member.  /// The value is sent to the beneficiary of the specific member.  /// @param _member Keep member address.  function withdraw(address _member) external {  uint256 value = memberETHBalances[_member];  memberETHBalances[_member] = 0;  /* solium-disable-next-line security/no-call-value */  (bool success, ) = tokenStaking.magpieOf(_member).call.value(value)(\"\");  require(success, \"Transfer failed\");  Recommendation  Require that the amount to be withdrawn is greater than zero.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.36 keep-core - TokenStaking owner should be protected from slash() and seize() during initializationPeriod    Addressed", "body": "  Resolution                           Addressed by   https://github.com/keep-network/keep-core/issues/1426 and fixed with  keep-network/keep-core#1453.  Description  From the specification:  Slashing If a staker violates the protocol of an operation in a way which can be proven on-chain, they will be penalized by having their stakes slashed.  The initialization period is a backoff time during which operator stakes are not active nor eligible to receive work. Since they cannot misbehave they should be protected from having their stake slashed or seized.  It should also be noted that slash() and seize() can be front-run during the initializationPeriod by having the operator owner cancel the deposit before it is being slashed or seized.  Recommendation  Require deposits to be in active state for being slashed or seized.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.37 tbtc - Signer collusion may bypass increaseRedemptionFee flow    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/tbtc#522  Description  DepositRedemption.increaseRedemptionFee is used by signers to approve a signable bitcoin transaction with a higher fee, in case the network is congested and miners are not approving the lower-fee transaction.  Fee increases can be performed every 4 hours:  tbtc/implementation/contracts/deposit/DepositRedemption.sol:L225  require(block.timestamp >= _d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");  In addition, each increase must increment the fee by exactly the initial proposed fee:  tbtc/implementation/contracts/deposit/DepositRedemption.sol:L260-L263  // Check that we're incrementing the fee by exactly the redeemer's initial fee  uint256 _previousOutputValue = DepositUtils.bytes8LEToUint(_previousOutputValueBytes);  _newOutputValue = DepositUtils.bytes8LEToUint(_newOutputValueBytes);  require(_previousOutputValue.sub(_newOutputValue) == _d.initialRedemptionFee, \"Not an allowed fee step\");  Outside of these two restrictions, there is no limit to the number of times increaseRedemptionFee can be called. Over a 20-hour period, for example, increaseRedemptionFee could be called 5 times, increasing the fee to initialRedemptionFee * 5.  Rather than calling increaseRedemptionFee 5 times over 20 hours, colluding signers may immediately create and sign a transaction with a fee of initialRedemptionFee * 5, wait for it to be mined, then submit it to provideRedemptionProof. Because provideRedemptionProof does not check that a transaction signature signs an approved digest, interested parties would need to monitor the bitcoin blockchain, notice the spend, and provide an ECDSA fraud proof before provideRedemptionProof is called.  Recommendation  Track the latest approved fee, and ensure the transaction in provideRedemptionProof does not include a higher fee.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.38 tbtc - liquidating a deposit does not send the complete remainder of the contract balance to recipients    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/tbtc/issues/504 and commits from  keep-network/tbtc#524, transferring the remaining balance of the contract to the initiator and switching from  Description  purchaseSignerBondsAtAuction might leave a wei in the contract if:  there is only one wei remaining in the contract  there is more than one wei remaining but the contract balance is odd.  Examples  contract balances must be > 1 wei otherwise no transfer is attempted  the division at line 271 floors the result if dividing an odd balance. The contract is sending floor(contract.balance / 2) to the keep group and liquidationInitiator leaving one 1 in the contract.  tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L266-L275  if (contractEthBalance > 1) {  if (_wasFraud) {  initiator.transfer(contractEthBalance);  } else {  // There will always be a liquidation initiator.  uint256 split = contractEthBalance.div(2);  _d.pushFundsToKeepGroup(split);  initiator.transfer(split);  Recommendation  Define a reasonable minimum amount when awarding the fraud reporter or liquidation initiator. Alternatively, always transfer the contract balance. When splitting the amount use the contract balance after the first transfer as the value being sent to the second recipient. Use the presence of locked funds in a contract as an error indicator unless funds were sent forcefully to the contract.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.39 tbtc - approveAndCall unused return parameter    Addressed", "body": "  Resolution                           Addressed with   https://github.com/keep-network/tbtc/issues/505 by returning  Description  approveAndCall always returns false because the return value bool success is never set.  Examples  tbtc/implementation/contracts/system/TBTCDepositToken.sol:L42-L54  /// @notice           Set allowance for other address and notify.  ///                   Allows `_spender` to transfer the specified TDT  ///                   on your behalf and then ping the contract about it.  /// @dev              The `_spender` should implement the `tokenRecipient` interface below  ///                   to receive approval notifications.  /// @param _spender   Address of contract authorized to spend.  /// @param _tdtId     The TDT they can spend.  /// @param _extraData Extra information to send to the approved contract.  function approveAndCall(address _spender, uint256 _tdtId, bytes memory _extraData) public returns (bool success) {  tokenRecipient spender = tokenRecipient(_spender);  approve(_spender, _tdtId);  spender.receiveApproval(msg.sender, _tdtId, address(this), _extraData);  Recommendation  Return the correct success state.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.40 bitcoin-spv - Unnecessary memory allocation in BTCUtils   Pending", "body": "  Resolution  The client provided feedback that this issue is not scheduled to be addressed.  Description  BTCUtils makes liberal use of BytesLib.slice, which returns a freshly-allocated slice of an existing bytes array. In many cases, the desired behavior is simply to read a 32-byte slice of a byte array. As a result, the typical pattern used is: bytesVar.slice(start, start + 32).toBytes32().  This pattern introduces unnecessary complexity and memory allocation in a critically important library: cloning a portion of the array, storing that clone in memory, and then reading it from memory. A simpler alternative would be to implement BytesLib.readBytes32(bytes _b, uint _idx) and other  memory-read  functions.  Rather than moving the free memory pointer and redundantly reading, storing, then re-reading memory, readBytes32 and similar functions would perform a simple length check and mload directly from the desired index in the array.  Examples  extractInputTxIdLE:  bitcoin-spv/solidity/contracts/BTCUtils.sol:L254-L260  /// @notice          Extracts the outpoint tx id from an input  /// @dev             32 byte tx id  /// @param _input    The input  /// @return          The tx id (little-endian bytes)  function extractInputTxIdLE(bytes memory _input) internal pure returns (bytes32) {  return _input.slice(0, 32).toBytes32();  verifyHash256Merkle:  bitcoin-spv/solidity/contracts/BTCUtils.sol:L574-L586  uint _idx = _index;  bytes32 _root = _proof.slice(_proof.length - 32, 32).toBytes32();  bytes32 _current = _proof.slice(0, 32).toBytes32();  for (uint i = 1; i < (_proof.length.div(32)) - 1; i++) {  if (_idx % 2 == 1) {  _current = _hash256MerkleStep(_proof.slice(i * 32, 32), abi.encodePacked(_current));  } else {  _current = _hash256MerkleStep(abi.encodePacked(_current), _proof.slice(i * 32, 32));  _idx = _idx >> 1;  return _current == _root;  Recommendation  Implement BytesLib.readBytes32 and favor its use over the bytesVar.slice(start, start + 32).toBytes32() pattern. Implement other memory-read functions where possible, and avoid the use of slice.  Note, too, that implementing this change in verifyHash256Merkle would allow _hash256MerkleStep to accept 2 bytes32 inputs (rather than bytes), removing additional unnecessary casting and memory allocation.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.41 bitcoin-spv - ValidateSPV.validateHeaderChain does not completely validate input   ", "body": "  Resolution                           Summa opted not to make this change. See   https://github.com/summa-tx/bitcoin-spv/issues/111  Description  ValidateSPV.validateHeaderChain takes as input a sequence of Bitcoin headers and calculates the total accumulated difficulty across the entire sequence. The input headers are checked to ensure they are relatively well-formed:  bitcoin-spv/solidity/contracts/ValidateSPV.sol:L173-L174  // Check header chain length  if (_headers.length % 80 != 0) {return ERR_BAD_LENGTH;}  However, the function lacks a check for nonzero length of _headers. Although the total difficulty returned would be zero, an explicit check would make this more clear.  Recommendation  If headers.length is zero, return ERR_BAD_LENGTH  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.42 bitcoin-spv - unnecessary intermediate cast    Addressed", "body": "  Resolution                           Issue addressed in   summa-tx/bitcoin-spv#123  Description  Examples  bitcoin-spv/solidity/contracts/CheckBitcoinSigs.sol:L15-L25  /// @notice          Derives an Ethereum Account address from a pubkey  /// @dev             The address is the last 20 bytes of the keccak256 of the address  /// @param _pubkey   The public key X & Y. Unprefixed, as a 64-byte array  /// @return          The account address  function accountFromPubkey(bytes memory _pubkey) internal pure returns (address) {  require(_pubkey.length == 64, \"Pubkey must be 64-byte raw, uncompressed key.\");  // keccak hash of uncompressed unprefixed pubkey  bytes32 _digest = keccak256(_pubkey);  return address(uint160(uint256(_digest)));  Recommendation  The intermediate cast from uint256 to uint160 can be omitted. Refactor to return address(uint256(_digest)) instead.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.43 bitcoin-spv - unnecessary logic in BytesLib.toBytes32()    Addressed", "body": "  Resolution                           Issue addressed in   summa-tx/bitcoin-spv#125  Description  The heavily used library function BytesLib.toBytes32() unnecessarily casts _source to bytes (same type) and creates a copy of the dynamic byte array to check it s length, while this can be done directly on the user-provided bytes _source.  Examples  bitcoin-spv/solidity/contracts/BytesLib.sol:L399-L408  function toBytes32(bytes memory _source) pure internal returns (bytes32 result) {  bytes memory tempEmptyStringTest = bytes(_source);  if (tempEmptyStringTest.length == 0) {  return 0x0;  assembly {  result := mload(add(_source, 32))  Recommendation  function toBytes32(bytes memory _source) pure internal returns (bytes32 result) {  if (_source.length == 0) {  return 0x0;  assembly {  result := mload(add(_source, 32))  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.44 bitcoin-spv - redundant functionality   ", "body": "  Resolution                           Summa opted not to make this change. See   https://github.com/summa-tx/bitcoin-spv/issues/116 for details.  Description  The library exposes redundant implementations of bitcoins double sha256.  Examples  solidity native implementation with an overzealous type correction issue 5.45  bitcoin-spv/solidity/contracts/BTCUtils.sol:L110-L116  /// @notice          Implements bitcoin's hash256 (double sha2)  /// @dev             abi.encodePacked changes the return to bytes instead of bytes32  /// @param _b        The pre-image  /// @return          The digest  function hash256(bytes memory _b) internal pure returns (bytes32) {  return abi.encodePacked(sha256(abi.encodePacked(sha256(_b)))).toBytes32();  assembly implementation  Note this implementation does not handle errors when staticcall ing the precompiled sha256 contract (private chains).  bitcoin-spv/solidity/contracts/BTCUtils.sol:L118-L129  /// @notice          Implements bitcoin's hash256 (double sha2)  /// @dev             sha2 is precompiled smart contract located at address(2)  /// @param _b        The pre-image  /// @return          The digest  function hash256View(bytes memory _b) internal view returns (bytes32 res) {  assembly {  let ptr := mload(0x40)  pop(staticcall(gas, 2, add(_b, 32), mload(_b), ptr, 32))  pop(staticcall(gas, 2, ptr, 32, ptr, 32))  res := mload(ptr)  Recommendation  We recommend providing only one implementation for calculating the double sha256 as maintaining two interfaces for the same functionality is not desirable. Furthermore, even though the assembly implementation is saving gas, we recommend keeping the language provided implementation.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.45 bitcoin-spv - unnecessary type correction    Addressed", "body": "  Resolution                           Issue addressed in   summa-tx/bitcoin-spv#126  Description  The type correction encodePacked().toBytes32() is not needed as sha256 already returns bytes32.  Examples  bitcoin-spv/solidity/contracts/BTCUtils.sol:L114-L117  function hash256(bytes memory _b) internal pure returns (bytes32) {  return abi.encodePacked(sha256(abi.encodePacked(sha256(_b)))).toBytes32();  Recommendation  Refactor to return sha256(abi.encodePacked(sha256(_b))); to save gas.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.46 tbtc - Restrict access to fallback function in Deposit.sol    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/tbtc#526  Description  Deposit.sol has an empty, payable fallback function. It is unused except when seizing signer bonds from BondedECDSAKeep.  Recommendation  So that Ether is not accidentally sent to a Deposit, have the fallback revert if the sender is not the BondedECDSAKeep.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.47 tbtc - Where possible, a specific contract type should be used rather than address    Addressed", "body": "  Resolution                           This issue has been addressed with   https://github.com/keep-network/tbtc/issues/507 and  keep-network/tbtc#542.  Description  Rather than storing addresses and then casting to the known contract type, it s better to use the best type available so the compiler can check for type safety.  Examples  tbtc/implementation/contracts/deposit/DepositUtils.sol:L25-L37  struct Deposit {  // SET DURING CONSTRUCTION  address TBTCSystem;  address TBTCToken;  address TBTCDepositToken;  address FeeRebateToken;  address VendingMachine;  uint256 lotSizeSatoshis;  uint8 currentState;  uint256 signerFeeDivisor;  uint128 undercollateralizedThresholdPercent;  uint128 severelyUndercollateralizedThresholdPercent;  tbtc/implementation/contracts/proxy/DepositFactory.sol:L16-L28  contract DepositFactory is CloneFactory, TBTCSystemAuthority{  // Holds the address of the deposit contract  // which will be used as a master contract for cloning.  address public masterDepositAddress;  address public tbtcSystem;  address public tbtcToken;  address public tbtcDepositToken;  address public feeRebateToken;  address public vendingMachine;  uint256 public keepThreshold;  uint256 public keepSize;  Remediation  Where possible, use more specific types instead of address. This goes for parameter types as well as state variable types.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.48 tbtc - Variable shadowing in DepositFactory    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/tbtc#512  Description  DepositFactory inherits from TBTCSystemAuthority. Both contracts declare a state variable with the same name, tbtcSystem.  tbtc/implementation/contracts/proxy/DepositFactory.sol:L21  address public tbtcSystem;  Recommendation  Remove the shadowed variable.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.49 tbtc - Values may contain dirty lower-order bits   Pending", "body": "  Resolution                           This is being tracked as   https://github.com/keep-network/tbtc/issues/557.  Description  Examples  FundingScript.receiveApproval:  tbtc/implementation/contracts/scripts/FundingScript.sol:L38-L44  // Verify _extraData is a call to unqualifiedDepositToTbtc.  bytes4 functionSignature;  assembly { functionSignature := mload(add(_extraData, 0x20)) }  require(  functionSignature == vendingMachine.unqualifiedDepositToTbtc.selector,  \"Bad _extraData signature. Call must be to unqualifiedDepositToTbtc.\"  );  RedemptionScript.receiveApproval:  tbtc/implementation/contracts/scripts/RedemptionScript.sol:L39-L45  // Verify _extraData is a call to tbtcToBtc.  bytes4 functionSignature;  assembly { functionSignature := mload(add(_extraData, 0x20)) }  require(  functionSignature == vendingMachine.tbtcToBtc.selector,  \"Bad _extraData signature. Call must be to tbtcToBtc.\"  );  Recommendation  Solidity truncates these unneeded bytes in the subsequent comparison operations, so there is no action required. However, this is good to keep in mind if these values are ever used for anything outside of strict comparison.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.50 tbtc - Revert error string may be malformed   Pending", "body": "  Resolution                           This issue is being tracked as   https://github.com/keep-network/tbtc/issues/509.  Description  FundingScript handles an error from a call to VendingMachine like so.  tbtc/implementation/contracts/scripts/FundingScript.sol:L46-L52  // Call the VendingMachine.  // We could explictly encode the call to vending machine, but this would  // involve manually parsing _extraData and allocating variables.  (bool success, bytes memory returnData) = address(vendingMachine).call(  _extraData  );  require(success, string(returnData));  On a high-level revert, returnData will already include the typical  error selector . As FundingScript propagates this error message, it will add another error selector, which may make it difficult to read the error message.  The same issue is present in RedemptionScript:  tbtc/implementation/contracts/scripts/RedemptionScript.sol:L47-L52  (bool success, bytes memory returnData) = address(vendingMachine).call(_extraData);  // By default, `address.call`  will catch any revert messages.  // Converting the `returnData` to a string will effectively forward any revert messages.  // https://ethereum.stackexchange.com/questions/69133/forward-revert-message-from-low-level-solidity-call  // TODO: there's some noisy couple bytes at the beginning of the converted string, maybe the ABI-coded length?  require(success, string(returnData));  Recommendation  Rather than adding an assembly-level revert to the affected contracts, ensure nested error selectors are handled in external libraries.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.51 tbtc - Where possible, use constant rather than state variables    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/tbtc#513  Description  TBTCSystem uses a state variable for pausedDuration, but this value is never changed.  tbtc/implementation/contracts/system/TBTCSystem.sol:L34  uint256 pausedDuration = 10 days;  Recommendation  Consider using the constant keyword.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "5.52 tbtc - Variable shadowing in TBTCDepositToken constructor    Addressed", "body": "  Resolution                           Issue addressed in   keep-network/tbtc#512  Description  TBTCDepositToken inherits from DepositFactoryAuthority, which has a single state variable, _depositFactory. This variable is shadowed in the TBTCDepositToken constructor.  tbtc/implementation/contracts/system/TBTCDepositToken.sol:L21-L26  constructor(address _depositFactory)  ERC721Metadata(\"tBTC Deopsit Token\", \"TDT\")  DepositFactoryAuthority(_depositFactory)  public {  // solium-disable-previous-line no-empty-blocks  Recommendation  Rename the parameter or state variable.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/02/thesis-tbtc-and-keep/"}, {"title": "4.1 Heavy Blocks May Affect Block Finalization, if the Gas Requirement Exceeds Block Gas Limit ", "body": "  Description  The sequencer takes care of finalizing blocks by submitting proof, blocks  data, proof type, and parent state root hash. The team mentions that the blocks are finalized every 12s, and under general scenarios, the system will work fine. However, in cases where there are blocks containing lots of transactions and event logs, the function may require gas more than the block gas limit. As a consequence, it may affect block finalization or lead to a potential DoS.  Examples  contracts/contracts/ZkEvmV2.sol:L110-L115  function finalizeBlocks(  BlockData[] calldata _blocksData,  bytes calldata _proof,  uint256 _proofType,  bytes32 _parentStateRootHash  Recommendation  We advise the team to benchmark the cost associated per block for the finalization and how many blocks can be finalized in one rollup and add the limits accordingly for the prover/sequencer.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.2 Postman Can Incorrectly Deliver a Message While Still Collecting the Fees ", "body": "  Description  The message service allows cross chain message delivery, where the user can define the parameters of the message as:  The postman estimates the gas before claiming/delivering the message on the destination chain, thus avoiding scenarios where the fees sent are less than the cost of claiming the message.  However, there is nothing that restricts the postman from sending the gas equal to the fees paid by the user. Although it contributes to the MEV, where the postman can select the messages with higher fees first and deliver them prior to others, it also opens up an opportunity where the postman can deliver a message incorrectly while still claiming the fees.  One such scenario is, where the low-level call to target _to makes another sub-call to another address, let s say x. Let s assume, the _to address doesn t check, whether the call to address x was successful or not. Now, if the postman supplies a gas, which makes the top-level call succeed, but the low-level call to x fails silently, the postman will still be retrieving the fees of claiming the message, even though the message was not correctly delivered.  Examples  contracts/contracts/messageService/l1/L1MessageService.sol:L125-L135  (bool success, bytes memory returnData) = _to.call{ value: _value }(_calldata);  if (!success) {  if (returnData.length > 0) {  assembly {  let data_size := mload(returnData)  revert(add(32, returnData), data_size)  } else {  revert MessageSendingFailed(_to);  contracts/contracts/messageService/l2/L2MessageService.sol:L150-L160  (bool success, bytes memory returnData) = _to.call{ value: _value }(_calldata);  if (!success) {  if (returnData.length > 0) {  assembly {  let data_size := mload(returnData)  revert(add(32, returnData), data_size)  } else {  revert MessageSendingFailed(_to);  Recommendation  Another parameter can be added to the message construct giving the user the option to define the amount of gas required to complete a transaction entirely. Also, a check can be added while claiming the message, to make sure the gas supplied by the postman is sufficient enough compared to the gas defined/demanded by the user. The cases, where the user can demand a huge amount of gas, can be simply avoided by doing the gas estimation, and if the demanded gas is more than the supplied fees, the postman will simply opt not to deliver the message  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.3 User s Funds Would Stuck if the Message Claim Failed on the Destination Layer ", "body": "  Description  When claiming the message on the destination layer, if the message failed to execute with various reasons (e.g. wrong target contract address, wrong contract logic, out of gas, malicious contract), the Ether sent with sendMessage on the original layer will be stuck, although the message can be retried later by the Postman or the user (could fail again)  Examples  contracts/contracts/messageService/l1/L1MessageService.sol:L81-L84  uint256 messageNumber = nextMessageNumber;  uint256 valueSent = msg.value - _fee;  bytes32 messageHash = keccak256(abi.encode(msg.sender, _to, _fee, valueSent, messageNumber, _calldata));  contracts/contracts/messageService/l2/L2MessageService.sol:L150-L160  (bool success, bytes memory returnData) = _to.call{ value: _value }(_calldata);  if (!success) {  if (returnData.length > 0) {  assembly {  let data_size := mload(returnData)  revert(add(32, returnData), data_size)  } else {  revert MessageSendingFailed(_to);  contracts/contracts/messageService/l1/L1MessageService.sol:L125-L135  (bool success, bytes memory returnData) = _to.call{ value: _value }(_calldata);  if (!success) {  if (returnData.length > 0) {  assembly {  let data_size := mload(returnData)  revert(add(32, returnData), data_size)  } else {  revert MessageSendingFailed(_to);  Recommendation  Add refund mechanism to refund users funds if the message failed to deliver on the destination layer  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.4 Front Running finalizeBlocks When Sequencers Are Decentralized ", "body": "  Description  When sequencer is decentralized in the future, one sequencer could front run another sequencer s finalizeBlocks transaction, without doing the actual proving and sequencing, and steal the reward for sequencing if there is one. Once the frontrunner s finalizeBlocks is executed, the original sequencer s transaction would fail as currentL2BlockNumber would increment by one and state root hash won t match, as a result the original sequencer s sequencing and proving work will be wasted.  Examples  contracts/contracts/ZkEvmV2.sol:L110-L126  function finalizeBlocks(  BlockData[] calldata _blocksData,  bytes calldata _proof,  uint256 _proofType,  bytes32 _parentStateRootHash  external  whenTypeNotPaused(PROVING_SYSTEM_PAUSE_TYPE)  whenTypeNotPaused(GENERAL_PAUSE_TYPE)  onlyRole(OPERATOR_ROLE)  if (stateRootHashes[currentL2BlockNumber] != _parentStateRootHash) {  revert StartingRootHashDoesNotMatch();  _finalizeBlocks(_blocksData, _proof, _proofType, _parentStateRootHash, true);  Recommendation  Add the sequencer s address as one parameters in _finalizeBlocks function, and include the sequencer s address in the public input hash of the proof in verification function _verifyProof.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.5 User Funds Would Stuck if the Single Coordinator Is Offline or Censoring Messages ", "body": "  Description  When user sends message from L1 to L2, the coordinator needs to post the messages to L2, this happens in the anchoring message(addL1L2MessageHashes) on L2, then the user or Postman can claim the message on L2. since there is only a single coordinator, if the coordinator is down or censoring messages sent from L1 to L2, users funds can stuck in L1, until the coordinator come back online or stops censoring the message, as there is no message cancel feature or message expire feature. Although the operator can pause message sending on L1 once the coordinator is down, but if the message is sent and not posted to L2 before the pause it will still stuck.  Examples  contracts/contracts/messageService/l1/L1MessageService.sol:L81-L84  uint256 messageNumber = nextMessageNumber;  uint256 valueSent = msg.value - _fee;  bytes32 messageHash = keccak256(abi.encode(msg.sender, _to, _fee, valueSent, messageNumber, _calldata));  contracts/contracts/messageService/l2/L2MessageManager.sol:L42-L60  function addL1L2MessageHashes(bytes32[] calldata _messageHashes) external onlyRole(L1_L2_MESSAGE_SETTER_ROLE) {  uint256 messageHashesLength = _messageHashes.length;  if (messageHashesLength > 100) {  revert MessageHashesListLengthHigherThanOneHundred(messageHashesLength);  for (uint256 i; i < messageHashesLength; ) {  bytes32 messageHash = _messageHashes[i];  if (inboxL1L2MessageStatus[messageHash] == INBOX_STATUS_UNKNOWN) {  inboxL1L2MessageStatus[messageHash] = INBOX_STATUS_RECEIVED;  unchecked {  i++;  emit L1L2MessageHashesAddedToInbox(_messageHashes);  Recommendation  Decentralize coordinator and sequencer or enable user cancel or drop the message if message deadline has expired.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.6 Changing Verifier Address Doesn t Emit Event ", "body": "  Description  In function setVerifierAddress, after the verifier address is changed, there is no event emitted, which means if the operator (security council) changes the verifier to a buggy verifier, or if the security council is compromised, the attacker can change the verifier to a malicious one, the unsuspecting user would still use the service, potentially lose funds due to the fraud transactions would be verified.  Examples  contracts/contracts/ZkEvmV2.sol:L83-L88  function setVerifierAddress(address _newVerifierAddress, uint256 _proofType) external onlyRole(DEFAULT_ADMIN_ROLE) {  if (_newVerifierAddress == address(0)) {  revert ZeroAddressNotAllowed();  verifiers[_proofType] = _newVerifierAddress;  Recommendation  Emits event after changing verifier address including old verifier address, new verifier address and the caller account  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.7 L2 Blocks With Incorrect Timestamp Could Be Finalized ", "body": "  Description  In _finalizeBlocks of ZkEvmV2, the current block timestamp blockInfo.l2BlockTimestamp should be greater or equal than the last L2 block timestamp and less or equal than the L1 block timestamp when _finalizeBlocks is executed. However the first check is missing, blocks with incorrect timestamp could be finalized, causing unintended system behavior  Examples  contracts/contracts/ZkEvmV2.sol:L158-L160  if (blockInfo.l2BlockTimestamp >= block.timestamp) {  revert BlockTimestampError();  Recommendation  Add the missing timestamp check  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.8 Rate Limiting Affecting the Usability and User s Funds Safety ", "body": "  Description  In claimMessage of L1MessageService and sendMessage function  of L1MessageService contract, function _addUsedAmount is used to rate limit the Ether amount (1000 Eth) sent from L2 to L1 in a time period (24 hours), this is problematic, usually user sends the funds to L1 when they need to exit from L2 to L1 especially when some security issues happened affecting their funds safety on L2, if there is a limit, the limit can be reached quickly by some whale sending large amount of Ether to L1, while other users cannot withdraw their funds to L1, putting their funds at risk. In addition, the limit can only be set and changed by the security council and security council can also pause message service at any time, blocking user withdraw funds from L2, this makes the L2->L1 message service more centralized.  Examples  contracts/contracts/messageService/l1/L1MessageService.sol:L121  _addUsedAmount(_fee + _value);  contracts/contracts/messageService/l2/L2MessageService.sol:L108  _addUsedAmount(msg.value);  contracts/contracts/messageService/lib/RateLimiter.sol:L53-L69  function _addUsedAmount(uint256 _usedAmount) internal {  uint256 currentPeriodAmountTemp;  if (currentPeriodEnd < block.timestamp) {  // Update period before proceeding  currentPeriodEnd = block.timestamp + periodInSeconds;  currentPeriodAmountTemp = _usedAmount;  } else {  currentPeriodAmountTemp = currentPeriodAmountInWei + _usedAmount;  if (currentPeriodAmountTemp > limitInWei) {  revert RateLimitExceeded();  currentPeriodAmountInWei = currentPeriodAmountTemp;  Recommendation  Remove rate limiting for L2->L1 message service  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.9 Front Running claimMessage on L1 and L2 ", "body": "  Description  The front-runner on L1 or L2 can front run the claimMessage transaction, as long as the fee is greater than the gas cost of the claiming the message and feeRecipient is not set, consequently the fee will be transferred to the message.sender(the front runner) once the message is claimed. As a result, postman would lose the incentive to deliver(claim) the message on the destination layer.  Examples  contracts/contracts/messageService/l1/L1MessageService.sol:L137-L142  if (_fee > 0) {  address feeReceiver = _feeRecipient == address(0) ? msg.sender : _feeRecipient;  (bool feePaymentSuccess, ) = feeReceiver.call{ value: _fee }(\"\");  if (!feePaymentSuccess) {  revert FeePaymentFailed(feeReceiver);  contracts/contracts/messageService/l2/L2MessageService.sol:L162-L168  if (_fee > 0) {  address feeReceiver = _feeRecipient == address(0) ? msg.sender : _feeRecipient;  (bool feePaymentSuccess, ) = feeReceiver.call{ value: _fee }(\"\");  if (!feePaymentSuccess) {  revert FeePaymentFailed(feeReceiver);  Recommendation  There are a few protections against front running including flashbots service. Another option to mitigate front running is to avoid using msg.sender and have user use the signed claimMessage transaction by the Postman to claim the message on the destination layer  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.10 Contracts Not Well Designed for Upgrades ", "body": "  Description  Inconsistent Storage Layout  The Contracts introduce some buffer space in the storage layout to cope with the scenarios where new storage variables can be added if a need exists to upgrade the contracts to a newer version. This helps in reducing the chances of potential storage collisions. However, the storage layout concerning the buffer space is inconsistent, and multiple variations have been observed.  PauseManager, RateLimitter, and MessageServiceBase adds a buffer space of 10, contrary to other contracts which define the space as 50.  contracts/contracts/messageService/lib/PauseManager.sol:L22  uint256[10] private _gap;  contracts/contracts/messageService/lib/RateLimiter.sol:L26  uint256[10] private _gap;  contracts/contracts/messageService/MessageServiceBase.sol:L14  uint256[10] private __base_gap;  L2MessageService defines the buffer space prior to its existing storage variables.  contracts/contracts/messageService/l2/L2MessageService.sol:L16  uint256[50] private __gap_L2MessageService;  If there exists a need to inherit from this contract in the future, the derived contract has to define the buffer space first, similar to L2MessageService. If it doesn t, L2MessageService can t have more storage variables. If it adds them, it will collide with the derived contract s storage slots.  2. RateLimiter and MessageServiceBase initializes values without the modifier onlyInitializing  contracts/contracts/messageService/lib/RateLimiter.sol:L33  function __RateLimiter_init(uint256 _periodInSeconds, uint256 _limitInWei) internal {  contracts/contracts/messageService/MessageServiceBase.sol:L65  function _init_MessageServiceBase(address _messageService, address _remoteSender) internal {  The modifier onlyInitializing makes sure that the function should only be invoked by a function marked as initializer. However, it is absent here, which means these are normal internal functions that can be utilized in any other function, thus opening opportunities for errors.  Recommendation  Define a consistent storage layout. Consider a positive number n for the number of buffer space slots, such that, it is equal to any arbitrary number d - No. of occupied storage slots. For instance, if the arbitrary number is 50, and the contract has 20 occupied storage slots, the buffer space can be 50-20 = 30. It will maintain a consistent storage layout throughout the inheritance hierarchy.  Follow a consistent approach to defining buffer space. Currently, all the contracts, define the buffer space after their occupied storage slots, so it should be maintained in the L2MessageService as well.  Define functions __RateLimiter_init and _init_MessageServiceBase as onlyInitializing.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.11 Potential Code Corrections ", "body": "  Description  Function _updateL1L2MessageStatusToReceived and addL1L2MessageHashes allows status update for already received/sent/claimed messages.  contracts/contracts/messageService/l1/L1MessageManager.sol:L76-L97  function _updateL1L2MessageStatusToReceived(bytes32[] memory _messageHashes) internal {  uint256 messageHashArrayLength = _messageHashes.length;  for (uint256 i; i < messageHashArrayLength; ) {  bytes32 messageHash = _messageHashes[i];  uint256 existingStatus = outboxL1L2MessageStatus[messageHash];  if (existingStatus == INBOX_STATUS_UNKNOWN) {  revert L1L2MessageNotSent(messageHash);  if (existingStatus != OUTBOX_STATUS_RECEIVED) {  outboxL1L2MessageStatus[messageHash] = OUTBOX_STATUS_RECEIVED;  unchecked {  i++;  emit L1L2MessagesReceivedOnL2(_messageHashes);  contracts/contracts/messageService/l2/L2MessageManager.sol:L42-L59  function addL1L2MessageHashes(bytes32[] calldata _messageHashes) external onlyRole(L1_L2_MESSAGE_SETTER_ROLE) {  uint256 messageHashesLength = _messageHashes.length;  if (messageHashesLength > 100) {  revert MessageHashesListLengthHigherThanOneHundred(messageHashesLength);  for (uint256 i; i < messageHashesLength; ) {  bytes32 messageHash = _messageHashes[i];  if (inboxL1L2MessageStatus[messageHash] == INBOX_STATUS_UNKNOWN) {  inboxL1L2MessageStatus[messageHash] = INBOX_STATUS_RECEIVED;  unchecked {  i++;  emit L1L2MessageHashesAddedToInbox(_messageHashes);  It may trigger false alarms, as they will still be a part of L1L2MessagesReceivedOnL2 and L1L2MessageHashesAddedToInbox.  _updateL1L2MessageStatusToReceived checks the status of L1->L2 messages as:  contracts/contracts/messageService/l1/L1MessageManager.sol:L83-L85  if (existingStatus == INBOX_STATUS_UNKNOWN) {  revert L1L2MessageNotSent(messageHash);  However, the status is need to be checked with OUTBOX_STATUS_UNKNOWN instead of INBOX_STATUS_UNKNOWN as it is an outbox message. This creates a hindrance in the code readability and should be fixed.  Array timestampHashes stores l2BlockTimestamp as integers, contrary to the hashes that the variable name states.  contracts/contracts/ZkEvmV2.sol:L172  timestampHashes[i] = blockInfo.l2BlockTimestamp;  Unused error declaration  contracts/contracts/messageService/lib/TransactionDecoder.sol:L21-L24  TransactionDecoder defines an error as InvalidAction which is supposed to be thrown when the decoding action is invalid, as stated in NATSPEC comment. However, it is currently unutilized.  dev Thrown when the decoding action is invalid.  /  error InvalidAction();  TransactionDecoder defines an error as InvalidAction which is supposed to be thrown when the decoding action is invalid, as stated in NATSPEC comment. However, it is currently unutilized.  Recommendation  Only update the status for sent messages in _updateL1L2MessageStatusToReceived, and unknown messages in addL1L2MessageHashes and revert otherwise, to avoid off-chain accounting errors.  Check the status of L1->L2 sent message with OUTBOX_STATUS_UNKNOWN to increase code readability.  Either store timestamp hashes in the variable timestampHashes or update the variable name likewise.  Remove the error declaration if it is not serving any purpose.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.12 TransactionDecoder Does Not Account for the Missing Elements While Decoding a Transaction ", "body": "  Description  The library tries to decode calldata from different transaction types, by jumping to the position of calldata element in the rlp encoding. These positions are:  EIP1559: 8  EIP2930: 7  Legacy: 6  Examples  contracts/contracts/messageService/lib/TransactionDecoder.sol:L69  data = it._skipTo(8)._toBytes();  contracts/contracts/messageService/lib/TransactionDecoder.sol:L83  data = it._skipTo(7)._toBytes();  contracts/contracts/messageService/lib/TransactionDecoder.sol:L97  data = it._skipTo(6)._toBytes();  However, the decoder doesn t check whether the required element is there or not in the encoding provided.  The decoder uses the library RLPReader to skip to the desired element in encoding. However, it doesn t revert in case there are not enough elements to skip to, and will simply return byte 0x00, while still completing unnecessary iterations.  contracts/contracts/messageService/lib/Rlp.sol:L54-L71  function _skipTo(Iterator memory _self, uint256 _skipToNum) internal pure returns (RLPItem memory item) {  uint256 ptr = _self.nextPtr;  uint256 itemLength = _itemLength(ptr);  _self.nextPtr = ptr + itemLength;  for (uint256 i; i < _skipToNum - 1; ) {  ptr = _self.nextPtr;  itemLength = _itemLength(ptr);  _self.nextPtr = ptr + itemLength;  unchecked {  i++;  item.len = itemLength;  item.memPtr = ptr;  Although it doesn t impose any security issue, as  ZkEvmV2 tries to decode an array of bytes32 hashes from the rlp encoded transaction. However, it may still lead to errors in other use cases if not handled correctly.  contracts/contracts/ZkEvmV2.sol:L222  CodecV2._extractXDomainAddHashes(TransactionDecoder.decodeTransaction(_transactions[_batchReceptionIndices[i]]))  Recommendation  rlp library should revert if there are not enough elements to skip to in the encoding.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.13 Incomplete Message State Check When Claiming Messages on L1 and L2 ", "body": "  Description  When claiming message on L1 orL2, _updateL2L1MessageStatusToClaimed and _updateL1L2MessageStatusToClaimed  are called to update the message status, however the message state check only checks status INBOX_STATUS_RECEIVED and is missing status  INBOX_STATUS_UNKNOWN, which means the message is not picked up by the coordinator or the message is not sent on L1 or L2 and should be reverted. As a result, the claiming message could be reverted with a incorrect reason.  Examples  contracts/contracts/messageService/l1/L1MessageManager.sol:L52-L60  function _updateL2L1MessageStatusToClaimed(bytes32 _messageHash) internal {  if (inboxL2L1MessageStatus[_messageHash] != INBOX_STATUS_RECEIVED) {  revert MessageAlreadyClaimed();  delete inboxL2L1MessageStatus[_messageHash];  emit L2L1MessageClaimed(_messageHash);  contracts/contracts/messageService/l2/L2MessageManager.sol:L66-L75  function _updateL1L2MessageStatusToClaimed(bytes32 _messageHash) internal {  if (inboxL1L2MessageStatus[_messageHash] != INBOX_STATUS_RECEIVED) {  revert MessageAlreadyClaimed();  inboxL1L2MessageStatus[_messageHash] = INBOX_STATUS_CLAIMED;  emit L1L2MessageClaimed(_messageHash);  Recommendation  Add the missing status check and relevant revert reason for status INBOX_STATUS_UNKNOWN  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.14 Events Which May Trigger False Alarms ", "body": "  Description  1- PauseManager allows PAUSE_MANAGER_ROLE to pause/unpause a type as:  contracts/contracts/bridge/lib/PauseManager.sol:L60-L63  function pauseByType(bytes32 _pauseType) external onlyRole(PAUSE_MANAGER_ROLE) {  pauseTypeStatuses[_pauseType] = true;  emit Paused(_msgSender(), _pauseType);  contracts/contracts/bridge/lib/PauseManager.sol:L70-L73  function unPauseByType(bytes32 _pauseType) external onlyRole(PAUSE_MANAGER_ROLE) {  pauseTypeStatuses[_pauseType] = false;  emit UnPaused(_msgSender(), _pauseType);  However, the functions don t check whether the given _pauseType has already been paused/unpaused or not and emits an event every time called. This may trigger false alarms for off-chain monitoring tools and may cause unnecessary panic.  2 - RateLimitter allows resetting the limit and used amount as:  contracts/contracts/messageService/lib/RateLimiter.sol:L78-L89  function resetRateLimitAmount(uint256 _amount) external onlyRole(RATE_LIMIT_SETTER_ROLE) {  bool amountUsedLoweredToLimit;  if (_amount < currentPeriodAmountInWei) {  currentPeriodAmountInWei = _amount;  amountUsedLoweredToLimit = true;  limitInWei = _amount;  emit LimitAmountChange(_msgSender(), _amount, amountUsedLoweredToLimit);  contracts/contracts/messageService/lib/RateLimiter.sol:L96-L100  function resetAmountUsedInPeriod() external onlyRole(RATE_LIMIT_SETTER_ROLE) {  currentPeriodAmountInWei = 0;  emit AmountUsedInPeriodReset(_msgSender());  However, it doesn t account for the scenarios where the function can be called after the current period ends and before a new period gets started. As the currentPeriodAmountInWei will still be holding the used amount of the last period, if the RATE_LIMIT_SETTER_ROLE tries to reset the limit with the lower value than the used amount, the function will emit the same event LimitAmountChange with the flag amountUsedLoweredToLimit.  Adding to it, the function will make currentPeriodAmountInWei = limitInWei, which means no more amount can be added as the used amount until the used amount is manually reset to 0, which points out to the fact that the used amount should be automatically reset, once the current period ends. Although it is handled automatically in function _addUsedAmount, however, if the new period has not yet started, it is supposed to be done in a 2-step approach i.e., first, reset the used amount and then the limit. It can be simplified by checking for the current period in the resetRateLimitAmount function itself.  The same goes for the scenario where the used amount is reset after the current period ends. It will emit the same event as AmountUsedInPeriodReset  These can create unnecessary confusion, as the events emitted don t consider the abovementioned scenarios.  Recommendation  Consider adding checks to make sure already paused/unpaused types don t emit respective events.  Consider emitting different events, or adding a flag in the events, that makes it easy to differentiate whether the limit and used amount are reset in the current period or after it has ended.  Reset currentPeriodAmountInWei in function resetRateLimitAmount itself if the current period has ended.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.15 PauseManager - Unnecessary Explicit Initialization of Values", "body": "  Description  __PauseManager_init explicitly initializes, defined types with the default boolean value false, which is unnecessary and can be removed.  contracts/contracts/bridge/lib/PauseManager.sol:L49-L53  function __PauseManager_init() internal onlyInitializing {  pauseTypeStatuses[L1_L2_PAUSE_TYPE] = false;  pauseTypeStatuses[L2_L1_PAUSE_TYPE] = false;  pauseTypeStatuses[PROVING_SYSTEM_PAUSE_TYPE] = false;  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "4.16 CodecV2 - Code Optimization", "body": "  Description  The library provides a simple utility function to decode an array of bytes32 hashes from calldata of a transaction as:  contracts/contracts/messageService/lib/Codec.sol:L17-L19  function _extractXDomainAddHashes(bytes memory _calldataWithSelector) internal pure returns (bytes32[] memory) {  return abi.decode(_slice(_calldataWithSelector, 4, _calldataWithSelector.length - 4), (bytes32[]));  which involves slicing down the memory array to get the desired length. However, the process can be simplified by switching _calldataWithSelector from memory to calldata, as solidity provides the index range access feature for calldata arrays.  Recommendation  The code can be simplified to increase code readability and decrease gas cost as:  Update: Since switching from memory to calldata may require making the library external and also ZkEvmV2 to make an external call to the library. The optimization will increase the gas cost instead of reducing it.  contracts/contracts/ZkEvmV2.sol:L221-L223  _updateL1L2MessageStatusToReceived(  CodecV2._extractXDomainAddHashes(TransactionDecoder.decodeTransaction(_transactions[_batchReceptionIndices[i]]))  );  A better approach could be to recraft the memory array skipping the 4 bytes selector as:  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2023/06/linea-message-service/"}, {"title": "5.1 All Roles Are Set to the Same Account.    ", "body": "  Resolution                           All roles, including regulatory manager, are now set to different accounts. The modification can be found in commit   Description  From talking to the team we know that all roles will be held by different timelock contracts. In the code they all are initiated to the same admin address. That would mean that most roles would need to be transferred. Given that each transfer take 2 transactions and there are 3 roles to transfer that would equate to 6 transactions just to properly set up the contract on deployment. That also increments the time it would take and space for making errors.  It is also should be noted that the regulator role is not being initialized there at all.  Examples  contracts/access/DramAccessControl.sol:L77-L84  // solhint-disable-next-line func-name-mixedcase  function __DramAccessControl_init_unchained(  address admin  ) internal onlyInitializing {  _grantRole(ADMIN_ROLE, admin);  _grantRole(ROLE_MANAGER_ROLE, admin);  _grantRole(SUPPLY_MANAGER_ROLE, admin);  Recommendation  We suggest passing several addresses into the constructor and setting them to the correct addresses right away. Alternatively one can not set them at all and grant those roles later in order to avoid revoking the roles that admin should not have, such as SUPPLY_MANAGER_ROLE.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2023/08/dram-stablecoin/"}, {"title": "5.2 Setting MintCap to a Specific Value Is Prone to Front-Running. ", "body": "  Resolution                           Acknowledged by the team with a comment: We will modify   Description  Dram stable coin is using the approval-like model to set the minting caps of different operators, thus it is prone to the same front-run issues as the approval mechanism. When using the setMintCap function directly operator could front-run the transaction and completely spend the old cap and then spend the new one again after setting the transaction goes through.  contracts/Dram.sol:L110-L115  function setMintCap(  address operator,  uint256 amount  ) external onlyRoleOrAdmin(ROLE_MANAGER_ROLE) {  _setMintCap(operator, amount);  Examples  Imagine the following scenario:  Alice has a mint cap of 10.  A transaction is sent to the mem-pool to set it to 5 (decrease the cap). The intent is that Alice should only be able to mint 5 tokens.  Alice frontruns this transaction and mints 10 tokens.  Once transaction 2 goes through Alice mints 5 more tokens.  In total Alice minted 15 tokens.  Recommendation  Avoid using setting the specific mint caps and rather use increase/decrease methods that are present in the code already.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2023/08/dram-stablecoin/"}, {"title": "5.3 Context.sol Is Not Required in the Present Use Case.    ", "body": "  Resolution                           Fixed in commit:   Description  ContextUpgradeable.sol contract that is used in the DramMintable contract can be regarded as a foundational contract, the methods of which are intended for overriding to facilitate the implementation of varying meta transaction logics.  contracts/token/ERC20/extensions/DramMintable.sol:L18-L23  abstract contract DramMintable is  Initializable,  IDramMintable,  ContextUpgradeable,  ERC20Upgradeable  In its isolated state, it brings no additional value but rather makes code evaluation more difficult.  Recommendation  In the case of DramMintable msg.sender can be used directly. In the case where meta-transactions are planned to be utilized, ContextUpgradeable.sol has to be overridden accordingly.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2023/08/dram-stablecoin/"}, {"title": "5.4 Admin Can Mint and Burn Tokens Which Is Not Immediately Evident From Code.", "body": "  Description  Burning and minting tokens functions both have the following modifier: onlyRole(SUPPLY_MANAGER_ROLE) which is different from onlyRoleOrAdmin used elsewhere. That implies that the Admin can not do minting or burning while in reality Admin can do that by just granting themselves a supply manager role first.  Examples  contracts/Dram.sol:L126  ) external onlyRole(SUPPLY_MANAGER_ROLE) {  contracts/Dram.sol:L135  function burn(uint256 amount) external onlyRole(SUPPLY_MANAGER_ROLE) {  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2023/08/dram-stablecoin/"}, {"title": "5.1 zAuction - incomplete / dead code zWithdraw and zDeposit    ", "body": "  Resolution                           obsolete with changes from   zer0-os/zAuction@135b2aa removing the  Description  Examples  zAuction/contracts/zAuctionAccountant.sol:L44-L52  function zDeposit(address to) external payable onlyZauction {  ethbalance[to] = SafeMath.add(ethbalance[to], msg.value);  emit zDeposited(to, msg.value);  function zWithdraw(address from, uint256 amount) external onlyZauction {  ethbalance[from] = SafeMath.sub(ethbalance[from], amount);  emit zWithdrew(from, amount);  Recommendation  The methods do not seem to be used by the zAuction contract. It is highly discouraged from shipping incomplete implementations in productive code. Remove dead/unreachable code. Fix the implementations to perform proper accounting before reintroducing them if they are called by zAuction.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.2 zAuction - Unpredictable behavior for users due to admin front running or general bad timing    ", "body": "  Resolution  obsolete with changes from zer0-os/zAuction@135b2aa removing the zAccountAccountant. The client provided the following remark:  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.20 accountant deprecated", "body": "  Description  An administrator of zAuctionAccountant contract can update the zAuction contract without warning. This has the potential to violate a security goal of the system.  Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.  In general users of the system should have assurances about the behavior of the action they re about to take.  Examples  updating the zAuction  takes effect immediately. This has the potential to fail acceptance of bids by sellers on the now outdated zAuction contract as interaction with the accountant contract is now rejected. This forces bidders to reissue their bids in order for the seller to be able to accept them using the Accountant contract. This may also be used by admins to selectively censor the acceptance of accountant based bids by changing the active zAuction address.  zAuction/contracts/zAuctionAccountant.sol:L60-L68  function SetZauction(address zauctionaddress) external onlyAdmin{  zauction = zauctionaddress;  emit ZauctionSet(zauctionaddress);  function SetAdmin(address newadmin) external onlyAdmin{  admin = newadmin;  emit AdminSet(msg.sender, newadmin);  Upgradeable contracts may introduce the same unpredictability issues where the proxyUpgradeable owner may divert execution to a new zNS registrar implementation selectively for certain transactions or without prior notice to users.  Recommendation  The underlying issue is that users of the system can t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.  We recommend giving the user advance notice of changes with a time lock. For example, make all system-parameter and upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period. This allows users that do not accept the change to withdraw immediately.  Validate arguments before updating contract addresses (at least != current/0x0). Consider implementing a 2-step admin ownership transfer (transfer+accept) to avoid losing control of the contract by providing the wrong ETH address.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.3 zAuction, zNS - Bids cannot be cancelled, never expire, and the auction lifecycle is unclear    ", "body": "  Resolution  Addressed with zer0-os/zNS@ab7d62a by refactoring the StakingController to control the lifecycle of bids instead of handling this off-chain.  Addressed with zer0-os/zAuction@135b2aa for zAuction by adding a bid/saleOffer expiration for bids. The client also provided the following statement:  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.6 added expireblock and startblock to zauction, expireblock to zsale", "body": " Decided not to add a cancel function. Paying gas to cancel isn t ideal, and it can be used as a griefing function. though that s still possible to do by moving weth but differently  The stateless nature of auctions may make it hard to enforce bid/sale expirations and it is not possible to cancel a bid/offer that should not be valid anymore. The expiration reduces the risk of old offers being used as they now automatically invalidate after time, however, it is still likely that multiple valid offers may be present at the same time. As outlined in the recommendation, one option would be to allow someone who signed a commitment to explicitly cancel it in the contract. Another option would be to create a stateful auction where the entity that puts up something for  starts  an auction, creating an auction id, requiring bidders to bid on that auction id. Once a bid is accepted the auction id is invalidated which invalidates all bids that might be floating around.  zer0-os/zAuction@2f92aa1 for  Description  The lifecycle of a bid both for zAuction and zNS is not clear, and has many flaws.  zAuction - Consider the case where a bid is placed, then the underlying asset in being transferred to a new owner. The new owner can now force to sell the asset even though it s might not be relevant anymore.  zAuction - Once a bid was accepted and the asset was transferred, all other bids need to be invalidated automatically, otherwise and old bid might be accepted even after the formal auction is over.  zAuction, zNS - There is no way for the bidder to cancel an old bid. That might be useful in the event of a significant change in market trend, where the old pricing is no longer relevant. Currently, in order to cancel a bid, the bidder can either withdraw his ether balance from the zAuctionAccountant, or disapprove WETH which requires an extra transaction that might be front-runned by the seller.  Examples  zAuction/contracts/zAuction.sol:L35-L45  function acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {  address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);  require(bidder == recoveredbidder, 'zAuction: incorrect bidder');  require(!randUsed[rand], 'Random nonce already used');  randUsed[rand] = true;  IERC721 nftcontract = IERC721(nftaddress);  accountant.Exchange(bidder, msg.sender, bid);  nftcontract.transferFrom(msg.sender, bidder, tokenid);  emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);  zNS/contracts/StakingController.sol:L120-L152  function fulfillDomainBid(  uint256 parentId,  uint256 bidAmount,  uint256 royaltyAmount,  string memory bidIPFSHash,  string memory name,  string memory metadata,  bytes memory signature,  bool lockOnCreation,  address recipient  ) external {  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);  address recoveredBidder = recover(recoveredBidHash, signature);  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");  bytes32 hashOfSig = keccak256(abi.encode(signature));  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);  registrar.setDomainMetadataUri(id, metadata);  registrar.setDomainRoyaltyAmount(id, royaltyAmount);  registrar.transferFrom(controller, recoveredBidder, id);  if (lockOnCreation) {  registrar.lockDomainMetadataForOwner(id);  approvedBids[hashOfSig] = false;  emit DomainBidFulfilled(  metadata,  name,  recoveredBidder,  id,  parentId  );  Recommendation  Consider adding an expiration field to the message signed by the bidder both for zAuction and zNS. Consider adding auction control, creating an auctionId, and have users bid on specific auctions. By adding this id to the signed message, all other bids are invalidated automatically and users would have to place new bids for a new auction. Optionally allow users to cancel bids explicitly.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.4 zAuction - pot. initialization fronrunning and unnecessary init function    ", "body": "  Resolution  Addressed with zer0-os/zAuction@135b2aa and the following statement:  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.21 init deprecated, constructor added", "body": "  Description  The zAuction initialization method is unprotected and while only being executable once, can be called by anyone. This might allow someone to monitor the mempool for new deployments of this contract and fron-run the initialization to initialize it with different parameters.  A mitigating factor is that this condition can be detected by the deployer as subsequent calls to init() will fail.  Note: this doesn t adhere to common interface naming convention/oz naming convention where this method would be called initialize.  Note: that zNS in contrast relies on ou/initializable pattern with proper naming.  Note: that this function might not be necessary at all and should be replaced by a constructor instead, as the contract is not used with a proxy pattern.  Examples  zAuction/contracts/zAuction.sol:L22-L26  function init(address accountantaddress) external {  require(!initialized);  initialized = true;  accountant = zAuctionAccountant(accountantaddress);  Recommendation  The contract is not used in a proxy pattern, hence, the initialization should be performed in the constructor instead.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.5 zAuction - unclear upgrade path    ", "body": "  Resolution                           obsolete with changes from   zer0-os/zAuction@135b2aa removing the  Description  https://github.com/ConsenSys/zer0-zauction-audit-2021-05/issues/7).  Acceptance of bids via the accountant on the old contract immediately fail after an admin updates the referenced zAuction contract while WETH bids may still continue. This may create an unfavorable scenario where two contracts may be active in parallel accepting WETH bids.  It should also be noted that 2nd layer bids (signed data) using the accountant for the old contract will not be acceptable anymore.  Examples  zAuction/contracts/zAuctionAccountant.sol:L60-L63  function SetZauction(address zauctionaddress) external onlyAdmin{  zauction = zauctionaddress;  emit ZauctionSet(zauctionaddress);  Recommendation  Consider re-thinking the upgrade path. Avoid keeping multiple versions of the auction contact active.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.6 zAuction, zNS - gas griefing by spamming offchain fake bids   ", "body": "  Resolution  Addressed and acknowledged with changes from zer0-os/zAuction@135b2aa. The client provided the following remark:  ", "labels": ["Consensys", "Medium", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.19 I have attempted to order the requires sensibly, putting the least expensive first. Please advise if the ordering is optimal. gas griefing will be mitigated in the dapp with off-client checks", "body": "  Description  The execution status of both zAuction.acceptBid and StakingController.fulfillDomainBid transactions depend on the bidder, as his approval is needed, his signature is being validated, etc. However, these transactions can be submitted by accounts that are different from the bidder account, or for accounts that do not have the required funds/deposits available, luring the account that has to perform the on-chain call into spending gas on a transaction that is deemed to fail (gas griefing). E.g. posting high-value fake bids for zAuction without having funds deposited or WETH approved.  Examples  zNS/contracts/StakingController.sol:L120-L152  function fulfillDomainBid(  uint256 parentId,  uint256 bidAmount,  uint256 royaltyAmount,  string memory bidIPFSHash,  string memory name,  string memory metadata,  bytes memory signature,  bool lockOnCreation,  address recipient  ) external {  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);  address recoveredBidder = recover(recoveredBidHash, signature);  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");  bytes32 hashOfSig = keccak256(abi.encode(signature));  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);  registrar.setDomainMetadataUri(id, metadata);  registrar.setDomainRoyaltyAmount(id, royaltyAmount);  registrar.transferFrom(controller, recoveredBidder, id);  if (lockOnCreation) {  registrar.lockDomainMetadataForOwner(id);  approvedBids[hashOfSig] = false;  emit DomainBidFulfilled(  metadata,  name,  recoveredBidder,  id,  parentId  );  zAuction/contracts/zAuction.sol:L35-L44  function acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {  address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);  require(bidder == recoveredbidder, 'zAuction: incorrect bidder');  require(!randUsed[rand], 'Random nonce already used');  randUsed[rand] = true;  IERC721 nftcontract = IERC721(nftaddress);  accountant.Exchange(bidder, msg.sender, bid);  nftcontract.transferFrom(msg.sender, bidder, tokenid);  emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);  Recommendation  Revert early for checks that depend on the bidder before performing gas-intensive computations.  Consider adding a dry-run validation for off-chain components before transaction submission.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.7 zAuction - functionality outlined in specification that is not implemented yet    ", "body": "  Resolution                           implemented as   zer0-os/zAuction@135b2aa.  Description  The specification outlines three main user journeys of which one does not seem to be implemented.  Users will be able to do simple transfer of NFTs. - which does not require functionality in the smart contract  Users will be able to post NFTs at a sale price, and buy at that price.  - does not seem to be implemented  Users will be able to post NFTs for auction, bid on auctions, and accept bids - is implemented  Recommendation  User flow (2) is not implemented in the smart contract system. Consider updating the spec or clearly highlighting functionality that is still in development for it to be excluded from security testing.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.8 zAuction - auctions/offers can be terminated by reusing the auction id    ", "body": "  Resolution  zer0-os/zAuction@8ff0eab by binding  In the zSale case the saleId is chosen by the seller. The offer (signed offer parameters including saleid) is shared on an off-chain channel. The buyer calls zSale.purchase to buy the token from the offer. The offer and all offers containing the same seller+saleid are then invalidated.  In zAuction there is no seller or someone who initiates an auction. Anyone can bid for nft s held by anyone else. The bidder chooses an auction id. There might be multiple bidders. Since the auctionId is an individual choice and the smart contract does not enforce an auction to be started there may be multiple auctions for the same token but using different auction ids. The current mechanism automatically invalidates all current bids for the token+auctionId combination for the winning bidder. Bids by other holders are not automatically invalidated but they can be invalidated manually via cancelBidsUnderPrice for an auctionId. Note that the winning bid is chosen by the nftowner/seller. The new owner of the nft may be able to immediately accept another bid and transfer the token [seller]--acceptBid-->[newOwner-A]--acceptBid-->[newOwner-B].  Description  zer0-os/zAuction@2f92aa1 introduced a way of tracking auctions/sales by using an auctionId/saleId. The id s are unique and the same id cannot be used for multiple auctions/offers.  Two different auctions/offers may pick the same id, the first auction/offer will go through while the latter cannot be fulfilled anymore. This may happen accidentally or intentionally be forced by a malicious actor to terminate active auctions/sales (griefing, front-running).  Examples  Alice puts out an offer for someone to buy nft X at a specific price. Bob decides to accept that offer and buy the nft by calling zSale.purchase(saleid, price, token, ...). Mallory monitors the mempool, sees this transaction, front-runs it to fulfill its own sale (for a random nft he owns) reusing the saleid from Bobs transaction. Since Mallories transaction marks the saleid as consumed it terminates Alie s offer and hence Bob cannot buy the token as the transaction will revert.  Recommendation  Consider using keccak(saleid+nftcontract+nfttokenid) as the unique sale/auction identifier instead, or alternatively associate the bidder address with the auctionId (require that consumed[bidder][auctionId]== false)  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.9 zAuction - hardcoded ropsten token address    ", "body": "  Resolution  Addressed with zer0-os/zAuction@135b2aa and the following statement:  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.30 weth address in constructor", "body": "  Note: does not perform input validation as recommended  Description  The auction contract hardcodes the WETH ERC20 token address. this address will not be functional when deploying to mainnet.  Examples  zAuction/contracts/zAuction.sol:L15-L16  IERC20 weth = IERC20(address(0xc778417E063141139Fce010982780140Aa0cD5Ab)); // rinkeby weth  Recommendation  Consider taking the used WETH token address as a constructor argument. Avoid code changes to facilitate testing! Perform input validation on arguments rejecting address(0x0) to facilitate the detection of potential misconfiguration in the deployment pipeline.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.10 zAuction - accountant allows zero value withdrawals/deposits/exchange    ", "body": "  Resolution                           Obsolete. The affected component has been removed from the system with   zer0-os/zAuction@135b2aa.  Description  Zero value transfers effectively perform a no-operation sometimes followed by calling out to the recipient of the withdrawal.  A transfer where from==to or where the value is 0 is ineffective.  Examples  zAuction/contracts/zAuctionAccountant.sol:L38-L42  function Withdraw(uint256 amount) external {  ethbalance[msg.sender] = SafeMath.sub(ethbalance[msg.sender], amount);  payable(msg.sender).transfer(amount);  emit Withdrew(msg.sender, amount);  zAuction/contracts/zAuctionAccountant.sol:L33-L36  function Deposit() external payable {  ethbalance[msg.sender] = SafeMath.add(ethbalance[msg.sender], msg.value);  emit Deposited(msg.sender, msg.value);  zAuction/contracts/zAuctionAccountant.sol:L44-L58  function zDeposit(address to) external payable onlyZauction {  ethbalance[to] = SafeMath.add(ethbalance[to], msg.value);  emit zDeposited(to, msg.value);  function zWithdraw(address from, uint256 amount) external onlyZauction {  ethbalance[from] = SafeMath.sub(ethbalance[from], amount);  emit zWithdrew(from, amount);  function Exchange(address from, address to, uint256 amount) external onlyZauction {  ethbalance[from] = SafeMath.sub(ethbalance[from], amount);  ethbalance[to] = SafeMath.add(ethbalance[to], amount);  emit zExchanged(from, to, amount);  Recommendation  Consider rejecting ineffective withdrawals (zero value) or at least avoid issuing a zero value ETH transfers.  Avoid emitting successful events for ineffective calls to not trigger 3rd party components on noop s.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.11 zAuction - seller should not be able to accept their own bid    ", "body": "  Resolution  Addressed with zer0-os/zAuction@135b2aa by disallowing the seller to accept their own bid. The client provided the following note:  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.28 seller != buyer required", "body": "  Description  A seller can accept their own bid which is an ineffective action that is emitting an event.  Examples  zAuction/contracts/zAuction.sol:L35-L56  function acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {  address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);  require(bidder == recoveredbidder, 'zAuction: incorrect bidder');  require(!randUsed[rand], 'Random nonce already used');  randUsed[rand] = true;  IERC721 nftcontract = IERC721(nftaddress);  accountant.Exchange(bidder, msg.sender, bid);  nftcontract.transferFrom(msg.sender, bidder, tokenid);  emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);  /// @dev 'true' in the hash here is the eth/weth switch  function acceptWethBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {  address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid, true))), signature);  require(bidder == recoveredbidder, 'zAuction: incorrect bidder');  require(!randUsed[rand], 'Random nonce already used');  randUsed[rand] = true;  IERC721 nftcontract = IERC721(nftaddress);  weth.transferFrom(bidder, msg.sender, bid);  nftcontract.transferFrom(msg.sender, bidder, tokenid);  emit WethBidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);  Recommendation  Disallow transfers to self.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zauction/"}, {"title": "5.1 Anyone is able to mint NFTs by calling mintNFTsForLM    ", "body": "  Resolution  Fixed. Not an issue, as the contract is meant to be used as a mock.  Description  The contract LiquidityMiningNFT has the method mintNFTsForLM.  code/contracts/LiquidityMiningNFT.sol:L12-L29  function mintNFTsForLM(address _liquidiyMiningAddr) external {  uint256[] memory _ids = new uint256[](NFT_TYPES_COUNT);  uint256[] memory _amounts = new uint256[](NFT_TYPES_COUNT);  _ids[0] = 1;  _amounts[0] = 5;  _ids[1] = 2;  _amounts[1] = 1 * LEADERBOARD_SIZE;  _ids[2] = 3;  _amounts[2] = 3 * LEADERBOARD_SIZE;  _ids[3] = 4;  _amounts[3] = 6 * LEADERBOARD_SIZE;  _mintBatch(_liquidiyMiningAddr, _ids, _amounts, \"\");  However, this contract does not have any kind of special permissions to limit who is able to mint tokens.  An attacker could call LiquidityMiningNFT.mintNFTsForLM(0xhackerAddress) to mint tokens for their address and sell them on the marketplace. They are also allowed to mint as many tokens as they want by calling the method multiple times.  Recommendation  Add some permissions to limit only some actors to mint tokens.  ", "labels": ["Consensys", "Critical", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.2 Liquidity providers can create deficit of DAI tokens    ", "body": "  Resolution  Fixed by keeping all the DAI inside the PolicyBook.  Description  The current staking system is built in a way that a liquidity provider can stake DAIx tokens to the staking contract. By doing so, DAI tokens are getting withdrawn from the PolicyBook and there may be not enough funds to fulfill claims.  Recommendation  This issue requires major changes in the logic of the system.  ", "labels": ["Consensys", "Critical", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.3 Profit and loss distribution mechanism is not working    ", "body": "  Resolution                           Fixed by updating the   Description  That error may also lead to the deficit of funds during withdrawals or claims.  Recommendation  Properly keep track of the totalLiquidity.  ", "labels": ["Consensys", "Critical", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.4 A liquidity provider can withdraw all his funds anytime    ", "body": "  Resolution  The funds are now locked when the withdrawal is requested, so funds cannot be transferred after the request, and this bug cannot be exploited anymore.  Description  Since some users provide liquidity to sell the insurance policies, it is important that these providers cannot withdraw their funds when the security breach happens and the policyholders are submitting claims. The liquidity providers can only request their funds first and withdraw them later (in a week).  code/contracts/PolicyBook.sol:L358-L382  function requestWithdrawal(uint256 _tokensToWithdraw) external override {  WithdrawalStatus _status = getWithdrawalStatus(msg.sender);  require(_status == WithdrawalStatus.NONE || _status == WithdrawalStatus.EXPIRED,  \"PB: Can't request withdrawal\");  uint256 _daiTokensToWithdraw = _tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE_100);  uint256 _availableDaiBalance = balanceOf(msg.sender).mul(getDAIToDAIxRatio()).div(PERCENTAGE_100);  if (block.timestamp < liquidityMining.getEndLMTime().add(neededTimeAfterLM)) {  _availableDaiBalance = _availableDaiBalance.sub(liquidityFromLM[msg.sender]);  require(totalLiquidity >= totalCoverTokens.add(_daiTokensToWithdraw),  \"PB: Not enough liquidity\");  require(_availableDaiBalance >= _daiTokensToWithdraw, \"PB: Wrong announced amount\");  WithdrawalInfo memory _newWithdrawalInfo;  _newWithdrawalInfo.amount = _tokensToWithdraw;  _newWithdrawalInfo.readyToWithdrawDate = block.timestamp.add(withdrawalPeriod);  withdrawalsInfo[msg.sender] = _newWithdrawalInfo;  emit RequestWithdraw(msg.sender, _tokensToWithdraw, _newWithdrawalInfo.readyToWithdrawDate);  code/contracts/PolicyBook.sol:L384-L396  function withdrawLiquidity() external override {  require(getWithdrawalStatus(msg.sender) == WithdrawalStatus.READY,  \"PB: Withdrawal is not ready\");  uint256 _tokensToWithdraw = withdrawalsInfo[msg.sender].amount;  uint256 _daiTokensToWithdraw = _tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE_100);  if (withdrawalQueue.length != 0 || totalLiquidity.sub(_daiTokensToWithdraw) < totalCoverTokens) {  withdrawalQueue.push(msg.sender);  } else {  _withdrawLiquidity(msg.sender, _tokensToWithdraw);  There is a restriction in requestWithdrawal that requires the liquidity provider to have enough funds at the moment of request:  code/contracts/PolicyBook.sol:L371-L374  require(totalLiquidity >= totalCoverTokens.add(_daiTokensToWithdraw),  \"PB: Not enough liquidity\");  require(_availableDaiBalance >= _daiTokensToWithdraw, \"PB: Wrong announced amount\");  But after the request is created, these funds can then be transferred to another address. When the request is created, the provider should wait for 7 days, and then there will be 2 days to withdraw the requested amount:  code/contracts/PolicyBook.sol:L113-L114  withdrawalPeriod = 1 weeks;  withdrawalExpirePeriod = 2 days;  The attacker would have 4 addresses that will send the pool tokens to each other and request withdrawal of the full amount one by one every 2 days. So at least one of the addresses can withdraw all of the funds at any point in time. If the liquidity provider needs to withdraw funds immediately, he should transfer all funds to that address and execute the withdrawal.  Recommendation  One of the solutions would be to block the DAIx tokens from being transferred after the withdrawal request.  ", "labels": ["Consensys", "Critical", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.5 Re-entrancy issue for ERC1155    ", "body": "  Resolution                           Addressed by moving   Description  ERC1155 tokens have callback functions on some of the transfers, like safeTransferFrom, safeBatchTransferFrom. During these transfers, the IERC1155ReceiverUpgradeable(to).onERC1155Received function is called in the to address.  For example,  safeTransferFrom  is used in the LiquidityMining contract:  code/contracts/LiquidityMining.sol:L204-L224  function distributeAllNFT() external {  require(block.timestamp > getEndLMTime(),  \"2 weeks after liquidity mining time has not expired\");  require(!isNFTDistributed, \"NFT is already distributed\");  for (uint256 i = 0; i < leaderboard.length; i++) {  address[] memory _groupLeaders = groupsLeaders[leaderboard[i]];  for (uint256 j = 0; j < _groupLeaders.length; j++) {  _sendNFT(j, _groupLeaders[j]);  for (uint256 i = 0; i < topUsers.length; i++) {  address _currentAddress = topUsers[i];  LMNFT.safeTransferFrom(address(this), _currentAddress, 1, 1, \"\");  emit NFTSent(_currentAddress, 1);  isNFTDistributed = true;  During that transfer, the distributeAllNFT  function can be called again and again. So multiple transfers will be done for each user.  In addition to that, any receiver of the tokens can revert the transfer. If that happens, nobody will be able to receive their tokens.  Recommendation  Add a reentrancy guard.  Avoid transferring tokens for different receivers in a single transaction.  ", "labels": ["Consensys", "Critical", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.6 The buyPolicyFor/addLiquidityFor should transfer funds from msg.sender    ", "body": "  Resolution                           Addressed by removing the   Description  When calling the buyPolicyFor/addLiquidityFor functions, are called with the parameter _policyHolderAddr/_liquidityHolderAddr who is going to be the beneficiary in buying policy/adding liquidity:  code/contracts/PolicyBook.sol:L183-L189  function buyPolicyFor(  address _policyHolderAddr,  uint256 _epochsNumber,  uint256 _coverTokens  ) external override {  _buyPolicyFor(_policyHolderAddr, _epochsNumber, _coverTokens);  code/contracts/PolicyBook.sol:L264-L266  function addLiquidityFor(address _liquidityHolderAddr, uint256 _liquidityAmount) external override {  _addLiquidityFor(_liquidityHolderAddr, _liquidityAmount, false);  During the execution, the funds for the policy/liquidity are transferred from the _policyHolderAddr/_liquidityHolderAddr, while it s usually expected that they should be transferred from msg.sender. Because of that, anyone can call a function on behalf of a user that gave the allowance to the PolicyBook.  For example, a user(victim) wants to add some DAI to the liquidity pool and gives allowance to the PolicyBook. After that, the user should call addLiquidity, but the attacker can front-run this transaction and buy a policy on behalf of the victim instead.  Also, there is a curious edge case that makes this issue Critical: _policyHolderAddr/_liquidityHolderAddr parameters can be equal to the address of the PolicyBook contract. That may lead to multiple different dangerous attack vectors.  Recommendation  Make sure that nobody can transfer funds on behalf of the users if it s not intended.  ", "labels": ["Consensys", "Critical", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.7 LiquidityMining can t accept single ERC1155 tokens    ", "body": "  Resolution                           Fixed by properly implementing the   Description  The contract LiquidityMining is also defined as an ERC1155Receiver  code/contracts/LiquidityMining.sol:L19  contract LiquidityMining is ILiquidityMining, ERC1155Receiver, Ownable {  The finalized EIP-1155 standard states that a contract which acts as an EIP-1155 Receiver must implement all the functions in the ERC1155TokenReceiver interface to be able to accept transfers.  These are indeed implemented here:  code/contracts/LiquidityMining.sol:L502  function onERC1155Received(  code/contracts/LiquidityMining.sol:L517  function onERC1155BatchReceived(  The standard states that they will be called and they MUST return a specific byte4 value, otherwise the transfer will fail.  However one of the methods returns an incorrect value. This seems to an error generated by a copy/paste action.  code/contracts/LiquidityMining.sol:L502-L515  function onERC1155Received(  address operator,  address from,  uint256 id,  uint256 value,  bytes memory data  external  pure  override  returns(bytes4)  return bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"));  The value returned is equal to  bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"));  But it should be  bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\")).  On top of this, the contract MUST implement the ERC-165 standard to correctly respond to supportsInterface.  Recommendation  Change the return value of onERC1155Received to be equal to 0xf23a6e61 which represents bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\")).  Also, make sure to implement supportsInterface to signify support of ERC1155TokenReceiver to accept transfers.  Add tests to check the functionality is correct and make sure these kinds of bugs do not exist in the future.  Make sure to read the EIP-1155 and EIP-165 standards in detail and implement them correctly.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.8 DAI is assumed to have the same price as DAIx in the staking contract    ", "body": "  Resolution  Fixed by not transferring DAI anymore.  Description  When a liquidity provider stakes tokens to the BMIDAIStaking contract, the equal amount of DAI and DAIx are transferred from the pool contract.  code/contracts/BMIDAIStaking.sol:L113-L124  function _stakeDAIx(address _user, uint256 _amount, address _policyBookAddr) internal {  require (_amount > 0, \"BMIDAIStaking: Can't stake zero tokens\");  PolicyBook _policyBook = PolicyBook(_policyBookAddr);  // transfer DAI from PolicyBook to yield generator  daiToken.transferFrom(_policyBookAddr, address(defiYieldGenerator), _amount);  // transfer bmiDAIx from user to staking  _policyBook.transferFrom(_user, address(this), _amount);  _mintNFT(_user, _amount, _policyBook);  Recommendation  Only the corresponding amount of DAI should be transferred to the pool.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.9 _updateWithdrawalQueue can run out of gas    ", "body": "  Resolution                           The   Description  When there s not enough collateral to withdraw liquidity from a policy book, the withdrawal request is added to a queue. The queue is supposed to be processed and cleared once there are enough funds for that. The only way to do so is the _updateWithdrawalQueue function that is caller when new liquidity is added:  code/contracts/PolicyBook.sol:L315-L338  function _updateWithdrawalQueue() internal {  uint256 _availableLiquidity = totalLiquidity.sub(totalCoverTokens);  uint256 _countToRemoveFromQueue;  for (uint256 i = 0; i < withdrawalQueue.length; i++) {  uint256 _tokensToWithdraw = withdrawalsInfo[withdrawalQueue[i]].amount;  uint256 _amountInDai = _tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE_100);  if (balanceOf(withdrawalQueue[i]) < _tokensToWithdraw) {  _countToRemoveFromQueue++;  continue;  if (_availableLiquidity >= _amountInDai) {  _withdrawLiquidity(withdrawalQueue[i], _tokensToWithdraw);  _availableLiquidity = _availableLiquidity.sub(_amountInDai);  _countToRemoveFromQueue++;  } else {  break;  _removeFromQueue(_countToRemoveFromQueue);  The problem is that this function can only process all queue until the pool run out of available funds or the whole queue is going to be processed. If the queue is big enough, this process can be stuck.  Recommendation  Pass the parameter to the _updateWithdrawalQueue that defines how many requests to process in the queue per one call.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.10 The PolicyBook should make DAI transfers inside the contract    ", "body": "  Resolution                           The   Description  The PolicyBook contract gives full allowance over DAI tokens to the other contracts:  code/contracts/PolicyBook.sol:L120-L125  function approveAllDaiTokensForStakingAndVotingAndTransferOwnership() internal {  daiToken.approve(address(bmiDaiStaking), MAX_INT);  daiToken.approve(address(claimVoting), MAX_INT);  transferOwnership(address(bmiDaiStaking));  That behavior is dangerous because it s hard to keep track of and control the contract s DAI balance. And it s also hard to track in the code where the balance of the PolicyBook can be changed from.  Recommendation  It s better to perform all the transfers inside the PolicyBook contract. So if the bmiDaiStaking and the claimVoting contracts need DAI tokens from the PolicyBook, they should call some function of the PolicyBook to perform transfers.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.11 Premium is payed instantly to the liquidity providers    ", "body": "  Resolution  The premium is now distributed on a daily basis.  Description  When the policy is bought, the premium is transferred to the PolicyBook instantly. Currently, these funds are not going to the liquidity providers as a reward due to the issue 5.3. But when the issue is fixed, it seems like the premium is paid and distributed as a reward instantly when the policy is purchased.  The problem is that if someone buys the policy for a long period of time, every liquidity provider instantly gets the premium from the full period. If there s enough liquidity, any provider can withdraw the funds after that without taking a risk for this period.  Recommendation  Distribute the premium over time. For example, increase the reward after each epoch.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.12 The totalCoverTokens is only updated when the policy is bought    ", "body": "  Resolution                           The   Description  The totalCoverTokens value represents the amount of collateral that needs to be locked in the policy book. It should be changed either by buying a new policy or when an old policy expires. The problem is that when the old policy expires, this value is not updated; it is only updated when someone buys a policy by calling the _updateEpochsInfo  function:  code/contracts/PolicyBook.sol:L240-L251  function _updateEpochsInfo() internal {  uint256 _totalEpochTime = block.timestamp.sub(epochStartTime);  uint256 _countOfPassedEpoch = _totalEpochTime.div(epochDuration);  uint256 _lastEpochUpdate = currentEpochNumber;  currentEpochNumber = _countOfPassedEpoch.add(1);  for (uint256 i = _lastEpochUpdate; i < currentEpochNumber; i++) {  totalCoverTokens = totalCoverTokens.sub(epochAmounts[i]);  delete epochAmounts[i];  Users waiting to withdraw liquidity should wait for someone to buy the policy to update the totalCoverTokens.  Recommendation  Make sure it s possible to call the _updateEpochsInfo function without buying a new policy.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.13 Unbounded loops in LiquidityMining    ", "body": "  Resolution  Fixed by adding the limits.  Description  There are some methods that have unbounded loops and will fail when enough items exist in the arrays.  code/contracts/LiquidityMining.sol:L83  for (uint256 i = 0; i < _teamsNumber; i++) {  code/contracts/LiquidityMining.sol:L97  for (uint256 i = 0; i < _membersNumber; i++) {  code/contracts/LiquidityMining.sol:L110  for (uint256 i = 0; i < _usersNumber; i++) {  These methods will fail when lots of items will be added to them.  Recommendation  Consider adding limits (from, to) when requesting the items.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.14 The _removeFromQueue is very gas greedy    ", "body": "  Resolution  The queue structure has changed significantly and became more optimized. On the other hand, the new structure has some overhead and can be simplified to optimize more gas.  Description  The _removeFromQueue function is supposed  to remove _countToRemove elements from the queue:  code/contracts/PolicyBook.sol:L296-L313  function _removeFromQueue(uint256 _countToRemove) internal {  for (uint256 i = 0; i < _countToRemove; i++) {  delete withdrawalsInfo[withdrawalQueue[i]];  if (_countToRemove == withdrawalQueue.length) {  delete withdrawalQueue;  } else {  uint256 _remainingArrLength = withdrawalQueue.length.sub(_countToRemove);  address[] memory _remainingArr = new address[](_remainingArrLength);  for (uint256 i = 0; i < _remainingArrLength; i++) {  _remainingArr[i] = withdrawalQueue[i.add(_countToRemove)];  withdrawalQueue = _remainingArr;  This function uses too much gas, which makes it easier to make attacks on the system. Even if only one request is removed and executed, this function rewrites all the requests to the storage.  Recommendation  The data structure should be changed so this function shouldn t rewrite the requests that did not change. For example, it can be a mapping (unit => address) with 2 indexes (start, end) that are only increasing.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.15 Withdrawal with zero amount is possible    ", "body": "  Resolution                           The   Description  When creating a withdrawal request, the amount of tokens to withdraw is passed as a parameter:  code/contracts/PolicyBook.sol:L358  function requestWithdrawal(uint256 _tokensToWithdraw) external override {  The problem is that this parameter can be zero, and the function will be successfully executed. Moreover, this request can then be added to the queue, and the actual withdrawal will also be executed with zero value. Addresses that never added any liquidity could spam the system with these requests.  Recommendation  Do not allow withdrawals of zero tokens.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.16 The withdrawal queue is only updated when the liquidity is added    ", "body": "  Resolution                           The queue is now updated via the   Description  Sometimes when the amount of liquidity is not much higher than the number of tokens locked for the collateral, it s impossible to withdraw liquidity.  For a user that wants to withdraw liquidity, a withdrawal request is created. If the request can t be executed, it s added to the withdrawal queue, and the user needs to wait until there s enough collateral for withdrawal. There are potentially 2 ways to achieve that: either someone adds more liquidity or some existing policies expire.  Currently, the queue can only be cleared when the internal _updateWithdrawalQueue  function is called. And it is only called in one place while adding liquidity:  code/contracts/PolicyBook.sol:L276-L290  function _addLiquidityFor(address _liquidityHolderAddr, uint256 _liquidityAmount, bool _isLM) internal {  daiToken.transferFrom(_liquidityHolderAddr, address(this), _liquidityAmount);  uint256 _amountToMint = _liquidityAmount.mul(PERCENTAGE_100).div(getDAIToDAIxRatio());  totalLiquidity = totalLiquidity.add(_liquidityAmount);  _mintERC20(_liquidityHolderAddr, _amountToMint);  if (_isLM) {  liquidityFromLM[_liquidityHolderAddr] = liquidityFromLM[_liquidityHolderAddr].add(_liquidityAmount);  _updateWithdrawalQueue();  emit AddLiquidity(_liquidityHolderAddr, _liquidityAmount, totalLiquidity);  Recommendation  It would be better if the queue could be processed when some policies expire without adding new liquidity. For example, there may be an external function that allows users to process the queue.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.17 Optimize gas usage when checking max length of arrays    ", "body": "  Description  There are a few cases where some arrays have to be limited to a number of items.  And the max size is enforced by removing the last item if the array reached max size + 1.  code/contracts/LiquidityMining.sol:L386-L388  if (leaderboard.length == MAX_LEADERBOARD_SIZE.add(1)) {  leaderboard.pop();  code/contracts/LiquidityMining.sol:L439-L441  if (topUsers.length == MAX_TOP_USERS_SIZE.add(1)) {  topUsers.pop();  code/contracts/LiquidityMining.sol:L495-L497  if (_addresses.length == MAX_GROUP_LEADERS_SIZE.add(1)) {  groupsLeaders[_referralLink].pop();  A simpler and cheaper way to check if an item should be removed is to change the condition to  if (limitedSizedArray.length > MAX_DEFINED_SIZE_FOR_ARRAY) {  limitedSizedArray.pop();  This check does not need or do a SafeMath call (which is more expensive), and because of the limited number of items, as well as a practical impossibility to add enough items to overflow the limit, makes it a preferred way to check the maximum limit.  Recommendation  Rewrite the checks and remove SafeMath operations, as well as the addition by 1 and change the check to a  greater than  verification.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.18 Methods return values that are never used    ", "body": "  Description  When a user calls investDAI these 3 methods are called internally:  code/contracts/LiquidityMining.sol:L196-L198  _updateTopUsers();  _updateLeaderboard(_userTeamInfo.teamAddr);  _updateGroupLeaders(_userTeamInfo.teamAddr);  Each method returns a boolean, but the value is never used. It is also unclear what the value should represent.  Recommendation  Remove the returned variable or use it in method investDAI.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.19 Save some gas when looping over state arrays    ", "body": "  Resolution  Fixed by caching array state length in a local variable.  Description  There are a few loops over state arrays in LiquidutyMining.  code/contracts/LiquidityMining.sol:L209  for (uint256 i = 0; i < leaderboard.length; i++) {  code/contracts/LiquidityMining.sol:L217  for (uint256 i = 0; i < topUsers.length; i++) {  Consider caching the length in a local variable to reduce gas costs.  Examples  Similar to  code/contracts/LiquidityMining.sol:L107  uint256 _usersNumber = allUsers.length;  code/contracts/LiquidityMining.sol:L110  for (uint256 i = 0; i < _usersNumber; i++) {  Recommendation  Reduce gas cost by caching array state length in a local variable.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.20 Optimize gas costs when handling liquidity start and end times ", "body": "  Description  When the LiquidityMining contract is deployed, startLiquidityMiningTime saves the current block timestamp.  code/contracts/LiquidityMining.sol:L46  startLiquidityMiningTime = block.timestamp;  This value is never changed.  There also exists an end limit calculated by getEndLMTime.  code/contracts/LiquidityMining.sol:L271-L273  function getEndLMTime() public view override returns (uint256) {  return startLiquidityMiningTime.add(2 weeks);  This value is also fixed, once the start was defined.  None of the values change after the contract was deployed. This is why you can use the immutable feature provided by Solidity.  It will reduce costs significantly.  Examples  contract A {  uint public immutable start;  uint public immutable end;  constructor() {  start = block.timestamp;  end = block.timestamp + 2 weeks;  This contract defines 2 variables: start and end and their value is fixed on deploy and cannot be changed.  It does not need to use SafeMath because there s no risk of overflowing.  Setting public on both variables creates getters, and calling A.start() and A.end() returns the respective values.  Having set as immutable does not request EVM storage and makes them very cheap to access.  Recommendation  Use Solidity s immutable feature to reduce gas costs and rename variables for consistency.  Use the example for inspiration.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "5.21 Computing the quote should be done for a positive amount of tokens    ", "body": "  Description  When a policy is bought, a quote is requested from the PolicyQuote contract.  code/contracts/PolicyBook.sol:L191-L195  function _buyPolicyFor(  address _policyHolderAddr,  uint256 _epochsNumber,  uint256 _coverTokens  ) internal {  code/contracts/PolicyBook.sol:L213  uint256 _totalPrice = policyQuote.getQuote(_totalSeconds, _coverTokens, address(this));  The getQuote call is then forwarded to an internal function  code/contracts/PolicyQuote.sol:L39-L43  function getQuote(uint256 _durationSeconds, uint256 _tokens, address _policyBookAddr)  external view override returns (uint256 _daiTokens)  _daiTokens = _getQuote(_durationSeconds, _tokens, _policyBookAddr);  code/contracts/PolicyQuote.sol:L45-L47  function _getQuote(uint256 _durationSeconds, uint256 _tokens, address _policyBookAddr)  internal view returns (uint256)  There are some basic checks that make sure the total covered tokens with the requested quote do not exceed the total liquidity. On top of that check, it makes sure the total liquidity is positive.  code/contracts/PolicyQuote.sol:L52-L53  require(_totalCoverTokens.add(_tokens) <= _totalLiquidity, \"PolicyBook: Requiring more than there exists\");  require(_totalLiquidity > 0, \"PolicyBook: The pool is empty\");  But there is no check for the number of quoted tokens. It should also be positive.  Recommendation  Add an additional check for the number of quoted tokens to be positive. The check could fail or return 0, depending on your use case.  If you add a check for the number of quoted tokens to be positive, the check for _totalLiquidity to be positive becomes obsolete and can be removed.  6 Re-audit issues  This section lists the issues found in the re-audit phase. The audit team, reviewed the code fixes after the initial report was delivered.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.1 Anyone can win all the funds from the LiquidityMining without investing any DAI ", "body": "  Description  When a user decides to investDAI in the LiquidityMining contract, the policy book address is passed as a  parameter:  code_new/contracts/LiquidityMining.sol:L198  function investDAI(uint256 _tokensAmount, address _policyBookAddr) external override {  But this parameter is never checked and only used at the end of the function:  code_new/contracts/LiquidityMining.sol:L223  IPolicyBook(_policyBookAddr).addLiquidityFromLM(msg.sender, _tokensAmount);  The attacker can pass the address of a simple multisig that will process this transaction successfully without doing anything. And pretend to invest a lot of DAI without actually doing that to win all the rewards in the LiquidityMining contract.  Recommendation  Check that the pool address is valid.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.2 Liquidity withdrawal can be blocked ", "body": "  Description  The main problem in that issue is that the liquidity provider may face many potential issues when withdrawing the liquidity. Under some circumstances, a normal user will never be able to withdraw the liquidity. This issue consists of multiple factors that are interconnected and share the same solution.  There are no partial withdrawals when in the queue. When the withdrawal request is added to the queue, it can only be processed fully: code_new/contracts/PolicyBook.sol:L444-L451 address _currentAddr = withdrawalQueue.head(); uint256 _tokensToWithdraw = withdrawalsInfo[_currentAddr].withdrawalAmount;  uint256 _amountInDAI = convertDAIXtoDAI(_tokensToWithdraw);  if (_availableLiquidity < _amountInDAI) {   break; } But when the request is not in the queue, it can still be processed partially, and the rest of the locked tokens will wait in the queue. code_new/contracts/PolicyBook.sol:L581-L590 } else if (_availableLiquidity < convertDAIXtoDAI(_tokensToWithdraw)) {   uint256 _availableDAIxTokens = convertDAIToDAIx(_availableLiquidity);   uint256 _currentWithdrawalAmount = _tokensToWithdraw.sub(_availableDAIxTokens);   withdrawalsInfo[_msgSender()].withdrawalAmount = _currentWithdrawalAmount;    aggregatedQueueAmount = aggregatedQueueAmount.add(_currentWithdrawalAmount);   withdrawalQueue.push(_msgSender());    _withdrawLiquidity(_msgSender(), _availableDAIxTokens); } else { If there s a huge request in the queue, it can become a bottleneck that does not allow others to withdraw even if there is enough free liquidity.  Withdrawals can be blocked forever by the bots. The withdrawal can only be requested if there are enough free funds in the contract. But once these funds appear, the bots can instantly buy a policy, and for the normal users, it will be impossible to request the withdrawal. Even when a withdrawal is requested and then in the queue, the same problem appears at that stage.  The policy can be bought even if there are pending withdrawals in the queue.  Recommendation  One of the solutions would be to implement the following changes, but the team should thoroughly consider them:  Allow people to request the withdrawal even if there is not enough liquidity at the moment.  Do not allow people to buy policies if there are pending withdrawals in the queue and cannot be executed.  (Optional) Even when the queue is empty, do not allow people to buy policies if there is not enough liquidity for the pending requests (that are not yet in the queue).  (Optional if the points above are implemented) Allow partial executions of the withdrawals in the queue.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.3 The totalCoverTokens can be decreased before the claim is committed ", "body": "  Description  The totalCoverTokens is decreased right after the policy duration ends (_endEpochNumber). When that happens, the liquidity providers can withdraw their funds:  code_new/contracts/PolicyBook.sol:L262-L265  policyHolders[_msgSender()] = PolicyHolder(_coverTokens, currentEpochNumber,  _endEpochNumber, _totalPrice, _reinsurancePrice);  epochAmounts[_endEpochNumber] = epochAmounts[_endEpochNumber].add(_coverTokens);  code_new/contracts/PolicyBook.sol:L343-L351  uint256 _countOfPassedEpoch = block.timestamp.sub(epochStartTime).div(EPOCH_DURATION);  newTotalCoverTokens = totalCoverTokens;  lastEpochUpdate = currentEpochNumber;  newEpochNumber = _countOfPassedEpoch.add(1);  for (uint256 i = lastEpochUpdate; i < newEpochNumber; i++) {  newTotalCoverTokens = newTotalCoverTokens.sub(epochAmounts[i]);  On the other hand, the claim can be created while the policy is still  active . And is considered active until one week after the policy expired:  code_new/contracts/PolicyRegistry.sol:L50-L58  function isPolicyActive(address _userAddr, address _policyBookAddr) public override view returns (bool) {  PolicyInfo storage _currentInfo = policyInfos[_userAddr][_policyBookAddr];  if (_currentInfo.endTime == 0) {  return false;  return _currentInfo.endTime.add(STILL_CLAIMABLE_FOR) > block.timestamp;  By the time when the claim is created + voted, the liquidity provider can potentially withdraw all of their funds already, and the claim will fail.  Recommendation  Make sure that there will always be enough funds for the claim.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.4 The totalCoverTokens is not decreased after the claim happened ", "body": "  Description  When the claim happens and the policy is removed, the totalCoverTokens should be decreased instantly, that s why the scheduled reduction value is removed:  code_new/contracts/PolicyBook.sol:L228-L236  PolicyHolder storage holder = policyHolders[claimer];  epochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);  totalLiquidity = totalLiquidity.sub(claimAmount);  daiToken.transfer(claimer, claimAmount);  delete policyHolders[claimer];  policyRegistry.removePolicy(claimer);  But the totalCoverTokens  is not changed and will have the coverage from the removed policy forever.  Recommendation  Decrease the totalCoverTokens  inside the commitClaim function.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.5 The Queue remove function does not remove the item completely ", "body": "  Description  When removing an item in a queue, the following function is used:  code_new/contracts/helpers/Queue.sol:L78-L98  function remove(UniqueAddressQueue storage baseQueue, address addrToRemove) internal returns (bool) {  if (!contains(baseQueue, addrToRemove)) {  return false;  if (baseQueue.HEAD == addrToRemove) {  return removeFirst(baseQueue);  if (baseQueue.TAIL == addrToRemove) {  return removeLast(baseQueue);  address prevAddr = baseQueue.queue[addrToRemove].prev;  address nextAddr = baseQueue.queue[addrToRemove].next;  baseQueue.queue[prevAddr].next = nextAddr;  baseQueue.queue[nextAddr].prev = prevAddr;  baseQueue.queueLength--;  return true;  As the result, the baseQueue.queue[addrToRemove] is not deleted, so the contains function will still return True after the removal.  Recommendation  Remove the element from the queue completely.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.6 Optimization issue ", "body": "  Description  The codebase is huge, and there are still a lot of places where these complications and gas efficiency can be improved.  Examples  _updateTopUsers, _updateGroupLeaders, _updateLeaderboard are having a similar mechanism of adding users to a sorted set which makes more storage operations than needed: code_new/contracts/LiquidityMining.sol:L473-L486 uint256 _tmpIndex = _currentIndex - 1; uint256 _currentUserAmount = usersTeamInfo[msg.sender].stakedAmount;  while (_currentUserAmount > usersTeamInfo[topUsers[_tmpIndex]].stakedAmount) {     address _tmpAddr = topUsers[_tmpIndex];     topUsers[_tmpIndex] = msg.sender;     topUsers[_tmpIndex + 1] = _tmpAddr;      if (_tmpIndex == 0) {         break;     }      _tmpIndex--; } Instead of doing 2 operations per item that is lower than the new_item, same can be done with one operation: while topUsers[_tmpIndex] is lower than the new itemtopUsers[_tmpIndex + 1] = topUsers[_tmpIndex].  creating the Queue library looks like overkill for the intended task. It is only used for the withdrawal queue in the PolicyBook. The structure stores and processes extra data, which is unnecessary and more expensive. A larger codebase also has a higher chance of introducing a bug (and it happened here https://github.com/ConsenSys/bridge-mutual-audit-2021-03/issues/25). It s usually better to have a simpler and optimized version like described here issue 5.14.  There are a few for loops that are using uint8 iterators. It s unnecessary and can be even more expensive because, under the hood, it s additionally converted to uint256 all the time. In general, shrinking data to uint8 makes sense to optimize storage slots, but that s not the case here.  The value that is calculated in a loop can be obtained simpler by just having a 1-line formula: code_new/contracts/LiquidityMining.sol:L351-L367 function _getAvailableMonthForReward(address _userAddr) internal view returns (uint256) {     uint256 _oneMonth = 30 days;     uint256 _startRewardTime = getEndLMTime();      uint256 _countOfRewardedMonth = countsOfRewardedMonth[usersTeamInfo[_userAddr].teamAddr][_userAddr];     uint256 _numberOfMonthForReward;      for (uint256 i = _countOfRewardedMonth; i < MAX_MONTH_TO_GET_REWARD; i++) {         if (block.timestamp > _startRewardTime.add(_oneMonth.mul(i))) {         _numberOfMonthForReward++;         } else {             break;         }     }      return _numberOfMonthForReward; }  The mapping is using 2 keys, but the first key is strictly defined by the second one, so there s no need for it: code_new/contracts/LiquidityMining.sol:L60-L61 // Referral link => Address => count of rewarded month mapping (address => mapping (address => uint256)) public countsOfRewardedMonth;  There are a lot of structures in the code with duplicated and unnecessary data, for example: code_new/contracts/LiquidityMining.sol:L42-L48 struct UserTeamInfo {     string teamName;     address teamAddr;      uint256 stakedAmount;     bool isNFTDistributed; } Here the structure is created for every team member, duplicating the team name for each member.  Recommendation  Optimize and simplify the code.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.7 Proper usage of the transfer and the transferFrom functions ", "body": "  Description  Many ERC-20 transfers in the code are just called without checking the return values:  code_new/contracts/PolicyBook.sol:L269-L270  daiToken.transferFrom(_msgSender(), reinsurancePoolAddress, _reinsurancePrice);  daiToken.transferFrom(_msgSender(), address(this), _price);  code_new/contracts/PolicyBook.sol:L556-L559  function _unlockTokens(uint256 _amountToUnlock) internal {  this.transfer(_msgSender(), _amountToUnlock);  delete withdrawalsInfo[_msgSender()];  code_new/contracts/LiquidityMining.sol:L278  bmiToken.transfer(msg.sender, _userReward);  Even though the tokens in these calls are not arbitrary (DAI, BMI, DAIx, stkBMIToken) and probably always return True or call revert, it s still better to comply with the ERC-20 standard and make sure that the transfer went well.  Recommendation  The best solution would be better to always use the safe version of the transfers from openzeppelin/contracts/token/ERC20/SafeERC20.sol.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.8 The price and the duration of a policy may be unpredictable ", "body": "  Description  When the user is buying a policy, the price is calculated based on the current liquidity/coverage ratio, and the duration is calculated based on the current timestamp. A malicious actor can front-run the buyer (e.g., buy short-term insurance with a huge coverage) and increase the policy s price. Or the transaction can be executed much later for some reason, and the number of the totalSeconds may be larger, the coverage period can be between _epochsNumber - 1 and _epochsNumber.  Recommendation  Given the unpredictability of the price, it s better to pass the hard limit for the insurance price as a parameter. Also, as an opinion, you can add a deadline for the transaction as a parameter.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.9 The  aggregatedQueueAmount  value is used inconsistently ", "body": "  Description  The aggregatedQueueAmount variable represents the cumulative DAIx amount in the queue that is waiting for the withdrawal.  When requesting the withdrawal, this value is used as the amount of DAI that needs to be withdrawn, which may be significantly different:  code_new/contracts/PolicyBook.sol:L539-L540  require(totalLiquidity >= totalCoverTokens.add(aggregatedQueueAmount).add(_daiTokensToWithdraw),  \"PB: Not enough available liquidity\");  That may lead to allowing the withdrawal request even if it shouldn t be allowed and the opposite.  Recommendation  Convert aggregatedQueueAmount to DAI in the _requestWithdrawal.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.10 The claim can only be done once ", "body": "  Description  When the claim happens, the policy is removed afterward:  code_new/contracts/PolicyBook.sol:L222-L237  function commitClaim(address claimer, uint256 claimAmount)  external  override  onlyClaimVoting  updateBMIDAIXStakingReward  PolicyHolder storage holder = policyHolders[claimer];  epochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);  totalLiquidity = totalLiquidity.sub(claimAmount);  daiToken.transfer(claimer, claimAmount);  delete policyHolders[claimer];  policyRegistry.removePolicy(claimer);  If the claim amount is much lower than the coverage, the users are incentivized not to submit it and wait until the end of the coverage period to accumulate all the claims into one.  Recommendation  Allow the policyholders to submit multiple claims until the coverTokens is not reached.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "6.11 Users are incentivised to invest right before the getEndLMTime to join the winning team ", "body": "  Description  When investing, there are 3 types of rewards in the LiquidityMining contracts: for the top users, for the top teams, for the group leaders in the top teams. EVERY member from the top teams is getting a reward proportional to the provided stake. Only the final snapshot of the stakes is used to determine the leaderboard which is right after the getEndLMTime.  Everyone can join any team, and everyone s goal is to go to the winning teams. The best way to do so is to wait right until the end of the period and join the most beneficial team.  Recommendation  It s better to avoid extra incentives that create race conditions.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/03/bridge-mutual/"}, {"title": "4.1 The Account Proof Is Not Verified Against the Target Address    ", "body": "  Resolution                           The problem has been fixed in   PR#162.  Description  Examples  packages/l1-contracts/contracts/linea-verifier/EVMFetcher.sol:L256-L262  abi.encode(  request.verifier,  request.commands,  request.constants,  callbackId,  callbackData  packages/l1-contracts/contracts/linea-verifier/EVMFetchTarget.sol:L24-L33  IEVMVerifier verifier,  bytes32[] memory commands,  bytes[] memory constants,  bytes4 callback,  bytes memory callbackData  ) = abi.decode(  extradata,  (IEVMVerifier, bytes32[], bytes[], bytes4, bytes)  );  packages/l1-contracts/contracts/linea-verifier/LineaProofHelper.sol:L154-L183  function verifyAccountProof(  AccountProofStruct memory accountProof,  bytes32 stateRoot  ) private pure returns (bool) {  bool accountProofVerified = SparseMerkleProof.verifyProof(  accountProof.proof.proofRelatedNodes,  accountProof.leafIndex,  stateRoot  );  require(  accountProofVerified,  \"LineaResolverStub: invalid account proof\"  );  bytes32 hAccountValue = SparseMerkleProof.hashAccountValue(  accountProof.proof.value  );  SparseMerkleProof.Leaf memory accountLeaf = SparseMerkleProof.getLeaf(  accountProof.proof.proofRelatedNodes[41]  );  require(  accountLeaf.hValue == hAccountValue,  \"LineaResolverStub: account value invalid\"  );  return true;  Recommendation  Add target data in the fetch and getStorageSlotsCallback function, meanwhile add target address verification in verifyAccountProof function.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.2 Lack of Verification for Latest L2 Block Number in Fetch Requests    ", "body": "  Resolution  The Linea team responded  there is a lag between the time of the finalization tx on L1 and the time it is notified to shomei nodes which respond to the query linea_getProof . This means that every time there is a finalization, for about 15 min, the ccip-read reverts because the Shomei nodes are not aware yet of this finalization  PR202 by using a virtual function  Description  The storage slot value returned by the gateway is verified by LineaSparseProofVerifier using a Merkel proof, the Merkel root is fetched from Linea  based on a block number (IRollup(_rollup).stateRootHashes(blockNo))   in the storage proof provided by the gateway. However the returned block number is not checked against the latest block number on L2 at the time of fetching request from the user, this allows the gateway to potentially return an incorrect L2 block number (either earlier or later) along with incorrect storage proof. Despite these inconsistencies, the verification process would pass and the user would receive incorrect ENS data.  Examples  packages/l1-contracts/contracts/linea-verifier/LineaSparseProofVerifier.sol:L22-L50  function getStorageValues(  bytes32[] memory commands,  bytes[] memory constants,  bytes memory proof  ) external view returns (bytes[] memory values) {  uint256 blockNo,  AccountProofStruct memory accountProof,  StorageProofStruct[] memory storageProofs  ) = abi.decode(  proof,  (uint256, AccountProofStruct, StorageProofStruct[])  );  bytes32 stateRoot = IRollup(_rollup).stateRootHashes(blockNo);  require(  stateRoot != bytes32(0),  \"LineaResolverStub: invalid state root\"  );  return  LineaProofHelper.getStorageValues(  commands,  constants,  stateRoot,  accountProof,  storageProofs  );  packages/l1-contracts/contracts/linea-verifier/EVMFetcher.sol:L248-L264  revert OffchainLookup(  address(this),  request.verifier.gatewayURLs(),  abi.encodeCall(  IEVMGateway.getStorageSlots,  (request.target, request.commands, request.constants)  ),  EVMFetchTarget.getStorageSlotsCallback.selector,  abi.encode(  request.verifier,  request.commands,  request.constants,  callbackId,  callbackData  );  packages/l1-contracts/contracts/linea-verifier/EVMFetchTarget.sol:L19-L38  function getStorageSlotsCallback(  bytes calldata response,  bytes calldata extradata  ) external {  bytes memory proof = abi.decode(response, (bytes));  IEVMVerifier verifier,  bytes32[] memory commands,  bytes[] memory constants,  bytes4 callback,  bytes memory callbackData  ) = abi.decode(  extradata,  (IEVMVerifier, bytes32[], bytes[], bytes4, bytes)  );  bytes[] memory values = verifier.getStorageValues(  commands,  constants,  proof  );  Recommendation  We recommend that client include the latest L2 block number at the time of fetching through a parameter L2blockNumber in the extradata of revert OffchainLookup in fetch function,  abi.encode(  request.verifier,  request.commands,  request.constants,  callbackId,  callbackData,  L2blockNumber  then verify the block number from the proof against the corresponding block number decoded from extradata in getStorageSlotsCallback by  getStorageValues of LineaSparseProofVerifier  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.3 Hash Collision in the MiMC Library    ", "body": "  Resolution                           The problem has been fixed in   PR#178.  Description  In the hash function of the Mimc library, because of the following block of code:  lastChunk := shr(mul(sub(0x20, remaining), 0x8), lastChunk)  Different calldata can result in the same hash. For example, by passing:  0x00000000000000000000000000000000000000000000000000000000000000000001, 0x000000000000000000000000000000000000000000000000000000000000000000000001  the mimcHash variable will be 0x0abfc49c04232d502cde9bfe87350d596ee3a8d4f736f747dc163c21991adab2 in both cases. This can lead to unexpected behavior within the protocol and integrator problems using the external mimcHash function, resulting in hash collisions.  Examples  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L54-L56  function mimcHash(bytes calldata _input) external pure returns (bytes32) {  return Mimc.hash(_input);  packages/l1-contracts/contracts/linea-verifier/lib/Mimc.sol:L24-L44  function hash(  bytes calldata _msg  ) external pure returns (bytes32 mimcHash) {  assembly {  let chunks := div(add(_msg.length, 0x1f), 0x20)  for {  let i := 0  } lt(i, sub(chunks, 1)) {  i := add(i, 1)  } {  let offset := add(_msg.offset, mul(i, 0x20))  let chunk := calldataload(offset)  let r := encrypt(mimcHash, chunk)  mimcHash := addmod(  addmod(mimcHash, r, FR_FIELD),  chunk,  FR_FIELD  Recommendation  We recommend validating that the input code is a multiple of 32 bytes in length.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.4 Overflow in the NameWrapper Contract    ", "body": "  Resolution                           The original problem has been fixed with the comment:  The register function is almost unusable with our deployment setup, only   PR#180 by reverting the overflow during the type casting.  Description  Consider the following PoC, which is a modification of the test from the TestEthRegistrarController file:  it.only('should permit new registrations with resolver and records', async () => {  var commitment = await controller2.makeCommitment(  'newconfigname',  registrantAccount,  // 18446744073709551616 - 7776000  // uintMax64 + 1 - grace period  (18446744073701775616).toString(),  secret,  resolver.address,  callData,  false,  5,  var tx = await controller2.commit(commitment)  await evm.advanceTime((await controller2.minCommitmentAge()).toNumber())  var tx = await controller2.register(  'newconfigname',  registrantAccount,  (18446744073701775616).toString(),  secret,  resolver.address,  callData,  false,  5,  { value: ethers.BigNumber.from((300000000000000*(28*DAY)+3*DAY).toString()).toString() },  await expect(tx)  .to.emit(controller, 'NameRegistered')  })  registrarExpiry = registrar.register(tokenId, address(this), duration); // <-- normal value, 18446744075420660688  _wrap(  label,  wrappedOwner,  ownerControlledFuses,  uint64(registrarExpiry) + GRACE_PERIOD, // <-- overflow, 1718885072  resolver  );  Which makes the wrapped name immediately expired.  Based on the documentation of the ENS:  If the name is a .eth 2LD, then the expiry will automatically be set to the same expiry in the .eth Registrar. But for all other names, the parent can choose what expiry to set for a child name.  However, due to the overflow, the expiry date in Registrar and Wrapper will differ.  When the name s expiration date (from the .eth Registrar) has been reached, and the name is now in the grace period, all Name Wrapper operations on the name will be restricted.  The owner will not yet lose ownership of the name, but they will also not be able to unwrap or update the name until it has been renewed.  The owner will still have ownership of the name. However, he will have to spend excessive money to renew the wrapped name. This problem can occur when the price oracle returns cheap prices for names or when the price for a name is fixed. For example, in the Linea ENS scope, there is a FixedPriceOracle contract that returns the FIXED_PRICE_ETH price for the name. If the user decides to buy it and specify a large duration value, it will lead to the overflow, causing unexpected behavior and creating an already outdated name.  Examples  packages/l2-contracts/contracts/wrapper/NameWrapper.sol:L337-L353  function registerAndWrap(  string calldata label,  address wrappedOwner,  uint256 duration,  address resolver,  uint16 ownerControlledFuses  ) external onlyController returns (uint256 registrarExpiry) {  uint256 tokenId = uint256(keccak256(bytes(label)));  registrarExpiry = registrar.register(tokenId, address(this), duration);  _wrap(  label,  wrappedOwner,  ownerControlledFuses,  uint64(registrarExpiry) + GRACE_PERIOD,  resolver  );  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L286-L310  function register(  string calldata name,  address owner,  uint256 duration,  bytes32 secret,  address resolver,  bytes[] calldata data,  bool reverseRecord,  uint16 ownerControlledFuses  ) public payable override {  IPriceOracle.Price memory price = rentPrice(name, duration);  if (msg.value < price.base + price.premium) {  revert InsufficientValue();  uint256 expires = _register(  name,  owner,  duration,  secret,  resolver,  data,  reverseRecord,  ownerControlledFuses,  false  );  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L54  uint64 private constant MAX_EXPIRY = type(uint64).max;  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L478-L480  if (duration < MIN_REGISTRATION_DURATION) {  revert DurationTooShort(duration);  Recommendation  We recommend validating the MAX_REGISTRATION_DURATION to prevent overflow issues.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.5 Namewrapper Doesn t Support Other .Eth 2 Level Domains   ", "body": "  Resolution  Linea won t support other base domains than the one initialized in the deployment so it won t be fixed.  Description  Examples  packages/l2-contracts/contracts/wrapper/NameWrapper.sol:L428  _wrap(node, name, wrappedOwner, 0, 0);  Recommendation  Add support for other .eth 2 level domains in wrap function to ensure they are correctly wrapped with appropriate fuses and expiry parameters.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.6 Unbounded Gas Consumption in the while in LineaProofHelper   Partially Addressed", "body": "  Resolution                           The problem has been downgraded from Major to Medium, Linea team responded  The user is paying for the gas fee, it s not the resolver s fund that is used, we agreed to put this issue as medium or low, only the optimisation part can be done . The code was gas optimized in the   PR#181, but the length of the variable wasn t limited.  Description  To sum up, a value with a length of 32 bytes results in over 80 for loops executing custom logic, and the length of the value is not limited. This unoptimized and gas-heavy logic creates risks of a gas bomb attack, where function execution will cost more gas than the gas block limit. Additionally, a malicious user of the system can take advantage of the unoptimized system and drain all the gas from the resolver s address, blocking the execution of other fetch requests.  For example, by setting the contract as a target:  // SPDX-License-Identifier: MIT  pragma solidity ^0.8.25;  contract TargetMock {  mapping(uint256 => bytes) contentHash; // Slot 0  constructor() {  contentHash[0] = \"\";  contentHash[1] = \"\";  // for e.x. the value with the length of 960 bytes will result in at least 2400 `for` loops  contentHash[2] = \"0xe3010170122029f2...e22a892c7e3f1f\"; // <-- value of the unlimited length  And calling the resolve function of the L1Resolver contract with the contentHash selector will execute the _contentHash function, request the value, and after the resolver processes the value, the while loop will consume an unlimited amount of gas based on the variable s length. Repeated calls to this value will drain all the native tokens from the resolver s address for gas fees.  Examples  packages/l1-contracts/contracts/L1Resolver.sol:L258-L270  function _contenthash(  bytes32 node,  address target  ) private view returns (bytes memory) {  EVMFetcher  .newFetchRequest(verifier, target)  .getStatic(RECORD_VERSIONS_SLOT)  .element(node)  .getDynamic(VERSIONABLE_HASHES_SLOT)  .ref(0)  .element(node)  .fetch(this.contenthashCallback.selector, \"\");  packages/l1-contracts/contracts/linea-verifier/LineaProofHelper.sol:L102-L130  while (length > 0) {  verifyStorageProof(  account,  storageProofs[proofIdx].leafIndex,  storageProofs[proofIdx].proof.proofRelatedNodes,  storageProofs[proofIdx].proof.value,  bytes32(slot)  );  slot++;  if (length < 32) {  value = bytes.concat(  value,  sliceBytes(  abi.encode(storageProofs[proofIdx++].proof.value),  0,  length  );  length = 0;  } else {  value = bytes.concat(  value,  storageProofs[proofIdx++].proof.value  );  length -= 32;  Recommendation  We recommend reviewing the current logic and optimizing it in the while loop, limiting the length of the dynamic values.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.7 Insufficient Input Length Check in hashAccountValue Function    ", "body": "  Resolution                           The problem has been fixed in   PR#179.  Description  In the SparseMerkleProof contract, there is an Account struct:  struct Account {  uint64 nonce; // 8 bytes, but occupies full slot, so 32 bytes  uint256 balance; // 32 bytes  bytes32 storageRoot; // 32 bytes  bytes32 mimcCodeHash; // 32 bytes  bytes32 keccakCodeHash; // 32 bytes  uint64 codeSize; // 8 bytes, but occupies full slot, so 32 bytes  } // = 192 bytes  However, no exception is thrown if the length of _value is more than 192 bytes. Consequently, this excess data gets silently ignored during the abi.decode execution since it takes exactly 192 bytes for decoding and leftover bytes remain untouched. This creates a problem where, for different inputs, the result is the same. For example:  // Input data with 192 bytes:  0x000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000d2a66d5598b4fc5482c311f22d2dc657579b5452ab4b3e60fb1a9e9dbbfc99e00c24dd0468f02fbece668291f3c3eb20e06d1baec856f28430555967f2bf280d798c662debc23e8199fbf0b0a3a95649f2defe90af458d7f62c03881f916b3f0000000000000000000000000000000000000000000000000000000000003030  // Output:  tuple(uint64,uint256,bytes32,bytes32,bytes32,uint64): 1,0,0x0d2a66d5598b4fc5482c311f22d2dc657579b5452ab4b3e60fb1a9e9dbbfc99e,0x00c24dd0468f02fbece668291f3c3eb20e06d1baec856f28430555967f2bf280,0xd798c662debc23e8199fbf0b0a3a95649f2defe90af458d7f62c03881f916b3f,12336  // Input data with more than 192 bytes:  0x000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000d2a66d5598b4fc5482c311f22d2dc657579b5452ab4b3e60fb1a9e9dbbfc99e00c24dd0468f02fbece668291f3c3eb20e06d1baec856f28430555967f2bf280d798c662debc23e8199fbf0b0a3a95649f2defe90af458d7f62c03881f916b3f000000000000000000000000000000000000000000000000000000000000303000122313  // Output is the same:  tuple(uint64,uint256,bytes32,bytes32,bytes32,uint64): 1,0,0x0d2a66d5598b4fc5482c311f22d2dc657579b5452ab4b3e60fb1a9e9dbbfc99e,0x00c24dd0468f02fbece668291f3c3eb20e06d1baec856f28430555967f2bf280,0xd798c662debc23e8199fbf0b0a3a95649f2defe90af458d7f62c03881f916b3f,12336  Examples  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L9-L16  struct Account {  uint64 nonce;  uint256 balance;  bytes32 storageRoot;  bytes32 mimcCodeHash;  bytes32 keccakCodeHash;  uint64 codeSize;  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L133-L140  function _parseAccount(  bytes calldata _value  ) private pure returns (Account memory) {  if (_value.length < 192) {  revert WrongBytesLength(192, _value.length);  return abi.decode(_value, (Account));  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L85-L102  function hashAccountValue(  bytes calldata _value  ) external pure returns (bytes32) {  Account memory account = _parseAccount(_value);  (bytes32 msb, bytes32 lsb) = _splitBytes32(account.keccakCodeHash);  return  Mimc.hash(  abi.encode(  account.nonce,  account.balance,  account.storageRoot,  account.mimcCodeHash,  lsb,  msb,  account.codeSize  );  Recommendation  We recommend reviewing existing logic and adding a condition to validate that the length of _value is exactly 192 bytes.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.8 Proof Can Be Verified Using Unexisting leafIndex    ", "body": "  Description  Examples  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L224-L243  function _verify(  bytes32[] memory _proof,  bytes32 _leafHash,  uint256 _leafIndex,  bytes32 _root,  bytes32 _nextFreeNode  ) private pure returns (bool) {  bytes32 computedHash = _leafHash;  uint256 currentIndex = _leafIndex;  for (uint256 height; height < TREE_DEPTH; ++height) {  if ((currentIndex >> height) & 1 == 1)  computedHash = Mimc.hash(  abi.encodePacked(_proof[height], computedHash)  );  else  computedHash = Mimc.hash(  abi.encodePacked(computedHash, _proof[height])  );  Recommendation  We recommend reviewing existing logic and adding validation to the leafIndex variable to ensure that the variable does not exceed the tree height.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.9 _isZeroBytes Returns Different Output for the Same Input Variable in SparseMerkleProof Contract    ", "body": "  Resolution                           The problem has been fixed in the   PR#179.  Description  Examples  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L194-L214  function _isZeroBytes(  bytes calldata _data  ) private pure returns (bool isZeroBytes) {  isZeroBytes = true;  assembly {  let dataStart := _data.offset  for {  let currentPtr := dataStart  } lt(currentPtr, add(dataStart, _data.length)) {  currentPtr := add(currentPtr, 0x20)  } {  let dataWord := calldataload(currentPtr)  if eq(iszero(dataWord), 0) {  isZeroBytes := 0  break  Consider the following PoC:  contract ReadExtraCalldata {  function _isZeroBytes(  bytes calldata _data  ) public pure returns (bool isZeroBytes) {  isZeroBytes = true;  assembly {  let dataStart := _data.offset  for {  let currentPtr := dataStart  } lt(currentPtr, add(dataStart, _data.length)) {  currentPtr := add(currentPtr, 0x20) // <-- takes full chunk of data for each iteration  } {  let dataWord := calldataload(currentPtr)  if eq(iszero(dataWord), 0) {  isZeroBytes := 0  break  function foo() public view returns (bool clean, bool dirty) {  // form `data` variable, it consists of empty bytes, can be divided into two parts: 32 + 10  bytes memory _data = new bytes(42);  bytes memory _calldata = abi.encodeWithSelector(this._isZeroBytes.selector, _data);  bool success;  bytes memory result;  // call the function with the clean calldata  (success, result) = address(this).staticcall(_calldata);  require(success);  clean = abi.decode(result, (bool)); // <-- we receive true  // Form dirty calldata. Note that _calldata is 132 bytes long:  // 4 bytes: selector,  // 32 bytes: offset,  // 32 bytes: length,  // 32 bytes: first byte of _data,  // 32 bytes: padded second byte of _data.  // We change the last bit of the padding:  _calldata[131] = 0x01; // <-- this dirty byte is not a part of the _data variable, but a part of the calldata  (success, result) = address(this).staticcall(_calldata);  require(success);  dirty = abi.decode(result, (bool)); // <-- we receive false, however in each example _data is empty bytes  Recommendation  We recommend adjusting the assembly code to properly handle cases where _data.length does not align with 32-byte word boundaries. Specifically, the function should ensure that its _data.length is a multiple of 32, without inadvertently loading additional bytes beyond this limit.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.10 Missing Length Validation of the First Element in _formatProof Function of SparseMerkleProof Contract    ", "body": "  Resolution                           The problem has been fixed in the   PR#179.  Description  Examples  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L162-L169  function _formatProof(  bytes[] calldata _rawProof  ) private pure returns (bytes32, bytes32, bytes32[] memory) {  uint256 rawProofLength = _rawProof.length;  uint256 formattedProofLength = rawProofLength - 2;  bytes32[] memory proof = new bytes32[](formattedProofLength);  bytes32 nextFreeNode = bytes32(_rawProof[0][:32]);  Recommendation  We recommend validating that the length of _rawProof[0] is at least 32 bytes before proceeding with the extraction of the first 32 bytes.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.11 Validation Missing in Constructors    ", "body": "  Resolution                           The problem has been fixed in the   PR#164 . However in the NameWrapper contract there is a  Description  Examples  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L130-L148  ) ReverseClaimer(_ens, msg.sender) {  if (_maxCommitmentAge <= _minCommitmentAge) {  revert MaxCommitmentAgeTooLow();  if (_maxCommitmentAge > block.timestamp) {  revert MaxCommitmentAgeTooHigh();  base = _base;  prices = _prices;  minCommitmentAge = _minCommitmentAge;  maxCommitmentAge = _maxCommitmentAge;  reverseRegistrar = _reverseRegistrar;  nameWrapper = _nameWrapper;  pohVerifier = _pohVerifier;  pohRegistrationManager = _pohRegistrationManager;  baseNode = _baseNode;  baseDomain = _baseDomain;  packages/l2-contracts/contracts/wrapper/NameWrapper.sol:L77-L101  baseNode = _baseNode;  /* Burn PARENT_CANNOT_CONTROL and CANNOT_UNWRAP fuses for ROOT_NODE, ETH_NODE and baseNode and set expiry to max */  _setData(  uint256(_baseNode),  address(0),  uint32(PARENT_CANNOT_CONTROL | CANNOT_UNWRAP),  MAX_EXPIRY  );  _setData(  uint256(ETH_NODE),  address(0),  uint32(PARENT_CANNOT_CONTROL | CANNOT_UNWRAP),  MAX_EXPIRY  );  _setData(  uint256(ROOT_NODE),  address(0),  uint32(PARENT_CANNOT_CONTROL | CANNOT_UNWRAP),  MAX_EXPIRY  );  names[ROOT_NODE] = \"\\x00\";  names[ETH_NODE] = \"\\x03eth\\x00\";  names[_baseNode] = _baseNodeDnsEncoded;  Recommendation  Add missing validations in the constructor of NameWrapper and ETHRegistrarController contract.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.12 Missing Validation for Matching Number of Storage Proofs and Commands    ", "body": "  Resolution                           The problem has been fixed in the   PR#165.  Description  In the function getStorageValues of the LineaProofHelper library, if the number of storage proofs (storageProofs) returned by the gateway is less than number of commands (commands.length), there will be an out-of-bounds array error. This situation arises when the gateway provides fewer storage proofs than the requested storage slots leading to a failure in getStorageValues.  Examples  packages/l1-contracts/contracts/linea-verifier/LineaProofHelper.sol:L232-L260  for (uint256 i = 0; i < commands.length; i++) {  bytes32 command = commands[i];  (bool isDynamic, uint256 slot) = computeFirstSlot(  command,  constants,  values  );  if (!isDynamic) {  if (!storageProofs[proofIdx].initialized) {  values[i] = abi.encode(0);  proofIdx++;  } else {  verifyStorageProof(  account,  storageProofs[proofIdx].leafIndex,  storageProofs[proofIdx].proof.proofRelatedNodes,  storageProofs[proofIdx].proof.value,  bytes32(slot)  );  values[i] = abi.encode(  storageProofs[proofIdx++].proof.value  );  if (values[i].length > 32) {  revert InvalidSlotSize(values[i].length);  } else {  Recommendation  Add a require statement to check whether the number of storage proofs is equal to the number of commands  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.13 No Validation of Raw Merkle Proof Length    ", "body": "  Resolution                           The problem has been fixed in the   PR#179.  Description  In the function verifyProof of the SparseMerkleProof contract, the length of the raw Merkel proof(_rawProof) should be same as the Merkel tree depth (TREE_DEPTH 42). However, there is no check of the length. If the length is less than 42, the function _verify would fail on an out of bounds of array access error:  for (uint256 height; height < TREE_DEPTH; ++height) {  if ((currentIndex >> height) & 1 == 1)  computedHash = Mimc.hash(abi.encodePacked(_proof[height], computedHash)  );  Examples  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L36-L47  function verifyProof(  bytes[] calldata _rawProof,  uint256 _leafIndex,  bytes32 _root  ) external pure returns (bool) {  bytes32 nextFreeNode,  bytes32 leafHash,  bytes32[] memory proof  ) = _formatProof(_rawProof);  return _verify(proof, leafHash, _leafIndex, _root, nextFreeNode);  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L234-L243  for (uint256 height; height < TREE_DEPTH; ++height) {  if ((currentIndex >> height) & 1 == 1)  computedHash = Mimc.hash(  abi.encodePacked(_proof[height], computedHash)  );  else  computedHash = Mimc.hash(  abi.encodePacked(computedHash, _proof[height])  );  Recommendation  Add a require statement to verify that the length of _rawProof is 42 in the verifyProof function.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.14 Missing Zero Value Validation in MIMC Library Leading to Out-of-Gas Error    ", "body": "  Description  assembly {  let chunks := div(add(_msg.length, 0x1f), 0x20)  for {  let i := 0  } lt(i, sub(chunks, 1)) {  i := add(i, 1)  } {  For better understanding, this part of the code can be represented in Solidity like:  uint chunks = (_msg.length + 31) / 32;  unchecked {  for (uint i; i < chunks - 1; ++i)  ...  Recommendation  We recommend validating the length of the input calldata.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.15 Unsafe Usage of abi.encodeWithSelector   ", "body": "  Resolution                           The problem hasn t been fixed with the comments:  We have to use   Description  Examples  packages/l1-contracts/contracts/linea-verifier/EVMFetchTarget.sol:L42-L44  bytes memory ret = address(this).functionCall(  abi.encodeWithSelector(callback, values, callbackData)  );  packages/l1-contracts/contracts/linea-verifier/EVMFetchTarget.sol:L42-L44  bytes memory ret = address(this).functionCall(  abi.encodeWithSelector(callback, values, callbackData)  );  Recommendation  We recommend using abi.encodeCall instead of abi.encodeWithSelector to adhere to best practices in the web3 sphere.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.16 Redundant return in EVMFetchTarget    ", "body": "  Resolution                           The problem has been fixed in   PR#166.  Description  Examples  packages/l1-contracts/contracts/linea-verifier/EVMFetchTarget.sol:L19-L48  function getStorageSlotsCallback(  bytes calldata response,  bytes calldata extradata  ) external {  bytes memory proof = abi.decode(response, (bytes));  IEVMVerifier verifier,  bytes32[] memory commands,  bytes[] memory constants,  bytes4 callback,  bytes memory callbackData  ) = abi.decode(  extradata,  (IEVMVerifier, bytes32[], bytes[], bytes4, bytes)  );  bytes[] memory values = verifier.getStorageValues(  commands,  constants,  proof  );  if (values.length != commands.length) {  revert ResponseLengthMismatch(values.length, commands.length);  bytes memory ret = address(this).functionCall(  abi.encodeWithSelector(callback, values, callbackData)  );  assembly {  return(add(ret, 32), mload(ret))  Recommendation  We recommend either removing the assembly block to save execution gas costs and keep the codebase clean or adding a modifier to the getStorageSlotsCallback function to return the ret variable to make the assembly work.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.17 Empty require() Statements   Partially Addressed", "body": "  Resolution                           The problem has been partially addressed in   PR#167.  Description  In the L1Resolver contract and in the PohRegistrationManager contract, there are empty require() statements without providing reason strings or custom errors in Solidity. Using reason strings or custom errors in require() statements helps in debugging and understanding why a transaction was reverted, thereby improving the overall readability and maintainability of the code.  Examples  packages/l1-contracts/contracts/L1Resolver.sol:L102  require(isAuthorised(node));  packages/l2-contracts/contracts/ethregistrar/PohRegistrationManager.sol:L14  require(managers[msg.sender]);  Recommendation  We recommend adding a descriptive reason string or using a custom error for the require() statement to provide more context when a transaction fails.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.18 Use Ownable2Step in PohRegistrationManager    ", "body": "  Resolution                           The problem has been fixed in the   PR#168.  Description  In the PohRegistrationManager contract, the Ownable contract is used for access verification. However, the Ownable contract lacks protection for cases when there is a transfer of ownership to an incorrect account or to contracts that are unable to interact with the permission system. To eliminate such risks, we recommend utilizing the Ownable2Step contract, which includes a two-step mechanism to transfer ownership, where the new owner must call acceptOwnership in order to replace the old one.  Examples  packages/l2-contracts/contracts/ethregistrar/PohRegistrationManager.sol:L3  import {Ownable} from \"@openzeppelin/contracts/access/Ownable.sol\";  Recommendation  We recommend using Ownable2Step instead of Ownable.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.19 Missing Event in the Constructor in PohVerifier    ", "body": "  Resolution                           The problem has been fixed in the   PR#169.  Description  Examples  packages/l2-contracts/contracts/ethregistrar/PohVerifier.sol:L24-L27  constructor() EIP712(SIGNING_DOMAIN, SIGNATURE_VERSION) Ownable() {  signer = msg.sender;  Recommendation  We recommend adding the SignerUpdated event to the constructor.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.20 Unused Imports    ", "body": "  Resolution                           The problem has been fixed in the   PR#170 with the comment:  Keeping NameEncoder since it s used in fix 4.11 .  Description  In the following locations, there are unused imports:  In ETHRegistrarController.sol#L17, the NameEncoder import is unused.  In NameWrapper.sol#L4, the IERC165 import is unused.  In NameWrapper.sol#L6, the CAN_DO_EVERYTHING import is unused.  In NameWrapper.sol#L10, the IReverseRegistrar import is unused.  In NameWrapper.sol#L14, the IERC1155 import is unused.  Examples  packages/l2-contracts/contracts/wrapper/NameWrapper.sol:L4  import {ERC1155Fuse, IERC165, IERC1155MetadataURI} from \"./ERC1155Fuse.sol\";  packages/l2-contracts/contracts/wrapper/NameWrapper.sol:L6  import {INameWrapper, CANNOT_UNWRAP, CANNOT_BURN_FUSES, CANNOT_TRANSFER, CANNOT_SET_RESOLVER, CANNOT_SET_TTL, CANNOT_CREATE_SUBDOMAIN, CANNOT_APPROVE, PARENT_CANNOT_CONTROL, CAN_DO_EVERYTHING, IS_DOT_ETH, CAN_EXTEND_EXPIRY, PARENT_CONTROLLED_FUSES, USER_SETTABLE_FUSES} from \"./INameWrapper.sol\";  packages/l2-contracts/contracts/wrapper/NameWrapper.sol:L10  import {IReverseRegistrar} from \"../reverseRegistrar/IReverseRegistrar.sol\";  packages/l2-contracts/contracts/wrapper/NameWrapper.sol:L14  import \"@openzeppelin/contracts/token/ERC1155/IERC1155.sol\";  Recommendation  We recommend removing unused imports to keep the codebase clean.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.21 Unused Custom Errors    ", "body": "  Resolution                           The problem has been fixed in   PR#171.  Description  In the LineaProofHelper contract and in the ETHRegistrarController contract, the AccountNotFound and Unauthorised custom errors are not used.  Examples  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L29  error Unauthorised(bytes32 node);  packages/l1-contracts/contracts/linea-verifier/LineaProofHelper.sol:L35  error AccountNotFound(address);  Recommendation  We recommend reviewing the use of these custom errors and removing them if they are not needed.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.22 verifyProof Doesn t Verify Anything in SparseMerkleProof Contract    ", "body": "  Resolution                           The problem has been fixed by specifying documentation in   PR 179,  PR 172.  Description  In the verifyAccountProof and verifyStorageProof functions, there are two separate require validations, which could be done in one require statement, making the code cleaner and saving deployment gas costs.  This also relates to the verify function of the PohVerifier contract.  Examples  packages/l2-contracts/contracts/ethregistrar/PohVerifier.sol:L39-L55  /**  @notice Verify the signature sent in parameter  @dev human is supposed to be a POH address, this is what is being signed by the POH API  @param signature The signature to verify  @param human the address for which the signature has been crafted  /  function verify(  bytes memory signature,  address human  ) public view virtual returns (bool) {  bytes32 digest = _hashTypedDataV4(  keccak256(abi.encode(keccak256(\"POH(address to)\"), human))  );  address recoveredSigner = ECDSA.recover(digest, signature);  return recoveredSigner == signer;  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L30-L47  /**  @notice Format input and verify sparse merkle proof  @param _rawProof Raw sparse merkle tree proof  @param _leafIndex Index of the leaf  @param _root Sparse merkle root  /  function verifyProof(  bytes[] calldata _rawProof,  uint256 _leafIndex,  bytes32 _root  ) external pure returns (bool) {  bytes32 nextFreeNode,  bytes32 leafHash,  bytes32[] memory proof  ) = _formatProof(_rawProof);  return _verify(proof, leafHash, _leafIndex, _root, nextFreeNode);  packages/l1-contracts/contracts/linea-verifier/lib/SparseMerkleProof.sol:L216-L247  /**  @notice Verify sparse merkle proof  @param _proof Sparse merkle tree proof  @param _leafHash Leaf hash  @param _leafIndex Index of the leaf  @param _root Sparse merkle root  @param _nextFreeNode Next free node  /  function _verify(  bytes32[] memory _proof,  bytes32 _leafHash,  uint256 _leafIndex,  bytes32 _root,  bytes32 _nextFreeNode  ) private pure returns (bool) {  bytes32 computedHash = _leafHash;  uint256 currentIndex = _leafIndex;  for (uint256 height; height < TREE_DEPTH; ++height) {  if ((currentIndex >> height) & 1 == 1)  computedHash = Mimc.hash(  abi.encodePacked(_proof[height], computedHash)  );  else  computedHash = Mimc.hash(  abi.encodePacked(computedHash, _proof[height])  );  return  Mimc.hash(abi.encodePacked(_nextFreeNode, computedHash)) == _root;  packages/l1-contracts/contracts/linea-verifier/LineaProofHelper.sol:L185-L201  function verifyStorageProof(  SparseMerkleProof.Account memory account,  uint256 leafIndex,  bytes[] memory proof,  bytes32 value,  bytes32 key  ) private pure {  bool storageProofVerified = SparseMerkleProof.verifyProof(  proof,  leafIndex,  account.storageRoot  );  require(  storageProofVerified,  \"LineaResolverStub: invalid storage proof\"  );  packages/l1-contracts/contracts/linea-verifier/LineaProofHelper.sol:L154-L167  function verifyAccountProof(  AccountProofStruct memory accountProof,  bytes32 stateRoot  ) private pure returns (bool) {  bool accountProofVerified = SparseMerkleProof.verifyProof(  accountProof.proof.proofRelatedNodes,  accountProof.leafIndex,  stateRoot  );  require(  accountProofVerified,  \"LineaResolverStub: invalid account proof\"  );  Recommendation  We recommend adding the validations inside the verifyProof function to improve clarity and readability of the code, as well as decrease deployment gas costs.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.23 Redundant decode Operation in EVMFetchTarget Contract   ", "body": "  Resolution  The problem won t be fixed, the client stated:  This triggers an error if we use the response bytes without decoding it to bytes first, this is due to the fact that there is some padding in the response bytes.   Description  Examples  packages/l1-contracts/contracts/linea-verifier/EVMFetchTarget.sol:L19-L23  function getStorageSlotsCallback(  bytes calldata response,  bytes calldata extradata  ) external {  bytes memory proof = abi.decode(response, (bytes));  Recommendation  We recommend removing the decoding of the response variable into bytes to make the code cleaner and save execution gas costs. The decoding step is not necessary unless decoding response into a different form other than bytes.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.24 public Functions Not Used Internally Could Be Marked external    ", "body": "  Resolution                           The problem has been fixed in the   PR#173.  Description  In the mentioned locations, public functions are used within the smart contracts, but these functions do not appear to be called internally. Functions declared as public can be called both externally and internally, which can result in larger deployment gas costs and a bigger size of the contract.  Examples  packages/l1-contracts/contracts/L1Resolver.sol:L100  function setTarget(bytes calldata name, address target) public {  packages/l1-contracts/contracts/L1Resolver.sol:L205  function addrCallback(  packages/l1-contracts/contracts/L1Resolver.sol:L228  function addrCoinTypeCallback(  packages/l1-contracts/contracts/L1Resolver.sol:L251  function textCallback(  packages/l1-contracts/contracts/L1Resolver.sol:L272  function contenthashCallback(  packages/l1-contracts/contracts/L1Resolver.sol:L285  function metadata(bytes calldata name) public view returns (string memory) {  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L197  function commit(bytes32 commitment) public override {  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L216  function registerPoh(  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L286  function register(  packages/l2-contracts/contracts/ethregistrar/ETHRegistrarController.sol:L444  function withdraw() public {  packages/l2-contracts/contracts/ethregistrar/PohRegistrationManager.sol:L31  function isRegistered(address _address) public view returns (bool) {  packages/l2-contracts/contracts/ethregistrar/PohVerifier.sol:L33  function setSigner(address _signer) public onlyOwner {  packages/l2-contracts/contracts/ethregistrar/PohVerifier.sol:L45  function verify(  packages/l2-contracts/contracts/ethregistrar/PohVerifier.sol:L60  function getSigner() public view returns (address) {  Recommendation  We recommend revising the modifier of these functions from public to external to optimize the smart contract gas usage and keep the codebase clean, as these functions are not needed internally.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.25 Magic Number Usage    ", "body": "  Resolution                           The problem has been fixed in the   PR#162.  Description  Examples  packages/l1-contracts/contracts/linea-verifier/LineaProofHelper.sol:L154-L182  function verifyAccountProof(  AccountProofStruct memory accountProof,  bytes32 stateRoot  ) private pure returns (bool) {  bool accountProofVerified = SparseMerkleProof.verifyProof(  accountProof.proof.proofRelatedNodes,  accountProof.leafIndex,  stateRoot  );  require(  accountProofVerified,  \"LineaResolverStub: invalid account proof\"  );  bytes32 hAccountValue = SparseMerkleProof.hashAccountValue(  accountProof.proof.value  );  SparseMerkleProof.Leaf memory accountLeaf = SparseMerkleProof.getLeaf(  accountProof.proof.proofRelatedNodes[41]  );  require(  accountLeaf.hValue == hAccountValue,  \"LineaResolverStub: account value invalid\"  );  return true;  Recommendation  We recommend avoiding magic numbers in the code, removing the 41 value, and using the LAST_LEAF_INDEX constant variable with a value of 41 to keep the codebase clean.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.26 Make Variables immutable to Save Gas    ", "body": "  Resolution                           The problem has been fixed in the   PR#174 with the comment:  graphqUrl variable can not be marked as immutable since it s a string variable .  Description  Examples  packages/l1-contracts/contracts/L1Resolver.sol:L40-L41  string public graphqlUrl;  uint256 public l2ChainId;  Recommendation  We recommend making these variables immutable.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.27 Lack of Error Handling for Unresolved Queries in resolve of L1Resolver Contract    ", "body": "  Resolution                           The problem has been fixed in the   PR#177.  Description  The resolve function in the L1Resolver contract is missing error handling for cases where the input data does not match any recognized selector. This function attempts to decode and process various types of requests based on the selector derived from the provided data. However, if none of the conditionals for known selectors match, the function will be executed without handling the case or notifying the caller that the provided data could not be resolved, and the execution of such a transaction will be successful, misleading the caller.  Examples  packages/l1-contracts/contracts/L1Resolver.sol:L145-L174  function resolve(  bytes calldata name,  bytes calldata data  ) external view returns (bytes memory result) {  (, address target) = _getTarget(name, 0);  bytes4 selector = bytes4(data);  if (selector == IAddrResolver.addr.selector) {  bytes32 node = abi.decode(data[4:], (bytes32));  return _addr(node, target);  if (selector == IAddressResolver.addr.selector) {  (bytes32 node, uint256 cointype) = abi.decode(  data[4:],  (bytes32, uint256)  );  return _addr(node, cointype, target);  if (selector == ITextResolver.text.selector) {  (bytes32 node, string memory key) = abi.decode(  data[4:],  (bytes32, string)  );  return bytes(_text(node, key, target));  if (selector == IContentHashResolver.contenthash.selector) {  bytes32 node = abi.decode(data[4:], (bytes32));  return _contenthash(node, target);  Recommendation  We recommend adding a revert statement when the input data s selector does not match any known patterns. This approach ensures that users are informed when their queries cannot be processed, thus enhancing the robustness and usability of the contract.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.28 Typos in the Code    ", "body": "  Resolution                           The problem has been fixed in the   PR#175.  Description  In the following locations, there are typos:  nearlest instead of nearest  aagainst instead of against  Examples  packages/l1-contracts/contracts/L1Resolver.sol:L96  packages/l1-contracts/contracts/L1Resolver.sol:L140  Set target address to verify aagainst  packages/l1-contracts/contracts/L1Resolver.sol:L140  Recommendation  @dev Resolve and verify a record stored in l2 target address. It supports subname by fetching target recursively to the nearlest parent.  Recommendation  We recommend fixing typos to keep the codebase clean.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "4.29 Insufficient data Validation in resolve Function of L1Resolver Contract    ", "body": "  Resolution                           The problem has been fixed in the   PR#176.  Description  Examples  packages/l1-contracts/contracts/L1Resolver.sol:L145-L154  function resolve(  bytes calldata name,  bytes calldata data  ) external view returns (bytes memory result) {  (, address target) = _getTarget(name, 0);  bytes4 selector = bytes4(data);  if (selector == IAddrResolver.addr.selector) {  bytes32 node = abi.decode(data[4:], (bytes32));  return _addr(node, target);  Recommendation  We recommend adding a validation at the beginning of the resolve function to verify that the data parameter is longer than 4 bytes.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2024/06/linea-ens/"}, {"title": "6.1 Potentially dangerous use of a cached exchange rate from Compound ", "body": "  Description  GPortfolioReserveManager.adjustReserve performs reserve adjustment calculations based on Compound s cached exchange rate values (using CompoundLendingMarketAbstraction.getExchangeRate()) then triggers operations on managed tokens based on up-to-date values (using CompoundLendingMarketAbstraction.fetchExchangeRate()) . Significant deviation between the cached and up-to-date values may make it difficult to predict the outcome of reserve adjustments.  Recommendation  Use getExchangeRate() consistently, or ensure fetchExchangeRate() is used first, and getExchangeRate() afterward.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/12/growth-defi-v1/"}, {"title": "6.2 Potential resource exhaustion by external calls performed within an unbounded loop ", "body": "  Description  DydxFlashLoanAbstraction._requestFlashLoan performs external calls in a potentially-unbounded loop. Depending on changes made to DyDx s SoloMargin, this may render this flash loan provider prohibitively expensive. In the worst case, changes to SoloMargin could make it impossible to execute this code due to the block gas limit.  code/contracts/modules/DydxFlashLoanAbstraction.sol:L62-L69  uint256 _numMarkets = SoloMargin(_solo).getNumMarkets();  for (uint256 _i = 0; _i < _numMarkets; _i++) {  address _address = SoloMargin(_solo).getMarketTokenAddress(_i);  if (_address == _token) {  _marketId = _i;  break;  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/12/growth-defi-v1/"}, {"title": "6.1 Exchange - CancelOrder has no effect   Pending", "body": "  Resolution  This issue has been addressed with mai-protocol-v2/2fcbf4b44f4595e5879ff5efea4e42c529ef0ce1 by verifying that an order has not been cancelled in method validateOrderParam.  cancelOrder still does not verify the order signature.  Description  The exchange provides means for the trader or broker to cancel the order. The cancelOrder method, however, only stores the hash of the canceled order in mapping but the mapping is never checked. It is therefore effectively impossible for a trader to cancel an order.  Examples  code/contracts/exchange/Exchange.sol:L179-L187  function cancelOrder(LibOrder.Order memory order) public {  require(msg.sender == order.trader || msg.sender == order.broker, \"invalid caller\");  bytes32 orderHash = order.getOrderHash();  cancelled[orderHash] = true;  emit Cancel(orderHash);  Recommendation  matchOrders* or validateOrderParam should check if cancelled[orderHash] == true and abort fulfilling the order.  Verify the order params (Signature) before accepting it as canceled.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.2 AMM - funding can be called in emergency mode   Pending", "body": "  Resolution                           This issue was addressed by silently skipping   Description  specification for  Recommendation  According to the specification, forceFunding should not be allowed in EMERGENCY mode. However, it is assumed that this method should only be callable in NORMAL mode.  The assessment team would like to note that the specification appears to be inconsistent and dated (method names, variable names, \u2026).  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.3 Perpetual - withdraw should only be available in NORMAL state   Pending", "body": "  Resolution                           This issue was resolved by requiring   Description  According to the specification withdraw can only be called in NORMAL state. However, the implementation allows it to be called in NORMAL and SETTLED mode.  Examples  Withdraw only checks for !SETTLING state which resolves to NORMAL and SETTLED.  code/contracts/perpetual/Perpetual.sol:L175-L178  function withdraw(uint256 amount) public {  withdrawFromAccount(msg.sender, amount);  code/contracts/perpetual/Perpetual.sol:L156-L169  function withdrawFromAccount(address payable guy, uint256 amount) private {  require(guy != address(0), \"invalid guy\");  require(status != LibTypes.Status.SETTLING, \"wrong perpetual status\");  uint256 currentMarkPrice = markPrice();  require(isSafeWithPrice(guy, currentMarkPrice), \"unsafe before withdraw\");  remargin(guy, currentMarkPrice);  address broker = currentBroker(guy);  bool forced = broker == address(amm.perpetualProxy()) || broker == address(0);  withdraw(guy, amount, forced);  require(isSafeWithPrice(guy, currentMarkPrice), \"unsafe after withdraw\");  require(availableMarginWithPrice(guy, currentMarkPrice) >= 0, \"withdraw margin\");  In contrast, withdrawFor requires the state to be NORMAL:  code/contracts/perpetual/Perpetual.sol:L171-L174  function withdrawFor(address payable guy, uint256 amount) public onlyWhitelisted {  require(status == LibTypes.Status.NORMAL, \"wrong perpetual status\");  withdrawFromAccount(guy, amount);  Recommendation  withdraw should only be available in the NORMAL operation mode.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.4 Perpetual - withdrawFromInsuranceFund should check wadAmount instead of rawAmount   Pending", "body": "  Resolution                           This issue was addressed by checking   Description  withdrawFromInsurance checks that enough funds are in the insurance fund before allowing withdrawal by an admin by checking the provided rawAmount <= insuranceFundBalance.toUint256(). rawAmount is the ETH (18 digit precision) or collateral token amount (can be less than 18 digit precision) to be withdrawn while insuranceFundBalance is a WAD-denominated value (18 digit precision).  The check does not hold if the configured collateral has different precision and may have unwanted consequences, e.g. the withdrawal of more funds than expected.  Note: there is another check for insuranceFundBalance staying positive after the potential external call to collateral.  Examples  code/contracts/perpetual/Perpetual.sol:L204-L216  function withdrawFromInsuranceFund(uint256 rawAmount) public onlyWhitelistAdmin {  require(rawAmount > 0, \"invalid amount\");  require(insuranceFundBalance > 0, \"insufficient funds\");  require(rawAmount <= insuranceFundBalance.toUint256(), \"insufficient funds\");  int256 wadAmount = toWad(rawAmount);  insuranceFundBalance = insuranceFundBalance.sub(wadAmount);  withdrawFromProtocol(msg.sender, rawAmount);  require(insuranceFundBalance >= 0, \"negtive insurance fund\");  emit UpdateInsuranceFund(insuranceFundBalance);  When looking at the test-cases there seems to be a misconception about what unit of amount withdrawFromInsuranceFund is taking. For example, the insurance fund withdrawal and deposit are not tested for collateral that specifies a precision that is not 18. The test-cases falsely assume that the input to withdrawFromInsuranceFund is a WAD value, while it is taking the collateral s rawAmount which is then converted to a WAD number.  code/test/test_perpetual.js:L471-L473  await perpetual.withdrawFromInsuranceFund(toWad(10.111));  fund = await perpetual.insuranceFundBalance();  assert.equal(fund.toString(), 0);  Recommendation  Check that require(wadAmount <= insuranceFundBalance.toUint256(), \"insufficient funds\");, add a test-suite testing the insurance fund with collaterals with different precision and update existing tests that properly provide the expected input to withdraFromInsurance.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.5 Perpetual - liquidateFrom should not have public visibility   Pending", "body": "  Resolution                           This issue has been resolved by removing the   Description  Perpetual.liquidate is used to liquidate an account that is  unsafe,  determined by the relative sizes of marginBalanceWithPrice and maintenanceMarginWithPrice:  code/contracts/perpetual/Perpetual.sol:L248-L253  // safe for liquidation  function isSafeWithPrice(address guy, uint256 currentMarkPrice) public returns (bool) {  return  marginBalanceWithPrice(guy, currentMarkPrice) >=  maintenanceMarginWithPrice(guy, currentMarkPrice).toInt256();  Perpetual.liquidate allows the caller to assume the liquidated account s position, as well as a small amount of  penalty collateral.  The steps to liquidate are, roughly:  Close the liquidated account s position  Perform a trade on the liquidated assets with the liquidator acting as counter-party  Grant the liquidator a portion of the liquidated assets as a reward. An additional portion is added to the insurance fund.  Handle any losses  We found several issues in Perpetual.liquidate:  Examples  liquidateFrom has public visibility:  code/contracts/perpetual/Perpetual.sol:L270  function liquidateFrom(address from, address guy, uint256 maxAmount) public returns (uint256, uint256) {  Given that liquidate only calls liquidateFrom after checking the current contract s status, this oversight allows anyone to call liquidateFrom during the SETTLED stage:  code/contracts/perpetual/Perpetual.sol:L291-L294  function liquidate(address guy, uint256 maxAmount) public returns (uint256, uint256) {  require(status != LibTypes.Status.SETTLED, \"wrong perpetual status\");  return liquidateFrom(msg.sender, guy, maxAmount);  Additionally, directly calling liquidateFrom allows anyone to liquidate on behalf of other users, forcing other accounts to assume liquidated positions.  Finally, neither liquidate nor liquidateFrom check that the liquidated account and liquidator are the same. Though the liquidation accounting process is hard to follow, we believe this is unintended and could lead to large errors in internal contract accounting.  Recommendation  Make liquidateFrom an internal function  In liquidate or liquidateFrom, check that msg.sender != guy  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.6 Unpredictable behavior due to front running or general bad timing   Pending", "body": "  Resolution  This issue was addressed by the client providing the following statement:  Not fixed in the perpetual. But later a voting system will take over the administration key. We intent to add a waiting period before voted changes applying.  Description  In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.  Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.  Some instances of this are more important than others, but in general users of the system should have assurances about the behavior of the action they re about to take.  Examples  Updating governance and global configuration parameters are not protected by a time-lock and take effect immediately. This, therefore, creates an opportunity for administrators to front-run users on the exchange by changing parameters for orders. It may also allow an administrator to temporarily lift restrictions for themselves (e.g. withdrawalLockBlockCount).  GlobalConfig  withdrawalLockBlockCount is queried when applying for withdrawal. This value can be set zero enabling allowing immediate withdrawal. brokerLockBlockCount is queried when setting a new broker. This value can e set to zero effectively enabling immediate broker changes.  code/contracts/global/GlobalConfig.sol:L18-L27  function setGlobalParameter(bytes32 key, uint256 value) public onlyWhitelistAdmin {  if (key == \"withdrawalLockBlockCount\") {  withdrawalLockBlockCount = value;  } else if (key == \"brokerLockBlockCount\") {  brokerLockBlockCount = value;  } else {  revert(\"key not exists\");  emit UpdateGlobalParameter(key, value);  PerpetualGovernance  e.g. Admin can front-run specific matchOrder calls and set arbitrary dev fees or curve parameters\u2026  code/contracts/perpetual/PerpetualGovernance.sol:L39-L80  function setGovernanceParameter(bytes32 key, int256 value) public onlyWhitelistAdmin {  if (key == \"initialMarginRate\") {  governance.initialMarginRate = value.toUint256();  require(governance.initialMarginRate > 0, \"require im > 0\");  require(governance.initialMarginRate < 10**18, \"require im < 1\");  require(governance.maintenanceMarginRate < governance.initialMarginRate, \"require mm < im\");  } else if (key == \"maintenanceMarginRate\") {  governance.maintenanceMarginRate = value.toUint256();  require(governance.maintenanceMarginRate > 0, \"require mm > 0\");  require(governance.maintenanceMarginRate < governance.initialMarginRate, \"require mm < im\");  require(governance.liquidationPenaltyRate < governance.maintenanceMarginRate, \"require lpr < mm\");  require(governance.penaltyFundRate < governance.maintenanceMarginRate, \"require pfr < mm\");  } else if (key == \"liquidationPenaltyRate\") {  governance.liquidationPenaltyRate = value.toUint256();  require(governance.liquidationPenaltyRate < governance.maintenanceMarginRate, \"require lpr < mm\");  } else if (key == \"penaltyFundRate\") {  governance.penaltyFundRate = value.toUint256();  require(governance.penaltyFundRate < governance.maintenanceMarginRate, \"require pfr < mm\");  } else if (key == \"takerDevFeeRate\") {  governance.takerDevFeeRate = value;  } else if (key == \"makerDevFeeRate\") {  governance.makerDevFeeRate = value;  } else if (key == \"lotSize\") {  require(  governance.tradingLotSize == 0 || governance.tradingLotSize.mod(value.toUint256()) == 0,  \"require tls % ls == 0\"  );  governance.lotSize = value.toUint256();  } else if (key == \"tradingLotSize\") {  require(governance.lotSize == 0 || value.toUint256().mod(governance.lotSize) == 0, \"require tls % ls == 0\");  governance.tradingLotSize = value.toUint256();  } else if (key == \"longSocialLossPerContracts\") {  require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");  socialLossPerContracts[uint256(LibTypes.Side.LONG)] = value;  } else if (key == \"shortSocialLossPerContracts\") {  require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");  socialLossPerContracts[uint256(LibTypes.Side.SHORT)] = value;  } else {  revert(\"key not exists\");  emit UpdateGovernanceParameter(key, value);  Admin can set devAddress or even update to a new amm and globalConfig  code/contracts/perpetual/PerpetualGovernance.sol:L82-L94  function setGovernanceAddress(bytes32 key, address value) public onlyWhitelistAdmin {  require(value != address(0x0), \"invalid address\");  if (key == \"dev\") {  devAddress = value;  } else if (key == \"amm\") {  amm = IAMM(value);  } else if (key == \"globalConfig\") {  globalConfig = IGlobalConfig(value);  } else {  revert(\"key not exists\");  emit UpdateGovernanceAddress(key, value);  AMMGovernance  code/contracts/liquidity/AMMGovernance.sol:L22-L43  function setGovernanceParameter(bytes32 key, int256 value) public onlyWhitelistAdmin {  if (key == \"poolFeeRate\") {  governance.poolFeeRate = value.toUint256();  } else if (key == \"poolDevFeeRate\") {  governance.poolDevFeeRate = value.toUint256();  } else if (key == \"emaAlpha\") {  require(value > 0, \"alpha should be > 0\");  governance.emaAlpha = value;  emaAlpha2 = 10**18 - governance.emaAlpha;  emaAlpha2Ln = emaAlpha2.wln();  } else if (key == \"updatePremiumPrize\") {  governance.updatePremiumPrize = value.toUint256();  } else if (key == \"markPremiumLimit\") {  governance.markPremiumLimit = value;  } else if (key == \"fundingDampener\") {  governance.fundingDampener = value;  } else {  revert(\"key not exists\");  emit UpdateGovernanceParameter(key, value);  Recommendation  The underlying issue is that users of the system can t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.  We recommend giving the user advance notice of changes with a time lock. For example, make all updates to system parameters or upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.  Additionally, users should verify the whitelist setup before using the contract system and monitor it for new additions to the whitelist. Documentation should clearly outline what roles are owned by whom to support suitability. Sane parameter bounds should be enforced (e.g. min. disallow block delay of zero )  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.7 AMM - Governance is able to set an invalid alpha value   Pending", "body": "  Resolution                           This issue was addressed by checking that the provided   Description  According to https://en.wikipedia.org/wiki/Moving_average  The coefficient \u03b1 represents the degree of weighting decrease, a constant smoothing factor between 0 and 1. A higher \u03b1 discounts older observations faster.  However, the code does not check upper bounds. An admin may, therefore, set an invalid alpha that puts emaAlpha2 out of bounds or negative.  Examples  code/contracts/liquidity/AMMGovernance.sol:L27-L31  } else if (key == \"emaAlpha\") {  require(value > 0, \"alpha should be > 0\");  governance.emaAlpha = value;  emaAlpha2 = 10**18 - governance.emaAlpha;  emaAlpha2Ln = emaAlpha2.wln();  Recommendation  Ensure that the system configuration is always within safe bounds. Document expected system variable types and their safe operating ranges. Enforce that bounds are checked every time a value is set. Enforce safe defaults when deploying contracts.  Ensure emaAlpha is 0 < value < 1 WAD  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.8 AMM - Amount of collateral spent or shares received may be unpredictable for liquidity provider   ", "body": "  Resolution  The client acknowledges this issue without providing further information or implementing the recommended fixes.  Description  When providing liquidity with addLiquidity(), the amount of collateral required is based on the current price and the amount of shares received depends on the total amount of shares in circulation. This price can fluctuate at a moment s notice, making the behavior of the function unpredictable for the user.  The same is true when removing liquidity via removeLiquidity().  Recommendation  Unpredictability can be introduced by someone front-running the transaction, or simply by poor timing. For example, adjustments to global variable configuration by the system admin will directly impact subsequent actions by the user. In order to ensure users know what to expect:  Allow the caller to specify a price limit or maximum amount of collateral to be spent  Allow the caller to specify the minimum amount of shares expected to be received  ", "labels": ["Consensys", "Medium", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.9 Exchange - insufficient input validation in matchOrders   Pending", "body": "  Resolution                           This issue was addressed by following the recommendation to verify that   Description  Additionally, the method allows the sender to provide no makerOrderParams at all, resulting in no state changes.  matchOrders also does not reject trades with an amount set to zero. Such orders should be rejected because they do not comply with the minimum tradingLotSize configured for the system. As a side-effect, events may be emitted for zero-amount trades and unexpected state changes may occur.  Examples  code/contracts/exchange/Exchange.sol:L34-L39  function matchOrders(  LibOrder.OrderParam memory takerOrderParam,  LibOrder.OrderParam[] memory makerOrderParams,  address _perpetual,  uint256[] memory amounts  ) public {  code/contracts/exchange/Exchange.sol:L113-L113  function matchOrderWithAMM(LibOrder.OrderParam memory takerOrderParam, address _perpetual, uint256 amount) public {  Recommendation  Require makerOrderParams.length > 0 && amounts.length == makerOrderParams.length  Require that amount or any of the amounts[i] provided to matchOrders is >=tradingLotSize.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.10 AMM - Liquidity provider may lose up to lotSize when removing liquidity   ", "body": "  Resolution  The client acknowledges this issue without providing further information.  Description  When removing liquidity, the amount of collateral received is calculated from the shareAmount (ShareToken) of the liquidity provider. The liquidity removal process registers a trade on the amount, with the liquidity provider and AMM taking opposite sides. Because trading only accepts multiple of the lotSize, the leftover is discarded. The amount discarded may be up to lotSize - 1.  The expectation is that this value should not be too high, but as lotSize can be set to arbitrary values by an admin, it is possible that this step discards significant value. Additionally, see issue 6.6 for how this can be exploited by an admin.  Note that similar behavior is present in Perpetual.liquidateFrom, where the liquidatableAmount calculated undergoes a similar modulo operation:  code/contracts/perpetual/Perpetual.sol:L277-L278  uint256 liquidatableAmount = totalPositionSize.sub(totalPositionSize.mod(governance.lotSize));  liquidationAmount = liquidationAmount.ceil(governance.lotSize).min(maxAmount).min(liquidatableAmount);  Examples  lotSize can arbitrarily be set up to pos_int256_max as long as tradingLotSize % lotSize == 0  code/contracts/perpetual/PerpetualGovernance.sol:L61-L69  } else if (key == \"lotSize\") {  require(  governance.tradingLotSize == 0 || governance.tradingLotSize.mod(value.toUint256()) == 0,  \"require tls % ls == 0\"  );  governance.lotSize = value.toUint256();  } else if (key == \"tradingLotSize\") {  require(governance.lotSize == 0 || value.toUint256().mod(governance.lotSize) == 0, \"require tls % ls == 0\");  governance.tradingLotSize = value.toUint256();  amount is derived from shareAmount rounded down to the next multiple of the lotSize. The leftover is discarded.  code/contracts/liquidity/AMM.sol:L289-L294  uint256 amount = shareAmount.wmul(oldPoolPositionSize).wdiv(shareToken.totalSupply());  amount = amount.sub(amount.mod(perpetualProxy.lotSize()));  perpetualProxy.transferBalanceOut(trader, price.wmul(amount).mul(2));  burnShareTokenFrom(trader, shareAmount);  uint256 opened = perpetualProxy.trade(trader, LibTypes.Side.LONG, price, amount);  Recommendation  Ensure that documentation makes users aware of the fact that they may lose up to lotsize-1 in value.  Alternatively, track accrued value and permit trades on values that exceed lotSize. Note that this may add significant complexity.  Ensure that similar system behavior, like the liquidatableAmount calculated in Perpetual.liquidateFrom, is also documented and communicated clearly to users.  ", "labels": ["Consensys", "Medium", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.11 Oracle - Unchecked oracle response timestamp and integer over/underflow    ", "body": "  Resolution  This issue was resolved by following the recommendations,  using LibMath for arithmetic operations to guard against over/underflows,  checking that newPrice != 0  verifying that the timestamp is within a configurable range,  duplicating the code and combining the reverse oracle into one contract  The assessment team would like to note that the acceptable time-frame for answers can vary, the price may be outdated, and it is totally up to the deployer to configure the acceptable timeout. The timeout can be changed by the account deploying the oracle feed without a delay allowing the price-feed owner to arbitrarily make calls to AMM.indexPrice fail (front-running). A timeout may be set to an arbitrarily high value to bypass the check. User s of the system are advised to validate that they trust the account operating the feeder and that the timeout is set correctly.  Description  The external Chainlink oracle, which provides index price information to the system, introduces risk inherent to any dependency on third-party data sources. For example, the oracle could fall behind or otherwise fail to be maintained, resulting in outdated data being fed to the index price calculations of the AMM. Oracle reliance has historically resulted in crippled on-chain systems, and complications that lead to these outcomes can arise from things as simple as network congestion.  Ensuring that unexpected oracle return values are properly handled will reduce reliance on off-chain components and increase the resiliency of the smart contract system that depends on them.  Examples  The ChainlinkAdapter and InversedChainlinkAdapter take the oracle s (int256) latestAnswer and convert the result using chainlinkDecimalsAdapter. This arithmetic operation can underflow/overflow if the Oracle provides a large enough answer:  code/contracts/oracle/ChainlinkAdapter.sol:L10-L19  int256 public constant chainlinkDecimalsAdapter = 10**10;  constructor(address _feeder) public {  feeder = IChainlinkFeeder(_feeder);  function price() public view returns (uint256 newPrice, uint256 timestamp) {  newPrice = (feeder.latestAnswer() * chainlinkDecimalsAdapter).toUint256();  timestamp = feeder.latestTimestamp();  code/contracts/oracle/InversedChainlinkAdapter.sol:L11-L20  int256 public constant chainlinkDecimalsAdapter = 10**10;  constructor(address _feeder) public {  feeder = IChainlinkFeeder(_feeder);  function price() public view returns (uint256 newPrice, uint256 timestamp) {  newPrice = ONE.wdiv(feeder.latestAnswer() * chainlinkDecimalsAdapter).toUint256();  timestamp = feeder.latestTimestamp();  The oracle provides a timestamp for the latestAnswer that is not validated and may lead to old oracle timestamps being accepted (e.g. caused by congestion on the blockchain or a directed censorship attack).  code/contracts/oracle/InversedChainlinkAdapter.sol:L19-L20  timestamp = feeder.latestTimestamp();  Recommendation  Use SafeMath for mathematical computations  Verify latestAnswer is within valid bounds (!=0)  Verify latestTimestamp is within accepted bounds (not in the future, was updated within a reasonable amount of time)  Deduplicate code by combining both Adapters into one as the only difference is that the InversedChainlinkAdapter returns ONE.wdiv(price).  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.12 AMM - Liquidity pools can be initialized with zero collateral   Pending", "body": "  Resolution  This issue was addressed by checking that amount > 0. The assessment team would like to note that;  The client chose to verify that amount is non-zero when calling createPool instead of requiring a minimum of a lotSize.  The client did not address the issues about removeLiquidity and addLiquidity allowing to remove and add zero liquidity.  Description  createPool can be initialized with amount == 0. Because a subsequent call to initFunding can only happen once, the contract is now initialized with a zero size pool that does not allow any liquidity to be added.  Trying to recover by calling createPool again fails as the funding state is already initialized. The specification also states the following about createPool:  Open asset pool by deposit to AMM. Only available when pool is empty.  This is inaccurate, as createPool can only be called once due to a check in initFunding, but this call may leave the pool empty.  Furthermore, the contract s liquidity management functionality (addLiquidity and removeLiquidity) allows adding zero liquidity (amount == 0) and removing zero shares (shareAmount == 0). As these actions do not change the liquidity of the pool, they should be rejected.  Recommendation  Require a minimum amount  lotSize to be provided when creating a Pool and adding liquidity via addLiquidity  Require a minimum amount of shares to be provided when removing liquidity via removeLiquidity  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.13 Perpetual - Administrators can put the system into emergency mode indefinitely   Pending", "body": "  Resolution  The client provided the following statement addressing the issue:  It should be solved by voting. Moreover, we add two roles who is able to disable withdrawing /pause the system.  The duration of the emergency phase is still unrestricted.  Description  There is no limitation on how long an administrator can put the Perpetual contract into emergency mode. Users cannot trade or withdraw funds in emergency mode and are effectively locked out until the admin chooses to put the contract in SETTLED mode.  Examples  code/contracts/perpetual/PerpetualGovernance.sol:L96-L101  function beginGlobalSettlement(uint256 price) public onlyWhitelistAdmin {  require(status != LibTypes.Status.SETTLED, \"already settled\");  settlementPrice = price;  status = LibTypes.Status.SETTLING;  emit BeginGlobalSettlement(price);  code/contracts/perpetual/Perpetual.sol:L146-L154  function endGlobalSettlement() public onlyWhitelistAdmin {  require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");  address guy = address(amm.perpetualProxy());  settleFor(guy);  status = LibTypes.Status.SETTLED;  emit EndGlobalSettlement();  Recommendation  Set a time-lock when entering emergency mode that allows anyone to set the system to SETTLED after a fixed amount of time.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.14 Signed data may be usable cross-chain    ", "body": "  Resolution                           This issue was addressed by adding the   order data and verifying it as part of  Description  Signed order data may be re-usable cross-chain as the chain-id is not explicitly part of the signed data.  Examples  The signed order data currently includes the EIP712 Domain Name Mai Protocol and the following information:  code/contracts/lib/LibOrder.sol:L23-L48  struct Order {  address trader;  address broker;  address perpetual;  uint256 amount;  uint256 price;  /**  Data contains the following values packed into 32 bytes  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557  \u2551                    \u2502 length(bytes)   desc                                      \u2551  \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562  \u2551 version            \u2502 1               order version                             \u2551  \u2551 side               \u2502 1               0: buy (long), 1: sell (short)            \u2551  \u2551 isMarketOrder      \u2502 1               0: limitOrder, 1: marketOrder             \u2551  \u2551 expiredAt          \u2502 5               order expiration time in seconds          \u2551  \u2551 asMakerFeeRate     \u2502 2               maker fee rate (base 100,000)             \u2551  \u2551 asTakerFeeRate     \u2502 2               taker fee rate (base 100,000)             \u2551  \u2551 (d) makerRebateRate\u2502 2               rebate rate for maker (base 100)          \u2551  \u2551 salt               \u2502 8               salt                                      \u2551  \u2551 isMakerOnly        \u2502 1               is maker only                             \u2551  \u2551 isInversed         \u2502 1               is inversed contract                      \u2551  \u2551                    \u2502 8               reserved                                  \u2551  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d  /  bytes32 data;  Signature verification:  code/contracts/lib/LibSignature.sol:L24-L47  function isValidSignature(OrderSignature memory signature, bytes32 hash, address signerAddress)  internal  pure  returns (bool)  uint8 method = uint8(signature.config[1]);  address recovered;  uint8 v = uint8(signature.config[0]);  if (method == uint8(SignatureMethod.ETH_SIGN)) {  recovered = ecrecover(  keccak256(abi.encodePacked(\"\\x19Ethereum Signed Message:\\n32\", hash)),  v,  signature.r,  signature.s  );  } else if (method == uint8(SignatureMethod.EIP712)) {  recovered = ecrecover(hash, v, signature.r, signature.s);  } else {  revert(\"invalid sign method\");  return signerAddress == recovered;  Recommendation  Include the chain-id in the signature to avoid cross-chain validity of signatures  verify s is within valid bounds to avoid signature malleability  if (uint256(s) > 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0) {  revert(\"ECDSA: invalid signature 's' value\");  verify v is within valid bounds  if (v != 27 && v != 28) {  revert(\"ECDSA: invalid signature 'v' value\");  return invalid if the result of ecrecover() is 0x0  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.15 Exchange - validateOrderParam does not check against SUPPORTED_ORDER_VERSION    ", "body": "  Resolution                           This issue was resolved by checking against   Description  validateOrderParam verifies the signature and version of a provided order. Instead of checking against the contract constant SUPPORTED_ORDER_VERSION it, however, checks against a hardcoded version 2 in the method itself.  This might be a problem if SUPPORTED_ORDER_VERSION is seen as the configuration parameter for the allowed version. Changing it would not change the allowed order version for validateOrderParam as this constant literal is never used.  At the time of this audit, however, the SUPPORTED_ORDER_VERSION value equals the hardcoded value in the validateOrderParam method.  Examples  code/contracts/exchange/Exchange.sol:L155-L170  function validateOrderParam(IPerpetual perpetual, LibOrder.OrderParam memory orderParam)  internal  view  returns (bytes32)  address broker = perpetual.currentBroker(orderParam.trader);  require(broker == msg.sender, \"invalid broker\");  require(orderParam.getOrderVersion() == 2, \"unsupported version\");  require(orderParam.getExpiredAt() >= block.timestamp, \"order expired\");  bytes32 orderHash = orderParam.getOrderHash(address(perpetual), broker);  require(orderParam.signature.isValidSignature(orderHash, orderParam.trader), \"invalid signature\");  require(filled[orderHash] < orderParam.amount, \"fullfilled order\");  return orderHash;  Recommendation  Check against SUPPORTED_ORDER_VERSION instead of the hardcoded value 2.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.16 LibMathSigned - wpowi returns an invalid result for a negative exponent   Pending", "body": "  Resolution                           This issue was addressed by requiring that   here). The method is still lacking proper natspec documentation outlining expected argument types and valid ranges. The client chose not to implement a check to detect the case where a user accidentally provides  Description  LibMathSigned.wpowi(x,n) calculates Wad value x (base) to the power of n (exponent).  The exponent is declared as a signed int, however, the method returns wrong results when calculating x ^(-n).  The comment for the wpowi method suggests that n is a normal integer instead of a Wad-denominated value. This, however, is not being enforced.  Examples  LibMathSigned.wpowi(8000000000000000000, 2) = 64000000000000000000  (wrong) LibMathSigned.wpowi(8000000000000000000, -2) = 64000000000000000000  code/contracts/lib/LibMath.sol:L103-L116  // x ^ n  // NOTE: n is a normal integer, do not shift 18 decimals  // solium-disable-next-line security/no-assign-params  function wpowi(int256 x, int256 n) internal pure returns (int256 z) {  z = n % 2 != 0 ? x : _WAD;  for (n /= 2; n != 0; n /= 2) {  x = wmul(x, x);  if (n % 2 != 0) {  z = wmul(z, x);  Recommendation  Make wpowi support negative exponents or use the proper type for n (uint) and reject negative values.  Enforce that the exponent bounds are within sane ranges and less than a Wad to detect potential misuse where someone accidentally provides a Wad value as n.  Add positive and negative unit-tests to fully cover this functionality.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.17 Outdated solidity version and floating pragma   Pending", "body": "  Resolution                           This issue was addressed by removing the floating pragma and fixing the compiler version to v0.5.15. The assessment team would like to note, that the latest   ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "0.5.17 with 0.5.16 addressing an ABIEncoder issue.", "body": "  Description  Using an outdated compiler version can be problematic especially if there are publicly disclosed bugs and issues (see also https://github.com/ethereum/solidity/releases) that affect the current compiler version.  The codebase specifies a floating version of ^0.5.2 and makes use of the experimental feature ABIEncoderV2.  It should be noted, that ABIEncoderV2 was subject to multiple bug-fixes up until the latest 0.6.xversion and contracts compiled with earlier versions are - for example - susceptible to the following issues:  ImplicitConstructorCallvalueCheck  TupleAssignmentMultiStackSlotComponents  MemoryArrayCreationOverflow  privateCanBeOverridden  YulOptimizerRedundantAssignmentBreakContinue0.5  ABIEncoderV2CalldataStructsWithStaticallySizedAndDynamicallyEncodedMembers  SignedArrayStorageCopy  ABIEncoderV2StorageArrayWithMultiSlotElement  DynamicConstructorArgumentsClippedABIV2  Examples  Codebase declares compiler version ^0.5.2:  code/contracts/liquidity/AMM.sol:L1-L2  pragma solidity ^0.5.2;  pragma experimental ABIEncoderV2; // to enable structure-type parameters  According to etherscan.io, the currently deployed main-net AMM contract is compiled with solidity version 0.5.8:  https://etherscan.io/address/0xb95B9fb0539Ec84DeD2855Ed1C9C686Af9A4e8b3#code  Recommendation  It is recommended to settle on the latest stable 0.6.x or 0.5.x version of the Solidity compiler and lock the pragma version to a specifically tested compiler release.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.18 AMM - ONE_WAD_U is never used    ", "body": "  Resolution                           This issue is resolved by removing   Description  The const ONE_WAD_U is declared but never used. Avoid re-declaring the same constants in multiple source-units (and unit-test cases) as this will be hard to maintain.  Examples  code/contracts/liquidity/AMM.sol:L17-L17  uint256 private constant ONE_WAD_U = 10**18;  Recommendation  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.19 Perpetual - Variable shadowing in constructor    ", "body": "  Resolution  This issue was addressed by following the recommendation.  Description  Perpetual inherits from PerpetualGovernance and Collateral, which declare state variables that are shadowed in the Perpetual constructor.  Examples  Local constructor argument shadows PerpetualGovernance.globalConfig, PerpetualGovernance.devAddress, Collateral.collateral  Note: Confusing name: Collateral is an inherited contract and a state variable.  code/contracts/perpetual/Perpetual.sol:L34-L41  constructor(address globalConfig, address devAddress, address collateral, uint256 collateralDecimals)  public  Position(collateral, collateralDecimals)  setGovernanceAddress(\"globalConfig\", globalConfig);  setGovernanceAddress(\"dev\", devAddress);  emit CreatePerpetual();  Recommendation  Rename the parameter or state variable.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.20 Perpetual - The specified decimals for the collateral may not reflect the token s actual decimals   ", "body": "  Resolution  The client acknowledges this issue without providing further information.  Description  When initializing the Perpetual contract, the deployer can decide to use either ETH, or an  ERC20-compliant collateral. In the latter case, the deployer must provide a nonzero address for the token, as well as the number of decimals used by the token:  code/contracts/perpetual/Collateral.sol:L28-L34  constructor(address _collateral, uint256 decimals) public {  require(decimals <= MAX_DECIMALS, \"decimals out of range\");  require(_collateral != address(0x0) || (_collateral == address(0x0) && decimals == 18), \"invalid decimals\");  collateral = _collateral;  scaler = (decimals == MAX_DECIMALS ? 1 : 10**(MAX_DECIMALS - decimals)).toInt256();  The provided decimals value is not checked for validity and can differ from the actual token s decimals.  Recommendation  Ensure to establish documentation that makes users aware of the fact that the decimals configured are not enforced to match the actual tokens decimals. This is to allow users to audit the system configuration and decide whether they want to participate in it.  ", "labels": ["Consensys", "Minor", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.21 AMM - Unchecked return value in ShareToken.mint   Pending", "body": "  Resolution                           This issue was addressed by adding checks to   Description  ShareToken is an extension of the Openzeppelin ERC20Mintable pattern which exposes a method called mint() that allows accounts owning the minter role to mint new tokens. The return value of ShareToken.mint() is not checked.  Since the ERC20 standard does not define whether this method should return a value or revert it may be problematic to assume that all tokens revert. If, for example, an implementation is used that does not revert on error but returns a boolean error indicator instead the caller might falsely continue without the token minted.  We would like to note that the functionality is intended to be used with the provided ShareToken and therefore the contract is safe to use assuming ERC20Mintable.mint reverts on error. The issue arises if the system is used with a different ShareToken implementation that is not implemented in the same way.  Examples  Openzeppelin implementation  function mint(address account, uint256 amount) public onlyMinter returns (bool) {  _mint(account, amount);  return true;  Call with unchecked return value  code/contracts/liquidity/AMM.sol:L499-L502  function mintShareTokenTo(address guy, uint256 amount) internal {  shareToken.mint(guy, amount);  Recommendation  Consider wrapping the mint statement in a require clause, however, this way only tokens that are returning a boolean error indicator are supported. Document the specification requirements for the ShareToken and clearly state if the token is expected to revert or return an error indicator.  It should also be documented that the Token exposes a burn method that does not adhere to the Openzeppelin ERC20Burnable implementation. The ERC20Burnable import is unused as noted in issue 6.23.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.22 Perpetual - beginGlobalSettlement can be called multiple times   ", "body": "  Resolution  The client addressed this issue with the following statement:  Acknowledged.  It sill can be call multiple times to correct the settlement price. Voting and pausemay improve the situation.When pause, no liquidation which may leading to losing position happens event in theemergency mode.  beginGlobalSettlement can still be called multiple times.  Description  The system can be put into emergency mode by an admin calling beginGlobalSettlement and providing a fixed settlementPrice. The method can be invoked even when the contract is already in SETTLING (emergency) mode, allowing an admin to selectively adjust the settlement price again. This does not seem to be the intended behavior as calling the method again re-sets the status to SETTLING. Furthermore, it may affect users  behavior during the SETTLING phase.  Examples  code/contracts/perpetual/PerpetualGovernance.sol:L96-L101  function beginGlobalSettlement(uint256 price) public onlyWhitelistAdmin {  require(status != LibTypes.Status.SETTLED, \"already settled\");  settlementPrice = price;  status = LibTypes.Status.SETTLING;  emit BeginGlobalSettlement(price);  Recommendation  Emergency mode should only be allowed to be set once  ", "labels": ["Consensys", "Minor", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.23 Unused Imports    ", "body": "  Resolution  This issue was addressed by removing the listed imports.  Description  The following source units are imported but not referenced in the contract:  Examples  code/contracts/perpetual/Perpetual.sol:L4-L5  import \"@openzeppelin/contracts/token/ERC20/IERC20.sol\";  import \"@openzeppelin/contracts/token/ERC20/SafeERC20.sol\";  code/contracts/perpetual/Perpetual.sol:L14-L15  import \"../interface/IPriceFeeder.sol\";  import \"../interface/IGlobalConfig.sol\";  code/contracts/token/ShareToken.sol:L5-L5  import \"@openzeppelin/contracts/token/ERC20/ERC20Burnable.sol\";  code/contracts/token/ShareToken.sol:L3-L3  import \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";  Recommendation  Check all imports and remove all unused/unreferenced and unnecessary imports.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.24 Exchange - OrderStatus is never used    ", "body": "  Resolution  This issue was resolved by removing the unused code.  Description  The enum OrderStatus is declared but never used.  Examples  code/contracts/exchange/Exchange.sol:L20-L20  enum OrderStatus {EXPIRED, CANCELLED, FILLABLE, FULLY_FILLED}  Recommendation  Remove unused code.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.25 LibMath - Inaccurate declaration of _UINT256_MAX    ", "body": "  Resolution                           This issue was addressed by renaming   Description  LibMathUnsigned declares _UINT256_MAX as 2^255-1 while this value actually represents _INT256_MAX. This appears to just be a naming issue.  Examples  (UINT256_MAX/2-1 => pos INT256_MAX; 2**256/2-1==2**255-1)  code/contracts/lib/LibMath.sol:L228-L230  library LibMathUnsigned {  uint256 private constant _WAD = 10**18;  uint256 private constant _UINT256_MAX = 2**255 - 1;  Recommendation  Rename _UINT256_MAX to _INT256MAX or _SIGNED_INT256MAX.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.26 LibMath - inconsistent assertion text and improve representation of literals with many digits   ", "body": "  Resolution  The client acknowledges this issue without providing further information.  Description  The assertion below states that logE only accepts v <= 1e22 * 1e18 while the argument name is x. In addition to that we suggest representing large literals in scientific notation.  Examples  code/contracts/lib/LibMath.sol:L153-L157  function wln(int256 x) internal pure returns (int256) {  require(x > 0, \"logE of negative number\");  require(x <= 10000000000000000000000000000000000000000, \"logE only accepts v <= 1e22 * 1e18\"); // in order to prevent using safe-math  int256 r = 0;  uint8 extra_digits = longer_digits - fixed_digits;  Recommendation  Update the inconsistent assertion text v -> x and represent large literals in scientific notation as they are otherwise difficult to read and review.  ", "labels": ["Consensys", "Minor", "Acknowledged"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.27 LibMath - roundHalfUp returns unfinished result    ", "body": "  Resolution  This issue was addressed by adding the following comment to the function signature. Please note that the code documentation does not adhere to the natspec format.  // ROUND_HALF_UP rule helper. You have to call roundHalfUp(x, y) / y to finish the rounding operation  There is still the residual risk that someone might miss the comment and wrongly assume that the method finishes rounding. This is, however, accepted by the client.  Description  It is assumed that the final rounding step is not executed for performance reasons. However, this might easily introduce errors when the caller assumes the result is rounded for base while it is not.  Examples  roundHalfUp(-4700, 1000) = -4700 instead of 5000  roundHalfUp(4700, 1000) = 4700 instead of 5000  code/contracts/lib/LibMath.sol:L126-L133  // ROUND_HALF_UP rule helper. 0.5 \u2248 1, 0.4 \u2248 0, -0.5 \u2248 -1, -0.4 \u2248 0  function roundHalfUp(int256 x, int256 y) internal pure returns (int256) {  require(y > 0, \"roundHalfUp only supports y > 0\");  if (x >= 0) {  return add(x, y / 2);  return sub(x, y / 2);  Recommendation  We have verified the current code-base and the callers for roundHalfUp are correctly finishing the rounding step. However, it is recommended to finish the rounding within the method or document this behavior to prevent errors caused by code that falsely assumes that the returned value finished rounding.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.28 LibMath/LibOrder - unused named return value    ", "body": "  Resolution  This issue was resolved by either returning a named value or using the return statement.  Description  The following methods declare a named return value but explicitly return a value instead. The named return value is not used.  LibMathSigned.min()  LibMathSigned.max()  LibMathUnsigned.min()  LibMathUnsigned.max()  LibOrder.getOrderHash()  LibOrder.hashOrder()  Examples  code/contracts/lib/LibMath.sol:L90-L96  function min(int256 x, int256 y) internal pure returns (int256 z) {  return x <= y ? x : y;  function max(int256 x, int256 y) internal pure returns (int256 z) {  return x >= y ? x : y;  code/contracts/lib/LibMath.sol:L285-L292  function min(uint256 x, uint256 y) internal pure returns (uint256 z) {  return x <= y ? x : y;  function max(uint256 x, uint256 y) internal pure returns (uint256 z) {  return x >= y ? x : y;  code/contracts/lib/LibOrder.sol:L68-L71  function getOrderHash(Order memory order) internal pure returns (bytes32 orderHash) {  orderHash = LibEIP712.hashEIP712Message(hashOrder(order));  return orderHash;  code/contracts/lib/LibOrder.sol:L86-L97  function hashOrder(Order memory order) internal pure returns (bytes32 result) {  bytes32 orderType = EIP712_ORDER_TYPE;  // solium-disable-next-line security/no-inline-assembly  assembly {  let start := sub(order, 32)  let tmp := mload(start)  mstore(start, orderType)  result := keccak256(start, 224)  mstore(start, tmp)  return result;  Recommendation  Remove the named return value and explicitly return the value.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.29 Where possible, a specific contract type should be used rather than address   Pending", "body": "  Resolution                           This issue was partially addressed by changing some state variable declarations from   Description  Rather than storing addresses and then casting to the known contract type, it s better to use the best type available so the compiler can check for type safety.  Examples  Collateral. collateral is of type address, but it could be type IERC20 instead. Not only would this give a little more type safety when deploying new modules, but it would avoid repeated casts throughout the codebase of the form IERC20(collateral), IPerpetual(_perpetual) and others. The following is an incomplete list of examples:  declare collateral as IERC20  code/contracts/perpetual/Collateral.sol:L19-L19  address public collateral;  code/contracts/perpetual/Collateral.sol:L51-L51  IERC20(collateral).safeTransferFrom(guy, address(this), rawAmount);  declare argument perpetual as IPerpetual  code/contracts/exchange/Exchange.sol:L34-L42  function matchOrders(  LibOrder.OrderParam memory takerOrderParam,  LibOrder.OrderParam[] memory makerOrderParams,  address _perpetual,  uint256[] memory amounts  ) public {  require(!takerOrderParam.isMakerOnly(), \"taker order is maker only\");  IPerpetual perpetual = IPerpetual(_perpetual);  declare argument feeder as IChainlinkFeeder  code/contracts/oracle/ChainlinkAdapter.sol:L12-L14  constructor(address _feeder) public {  feeder = IChainlinkFeeder(_feeder);  Remediation  Where possible, use more specific types instead of address. This goes for parameter types as well as state variable types.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/05/mcdex-mai-protocol-v2/"}, {"title": "6.1 zDAO Token - Specification violation - Snapshots are never taken   Partially Addressed", "body": "  Resolution  Addressed with zer0-os/zDAO-Token@81946d4 by exposing the _snapshot() method to a dedicated snapshot role (likely to be a DAO) and the owner of the contract.  We would like to note that we informed the client that depending on how the snapshot method is used and how predictably snapshots are consumed this might open up a frontrunning vector where someone observing that a _snapshot() is about to be taken might sandwich the snapshot call, accumulate a lot of stake (via 2nd markets, lending platforms), and returning it right after it s been taken. The risk of losing funds may be rather low (especially if performed by a miner) and the benefit from a DAO proposal using this snapshot might outweigh it. It is still recommended to increase the number of snapshots taken or take them on a regular basis (e.g. with every first transaction to the contract in a block) to make it harder to sandwich the snapshot taking.  Description  According to the zDAO Token specification the DAO token should implement a snapshot functionality to allow it being used for DAO governance votings.  Any transfer, mint, or burn operation should result in a snapshot of the token balances of involved users being taken.  While the corresponding functionality is implemented and appears to update balances for snapshots, _snapshot() is never called, therefore, the snapshot is never taken. e.g. attempting to call balanceOfAt always results in an error as no snapshot is available.  zDAO-Token/contracts/ZeroDAOToken.sol:L12-L17  contract ZeroDAOToken is  OwnableUpgradeable,  ERC20Upgradeable,  ERC20PausableUpgradeable,  ERC20SnapshotUpgradeable  zDAO-Token/contracts/ZeroDAOToken.sol:L83-L83  _updateAccountSnapshot(sender);  Note that this is an explicit requirement as per specification but unit tests do not seem to attempt calls to balanceOfAt at all.  Recommendation  Actually, take a snapshot by calling _snapshot() once per block when executing the first transaction in a new block. Follow the openzeppeling documentation for ERC20Snapshot.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zdao-token/"}, {"title": "6.2 zDAO-Token - Revoking vesting tokens right before cliff period expiration might be delayed/front-runned ", "body": "  Description  The owner of TokenVesting contract has the right to revoke the vesting of tokens for any beneficiary. By doing so, the amount of tokens that are already vested and weren t released yet are being transferred to the beneficiary, and the rest are being transferred to the owner. The beneficiary is expected to receive zero tokens in case the revocation transaction was executed before the cliff period is over. Although unlikely, the beneficiary may front run this revocation transaction by delaying the revocation (and) or inserting a release transaction right before that, thus withdrawing the vested amount.  zDAO-Token/contracts/TokenVesting.sol:L69-L109  function release(address beneficiary) public {  uint256 unreleased = getReleasableAmount(beneficiary);  require(unreleased > 0, \"Nothing to release\");  TokenAward storage award = getTokenAwardStorage(beneficiary);  award.released += unreleased;  targetToken.safeTransfer(beneficiary, unreleased);  emit Released(beneficiary, unreleased);  /**  @notice Allows the owner to revoke the vesting. Tokens already vested  are transfered to the beneficiary, the rest are returned to the owner.  @param beneficiary Who the tokens are being released to  /  function revoke(address beneficiary) public onlyOwner {  TokenAward storage award = getTokenAwardStorage(beneficiary);  require(award.revocable, \"Cannot be revoked\");  require(!award.revoked, \"Already revoked\");  // Figure out how many tokens were owed up until revocation  uint256 unreleased = getReleasableAmount(beneficiary);  award.released += unreleased;  uint256 refund = award.amount - award.released;  // Mark award as revoked  award.revoked = true;  award.amount = award.released;  // Transfer owed vested tokens to beneficiary  targetToken.safeTransfer(beneficiary, unreleased);  // Transfer unvested tokens to owner (revoked amount)  targetToken.safeTransfer(owner(), refund);  emit Released(beneficiary, unreleased);  emit Revoked(beneficiary, refund);  Recommendation  The issue described above is possible, but very unlikely. However, the TokenVesting owner should be aware of that, and make sure not to revoke vested tokens closely to cliff period ending.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zdao-token/"}, {"title": "6.3 zDAO-Token - Vested tokens revocation depends on claiming state ", "body": "  Description  Examples  zDAO-Token/contracts/TokenVesting.sol:L86-L109  function revoke(address beneficiary) public onlyOwner {  TokenAward storage award = getTokenAwardStorage(beneficiary);  require(award.revocable, \"Cannot be revoked\");  require(!award.revoked, \"Already revoked\");  // Figure out how many tokens were owed up until revocation  uint256 unreleased = getReleasableAmount(beneficiary);  award.released += unreleased;  uint256 refund = award.amount - award.released;  // Mark award as revoked  award.revoked = true;  award.amount = award.released;  // Transfer owed vested tokens to beneficiary  targetToken.safeTransfer(beneficiary, unreleased);  // Transfer unvested tokens to owner (revoked amount)  targetToken.safeTransfer(owner(), refund);  emit Released(beneficiary, unreleased);  emit Revoked(beneficiary, refund);  Recommendation  Make sure that the potential owner of a TokenVesting contract is aware of this potential issue, and has the required processes in place to handle it.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zdao-token/"}, {"title": "6.4 zDAO-Token - Total amount of claimable tokens is not verifiable    ", "body": "  Description  Since both MerkleTokenVesting and MerkleTokenAirdrop use an off-chain Merkle tree to store the accounts that can claim tokens from the underlying contract, there is no way for a user to verify whether the contract token balance is sufficient for all claimers.  Recommendation  Make sure that users are aware of this trust assumption.  7 Document Change Log  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zdao-token/"}, {"title": "1.0", "body": "  2021-05-20  Initial report  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zdao-token/"}, {"title": "1.1", "body": "  2021-08-23  Update: added section 3 - WILD Token  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2021/05/zer0-zdao-token/"}, {"title": "6.1 An account that confirms a transaction via AssetProxyOwner can indefinitely block that transaction    ", "body": "  Resolution                           This is fixed in   0xProject/0x-monorepo#2297 by allowing transactions to be  over confirmed  without resetting the confirmation time. As long as there are enough honest signers, this prevents a malicious signer from blocking transactions.  Description  When a transaction reaches the required number of confirmations in confirmTransaction(), its confirmation time is recorded:  code/contracts/multisig/contracts/src/MultiSigWalletWithTimeLock.sol:L86-L100  /// @dev Allows an owner to confirm a transaction.  /// @param transactionId Transaction ID.  function confirmTransaction(uint256 transactionId)  public  ownerExists(msg.sender)  transactionExists(transactionId)  notConfirmed(transactionId, msg.sender)  notFullyConfirmed(transactionId)  confirmations[transactionId][msg.sender] = true;  emit Confirmation(msg.sender, transactionId);  if (isConfirmed(transactionId)) {  _setConfirmationTime(transactionId, block.timestamp);  Before the time lock has elapsed and the transaction is executed, any of the owners that originally confirmed the transaction can revoke their confirmation via revokeConfirmation():  code/contracts/multisig/contracts/src/MultiSigWallet.sol:L249-L259  /// @dev Allows an owner to revoke a confirmation for a transaction.  /// @param transactionId Transaction ID.  function revokeConfirmation(uint256 transactionId)  public  ownerExists(msg.sender)  confirmed(transactionId, msg.sender)  notExecuted(transactionId)  confirmations[transactionId][msg.sender] = false;  emit Revocation(msg.sender, transactionId);  Immediately after, that owner can call confirmTransaction() again, which will reset the confirmation time and thus the time lock.  This is especially troubling in the case of a single compromised key, but it s also an issue for disagreement among owners, where any m of the n owners should be able to execute transactions but could be blocked.  Mitigations  Only an owner can do this, and that owner has to be part of the group that originally confirmed the transaction. This means the malicious owner may have to front run the others to make sure they re in that initial confirmation set.  Even once a malicious owner is in position to execute this perpetual delay, they need to call revokeConfirmation() and confirmTransaction() again each time. Another owner can attempt to front the attacker and execute their own confirmTransaction() immediately after the revokeConfirmation() to regain control.  Recommendation  There are several ways to address this, but to best preserve the original MultiSigWallet semantics, once a transaction has reached the required number of confirmations, it should be impossible to revoke confirmations. In the original implementation, this is enforced by immediately executing the transaction when the final confirmation is received.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.2 Orders with signatures that require regular validation can have their validation bypassed if the order is partially filled    ", "body": "  Resolution                           This is fixed in   0xProject/0x-monorepo#2246. Signatures are now always validated each time, regardless of type.  Description  This re-validation step for Wallet, Validator, and EIP1271Wallet signatures is intended to facilitate their use with contracts whose validation depends on some state that may change over time. For example, a validating contract may call into a price feed and determine that some order is invalid if its price deviates from some expected range. In this case, the repeated validation allows 0x users to make orders with custom fill conditions which are evaluated at run-time.  We found that if the sender provides the contract with an invalid signature after the order in question has already been partially filled, the regular validation check required for Wallet, Validator, and EIP1271Wallet signatures can be bypassed entirely.  Examples  Signature validation takes place in MixinExchangeCore._assertFillableOrder. A signature is only validated if it passes the following criteria:  code/contracts/exchange/contracts/src/MixinExchangeCore.sol:L372-L381  // Validate either on the first fill or if the signature type requires  // regular validation.  address makerAddress = order.makerAddress;  if (orderInfo.orderTakerAssetFilledAmount == 0 ||  _doesSignatureRequireRegularValidation(  orderInfo.orderHash,  makerAddress,  signature  ) {  In effect, signature validation only occurs if:  orderInfo.orderTakerAssetFilledAmount == 0 OR  _doesSignatureRequireRegularValidation(orderHash, makerAddress, signature)  If an order is partially filled, the first condition will evaluate to false. Then, that order s signature will only be validated if _doesSignatureRequireRegularValidation evaluates to true:  code/contracts/exchange/contracts/src/MixinSignatureValidator.sol:L183-L206  function _doesSignatureRequireRegularValidation(  bytes32 hash,  address signerAddress,  bytes memory signature  internal  pure  returns (bool needsRegularValidation)  // Read the signatureType from the signature  SignatureType signatureType = _readSignatureType(  hash,  signerAddress,  signature  );  // Any signature type that makes an external call needs to be revalidated  // with every partial fill  needsRegularValidation =  signatureType == SignatureType.Wallet ||  signatureType == SignatureType.Validator ||  signatureType == SignatureType.EIP1271Wallet;  return needsRegularValidation;  The result is that an order whose signature requires regular validation can be forced to skip validation if it has been partially filled, by passing in an invalid signature.  Recommendation  There are a few options for remediation:  Have the Exchange validate the provided signature every time an order is filled.  Record the first seen signature type or signature hash for each order, and check that subsequent actions are submitted with a matching signature.  The first option requires the fewest changes, and does not require storing additional state. While this does mean some additional cost validating subsequent signatures, we feel the increase in flexibility is well worth it, as a maker could choose to create multiple valid signatures for use across different order books.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.3 Changing the owners or required confirmations in the AssetProxyOwner can unconfirm a previously confirmed transaction    ", "body": "  Resolution  This issue is somewhat inaccurate: isConfirmed() breaks out of the loop once it s found the correct number of confirmations. That means that lowering the number of required confirmations is not a problem.  Further, 0xProject/0x-monorepo#2297 allows signers to confirm transactions that have already been confirmed.  Increasing signing requirements or changing signers can still unconfirm previously confirmed transactions, but the development team is happy with that behavior.  Description  Once a transaction has been confirmed in the AssetProxyOwner, it cannot be executed until a lock period has passed. During that time, any change to the number of required confirmations will cause this transaction to no longer be executable.  If the number of required confirmations was decreased, then one or more owners will have to revoke their confirmation before the transaction can be executed.  If the number of required confirmations was increased, then additional owners will have to confirm the transaction, and when the new required number of confirmations is reached, a new confirmation time will be recorded, and thus the time lock will restart.  Similarly, if an owner that had previously confirmed the transaction is replaced, the number of confirmations will drop for existing transactions, and they will need to be confirmed again.  This is not disastrous, but it s almost certainly unintended behavior and may make it difficult to make changes to the multisig owners and parameters.  Examples  executeTransaction() requires that at the time of execution, the transaction is confirmed:  code/contracts/multisig/contracts/src/AssetProxyOwner.sol:L115-L118  function executeTransaction(uint256 transactionId)  public  notExecuted(transactionId)  fullyConfirmed(transactionId)  isConfirmed() checks for exact equality with the number of required confirmations. Having too many confirmations is just as bad as too few:  code/contracts/multisig/contracts/src/MultiSigWallet.sol:L318-L335  /// @dev Returns the confirmation status of a transaction.  /// @param transactionId Transaction ID.  /// @return Confirmation status.  function isConfirmed(uint256 transactionId)  public  view  returns (bool)  uint256 count = 0;  for (uint256 i = 0; i < owners.length; i++) {  if (confirmations[transactionId][owners[i]]) {  count += 1;  if (count == required) {  return true;  If additional confirmations are required to reconfirm a transaction, that resets the time lock:  code/contracts/multisig/contracts/src/MultiSigWalletWithTimeLock.sol:L86-L100  /// @dev Allows an owner to confirm a transaction.  /// @param transactionId Transaction ID.  function confirmTransaction(uint256 transactionId)  public  ownerExists(msg.sender)  transactionExists(transactionId)  notConfirmed(transactionId, msg.sender)  notFullyConfirmed(transactionId)  confirmations[transactionId][msg.sender] = true;  emit Confirmation(msg.sender, transactionId);  if (isConfirmed(transactionId)) {  _setConfirmationTime(transactionId, block.timestamp);  Recommendation  As in issue 6.1, the semantics of the original MultiSigWallet were that once a transaction is fully confirmed, it s immediately executed. The time lock means this is no longer possible, but it is possible to record that the transaction is confirmed and never allow this to change. In fact, the confirmation time already records this. Once the confirmation time is non-zero, a transaction should always be considered confirmed.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.4 Reentrancy in executeTransaction()   ", "body": "  Resolution  From the development team:  Reentrancy would be dangerous in executeTransaction if combined with updating the currentContextAddress. However, this is is prevented by checking currentContextAddress_ != address(0) when validating a transaction.  executeTransaction also inherits a lot of the safety from the reentrancy protection on other individual functions in the Exchange contract.  Setting transactionsExecuted before making the delegatecall also prevents the same transaction from being executed multiple times.  Description  In MixinTransactions, executeTransaction() and batchExecuteTransactions() do not have the nonReentrant modifier. Because of that, it is possible to execute nested transactions or call these functions during other reentrancy attacks on the exchange. The reason behind that decision is to be able to call functions with nonReentrant modifier as delegated transactions.  Nested transactions are partially prevented with a separate check that does not allow transaction execution if the exchange is currently in somebody else s context:  code/contracts/exchange/contracts/src/MixinTransactions.sol:L155-L162  // Prevent `executeTransaction` from being called when context is already set  address currentContextAddress_ = currentContextAddress;  if (currentContextAddress_ != address(0)) {  LibRichErrors.rrevert(LibExchangeRichErrors.TransactionInvalidContextError(  transactionHash,  currentContextAddress_  ));  This check still leaves some possibility of reentrancy. Allowing that behavior is dangerous and may create possible attack vectors in the future.  Recommendation  Add a new modifier to executeTransaction() and batchExecuteTransactions() which is similar to nonReentrant but uses different storage slot.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.5  Poison  order that consumes gas can block market trades   ", "body": "  Resolution  From the development team:  This can be prevented fairly easily by performing an eth_call off-chain before attempting to fill any orders (which is pretty standard practice). Hard coding gas limits reduces flexibility and may ultimately prevent some use cases from developing in the future.  (Note from the audit team: Hardcoding is not necessary. A parameter would do.)  Description  The market buy/sell functions gather a list of orders together for the same asset and try to fill them in order until a target amount has been traded.  These functions use MixinWrapperFunctions._fillOrderNoThrow() to attempt to fill each order but ignore failures. This way, if one order is unfillable for some reason, the overall market order can still succeed by filling other orders.  Orders can still force _fillOrderNoThrow() to revert by using an external contract for signature validation and having that contract consume all available gas.  This makes it possible to advertise a  poison  order for a low price that will block all market orders from succeeding. It s reasonable to assume that off-chain order books will automatically include the best prices when constructing market orders, so this attack would likely be quite effective. Note that such an attack costs the attacker nothing because all they need is an on-chain contract that consumers all available gas (maybe via an assert). This makes it a very appealing attack vector for, e.g., an order book that wants to temporarily disable a competitor.  Details  _fillOrderNoThrow() forwards all available gas when filling the order:  code/contracts/exchange/contracts/src/MixinWrapperFunctions.sol:L340-L348  // ABI encode calldata for `fillOrder`  bytes memory fillOrderCalldata = abi.encodeWithSelector(  IExchangeCore(address(0)).fillOrder.selector,  order,  takerAssetFillAmount,  signature  );  (bool didSucceed, bytes memory returnData) = address(this).delegatecall(fillOrderCalldata);  Similarly, when the Exchange attempts to fill an order that requires external signature validation (Wallet, Validator, or EIP1271Wallet signature types), it forwards all available gas:  code/contracts/exchange/contracts/src/MixinSignatureValidator.sol:L642  (bool didSucceed, bytes memory returnData) = verifyingContractAddress.staticcall(callData);  If the verifying contract consumes all available gas, it can force the overall transaction to revert.  Pedantic Note  Technically, it s impossible to consume all remaining gas when called by another contract because the EVM holds back a small amount, but even at the block gas limit, the amount held back would be insufficient to complete the transaction.  Recommendation  Constrain the gas that is forwarded during signature validation. This can be constrained either as a part of the signature or as a parameter provided by the taker.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.6 Front running in matchOrders()   ", "body": "  Resolution  From the development team:  Front-running is typically prevented with a combination of external contracts and various off-chain mechanics.  These functions are primarily intended to be used with  matching relayers . In this model, orders must set their takerAddress or senderAddress  to the address of the matcher, who is the only party allowed to actually fill the orders. This prevents any other address from participating in a gas auction.  A commit-reveal scheme would be difficult to take advantage of in practice, since orders could be filled through a number of other functions on the Exchange contract. All of these functions would have to adhere to the commit-reveal scheme in order to be effective.  Description  Calls to matchOrders() are made to extract profit from the price difference between two opposite orders: left and right.  code/contracts/exchange/contracts/src/MixinMatchOrders.sol:L106-L111  function matchOrders(  LibOrder.Order memory leftOrder,  LibOrder.Order memory rightOrder,  bytes memory leftSignature,  bytes memory rightSignature  The caller only pays protocol and transaction fees, so it s almost always profitable to front run every call to matchOrders(). That would lead to gas auctions and would make matchOrders() difficult to use.  Recommendation  Consider adding a commit-reveal scheme to matchOrders() to stop front running altogether.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.7 The Exchange owner should not be able to call executeTransaction or batchExecuteTransaction   ", "body": "  Resolution  From the development team:  While this is a minor inconsistency in the logic of these functions, it is in no way dangerous. currentContextAddress is not used when calling any admin functions, so the address of the transaction signer will be completely disregarded.  Description  Examples  _executeTransaction sets the context address to the signer address, which is not msg.sender in this case: code/contracts/exchange/contracts/src/MixinTransactions.sol:L102-L104 // Set the current transaction signer address signerAddress = transaction.signerAddress; _setCurrentContextAddressIfRequired(signerAddress, signerAddress);  The resulting delegatecall could target an admin function like this one: code/contracts/exchange/contracts/src/MixinAssetProxyDispatcher.sol:L38-L61 /// @dev Registers an asset proxy to its asset proxy id. ///      Once an asset proxy is registered, it cannot be unregistered. /// @param assetProxy Address of new asset proxy to register. function registerAssetProxy(address assetProxy)     external     onlyOwner {     // Ensure that no asset proxy exists with current id.     bytes4 assetProxyId = IAssetProxy(assetProxy).getProxyId();     address currentAssetProxy = _assetProxies[assetProxyId];     if (currentAssetProxy != address(0)) {         LibRichErrors.rrevert(LibExchangeRichErrors.AssetProxyExistsError(             assetProxyId,             currentAssetProxy         ));     }      // Add asset proxy and log registration.     _assetProxies[assetProxyId] = assetProxy;     emit AssetProxyRegistered(         assetProxyId,         assetProxy     ); }  The onlyOwner modifier does not check the context address, but checks msg.sender: code/contracts/utils/contracts/src/Ownable.sol:L35-L45 function _assertSenderIsOwner()     internal     view {     if (msg.sender != owner) {         LibRichErrors.rrevert(LibOwnableRichErrors.OnlyOwnerError(             msg.sender,             owner         ));     } }  Recommendation  Add a check to _executeTransaction that prevents the owner from calling this function.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.8 Anyone can front run MixinExchangeCore.cancelOrder()   ", "body": "  Resolution  From the development team:  Front-running is typically prevented with a combination of external contracts and various off-chain mechanics.  It is not possible to cancel an order by providing less data to the cancelOrder function without drastically changing the logic of the fill functions. However, this type of behavior could possibly be enforced by using external contracts that are set to the senderAddress of the related orders.  Description  In order to cancel an order, an authorized address (maker or sender) calls cancelOrder(LibOrder.Order memory order). When calling that function, all data for the order becomes visible to everyone on the network, and anyone can fill that order before it s canceled.  Usually, a maker is canceling an order because it s no longer profitable for them, so an attacker is likely to profit from front running the cancelOrder() transaction.  Recommendation  Make it impossible to front run order cancelation by providing less data to the cancelOrder() function such that this data is insufficient to execute the order.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.9 By manipulating the gas limit, relayers can affect the outcome of ZeroExTransactions   ", "body": "  Resolution  From the development team:  While this is an annoyance when used in combination with marketBuyOrdersNoThrow and marketSellOrdersNoThrow, it does not seem worth it to add a gasLimit to 0x transactions for this reason alone. Instead, this quirk should be documented along with a recommendation to use the fillOrKill variants of each market fill function when used in combination with 0x transactions.  Description  ZeroExTransactions are meta transactions supported by the Exchange. They do not require that they are executed with a specific amount of gas, so the transaction relayer can choose how much gas to provide. By choosing a low gas limit, a relayer can affect the outcome of the transaction.  A ZeroExTransaction specifies a signer, an expiration, and call data for the transaction:  code/contracts/exchange-libs/contracts/src/LibZeroExTransaction.sol:L41-L47  struct ZeroExTransaction {  uint256 salt;                   // Arbitrary number to ensure uniqueness of transaction hash.  uint256 expirationTimeSeconds;  // Timestamp in seconds at which transaction expires.  uint256 gasPrice;               // gasPrice that transaction is required to be executed with.  address signerAddress;          // Address of transaction signer.  bytes data;                     // AbiV2 encoded calldata.  In MixinTransactions._executeTransaction(), all available gas is forwarded in the delegate call, and the transaction is marked as executed:  code/contracts/exchange/contracts/src/MixinTransactions.sol:L107-L108  transactionsExecuted[transactionHash] = true;  (bool didSucceed, bytes memory returnData) = address(this).delegatecall(transaction.data);  Examples  A likely attack vector for this is front running a ZeroExTransaction that ultimately invokes _fillNoThrow(). In this scenario, an attacker sees the call to executeTransaction() and makes their own call with a lower gas limit, causing the order being filled to run out of gas but allowing the transaction as a whole to succeed.  If such an attack is successful, the ZeroExTransaction cannot be replayed, so the signer must produce a new signature and try again, ad infinitum.  Recommendation  Add a gasLimit field to ZeroExTransaction and forward exactly that much gas via delegatecall. (Note that you must explicitly check that sufficient gas is available because the EVM allows you to supply a gas parameter that exceeds the actual remaining gas.)  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.10 Front running market orders   ", "body": "  Resolution  From the development team:  Front-running is typically prevented with a combination of external contracts and various off-chain mechanics.  Users should always understand the risk of using market orders in any market or exchange structure. Although they increase convenience and arguably have a better UX, they almost always carry more risk than other order types.  Users can always enforce a worst price by padding a market fill with an appropriate number of orders that do not exceed the worst acceptable price.  Description  MixinWrapperFunctions defines a number of functions for market buy/sell orders. These functions take a list of orders and a target asset amount to buy or sell. They fill each order in turn until the target has been reached.  These functions provide an appealing opportunity for front running because of the near-guaranteed profit to be had. This is most easily explained with an example:  Alice wishes to buy 10 FOO tokens. She creates a market buy order to purchase tokens first from Bob, who is selling 4 FOO tokens at $9 each, and then from Eve, who is selling 20 tokens at $10 each.  Eve front runs this market order with a transaction that buys all 4 FOO tokens from Bob for $9 each.  Alice s transaction goes through, but because Bob s inventory has been depleted, all 10 FOO tokens are purchased from Eve at a price of $10 each. By front running, Eve gained $4.  In a more traditional front running scheme, Alice would have just been trying to make a simple purchase of FOO tokens at $9 each, and Eve would be taking on non-trivial risk by buying them first and hoping Alice (or another buyer) would be willing to pay a higher price later.  With a market order, however, Eve s front running is nearly risk free because she knows the market order already commits Alice to buying at the higher price.  Recommendation  For the most part, traders will simply have to understand the risks of market orders and take care to only authorize trades they will be happy with.  That said, each order in a market order could specify a maximum quantity, e.g.  I want 10 FOO tokens, and I m willing to buy up to 10 from Bob but only up to 5 from Eve.  This would limit the trader s exposure to increased prices due to front running, but it would retain the convenience and efficiency of market orders.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.11 Modifier ordering plays a significant role in modifier efficacy    ", "body": "  Resolution                           This is fixed in   0xProject/0x-monorepo#2228 by introducing a new modifier that combines the two:  Description  The nonReentrant and refundFinalBalance modifiers always appear together across the 0x monorepo. When used, they invariably appear with nonReentrant listed first, followed by refundFinalBalance. This specific order appears inconsequential at first glance but is actually important. The order of execution is as follows:  The nonReentrant modifier runs (_lockMutexOrThrowIfAlreadyLocked).  If refundFinalBalance had a prefix, it would run now.  The function itself runs.  The refundFinalBalance modifier runs (_refundNonZeroBalanceIfEnabled).  The nonReentrant modifier runs (_unlockMutex).  The fact that the refundFinalBalance modifier runs before the mutex is unlocked is of particular importance because it potentially invokes an external call, which may reenter. If the order of the two modifiers were flipped, the mutex would unlock before the external call, defeating the purpose of the reentrancy guard.  Examples  code/contracts/exchange/contracts/src/MixinExchangeCore.sol:L64-L65  nonReentrant  refundFinalBalance  Recommendation  Although the order of the modifiers is correct as-is, this pattern introduces cognitive overhead when making or reviewing changes to the 0x codebase. Because the two modifiers always appear together, it may make sense to combine the two into a single modifier where the order of operations is explicit.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.12 Several overflows in LibBytes    Addressed", "body": "  Resolution                           This is addressed in   0xProject/0x-monorepo#2265. Unused functions have been removed. The remaining functions are only used with safe parameters (ones guaranteed not to overflow).  Description  Several functions in LibBytes have integer overflows.  Examples  LibBytes.readBytesWithLength returns a pointer to a bytes array within an existing bytes array at some given index. The length of the nested array is added to the given index and checked against the parent array to ensure the data in the nested array is within the bounds of the parent. However, because the addition can overflow, the bounds check can be bypassed to return an array that points to data out of bounds of the parent array.  code/contracts/utils/contracts/src/LibBytes.sol:L546-L553  if (b.length < index + nestedBytesLength) {  LibRichErrors.rrevert(LibBytesRichErrors.InvalidByteOperationError(  LibBytesRichErrors  .InvalidByteOperationErrorCodes.LengthGreaterThanOrEqualsNestedBytesLengthRequired,  b.length,  index + nestedBytesLength  ));  The following functions have similar issues:  readAddress  writeAddress  readBytes32  writeBytes32  readBytes4  Recommendation  An overflow check should be added to the function. Alternatively, because readBytesWithLength does not appear to be used anywhere in the 0x project, the function should be removed from LibBytes. Additionally, the following functions in LibBytes are also not used and should be considered for removal:  popLast20Bytes  writeAddress  writeBytes32  writeUint256  writeBytesWithLength  deepCopyBytes  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "6.13 NSignatureTypes enum value bypasses Solidity safety checks   ", "body": "  Resolution  From the development team:  This has been left unchanged in order to provide more context with a revert when an invalid signature type is used.  Description  The ISignatureValidator contract defines an enum SignatureType to represent the different types of signatures recognized within the exchange. The final enum value, NSignatureTypes, is not a valid signature type. Instead, it is used by MixinSignatureValidator to check that the value read from the signature is a valid enum value. However, Solidity now includes its own check for enum casting, and casting a value over the maximum enum size to an enum is no longer possible.  Because of the added NSignatureTypes value, Solidity s check now recognizes 0x08 as a valid SignatureType value.  Examples  The check is made here:  code/contracts/exchange/contracts/src/MixinSignatureValidator.sol:L441-L449  // Ensure signature is supported  if (uint8(signatureType) >= uint8(SignatureType.NSignatureTypes)) {  LibRichErrors.rrevert(LibExchangeRichErrors.SignatureError(  LibExchangeRichErrors.SignatureErrorCodes.UNSUPPORTED,  hash,  signerAddress,  signature  ));  Recommendation  The check should be removed, as should the SignatureTypes.NSignatureTypes value.  7 Tool-Based Analysis  Several tools were used to perform automated analysis of the reviewed contracts. These issues were reviewed by the audit team, and relevant issues are listed in the Issues section.  ", "labels": ["Consensys", "Minor", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "7.1 MythX", "body": "  MythX is a security analysis API for Ethereum smart contracts. It performs multiple types of analysis, including fuzzing and symbolic execution, to detect many common vulnerability types. The tool was used for automated vulnerability discovery for all audited contracts and libraries. More details on MythX can be found at mythx.io.  The full set of MythX results for both the exchange and staking contracts are available in a separate report.  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "7.2 Surya", "body": "  Surya is an utility tool for smart contract systems. It provides a number of visual outputs and information about structure of smart contracts. It also supports querying the function call graph in multiple ways to aid in the manual inspection and control flow analysis of contracts.  Below is a complete list of functions with their visibility and modifiers:  S\u016brya s Description Report  Files Description Table  exchange/contracts/src/Exchange.sol  cb6733c32d3306348791b83a9ae76460b75555df  exchange/contracts/src/MixinAssetProxyDispatcher.sol  ee5492092ebea3397d53163cad5cfe8b8050f88e  exchange/contracts/src/MixinExchangeCore.sol  87f9d192c0d75569ee95705baa9c1cdfd129d7a5  exchange/contracts/src/MixinMatchOrders.sol  42868be4aea9327a636766682a8655686af3fc72  exchange/contracts/src/MixinProtocolFees.sol  4982d287aaa206897698039fb34f95f53deda0b5  exchange/contracts/src/MixinSignatureValidator.sol  a69bf0916642b2abaf7e2705d704c00bf2e79150  exchange/contracts/src/MixinTransactions.sol  c3108f751ef627e171ad35c445c8e38cbe0c4d2c  exchange/contracts/src/MixinTransferSimulator.sol  b3ceb9d2e4a8cc1c55648548b950ad1114d29961  exchange/contracts/src/MixinWrapperFunctions.sol  69ea7edd94fc6fd1ede6c6bad139e3e61472c3df  exchange/contracts/src/interfaces/IAssetProxy.sol  21860ce6d0fe6286966dab04b39784f6e2d23857  exchange/contracts/src/interfaces/IAssetProxyDispatcher.sol  f3022084eee2e1a87d4bc023d2aa58d44a3bc3c3  exchange/contracts/src/interfaces/IEIP1271Data.sol  3e98264aa000a238a3f954b17acb6c6606fb3104  exchange/contracts/src/interfaces/IEIP1271Wallet.sol  d99b3b52044cba515a1eebbee67cf5db4f0ae280  exchange/contracts/src/interfaces/IExchange.sol  82d342133ab823431dc07255853f99da8cd49b10  exchange/contracts/src/interfaces/IExchangeCore.sol  48b0562a46653734202a40cc2ce7fcf0e653327a  exchange/contracts/src/interfaces/IMatchOrders.sol  db34eec2bf4bc41c3b51ec35803e1c5aaae4a6fb  exchange/contracts/src/interfaces/IProtocolFees.sol  bcc0151ed53fa72a87102f18015b3bcbf604b4cc  exchange/contracts/src/interfaces/ISignatureValidator.sol  e2304c3b8612ec7b7899d163b82a1bb1145c191a  exchange/contracts/src/interfaces/ITransactions.sol  a2f67b8a9e047c0dc7c33efda4223e087a6e90b4  exchange/contracts/src/interfaces/ITransferSimulator.sol  02ea8f864e3277e1f7c30e0ea38aac177625177d  exchange/contracts/src/interfaces/IWallet.sol  81fbaee73e754cfbc57882e1cd81be5fbf70b9de  exchange/contracts/src/interfaces/IWrapperFunctions.sol  d1b20adfa9b2639aff21e8a0d8f864a5b9435fa4  exchange/contracts/src/libs/LibExchangeRichErrorDecoder.sol  02c13f0e1c57b12da14b0384bebb38d1039bc7c1  exchange-libs/contracts/src/IWallet.sol  d3c769706e00d8a68175a261d79c04a8750b6118  exchange-libs/contracts/src/LibEIP712ExchangeDomain.sol  823955e1f1b21a34ad3fda91c7e691dd68e9a62e  exchange-libs/contracts/src/LibExchangeRichErrors.sol  e58712de5e18edfe951ea694124859ca1a1c05f5  exchange-libs/contracts/src/LibFillResults.sol  49422e7a81067b52f6acc8fe5de1acf21134ee7a  exchange-libs/contracts/src/LibMath.sol  ca6e24ec1de03bdea83351ce5f96082f8f5a9976  exchange-libs/contracts/src/LibMathRichErrors.sol  7f3b0be62d7a8d6f3026018aad08dcc9cbb41825  exchange-libs/contracts/src/LibOrder.sol  114be366ad7a0a711a0c2e552500a2c9fb1bbddf  exchange-libs/contracts/src/LibZeroExTransaction.sol  95ea4427d1df12aef259e07ac6215f2e2d9bd6d9  multisig/contracts/src/AssetProxyOwner.sol  df9ed7cba84c1362fee9de80d7774592323a86df  multisig/contracts/src/MultiSigWallet.sol  33b84d070486847dcc86a140fd682a1d8c953164  multisig/contracts/src/MultiSigWalletWithTimeLock.sol  c54d8b6631eacb20fe6bfad6ee268ab81c112614  utils/contracts/src/Authorizable.sol  2ae731a21730cfdd30feb5d20da4d4d2fa194e1d  utils/contracts/src/LibAddress.sol  33eef1855488fbbbfd1eed92101f379343a8f0f7  utils/contracts/src/LibAddressArray.sol  b13d0359922c04fadb4b24abd3d5318462c62d8e  utils/contracts/src/LibAddressArrayRichErrors.sol  883bc123ba699ba1efc11a75f806e1150e8af1ba  utils/contracts/src/LibAuthorizableRichErrors.sol  abfba41b1c63ba91803721d4d0ec6a7a1678752b  utils/contracts/src/LibBytes.sol  7a0c37b1577f5a12378fbf529177ca62314a4e62  utils/contracts/src/LibBytesRichErrors.sol  611b4e660351ee4e24140074ee1df49756e496ec  utils/contracts/src/LibEIP1271.sol  2fe0c70163677ea228d9bcfecdbba2627a5be77f  utils/contracts/src/LibEIP712.sol  3b486180d6ee3e6d5e1f2fa57c1ca060a1bdca9b  utils/contracts/src/LibFractions.sol  552a637f32edb135942cd1ea25e88d6972b8cf79  utils/contracts/src/LibOwnableRichErrors.sol  dfda0c5639f5fc994712421dc92b284071fc9e56  utils/contracts/src/LibReentrancyGuardRichErrors.sol  8af2504839d0b9a4a7a4694886704bee31fb43ad  utils/contracts/src/LibRichErrors.sol  3be89d9503f6fb6aee08aa515119af83d63f7d29  utils/contracts/src/LibSafeMath.sol  f095f7330b0d2b0d85370b47bd5ac98360ed5b48  utils/contracts/src/LibSafeMathRichErrors.sol  7785c4a4076e3f0be3319ec4bc17aca0090c2ce0  utils/contracts/src/Ownable.sol  8ede7b82d2ee0ed63b2162709d8afa7250efc3cf  utils/contracts/src/ReentrancyGuard.sol  5364694b8a2bba36861bfdd8d5886ece26e301a4  utils/contracts/src/Refundable.sol  0fe9acae963bb683b6c3539de8377ed05240bae0  utils/contracts/src/SafeMath.sol  5b675f9c12bf862a72c7dc71d00839214d970d34  utils/contracts/src/interfaces/IAuthorizable.sol  3a438f74bdb79cf6bff4dbe52a31651928601022  utils/contracts/src/interfaces/IOwnable.sol  5fe3a74b7d5948bba5644db684459d87e84fb5c6  Contracts Description Table  Function Name  Visibility  Mutability  Modifiers  Exchange  Implementation  LibEIP712ExchangeDomain, MixinMatchOrders, MixinWrapperFunctions, MixinTransferSimulator  <Constructor>  Public    LibEIP712ExchangeDomain  MixinAssetProxyDispatcher  Implementation  Ownable, IAssetProxyDispatcher  registerAssetProxy  External    onlyOwner  getAssetProxy  External    NO   _dispatchTransferFrom  Internal \ud83d\udd12  MixinExchangeCore  Implementation  IExchangeCore, Refundable, LibEIP712ExchangeDomain, MixinAssetProxyDispatcher, MixinProtocolFees, MixinSignatureValidator  cancelOrdersUpTo  External    refundFinalBalanceNoReentry  fillOrder  Public    refundFinalBalanceNoReentry  cancelOrder  Public    refundFinalBalanceNoReentry  getOrderInfo  Public    NO   _fillOrder  Internal \ud83d\udd12  _cancelOrder  Internal \ud83d\udd12  _updateFilledState  Internal \ud83d\udd12  _updateCancelledState  Internal \ud83d\udd12  _assertFillableOrder  Internal \ud83d\udd12  _assertValidCancel  Internal \ud83d\udd12  _settleOrder  Internal \ud83d\udd12  _getOrderHashAndFilledAmount  Internal \ud83d\udd12  MixinMatchOrders  Implementation  MixinExchangeCore, IMatchOrders  batchMatchOrders  Public    refundFinalBalanceNoReentry  batchMatchOrdersWithMaximalFill  Public    refundFinalBalanceNoReentry  matchOrders  Public    refundFinalBalanceNoReentry  matchOrdersWithMaximalFill  Public    refundFinalBalanceNoReentry  _assertValidMatch  Internal \ud83d\udd12  _batchMatchOrders  Internal \ud83d\udd12  _matchOrders  Internal \ud83d\udd12  _settleMatchedOrders  Internal \ud83d\udd12  MixinProtocolFees  Implementation  IProtocolFees, Ownable  setProtocolFeeMultiplier  External    onlyOwner  setProtocolFeeCollectorAddress  External    onlyOwner  _paySingleProtocolFee  Internal \ud83d\udd12  _payTwoProtocolFees  Internal \ud83d\udd12  _payProtocolFeeToFeeCollector  Internal \ud83d\udd12  MixinSignatureValidator  Implementation  LibEIP712ExchangeDomain, LibEIP1271, ISignatureValidator, MixinTransactions  preSign  External    refundFinalBalanceNoReentry  setSignatureValidatorApproval  External    refundFinalBalanceNoReentry  isValidHashSignature  Public    NO   isValidOrderSignature  Public    NO   isValidTransactionSignature  Public    NO   _isValidOrderWithHashSignature  Internal \ud83d\udd12  _isValidTransactionWithHashSignature  Internal \ud83d\udd12  _validateHashSignatureTypes  Private \ud83d\udd10  _readSignatureType  Private \ud83d\udd10  _readValidSignatureType  Private \ud83d\udd10  _encodeEIP1271OrderWithHash  Private \ud83d\udd10  _encodeEIP1271TransactionWithHash  Private \ud83d\udd10  _validateHashWithWallet  Private \ud83d\udd10  _validateBytesWithWallet  Private \ud83d\udd10  _validateBytesWithValidator  Private \ud83d\udd10  _staticCallEIP1271WalletWithReducedSignatureLength  Private \ud83d\udd10  MixinTransactions  Implementation  Refundable, LibEIP712ExchangeDomain, ISignatureValidator, ITransactions  executeTransaction  Public    disableRefundUntilEnd  batchExecuteTransactions  Public    disableRefundUntilEnd  _executeTransaction  Internal \ud83d\udd12  _assertExecutableTransaction  Internal \ud83d\udd12  _setCurrentContextAddressIfRequired  Internal \ud83d\udd12  _getCurrentContextAddress  Internal \ud83d\udd12  MixinTransferSimulator  Implementation  MixinAssetProxyDispatcher  simulateDispatchTransferFromCalls  Public    NO   MixinWrapperFunctions  Implementation  IWrapperFunctions, MixinExchangeCore  fillOrKillOrder  Public    refundFinalBalanceNoReentry  batchFillOrders  Public    refundFinalBalanceNoReentry  batchFillOrKillOrders  Public    refundFinalBalanceNoReentry  batchFillOrdersNoThrow  Public    disableRefundUntilEnd  marketSellOrdersNoThrow  Public    disableRefundUntilEnd  marketBuyOrdersNoThrow  Public    disableRefundUntilEnd  marketSellOrdersFillOrKill  Public    NO   marketBuyOrdersFillOrKill  Public    NO   batchCancelOrders  Public    refundFinalBalanceNoReentry  _fillOrKillOrder  Internal \ud83d\udd12  _fillOrderNoThrow  Internal \ud83d\udd12  IAssetProxy  Implementation  transferFrom  External    NO   getProxyId  External    NO   IAssetProxyDispatcher  Implementation  registerAssetProxy  External    NO   getAssetProxy  External    NO   IEIP1271Data  Implementation  OrderWithHash  External    NO   ZeroExTransactionWithHash  External    NO   IEIP1271Wallet  Implementation  LibEIP1271  isValidSignature  External    NO   IExchange  Implementation  IProtocolFees, IExchangeCore, IMatchOrders, ISignatureValidator, ITransactions, IAssetProxyDispatcher, ITransferSimulator, IWrapperFunctions  IExchangeCore  Implementation  cancelOrdersUpTo  External    NO   fillOrder  Public    NO   cancelOrder  Public    NO   getOrderInfo  Public    NO   IMatchOrders  Implementation  batchMatchOrders  Public    NO   batchMatchOrdersWithMaximalFill  Public    NO   matchOrders  Public    NO   matchOrdersWithMaximalFill  Public    NO   IProtocolFees  Implementation  setProtocolFeeMultiplier  External    NO   setProtocolFeeCollectorAddress  External    NO   protocolFeeMultiplier  External    NO   protocolFeeCollector  External    NO   ISignatureValidator  Implementation  preSign  External    NO   setSignatureValidatorApproval  External    NO   isValidHashSignature  Public    NO   isValidOrderSignature  Public    NO   isValidTransactionSignature  Public    NO   _isValidOrderWithHashSignature  Internal \ud83d\udd12  _isValidTransactionWithHashSignature  Internal \ud83d\udd12  ITransactions  Implementation  executeTransaction  Public    NO   batchExecuteTransactions  Public    NO   _getCurrentContextAddress  Internal \ud83d\udd12  ITransferSimulator  Implementation  simulateDispatchTransferFromCalls  Public    NO   IWallet  Implementation  isValidSignature  External    NO   IWrapperFunctions  Implementation  fillOrKillOrder  Public    NO   batchFillOrders  Public    NO   batchFillOrKillOrders  Public    NO   batchFillOrdersNoThrow  Public    NO   marketSellOrdersNoThrow  Public    NO   marketBuyOrdersNoThrow  Public    NO   marketSellOrdersFillOrKill  Public    NO   marketBuyOrdersFillOrKill  Public    NO   batchCancelOrders  Public    NO   LibExchangeRichErrorDecoder  Implementation  decodeSignatureError  Public    NO   decodeEIP1271SignatureError  Public    NO   decodeSignatureValidatorNotApprovedError  Public    NO   decodeSignatureWalletError  Public    NO   decodeOrderStatusError  Public    NO   decodeExchangeInvalidContextError  Public    NO   decodeFillError  Public    NO   decodeOrderEpochError  Public    NO   decodeAssetProxyExistsError  Public    NO   decodeAssetProxyDispatchError  Public    NO   decodeAssetProxyTransferError  Public    NO   decodeNegativeSpreadError  Public    NO   decodeTransactionError  Public    NO   decodeTransactionExecutionError  Public    NO   decodeIncompleteFillError  Public    NO   _assertSelectorBytes  Private \ud83d\udd10  IWallet  Implementation  isValidSignature  External    NO   LibEIP712ExchangeDomain  Implementation  <Constructor>  Public    LibExchangeRichErrors  Library  SignatureErrorSelector  Internal \ud83d\udd12  SignatureValidatorNotApprovedErrorSelector  Internal \ud83d\udd12  EIP1271SignatureErrorSelector  Internal \ud83d\udd12  SignatureWalletErrorSelector  Internal \ud83d\udd12  OrderStatusErrorSelector  Internal \ud83d\udd12  ExchangeInvalidContextErrorSelector  Internal \ud83d\udd12  FillErrorSelector  Internal \ud83d\udd12  OrderEpochErrorSelector  Internal \ud83d\udd12  AssetProxyExistsErrorSelector  Internal \ud83d\udd12  AssetProxyDispatchErrorSelector  Internal \ud83d\udd12  AssetProxyTransferErrorSelector  Internal \ud83d\udd12  NegativeSpreadErrorSelector  Internal \ud83d\udd12  TransactionErrorSelector  Internal \ud83d\udd12  TransactionExecutionErrorSelector  Internal \ud83d\udd12  IncompleteFillErrorSelector  Internal \ud83d\udd12  BatchMatchOrdersErrorSelector  Internal \ud83d\udd12  TransactionGasPriceErrorSelector  Internal \ud83d\udd12  TransactionInvalidContextErrorSelector  Internal \ud83d\udd12  PayProtocolFeeErrorSelector  Internal \ud83d\udd12  BatchMatchOrdersError  Internal \ud83d\udd12  SignatureError  Internal \ud83d\udd12  SignatureValidatorNotApprovedError  Internal \ud83d\udd12  EIP1271SignatureError  Internal \ud83d\udd12  SignatureWalletError  Internal \ud83d\udd12  OrderStatusError  Internal \ud83d\udd12  ExchangeInvalidContextError  Internal \ud83d\udd12  FillError  Internal \ud83d\udd12  OrderEpochError  Internal \ud83d\udd12  AssetProxyExistsError  Internal \ud83d\udd12  AssetProxyDispatchError  Internal \ud83d\udd12  AssetProxyTransferError  Internal \ud83d\udd12  NegativeSpreadError  Internal \ud83d\udd12  TransactionError  Internal \ud83d\udd12  TransactionExecutionError  Internal \ud83d\udd12  TransactionGasPriceError  Internal \ud83d\udd12  TransactionInvalidContextError  Internal \ud83d\udd12  IncompleteFillError  Internal \ud83d\udd12  PayProtocolFeeError  Internal \ud83d\udd12  LibFillResults  Library  calculateFillResults  Internal \ud83d\udd12  calculateMatchedFillResults  Internal \ud83d\udd12  addFillResults  Internal \ud83d\udd12  _calculateMatchedFillResults  Private \ud83d\udd10  _calculateMatchedFillResultsWithMaximalFill  Private \ud83d\udd10  _calculateCompleteFillBoth  Private \ud83d\udd10  _calculateCompleteRightFill  Private \ud83d\udd10  LibMath  Library  safeGetPartialAmountFloor  Internal \ud83d\udd12  safeGetPartialAmountCeil  Internal \ud83d\udd12  getPartialAmountFloor  Internal \ud83d\udd12  getPartialAmountCeil  Internal \ud83d\udd12  isRoundingErrorFloor  Internal \ud83d\udd12  isRoundingErrorCeil  Internal \ud83d\udd12  LibMathRichErrors  Library  DivisionByZeroError  Internal \ud83d\udd12  RoundingError  Internal \ud83d\udd12  LibOrder  Library  getTypedDataHash  Internal \ud83d\udd12  getStructHash  Internal \ud83d\udd12  LibZeroExTransaction  Library  getTypedDataHash  Internal \ud83d\udd12  getStructHash  Internal \ud83d\udd12  TestLibEIP712ExchangeDomain  Implementation  LibEIP712ExchangeDomain  <Constructor>  Public    LibEIP712ExchangeDomain  TestLibFillResults  Implementation  calculateFillResults  Public    NO   calculateMatchedFillResults  Public    NO   addFillResults  Public    NO   TestLibMath  Implementation  safeGetPartialAmountFloor  Public    NO   safeGetPartialAmountCeil  Public    NO   getPartialAmountFloor  Public    NO   getPartialAmountCeil  Public    NO   isRoundingErrorFloor  Public    NO   isRoundingErrorCeil  Public    NO   TestLibOrder  Implementation  getTypedDataHash  Public    NO   getStructHash  Public    NO   TestLibZeroExTransaction  Implementation  getTypedDataHash  Public    NO   getStructHash  Public    NO   AssetProxyOwner  Implementation  MultiSigWalletWithTimeLock  <Constructor>  Public    MultiSigWalletWithTimeLock  registerFunctionCall  External    onlyWallet  executeTransaction  Public    notExecuted fullyConfirmed  _registerFunctionCall  Internal \ud83d\udd12  _assertValidFunctionCall  Internal \ud83d\udd12  MultiSigWallet  Implementation  <Fallback>  External    NO   <Constructor>  Public    validRequirement  addOwner  Public    onlyWallet ownerDoesNotExist notNull validRequirement  removeOwner  Public    onlyWallet ownerExists  replaceOwner  Public    onlyWallet ownerExists ownerDoesNotExist  changeRequirement  Public    onlyWallet validRequirement  submitTransaction  Public    NO   confirmTransaction  Public    ownerExists transactionExists notConfirmed  revokeConfirmation  Public    ownerExists confirmed notExecuted  executeTransaction  Public    ownerExists confirmed notExecuted  _externalCall  Internal \ud83d\udd12  isConfirmed  Public    NO   _addTransaction  Internal \ud83d\udd12  notNull  getConfirmationCount  Public    NO   getTransactionCount  Public    NO   getOwners  Public    NO   getConfirmations  Public    NO   getTransactionIds  Public    NO   MultiSigWalletWithTimeLock  Implementation  MultiSigWallet  <Constructor>  Public    MultiSigWallet  changeTimeLock  Public    onlyWallet  confirmTransaction  Public    ownerExists transactionExists notConfirmed notFullyConfirmed  executeTransaction  Public    notExecuted fullyConfirmed pastTimeLock  _setConfirmationTime  Internal \ud83d\udd12  Authorizable  Implementation  Ownable, IAuthorizable  <Constructor>  Public    Ownable  addAuthorizedAddress  External    onlyOwner  removeAuthorizedAddress  External    onlyOwner  removeAuthorizedAddressAtIndex  External    onlyOwner  getAuthorizedAddresses  External    NO   _assertSenderIsAuthorized  Internal \ud83d\udd12  _addAuthorizedAddress  Internal \ud83d\udd12  _removeAuthorizedAddressAtIndex  Internal \ud83d\udd12  LibAddress  Library  isContract  Internal \ud83d\udd12  LibAddressArray  Library  append  Internal \ud83d\udd12  contains  Internal \ud83d\udd12  indexOf  Internal \ud83d\udd12  LibAddressArrayRichErrors  Library  MismanagedMemoryError  Internal \ud83d\udd12  LibAuthorizableRichErrors  Library  AuthorizedAddressMismatchError  Internal \ud83d\udd12  IndexOutOfBoundsError  Internal \ud83d\udd12  SenderNotAuthorizedError  Internal \ud83d\udd12  TargetAlreadyAuthorizedError  Internal \ud83d\udd12  TargetNotAuthorizedError  Internal \ud83d\udd12  ZeroCantBeAuthorizedError  Internal \ud83d\udd12  LibBytes  Library  rawAddress  Internal \ud83d\udd12  contentAddress  Internal \ud83d\udd12  memCopy  Internal \ud83d\udd12  slice  Internal \ud83d\udd12  sliceDestructive  Internal \ud83d\udd12  popLastByte  Internal \ud83d\udd12  equals  Internal \ud83d\udd12  readAddress  Internal \ud83d\udd12  writeAddress  Internal \ud83d\udd12  readBytes32  Internal \ud83d\udd12  writeBytes32  Internal \ud83d\udd12  readUint256  Internal \ud83d\udd12  writeUint256  Internal \ud83d\udd12  readBytes4  Internal \ud83d\udd12  writeLength  Internal \ud83d\udd12  LibBytesRichErrors  Library  InvalidByteOperationError  Internal \ud83d\udd12  LibEIP1271  Implementation  LibEIP712  Library  hashEIP712Domain  Internal \ud83d\udd12  hashEIP712Message  Internal \ud83d\udd12  LibFractions  Library  add  Internal \ud83d\udd12  normalize  Internal \ud83d\udd12  normalize  Internal \ud83d\udd12  scaleDifference  Internal \ud83d\udd12  LibOwnableRichErrors  Library  OnlyOwnerError  Internal \ud83d\udd12  TransferOwnerToZeroError  Internal \ud83d\udd12  LibReentrancyGuardRichErrors  Library  IllegalReentrancyError  Internal \ud83d\udd12  LibRichErrors  Library  StandardError  Internal \ud83d\udd12  rrevert  Internal \ud83d\udd12  LibSafeMath  Library  safeMul  Internal \ud83d\udd12  safeDiv  Internal \ud83d\udd12  safeSub  Internal \ud83d\udd12  safeAdd  Internal \ud83d\udd12  max256  Internal \ud83d\udd12  min256  Internal \ud83d\udd12  LibSafeMathRichErrors  Library  Uint256BinOpError  Internal \ud83d\udd12  Uint256DowncastError  Internal \ud83d\udd12  Ownable  Implementation  IOwnable  <Constructor>  Public    transferOwnership  Public    onlyOwner  _assertSenderIsOwner  Internal \ud83d\udd12  ReentrancyGuard  Implementation  _lockMutexOrThrowIfAlreadyLocked  Internal \ud83d\udd12  _unlockMutex  Internal \ud83d\udd12  Refundable  Implementation  ReentrancyGuard  _refundNonZeroBalanceIfEnabled  Internal \ud83d\udd12  _refundNonZeroBalance  Internal \ud83d\udd12  _disableRefund  Internal \ud83d\udd12  _enableAndRefundNonZeroBalance  Internal \ud83d\udd12  _areRefundsDisabled  Internal \ud83d\udd12  SafeMath  Implementation  _safeMul  Internal \ud83d\udd12  _safeDiv  Internal \ud83d\udd12  _safeSub  Internal \ud83d\udd12  _safeAdd  Internal \ud83d\udd12  _max256  Internal \ud83d\udd12  _min256  Internal \ud83d\udd12  IAuthorizable  Implementation  IOwnable  addAuthorizedAddress  External    NO   removeAuthorizedAddress  External    NO   removeAuthorizedAddressAtIndex  External    NO   getAuthorizedAddresses  External    NO   IOwnable  Implementation  transferOwnership  Public    NO   Legend  Function can modify state  Function is payable  ", "labels": ["Consensys"], "html_url": "https://consensys.io/diligence/audits/2019/09/0x-v3-exchange/"}, {"title": "4.1 Users can withdraw their funds immediately when they are over-leveraged ", "body": "  Description  Accounts.withdraw makes two checks before processing a withdrawal.  First, the method checks that the amount requested for withdrawal is not larger than the user s balance for the asset in question:  code/contracts/Accounts.sol:L197-L201  function withdraw(address _accountAddr, address _token, uint256 _amount) external onlyAuthorized returns(uint256) {  // Check if withdraw amount is less than user's balance  require(_amount <= getDepositBalanceCurrent(_token, _accountAddr), \"Insufficient balance.\");  uint256 borrowLTV = globalConfig.tokenInfoRegistry().getBorrowLTV(_token);  Second, the method checks that the withdrawal will not over-leverage the user. The amount to be withdrawn is subtracted from the user s current  borrow power  at the current price. If the user s total value borrowed exceeds this new borrow power, the method fails, as the user no longer has sufficient collateral to support their borrow positions. However, this require is only checked if a user is not already over-leveraged:  code/contracts/Accounts.sol:L203-L211  // This if condition is to deal with the withdraw of collateral token in liquidation.  // As the amount if borrowed asset is already large than the borrow power, we don't  // have to check the condition here.  if(getBorrowETH(_accountAddr) <= getBorrowPower(_accountAddr))  require(  getBorrowETH(_accountAddr) <= getBorrowPower(_accountAddr).sub(  _amount.mul(globalConfig.tokenInfoRegistry().priceFromAddress(_token))  .mul(borrowLTV).div(Utils.getDivisor(address(globalConfig), _token)).div(100)  ), \"Insufficient collateral when withdraw.\");  If the user has already borrowed more than their  borrow power  allows, they are allowed to withdraw regardless. This case may arise in several circumstances; the most common being price fluctuation.  Recommendation  Disallow withdrawals if the user is already over-leveraged.  From the comment included in the code sample above, this condition is included to support the liquidate method, but its inclusion creates an attack vector that may allow users to withdraw when they should not be able to do so. Consider adding an additional method to support liquidate, so that users may not exit without repaying debts.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "4.2 Users can borrow funds, deposit them, then borrow more   ", "body": "  Resolution  Comment from DeFiner team:  This is expected behaviour and our contracts are designed like that. Other lending protocols like Compound and AAVE allows this feature as well. So this is not a CRITICAL issue, as the user s funds are not at risk. The funds of the users are only at risk when their position is over-leveraged, which is expected behaviour.  Description  Users may deposit and borrow funds denominated in any asset supported by the TokenRegistry. Each time a user deposits or borrows a token, they earn FIN according to the difference in deposit / borrow rate indices maintained by Bank.  Borrowing funds  When users borrow funds, they may only borrow up to a certain amount: the user s  borrow power.  As long as the user is not requesting to borrow an amount that would cause their resulting borrowed asset value to exceed their available borrow power, the borrow is successful and the user receives the assets immediately. A user s borrow power is calculated in the following function:  code/contracts/Accounts.sol:L333-L353  /**  Calculate an account's borrow power based on token's LTV  /  function getBorrowPower(address _borrower) public view returns (uint256 power) {  for(uint8 i = 0; i < globalConfig.tokenInfoRegistry().getCoinLength(); i++) {  if (isUserHasDeposits(_borrower, i)) {  address token = globalConfig.tokenInfoRegistry().addressFromIndex(i);  uint divisor = INT_UNIT;  if(token != ETH_ADDR) {  divisor = 10**uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(token));  // globalConfig.bank().newRateIndexCheckpoint(token);  power = power.add(getDepositBalanceCurrent(token, _borrower)  .mul(globalConfig.tokenInfoRegistry().priceFromIndex(i))  .mul(globalConfig.tokenInfoRegistry().getBorrowLTV(token)).div(100)  .div(divisor)  );  return power;  For each asset, borrow power is calculated from the user s deposit size, multiplied by the current chainlink price, multiplied and that asset s  borrow LTV.   Depositing borrowed funds  After a user borrows tokens, they can then deposit those tokens, increasing their deposit balance for that asset. As a result, their borrow power increases, which allows the user to borrow again.  By continuing to borrow, deposit, and borrow again, the user can repeatedly borrow assets. Essentially, this creates positions for the user where the collateral for their massive borrow position is entirely made up of borrowed assets.  Conclusion  There are several potential side-effects of this behavior.  First, as described in issue 4.6, the system is comprised of many different tokens, each of which is subject to price fluctuation. By borrowing and depositing repeatedly, a user may establish positions across all supported tokens. At this point, if price fluctuations cause the user s account to cross the liquidation threshold, their positions can be liquidated.  Liquidation is a complicated function of the protocol, but in essence, the liquidator purchases a target s collateral at a discount, and the resulting sale balances the account somewhat. However, when a user repeatedly deposits borrowed tokens, their collateral is made up of borrowed tokens: the system s liquidity! As a result, this may allow an attacker to intentionally create a massively over-leveraged account on purpose, liquidate it, and exit with a chunk of the system liquidity.  Another potential problem with this behavior is FIN token mining. When users borrow and deposit, they earn FIN according to the size of the deposit / borrow, and the difference in deposit / borrow rate indices since the last deposit / borrow. By repeatedly depositing / borrowing, users are able to artificially deposit and borrow far more often than normal, which may allow them to generate FIN tokens at will. This additional strategy may make attacks like the one described above much more economically feasible.  Recommendation  Due to the limited time available during this engagement, these possibilities and potential mitigations were not fully explored. Definer is encouraged to investigate this behavior more carefully.  ", "labels": ["Consensys", "Major", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "4.3 Stale Oracle prices might affect the rates ", "body": "  Description  It s possible that due to network congestion or other reasons, the price that the ChainLink oracle returns is old and not up to date. This is more extreme in lesser known tokens that have fewer ChainLink Price feeds to update the price frequently. The codebase as is, relies on chainLink().getLatestAnswer() and does not check the timestamp of the price.  Examples  /contracts/registry/TokenRegistry.sol#L291-L296  function priceFromAddress(address tokenAddress) public view returns(uint256) {  if(Utils._isETH(address(globalConfig), tokenAddress)) {  return 1e18;  return uint256(globalConfig.chainLink().getLatestAnswer(tokenAddress));  Recommendation  Do a sanity check on the price returned from the oracle. If the price is older than a threshold, revert or handle in other means.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "4.4 Overcomplicated unit conversions ", "body": "  Description  There are many instances of unit conversion in the system that are implemented in a confusing way. This could result in mistakes in the conversion and possibly failure in correct accounting. It s been seen in the ecosystem that these type of complicated unit conversions could result in calculation mistake and loss of funds.  Examples  Here are a few examples:  /contracts/Bank.sol#L216-L224  function getBorrowRatePerBlock(address _token) public view returns(uint) {  if(!globalConfig.tokenInfoRegistry().isSupportedOnCompound(_token))  // If the token is NOT supported by the third party, borrowing rate = 3% + U * 15%.  return getCapitalUtilizationRatio(_token).mul(globalConfig.rateCurveSlope()).div(INT_UNIT).add(globalConfig.rateCurveConstant()).div(BLOCKS_PER_YEAR);  // if the token is suppored in third party, borrowing rate = Compound Supply Rate * 0.4 + Compound Borrow Rate * 0.6  return (compoundPool[_token].depositRatePerBlock).mul(globalConfig.compoundSupplyRateWeights()).  add((compoundPool[_token].borrowRatePerBlock).mul(globalConfig.compoundBorrowRateWeights())).div(10);  /contracts/Bank.sol#L350-L351  compoundPool[_token].depositRatePerBlock = cTokenExchangeRate.mul(UNIT).div(lastCTokenExchangeRate[cToken])  .sub(UNIT).div(blockNumber.sub(lastCheckpoint[_token]));  /contracts/Bank.sol#L384-L385  return lastDepositeRateIndex.mul(getBlockNumber().sub(lcp).mul(depositRatePerBlock).add(INT_UNIT)).div(INT_UNIT);  Recommendation  Simplify the unit conversions in the system. This can be done either by using a function wrapper for units to convert all values to the same unit before including them in any calculation or by better documenting every line of unit conversion  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "4.5 Commented out code in the codebase ", "body": "  Description  There are many instances of code lines (and functions) that are commented out in the code base. Having commented out code increases the cognitive load on an already complex system. Also, it hides the important parts of the system that should get the proper attention, but that attention gets to be diluted.  The main problem is that commented code adds confusion with no real benefit. Code should be code, and comments should be comments.  Examples  Here s a few examples of such lines of code, note that there are more.  /contracts/SavingAccount.sol#L211-L218  struct LiquidationVars {  // address token;  // uint256 tokenPrice;  // uint256 coinValue;  uint256 borrowerCollateralValue;  // uint256 tokenAmount;  // uint256 tokenDivisor;  uint256 msgTotalBorrow;  contracts/Accounts.sol#L341-L345  if(token != ETH_ADDR) {  divisor = 10**uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(token));  // globalConfig.bank().newRateIndexCheckpoint(token);  power = power.add(getDepositBalanceCurrent(token, _borrower)  Many usage of console.log() and also the commented import on most of the contracts  // import \"@nomiclabs/buidler/console.sol\";  ...  //console.log(\"tokenNum\", tokenNum);  /contracts/Accounts.sol#L426-L429  // require(  //     totalBorrow.mul(100) <= totalCollateral.mul(liquidationDiscountRatio),  //     \"Collateral is not sufficient to be liquidated.\"  // );  /contracts/registry/TokenRegistry.sol#L298-L306  // function _isETH(address _token) public view returns (bool) {  //     return globalConfig.constants().ETH_ADDR() == _token;  // }  // function getDivisor(address _token) public view returns (uint256) {  //     if(_isETH(_token)) return INT_UNIT;  //     return 10 ** uint256(getTokenDecimals(_token));  // }  /contracts/registry/TokenRegistry.sol#L118-L121  // require(_borrowLTV != 0, \"Borrow LTV is zero\");  require(_borrowLTV < SCALE, \"Borrow LTV must be less than Scale\");  // require(liquidationThreshold > _borrowLTV, \"Liquidation threshold must be greater than Borrow LTV\");  Recommendation  In many of the above examples, it s not clear if the commented code is for testing or obsolete code (e.g. in the last example, can _borrowLTV ==0?) . All these instances should be reviewed and the system should be fully tested for all edge cases after the code changes.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "4.6 Price volatility may compromise system integrity   ", "body": "  Resolution  Comment from DeFiner team:  The issue says that due to price volatility there could be an attack on DeFiner. However, price volatility is inherent in the Cryptocurrency ecosystem. All the other lending platforms like MakerDAO, Compound and AAVE also designed like that, in case of price volatility(downside) more liquidation happens on these platforms as well. Liquidations are in a sense good to keep the market stable. If there is no liquidation during those market crash, the system will be at risk. Due to this, it is always recommended to maintain the collateral and borrow ratio by the user. A user should keep checking his risk in the time when the market crashes.  Description  SavingAccount.borrow allows users to borrow funds from the bank. The funds borrowed may be denominated in any asset supported by the system-wide TokenRegistry. Borrowed funds come from the system s existing liquidity: other users  deposits.  Borrowing funds is an instant process. Assuming the user has sufficient collateral to service the borrow request (as well as any existing loans), funds are sent to the user immediately:  code/contracts/SavingAccount.sol:L130-L140  function borrow(address _token, uint256 _amount) external onlySupportedToken(_token) onlyEnabledToken(_token) whenNotPaused nonReentrant {  require(_amount != 0, \"Borrow zero amount of token is not allowed.\");  globalConfig.bank().borrow(msg.sender, _token, _amount);  // Transfer the token on Ethereum  SavingLib.send(globalConfig, _amount, _token);  emit Borrow(_token, msg.sender, _amount);  Users may borrow up to their  borrow power , which is the sum of their deposit balance for each token, multiplied by each token s borrowLTV, multiplied by the token price (queried from a chainlink oracle):  code/contracts/Accounts.sol:L344-L349  // globalConfig.bank().newRateIndexCheckpoint(token);  power = power.add(getDepositBalanceCurrent(token, _borrower)  .mul(globalConfig.tokenInfoRegistry().priceFromIndex(i))  .mul(globalConfig.tokenInfoRegistry().getBorrowLTV(token)).div(100)  .div(divisor)  );  If users borrow funds, their position may be liquidated via SavingAccount.liquidate. An account is considered liquidatable if the total value of borrowed funds exceeds the total value of collateral (multiplied by some liquidation threshold ratio). These values are calculated similarly to  borrow power:  the sum of the deposit balance for each token, multiplied by each token s borrowLTV, multiplied by the token price as determined by chainlink.  Conclusion  The instant-borrow approach, paired with the chainlink oracle represents a single point of failure for the Definer system. When the price of any single supported asset is sufficiently volatile, the entire liquidity held by the system is at risk as borrow power and collateral value become similarly volatile.  Some users may find their borrow power skyrocket and use this inflated value to drain large amounts of system liquidity they have no intention of repaying. Others may find their held collateral tank in value and be subject to sudden liquidations.  ", "labels": ["Consensys", "Medium", "Won't Fix"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "4.7 Emergency withdrawal code present ", "body": "  Description  Code and functionality for emergency stop and withdrawal is present in this code base.  Examples  /contracts/lib/SavingLib.sol#L43-L48  // ============================================  // EMERGENCY WITHDRAWAL FUNCTIONS  // Needs to be removed when final version deployed  // ============================================  function emergencyWithdraw(GlobalConfig globalConfig, address _token) public {  address cToken = globalConfig.tokenInfoRegistry().getCToken(_token);  ...  /contracts/SavingAccount.sol#L307-L309  function emergencyWithdraw(address _token) external onlyEmergencyAddress {  SavingLib.emergencyWithdraw(globalConfig, _token);  /contracts/config/Constant.sol#L7-L8  ...  address payable public constant EMERGENCY_ADDR = 0xc04158f7dB6F9c9fFbD5593236a1a3D69F92167c;  ...  Recommendation  To remove the emergency code and fully test all the affected contracts.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "4.8 Accounts contains expensive looping ", "body": "  Description  Accounts.getBorrowETH performs multiple external calls to GlobalConfig and TokenRegistry within a for loop:  code/contracts/Accounts.sol:L381-L397  function getBorrowETH(  address _accountAddr  ) public view returns (uint256 borrowETH) {  uint tokenNum = globalConfig.tokenInfoRegistry().getCoinLength();  //console.log(\"tokenNum\", tokenNum);  for(uint i = 0; i < tokenNum; i++) {  if(isUserHasBorrows(_accountAddr, uint8(i))) {  address tokenAddress = globalConfig.tokenInfoRegistry().addressFromIndex(i);  uint divisor = INT_UNIT;  if(tokenAddress != ETH_ADDR) {  divisor = 10 ** uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(tokenAddress));  borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, _accountAddr).mul(globalConfig.tokenInfoRegistry().priceFromIndex(i)).div(divisor));  return borrowETH;  The loop also makes additional external calls and delegatecalls from:  TokenRegistry.priceFromIndex:  code/contracts/registry/TokenRegistry.sol:L281-L289  function priceFromIndex(uint index) public view returns(uint256) {  require(index < tokens.length, \"coinIndex must be smaller than the coins length.\");  address tokenAddress = tokens[index];  // Temp fix  if(Utils._isETH(address(globalConfig), tokenAddress)) {  return 1e18;  return uint256(globalConfig.chainLink().getLatestAnswer(tokenAddress));  Accounts.getBorrowBalanceCurrent:  code/contracts/Accounts.sol:L313-L331  function getBorrowBalanceCurrent(  address _token,  address _accountAddr  ) public view returns (uint256 borrowBalance) {  AccountTokenLib.TokenInfo storage tokenInfo = accounts[_accountAddr].tokenInfos[_token];  uint accruedRate;  if(tokenInfo.getBorrowPrincipal() == 0) {  return 0;  } else {  if(globalConfig.bank().borrowRateIndex(_token, tokenInfo.getLastBorrowBlock()) == 0) {  accruedRate = INT_UNIT;  } else {  accruedRate = globalConfig.bank().borrowRateIndexNow(_token)  .mul(INT_UNIT)  .div(globalConfig.bank().borrowRateIndex(_token, tokenInfo.getLastBorrowBlock()));  return tokenInfo.getBorrowBalance(accruedRate);  In a worst case scenario, each iteration may perform a maximum of 25+ calls/delegatecalls. Assuming a maximum tokenNum of 128 (TokenRegistry.MAX_TOKENS), the gas cost for this method may reach upwards of 2 million for external calls alone.  Given that this figure would only be a portion of the total transaction gas cost, getBorrowETH may represent a DoS risk within the Accounts contract.  Recommendation  Avoid for loops unless absolutely necessary  Where possible, consolidate multiple subsequent calls to the same contract to a single call, and store the results of calls in local variables for re-use. For example,  Instead of this:  uint tokenNum = globalConfig.tokenInfoRegistry().getCoinLength();  for(uint i = 0; i < tokenNum; i++) {  if(isUserHasBorrows(_accountAddr, uint8(i))) {  address tokenAddress = globalConfig.tokenInfoRegistry().addressFromIndex(i);  uint divisor = INT_UNIT;  if(tokenAddress != ETH_ADDR) {  divisor = 10 ** uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(tokenAddress));  borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, _accountAddr).mul(globalConfig.tokenInfoRegistry().priceFromIndex(i)).div(divisor));  Modify TokenRegistry to support a single call, and cache intermediate results like this:  TokenRegistry registry = globalConfig.tokenInfoRegistry();  uint tokenNum = registry.getCoinLength();  for(uint i = 0; i < tokenNum; i++) {  if(isUserHasBorrows(_accountAddr, uint8(i))) {  // here, getPriceFromIndex(i) performs all of the steps as the code above, but with only 1 ext call  borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, _accountAddr).mul(registry.getPriceFromIndex(i)).div(divisor));  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "4.9 Naming inconsistency ", "body": "  Description  There are some inconsistencies in the naming of some functions with what they do.  Examples  /contracts/registry/TokenRegistry.sol#L272-L274  function getCoinLength() public view returns (uint256 length) { //@audit-info coin vs token  return tokens.length;  Recommendation  Review the code for the naming inconsistencies.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2021/02/definer/"}, {"title": "5.1 PeriodicPrizeStrategy - RNG failure can lock user funds ", "body": "  Description  To prevent manipulation of the SortitionSumTree after a requested random number enters the mempool, users are unable to withdraw funds while the strategy contract waits on a random number request between execution of startAward() and completeAward().  If an rng request fails, however, there is no way to exit this locked state. After an rng request times out, only startAward() can be called, which will make another rng request and re-enter the same locked state. The rng provider can also not be updated while the contract is in this state. If the rng provider fails permanently, user funds are permanently locked.  Examples  requireNotLocked() prevents transfers, deposits, or withdrawals when there is a pending award.  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L282-L285  function beforeTokenTransfer(address from, address to, uint256 amount, address controlledToken) external override onlyPrizePool {  if (controlledToken == address(ticket)) {  _requireNotLocked();  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L528-L531  function _requireNotLocked() internal view {  uint256 currentBlock = _currentBlock();  require(rngRequest.lockBlock == 0 || currentBlock < rngRequest.lockBlock, \"PeriodicPrizeStrategy/rng-in-flight\");  setRngService() reverts if there is a pending or timed-out rng request  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L413-L414  function setRngService(RNGInterface rngService) external onlyOwner {  require(!isRngRequested(), \"PeriodicPrizeStrategy/rng-in-flight\");  Recommendation  Instead of forcing the pending award phase to be re-entered in the event of an rng request time-out, provide an exitAwardPhase() function that ends the award phase without paying out the award. This will at least allow users to withdraw their funds in the event of a catastrophic failure of the rng service. It may also be prudent to allow the rng service to be updated in the event of an rng request time out.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.2 LootBox - Unprotected selfdestruct in proxy implementation ", "body": "  Description  When the LootBoxController is deployed, it also deploys an instance of LootBox. When someone calls LootBoxController.plunder() or LootBoxController.executeCall() the controller actually deploys a temporary proxy contract to a deterministic address using create2, then calls out to it to collect the loot.  The LootBox implementation contract is completely unprotected, exposing all its functionality to any actor on the blockchain. The most critical functionality is actually the LootBox.destroy() method that calls selfdestruct() on the implementation contract.  Therefore, an unauthenticated user can selfdestruct the LootBox proxy implementation and cause the complete system to become dysfunctional. As an effect, none of the AirDrops that were delivered based on this contract will be redeemable (Note: create2 deploy address is calculated from the current contract address and salt). Funds may be lost.  Examples  code/loot-box/contracts/LootBoxController.sol:L28-L31  constructor () public {  lootBoxActionInstance = new LootBox();  lootBoxActionBytecode = MinimalProxyLibrary.minimalProxy(address(lootBoxActionInstance));  code/loot-box/contracts/LootBox.sol:L86-L90  /// @notice Destroys this contract using `selfdestruct`  /// @param to The address to send remaining Ether to  function destroy(address payable to) external {  selfdestruct(to);  not in scope but listed for completeness  code/pool/contracts/counterfactual-action/CounterfactualAction.sol:L7-L21  contract CounterfactualAction {  function depositTo(address payable user, PrizePool prizePool, address output, address referrer) external {  IERC20 token = IERC20(prizePool.token());  uint256 amount = token.balanceOf(address(this));  token.approve(address(prizePool), amount);  prizePool.depositTo(user, amount, output, referrer);  selfdestruct(user);  function cancel(address payable user, PrizePool prizePool) external {  IERC20 token = IERC20(prizePool.token());  token.transfer(user, token.balanceOf(address(this)));  selfdestruct(user);  Recommendation  Enforce that only the deployer of the contract can call functionality in the contract. Make sure that nobody can destroy the implementation of proxy contracts.  ", "labels": ["Consensys", "Critical"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.3 Ticket duplication ", "body": "  Description  Ticket._beforeTokenTransfer() contains logic to update the SortitionSumTree from which prize winners are drawn. In the case where the from address is the same as the to address, tickets are duplicated rather than left unchanged. This allows any attacker to duplicate their tickets with no limit and virtually guarantee that they will win all awarded prizes.  code/pool/contracts/token/Ticket.sol:L71-L79  if (from != address(0)) {  uint256 fromBalance = balanceOf(from).sub(amount);  sortitionSumTrees.set(TREE_KEY, fromBalance, bytes32(uint256(from)));  if (to != address(0)) {  uint256 toBalance = balanceOf(to).add(amount);  sortitionSumTrees.set(TREE_KEY, toBalance, bytes32(uint256(to)));  This code was outside the scope of our review but was live on mainnet at the time the issue was disovered. We immediately made the client aware of the issue and an effort was made to mitigate the impact on the existing deployment.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.4 PeriodicPriceStrategy - trustedForwarder can impersonate any msg.sender ", "body": "  Description  The centralization of power to allow one account to impersonate other components and roles (owner, listener, prizePool) in the system is a concern by itself and may give users pause when deciding whether to trust the contract system. The fact that the trustedForwarder can spoof events for any msg.sender may also make it hard to keep an accurate log trail of events in case of a security incident.  Note: The same functionality seems to be used in ControlledToken and other contracts which allows the trustedForwarder to assume any tokenholder in ERC20UpgradeSafe. There is practically no guarantee to ControlledToken holders.  Note: The trustedForwarder/msgSender() pattern is used in multiple contracts, many of which are not in the scope of this assessment.  Examples  access control modifiers that can be impersonated  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L588-L591  modifier onlyPrizePool() {  require(_msgSender() == address(prizePool), \"PeriodicPrizeStrategy/only-prize-pool\");  _;  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L565-L568  modifier onlyOwnerOrListener() {  require(_msgSender() == owner() || _msgSender() == address(periodicPrizeStrategyListener), \"PeriodicPrizeStrategy/only-owner-or-listener\");  _;  event msg.sender that can be spoofed because the actual msg.sender can be trustedForwarder  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L164-L164  emit PrizePoolOpened(_msgSender(), prizePeriodStartedAt);  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L340-L340  emit PrizePoolAwardStarted(_msgSender(), address(prizePool), requestId, lockBlock);  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L356-L357  emit PrizePoolAwarded(_msgSender(), randomNumber);  emit PrizePoolOpened(_msgSender(), prizePeriodStartedAt);  _msgSender() implementation allows the trustedForwarder to impersonate any msg.sender address  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L541-L551  /// @dev Provides information about the current execution context for GSN Meta-Txs.  /// @return The payable address of the message sender  function _msgSender()  internal  override(BaseRelayRecipient, ContextUpgradeSafe)  virtual  view  returns (address payable)  return BaseRelayRecipient._msgSender();  // File: @opengsn/gsn/contracts/BaseRelayRecipient.sol  ...  /**  return the sender of this call.  if the call came through our trusted forwarder, return the original sender.  otherwise, return `msg.sender`.  should be used in the contract anywhere instead of msg.sender  /  function _msgSender() internal override virtual view returns (address payable ret) {  if (msg.data.length >= 24 && isTrustedForwarder(msg.sender)) {  // At this point we know that the sender is a trusted forwarder,  // so we trust that the last bytes of msg.data are the verified sender address.  // extract sender address from the end of msg.data  assembly {  ret := shr(96,calldataload(sub(calldatasize(),20)))  } else {  return msg.sender;  Recommendation  Remove the trustedForwarder or restrict the type of actions the forwarder can perform and don t allow it to impersonate other components in the system. Make sure users understand the trust assumptions and who has what powers in the system. Make sure to keep an accurate log trail of who performed which action on whom s behalf.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.5 Unpredictable behavior for users due to admin front running or general bad timing ", "body": "  Description  In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.  Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.  In general users of the system should have assurances about the behavior of the action they re about to take.  Examples  An administrator (deployer) of MultipleWinners can change the number of winners in the system without warning. This has the potential to violate a security goal of the system.  admin can change the number of winners during a prize-draw period  code/pool/contracts/prize-strategy/multiple-winners/MultipleWinners.sol:L38-L42  function setNumberOfWinners(uint256 count) external onlyOwner {  __numberOfWinners = count;  emit NumberOfWinnersSet(count);  PeriodicPriceStrategy - admin may switch-out RNG service at any time (when RNG is not in inflight or timed-out)  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L413-L418  function setRngService(RNGInterface rngService) external onlyOwner {  require(!isRngRequested(), \"PeriodicPrizeStrategy/rng-in-flight\");  rng = rngService;  emit RngServiceUpdated(address(rngService));  PeriodicPriceStrategy - admin can effectively disable the rng request timeout by setting a high value during a prize-draw (e.g. to indefinitely block payouts)  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L420-L422  function setRngRequestTimeout(uint32 _rngRequestTimeout) external onlyOwner {  _setRngRequestTimeout(_rngRequestTimeout);  PeriodicPriceStrategy - admin may set new tokenListener which might intentionally block token-transfers  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L175-L179  function setTokenListener(TokenListenerInterface _tokenListener) external onlyOwner {  tokenListener = _tokenListener;  emit TokenListenerUpdated(address(tokenListener));  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L360-L364  function setPeriodicPrizeStrategyListener(address _periodicPrizeStrategyListener) external onlyOwner {  periodicPrizeStrategyListener = PeriodicPrizeStrategyListener(_periodicPrizeStrategyListener);  emit PeriodicPrizeStrategyListenerSet(_periodicPrizeStrategyListener);  out of scope but mentioned as a relevant example: PrizePool owner can set new PrizeStrategy at any time  code/pool/contracts/prize-pool/PrizePool.sol:L1003-L1008  /// @notice Sets the prize strategy of the prize pool.  Only callable by the owner.  /// @param _prizeStrategy The new prize strategy  function setPrizeStrategy(address _prizeStrategy) external override onlyOwner {  _setPrizeStrategy(TokenListenerInterface(_prizeStrategy));  a malicious admin may remove all external ERC20/ERC721 token awards prior to the user claiming them (admin front-running opportunity)  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L461-L464  function removeExternalErc20Award(address _externalErc20, address _prevExternalErc20) external onlyOwner {  externalErc20s.removeAddress(_prevExternalErc20, _externalErc20);  emit ExternalErc20AwardRemoved(_externalErc20);  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L506-L510  function removeExternalErc721Award(address _externalErc721, address _prevExternalErc721) external onlyOwner {  externalErc721s.removeAddress(_prevExternalErc721, _externalErc721);  delete externalErc721TokenIds[_externalErc721];  emit ExternalErc721AwardRemoved(_externalErc721);  the PeriodicPrizeStrategy owner (also see concerns outlined in issue 5.4) can transfer external ERC20 at any time to avoid them being awarded to users. there is no guarantee to the user.  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L517-L526  function transferExternalERC20(  address to,  address externalToken,  uint256 amount  external  onlyOwner  prizePool.transferExternalERC20(to, externalToken, amount);  Recommendation  The underlying issue is that users of the system can t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.  We recommend giving the user advance notice of changes with a time lock. For example, make all system-parameter and upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period. This allows users that do not accept the change to withdraw immediately.  ", "labels": ["Consensys", "Major"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.6 PeriodicPriceStrategy - addExternalErc721Award duplicate or invalid tokenIds may block award phase ", "body": "  Description  The prize-strategy owner (or a listener) can add ERC721 token awards by calling addExternalErc721Award providing the ERC721 token address and a list of tokenIds owned by the prizePool.  The method does not check if duplicate tokenIds or tokenIds that are not owned by the contract are provided. This may cause an exception when _awardExternalErc721s calls prizePool.awardExternalERC721 to transfer an invalid or previously transferred token, blocking the award phase.  Note: An admin can recover from this situation by removing and re-adding the ERC721 token from the awards list.  Examples  adding tokenIds  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L478-L499  /// @notice Adds an external ERC721 token as an additional prize that can be awarded  /// @dev Only the Prize-Strategy owner/creator can assign external tokens,  /// and they must be approved by the Prize-Pool  /// NOTE: The NFT must already be owned by the Prize-Pool  /// @param _externalErc721 The address of an ERC721 token to be awarded  /// @param _tokenIds An array of token IDs of the ERC721 to be awarded  function addExternalErc721Award(address _externalErc721, uint256[] calldata _tokenIds) external onlyOwnerOrListener {  // require(_externalErc721.isContract(), \"PeriodicPrizeStrategy/external-erc721-not-contract\");  require(prizePool.canAwardExternal(_externalErc721), \"PeriodicPrizeStrategy/cannot-award-external\");  if (!externalErc721s.contains(_externalErc721)) {  externalErc721s.addAddress(_externalErc721);  for (uint256 i = 0; i < _tokenIds.length; i++) {  uint256 tokenId = _tokenIds[i];  require(IERC721(_externalErc721).ownerOf(tokenId) == address(prizePool), \"PeriodicPrizeStrategy/unavailable-token\");  externalErc721TokenIds[_externalErc721].push(tokenId);  emit ExternalErc721AwardAdded(_externalErc721, _tokenIds);  awarding tokens  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L248-L263  /// @notice Awards all external ERC721 tokens to the given user.  /// The external tokens must be held by the PrizePool contract.  /// @dev The list of ERC721s is reset after every award  /// @param winner The user to transfer the tokens to  function _awardExternalErc721s(address winner) internal {  address currentToken = externalErc721s.start();  while (currentToken != address(0) && currentToken != externalErc721s.end()) {  uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));  if (balance > 0) {  prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);  delete externalErc721TokenIds[currentToken];  currentToken = externalErc721s.next(currentToken);  externalErc721s.clearAll();  transferring the tokens  code/pool/contracts/prize-pool/PrizePool.sol:L582-L606  /// @notice Called by the prize strategy to award external ERC721 prizes  /// @dev Used to award any arbitrary NFTs held by the Prize Pool  /// @param to The address of the winner that receives the award  /// @param externalToken The address of the external NFT token being awarded  /// @param tokenIds An array of NFT Token IDs to be transferred  function awardExternalERC721(  address to,  address externalToken,  uint256[] calldata tokenIds  external override  onlyPrizeStrategy  require(_canAwardExternal(externalToken), \"PrizePool/invalid-external-token\");  if (tokenIds.length == 0) {  return;  for (uint256 i = 0; i < tokenIds.length; i++) {  IERC721(externalToken).transferFrom(address(this), to, tokenIds[i]);  emit AwardedExternalERC721(to, externalToken, tokenIds);  Recommendation  Ensure that no duplicate token-ids were provided or skip over token-ids that are not owned by prize-pool (anymore).  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.7 PeriodicPrizeStrategy - Token with callback related warnings (ERC777 a.o.) ", "body": "  Description  This issue is highly dependent on the configuration of the system. If an admin decides to allow callback enabled token (e.g. ERC20 compliant ERC777 or other ERC721/ERC20 extensions) as awards then one recipient may be able to  block the payout for everyone by forcing a revert in the callback when accepting token awards  use the callback to siphon gas, mint gas token, or similar activities  potentially re-enter the PrizeStrategy contract in an attempt to manipulate the payout (e.g. by immediately withdrawing from the pool to manipulate the 2nd ticket.draw())  Examples  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L252-L263  function _awardExternalErc721s(address winner) internal {  address currentToken = externalErc721s.start();  while (currentToken != address(0) && currentToken != externalErc721s.end()) {  uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));  if (balance > 0) {  prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);  delete externalErc721TokenIds[currentToken];  currentToken = externalErc721s.next(currentToken);  externalErc721s.clearAll();  Recommendation  It is highly recommended to not allow tokens with callback functionality into the system. Document and/or implement safeguards that disallow the use of callback enabled tokens. Consider implementing means for the  other winners  to withdraw their share of the rewards independently from others.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.8 PeriodicPrizeStrategy - unbounded external tokens linked list may be used to force a gas DoS ", "body": "  Description  The size of the linked list of ERC20/ERC721 token awards is not limited. This fact may be exploited by an administrative account by adding an excessive number of external token addresses.  The winning user might want to claim their win by calling completeAward() which fails in one of the _distribute() -> _awardAllExternalTokens() ->  _awardExternalErc20s/_awardExternalErc721s while loops if too many token addresses are configured and gas consumption hits the block gas limit (or it just gets too expensive for the user to call).  Note: an admin can recover from this situation by removing items from the list.  Examples  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L436-L448  /// @notice Adds an external ERC20 token type as an additional prize that can be awarded  /// @dev Only the Prize-Strategy owner/creator can assign external tokens,  /// and they must be approved by the Prize-Pool  /// @param _externalErc20 The address of an ERC20 token to be awarded  function addExternalErc20Award(address _externalErc20) external onlyOwnerOrListener {  _addExternalErc20Award(_externalErc20);  function _addExternalErc20Award(address _externalErc20) internal {  require(prizePool.canAwardExternal(_externalErc20), \"PeriodicPrizeStrategy/cannot-award-external\");  externalErc20s.addAddress(_externalErc20);  emit ExternalErc20AwardAdded(_externalErc20);  code/pool/contracts/utils/MappedSinglyLinkedList.sol:L46-L53  /// @param newAddress The address to shift to the front of the list  function addAddress(Mapping storage self, address newAddress) internal {  require(newAddress != SENTINEL && newAddress != address(0), \"Invalid address\");  require(self.addressMap[newAddress] == address(0), \"Already added\");  self.addressMap[newAddress] = self.addressMap[SENTINEL];  self.addressMap[SENTINEL] = newAddress;  self.count = self.count + 1;  awarding the tokens loops through the linked list of configured tokens  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L248-L263  /// @notice Awards all external ERC721 tokens to the given user.  /// The external tokens must be held by the PrizePool contract.  /// @dev The list of ERC721s is reset after every award  /// @param winner The user to transfer the tokens to  function _awardExternalErc721s(address winner) internal {  address currentToken = externalErc721s.start();  while (currentToken != address(0) && currentToken != externalErc721s.end()) {  uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));  if (balance > 0) {  prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);  delete externalErc721TokenIds[currentToken];  currentToken = externalErc721s.next(currentToken);  externalErc721s.clearAll();  Recommendation  Limit the number of tokens an admin can add. Consider implementing an interface that allows the user to claim tokens one-by-one or in user-configured batches.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.9 MultipleWinners - setNumberOfWinners does not enforce count>0 ", "body": "  Description  The constructor of MultipleWinners enforces that the argument _numberOfWinners > 0 while setNumberOfWinners does not. A careless or malicious admin might set __numberOfWinners to zero to cause the distribute() method to throw and not pay out any winners.  Examples  enforced in the constructor  code/pool/contracts/prize-strategy/multiple-winners/MultipleWinners.sol:L34-L34  require(_numberOfWinners > 0, \"MultipleWinners/num-gt-zero\");  not enforced when updating the value at a later stage  code/pool/contracts/prize-strategy/multiple-winners/MultipleWinners.sol:L38-L42  function setNumberOfWinners(uint256 count) external onlyOwner {  __numberOfWinners = count;  emit NumberOfWinnersSet(count);  Recommendation  Require that numberOfWinners > 0.  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.10 LootBox - plunder should disallow plundering to address(0) ", "body": "  Description  Note:  Depending on the token implementation, transfers may or may not revert if the toAddress == address(0), while burning the ETH will succeed.  This might allow anyone to  forcefully burn received ETH that would otherwise be available to the future beneficiary  If the airdrop and transfer of LootBox ownership are not done within one transaction, this might open up a front-running window that allows a third party to burn air-dropped ETH before it can be claimed by the owner.  consider one component issues the airdrop in one transaction (or block) and setting the owner in a later transaction (or block). The owner is unset for a short duration of time which might allow anyone to burn ETH held by the LootBox proxy instance.  Examples  plunder() receiving the owner of an ERC721.tokenId  code/loot-box/contracts/LootBoxController.sol:L49-L56  function plunder(  address erc721,  uint256 tokenId,  IERC20[] calldata erc20s,  LootBox.WithdrawERC721[] calldata erc721s,  LootBox.WithdrawERC1155[] calldata erc1155s  ) external {  address payable owner = payable(IERC721(erc721).ownerOf(tokenId));  The modified ERC721 returns address(0) if the owner is not known  code/loot-box/contracts/external/openzeppelin/ERC721.sol:L102-L107  While withdraw[ERC20|ERC721|ERC1155] fail with to == address(0), transferEther() succeeds and burns the eth by sending it to  address(0)  @dev See {IERC721-ownerOf}.  /  function ownerOf(uint256 tokenId) public view override returns (address) {  return _tokenOwners[tokenId];  While withdraw[ERC20|ERC721|ERC1155] fail with to == address(0), transferEther() succeeds and burns the eth by sending it to  address(0)  code/loot-box/contracts/LootBox.sol:L74-L84  function plunder(  IERC20[] memory erc20,  WithdrawERC721[] memory erc721,  WithdrawERC1155[] memory erc1155,  address payable to  ) external {  _withdrawERC20(erc20, to);  _withdrawERC721(erc721, to);  _withdrawERC1155(erc1155, to);  transferEther(to, address(this).balance);  Recommendation  Require that the destination address to in plunder() and transferEther() is not address(0).  ", "labels": ["Consensys", "Medium"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.11 PeriodicPrizeStrategy - Inconsistent behavior between award-phase modifiers and view functions ", "body": "  Description  The logic in the canStartAward() function is inconsistent with that of the requireCanStartAward modifier, and the logic in the canCompleteAward() function is inconsistent with that of the requireCanCompleteAward modifier. Neither of these view functions appear to be used elsewhere in the codebase, but the similarities between the function names and the corresponding modifiers is highly misleading.  Examples  canStartAward() is inconsistent with requireCanStartAward  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L377-L379  function canStartAward() external view returns (bool) {  return _isPrizePeriodOver() && !isRngRequested();  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L575-L579  modifier requireCanStartAward() {  require(_isPrizePeriodOver(), \"PeriodicPrizeStrategy/prize-period-not-over\");  require(!isRngRequested() || isRngTimedOut(), \"PeriodicPrizeStrategy/rng-already-requested\");  _;  canCompleteAward() is inconsistent with requireCanCompleteAward  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L383-L385  function canCompleteAward() external view returns (bool) {  return isRngRequested() && isRngCompleted();  code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L581-L586  modifier requireCanCompleteAward() {  require(_isPrizePeriodOver(), \"PeriodicPrizeStrategy/prize-period-not-over\");  require(isRngRequested(), \"PeriodicPrizeStrategy/rng-not-requested\");  require(isRngCompleted(), \"PeriodicPrizeStrategy/rng-not-complete\");  _;  Recommendation  Make the logic consistent between the view functions and the modifiers of the same name or remove the functions.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.12 MultipleWinners - Awards can be guaranteed with a set number of tickets ", "body": "  Description  Because additional award drawings are distributed at a constant interval in the SortitionSumTree by MultipleWinners._distribute(), any user that holds a number of tickets >= floor(totalSupply / __numberOfWinners) can guarantee at least one award regardless of the initial drawing.  MultipleWinners._distribute():  code/pool/contracts/prize-strategy/multiple-winners/MultipleWinners.sol:L59-L65  uint256 ticketSplit = totalSupply.div(__numberOfWinners);  uint256 nextRandom = randomNumber.add(ticketSplit);  // the other winners receive their prizeShares  for (uint256 winnerCount = 1; winnerCount < __numberOfWinners; winnerCount++) {  winners[winnerCount] = ticket.draw(nextRandom);  nextRandom = nextRandom.add(ticketSplit);  Recommendation  Do not distribute awards at fixed intervals from the initial drawing, but instead randomize the additional drawings as well.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.13 MultipleWinners - Inconsistent behavior compared to SingleRandomWinner ", "body": "  Description  The MultipleWinners strategy carries out award distribution to the zero address if ticket.draw() returns address(0) (indicating an error condition) while SingleRandomWinner does not.  Examples  SingleRandomWinner silently skips award distribution if ticket.draw() returns address(0).  code/pool/contracts/prize-strategy/single-random-winner/SingleRandomWinner.sol:L8-L17  contract SingleRandomWinner is PeriodicPrizeStrategy {  function _distribute(uint256 randomNumber) internal override {  uint256 prize = prizePool.captureAwardBalance();  address winner = ticket.draw(randomNumber);  if (winner != address(0)) {  _awardTickets(winner, prize);  _awardAllExternalTokens(winner);  MultipleWinners still attempts to distribute awards if ticket.draw() returns address(0). This may or may not succeed depending on the implementation of the tokens included in the externalErc20s and externalErc721s linked lists.  code/pool/contracts/prize-strategy/multiple-winners/MultipleWinners.sol:L48-L57  function _distribute(uint256 randomNumber) internal override {  uint256 prize = prizePool.captureAwardBalance();  // main winner gets all external tokens  address mainWinner = ticket.draw(randomNumber);  _awardAllExternalTokens(mainWinner);  address[] memory winners = new address[](__numberOfWinners);  winners[0] = mainWinner;  Recommendation  Implement consistent behavior. Avoid hiding error conditions and consider throwing an exception instead.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.14 Initialize implementations for proxy contracts and protect initialization methods ", "body": "  Description  Any situation where the implementation of proxy contracts can be initialized by third parties should be avoided. This can be the case if the initialize function is unprotected or not initialized immediately after deployment. Since the implementation contract is not meant to be used directly without a proxy delegate-calling to it, it is recommended to protect the initialization method of the implementation by initializing on deployment.  This affects all proxy implementations (the delegatecall target contract) deployed in the system.  Examples  The implementation for MultipleWinners is not initialized. Even though not directly used by the system it may be initialized by a third party.  code/pool/contracts/prize-strategy/multiple-winners/MultipleWinnersProxyFactory.sol:L13-L15  constructor () public {  instance = new MultipleWinners();  The deployed ERC721Contract is not initialized.  code/loot-box/contracts/ERC721ControlledFactory.sol:L25-L29  constructor () public {  erc721ControlledInstance = new ERC721Controlled();  erc721ControlledBytecode = MinimalProxyLibrary.minimalProxy(address(erc721ControlledInstance));  The deployed LootBox is not initialized.  code/loot-box/contracts/LootBoxController.sol:L28-L31  constructor () public {  lootBoxActionInstance = new LootBox();  lootBoxActionBytecode = MinimalProxyLibrary.minimalProxy(address(lootBoxActionInstance));  Recommendation  Initialize unprotected implementation contracts in the implementation s constructor. Protect initialization methods from being called by unauthorized parties or ensure that deployment of the proxy and initialization is performed in the same transaction.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.15 LootBox - transferEther should be internal ", "body": "  Description  LootBox.transferEther() can be internal as it is only called from LootBox.plunder() and the LootBox(proxy) instances are generally very short-living (created and destroyed within one transaction).  Examples  code/loot-box/contracts/LootBox.sol:L63-L67  function transferEther(address payable to, uint256 amount) public {  to.transfer(amount);  emit TransferredEther(to, amount);  Recommendation  Restrict transferEther() s visibility to internal.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.16 LootBox - executeCalls can be misused to relay calls ", "body": "  Description  Note: allows non-value and value calls (deposits can be forces via selfdestruct)  Examples  code/loot-box/contracts/LootBox.sol:L52-L58  function executeCalls(Call[] calldata calls) external returns (bytes[] memory) {  bytes[] memory response = new bytes[](calls.length);  for (uint256 i = 0; i < calls.length; i++) {  response[i] = _executeCall(calls[i].to, calls[i].value, calls[i].data);  return response;  Recommendation  Restrict access to call forwarding functionality to trusted entities. Consider implementing the Ownable pattern allowing access to functionality to the owner only.  ", "labels": ["Consensys", "Minor"], "html_url": "https://consensys.io/diligence/audits/2020/11/pooltogether-lootbox-and-multiplewinners-strategy/"}, {"title": "5.1 Reactivated gauges can t queue up rewards    ", "body": "  Resolution                           Fixed in   fei-protocol/flywheel-v2@e765d24 by making it so all gauges are always included in cycles, thus keeping in sync their  Description  Active gauges as set in ERC20Gauges.addGauge() function by authorised users get their rewards queued up in the FlywheelGaugeRewards._queueRewards() function. As part of it, their associated struct QueuedRewards updates its storedCycle value to the cycle in which they get queued up:  code-flywheel-v2/src/rewards/FlywheelGaugeRewards.sol:L202-L206  gaugeQueuedRewards[gauge] = QueuedRewards({  priorCycleRewards: queuedRewards.priorCycleRewards + completedRewards,  cycleRewards: uint112(nextRewards),  storedCycle: currentCycle  });  Once reactivated later with at least 1 full cycle being done without it, it will produce issues. It will now be returned by gaugeToken.gauges() to be processed in either FlywheelGaugeRewards.queueRewardsForCycle()or FlywheelGaugeRewards.queueRewardsForCyclePaginated(), but, once the reactivated gauge is passed to _queueRewards(), it will fail an assert:  code-flywheel-v2/src/rewards/FlywheelGaugeRewards.sol:L196  assert(queuedRewards.storedCycle == 0 || queuedRewards.storedCycle >= lastCycle);  This is because it already has a set value from the cycle it was processed in previously (i.e. storedCycle>0), and, since that cycle is at least 1 full cycle behind the state contract, it will also not pass the second condition queuedRewards.storedCycle >= lastCycle.  The result is that this gauge is locked out of queuing up for rewards because queuedRewards.storedCycle is only synchronised with the contract s cycle later in _queueRewards() which will now always fail for this gauge.  Recommendation  Account for the reactivated gauges that previously went through the rewards queue process, such as introducing a separate flow for newly activated gauges. However, any changes such as removing the above mentioned assert() should be carefully validated for other downstream logic that may use the QueuedRewards.storedCycle value. Therefore, it is recommended to review the state transitions as opposed to only passing this specific check.  ", "labels": ["Consensys", "Major", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2022/04/tribe-dao-flywheel-v2-xtribe-xerc4626/"}, {"title": "5.2 Reactivated gauges have incorrect accounting for the last cycle s rewards    ", "body": "  Resolution                           Fixed in   fei-protocol/flywheel-v2@e765d24 by making it so all gauges are always included in cycles, thus keeping in sync their  Description  As described in issue 5.1, reactivated gauges that previously had queued up rewards have a mismatch between their storedCycle and contract s gaugeCycle state variable.  Due to this mismatch, there is also a resulting issue with the accounting logic for its completed rewards:  code-flywheel-v2/src/rewards/FlywheelGaugeRewards.sol:L198  uint112 completedRewards = queuedRewards.storedCycle == lastCycle ? queuedRewards.cycleRewards : 0;  Consequently, this then produces an incorrect value for QueuedRewards.priorCycleRewards:  code-flywheel-v2/src/rewards/FlywheelGaugeRewards.sol:L203  priorCycleRewards: queuedRewards.priorCycleRewards + completedRewards,  As now completedRewards will be equal to 0 instead of the previous cycle s rewards for that gauge. This may cause a loss of rewards accounted for this gauge as this value is later used in getAccruedRewards().  Recommendation  Consider changing the logic of the check so that storedCycle values further in the past than lastCycle may produce the right rewards return for this expression, such as using <= instead of == and adding an explicit check for storedCycle == 0 to account for the initial scenario.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2022/04/tribe-dao-flywheel-v2-xtribe-xerc4626/"}, {"title": "5.3 Lack of input validation in delegateBySig    ", "body": "  Resolution                           Fixed in   fei-protocol/flywheel-v2@e765d24 by reverting for  Description  ERC20MultiVotes.sol makes use of ecrecover() in delegateBySig to return the address of the message signer. ecrecover() typically returns address(0x0) to indicate an error; however, there s no zero address check in the function logic. This might not be exploitable though, as delegate(0x0, arbitraryAddress) might always return zero votes (in freeVotes). Additionally, ecrecover() can be forced to return a random address by messing with the parameters. Although this is extremely rare and will likely resolve to zero free votes most times, this might return a random address and delegate someone else s votes.  Examples  code-flywheel-v2/src/token/ERC20MultiVotes.sol:L364-L387  function delegateBySig(  address delegatee,  uint256 nonce,  uint256 expiry,  uint8 v,  bytes32 r,  bytes32 s  ) public {  require(block.timestamp <= expiry, \"ERC20MultiVotes: signature expired\");  address signer = ecrecover(  keccak256(  abi.encodePacked(  \"\\x19\\x01\",  DOMAIN_SEPARATOR(),  keccak256(abi.encode(DELEGATION_TYPEHASH, delegatee, nonce, expiry))  ),  v,  r,  );  require(nonce == nonces[signer]++, \"ERC20MultiVotes: invalid nonce\");  _delegate(signer, delegatee);  Recommendation  Introduce a zero address check i.e require signer!=address(0) and check if the recovered signer is an expected address. Refer to ERC20 s permit for inspiration.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2022/04/tribe-dao-flywheel-v2-xtribe-xerc4626/"}, {"title": "5.4 Decreasing maxGauges does not account for users  previous gauge list size.    ", "body": "  Resolution                           Fixed in   fei-protocol/flywheel-v2@e765d24 by documenting.  Description  ERC20Gauges contract has a maxGauges state variable meant to represent the maximum amount of gauges a user can allocate to. As per the natspec, it is meant to protect against gas DOS attacks upon token transfer to allow complicated transactions to fit in a block. There is also a function setMaxGauges for authorised users to decrease or increase this state variable.  code-flywheel-v2/src/token/ERC20Gauges.sol:L499-L504  function setMaxGauges(uint256 newMax) external requiresAuth {  uint256 oldMax = maxGauges;  maxGauges = newMax;  emit MaxGaugesUpdate(oldMax, newMax);  Recommendation  Either document the potential discrepancy between the user gauges size and the maxGauges state variable, or limit maxGauges to be only called within the contract thereby forcing other contracts to retrieve user gauge list size through numUserGauges().  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2022/04/tribe-dao-flywheel-v2-xtribe-xerc4626/"}, {"title": "5.5 Decrementing a gauge by 0 that is not in the user gauge list will fail an assert.    ", "body": "  Resolution                           Fixed in   fei-protocol/flywheel-v2@e765d24 by implementing auditor s recommendation.  Description  ERC20Gauges._decrementGaugeWeight has an edge case scenario where a user can attempt to decrement a gauge that is not in the user gauge list by 0 weight, which would trigger a failure in an assert.  code-flywheel-v2/src/token/ERC20Gauges.sol:L333-L345  function _decrementGaugeWeight(  address user,  address gauge,  uint112 weight,  uint32 cycle  ) internal {  uint112 oldWeight = getUserGaugeWeight[user][gauge];  getUserGaugeWeight[user][gauge] = oldWeight - weight;  if (oldWeight == weight) {  // If removing all weight, remove gauge from user list.  assert(_userGauges[user].remove(gauge));  code-flywheel-v2/src/token/ERC20Gauges.sol:L339-L341  uint112 oldWeight = getUserGaugeWeight[user][gauge];  getUserGaugeWeight[user][gauge] = oldWeight - weight;  However, passing a weight=0 parameter with a gauge that doesn t belong to the user, would successfully process that line. This would then be followed by an evaluation if (oldWeight == weight), which would also succeed since both are 0, to finally reach an assert that will verify a remove of that gauge from the user gauge list. However, it will fail since it was never there in the first place.  code-flywheel-v2/src/token/ERC20Gauges.sol:L344  assert(_userGauges[user].remove(gauge));  Although an edge case with no effect on contract state s health, it may happen with front end bugs or incorrect user transactions, and it is best not to have asserts fail.  Recommendation  Replace assert() with a require() or verify that the gauge belongs to the user prior to performing any operations.  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2022/04/tribe-dao-flywheel-v2-xtribe-xerc4626/"}, {"title": "5.6 Undelegating 0 votes from an address who is not a delegate of a user will fail an assert.    ", "body": "  Resolution                           Fixed in   fei-protocol/flywheel-v2@e765d24 by implementing auditor s recommendation.  Description  Similar scenario with issue 5.5. ERC20MultiVotes._undelegate has an edge case scenario where a user can attempt to undelegate from a delegatee that is not in the user delegates list by 0 amount, which would trigger a failure in an assert.  code-flywheel-v2/src/token/ERC20MultiVotes.sol:L251-L260  function _undelegate(  address delegator,  address delegatee,  uint256 amount  ) internal virtual {  uint256 newDelegates = _delegatesVotesCount[delegator][delegatee] - amount;  if (newDelegates == 0) {  assert(_delegates[delegator].remove(delegatee)); // Should never fail.  code-flywheel-v2/src/token/ERC20MultiVotes.sol:L256  uint256 newDelegates = _delegatesVotesCount[delegator][delegatee] - amount;  However, passing a amount=0 parameter with a delegatee that doesn t belong to the user, would successfully process that line. This would then be followed by an evaluation if (newDelegates == 0), which would succeed, to finally reach an assert that will verify a remove of that delegatee from the user delegates list. However, it will fail since it was never there in the first place.  code-flywheel-v2/src/token/ERC20MultiVotes.sol:L259  assert(_delegates[delegator].remove(delegatee)); // Should never fail.  Although an edge case with no effect on contract state s health, it may happen with front end bugs or incorrect user transactions, and it is best not to have asserts fail, as per the dev comment in that line  // Should never fail .  Recommendation  Replace assert() with a require() or verify that the delegatee belongs to the user prior to performing any operations.  6 Findings: xTRIBE  ", "labels": ["Consensys", "Minor", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2022/04/tribe-dao-flywheel-v2-xtribe-xerc4626/"}, {"title": "6.1 xTRIBE.emitVotingBalances - DelegateVotesChanged event can be emitted by anyone    ", "body": "  Resolution                           Fixed in   fei-protocol/xTRIBE@ea9705b by adding authentication.  Description  xTRIBE.emitVotingBalances is an external function without authentication constraints. It means anyone can call it and emit DelegateVotesChanged which may impact other layers of code that rely on these events.  Examples  code-xTRIBE/src/xTRIBE.sol:L89-L99  function emitVotingBalances(address[] calldata accounts) external {  uint256 size = accounts.length;  for (uint256 i = 0; i < size; ) {  emit DelegateVotesChanged(accounts[i], 0, getVotes(accounts[i]));  unchecked {  i++;  Recommendation  Consider restricting access to this function for allowed accounts only.  ", "labels": ["Consensys", "Medium", "Fixed"], "html_url": "https://consensys.io/diligence/audits/2022/04/tribe-dao-flywheel-v2-xtribe-xerc4626/"}]