[{"title": "Invalid Gas Accounting", "body": "The bootloader reverses the last two parameters when calling ZKSYNC_NEAR_CALL_callPostOp. This causes the pubdata allowance check to significantly overestimate the pubdata cost and underestimate the gas limit. Consequently, transactions that specify a paymaster and consume pubdata would likely fail this check, incorrectly reverting the postTransaction changes.  Consider correcting the parameter order.  Update: Resolved in pull request #316.", "html_url": "https://blog.openzeppelin.com/zk-stack-vm1.5-diff-audit#invalid-gas-accounting", "labels": ["OpenZeppelin"]}, {"title": "Skipped Transaction Processing", "body": "The audit commit inadvertently removed the processL2Tx function invocation. If deployed, the bootloader would not process any L2 transactions. Consider restoring the invocation.  Update: Resolved in pull request #316.  Low Severity", "html_url": "https://blog.openzeppelin.com/zk-stack-vm1.5-diff-audit#skipped-transaction-processing", "labels": ["OpenZeppelin"]}, {"title": "Misleading Comments", "body": "We have identified the following examples of misleading comments:  The gasBoundCall function description mentions a BOUND_CALL_OVERHEAD constant, which does not exist in the codebase.  The sendToL1 function contains an inline comment that refers to removed code.  The _processL2Logs function contains an outdated comment describing the wrong number of logs.  The computeGas parameter to the isNotEnoughGasForPubdata function is described as \"The amount of gas spent on the computation\", but it is actually the amount of execution gas remaining that can still be spent on future computation.  The askOperatorForRefund function comment no longer describes the correct inputs.  The getPubdataPublishedFromMeta function comment has correctly renamed the return value but still describes the old value. Similarly, the offset constant it uses also refers to the old value.  Consider correcting or clarifying these comments.  Update: Resolved in pull request #344.", "html_url": "https://blog.openzeppelin.com/zk-stack-vm1.5-diff-audit#misleading-comments", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are several values that do not have docstrings:  The new _pubdataToSpend parameter (1, 2).  Both parameters for the setPubdataInfo function. The description also only covers the first parameter.  The new gas parameters (1, 2, 3, 4, 5, 6, 7, 8, 9, 10).  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #346.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/zk-stack-vm1.5-diff-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Typographical errors", "body": "We identified the following typographical errors. Consider correcting them.  \"wouldbn't\" should be \"wouldn't\".  both instances (1, 2) of \"a most\" should be \"at most\".  \"decomit\" should be \"decommit\".  \"not\" should be \"no\".  \"baseSepnt\" should be \"baseSpent\".  Update: Resolved in pull request #347.", "html_url": "https://blog.openzeppelin.com/zk-stack-vm1.5-diff-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Naming suggestions", "body": "The pubdataPrice and pubdataCost variables are measured in gas, not ETH. For clarity, consider renaming them to pubdataGasRate and pubdataGas respectively.  Update: Resolved in pull request #348.", "html_url": "https://blog.openzeppelin.com/zk-stack-vm1.5-diff-audit#naming-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Code simplifications", "body": "Here are some suggestions for code simplifications:  Instead of copying values individually from calldata, a single calldatacopy instruction could be used.  Instead of using an exclusive upper bound to identify blob hash keys, using the last relevant key as the upper bound would be clearer.  There are multiple places (1, 2, 3) where the new saturatingSub function could be used.  Update: Resolved in pull request #349.", "html_url": "https://blog.openzeppelin.com/zk-stack-vm1.5-diff-audit#code-simplifications", "labels": ["OpenZeppelin"]}, {"title": "swapTokens Function Is Unusable", "body": "_depositToCoreLendingPool function has a  swapTokens function which also has a  Consider removing the nonReentrant modifier from the internal _depositToCoreLendingPool function. Additionally, consider implementing unit testing to ensure that the function executes properly.  Update: Resolved in pull request #60 at commit c35716e.  High Severity", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#swaptokens-function-is-unusable", "labels": ["OpenZeppelin"]}, {"title": "Potential Reentrancy in emergencyWithdraw", "body": "emergencyWithdraw function, the  check which prevents double withdrawals is at the top of the function. However, the value representing \"has withdrawn\" is only set  at the bottom of the function, after  the assets are transferred to the user. Importantly, since  are not burned at this step, if the underlying asset has a hook on transfer, a user could potentially reenter this function and withdraw again, multiple times.  Consider setting the user's withdrawn status directly below the check at the top of the function. Alternatively, consider implementing a non-reentrant modifier onto the emergencyWithdraw function. Finally, consider vetting all tokens and ensuring that any tokens added to the Riz system do not have hooks on transfer and cannot be upgraded to have them in the future.  Update: Resolved in pull request #61 at commit bd13afe. The emergencyWithdraw function now sets the status on the holder just after checking it.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#potential-reentrancy-in-emergencywithdraw", "labels": ["OpenZeppelin"]}, {"title": "Data For Swap Might Not Match Its Inputs", "body": "calculate the total value going into the trade using the array of input assets and their amounts. Later, the  DEX is called, passing all the inputs and the  only the bytes data is used to perform the swap operations.  This means that there is a disconnection between the inputs passed to the swapTokens function and what the DEX will be using for the actual swap. Moreover, the rest of the inputs passed to the DexSwapStrategy library can be independently used as part of the attack to grant allowance on some other asset stored in the contract to then proceed with the attack. Even though the entry point is access-controlled, any whitelisted user could take advantage of that power and craft the data (and the right conditions, such as creating a pair for the swap using a token controlled by them and the desired asset) to get funds from the contract.  Consider constraining the encoding of the inputs passed to the swapTokens function to prevent the possibility of crafting undesired routes and to reduce the attack surface of the functionality.  Update: Acknowledged, not resolved. The Radiant team stated:  We acknowledge this issue but believe that there is a low chance of anything malicious happening due to the restrictions already imposed. The only addresses which are granted whitelist permission are the addresses we call for the swaps. In our case, these are 1inch's AggregationRouter and Paraswap's AugustusSwapper. We also revoke approvals before the end of the function.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#data-for-swap-might-not-match-its-inputs", "labels": ["OpenZeppelin"]}, {"title": "Duplicated Elements in Configuration Could Return the Wrong Amount During Swaps", "body": "The RevenueManagement contract implements functionality which allows users to swap the tokens deposited in the contract for a specific list of output tokens with pre-defined ratios. The sum of such ratios must equal 10_000 (or 100%) during the setup.  However, when computing that sum, the setOutputTokensConfig function does not take into consideration the possibility of having repeated elements in the _outputTokens input array. As a result, two problems arise:  The configuration of the repeated element will be same as that of its last repeated instance.  The calculations performed during the swap will include the same element twice but with the configuration of the last repeated instance. This can potentially skew the 100% limitation.  To prevent erroneous transactions during the swap after a faulty setup is not caught by the current validation, consider checking that there are no repeated elements in the _outputTokens input array.  Update: Resolved in pull request #63 at commit a98e99e.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#duplicated-elements-in-configuration-could-return-the-wrong-amount-during-swaps", "labels": ["OpenZeppelin"]}, {"title": "Old Distributions May Still Exist After Updating", "body": "Within the YRizStrategy contract, the setFullPoolDistributions function changes the content of the _distributions mapping via the _setPoolDistribution function.  However, in the event that newDistros.length is less than the number of previous elements in the _distributions mapping, the elements which exceed the length of newDistros will never be overwritten nor deleted in the _setPoolDistribution function.  This means that if there is a reconfiguration of distributions where the number of distributions decreases, some of these old distributions may still appear valid, and functions such as getUiKeeperPoolBalances, getAllPoolDistributions, and _deployFunds may behave unintuitively and may move funds in unexpected ways.  detect invalid pools early in loops.  Update: Resolved in pull request #100 at commit e15ba56.  Medium Severity", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#old-distributions-may-still-exist-after-updating", "labels": ["OpenZeppelin"]}, {"title": "Deactivating Reserves Has Improper Checks", "body": "_checkNoLiquidity function checks the  balance of the underlying asset in the aToken contract. This is paired with a  check on the liquidity rate being zero. The  setting a reserve's liquidation threshold to 0 and when  setting a reserve to \"inactive\". The goal of this function appears to be to check whether a reserve is currently unused. However, in the case that all deposited assets are currently borrowed, the  balance check can still return 0. In this case, a reserve may be deactivated or removed as a collateral while it still has borrows. If it is deactivated, those borrows will not be repayable due to the check  of isActive within validateRepay.  Consider changing the logic of _checkNoLiquidity to check that there are no open borrows and that no assets are currently deposited.  Update: Acknowledged, not resolved. The Radiant team stated:  We have thoroughly reviewed this issue and acknowledge it. We have decided not to take any action because reserve deactivation will be unlikely in our case since Riz will mostly have two asset-pairs only.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#deactivating-reserves-has-improper-checks", "labels": ["OpenZeppelin"]}, {"title": "Looping Fees Can Be Bypassed", "body": "The RizLeverager contract implements functionality allowing users to loop over their positions. To do this, users must specify several parameters including the number of loops, the borrow ratio for each loop, and the amount. However, by having control over these values, a user might pass a high loop count with a small amount value and a borrow ratio of 100%. As a result, due to how fees are calculated on line 209 and line 227, if the amount value is small enough, the fee will be zero for all the operations. It is worth noting that even though the fee would be zero, the gas cost associated with the process will increase. Nonetheless, this attack might be more potent in networks that have a lower gas fee which could result in a break-even net result.  Consider always rounding up the fee calculations.  Update: Resolved in pull request #88 at commit ba21d2e.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#looping-fees-can-be-bypassed", "labels": ["OpenZeppelin"]}, {"title": "Potential Overflow", "body": "bytesToSwapData function of the  single, insufficient check on rawData.length. This check ensures that  later on in the function, it is assumed that rawData.length >= 160. In the case that  the subtraction will fail silently.  Consider changing the initial check to check that the length is at least 160. Alternatively, consider handling inputs whose length is shorter than 160.  Update: Resolved in pull request #81 at commit 4d61055. The length validation now uses 160.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#potential-overflow", "labels": ["OpenZeppelin"]}, {"title": "Junk Data May Be Returned from getAllPoolDistributions", "body": "Within the YRizStrategy contract, the getAllPoolDistributions function may return data which is not useful. This data could be interpreted incorrectly by contracts that call the getAllDistributions function and lead to unexpected behavior.  pool value set to 0. This should generally correspond to an invalid or uninitialized distribution. Once this is detected, the loop which is  constructing the return value of  break, but crucially, the  returned distributions array will contain the invalid configuration at its end. Note that this is only the case if the  less than maxRizPools number of configurations.In this case, an invalid set of  Consider first checking whether the _distributions element is initialized, and then writing to distributions, rather than doing it in the opposite order.  Update: Resolved in pull request #52. The Radiant team stated:  Added a variable which will hold all the valid distributions. We loop through those instead of the max Riz pools.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#junk-data-may-be-returned-from-getallpooldistributions", "labels": ["OpenZeppelin"]}, {"title": "Native Asset Not Accounted for When Swapping", "body": "In the swapTokens function, the computeInputValue function only totals the values of swap inputs which are ERC20 tokens. It does not include the value field of data, which will be sent when performing the swap.  Since the call within DexSwapStrategy performs an arbitrary call, it can have any target and any parameters. So, it easily could be used to receive ETH and send it to a different address.  However, this is complicated by the fact that the RevenueManagement contract has no payable functions.  Consider including a receive function within RevenueManagement and including native assets within the total input value computations. Alternatively, consider entirely removing the ability to send the native asset within the DexSwapStrategy contract.  Update: Resolved in pull request #53. The Radiant team stated:  Removed the ability to send the native asset in the swap and added an if check to make sure the value != 0.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#native-asset-not-accounted-for-when-swapping", "labels": ["OpenZeppelin"]}, {"title": "Missing Checks on Transferred Amounts of Tokens", "body": "Within the codebase, there are many places where ERC-20 tokens are transferred either into or out of the protocol. In the case that they are being transferred in, there is a chance that some behavior results in fewer tokens than expected being transferred. This could be the case if the token charges a fee on transfer.  The following places have transfers without corresponding checks on the amount transferred:  Line 150 of RizLendingPool  Line 573 of RizLockZap  Line 585 of RizLockZap  Line 400 of RizRegistry  Line 208 of RizLeverager  Line 211 of RizLeverager  Line 229 of RizLeverager  Line 328 of RizLendingPool  Line 835 of TokenizedStrategy  Consider implementing a balance check before and after each of the above transfers, and confirming that the desired number of tokens have been received.  Update: Acknowledged, not resolved. The Radiant team stated:  Acknowledged. We think we can accept that transactions are reverting in case there is not much liquidity to transfer. SafeLib also has some descriptive error messages in case a transfer fails.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#missing-checks-on-transferred-amounts-of-tokens", "labels": ["OpenZeppelin"]}, {"title": "Lack of Liquidity Check", "body": "In the RizLendingPool contract, within the withdraw and the borrow functions, there are no checks which confirm the existence of liquidity in the market. In the case that a user attempts to withdraw or borrow more assets than the pool has, the transaction is likely to revert upon transferring to the user. However, this may not be obvious to users. In addition, since tokens can implement arbitrary logic, it is possible that the call does not revert but the user receives significantly less than expected.  Consider implementing a check at the beginning of these functions to ensure that the desired withdrawal or borrow amount is available in the lending pool.  Update: Acknowledged, not resolved. The Radiant team stated:  We think that we have never had any checks for token balances during deposits/withdrawals. Aave v2 does not have them either. We think we can accept that transactions are still reverting in case there are not enough token balances.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#lack-of-liquidity-check", "labels": ["OpenZeppelin"]}, {"title": "Erroneous Condition in _setAssetSource", "body": "check being done over the  Consider correcting this check to be meaningful and disallow the feedId from being 0.  Update: Resolved in pull request #80 at commit cf84c06. The Radiant team stated:  Removed the check for CL feed address when we set Pyth in the Router.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#erroneous-condition-in-_setassetsource", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Checks in addPool", "body": "LENDING_POOL_ADDRESSES_PROVIDER and BAD_DEBT_MANAGER are initialized. However, this function also depends on  LENDING_POOL,  LENDING_POOL_CONFIGURATOR, and  BAD_DEBT_MANAGER being initialized in  Since all of the aforementioned initializations are necessary, consider including them in the check at the beginning of the addPool function.  Update: Resolved in pull request #66 at commit bac3658.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#insufficient-checks-in-addpool", "labels": ["OpenZeppelin"]}, {"title": "Distribution Changes Can Be Delayed or Prevented", "body": "setFullPoolDistribution function allows a new set of \"distributions\" to be set up for the strategy. Old distributions can be removed and new distributions can be added. Inside the  _checkPoolsWithBalanceAreIncluded function, pools where the  cannot be removed. If any pool which is being removed has a balance at this point, the entire call will revert. This can be taken advantage of by a bad actor to delay or prevent changes to the distribution set. Any user may front-run calls to  Consider implementing an automated withdrawal from the removed pools, rather than a reversion when its balance differs from zero.  Update: Resolved in pull request #100 at commit e15ba56.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#distribution-changes-can-be-delayed-or-prevented", "labels": ["OpenZeppelin"]}, {"title": "Erroneous Validation After Market Shutdown", "body": "shutdown, the  updateLendingPoolStatus function from the  addressProvider address is a valid address in the  pool was registered in the  set it to the false state. However, since the flag in the  \"skipping\" check done in the  Consider setting the _isValidAddressProvider mapping to false when status == false within updateLendingPoolStatus and handling that state when used.  Update: Resolved in pull request #89 at commit d2728a7.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#erroneous-validation-after-market-shutdown", "labels": ["OpenZeppelin"]}, {"title": "ETH For Oracle Fees Can Be Front-Run", "body": "receive function used for getting the ETH for  paying the fees in Pyth. As the  updateUnderlyingPrices method is not  Consider making the updateUnderlyingPrices function payable or encapsulating both calls to prevent using the ETH for another price update.  Update: Resolved in pull request #79 at commit fe24699.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#eth-for-oracle-fees-can-be-front-run", "labels": ["OpenZeppelin"]}, {"title": "Off-by-One Possible in deployFunds", "body": "_deployFunds function there could be an off-by-one error due to  rounding. Consider the case where two assets have  _amount is 10001. In this case, the  amount for both will be  Since distributions should be descending, consider transferring the remaining balance for the final asset instead of computing the amount using bps.  Update: Resolved in pull request #94 at commit f8d4889.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#off-by-one-possible-in-deployfunds", "labels": ["OpenZeppelin"]}, {"title": "Possible Revert In _depositToCoreLendingPool", "body": "Within the _depositToCoreLendingPool function, the call to lendingPool.deposit could potentially pass an _amount of 0, causing the validateDeposit function to fail.  Consider implementing a check to skip the entire _depositToCoreLendingPool call if actualTokens == 0.  Update: Resolved in pull request #84 at commit b25bc7a.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#possible-revert-in-_deposittocorelendingpool", "labels": ["OpenZeppelin"]}, {"title": "Allowance Could Cause a Denial of Service During Loops", "body": "The RizLeverager contract implements the functionality to loop over positions and increase both the deposit and debt at the same time. To do so, it must approve the lending pool for taking the particular asset. Such approvals check if the allowance is zero in the lending pool and the treasury before raising it to the maximum.  However, depending on the assets and how they are looped over, it might be possible for them to reach an artificially high value, which would gradually reduce the allowance. This might happen with assets that do not have a full uint256 range for the allowance, since the storage slot is shared with another variable (e.g., a slot containing the balance and the allowance in the same 256 bits). The problem arising from this would be that even with a small, non-zero value as the allowance, the _approve function will not raise the allowance back to the maximum value. Thus, the transaction will fail as it will not have enough allowance to proceed. When the allowance drops below the value that will be used for the loop (which primarily depends on the number of loops and the amount), the allowance should be raised again.  Consider checking the value that will be used as a whole during the loop against the current allowance and raising it again if needed. This will help prevent transactions from failing with certain assets.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#allowance-could-cause-a-denial-of-service-during-loops", "labels": ["OpenZeppelin"]}, {"title": "Shutdown Is Not Irreversible", "body": "The Riz protocol is meant for riskier assets and supports a feature whereby a shutdown can be triggered to then slash the positions and redistribute the remaining funds after the bad debt has been socialized. However, even though the shutdown state cannot currently be changed after it has been triggered, most of the modules in the market are upgradeable. As such, these modules might call an upgraded implementation that would de-shutdown the state.  In order to follow the specs of being completely and irreversibly shut down, consider preventing any shutdown markets from being upgraded.  Update: Acknowledged, not resolved. The Radiant team stated:  Noted. If a shutdown happens, we will need to burn admin access to all the proxies in that specific Riz market. Making the proxy bricked might be slightly more complicated.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#shutdown-is-not-irreversible", "labels": ["OpenZeppelin"]}, {"title": "Modules Can Be Connected to Implementation", "body": "In the RizLendingPoolAddressesProvider contract, the _addresses mapping stores all the module addresses against their respective ids, whether they are proxy instances or contracts. Typically, to retrieve or update one of these modules, the contract uses a function that eventually calls the _updateImpl function. This function either deploys a new proxy and stores it in the mapping, or updates the proxy to point to the new implementation.  However, some methods bypass this mechanism and allow for manually setting the target address where the address provider will be redirecting the calls to. For instance, the setLendingPoolCollateralManager and the general setAddress functions directly overwrite the address for the respective id. This can lead to issues if the contract owner manually sets the address to the implementation instead of the proxy. In such cases, the market might use the implementation contract directly which may not have all the parameters set up correctly. Since there are no checks to validate whether the new address is a proxy or the underlying implementation, the present setup of links between modules is error-prone and can adversely affect the protocol.  Where applicable, consider implementing validation to ensure that the new address is always a proxy and not the underlying implementation.  Update: Acknowledged, not resolved. The Radiant team stated:  We have fixed setAddress to always check whether address(0) has been passed as the input. We acknowledge this and want to use it as it is since we can quickly fix it even if we pass something wrong through our multi-sig configuration.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#modules-can-be-connected-to-implementation", "labels": ["OpenZeppelin"]}, {"title": "setAddress Could Reset Module Storage", "body": "The _updateImpl function of the RizLendingPoolAddressesProvider contract deploys a new proxy when the _addresses mapping has a zero value for the particular id. Otherwise, it makes a call to the deployed proxy to initiate the upgrade to the new implementation.  However, if the owner calls the setAddress function with a zero value for the particular id and then upgrades the implementation of the module, the contract will read the zero address, create a new proxy, and start the storage from scratch in that module. This would reset all stored data for that module, potentially causing functionality to become stuck or users to lose funds.  As the _updateImpl function already takes into account whether a proxy has been deployed or not, consider either removing the manual setAddress functionality from the code, or restricting its parameter to any implementation besides the zero address.  Update: Resolved in pull request #82 at commit 8e7584e. The setAddress function no longer accepts the zero address as input.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#setaddress-could-reset-module-storage", "labels": ["OpenZeppelin"]}, {"title": "Order of Operations Will Reduce Output Precision", "body": "In the EmergencyWithdraw library, the code gets the amount of tokens owed to the user for each reserve in the market. The mentioned operation results in:  (valueInUSD[i] / priceAsset[i]) * DEFAULT_DENOMINATOR  However, because the division operation comes first, the value in assets will be rounded down by the price and then the result will be multiplied up by DEFAULT_DENOMINATOR (1e18). This means that it will have 18 ending zeros and part of the precision of the operation will be lost.  Consider swapping the operations to improve the precision of the result.  Update: Resolved in pull request #83 at commit c92e990.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#order-of-operations-will-reduce-output-precision", "labels": ["OpenZeppelin"]}, {"title": "Emergency Withdrawal Conditions Might Change Over Time", "body": "shut down, the  takes a snapshot through the  prices in the particular lending pool and also calculate the ratio for slashing the remaining users who still possess some positive net worth in the market.  In case an asset becomes problematic or the prices cannot be trusted due to market dynamics, the owner of the BadDebtManager contract can still modify the snapshot data after the initial snapshot. However, there is no restriction on when and how many times this data can be modified. In particular, the owner can alter the parameters, especially the slashing ratio, after some users have already proceeded with emergency withdrawals, resulting in unfairness towards the users before and after this change. Moreover, the contract owner can front-run users' withdrawals and change the parameters before those are executed.  In favor of having fair debt socialization, consider using a short time window, perhaps a single day, in which the owner can adjust the values after the snapshot, and after that change is made, values cannot be modified. In addition, consider limiting the number of times the snapshot data can be modified within this window, ideally to a maximum of one time.  Update: Acknowledged, not resolved. The Radiant team stated:  Acknowledged. We want to leave as much room for adjustments as possible for this one, as there is a large room for errors when things go really bad. The BadDebtManager is the last resort for users to withdraw funds, and we might even need to run snapshots and votes in order to set the proper data if that is ever needed. We will discuss this internally and check if we need to do anything.  Low Severity", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#emergency-withdrawal-conditions-might-change-over-time", "labels": ["OpenZeppelin"]}, {"title": "Unchecked transfer/transferFrom Call", "body": "Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior. For instance, in the _depositToCoreLendingPool function of the RevenueManagement contract, the transfer call is unchecked.  Consider using the SafeERC20 OpenZeppelin library to perform safe token transfers in the mentioned case and in other similar situations.  Update: Resolved in pull request #71. The Radiant team stated:  We are now using safeTransfer for depositToCoreLendingPool.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unchecked-transfer/transferfrom-call", "labels": ["OpenZeppelin"]}, {"title": "Unused Constant", "body": "The following instance of unused constant was identified and can be removed:  The BIPS_DIVISOR constant declared in RizLendingPool and in RizLendingPoolConfigurator  Consider removing any unused constant to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #49. The Radiant team stated:  We removed the unused constant.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unused-constant", "labels": ["OpenZeppelin"]}, {"title": "Unsafe Casts", "body": "Throughout the codebase, there are instances of unsafe casts.  The uint256 cast in the OracleRouter contract  The uint256 cast in the OracleRouter contract  The uint8 cast in the RizLendingPoolConfigurator contract  The uint8 cast in the RizLendingPoolConfigurator contract  The uint8 cast in the RizLendingPoolConfigurator contract  To avoid unexpected behavior, consider ensuring the values being casted are in the expected type range before being casted and use informative error messages in case they are not within acceptable ranges.  Update: Resolved in pull request #72. The Radiant team stated:  Added checks before casting.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unsafe-casts", "labels": ["OpenZeppelin"]}, {"title": "RizLeverager Could Fail During loop", "body": "In the loop function of RizLeverager, the division by the RATIO_DIVISOR can return 0 in some cases. Due to the requirement that the amount cannot be 0 for validating deposits and borrows, this could cause a revert.  Consider exiting the loop early if the computed amount is 0. This will have the same effect but without reverting and will help save gas as well.  Update: Resolved in pull request #73. The Radiant team stated:  We now break from the loop early if amount == 0.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#rizleverager-could-fail-during-loop", "labels": ["OpenZeppelin"]}, {"title": "Docstrings Referencing Previous Authors", "body": "Within the codebase, some files have been forked from other projects, namely Aave and Yearn. However, the docstrings in these files still reference the previous projects. As a result, these docstrings have also become outdated.  The RizLendingPool contract has outdated @title, outdated @dev, and outdated @author tags.  The RizLendingPoolAddressesProvider contract has outdated @title, outdated @dev and outdated @author tags.  The RizLendingPoolConfigurator contract has outdated @title, outdated @author, and outdated @dev tags.  Consider updating all docstrings to reflect the changes that have been made since forking the code.  Update: Resolved in pull request #78. The Radiant team stated:  Updated the docstrings in the recommended contracts.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#docstrings-referencing-previous-authors", "labels": ["OpenZeppelin"]}, {"title": "Chainlink Feeds Cannot Have More Than 18 Decimals", "body": "Within OracleRouter, a subtraction of chainlink's decimals is performed inside _getChainlinkPrice. If the decimals from the chainlink aggregator exceed 18, then this operation will fail non-descriptively.  Consider implementing an informative error message which is returned when the decimals exceed 18. Alternatively, consider adding logic to format prices with greater than 18 decimals.  Update: Acknowledged, not resolved. The Radiant team stated:  Acknowledged. We find this scenario to be very unlikely.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#chainlink-feeds-cannot-have-more-than-18-decimals", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "Throughout the codebase, there are several instances of incomplete docstrings. For example:  The mappings within RevenueManagement.sol  The batchInitReserve function within RizLendingPoolConfigurator.sol  Many state variables and constants within RizRegistry.sol  Note that these are just a few examples and not an exhaustive list.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of a contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #96. The Radiant team stated:  Added docstrings/NatSpec at various places.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Pyth Feeds Exponent Unchecked", "body": "Within the OracleRouter contract, a subtraction of Pyth's expo value is performed inside the _getPythPrice function. If the expo from Pyth's return exceed 18 or are less than -18, then this will fail non-descriptively.  Consider implementing an informative error message which is returned when abs(priceData.expo) > 18. Alternatively, consider adding logic to format prices with exponents outside of [-18,18].  Update: Resolved in pull request #92 at commit 3f0fdc0.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#pyth-feeds-exponent-unchecked", "labels": ["OpenZeppelin"]}, {"title": "Only One Type of swapStrategy", "body": "Within the swapTokens function in RevenueManagement.sol, if the provided swapStrategy value is not specified (i.e., is 0), it will be considered of type AGGREGATOR. This is because the SwapStrategies enum has only one value.  To prevent invalid swapStrategy values from being successful in the future, consider adding a buffer as the first element of the enum, like NONE or UNSPECIFIED.  Update: Resolved in pull request #86. The Radiant team stated:  Added NONE as the first option in the struct.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#only-one-type-of-swapstrategy", "labels": ["OpenZeppelin"]}, {"title": "Unused Errors", "body": "Within the codebase, there are instances of unused errors:  Within RizRegistry.sol, the TransferFailed error  Within Errors.sol, the ETHTransferFailed error  Consider removing the unused errors.  Update: Resolved in pull request #87. The Radiant team stated:  Removed unused errors.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unused-errors", "labels": ["OpenZeppelin"]}, {"title": "Lack of Event Emission", "body": "Throughout the codebase, there are instances of missing event emissions:  In the RizRegistry contract, the configureReserveAsCollateral function triggers the CollateralConfigurationChanged event inside the RizLendingPoolConfigurator contract. However, it does not trigger an analogous event that also emits the RizLendingPoolAddressesProvider's address.  In the RizLendingPoolAddressesProvider contract, the setLiquidationFeeTo function does not emit any event. Moreover, the function calling this function from the RizRegistry contract does not emit an event either.  To improve code readability and inform about the sensitive actions happening in the protocol, consider emitting relevant events at the aforementioned places.  Update: Resolved in pull request #77. The Radiant team stated:  Added the events recommended by the audit team.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#lack-of-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Contracts Set in the Protocol Can Implement Different Logic", "body": "Throughout the codebase, there are several access-controlled actions that allow the respective roles to set/link the different modules between each other relying only (in some cases) on the fact that the passed address is a contract or not. However, even when an address might have code at it, the expected implementation might be completely different from the desired one. This could render the markets useless as expected logic will not be executed.  The functions setOracleRouter, setOracle, setReserveInterestRateStrategyAddress, setWethGateway all do not validate anything beyond whether the address being set is a contract. The function setTreasury does no validation whatsoever. All of these would benefit from checking that the interface of the input parameter contract matches what is expected.  Consider using an introspection standard to prevent scenarios in which a market is tied to an erroneous module by mistake.  Update: Partially resolved in pull request #95 at commit 13d4377. The Radiant team stated:  We have added a zero address check in the setTreasury function but have decided not to implement introspection checks in the other mentioned functions. This decision is based on our belief that the current checks are already sufficient. In addition, these functions are restricted to being called by the owner which, in our setup, is a multi-sig wallet. The multi-sig wallet requires multiple approvals for any transaction, significantly reducing the likelihood of passing incorrect data to the functions without it being noticed during the review process.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#contracts-set-in-the-protocol-can-implement-different-logic", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Coding Style", "body": "Throughout the codebase, there are instances of inconsistent coding style:  In the RizLendingPool contract, when the liquidationCall function is called, the returnCode output is compared against zero instead of using the constant assigned for it in the LendingPoolCollateralManager contract.  In the RizLendingPoolConfigurator contract, the code uses the ILendingPool interface for defining the variable type. However, as it is referring to the Riz version, the poolShutdown function needs to convert it to the IRizLendingPool interface, which has the extended methods. The same applies to the ILendingPoolAddressesProvider interface and the IRizLendingPoolAddressesProvider interface with the extended methods.  Consider fixing these inconsistencies throughout the codebase to improve code readability.  Update: Partially resolved in pull request #85 at commit c310807. The Radiant team stated:  Implemented the recommendation in RizLendingPool. For RizLendingPoolConfigurator, we decided to only change the lendingPoolAddressesProvider to the Riz interface as we would have to modify more code to be able to use IRizLendingPool on some of the methods due to incompatibility with v2-core.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#inconsistent-coding-style", "labels": ["OpenZeppelin"]}, {"title": "Unreachable State in updateLendingPoolStatus", "body": "The RizRegistry contract implements the updateLendingPoolStatus function which is used whenever a market is being shutdown. Since the function is only callable by the RizLendingPoolConfigurator contract and has a constant false as the status input there, the second parameter of the function does not serve any purpose.  Consider removing the status parameter from the updateLendingPoolStatus function if there is no possibility of using a true status.  Update: Acknowledged, not resolved. The Radiant team stated:  Acknowledged. We have decided to keep it as it is.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unreachable-state-in-updatelendingpoolstatus", "labels": ["OpenZeppelin"]}, {"title": "Initialization Chain Is Not Complete", "body": "In the RizRegistry contract, the initialize function calls the __Ownable_init hook but not the __UUPSUpgradeable_init one. Even though the __UUPSUpgradeable_init hook is currently empty, it is recommended to call it nonetheless. This would help reduce the error-proneness of the initialization of future implementations that do implement some logic in this hook.  In the initialize function of the RizRegistry contract, consider calling the __UUPSUpgradeable_init hook as well.  Update: Resolved in pull request #91 at commit 3457609.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#initialization-chain-is-not-complete", "labels": ["OpenZeppelin"]}, {"title": "Linkage of Modules and/or Markets Can Be Altered After Becoming Operational", "body": "The RizLendingPoolAddressesProvider contract allows the owner to define the marketId parameter when adding a new pool manually. In addition to this, the owner can also generally set the marketId at will. This action can cause problems if done after the market has become operational. In particular:  Once the users have started interacting with the market, the owner changing the marketId might cause linking problems in other parts of the codebase.  The marketId can be accidentally changed to that of another market.  To prevent possible breakdown of a market or the protocol, consider disabling such functionality. Alternatively, consider documenting the reasons for having this functionality while also implementing checks to detect and disallow identical marketIds.  Update: Resolved in pull request #98. The Radiant team stated:  Implemented a validation check to ensure that marketId is not empty.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#linkage-of-modules-and/or-markets-can-be-altered-after-becoming-operational", "labels": ["OpenZeppelin"]}, {"title": "WETH Gateway Works for Any Token", "body": "The RizRegistry contract implements the functionality to perform an emergency transfer of tokens on behalf of the contract owner. However, the contract being used is the WETHGateway contract and the owner can specify any token when performing such a transfer, not limited to WETH or ETH.  This can cause confusion and make the protocol error-prone, as unexpected actions can occur (such as having assets stuck in a gateway or having a different asset than WETH/ETH in a gateway meant for WETH/ETH).  Consider adapting the WETHGateway contract to reflect a more general kind of gateway, splitting the functionality into a different contract, or restricting it in the aforementioned contract.  Update: Resolved in pull request #99. The Radiant team stated:  Updated the docstring to clearly detail the function's purpose. Please note that this function is only used if an asset is stuck inside wethGateway, which is unlikely.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#weth-gateway-works-for-any-token", "labels": ["OpenZeppelin"]}, {"title": "Lack of Validation on setAddressAsProxy", "body": "it is known that passing an  As ids that might be susceptible to such problems are known, consider enforcing respective validations to prevent touching such modules with this functionality.  Update: Resolved in pull request #97. The Radiant team stated:  Implemented validation checks.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#lack-of-validation-on-setaddressasproxy", "labels": ["OpenZeppelin"]}, {"title": "OracleRouter Not Utilizing Pyth Confidence Interval", "body": "The OracleRouter reads data from Pyth without incorporating the confidence interval returned by Pyth.  In some cases, this confidence interval may be useful, to set bounds on the value of assets in the system for purposes of collateralization or liquidation, or when markets are subject to high fluctuation of prices.  Consider utilizing the Pyth returned confidence interval, or alternatively explaining why it is not needed within the documentation.  Update: Acknowledged, not resolved. The Radiant team stated:  Chainlink has no such functionality and we treat each oracle provider equally (i.e., the oracle can provide the latest prices). Also, we have doubts if we need to utilize this function in the OracleRouter.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#oraclerouter-not-utilizing-pyth-confidence-interval", "labels": ["OpenZeppelin"]}, {"title": "uint256 Casted to Enum", "body": "repay function accepts, among other parameters, the  InterestRateMode enum from the  converted back to the  Consider passing the rateMode input argument as a InterestRateMode enum type directly instead of passing it as a numerical value of type uint256.  Update: Resolved in pull request #76. The Radiant team stated:  Switched from uint256 to DataTypes.InterestRateMode enum.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#uint256-casted-to-enum", "labels": ["OpenZeppelin"]}, {"title": "Regular Dependency Used Instead of Upgradeable", "body": "The RevenueManagement contract inherits the properties of the ReentrancyGuard contract to reduce the attack surface and mitigate certain attacks. However, it is importing the regular dependency instead of the upgradeable one, as it is being done for other dependencies.  Consider using the upgradeable version of the ReentrancyGuard contract.  Update: Resolved in pull request #75. The Radiant team stated:  We are now using ReentrancyGuardUpgradeable.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#regular-dependency-used-instead-of-upgradeable", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Testing", "body": "Due to the complex nature of the system, we believe this audit would have benefited from more complete testing coverage.  While insufficient testing is not a vulnerability per se, it nonetheless implies a high probability of hidden vulnerabilities and bugs. Given the complexity of this codebase, the integration with previous versions, and the numerous interrelated risk factors, this probability is further increased. Testing provides a full, implicit specification along with the expected behaviors of the codebase, which is especially important when adding novel functionalities. A lack of testing increases the chances that correctness issues will be missed. It also results in more effort to establish basic correctness and reduces the amount of effort spent exploring edge cases, thereby increasing the chances of missing complex issues.  We recommend implementing a comprehensive multi-level test suite consisting of contract-level tests with >90% coverage and per-layer deployment, integration tests that test the deployment scripts as well as the system as a whole, and tests for planned upgrades. Crucially, the test suite should be documented in a way so that a reviewer can set up and run all these test layers independently of the development team. Furthermore, applying advanced testing over the protocol, such as invariant property testing, might have the extra benefit of finding more edge cases or patterns that might not be easy to think of while coding cases, even when using fuzzing scenarios. Also, as the codebase relies on previous versions, it would benefit both protocols to create common properties that could be shared and imported into the respective test suites. Implementing such a test suite should be a very high priority to ensure the system's robustness and reduce the risk of vulnerabilities and bugs.  Update: Acknowledged, not resolved. The Radiant team stated:  Acknowledged.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#insufficient-testing", "labels": ["OpenZeppelin"]}, {"title": "Naming Issues", "body": "Within the codebase there are a few places where names of variables or functions result in confusion. For example:  On line 399 of RizRegistry.sol, the variable reserve actually refers to an underlying asset. Consider renaming this variable to something like asset.  On line 620 of RizRegistry.sol, the function is titled _deployCopyFromFromImpl, with a repetition of the word \"from\". Consider renaming or removing this function, as it appears unused.  On line 748 of RizRegistry.sol, the variable amountInETH will actually contain a value in USD. A similar pattern is noted on line 521, but on line 748 it is not noted. Consider changing the naming or noting with comments that it will not be an ETH-denominated value.  On line 32 of EmergencyWithdraw.sol, the user performing the withdrawal is called owner. Throughout the codebase, owner is used to refer to the \"owner\" of a proxy contract. Consider renaming this parameter to \"user\" or something similar.  Consider following the above-outlined recommendation for increased code quality and clarity. Remember that any future development work may rely on these names, so having correct and descriptive naming will speed up development work and result in a lower probability of introducing bugs.  Update: Resolved in pull request #74. The Radiant team stated:  Implemented the recommendations by the audit team.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#naming-issues", "labels": ["OpenZeppelin"]}, {"title": "Unneeded WETH Functionality in RizLeverager", "body": "In the RizLeverager contract it is impossible to withdraw ETH and as a result, funds sent to it would be lost.  This stems from the integration of WETH (Wrapped ETH) as a potential \"common asset\". A payable receive function has been added to handle the WETH contract transferring ETH to the RizLeverager contract. However there would be no way to actually utilize this, since the WETH contract can only transfer ETH to the caller of the withdraw function, and there is no call to withdraw within the RizLeverager contract.  There appears to be no need for this contract to store WETH.  Consider removing this storage variable, updating the receive function to always revert, and removing code associated with WETH, such as the import of the IWETH interface, and its use within the initialize function.  Update: Resolved in pull request #51.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unneeded-weth-functionality-in-rizleverager", "labels": ["OpenZeppelin"]}, {"title": "Issues With Custom Errors", "body": "Since Solidity version 0.8.4, custom errors provide a cleaner and more cost-efficient way to explain to users why an operation failed.  TokenizedStrategy.sol file, most error handling uses literal strings instead of custom errors. In addition, within  RizLendingPool.sol,  RizLendingPoolConfigurator.sol, and  RizAToken.sol, two different contracts called  For conciseness and gas savings, consider replacing the require and revert statements with custom errors wherever they are used. Moreover, for the sake of code clarity, consider combining both of the Errors.sol files into a single file that is local to the riz github repository. This will make understanding errors and situations when they arise much easier to understand, and will prevent integration issues if changes are made to the v2-core repository.  Update: Resolved in pull request #69. The Radiant team stated:  Merged the error files into one and changed all require statements to if statements with custom errors.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#issues-with-custom-errors", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for their maintainers to contact the appropriate person about the problem and provide mitigation instructions.  Throughout the audited codebase, there are no contracts that have a security contact.  Consider adding a NatSpec comment containing a security contact above each contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #70. The Radiant team stated:  Added a security contact in each Riz contract.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Array Length Could Be Written to Stack", "body": "In the EVM, it is more gas-efficient to read values from the stack than from memory or state. In a for loop, where a value is read repeatedly, it is more efficient to write the length of an array to stack and read it from there.  Throughout the codebase, there are instances where the aforementioned optimization could be applied:  In line 128 of BadDebtManager.sol  In line 141 of BadDebtManager.sol  In line 144 of BadDebtManager.sol  In line 79 of DexSwapStrategy.sol  In line 384 of RizRegistry.sol  In line 398 of RizRegistry.sol  For gas savings, consider writing the array length to the stack (e.g., uint256 arrayLength = array.length;) and then using the arrayLength variable.  Update: Resolved in pull request #64. The Radiant team stated:  Wrote array lengths to stack before looping through them.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#array-length-could-be-written-to-stack", "labels": ["OpenZeppelin"]}, {"title": "Variable Could Be immutable", "body": "If a variable is only ever assigned a value from within the constructor of a contract, then it could be declared as immutable.  The maxRizPools state variable could be immutable.  To better convey the intended use of variables and to potentially save gas, consider adding the immutable keyword to variables that are only set in the constructor.  Update: Resolved in pull request #59. The Radiant team stated:  Made maxRizPools immutable.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#variable-could-be-immutable", "labels": ["OpenZeppelin"]}, {"title": "Return Value Not Used", "body": "The swap function of DexSwapStrategy.sol returns a uint256 value. However, the only place where this function is called does not utilize this return value.  Consider either removing it, utilizing the return value within the swapTokens function, or using comments to document why it is not being used.  Update: Resolved in pull request #55. The Radiant team stated:  Removed the unused return variable.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#return-value-not-used", "labels": ["OpenZeppelin"]}, {"title": "Redundant Use of SafeMath Library", "body": "The OpenZeppelin SafeMath library provides arithmetic functions with overflow/underflow protection, but Solidity 0.8.0 has added built-in overflow and underflow checking, supplanting the functionality provided by the library.  Throughout the codebase, the SafeMath library is being used in contracts with a Solidity version greater than 0.8.0, resulting in the addition of redundant overflow/underflow checks.  The following contracts import the SafeMath library:  EmergencyWithdraw.sol  RizLendingPool.sol  RizLendingPoolConfigurator.sol  Consider removing the SafeMath import and its associated function calls from the codebase.  Update: Resolved in pull request #50. The Radiant team stated:  Removed the SafeMath library from where it is not needed.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#redundant-use-of-safemath-library", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors were identified in the codebase:  In this sentence within the BaseStrategy.sol there is either a missing or an incorrect word.  Line 12 of PythStructs.sol should say \"use\" rather than \"how\".  Line 14 of PythStructs.sol contains a link which no longer is valid. It may have been replaced by the URL https://docs.pyth.network/price-feeds/best-practices, which is currently active.  Line 445 of RizLendingPool.sol should say \"proportional\" instead of \"proportionally\".  Line 517 of RizLockZap.sol only needs one of the words \"amount\" or \"value\".  Line 627 of TokenizedStrategy.sol says \"deposits\" when it should say \"deposit\".  Line 874 of TokenizedStrategy.sol has two periods at the end instead of one.  Line 984 of TokenizedStrategy.sol should say \"Assess\" instead of \"Asses\".  To improve readability, consider correcting typographical errors in the codebase.  Update: Resolved in pull request #54. The Radiant team stated:  Fixed all typographical errors.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Prefix Increment Operator ++i Can Save Gas in Loops", "body": "Throughout the codebase, there are multiple opportunities where this optimization could be applied.  For instance:  The i++ in BadDebtManager.sol.  The i++ in BadDebtManager.sol.  The i++ in BadDebtManager.sol.  Note that this is not an exhaustive list. Consider using the prefix increment operator ++i instead of the post-increment operator i++ in order to save gas. This optimization skips storing the value before the incremental operation, as the return value of the expression is ignored.  Update: Resolved in pull request #57 at commit 4076233.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#prefix-increment-operator-++i-can-save-gas-in-loops", "labels": ["OpenZeppelin"]}, {"title": "Unused Event", "body": "In RizRegistry.sol, the BadDebtManagerSet event is unused.  To improve the overall clarity, intentionality, and readability of the codebase, consider emitting or removing any currently unused events.  Update: Resolved in pull request #58. The Radiant team stated:  Removed the unused event.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unused-event", "labels": ["OpenZeppelin"]}, {"title": "Possible Duplicate Event Emissions", "body": "When a setter function does not check whether the value has changed, it opens up the possibility for spamming events that indicate a value change, even when no change has occurred. Spamming the same values can potentially confuse off-chain clients.  Throughout the codebase, there are multiple instances of possible event spamming:  The setParamsForEmergencyWithdrawals sets the slashingRatio and emits an event without checking if the value has changed.  The setLeverager sets the leverager and emits an event without checking if the value has changed.  The setBadDebtManager sets the badDebtManager and emits an event without checking if the value has changed.  The _setMarketId sets the _marketId and emits an event without checking if the value has changed.  The setFeePercent sets the feePercent and emits an event without checking if the value has changed.  The setTreasury sets the treasury and emits an event without checking if the value has changed.  The setCommonAsset sets the commonAsset and emits an event without checking if the value has changed.  The setUniRouter sets the uniRouter and emits an event without checking if the value has changed.  The setEmergencyAdmin sets the emergencyAdmin and emits an event without checking if the value has changed.  The setTreasury sets the treasury and emits an event without checking if the value has changed.  The setOracle sets the oracle and emits an event without checking if the value has changed.  The setDepositLimit sets the depositLimit and emits an event without checking if the value has changed.  Consider adding a check which ensures that an event is only emitted if the value has changed.  Update: Resolved in pull request #65. The Radiant team stated:  Implemented checks on the listed methods and a few extra ones which were missed.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#possible-duplicate-event-emissions", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Order Within Contracts", "body": "Throughout the codebase, there are multiple contracts that deviate from the Solidity Style Guide due to having inconsistent ordering of functions:  The OracleRouter contract in OracleRouter.sol  The RevenueManagement contract in RevenueManagement.sol  The RizLendingPool contract in RizLendingPool.sol  The RizLendingPoolAddressesProvider contract in RizLendingPoolAddressesProvider.sol  The RizLendingPoolConfigurator contract in RizLendingPoolConfigurator.sol  The RizLeverager contract in RizLeverager.sol  The RizLockZap contract in RizLockZap.sol  The YRizStrategy contract in YRizStrategy.sol  To improve the project's overall legibility, consider standardizing ordering throughout the codebase as recommended by the Solidity Style Guide (Order of Functions).  Update: Resolved in pull request #67. The Radiant team stated:  Followed the Solidity Style Guide. Had to adjust tests/scripts slightly to accommodate these changes.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#inconsistent-order-within-contracts", "labels": ["OpenZeppelin"]}, {"title": "Unused Imports", "body": "Throughout the codebase, there are instances of unused imports:  The import import {RizLendingPoolAddressesProvider,  IRizLendingPoolAddressesProvider} from \"./RizLendingPoolAddressesProvider.sol\"; imports unused alias RizLendingPoolAddressesProvider in RizLendingPool.sol.  The import import { RizAToken } from \"../tokenization/RizAToken.sol\"; imports unused alias RizAToken in RizLendingPool.sol.  The import import { OracleRouter } from \"../OracleRouter.sol\"; imports unused alias OracleRouter in RizLendingPool.sol.  The import import { Errors as RizErrors } from \"../libraries/Errors.sol\"; imports unused alias RizErrors in RizLendingPoolConfigurator.sol.  Consider removing unused imports to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #62. The Radiant team stated:  Removed the unused imports.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unused-imports", "labels": ["OpenZeppelin"]}, {"title": "Unaddressed TODOs", "body": "There is a \"TODO\" comment in the codebase that should be tracked in the project's issue backlog. See, for example, line 11 of IOracleRouter.sol.  During development, having well-described \"TODO\" comments will make the process of tracking and solving them easier. Without that information, these comments might tend to rot and important information for the security of the system might be forgotten by the time it is released to production. These TODO comments should at least have a brief description of the task pending to do, and a link to the corresponding issue in the project repository.  To improve code clarity, consider updating the TODO comments to add the above information. For completeness and traceability, a signature and a timestamp can be added as well.  Update: Resolved in pull request #68. The Radiant team stated:  Removed the TODO in IOracleRouter as it is not needed.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#unaddressed-todos", "labels": ["OpenZeppelin"]}, {"title": "Gas Optimizations", "body": "Within the codebase, there are places where small changes can be made to save gas without affecting functionality:  In Line 161 of RizRegistry.sol, the lendingPool variable can be re-used instead of making another external call.  In Line 264 of RizLendingPoolAddressesProvider.sol, the initialization of the proxy variable is redundant when proxyAddress == address(0). Consider moving this initialization into the else clause of the conditional below.  In Line 85 of BadDebtManager.sol, the check for zero length can be reduced to checking only one array, as the following check will ensure equal length of each array.  In Line 237 of RizLendingPool.sol, the reservesCount is the same as reservesList.length. Since this is the only place that the Params struct is used at, consider removing reservesCount from the struct rather than passing it and instead read the length of reservesList inside any receiving function.  In lines 54 and 83 of EmergencyWithdraw.sol, calls to badDebtManager.getAssetPrice are made. Instead of making external calls, these values can be cached within EmergencyWithdraw.sol.  In line 74 of EmergencyWithdraw.sol, the slashingRatio will be read from badDebtManager multiple times due to the loop. Since slashingRatio is not a function, it will return the same value here each time. Consider reading this value once and caching it for use here.  Consider implementing the changes outlined above to save gas. Ensure that all passing tests still pass and either use the same or lesser amount of gas after each change.  Update: Resolved in pull request #90. The Radiant team stated:  Implemented the gas optimizations recommended by the audit team. We split the EmergencyWithdraw library into separate helper functions as the stack was too deep.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#gas-optimizations", "labels": ["OpenZeppelin"]}, {"title": "Variable Visibility Can Be Reduced", "body": "The visibility of the _marketIdToAddressProvider mapping of the RizRegistry contract is public. However, the contract contains a getter function for it under a different name.  In order to improve code readability and minimize the attack surface, consider reducing the visibility of the mapping from public to internal.  Update: Resolved in pull request #56. The Radiant team stated:  Changed the visibility to internal.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#variable-visibility-can-be-reduced", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease code clarity and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity file or when inheritance chains are long.  Within RizLendingPoolConfigurator.sol, the import \"@openzeppelin/contracts/token/ERC20/extensions/IERC20Metadata.sol\"; import is a global import.  Following the principle that clearer code is better code, consider using the named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #93. The Radiant team stated:  Used explicit imports.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "Client Reported", "body": "Client Reported", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Withdrawals of Amount 0 Revert in _freeFunds", "body": "Withdrawals of Amount 0 Revert in _freeFunds", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#withdrawals-of-amount-0-revert-in-_freefunds", "labels": ["OpenZeppelin"]}, {"title": "Recommendations", "body": "Conclusion  Summary  DeFi  From 2024-05-20  To 2024-06-14  Solidity  66 (52\u202fresolved, 2\u202fpartially\u202fresolved)  1 (1\u202fresolved)  4 (3\u202fresolved)  20 (13\u202fresolved)  24 (18\u202fresolved, 2\u202fpartially\u202fresolved)  16 (16\u202fresolved)  1 (1\u202fresolved)  Scope  We audited the radiant-capital/riz repository originally at the v0.0.1-alpha tag, and later, after changes were introduced, at the 65ca7bb commit.  In scope were the following files:  System Overview  The \"Riz\" system is a part of Radiant known as the \"Radiant Innovation Zone\". Its general purpose is to allow the creation of new lending markets that are isolated from each other. This allows Radiant to create markets which include assets which are riskier, either due to price movement, liquidity or smart contract bugs or behavior. These lending markets are based on Aave V2 and utilize the overcollateralized lending pattern, along with liquidations which can be performed when users' borrows are too high.  Lending pools can be deployed via a contract factory pattern, so there are also contracts which manage these deployments and track all relevant information such as which lending pools are still valid and active.  Since Riz markets are intended to take on riskier assets, there is an \"emergency shutdown\" feature in case a market suffers from an issue. These issues are not strictly defined, but could include loss of liquidity or quick price movements making borrows unliquidateable. Emergency shutdown is triggered by the \"Emergency Admin\" role and immediately stops all pool operations, such as depositing and borrowing, but also including liquidations and transferring rTokens. Additionally, it takes a \"snapshot\" of the market's state at the time of shutdown, and this snapshot can be used to then deduce how much each user is owed after the shutdown. After the market has been \"shutdown\", the withdraw functionality becomes the \"emergency withdrawal\" one, which can be called once per user which transfers their owed amount to them. After the snapshot, each user's balance may receive the same percentage slash in order to be able to fairly compensate users after an incident and debt socialization.  Users may utilize \"referral codes\" when interacting with the protocol, which simply emit events for off-chain use. It should be noted that the value 0 codes for \"no referral code\", so when referral codes are being assigned it should be made clear that 0 is not available. Referral codes come from Aave originally, and it appears that currently the Radiant team does not have any plans for implementing referral codes.  At the moment, only Chainlink and Pyth oracles have been included to supply the assets' prices in the system. This information is used to compute health factors for accounts and the fair amount owed to users after snapshots.  A Zapper contract exists to help users easily transfer their Riz market assets into LP tokens within the Radiant system, to be eligible for Radiant rewards.  There is a leverager contract so that users can seamlessly loop their positions into a leveraged one, by atomically borrowing and redepositing collateral in a single transaction.  There is a \"YRizStrategy\" contract, based on Yearn.finance strategies, which allows users to deposit collateral and automatically re-invest dividends. This is controlled by the radiant team and allows users to spread their deposits of some asset across multiple lending pools.  Finally, there is a \"revenue management\" contract which receives system profit and swaps it through a Dex into some predetermined basket of more liquid \"blue-chip\" assets.  Stable borrowing, while a part of the system, is turned off by default when pools are launched. Radiant has stated an intention to never allow stable borrowing, though the stable-borrowing functionality still exists in the code and can technically be turned on. Stable borrowing is simply borrowing some asset in a lending pool at a stable, pre-fixed interest rate.  Trust Assumptions and Privileged Roles  The system has many privileged Roles with various powers. In general, these roles are trusted not to abuse their power in order to profit from the system. This could be done in a few cases by setting addresses which receive funds or by setting up interactions with decentralized exchanges which can be sandwich-attacked.  Generally speaking, all privileged roles in the system are EOAs or multi-sig accounts controlled by Radiant.  One of the most powerful contracts within the system is the RizRegistry contract, which is able to initialize new pools and set their \"Pool Admin\" addresses. The Pool Admin role is able to set up new reserves in a lending pool, update debt token implementations, update rToken implementations, and modify which reserves are active or enabled as collateral. They also can set pool parameters such as borrow cap, supply cap, and interest rate strategies. Since the RizRegistry owner assigns the Pool Admin role, the RizRegistry owner thus has some degree of power over a", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#recommendations", "labels": ["OpenZeppelin"]}, {"title": "ERC20 Vetting", "body": "We recommend that the Radiant team create a \"checklist\" for ERC20 tokens before they are listed in the Riz protocol. For example, we encourage them to check:  All ERC-20 functions are implemented per the specification, including functions like name and symbol.  Any hooks on transfer are vetted and ideally do not do anything  The token contract is not upgradeable  The token contract does not allow arbitrary minting, burning, or freezing of accounts  The token is not rebasing  The tokenomics of the token do not encourage volatile price movements.  The token has a decently high amount of liquidity and has had this for a long enough time into the past.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#erc20-vetting", "labels": ["OpenZeppelin"]}, {"title": "Runtime Monitoring", "body": "While operating Riz markets, we recommend that the Radiant team setup monitoring on their usage. For example:  Track prices of all involved assets, with alerts when prices move too quickly  Track liquidity of all involved assets with alerts when lower bounds are crossed  Track transfers of rTokens to addresses which are non-recoverable, such as contracts that cannot transfer them or unowned addresses like address(1). Use this to keep a running list of updates to slashing ratios to be applied after shutdown, since the value of those lost tokens can be re-distributed to users.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#runtime-monitoring", "labels": ["OpenZeppelin"]}, {"title": "General Recommendations", "body": "We also recommend that the Radiant team:  Utilize timelocks for changes that are not emergency-related, such as contract upgrades or interest rate formula changes. This will give users ample time to review such changes, and move their funds based on their preferences  Identify all potential emergencies they can find, and monitor for them using something like Forta or Defender  Expand test coverage, including fuzzing tests.  Implement input sanitization on all functions, including those which are only called by trusted roles. This will avoid common footguns like un-assigned parameters having the value 0.  Define a comprehensive plan to contact multisig signers for any admin roles quickly and effectively. Create a plan for how decisions will be made, and conduct drills to see how fast signers can respond in the event of an emergency.  Remove all logic related to stable borrowing from the code.  Finally, due to the nature of this early v0.0.1-alpha release of the protocol, we recommend another audit or security review after the code is finalized. We understand more changes are planned and needed before deployment. Ensure that all recommendations from this audit, as well as from the solidity style guide, are followed before finalizing the code. Consider conducting an internal audit of all code and changes versus any locations the code was forked from.", "html_url": "https://blog.openzeppelin.com/radiant-riz-audit#general-recommendations", "labels": ["OpenZeppelin"]}, {"title": "[Across] It Will Not Be Possible to Bridge DAI to Blast", "body": "The relayTokens function of the Blast_Adapter contract is responsible for bridging tokens from Ethereum to Blast. In order to do that, it uses either the L1 standard bridge or the L1 Blast bridge, depending on the token being bridged. In case of DAI, an attempt to call depositERC20To function of the L1 Blast bridge is made. However, the bridge does not contain this function. This means that all transactions trying to bridge DAI to Blast using the relayTokens function will revert.  When DAI is being bridged, consider calling the bridgeERC20To function of the L1 Blast bridge instead.  Update: Resolved in pull request #518 at commit 9b9b3d6.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-it-will-not-be-possible-to-bridge-dai-to-blast", "labels": ["OpenZeppelin"]}, {"title": "[Oval] Attempts to Push Price to the CoinbaseOracle Will Always Fail", "body": "CoinbaseOracle contract serves as an oracle for price data reported and signed by Coinbase. In order to supply such price data to the contract, users have to call the  pushPrice function which, in case of the correct data passed,  updates the price data for a given asset. In order to verify the correctness of provided data,  several checks are made, including the  check for a valid kind field. However, this check reverts when  will always contain kind equal to \"prices\", resulting in the  Consider verifying that the provided kind value is equal to \"prices\".  Update: Resolved in pull request #18 at commit ff31b1b.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-attempts-to-push-price-to-the-coinbaseoracle-will-always-fail", "labels": ["OpenZeppelin"]}, {"title": "[Oval] Newest Prices May Be Reported Ignoring the lockWindow() Constraint", "body": "_tryLatestRoundDataAt function is  invoked after the  called inside the  internalLatestData function of the  timestamp argument is equal to the maximum of the last unlock time and  would be returned. In the opposite case, the most recent price as of  would be returned.  maxAge() parameter has been introduced to limit the staleness of the data returned by the adapters. If the  data to be returned by the  returned instead. This means that if the  However, this is not the desired behavior as the lock window mechanism has been introduced in order to guarantee that the \"unlock\" transactions unlock the most recent price that has not yet been used by anyone. As a consequence, the OEV opportunity for Oval will be lost since the newest price will be available for use by anyone before the \"unlock\" transaction takes place. A similar scenario may happen if the maxTraversal parameter is set to 0. In such a case, uninitialized data is returned by the _searchRoundDataAt functions inside the adapters and hence the check against the maxAge() value will never pass. As a result, the newest price data will always be returned.  Consider carefully validating the parameters with which the Oval contracts are deployed, especially ensuring that the max age is always bigger than the lock window and that the maxTraversal parameter is set to a reasonable value.  Update: Resolved in pull request #17 at commit 2aa2c7d.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-newest-prices-may-be-reported-ignoring-the-lockwindow()-constraint", "labels": ["OpenZeppelin"]}, {"title": "[Oval] Updating Parameters Inside the BaseController Contract May Lead to Undesired Outcomes", "body": "maxAge() parameter has been introduced to controllers in order to limit the staleness of the data returned by the adapters. Stale data could possibly be returned if no \"unlock\" transaction happens during the  lockWindow() period. In such a case, the latest available price data for  is returned. The  ImmutableController and  MutableUnlockersController, the  BaseController contract.  The opposite scenario is also possible when the maxAge() parameter is decreased. In such a case, the most recent data will be unexpectedly returned which will take away the possibility of extracting OEV for the newest price for Oval by unlocking the price. It should be noted that these are just two of many different scenarios that may happen if the maxAge() parameter is changed. Similar problems may also arise when the unlockWindow() and maxTraversal() parameters are modified, even if maxAge() stays the same.  Consider setting the maxAge(), unlockWindow(), and maxTraversal() parameters as immutable inside the BaseController in order to avoid returning multiple different prices for the same timestamp.  Update: Resolved in pull request #19, at commit 0e94235. It is ensured that the reported price does not change when any of the lockWindow, maxAge and maxTraversal parameters is changed and also that maxAge is always a value greater than lockWindow.  Low Severity", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-updating-parameters-inside-the-basecontroller-contract-may-lead-to-undesired-outcomes", "labels": ["OpenZeppelin"]}, {"title": "[Across] Error-Prone Initialization of Blast_Adapter.sol", "body": "Blast_Adapter contract initializes the inherited  providing the Circle domain ID of the Base chain. However, Blast is not yet supported by the CCTP protocol. The  Consider clearly initializing all CircleCCTPAdapter parameters with dummy values in Blast_Adapter to avoid possible erroneous configuration in a future version of the contract.  Update: Resolved in pull request #525.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-error-prone-initialization-of-blast_adapter.sol", "labels": ["OpenZeppelin"]}, {"title": "[Across] Permit2 Witness Is Not Fully Compliant With EIP-712", "body": "ERC7683Permit2Lib library contains EIP-712 typehashes of various types and helper functions for hashing data. However, the  hashOrder and  hashOrderData functions, which are  used to calculate the Permit2 witness, do not comply with the EIP-712 standard as they use  required by the EIP-712 standard. As such,  Moreover, since the message member of the AcrossOrderData struct is of type bytes, its keccak256 hash should be used for the encoding. However, the message member is used directly instead.  permitWitnessTransferFrom function as the  TokenPermissions struct in the alphabetical order. The reason for that is that both the custom witness and the  PermitWitnessTransferFrom struct, whose encoding is then  used for verifying the signature. As a result, both the  referenced struct types and because of that, should be sorted by name in the encoding of the  data passed to the  Consider updating the hashOrder and the hashOrderData functions so that they return data that is compliant with EIP-712. Moreover, consider changing the order of the struct encodings in the data passed to the permitWitnessTransferFrom function, so that they are sorted alphabetically.  Update: Resolved in pull request #519 at commit 0dbde21 and in pull request #506 at commit e2d406f.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-permit2-witness-is-not-fully-compliant-with-eip-712", "labels": ["OpenZeppelin"]}, {"title": "[Across] Users May Lose Assets if They Specify an Empty Address as a Call Target", "body": "The attemptCalls function of the MulticallHandler contract enables users to specify and execute custom operations on a target blockchain right after tokens are bridged. It performs these operations by doing a series of low-level calls to the target addresses with the given data. If any of these calls fails, the entire chain of transactions is reverted in order to protect users from losing their assets.  In Solidity, whenever high-level calls are made to an address without any code, the execution reverts. However, when low-level calls are made to an empty address, they are considered successful. It means that if a user mistakenly specifies an address not containing any code as a target, their transaction will succeed, whereas it would have failed if high-level calls had been made. This may cause users to lose their assets.  In order to illustrate this, consider an example where a user bridges token A from Ethereum to Blast and wants to immediately swap it to token B and send the received amount of B to their own account. In addition, suppose that the DEX they want to use has different address on these two blockchains. If a user mistakenly specifies the DEX address from Ethereum, the call made to this address (with no code) on Blast will be treated as successful and the subsequent transaction will send zero amount of B tokens to the user's account. All bridged A tokens will still remain in the contract, available to be stolen by anyone.  Consider validating the code size of a target address for each call with non-empty calldata in the attemptCalls function and revert in case it equals 0.  Update: Resolved in pull request #531 at commit 53d21b6.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-users-may-lose-assets-if-they-specify-an-empty-address-as-a-call-target", "labels": ["OpenZeppelin"]}, {"title": "[Across] Blast_SpokePool May Fail on Attempt to Bridge Native Blast Tokens", "body": "_bridgeTokensToHubPool function handles bridging tokens from the Blast spoke pool to the hub pool. For each token different from USDB and WETH, the  called. However, this function will only work for ERC-20 tokens that are not native to Blast, as otherwise, the standard bridge will attempt to  call the  calls safeTransferFrom in order to lock the tokens. However, currently, the  Consider approving the relevant amount of tokens to the bridge and calling the bridgeERC20To function of the standard bridge (as described here) when bridging native Blast ERC-20 tokens from the spoke pool. Alternatively, if tokens native to Blast are not expected to be bridged in the future, consider documenting it.  Update: Resolved in pull request #520 and in pull request #536. The UMA team stated:  We decided to add a mapping to the Ovm_SpokePool to support native L2 token bridging. This will allow OVM chains like Blast to specify the corresponding remote L1 tokens.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-blast_spokepool-may-fail-on-attempt-to-bridge-native-blast-tokens", "labels": ["OpenZeppelin"]}, {"title": "[Oval] PermissionProxy.execute Will Fail if Non-Zero value Is Provided", "body": "The PermissionProxy contract is intended to be used as a proxy for calls that unlock new prices reported as a part of the MEV-share auction flow. It allows multiple different accounts to unlock new prices by performing calls to the controllers on their behalf. Calls may only be performed by authorized accounts and may be executed by invoking the execute function. Apart from the call target and the call data, it is possible to also specify the call value. However, the PermissionProxy contract has no function allowing it to receive the native value. This means that it is not possible for users to execute any call involving non-zero native value as all such calls would revert.  Consider making the execute function payable or removing the value argument if the PermissionProxy contract is not expected to make any calls with non-zero native value.  Update: Resolved in pull request #20 at commit 77e5441.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-permissionproxy.execute-will-fail-if-non-zero-value-is-provided", "labels": ["OpenZeppelin"]}, {"title": "[Oval] CoinbaseSourceAdapter May Return Old Prices", "body": "In order to limit the staleness of the data returned by source adapters, the maxAge function has been introduced. It defines the maximum age of prices that can be returned by the tryLatestDataAt function. However, the CoinbaseSourceAdapter does not use the maxAge function when it returns historical data as other adapters do. This means that it can possibly return very old prices.  Consider limiting the staleness of the data returned by the CoinbaseSourceAdapter by utilizing the maxAge function.  Update: Resolved in pull request #24 at commit 70e5b66.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-coinbasesourceadapter-may-return-old-prices", "labels": ["OpenZeppelin"]}, {"title": "[Oval] Missing Input Validation", "body": "CoinbaseOracle contract  sets the immutable reporter variable during the contract's construction. The  pushPrice function. The access control mechanism in  recovering the signer of the provided message and verifying that it matches the reporter's address. However, the  ecrecover precompile does not fail on invalid signatures. Instead, it returns the zero address. If the  Consider implementing a validation check to ensure that the reporter address is not set to the zero address to prevent erroneous contract deployments.  Update: Resolved in pull request #18 at commit b057756.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-missing-input-validation", "labels": ["OpenZeppelin"]}, {"title": "[Across] Lack of Indexed Event Parameters", "body": "Within MulticallHandler.sol, several events do not have indexed parameters:  The CallsFailed event  The DrainedTokens event  To improve the ability of off-chain services to search and filter for specific events, consider indexing event parameters.  Update: Resolved in pull request #532 at commit e2b80bd.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-lack-of-indexed-event-parameters", "labels": ["OpenZeppelin"]}, {"title": "[Across] Unnecessary Cast", "body": "Within the Blast_Adapter contract, the IL1ERC20Bridge(L1_BLAST_BRIDGE) cast is unnecessary.  To improve the overall clarity, intent, and readability of the codebase, consider removing the unnecessary cast.  Update: Resolved in pull request #530 at commit 983531d.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-unnecessary-cast", "labels": ["OpenZeppelin"]}, {"title": "[Across] Variable Names Inconsistent With Interfaces", "body": "Throughout the codebase, there are several instances of variables having different names than those in the original interface defining them:  The mode variable from the IERC20Rebasing has a different name than the corresponding variable declared in the configure function of the USDB implementation contract deployed on the Blast blockchain.  The recipient variable from the IBlast interface has a different name than the corresponding variable declared in the Blast implementation contract deployed on the Blast blockchain.  The settlerContract variable used for the calculation of CROSS_CHAIN_ORDER_TYPE has a different name than its counterpart in the CrossChainOrder struct.  While these inconsistencies do not have any negative impact on the behavior of the code, fixing them would make the code easier to read. As such, consider changing variable names so that they are consistent with the original ones in order to improve the readability of the codebase.  Update: Resolved in pull request #526 at commit 974e2d6.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-variable-names-inconsistent-with-interfaces", "labels": ["OpenZeppelin"]}, {"title": "[Across] Code Duplication", "body": "The SpokePool contracts of the chains based on the Optimistic Virtual Machine (OVM-based chains) share a significant amount of code, primarily utilizing the bridge contracts of Optimism. This common logic is encapsulated within the Ovm_SpokePool contract, from which all OVM-based SpokePools inherit. The _bridgeTokensToHubPool function in the Ovm_SpokePool contract handles the process of transferring funds from the L2 chain back to the HubPool via bridging.  Blast_SpokePool contract, which is also OVM-based, inherits from the  Consider relocating the part of the code specifically responsible for handling the SNX token to the relevant OVM-based SpokePool contract. Doing this will enable the Blast_SpokePool contract to invoke the inherited _bridgeTokensToHubPool function and avoid code duplication.  Update: Resolved in pull request #520, pull request #524. The SNX specific logic has been relocated to the Optimism_Spokepool contract and code duplication has been mitigated.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-code-duplication", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for their maintainers to contact the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact.  Consider adding a NatSpec comment containing a security contact above each contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #535 at commit 8043c74.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "[Oval] State Variable Visibility Not Explicitly Declared", "body": "Throughout the codebase, there are state variables that lack explicitly declared visibility:  The reporter state variable in CoinbaseOracle.sol  The SOURCE state variable in StandardCoinbaseFactory.sol  The pyth state variable in StandardPythFactory.sol  For clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #21 at commit 2552ef0 and in pull request #18 at commit b057756.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "[Across] Orders May Be Blocked for Some Time", "body": "The ERC7683OrderDepositor contract allows initiating cross-chain orders by providing users' signatures for these orders to the initiate function. This function is callable by anyone and, apart from the order to be initiated and the user's signature, it also allows a caller to specify the filler data which is then used to fill the exclusive relayer data for the order. The exclusive relayer is an account which is exclusively allowed to fill a certain deposit before the exclusivity deadline passes.  However, in contrast to the specified order, the fillerData is not validated in any way inside the initiate function which means that it may contain an arbitrary value. This allows an attacker to specify a random address, making it impossible for the order to be filled until the exclusivity deadline passes.  Consider limiting the exclusivity deadline period so that this attack is not problematic for the users.  Update: Partially resolved in pull request #515. The UMA team stated:  This no longer becomes an issue once pull request #515 is merged because the depositor now includes in their CrossChainOrder.order bytes information about an exclusivityDeadlineOffset. The filler that then calls initiate() to bring the deposit on chain can fill in any account they wish as the exclusiveRelayer but the depositor can protect themselves from malicious relayers by setting a short deadline offset. Moreover, the channel through which the depositor and relayer communicate will presumably be designed to penalize fillers who misbehave and set any part of the fillerData with griefing intent", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-orders-may-be-blocked-for-some-time", "labels": ["OpenZeppelin"]}, {"title": "[Across] Multiple Contract Declarations Per File", "body": "Within ERC7683Depositor.sol, more than one contract, library, or interface have been declared.  Consider separating the contracts into their own files to make the codebase easier to understand for both developers and reviewers.  Update: Resolved in pull request #527 at commit 74b6c90.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-multiple-contract-declarations-per-file", "labels": ["OpenZeppelin"]}, {"title": "[Across] Typographical Errors", "body": "Throughout the codebase, there are several instances of typographical errors:  In the ERC7683.sol file:  In line 12, \"receive\" should be changed to \"received\".  In the ERC7683Depositor.sol file:  In line 26, \"quoteBeforeDeadline\" should be replaced with \"QUOTE_BEFORE_DEADLINE\".  In the Blast_Adapter.sol file:  In lines 64 and 65, \"Base\" should be changed to \"Blast\".  In line 89, \"blast\" should be replaced with \"standard\".  In the MulticallHandler.sol file:  In line 52, \"drainRemainingTokens\" should be changed to \"drainLeftoverTokens\".  In the Blast_SpokePool.sol file:  In line 9, the word \"can\" is written twice.  Consider fixing all instances of typographical errors in order to improve the readability of the codebase.  Update: Resolved in pull request #529 at commit bfb8596.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "[Oval] Typographical Errors", "body": "Throughout the codebase, there are several instances of typographical errors:  In the PermissionProxy.sol file:  In line 8, the word \"allows\" should be removed.  In line 10, the word \"oval\" should be written starting with a capital letter.  In the MutableUnlockersController.sol file:  In line 8, \"can be change\" should be \"can be changed\".  Consider fixing all instances of typographical errors in order to improve the readability of the codebase.  Update: Resolved in pull request #23 at commit d977126.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "[Across] Prefix Increment Operator ++i Can Save Gas in Loops", "body": "Throughout the codebase, there are multiple opportunities where the subject optimization can be applied:  The i++ in MultiCallerUpgradeable.sol  The i++ in MultiCallerUpgradeable.sol  The i++ in MulticallHandler.sol  Consider using the prefix increment operator (++i) instead of the postfix increment operator (i++) in order to save gas. This optimization skips storing the value before the incremental operation as the return value of the expression is ignored.  Update: Resolved in pull request #522 at commit d70155c and in pull request #534 at commit 47e59f7.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-prefix-increment-operator-++i-can-save-gas-in-loops", "labels": ["OpenZeppelin"]}, {"title": "[Across] Misleading Comments", "body": "The following instances of misleading comments have been identified:  In Blast_SpokePool.sol, the comment inside the _claimYield function suggests that the native yield received from the yield contract is converted to WETH, but it is not, as ETH is transferred directly to the recipient.  In Blast_SpokePool.sol, in this comment, it might not be immediately clear what the word \"this\" refers to. 0xDeadDeAddeAddEAddeadDEaDDEAdDeaDDeAD0000 is the address of the LegacyERC20ETH contract. However, it might be understood from the comment that it is the address of the canonical bridge.  Consider correcting the comments in order to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #528 and pull request #520.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[across]-misleading-comments", "labels": ["OpenZeppelin"]}, {"title": "[Oval] Misleading Comment", "body": "The following misleading comment has been identified:  In ChainlinkSourceAdapter.sol, this comment says that if the data returned by the _searchRoundDataAt function is uninitialized, the current price data is returned. However, the latest price data will also be returned in case the _searchRoundDataAt function returns initialized data that is older than maxAge().  Consider fixing the comment in order to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #25, at commit 5624e60.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-misleading-comment", "labels": ["OpenZeppelin"]}, {"title": "[Oval] Possible Duplicate Event Emission", "body": "When a setter function does not check if the value has changed, it opens up the possibility of spamming events indicating that the value has changed when it has not. Spamming the same values can potentially confuse off-chain clients.  Within MutableUnlockersController.sol, the setUnlocker function sets the unlockers state variable and emits an event without checking if the value has changed.  Consider adding a check to revert the transaction if the value remains unchanged.  Update: Resolved in pull request #26, at commit 6f53172.", "html_url": "https://blog.openzeppelin.com/across-v3-and-oval-incremental-audit#[oval]-possible-duplicate-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Teleporter Fee Is Minted Out of Thin Air - Phase 2", "body": "SendTokensInput struct passed to the  send or  sendAndCall function. The Teleporter only supports fees being paid in ERC-20 tokens. Thus, if a user wants to pay in native tokens, they have to wrap the native tokens into wrapped native tokens.  will call _handleFees in order to ensure that the fee is transferred from the sender to the  _handleFees function will call _deposit of NativeTokenSpoke. This function will  mint wrapped native tokens out of thin air instead of transferring the wrapped native tokens from the sender to the  Instead of minting the fee amount out of thin air, consider ensuring that the specified fee amount is sent from the user to the NativeTokenSpoke contract before bridging the tokens.  Update: Resolved in pull request #158. If the user wishes to pay the fee in wrapped native tokens, the _handleFees function will now first approve the wrapped native tokens from the sender and afterwards pull the wrapped native tokens from the sender into the NativeTokenSpoke contract.  Medium Severity", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#teleporter-fee-is-minted-out-of-thin-air---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Bridging Funds Smaller Than the Minimum Denomination Results in Loss of Funds - Phase 1", "body": "scaled down in the  _receiveTeleporterMessage function. If the amount of received tokens is smaller than the  scaleTokens function will result in 0 and thus no tokens will be minted on the destination chain.  This creates an imbalance between the funds locked in the bridge contract on the source chain and those on the destination chain. As a result, the tokens on the destination chain will become over-collateralized, and some tokens will remain locked in the source chain forever. Ideally, the bridge contract on the home chain should prevent users from bridging funds that are smaller than the minimum denomination of the destination chain. However, since the home chain is currently unaware of the decimal configuration on the destination chain, this limitation might necessitate a redesign of the current system.  Consider redesigning your system to enable the home chain to recognize the decimal settings of the destination chain. Alternatively, ensure that this behavior is well-documented to prevent user losses.  Update: Partially resolved in pull request #108 and pull request #124. The Ava Labs team stated:  We decided to add a required \"destination registration\" step for a source to learn of new destination contracts prior to allowing tokens to be bridged to them. In addition to preventing fund amounts smaller than the minimum denomination from being able to be bridge, it also (possibly more significantly) adds a guard rail to prevent against funds being bridged to invalid/non-existent destination contracts in the event a wrong blockchain ID or address is provided by mistake.  The registration steps work by sending a Teleporter message from the destination contract to the source contract via calling registerWithSource on the destination contract. This message includes the destination's denomination information, as well as its initial reserve imbalance (used in the case of NativeTokenDestination). When this RegisterDestinationMessage is delivered to the source contract, it is added to the mapping of registered destinations. The source contract is now responsible for scaling the token amounts to be sent to destinations with different denominations and also collecting sufficient collateral to account for a destination's initial reserve imbalance prior to allowing funds to be bridged to that destination.  Collateral can be added to the source contract for a specific destination by calling addCollateral. This is a UX improvement since users are now unable to call send for destinations that are not yet collateralized, which previously would add collateral but not result in any tokens being minted on the destination. In the case of multi-hop transfers, it is possible for the intermediate transaction on the source chain to fail in the event that the destination specified by the first message is not properly registered. To prevent funds from being locked in this case, we added a multiHopFallback recipient where the tokens are sent on the source chain in this event.  Note that any address on any Subnet could register itself as a destination whether or not it is implemented properly. The fact that a destination is registered with a source contract that is known to be verified/correct does not mean that the destination contract is correct/trustworthy. While this design does add an additional step to the set-up of a new destination contract, we think the guard rails it provides makes it worth adding.  The new design requires the destination bridge to register its token configuration on the source bridge by means of a registration message. Registering the token configuration on the source bridge enables bridges to scale tokens to the denomination of the receiving bridge before actually bridging the tokens. In the event that this scaling results in zero tokens, no tokens are bridged and the user will not lose any funds. While the implementation of this new design looks good, consider taking into account the following:  In the unlikely event that native assets are sent to fallbackRecipient or multiHopFallback and these contracts are not payable, the funds will remain locked in the bridge. Consider implementing a recovery mechanism which allows the original sender to retrieve the funds in case these fallback calls fail.  The bridgedBalances mapping to keep track of the different bridged balances on the source chain stores the balance in the denomination of the destination chain. As the mapping is public, other contracts on the source chain may use this balance. We think it would be valuable to mention this somewhere in the docstrings of the mapping.  The function registerWithSource allows users to specify the fee token and fee amount to incentivize the relayer to send cross-chain messages to the source chain. However, this specific fee token is not sent to the bridge instance. When sending a Teleporter message with _sendTeleporterMessage, the bridge will attempt to approve the TeleporterMessenger to use the fees, which will fa", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#bridging-funds-smaller-than-the-minimum-denomination-results-in-loss-of-funds---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Inability to Identify Originating Transaction Address on Destination Chain - Phase 1", "body": "The Teleporter Token Bridge contracts enable the transfer of tokens between different subnets by specifying a recipient on the destination chain using the _send method. In addition, they also support token transfers using a function call with the _sendAndCall method. However, the context provided as input when executing these methods may not be sufficient for users as it does not specify the sender of the originating transaction.  This could impact the user experience and may limit the bridge's applications. Consider a scenario where a user wants to authenticate the original sender to restrict calls. They might configure the contract to be callable only by the bridge contract but may also need to identify who initiated the transaction on the source chain. This could be critical, especially if the contract handles value, as they would not want to receive calls from just any origin sender.  Consider including a field in the message received by the targeted smart contract that represents the origin sender's address.  Update: Partially resolved in pull request #101. The Ava Labs team stated:  We added the verified sourceBlockchainID and originSenderAddress values to the receiveTokens interfaces for both ERC-20 tokens and the native token to allow for sendAndCall use cases that require authenticating the caller. In a multi-hop case, these values are passed through the source chain on their intended destination. This required adding the fields to the SingleHopCallMessage payload. The MultiHopCallMessage only needs to include the originSenderAddress because the sourceBlockchainID is the source blockchain ID of the Teleporter message itself.  The new implementation properly passes the original caller and source blockchain ID to the recipients of the sendAndCall feature. This enables use cases that require authenticating the caller on the source blockchain who initiated the transaction. On top of passing the caller and the source blockchain ID, consider adding the source bridge address. This allows the recipient of the sendAndCall feature to ensure the sendAndCall was handled by a trusted source bridge contract.  Update 2: Resolved in pull request #136. The new implementation now also passes the originBridgeAddress to the receiveTokens interface in both the IERC20SendAndCallReceiver and INativeSendAndCallReceiver. This allows the recipient contracts of the sendAndCall feature to verify that the sendAndCall was handled by a trusted source bridge contract.  Low Severity", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#inability-to-identify-originating-transaction-address-on-destination-chain---phase-1", "labels": ["OpenZeppelin"]}, {"title": "transfer and send Calls Are No Longer Considered Best Practice - Phase 1", "body": "When transfer or send calls are used to transfer native assets to an address, they forward a limited amount of gas. Given that EVM operations are sometimes re-priced, code execution on the receiving end of these calls cannot be guaranteed in perpetuity.  Throughout the codebase, there are instances where transfer or send is used to transfer native assets:  In line 252 of NativeTokenDestination.sol, native assets are transferred via transfer.  In line 343 of NativeTokenDestination.sol, native assets are transferred via transfer.  In line 387 of NativeTokenDestination.sol, native assets are transferred via transfer.  In line 87 of NativeTokenSource.sol, native assets are transferred via transfer.  In line 119 of NativeTokenSource.sol, native assets are transferred via transfer.  OpenZeppelin Address library to transfer native assets. As more gas is forwarded with transfers using this approach, reentrancy vectors might become possible. However, the system properly prevents malicious reentrancy using the  Update: Resolved in pull request #104. The Ava Labs team stated:  We updated the contracts to use the sendValue function from the OpenZeppelin Address library.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#transfer-and-send-calls-are-no-longer-considered-best-practice---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Potential Misconfiguration of ERC-20 Token Decimals - Phase 2", "body": "The ERC20TokenHub constructor allows the deployer to specify both the ERC-20 token contract address and the number of decimals for the token. This approach introduces a risk of misconfiguration, as the manually provided decimals may not accurately reflect the token's actual decimals. To minimize configuration errors and ensure consistency, it is recommended to retrieve the token's decimals directly using the decimals() function from the ERC-20 token within the constructor. This method would reduce the potential for error in the configuration.  Consider obtaining the token decimals from the ERC-20 token instead of requiring it as an argument in the constructor.  Update: Acknowledged, not resolved. The Ava Labs team stated:  Since decimals() is not part of the IERC20 interface, we want to maintain the possibility for the bridge contracts to be used for ERC-20's that do not provide that function, which requires the decimals to be provided explicitly.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#potential-misconfiguration-of-erc-20-token-decimals---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Use Custom Errors - Phase 1", "body": "Since Solidity version 0.8.4, custom errors provide a cleaner and more cost-efficient way to explain to users why an operation failed. Throughout the codebase, instances of revert and require messages were found.  For conciseness and gas savings, consider replacing require and revert messages with custom errors.  Update: Acknowledged, not resolved. The Ava Labs team stated:  We chose to keep the use of custom errors for now at the expense of having slightly higher gas costs because we have observed that explorers are able to better display the error messages when custom error strings are used with require statements. If this changes in the future, we can update the contracts and the new versions will still be compatible with prior versions.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#use-custom-errors---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Functions Are Updating the State Without Event Emissions - Phase 1", "body": "The _mintNativeCoin function in NativeTokenDestination.sol is updating the state without an event emission.  Consider emitting events whenever there are state changes to make the codebase less error-prone and improve its readability.  Update: Resolved. The Ava Labs team stated:  We discussed this issue with the OpenZeppelin team and came to the agreement that the NativeCoinMinted event emitted by the NativeMinter precompile is sufficient for this case. This event definition can be seen here. We decided to not add any additional events because they would be functional duplicates of the one emitted by the precompiled contract.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#functions-are-updating-the-state-without-event-emissions---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Misleading Comments - Phase 1", "body": "The following misleading and inconsistent comments have been identified in the codebase:  According to this comment, the value in wei to send to the contract is zero. However, this value parameter can be any value and does not need to be 0.  The totalNativeAssetSupply function could benefit from some additional documentation due to the fact that this might be an approximation of the total native asset supply on the destination chain.  Consider revising the comments to improve consistency and more accurately reflect the implemented logic.  Update: Resolved in pull request #103.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#misleading-comments---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Implicit Cast in deriveTokenMultiplierValues - Phase 2", "body": "In the TokenScalingUtils contract, the deriveTokenMultiplierValues function performs an exponentiation on the result of the subtraction of two uint8 values. Although it is not strictly necessary, it is good practice to avoid implicit casts.  Consider adding an explicit cast to the result of the subtraction to uint256 before performing the exponentiation.  Update: Resolved in pull request #163.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#implicit-cast-in-derivetokenmultipliervalues---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Import in ERC20TokenSpoke - Phase 2", "body": "ERC20TokenSpoke contract includes an  import statement for the  using keyword. However, none of the functions of the  Consider removing this unused import to avoid confusion and improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #163.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#unnecessary-import-in-erc20tokenspoke---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Misleading comments - Phase 2", "body": "The following misleading and inconsistent comments have been identified in the codebase:  According to the documentation of the SpokeBridgeSettings struct, it holds the tokenDecimals value. However, this value is not present in the implementation of the struct.  This documentation in the TokenSpoke contract still uses the destination/source terminology instead of the new spoke/hub terminology.  Consider revising the comments to improve consistency and more accurately reflect the implemented logic.  Update: Resolved in pull request #163.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#misleading-comments---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Gas optimizations - Phase 2", "body": "A few places in the codebase could benefit from gas optimization, for example:  When the user wishes to bridge native tokens using NativeTokenHub, the native tokens are wrapped into wrapped native tokens and held as collateral in the NativeTokenHub contract. Afterwards, once the NativeTokenHub receives a message from TokenSpoke to release the collateral, the wrapped native token is unwrapped to native tokens upon withdrawing in case of a simple send or upon calling the recipient in case of a sendAndCall. Instead of wrapping and unwrapping the native token, consider leaving the native token untouched in the contract. The only exception to this rule would be when handling the fees of multihop transfers. As Teleporter fees only support ERC-20 tokens and fees for multihop transfers are paid within NativeTokenHub, these native tokens should be wrapped into wrapped native tokens.  When the user wishes to bridge native tokens using NativeTokenSpoke, the native tokens are wrapped into wrapped native tokens. Afterwards, both the wrapped native tokens as well as the native tokens itself are immediately burned as they will result in a release of collateral on the TokenHub side. Consider simplifying this process by leaving out the wrapping of the native tokens such that only the native tokens need to be burned.  Consider optimizing these code sections to make them more gas efficient when bridging funds.  Update: Partially resolved in pull request #164. The Ava Labs team stated:  We chose to not make further changes to the NativeTokenHub contract for the gas optimization proposed because it would require an additional special case for handling multi-hop messages on a NativeTokenHub compared to the abstract TokenHub, and we didn't want to introduce the additional complexity.  While the gas optimization in NativeTokenHub is not addressed, the optimization in NativeTokenSpoke is correctly implemented. Now, the native tokens sent to the bridge contract are directly burned instead of first wrapping them into wrapped native tokens. In order to be compatible with the changes made in TokenSpoke, ERC20TokenSpoke now directly burns the bridged tokens from the user's address instead of transferring them into the bridge contract and burning them afterwards.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#gas-optimizations---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Usage of msg.sender - Phase 2", "body": "ERC-2771, allowing for the use of meta-transactions. The following functions  safeTransferFrom function from the  The _prepareSend function in TokenHub to pay for Teleporter fees on the hub chain  The _handleFees function in TokenSpoke to pay for Teleporter fees on the spoke chain  The _deposit function in ERC20TokenHub to transfer the amount to bridge from the hub chain to a spoke chain  However, as this safeTransferFrom function is using msg.sender instead of _msgSender, the tokens will be pulled from the trusted forwarder instead of the original transaction signer in case meta-transactions are used to interact with the bridge contracts and the _msgSender function is overwritten. This might make it possible for transaction signers to steal tokens from the trusted forwarders if the trusted forwarders do not properly validate the transactions before submitting them on-chain.  Consider using _msgSender within all contracts that are intended to be inherited elsewhere in the codebase to ensure that meta-transactions are universally supported.  Update: Resolved in pull request #165. All instances of safeTransferFrom are now using _msgSender instead of msg.sender.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#inconsistent-usage-of-msg.sender---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Client Reported", "body": "Client Reported", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Incorrect secondaryFee Denomination Could Lead to User Losses - Phase 1", "body": "All messages sent by TeleporterTokenDestination instances are sent to the specified token source contract. Therefore, if the final destination is not the source, a multihop is performed and two bridge messages will be sent. The first bridge message will send the tokens from the sending destination bridge to the source bridge, while the second message will send the tokens from the source bridge to the receiving destination bridge. When initiating the first bridge message from the destination bridge, the user must specify two fees:  The primaryFee, which will be used to pay relayers to relay the first bridge message of a multihop  The secondaryFee, which will be used to pay relayers to relay the second bridge message of a multihop  Before sending the first bridge message, the sending destination bridge properly scales the amount of funds to the denomination used by the source bridge. However, the secondaryFee remains denominated in the sending destinations chain token. Next, the source chain will attempt to use this fee without any conversion in the second cross-chain message of the multihop to the final destination chain. Depending on whether the denomination on the sending destination bridge has a higher or lower amount of decimals than the source bridge, the following two scenarios could unfold:  The denomination on the sending destination bridge has a lower amount of decimals. Therefore, the fee is too low according to the source bridge and the relayer will not pick up the message. The user has to manually increase the fee of the message by interacting with the TeleporterMessenger in order to incentivize a relayer to deliver the message to the final destination bridge. While there is no loss of funds, this scenario is likely when there is a difference in token decimals.  The denomination on the sending destination bridge has a higher amount of decimals. As the sending-destination-bridge-denominated fee is subtracted from the source-bridge-denominated amount to send, this might either revert ( if amount <= fee) or cause the user to pay a significant amount of the sent amount in fees (if amount > fee). Moreover, if the execution reverts on the source bridge, the funds will be locked on the sending destination bridge, and there will be no way to unlock the funds. Similar to the other scenario, this is likely to occur when there is a difference in token decimals. On top of that, this scenario would result in a loss of funds for the user.  Update: Resolved in pull request #109. When performing a multihop, the source bridge is now responsible for scaling both the received funds as well as the secondaryFee to its own denomination upon receiving the first bridge message from the sending destination bridge. Afterwards, this secondaryFee, denominated in the source bridge's token, is used to send the second cross-chain message of the multihop to the final destination chain.", "html_url": "https://blog.openzeppelin.com/avalanche-interchain-token-transfer-audit#incorrect-secondaryfee-denomination-could-lead-to-user-losses---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Vulnerability in Block Proposal Function Allows Token Theft - Phase 1", "body": "The proposeBlock function is designed to enable the proposing of L2 blocks to an L1 chain, requiring proposers to indicate a prover responsible for proving the block. The process needs proposers to provide a signature that verifies the prover's agreement to specific terms, such as fee costs, block metadata hash, and the token used for fee payment. Anyone can be a prover as long as they can execute the necessary computations for proving the L2 block and have 250 TKO or more tokens that could ensure their commitment to proving blocks within a certain timeframe.  A security flaw is present within the AssignmentHook's onBlockProposed method. This method, which is executed during the block proposal transaction, manages the transfer of fees from the proposer to the prover. If the transaction involves fee payment in a non-ETH token, the contract utilizes the safeTransferFrom method to facilitate the fee transfer from the Coinbase address to the prover's address. However, a malicious proposer can set the Coinbase address to be a user's address that has previously granted an ERC-20 token allowance to the TaikoL1 contract (usually a prover's address as they could set the maximum allowance on its TKO tokens to participate as a prover). By doing so, the proposer can specify the fee amount to be equivalent to the entire token allowance, choose that token for the payment of the fees, and assign a controlled prover to be the one that receives the tokens.  Consider adjusting the fee payment logic to ensure that the Coinbase address is not used when transferring the fees. In addition, consider using an address that correctly represents the proposeBlock caller, preventing unauthorized redirection of ERC-20 token allowances.  Update: Resolved in pull request #16327 at commit 7423ffa. A new variable was added to track the block proposer, who now pays the fees.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#vulnerability-in-block-proposal-function-allows-token-theft---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Bridge Signals Can Be Forged to Drain the Protocol - Phase 3", "body": "with the hash of the sent message. When a message is processed on the destination chain,  not to exceed the current quota. If it exceeds the quota, the message's status is set to  validated not to call forbidden addresses and to match  external call is made to the destination address.  However, the checks constraining the target of the message or the function selector are consequently not applied when a message is retried. Assuming an ETH quota on L1, an attacker can thus perform the following actions to invoke any message on L2:  Send a message on L2 that will exceed the available L1 ETH quota, targeting the SignalService to call sendSignal. The sent signal must be the hash of the crafted message, which the attacker will process on L2 in step 5.  The attacker attempts to process this message on L1, but as the message exceeds the quota, it would be directly set to RETRIABLE without validating its target or the function selector.  This message can then be retried and will make the Bridge contract invoke the call to sendSignal. Note that sendSignal is non-payable, so the message in step 1 would need to have a value of zero but a fee in excess of the available L1 ETH quota.  The L1 signal will be synchronized with L2 through normal protocol operation.  The attacker can process the crafted message.  Bridge context. This makes it possible to forward arbitrary amounts of  ETH or mint any  ERC-20,  ERC-721, or  ERC-1155 token on the L2. These tokens can then be bridged back to drain user assets from the  realOwner of the DelegateOwner contract, a backdoor can be installed that will be exploited at a later point in time.  Note that we assumed above for simplicity, but without loss of generality, that there were only two layers. This is because the exploit can occur between any two layers where one layer has an ETH quota defined.  Consider validating that messages are not calling arbitrary functions or forbidden addresses before setting their status to RETRIABLE or when retrying the message.  Update: Resolved in pull request #17411 at commit 304aec2. The invocation target and function signature are now also checked in the retryMessage function. However, the fix introduced a double spending attack vector of the fee that was addressed in pull request #17446 at commit 891967d.  High Severity", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#bridge-signals-can-be-forged-to-drain-the-protocol---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Initialization Script of TaikoL2 Allows Reinitialization of the Rollup - Phase 1", "body": "script setting the state variables in the genesis state root directly instead of calling the  init function. However, this script does not initialize the  Once granted the owner role, a malicious actor could, for example, withdraw any token sent to the TaikoL2 contract, or change the base fee of the rollup at will by manipulating the configuration. An example of malicious usage of this privilege could be to include one transaction setting the base fee to 1 wei at the beginning of its blocks before resetting it to a very high level at the end, allowing this user to have a monopoly over L2 transaction inclusion by pricing out all the other block proposers as well as circumventing any gas limit.  Consider modifying the genesis script to initialize all the variables of the TaikoL2 contract correctly, as well as adding a test scenario to ensure the storage layouts of the L2 contracts initialized by calling init are the same as the ones obtained by running the initialization script. This would also be useful for rollup users to be able to reproduce the genesis state root and ensure that no backdoor was included in the initial state.  Note that the initialization script is out of the scope of this engagement.  Update: Resolved in pull request #16543 at commit 37fa853. The deployment script was modified to initialize those variables.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#initialization-script-of-taikol2-allows-reinitialization-of-the-rollup---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Basefee Calculation on Taiko Rollups - Phase 1", "body": "explained as originating from the research around making EIP-1559 more like an  AMM curve. However, the formula used does not match the AMM formula, in which  exponential EIP-1559, except the formula to compute the base fee is multiplied by a factor  There are multiple issues with the EIP-1559 implementation:  The lastSyncedBlock state variable is updated every 6 blocks, but the new issuance of gas every L2 block is computed as (_l1BlockId - lastSyncedBlock) * gasTargetPerL1Block. This means that there will be significantly more L2 gas issuance than expected due to the fact that lastSyncedBlock is not updated every L1 block. For example, let us assume that lastSyncedBlock = 1000 and the current L1 block number is 1002. Let us now assume that we want to anchor any number of new L2 blocks. The new issuance of L2 gas for such a block would be (_l1BlockId - lastSyncedBlock) * gasTargetPerL1Block = 2 * gasTargetPerL1Block = 120 million, which is higher than the block gas limit. This would result in the base fee staying at 1 wei no matter how many L2 blocks are created, or how full they are. In practice, this would mean that no base fee is collected at all, and we expect the system to revert to a first-price auction mechanism for the pricing of its gas. Additionally, this means that there is no limit to the amount of L2 blocks which can be proposed or to the gas which can be consumed per unit of time. As long as the compensation earned from tips by block proposers is enough to pay for the proposal of new blocks, blocks could be proposed without any limit on network congestion. This could also have unexpected consequences related to the size of the ring buffers, as well as the equilibrium between the proving and proposing of blocks. Consider issuing new L2 gas only on new L1 blocks.  The issuance of new L2 gas is currently done every 6 L1 blocks, and could be done every L1 block as recommended in 1). However, issuing gas in one chunk every >= 4 L2 blocks runs counter to one of the goals of EIP-1559, which is to act as a gas smoothing mechanism. This creates undesirable spikes in the base fee, where the next L2 block anchored following an L1 block is significantly cheaper than the following blocks. Consider smoothing the L2 gas issuance over multiple blocks (e.g., by accumulating the L2 gas issuance in a storage variable and spreading it over 4 L2 blocks). The figures given below as examples assume that new gas issuance occurs every 4 L2 blocks and compare issuing gas in one chunk with issuing it over 4 L2 blocks. The demand for block space is modeled as being infinite below 10 gwei and 0 above.  As mentioned above, the current implementation of EIP-1559 is similar to an exponential 1559 where b0 = 1/TA = 2.08e-9. Since b0 is the minimum value that the base fee can take, its minimum value should be the minimum possible base fee (i.e., 1 wei instead of 2.08e-9 wei which is scaled up to 1 wei). This would avoid having to compensate for the low b0 by adjusting the excess gas in the exponential upward, which reduces the range before the input to the exponential gets too big and loses some precision. Consider removing the division by T * A and setting b0 to 1 wei as done in Ethereum (see [1] [2]).  Consider addressing the above issues to improve the gas pricing mechanism on L2. In addition, consider adding documentation around the gas logic as well as the lack of constraints on L2 block times.  Update: Partially resolved at commit a981ccd. All the points in the issue except the second one were addressed. The Taiko team stated:  Regarding the base-fee smoothing concept, we've already implemented and tested it, confirming its functionality. However, we've decided to first deploy a simpler version in production to assess its behaviors before integrating the base-fee smoothing feature. This decision aligns with potential future changes, including possibly eliminating the anchor transaction framework in favor of handling all anchor-related logic (including EIP1559 calculation) on the client-side and in the prover, to simplify the protocol further.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#incorrect-basefee-calculation-on-taiko-rollups---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Block Submission Susceptible to DOS - Phase 1", "body": "revert. This mechanism is there to avoid erasing blocks that have been proposed but not yet verified from the buffer. Once a block has been proposed, it can be proven. Assuming block proposals are uniform over L1 blocks, 99.9% of them will require to be proven with at least an  SGX proof on mainnet. Once proven and after a cooldown period of  1 day has passed, a block can then be  verified. During this cooldown period, block proofs can be contested. For SGX-proven blocks, contesting with a proof of the same tier  does not require a valid proof and resets the  timestamp associated with the transaction. Doing so thus resets the cooling period before the contested block can be  verified.  However, this makes it possible for a malicious user to DoS block submission by sequentially contesting blocks with SGX proof as their cooldown period expires. For example, let us assume that 42 blocks have been proposed and proven using SGX, but have not yet been verified. A malicious user can proceed as follows:  Contest the first block with an SGX proof, which requires paying a contest bond of 500 TKO tokens. Note that such a contest does not require a valid SGX proof. This stops the block verification process during the cooldown period of 24 hours, but blocks continue being proposed and accumulated to the ring buffer. Assuming a new L2 block is proposed every 3 seconds, the proposed block ring buffer gets filled up to ~1/42 of its size during the cooldown.  After the 24-hour cooldown window for the first block has elapsed, the malicious user can then contest the second block in the same way. This again costs 500 TKO tokens and freezes block verification for 24 hours, during which blocks continue being proposed and accumulated in the buffer.  The malicious user proceeds as above and continues contesting blocks sequentially as the cooldown periods expire.  At the end of this process, the ring buffer is now filled and proposing new blocks is impossible. The malicious user can continue this process, paying 500 TKO tokens for each additional day of DoS.  We note that this attack is easy to detect and that it is possible for the guardians to prove the affected transitions with the highest tier to reduce the cooldown window for verification to one hour, increasing the cost of such an attack. The total cost without guardian intervention is around 42 * 500 = 21000 TKO tokens, and the highest possible cost assuming guardian intervention is around 42 * 500 * 24 = 504,000 TKO tokens, which is high but not unreasonable for a motivated attacker. Effective intervention entails guardians being on the lookout and sending at least five approval transactions on L1 every hour, which is error-prone and costly. The impact of any error in this process could also be dramatic as guardians cannot re-prove invalid transitions (see M-01).  The impact of stopping the rollup block proposals is unknown. For example, it could be increased by DeFi activity emerging on Taiko as lending markets would not be able to process oracle price updates, which could provide an incentive to a malicious actor to pause the rollup. In any case, user funds would be stuck.  Consider preventing the contestation of transitions once the cooldown window has expired. Alternatively, consider monitoring for such situations and adapting the contestBond or the cooldownWindow to make such attacks uneconomical.  Update: Resolved in pull request #16543 at commit 37fa853. Transitions can no longer be contested after the cooldown window has expired, except if a higher level proof is provided.  Medium Severity  The Guardian Cannot Re-Prove Invalid Transitions - Phase 1  guardian address controlled by the security council to effectively prove any state transition. Should the guardian make a mistake, the intention of the code is for the guardian to be able to  re-prove a different transition. However, when re-proving a different transition for the highest tier, a check is made to ensure that the  equal to 0. This check makes any attempt to re-prove a transition revert, as the  previous transition proof.  This revert makes it impossible for anyone to correct an invalid transition when proven once by the guardian. If such an occurrence were to happen, the only practical solution would be to upgrade the implementation before the 1-hour cooling window expires to avoid the invalid transition being verified.  Consider replacing this check by ts.contestBond == 1, as well as adding a corresponding unit test of the ability for the guardian to re-prove transitions to the test suite.  Update: Resolved in pull request #16543 at commit 37fa853.  Governor Proposal Creation Is Vulnerable to Front Running in OpenZeppelin Contracts - Phase 1  The Taiko governance employs the GovernorCompatibilityBravoUpgradeable contract from OpenZeppelin version 4.8.2 which is susceptible to a front running attack. By front running the creation of a proposal, an attacker can take control as the proposer and have the opti", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#block-submission-susceptible-to-dos---phase-1", "labels": ["OpenZeppelin"]}, {"title": "The Guardian Cannot Re-Prove Invalid Transitions - Phase 1 ", "body": "The Guardian Cannot Re-Prove Invalid Transitions - Phase 1 ", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#the-guardian-cannot-re-prove-invalid-transitions---phase-1-", "labels": ["OpenZeppelin"]}, {"title": "Governor Proposal Creation Is Vulnerable to Front Running in OpenZeppelin Contracts - Phase 1", "body": "The Taiko governance employs the GovernorCompatibilityBravoUpgradeable contract from OpenZeppelin version 4.8.2 which is susceptible to a front running attack. By front running the creation of a proposal, an attacker can take control as the proposer and have the option to cancel it. This vulnerability can be leveraged to indefinitely prevent the submission of legitimate proposals, posing a significant risk to the governance process.  Consider updating the OpenZeppelin contracts library to version 4.9.1 or later as these versions contain the patch for this issue. This will enhance the security and integrity of the governor proposal mechanism.  Update: Resolved in pull request #16360 at commit 2a0fe95. The Taiko team stated:  Thank you for reporting this bug. We have upgraded @openzeppelin library to \"4.9.6\".", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#governor-proposal-creation-is-vulnerable-to-front-running-in-openzeppelin-contracts---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Design Flaw in Bridge Contract Suspension Mechanism - Phase 1", "body": "The Bridge contract implements a suspendMessages function that can be invoked by either the owner or a designated watchdog. This function is intended to suspend or unsuspend a message invocation by updating the receivedAt field within the message's proof receipt. Specifically, suspending a message sets this field to the maximum possible value for a uint64, whereas unsuspending it assigns the current timestamp. This approach introduces a vulnerability as the receivedAt field also serves to indicate whether a message has been proven, with any value greater than zero being interpreted as such. Consequently, the ability to suspend or unsuspend unproven messages inadvertently marks them as proven due to the non-zero receivedAt value.  One significant implication of this flaw is the potential exploitation by the owner or watchdog. By unsuspending a message and manipulating its data or value to match the bridge's balance or vaults' tokens balances, they could trigger the recallMessage method, effectively draining all assets from the bridge and the vaults. On a Taiko rollup, the attack can be executed immediately as there is no invocation delay, and for Ethereum, the attacker needs to wait only one hour. This could be even more problematic if the attacker does it with a bridged token on L2, as they could mint an infinite amount of tokens and affect Dapps deployed on the L2.  To mitigate this risk, consider introducing a separate dedicated field within the proof's receipt structure explicitly for saving the value prior to the suspension. Alternatively, to efficiently manage the receivedAt timestamp during suspension and unsuspension events, you can consider adopting a reversible computation method (e.g., implementing receivedAt = 2 ** 64 - 1 - receivedAt offers a pragmatic approach). This method ensures that upon suspension or unsuspension, the receivedAt value is transformed in a manner that allows for the original timestamp to be recovered through the same operation.  Update: Resolved in pull request #16545 at commit c879124. The Taiko team stated:  Thank you for identifying this issue. We've implemented a fix to ensure that even if the bridge_watchdog behaves maliciously, it cannot falsely mark a message as received without proper verification of its delivery.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#design-flaw-in-bridge-contract-suspension-mechanism---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Role Renunciation in TaikoTimelockController Deployment - Phase 2", "body": "The deployment script DeployOnL1 is used by the Taiko team to set up the contracts on the L1 chain. This includes the TaikoTimelockController, which serves as the owner of the other contracts. An oversight occurs during the deployment process: the TIMELOCK_ADMIN_ROLE, which can bypass the timelock delay, is not renounced by the deployer post-deployment.  zero address as the owner in the  msg.sender, who also receives the  TIMELOCK_ADMIN_ROLE. Although the script revokes the rest of the roles from  after the deployment, the admin role is not revoked. There is a  revoke call targeting  To mitigate this risk and enhance transparency, consider incorporating a renounceRole call at the end of the deployment script, allowing the deployer to explicitly renounce the TIMELOCK_ADMIN_ROLE.  Update: Resolved in pull request #16751 at commit abd18e8.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#incomplete-role-renunciation-in-taikotimelockcontroller-deployment---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Some ERC-20 and ERC-721 Tokens Can Not Be Bridged - Phase 2", "body": "ERC-20 tokens can be bridged through the ERC20Vault contract by calling the sendToken function. If the token is canonical to this side of the bridge, its metadata is fetched and transmitted to the other side. This metadata is fetched through external static calls. The same is done for ERC-721 tokens.  ERC-20 and  ERC-721 standards. Additionally, some tokens such as  MKR do not respect the standard and return their name and symbol as a  permitted to bridge, but the deployment of the  fail on the other side of the bridge and the message would have to be recalled.  Consider enclosing the calls to fetch the metadata in try/catch blocks or turning them into low-level calls, and assigning a default value on failure. Additionally, consider adding support for bytes32 decoding, and assigning a default value on invalid or empty decodings. Examples of such decoding functions can be found here and here.  Update: Resolved at commit dd8725f. The symbol and name can now be bytes32, and they are assigned default values if they do not exist. The BridgedERC20 deployments no longer revert if these properties are empty.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#some-erc-20-and-erc-721-tokens-can-not-be-bridged---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Cross-Chain Owner Cannot Call Privileged Functions - Phase 2", "body": "CrossChainOwned abstract contract can be inherited to allow an owner on a different chain to execute privileged actions on the child contract. For example, the  TaikoL2 contract inherits from  validated to correspond to the cross-chain owner, after which an  external call is made to itself.  onlyOwner on  address of the cross-chain owner, but the cross-chain owner calling the contract results in the contract calling itself with an  external call. This means that calls to any function protected by  withdraw or  setConfigAndExcess.  Consider allowing the cross-chain owner to call privileged functions.  Update: Resolved at commit 37fa853. The Taiko team stated:  Cross-Chain owner got removed (or reworked) and the new is \"DelegateOwner\", which will have the same role, to act like the owner essentially, for contracts deployed on L2.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#cross-chain-owner-cannot-call-privileged-functions---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Security of \u2018SignalService\u2019 Network Is No Higher Than Its Weakest Node - Phase 2", "body": "storage slot in the local  syncChainData function. This state synchronization is for example done during  L2 block verification on L1 or in the  anchor transaction at the beginning of new blocks on L2. Once synchronized, this allows the destination chain to prove that a signal has been sent from the source chain by doing a Merkle proof against this chain's state. These proofs are also allowed to be recursive by allowing for multiple \"hops\", meaning that L3 -> L1 communication can be done in a single call by proving that the L3 state was stored to L2 and that the L2 state was stored to L1. To save gas in future calls, the intermediate states can be  cached locally when such a proof is done.  This design effectively creates a network of interconnected chains, where each one is trusted and can communicate with any other. However, in practice, it is likely different chains will have very different trust and security assumptions.  For example, there could be two Taiko L2s on top of Ethereum: A canonical one and another one (called \"friendly fork\") originally vetted by the canonical Taiko DAO. A Taiko L3 could then settle to this friendly fork and have their SignalService be connected to the L3, for example by social engineering and/or by promising them financial incentives (eg. using their token as gas, etc.). While the canonical Taiko L2 is owned by the canonical chain's DAO, the Taiko L3 could be owned by a multisig for security purposes. In such a situation, this multisig which has not been vetted by the canonical Taiko L2 community could steal assets from the canonical rollup. Note that direct malicious hop proofs are impossible since the address resolution of SignalService does offer some protection: the L3 address can not be resolved without the canonical DAO's agreement. However, this protection is insufficient, and here is how such an attack could be done:  The compromised multisig uses the L3 to synchronize an invalid state root from the friendly fork. This invalid state root contains a malicious message from the friendly fork's L2 vault to the L1 vault asking for a withdrawal of all the assets in the L1 vault, including those belonging to the canonical chain.  The L3 state root is synchronized to the friendly fork.  proveSignalReceived is called on the friendly fork, with a hop proof that the malicious message was signaled in the friendly fork's invalid state root, which was signaled in the L3 state root, which was synchronized to the friendly fork in step 2). Note that this is possible as multi-hop proofs are allowed to have the same chainId multiple times, and the first hop is allowed to have the chainId of the current chain. The goal of this step is to cause the malicious friendly fork's state root to be cached and signaled by the friendly fork itself.  The friendly fork's state root is synchronized to the L1.  processMessage is called on the L1 vault with a proof that the malicious message belongs to the invalid L2 state which was signaled as part of the L2 state, which was itself synchronized in step 4). This could for example be used to drain all the assets from the L1 vaults.  The current design is dangerous as the security of all the rollups in the network depends on its weakest node: No matter how decentralized the canonical rollup gets, if any centralized chain's SignalService is added to the network by anyone else, this centralized actor has the power to drain the other rollup's assets.  This concern with the current design could be alleviated in multiple ways, for example:  Hop proofs should be prevented from containing the same chainId multiple times.  A specification should be written detailing what trust and security assumptions are required for a new chain to be added to the network and ratified by the DAO as well as any chain added to the network. Any new chain added to the network would need to be approved by the canonical DAO, and any violation of these conditions would result in expulsion from the network.  The caching mechanism could be deactivated.  If there is no use case for it, proveSignalReceived could revert if _chainId is the same as block.chainid as done in intermediary hops.  Update: Resolved at commit dd8725f. Different hops can no longer have the same chainid, and the first hop can no longer use the current chain's block.chainid.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#security-of-\u2018signalservice\u2019-network-is-no-higher-than-its-weakest-node---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Quota Manager Can Cause Recalled Funds to Be Stuck - Phase 3", "body": "ETH and ERC-20 tokens can be sent through the ERC20Vault and Bridge contracts, respectively. When funds are sent from these contracts to the users, consumeQuota is called on the QuotaManager contract.  However, the quota is not checked when sending funds from the users to the contracts. This makes it possible for a user to send funds, mark the message as failed on the destination chain, but not be able to recall their message and claim their funds back on the source chain [1] [2] if the amount exceeds the maximum quota. Hence, these funds would be stuck until the quota is increased or removed.  Consider validating during message sending that the funds sent are lower than the current quota to avoid issues when recalling messages.  Update: Acknowledged, not resolved. The likelihood of this issue justifies not introducing additional code changes. However, assets that have a quota are recommended to be monitored to check for the scenario depicted above. The Taiko team stated:  Quota only applies to tje ERC20 vault and we believe for ETH and tokens whose quota is configured to be non-zero (USDC, USDT, TKO), it is very unlikely the claiming will fail thus the message be marked as failed on the destination chain.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#quota-manager-can-cause-recalled-funds-to-be-stuck---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Reached Quota Can Cause Loss of Fee - Phase 3", "body": "consumeQuota on the  message processing. If the message is processed by its  retriable. The message can then either be retried or set as  failed and recalled on the source chain. However,  Consider adding a condition to return the fee to the destOwner if the fee is non-zero and does not exceed the available quota. In case message.fee exceeds the available quota, consider reverting to protect users from losing their fee. Note that this would mean any message with a fee exceeding the quota would be stuck until the quota is raised. In addition, and to mitigate such issues, consider having the same quotas on L1 and L2, and validating when sending a message that the value sent (inclusive of the fee) does not exceed the quota. As quotas are only expected to increase over time, it would then be possible to simply revert when processing a message which exceeds the quota.  Update: Resolved in pull request #17411 by refunding the value and fee in the retryMessage function. However, this fix was followed-up with pull request #17446, where processMessage reverts when the quota is reached or (a part of) the fee is refunded. If the message goes into retriable state and is unable to be invoked, the value is also refunded.  Low Severity", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#reached-quota-can-cause-loss-of-fee---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Assigned Prover Signature Is Underspecified - Phase 1", "body": "The AssignmentHook contract is a canonical hook that can be used by proposers during block proposals. The proposer sends to the hook a signature that was given by a prover that contains information about the proving fees as well as the proposed block. This, for example, protects provers against being paid a smaller fee to prove a bigger block than agreed upon. These signatures can either come from EOAs or contracts using EIP-1271 signatures.  here.  Furthermore, there is no way for a prover to cut an exclusive deal with a block proposer. While the data signed includes the metaHash and thus the block.coinbase address, the block could be proposed by a different address than the one designated as block.coinbase. Provers may want to have a simple mechanism to prove any block proposed by a designated address.  Consider including the assigned prover in the AssignmentHook signed data to avoid potential issues with smart wallets. Additionally, consider including the address of the block proposer in the data signed by the provers.  Update: Resolved in pull request #16665 at commit 2b27477.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#assigned-prover-signature-is-underspecified---phase-1", "labels": ["OpenZeppelin"]}, {"title": "The Snapshooter Cannot Take Snapshots of the Taiko Token - Phase 1", "body": "The Taiko token, designed with snapshot capabilities through inheritance from the ERC20SnapshotUpgradeable contract of the OpenZeppelin library, has an initialization flaw. This token uses a snapshot method, designed to give both the token's owner and a designated snapshooter the ability to take snapshots. However, an initialization error within the EssentialContract  a contract defining the onlyFromOwnerOrNamed modifier to ensure exclusive access for the owner and snapshooter to a method  affects the functionality.  __Essential_init initializer. The first variant establishes ownership and sets the paused state to  Consider using the __Essential_init initializer that properly incorporates the addressManager. This change ensures the system's architecture aligns with its designed capabilities, enabling the snapshooter to fulfill their role in snapshot management.  Update: Resolved in pull request #16394 at commit c64ec19.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#the-snapshooter-cannot-take-snapshots-of-the-taiko-token---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Inefficient Feature Inclusion in EssentialContract - Phase 1", "body": "The EssentialContract serves a critical role across various contracts in the protocol by inheriting features such as pausability, reentrancy protection, and access to an address manager. However, not all inheriting contracts fully utilize these features. This design does not align with the Solid Principle of single responsibility which advocates for a system design that promotes separation of concerns for efficiency and reduced error likelihood.  To enhance modularity and adherence to the single responsibility principle, consider splitting the EssentialContract into distinct contracts by responsibility. This approach enables contracts to only inherit the necessary features, thereby streamlining the codebase and minimizing unnecessary complexity.  Update: Acknowledged, not resolved. The Taiko team stated:  Thank you for your feedback. We have decided not to adopt the suggested approach, as we believe the associated risks are minimal and manageable.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#inefficient-feature-inclusion-in-essentialcontract---phase-1", "labels": ["OpenZeppelin"]}, {"title": "L2 Block Difficulty Is Susceptible to Manipulation - Phase 1", "body": "computed as the hash of  minimum tier associated with proving the block and is also used on L2 as the value returned when calling  using blobs.  However, the difficulty can be biased by the proposer by proposing multiple blocks. For example, this means that proposers can predict before the block proposal if proving the block will require a zk proof or an SGX proof. If the cost difference between zk and SGX proving warrants it, block proposers could in the same transaction submit multiple empty blocks, and include L2 transactions only when the difficulty is such that an SGX proof is required, effectively only using SGX to prove non-empty blocks and partially avoiding the minimum tier mechanism.  Similarly, depending on how the block.prevrandao is used by contract developers on L2, this could incentivize block proposers to bias the difficulty at the time of L2 transaction inclusion. While each L1 validator can have one bit of influence over block.prevrandao on L1, the ability to atomically propose multiple L2 blocks and choose in which to include L2 transactions give them more control over the L2 block.prevrandao than may be assumed by application developers.  Consider monitoring proposers for abuses of their privilege when proposing multiple blocks and choosing where to include transactions. In practice, the profitability of such strategies will depend on the fixed costs in gas associated with block proposals compared to the cost of zk proofs. If this issue was observed in practice, potential solutions could include the use of a VRF oracle, or disabling the ability for proposers to propose multiple blocks in one transaction. No matter which option is chosen, consider documenting any control block proposers may have over block.prevrandao on L2, as this is important for application developers.  Update: Acknowledged, not resolved. The Taiko team stated:  Internally we have been back and forth regarding how to decide a block's min tier. There is no perfect solution without major protocol design changes. The current decision is that we keep this part of the code as-is, at least for now.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#l2-block-difficulty-is-susceptible-to-manipulation---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Uncontrolled Gas Consumption When Sending ETH in Cross-Chain Messages - Phase 1", "body": "Cross-chain messages can be sent through the Bridge contract by calling the sendMessage function on one side and processMessage on the other. Messages can include a fee to incentivize relayers to process messages automatically on the destination chain. As the gas limit is specified in the message, relayers can simulate in advance to know if processing a message is profitable.  However, when sending the funds to the target address on the destination chain, all the gas is forwarded. This is because calling sendEther on an address without specifying a gas amount forwards all the gas. In practice, this would make it harder for relayers to estimate the gas costs associated with processing a message.  Consider only passing a fixed amount of gas when forwarding the refund to the refund address to make it easier for relayers to estimate the maximum amount of gas consumed when processing a message.  Update: Resolved in pull request #16666 at commit 4909782.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#uncontrolled-gas-consumption-when-sending-eth-in-cross-chain-messages---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Honest Provers Can Lose Money - Phase 1", "body": "When proposing a block, a prover is assigned to prove it. This assigned prover is the only one who can prove the first transition of this block for the duration of the proving window, in exchange for providing a liveness bond. This liveness bond can be lost if the proven state transition is later proven invalid by a higher level proof, but is returned if the transaction was not contested.  However, it is possible for an honest prover to lose TKO tokens when assigned to a block if another malicious actor is ready to lose more. For example, let us name Henry an honest prover, Mallory a malicious user, and look at the following sequence of events:  Henry is assigned to prove a block, and sends 250 TKO as liveness bond to the TaikoL1 contract. He correctly proves the state transition with an SGX proof, providing another 250 TKO as validity bond.  Mallory contests the state transition, providing 500 TKO as contest bond to the TaikoL1 contract.  In the same transaction, Mallory re-proves the block and confirms Henry's transition using a zk proof. In doing so, Henry earns 1/4 * contestBond = 125 TKO, and gets his original validity bond of 250 TKO back. Mallory gets 1/4 * contestBond = 125 TKO as she is the new prover. She provides a new validity bond of 500 TKO.  The block is verified, and Mallory as the final prover gets back half of the liveness bond as well as her validity bond, 1/2*250 + 500 = 625 TKO in total.  As a result of the above, Henry has lost his initial liveness bond but got 1/4th of the contest bond, a net loss of 125 TKO. Mallory has lost 3/4th of her contest bond but got back half of the liveness bond, a net loss of 250 TKO.  While Mallory lost more than Henry, Henry was honest but still lost money. If Mallory is malicious, has a lot of TKO tokens and wants to establish herself as the sole prover of Taiko blocks, she could for example systematically contest any SGX transition on a block she is not an assigned prover of, in order to disincentivize anyone but herself to prove blocks. This could be used in an attempt to get a monopoly on block proving. Alternatively, she could attempt to contest any SGX proof in order to disincentivize blocks from being proven at all.  Note that the scenario above can be mitigated if Henry initially provides a zk proof, as the guardian has the option of returning the liveness bond to the assigned prover when resolving a contest. Such a defense strategy however would only work for zk proofs and would require constant interventions from the guardian.  Consider adding a mechanism to return the liveness bond to the assigned prover in scenarios where a block has been contested but the assigned prover's proposed transition was valid.  Update: Resolved at commit dd8725f. The liveness bond is now returned directly to the assigned prover when the block is proven within the proving window, or if the guardian intervenes and decides to return the liveness bond.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#honest-provers-can-lose-money---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Duplicated USDC Bridging - Phase 2", "body": "The sendToken function can be called to bridge an ERC-20 token, represented as another token on the destination chain. Initially, native USDC on Ethereum L1 will be represented as a BridgedERC20 on Taiko L2s. Later, if a native USDC is deployed on a Taiko L2, it is possible to migrate to this native USDC version by migrating the BridgedERC20 version of USDC through a USDCAdapter contract.  However, this configuration by default makes it possible to bridge USDC from L2 to L1 in two different ways. The first one is to bridge the USDCAdapter, which after the migration would bridge to the native USDC on L1. The second way is to bridge the new native USDC on Taiko L2 directly as it is a canonical token, which would thus bridge to a newly deployed BridgedERC20 on L1. This dual-path approach risks confusing users and fragmenting USDC liquidity across Taiko's rollup ecosystem.  Consider keeping only one way to bridge USDC after the migration. This could be achieved by blacklisting bridging native Taiko USDC token directly to force users to bridge through the USDCAdapter.  Update: Resolved at commit dd8725f. USDC and BridgedERC20 tokens now use a common interface, so the USDCAdapter was removed.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#duplicated-usdc-bridging---phase-2", "labels": ["OpenZeppelin"]}, {"title": "ERC20Airdrop Claims Can Be DOSed - Phase 2", "body": "The ERC20Airdrop contract allows users to claim tokens by providing a Merkle proof of their airdrop. To do so, users can call the claimAndDelegate function and have to provide airdrop information as well as a signature to delegate their tokens.  However, the transaction calling claimAndDelegate is susceptible to a frontrunning attack where an adversary could independently use the user's signature with the ERC20Votes token. This action consumes the nonce and causes the user's original transaction to revert, thereby blocking them from claiming their tokens.  Consider making it possible for users to claim without delegating, for example by adding a second function or by wrapping the delegateBySig in a try/catch clause.  Update: Resolved in pull request #16738. The Taiko team stated:  Removed the delegation part.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#erc20airdrop-claims-can-be-dosed---phase-2", "labels": ["OpenZeppelin"]}, {"title": "TimelockTokenPool Signatures Can Be Replayed - Phase 2", "body": "TimelockTokenPool contract will be deployed multiple times to  allocate grants to investors, team members and other grantees. The status of granted tokens goes from locked to owned to unlocked  over time. Once unlocked, the amount can be claimed by calling the  withdraw function.  One of the two  keccak256(abi.encodePacked(\"Withdraw unlocked Taiko token to: \", _to)).  However, such signatures can be replayed to claim tokens for anyone else at any time, causing multiple potential issues. For example, tokens claimed for investors or team members could cause unexpected and increased tax obligations. Additionally, since claiming tokens has a fixed cost per claimed token, this could be used to force the recipient to lose money if the price of the claimed tokens is lower than the cost paid. Note that since the TimelockTokenPool contract will be deployed multiple times on one chain, signatures could be replayed across several of these contracts if they share a common grantee address. If the timelock is intended to be deployed across multiple chains, signatures could also in theory be replayed across chains.  Consider preventing signature replay across time, for example by adding a nonce. Additionally, consider adding the contract address to the signed data to avoid signature replay across multiple instances of the TimelockTokenPool contract, as well as adding the chainid if it is intended to be deployed across multiple chains. If the data is intended to be signed through third-party frontends, EIP-712 could also be integrated.  Update: Resolved in pull request #16934. The Taiko team stated:  Ackowledged and removing the whole contract. The new ones are under supplementary-contracts package (in the repo) so not part of protocol anymore. Unlocking is simplified and no signature based withdrawals.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#timelocktokenpool-signatures-can-be-replayed---phase-2", "labels": ["OpenZeppelin"]}, {"title": "evaluatePoint Precompile Calls Revert - Phase 2", "body": "The evaluatePoint function is used to validate that the opening of a KZG Commitment (corresponding to a blob in practice) at a point x is equal to the purported y by calling Ethereum's point evaluation precompile. This precompile expects its commitment and proof arguments to be 48 bytes each.  abi.encodePacked. The packed encoding of a  padded to 32 bytes. This means that the commitment and proof arguments sent to the precompile are  In practice, this means that any normal call to the point evaluation precompile would revert. Additionally, gas could be saved by changing the type of these arguments to bytes and validating their length separately. We note that while the Lib4844 library is in the scope of this audit, it is not currently used by the contracts in scope.  Consider changing the _commitment and _pointProof arguments to be of type bytes. Additionally, if the Lib4844 is intended to be used in practice, consider adding tests targeting this library.  Update: Resolved in pull request #16969. The Taiko team stated:  This file has been deleted.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#evaluatepoint-precompile-calls-revert---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Vaults Are Not ERC-165 Compliant - Phase 2", "body": "Token vaults inherit from the BaseVault contract. This contract implements the IERC165 interface and exposes the supportsInterface function.  However, ERC-165 states that ERC_165 compliant interfaces have to return true when interfaceID is 0x01ffc9a7 (the EIP-165 interface ID). Following the steps from ERC-165 to detect if the vaults implement ERC-165 would thus return false.  Consider adding the ERC-165 interface ID to the supported interfaces.  Update: Resolved in pull request #16935.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#vaults-are-not-erc-165-compliant---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Token Migrations Can Cause Losses - Phase 2", "body": "BridgedERC20Base contract can be  migrated by the owner or by calling the  changeMigrationStatus function of the  burn their tokens to mint the same amount of tokens on the new contract. If the migration is triggered by the bridge, old tokens are  added to a blacklist and have to be migrated before being able to bridge.  However, there are multiple migration scenarios that could cause accidental user losses:  If a new migration is triggered before some users have migrated from a previous migration, then these users would effectively lose their tokens as they would no longer be able to call mint() on the new contract nor bridge their tokens.  If a migration is triggered by the owner instead of the ERC20Vault, the vault would no longer be able to call burn or mint on the migrated token. This would prevent users from bridging and could cause losses as the new migrated token would not be bridging to the same contract when bridging through the vault.  If a migration happens to a token that doesn't implement the IBridgedERC20 interface, user losses could happen as well.  If such concerns are shared, consider addressing the above instances to protect users' funds from errors during migrations. Potential solutions include adding a delay to migrations during which no new migration can be done, preventing the owner from calling changeMigrationStatus, and validating that the new token implements the IBridgedERC20 using ERC-165 during migrations.  Update: Resolved at commit dd8725f. A minimal delay of 90 days between migrations was added to give users time to migrate. Additionally, the owner is now prevented from triggering migrations. We note that the new token is not enforced to support IBridgedERC20Migratable, as this would prevent migrating from a bridged token to a canonical implementation on Taiko. Migration of such token would have to be handled by the DAO to avoid loss of funds.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#token-migrations-can-cause-losses---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Unexpected Features in BridgedERC20 Tokens - Phase 2", "body": "When an ERC20 token is bridged from a source chain to a destination chain via the ERC20Vault, it results in the creation of a BridgedERC20 token. The BridgedERC20 implementation currently includes extra functionalities such as voting, snapshot capabilities, upgradability, and pausability, which may not be present in the original canonical token. This discrepancy could lead to confusion as users might not expect these additional features in the bridged token representation.  To address this issue, consider adopting a simpler BridgedERC20 implementation that retains only the essential features of an ERC20 token or to clearly documenting the additional functionalities. Clear documentation will ensure that users are fully informed about the capabilities of the bridged tokens, preventing any potential misunderstanding.  Update: Partially resolved in pull request #16950. The BridgedERC20 token contract no longer offers the vote/checkpoint feature. Remaining features like upgradability and pausability should be thoroughly documented, both within the contract itself and in external resources.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#unexpected-features-in-bridgederc20-tokens---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Banned Addresses Could Be Called By Cross-Chain Messages - Phase 2", "body": "The status of messages sent to addresses in the addressBanned mapping of the Bridge contract is set to DONE. Otherwise, the message can be retried if it fails.  However, the check for banned addresses is not made when retrying a message. This makes it theoretically possible for a message to call a newly banned address if its status was set to RETRIABLE before the address got added to the addressBanned mapping. This could for example be exploited if future deployment addresses are predictable and the code is open source, by calling such functions before the contract is deployed and its address is banned. This would set up dormant messages which can be processed later.  Consider checking the target of messages in the retryMessage function to avoid potential issues.  Update: Resolved in pull request #16394 at commit a6470a1. The Taiko team stated:  Not only because of this but also to avoid confusing, we removed the banning address feature completely.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#banned-addresses-could-be-called-by-cross-chain-messages---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Some Bridged Messages Can Not Be Refunded - Phase 2", "body": "processing a message on its destination chain's  \"banned\". This refund is always  sent to the  reverts. Otherwise, if the refund and the message call were successful, the status of the message is set to  DONE or  RETRIABLE. A message with the  FAILED if desired. This allows for the message to be  recalled on the source chain so its original sender can be  refunded.  banned. This could for example happen if  Consider not calling sendEther when the refund sent is 0. This would prevent the above from occurring except when the target address is banned, in addition to saving gas. Alternatively and to account for this last case if desired, consider setting the status of messages targeting banned addressed to FAILED instead of DONE. This would allow removing the concept of refunds entirely, simplifying the code, and allowing for these messages to be recalled by their original sender.  Update: Partially resolved at commit dd8725f. The ban of addresses was removed, and message processing now uses sendEtherAndVerify which does not trigger an external call if the value sent is 0. We note that it is however still possible for funds to get stuck if the destOwner is a contract without payable fallback and receive functions.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#some-bridged-messages-can-not-be-refunded---phase-2", "labels": ["OpenZeppelin"]}, {"title": "\u2018DelegateOwner\u2019 Does Not Check for Contract Existence - Phase 3", "body": "The DelegateOwner contract is intended to be deployed on L2 and set as the owner of all the other L2 contracts. The DAO on L1 can then call it through the Bridge contract to execute arbitrary calls in its name. This could, for example, be used by the DAO to execute privileged functions on L2 from L1. Calls from the DelegateOwner can be either low-level calls or delegate calls based on an input parameter.  However, low-level calls in Solidity do not check for contract existence. Such calls could thus be considered successful if the contract called has not been deployed yet, resulting in silent failures.  Consider validating the contract's existence if the given call.txdata is non-empty.  Update: Resolved in pull request #17328 at commit 39505e5 and pull request #17480 at commit 60d5d22.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#\u2018delegateowner\u2019-does-not-check-for-contract-existence---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Storage Collision in Bridge Contract - Phase 3", "body": "The Bridge implementation was upgraded. The previous implementation stored nextMessageId as a uint128 in storage slot 251. The new implementation stores two uint64 values instead, __reserved1 and nextMessageId, declared in that order.  init2 function, the  Consider validating that nextMessageId was not incremented before upgrading the contract to avoid loss of funds.  Update: Resolved. The Taiko team stated:  This issue affects the testnet since the previous version of the code was deployed. Fortunately, no one exploited this bug to manipulate the bridge and steal testnet tokens.  We now have a script to automatically verify that storage layouts are compatible with the previous version. On the testnet, we will avoid upgrades that could cause these kinds of issues.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#storage-collision-in-bridge-contract---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Inexplicit Revert - Phase 3", "body": "When a token is bridged through the ERC20Vault contract, the destination chain message value is derived as msg.value - _op.fee. However, this can lead to an underflow revert if the provided fee exceeds the message value.  Consider checking the values beforehand, as done in the Bridge contract.  Update: Resolved in pull request #17329 at commit f8042a2.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#inexplicit-revert---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Unrestricted Receive Function - Phase 3", "body": "The Bridge contract implements a receive function that allows anyone to send ETH to the contract. This might be necessary during setup to meet the amount of ETH that was minted in the genesis state on L2 and is in circulation on the rollup. However, for users interacting with the bridge, it can be a pitfall to accidentally get their funds locked.  Consider restricting the receive function to the owner role, or finding another way to balance these amounts between L1 and L2.  Update: Resolved in pull request #17330 at commit 4ef2847. The Taiko team stated:  Currently our approach is to remove the receive, but only after the genesis, once we seeded the initial liquidity.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#unrestricted-receive-function---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Lack of Constraints During Migration - Phase 3", "body": "The changeBridgedToken function of the ERC20Vault contract can be called to change the representation of a canonical token on the current chain. While the function can only be called by its owner, consider adding the following validations to reduce the risk of error:  A validation that ctoken.addr != 0 and _ctoken.chainid != block.chainid.  If desired, a check could be added that the _btokenNew address has code. This would constrain new canonical token deployments to always happen before migrations, but would reduce the risk of error.  Update: Resolved in pull request #17333 at commit 8d14e84.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#lack-of-constraints-during-migration---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Calldata Gas Accounting in Message Processing - Phase 3", "body": "The minimum gas limit set for a message accounts for the calldata costs of an encoded Message struct when processing the message. This is done by adding (message.data.length + 256) / 16 to a flat gas reserve.  The following issues were identified:  The computation of gas cost per calldata byte is done by dividing, although it should be multiplying by 16.  The word length accounted for the encoded Message struct is 7 words plus the dynamic data length, while additionally overcharging one word to account for the rounded up dynamic size. The actual encoding of the Message struct requires 13 words plus the dynamic data length, while the dynamic length can be rounded up to a multiple of 32. Hence, the bytes length formula should be 13 * 32 + ((dataLength + 31) / 32) * 32.  The calldata cost is not accounted for in the gas charged when calculating the fee, although it is at the expense of the processor. This is due to gasCharged only accounting for the gas consumption between the two calls to gasleft(), which does not include the gas costs associated with encoding _message in the transaction calldata.  Consider correcting the minimal gas and fee calculations to reflect more accurate costs.  Update: Resolved in pull request #17284 at commit 1a5b040 and pull request #17529 at commit 8c91db2.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#incorrect-calldata-gas-accounting-in-message-processing---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Message Processors Can Control Gas and Fee Consumption - Phase 3", "body": "Bridge contract allows users to send cross-chain messages between chains connected by a  sending a cross-chain message, users can input a  gas limit and a fee associated with the message. If the gas limit is non-zero, third party message processors can call  processMessage on the destination chain to process the message in exchange for  a part of the fee depending on the consumed amount of gas.  In pseudocode, and assuming no precision issues, a message processor is paid:  To control how much gas is charged, the message processor can add an arbitrary number of zero bytes at the end of the encoding of the HopProof[] in _proof. These excess bytes will be ignored during abi decoding but will consume unnecessary gas by expanding memory at the expense of the original message sender.  Because each zero byte of calldata costs 4 gas to the message processor and the memory expansion happens in the proxy contract as well, such attacks can only be profitable if message.gasLimit and/or message.fee are very high. A proof of concept shows that this exploit requires rather extreme conditions which are unlikely to occur in practice.  If such attacks are a concern, consider adding a validation that proof.length has a size in bytes below a certain threshold (e.g., 200,000). The quadratic part of the memory expansion costs only matters here for very high proof.length. Alternatively, consider removing the manual decoding of hopProofs and replacing it with a HopProof[] calldata argument.  Update: Resolved in pull request #17429 at commit 2fd442a.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#message-processors-can-control-gas-and-fee-consumption---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Inaccurate Gas Limit on Message Invocation - Phase 3", "body": "sendMessage on the  executed with at least A gas,  message length plus a flat gas amount.  When a message is processed by a third party, the gas remaining before invoking the user's message is validated to be greater than 64 / 63 * A. This is because of EIP-150, which silently caps the amount of gas sent in external calls to 63 / 64 * gasleft(). If such a check were not present, it would be possible for the gas to be capped by EIP-150, executing the call with less than A gas.  However, while the intention was correct, a gas limit of A is not guaranteed. This is due to the gas expenses that accumulate between the EIP-150 check and the actual message execution on the target:  Memory expansion costs  Account access  Transfers  Opcode costs  Because 1 / 64 * gasleft() has to be enough to execute the rest of the processMessage function without running out of gas, a gas limit below A on the target is only possible for high gas limits. This proof of concept shows the issue in practice.  Consider addressing the above to build a more predictable bridge for users and projects sending cross-chain messages. What follows is an example of how this could be achieved.  The goal of the computation is to ensure that EIP-150 does not silently cap the amount of gas sent with the external call to be less than A. We note:  memory_cost: the amount of gas needed to expand the memory when storing the inputs and outputs of the external call.  access_gas_cost: the gas cost of accessing the message.to account. This currently corresponds to 2600 gas if the account is cold, and 100 otherwise.  transfer_gas_cost: the cost of transferring a non-zero msg.value. This cost is currently 9000 gas but provides a 2300 gas stipend to the called contract.  create_gas_cost: the cost of creating a new account, currently 25000 gas. This only applies if message.value != 0, message.to.nounce == 0, message.to.code == b\"\", and message.to.balance == 0. Since message.to is checked to have code, this cost can be ignored here.  Thus, we want to check that the following:  reference implementation). The sum of  memory_cost is cumbersome to compute in practice, but by estimating the costs through tests, we can upper-bound the cost of memory expansion for up to  As such, it would be possible to validate that the call will have enough gas by checking the following condition right before the external call is made:  This would be accurate for messages with up to 10_000 bytes of message.data. Any message above this limit could be required to have a gas limit of zero which would force it to be processed by its destOwner. A similar approach, without a constraint on the data size, has been adopted by Optimism and can be used as inspiration.  Update: Resolved in pull request #17529 at commit a937ec5. After further discussions with the audit team, the fix implemented follows an alternative, more efficient approach than the one suggested in the issue.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#inaccurate-gas-limit-on-message-invocation---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Use of Named Returns - Phase 1", "body": "Throughout the codebase, there are multiple instances where contracts have inconsistent usage of named returns in their functions:  In the Bridge contract  In the DevnetTierProvider contract  In the MainnetTierProvider contract  In the TaikoL1 contract  In the TaikoL2 contract  In the TestnetTierProvider contract  In the ERC1155Vault contract  In the ERC20Vault contract  In the ERC721Vault contract  In the SgxVerifier contract  In the SignalService contract  In the TimelockTokenPool contract  Consider being consistent with the use of named returns throughout the codebase.  Update: Acknowledged, not resolved. The Taiko team stated:  Decided not to proceed with a fix.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#inconsistent-use-of-named-returns---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Lack of Indexed Event Parameters - Phase 1", "body": "Throughout the codebase, several events could benefit from having indexed parameters:  The GuardiansUpdated event of Guardians.sol could index the version parameter.  The MessageSuspended event of IBridge.sol could index the msgHash to be consistent with the other events defined above.  The Anchored event of TaikoL2.sol could index the parentHash.  The MigrationStatusChanged event of BridgedERC20Base.sol could index both the addr and the inbound parameters.  The Withdrawn event of ERC20Airdrop2.sol could index the user parameter.  The SignalSent event of ISignalService.sol could index the app and the signal parameters.  The Claimed event of MerkleClaimable.sol could index the hash.  The BlobCached event could index the blobHash parameter.  To improve the ability of off-chain services to search and filter for specific events, consider indexing the event parameters identified above.  Update: Acknowledged, not resolved. The Taiko team stated:  We decided not to add additional indexes as most of these events are not used directly by end users.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#lack-of-indexed-event-parameters---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Signatures Do Not Use EIP-712 - Phase 1", "body": "The AssignmentHook is a canonical hook using signatures to validate that the prover agreed to prove a certain block in exchange for a certain amount of fees. These signatures can be from EOAs or from smart contracts using EIP-1271. However, the signed data does not respect EIP-712. Depending on how the prover is expected to sign this data (e.g., through a third-party frontend) it could be beneficial to use a standard supported by the service providers such as wallets, etc.  Consider formatting the signed data according to EIP-712.  Update: Acknowledged, not resolved. The Taiko team stated:  We decided not to proceed with this as Assignments are signed by provers in the backend.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#signatures-do-not-use-eip-712---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Gas Optimization - Phase 1", "body": "The following opportunities for gas optimizations were found:  The EssentialContract contract packs two variables, __reentry and __paused, as two uint8 values in one storage slot. However, by default, these variables are neither read nor written at the same time. Consider changing them to be uint256 to save gas.  Resolved names such as \"proposer\", \"tier_provider\", and \"taiko_token\", domain separators such as \"PROVER_ASSIGNMENT\" or \"SIGNAL\", and verifier names such as \"tier_sgx\" could be constant bytes32 contract variables.  During during block verification, the tko token address could be cached, similar to the tier provider.  In the GuardianProver contract:  The Approved and the GuardianApproval events are always emitted consecutively and have some duplicate information. Consider only emitting one. The indexation of the guardian could use the loop iterator i + 1 instead of guardians.length to avoid reading from storage in the loop. The minGuardians storage variable read in the for loop during approvals could be cached to memory, similar to guardians.length. The address[] memory _newGuardians  argument could be stored in calldata to avoid copying the array to memory.  In the sendEther function, no returned value is necessary and the allocation of 64 bytes of memory could be avoided.  In the anchor function, the blockhash(parentId) and the state variable gasExcess could be cached to memory to save gas during the Anchored event emission.  In the onBlockProposed function of hooks, the _blk, _meta and _data arguments could be in calldata rather than memory by default to save gas.  Consider updating the identified instances to save gas during the operation/deployment of the protocol.  Update: Partially resolved at commit 84f06f3. All items except items one and four were addressed.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#gas-optimization---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Inefficient Bridge Message Handling - Phase 1", "body": "When a message has been processed before and the message call has failed, bridge users are currently forced to retry a message invocation on the destination chain to transition its status to FAILED. This is the case even in situations where it is known in advance that _invokeMessageCall will again not be successful. This status transition is necessary for users to invoke the recall function to recover their funds on the source chain.  Consider adding a way for users to directly transition a message's status from RETRIABLE to FAILED without having to retry executing the message call. This would reduce gas consumption for affected users and enhance their overall user experience by streamlining the process.  Update: Resolved in pull request #16669 at commit dce651e.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#inefficient-bridge-message-handling---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Code Quality and Readability Suggestions - Phase 1", "body": "The following opportunities to improve the quality of the codebase were identified:  The graffiti component of the Transition struct is unused and could be removed to save gas. Alternatively, consider documenting its use.  The TransitionState struct could be renamed to StateTransition.  The _createTransition function could be renamed (e.g., to \"_fetchOrCreateTransition\") as it does not always create a new transition.  The config validity check for the blockMaxProposals parameter could check that \"blockMaxProposals <= 1\" instead of == 1.  _operationId could be renamed to _blockId for consistency and clarity. Similarly, the proofSubmitted event argument could be renamed to minGuardiansReached as the Guardians contract has no context on a proof.  The init function of the TaikoTimelockController does not grant the PROPOSER_ROLE nor the EXECUTOR_ROLE to the TaikoGovernor contract. While the TIMELOCK_ADMIN_ROLE is granted to the owner, meaning that it could grant these roles separately, it would be clearer and simpler if these were granted during initialization. Consider passing the address of the TaikoGovernor to grant these roles during initialization. Alternatively, consider documenting that these roles are to be granted separately.  The _genesisBlockHash could be checked to be nonzero during initialization to ensure the following transitions can be proven.  The L1_TOO_MANY_TIERS error is unused and could be removed.  The AM_INVALID_PARAMS and AM_UNSUPPORTED error names are vague and could be changed to be more accurate (e.g., to \"AM_ADDRESS_ALREADY_SET\" and \"AM_PAUSE_UNSUPPORTED\", respectively).  Consider addressing the above instances to improve the clarity and safety of the codebase.  Update: Partially resolved in pull request #16667 at commit 250ad7d. All the issues were addressed except for the second point. Note: The TaikoTimelockController was removed in pull request #16933.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#code-quality-and-readability-suggestions---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Missing or Misleading Documentation - Phase 1", "body": "The following opportunities to improve the clarity of the documentation were found:  The structs defined in the TaikoData library would benefit from some added documentation on what the different fields represent.  The EthDeposit struct is incorrectly documented as using 1 slot but actually uses 2 slots as it is 40 bytes long.  meta.coinbase is documented as being the L2 block proposer, but it is only chosen by the block proposer.  In the proveBlock function, a comment mentions that if the transition does not exist the tid will be set to 0. However, it is set to 1 in practice.  A conditional branch for the TIER_OP tier is present in the code but could be documented as only being used for testnet.  The contest bond is documented as being burned from the prover, but it is only transferred and can in fact be regained if the transition is proven to be invalid.  The _overrideWithHigherProof function would benefit from better documentation overall (e.g., when ts.contester == 0 for the first transition, there is technically no existing contest but the code still uses this branch).  The NatSpec around the getBasefee function indicates that the function can be used to \"get the basefee and gas excess [...]\". However, the function only returns the base fee.  The NatSpec around the __ctx variable in the Bridge contract indicates that it fits in 3 slots, whereas it only occupies 2.  The NatSpec around the proveMessageReceived function is incorrect as it was duplicated from the function above it.  The NatSpec around the getInvocationDelays function has an extra \"and\" in the phrase \"a message can be executed since and the time it was received\".  The processDeposits function could use some additional documentation (e.g., around the fee logic).  The Message struct in the IBridge interface could document that the gasLimit of a message can be set to 0 so that only the destOwner can process the message on the destination chain. Additionally, the gasLimit could be documented as not being respected on message retries or when processed by the owner.  A comment around the gasLimit is reversed, as the remaining gas is used if called by the owner.  Consider addressing the above instances to improve the clarity and readability of the codebase.  Update: Partially resolved in pull request #16681 at commit f31a6ac. All the mentioned instances were fixed except for item 8 in the list. Note that the fifth item was resolved separately in commit 2c63cb0.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#missing-or-misleading-documentation---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors - Phase 1", "body": "The following typographical errors were identified in the codebase:  isAssignedPover should be isAssignedProver.  deleys should be delays.  Indenitifer should be Identifier.  \"send\" should be \"sent\".  \"choose use\" should be \"choose to use\".  tran should be transitions.  Consider addressing the above instances to improve the quality of the codebase.  Update: Resolved in pull request #16667 at commit 250ad7d.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#typographical-errors---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Changing Governor Parameters Requires an Upgrade - Phase 1", "body": "These parameters are hardcoded in the contract and would require a contract upgrade if there was a need to update them.  If such flexibility is desired, consider inheriting from GovernorSettingsUpgradeable to allow for these parameters to be changed by governance without having to upgrade the contract.  Update: Resolved in pull request #16687 at commit eba82ba.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#changing-governor-parameters-requires-an-upgrade---phase-1", "labels": ["OpenZeppelin"]}, {"title": "Unused Named Return Variables - Phase 1", "body": "Named return variables are a way to declare variables that are meant to be used within a function's body for the purpose of being returned as that function's output. They are an alternative to explicit in-line return statements.  In the codebase, there are instances of unused named return variables:  The invocationDelay_ return variable in the getInvocationDelays function in Bridge.sol  The invocationExtraDelay_ return variable in the getInvocationDelays function in Bridge.sol  Consider either using or removing any unused named return variables.  Update: Resolved in pull request #16600 at commit f6efe97.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#unused-named-return-variables---phase-1", "labels": ["OpenZeppelin"]}, {"title": "The TimelockTokenPool May Not Be Compatible With ERC-4337 - Phase 2", "body": "ERC-4337 is a standard that allows smart contracts to behave like user accounts. Under the EIP there will be ERC-4337 smart contract accounts in addition to Externally Owned Accounts (EOA). The former account type is incompatible with some code, such as tx.origin or ecrecover.  The TimelockTokenPool uses ecrecover for the withdrawal of the grant, which could be inconvenient for smart wallets and multisigs.  If smart wallet support is desired, consider using EIP-1271 to allow smart contract accounts to verify signatures instead of ecrecover. This could for example by achieved by using the SignatureChecker library instead of ECDSA.  Update: Resolved in pull request #16934. The Taiko team stated:  Removed (underway) the TimelockTokenPool, and the new one (under supplementary-contracts) will always be EOAs.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#the-timelocktokenpool-may-not-be-compatible-with-erc-4337---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors - Phase 2", "body": "The following typographical errors were identified in the codebase:  \"authrized\" [1] [2] should be \"authorized\"  \"Indenitifer\" [1] [2] should be \"Identifier\"  \"converison\" should be \"conversion\"  Consider correcting the above instances to improve the quality of the codebase.  Update: Resolved in the following commits: 810e723, 0eec494 and 1b9ba53.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#typographical-errors---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Gas Optimizations - Phase 2", "body": "The following opportunities for gas optimizations were found:  When emitting the MigratedTo event, the msg.sender could be used in place of the migratingAddress variable to save gas.  The isClaimed mapping in the MerkleClaimable contract could be made more efficient. Consider using a BitMaps instead, for example see Uniswap's MerkleDistributor.  The ERC1155Vault contract could call the _burnBatch (for example by implementing a public burnBatch function in BridgedERC1155) and safeBatchTransferFrom functions of ERC-1155 instead of the burn and safeTransferFrom functions. This would reduce the number of external calls and reduce gas costs.  Consider updating the identified instances to save gas during the operation/deployment of the protocol.  Update: Partially resolved at commit dd8725f. All the items were resolved except the second one. The Taiko team stated:  As the claiming will be done on our L2, gas cost shall not be an issue, and would want to avoid such changes as the infrastructure (for claiming and putting together off-chain data) is already in place.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#gas-optimizations---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Missing or Misleading Documentation - Phase 2", "body": "The following opportunities to improve the clarity of the documentation were found:  The CrossChainOwned abstract contract allows an \"owner to be a local address or one that lives on another chain\". However, during initialization the _ownerChainId is checked to be different from block.chainid, and it is used to synchronize the state root with another chain. It is thus unclear which value to give _ownerChainId if the owner is \"local\".  The BridgeTransferOp struct is documented in the BaseNFTVault contract but not in the ERC20Vault. Consider adding this documentation.  The NatSpec around blockSyncThreshold says that \"a value of zero disables syncing\", but this is not the case. Consider removing this comment.  The phrase \"uniquely from chainId, kind, and data\" above isChainDataSynced was copied from above and should be removed.  The documentation around the sendSignal function explains that it \"sets the storage slot to a value of 1\", however in practice the storage slot is set to signal.  The getMyGrantSummary function computes the cost to withdraw a token grant. Because the grant amount is divided by 1e18 before being multiplied by the cost, it is possible for the costToWithdraw to be off by one token over the lifetime of the grant. Consider documenting this to make it clear to readers. Besides, the arguments and return values of the getMyGrantSummary function are not documented.  Consider addressing the above instances to improve the clarity of the codebase.  Update: Resolved in pull request #17483. The CrossChainOwned and TimelockTokenPool contracts have been removed, so the first and last items no longer apply.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#missing-or-misleading-documentation---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Lack of Indexed Event Parameters - Phase 2", "body": "Multiple events could benefit from having indexed parameters:  The InstanceAdded event could index its replaced parameter.  The Withdrawn event could index its to parameter.  To improve the ability of off-chain services to search and filter for specific events, consider indexing the event parameters identified above.  Update: Resolved in pull request #16949. The Taiko team stated:  TimneLockTokenPool is deleted, but the other one is a good spot.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#lack-of-indexed-event-parameters---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Code Quality and Readability Suggestions - Phase 2", "body": "The following opportunities to improve the codebase were identified:  The SafeCast import in the SignalService contract is unused and could be removed.  The Strings import in the BridgedERC20 contract is unused and could be removed.  The customConfig state variable in the TaikoL2EIP1559Configurable contract is not used. Additionally, it is not initialized alongside the other variables. Consider removing it or initializing it during initialization.  The initializer __Essential_init is not protected by a onlyInitializing modifier. Consider adding one for consistency.  The __gap variable of the TimelockTokenPool contract is defined as a uint128[], which is error-prone. Consider changing it to be a uint256[] for consistency and safety.  The same MigratedTo event is used in two different contexts: when migrating from, and when migrating to. Consider emitting the migratingInbound variable as part of the MigratedTo event to differentiate these two situations.  The MessageRetried event could include the new status of the message.  The EssentialContract could have a public __reentry getter. This could be useful for integrations wanting to avoid potential read-only reentrancies when reading from the state of the protocol.  The BaseVault contract could support the IMessageInvocable ERC-165 interface id.  The deployment of bridged token contracts by vaults [1] [2] [3] currently uses CREATE. If desired, it could use CREATE2 with a salt depending on ctoken.addr and ctoken.chainId for example. This would make the deployment address of bridged tokens standardized and predictable.  The validSender(address _app) modifier validates the _app address is nonzero, and could thus be renamed to \"nonZeroApp\" for consistency and clarity.  MerkleClaimable is an abstract contract allowing an owner to set a Merkle root  against which proofs can be submitted during claims. The ability for an owner to set a new Merkle root even as an airdrop is already happening should be prevented or documented to minimize the risk of error and user loss.  Consider crediting Optimism explicitly in the NatSpec for the RLPWriter and RLPReader libraries. This would make it easier to review and diff against their version, in addition to crediting them for the libraries.  msg.sender could be replaced by user in the _handleMessage function for clarity and consistency.  Consider addressing the above instances to make the code clearer and safer.  Update: Partially resolved at commit dd8725f. All the items listed were addressed except for the tenth and twelfth ones.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#code-quality-and-readability-suggestions---phase-2", "labels": ["OpenZeppelin"]}, {"title": "BridgedERC1155 Does Not Return Correct URI - Phase 2", "body": "The BridgedERC1155 token currently does not override the uri method to return URIs specific to each token ID. As it stands, the method returns a uniform URI regardless of the input token ID, leading to a bad user experience.  Consider overriding the uri method such that it dynamically generates or retrieves URIs based on the token ID provided. Implementing this change will align the token functionality with typical expectations for ERC1155 tokens and enhance user experience.  Update: Acknowledged, not resolved. The Taiko team stated:  It was a design choice picked by Daniel and Brecht. So basically to give a signal, that this particular NFT is a bridged one, and the source could be find here and there (with .buildURI())", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#bridgederc1155-does-not-return-correct-uri---phase-2", "labels": ["OpenZeppelin"]}, {"title": "Gas Optimizations - Phase 3", "body": "The following opportunities for gas optimizations were identified:  The tokenQuota[_token].quota storage variable is read twice in the updateQuota function. Instead, it could be stored as an oldQuota stack variable to save gas.  The _transferTokens function first forwards the tokens that are sent to the destination chain or recalled on the source chain and then checks the available quota in the QuotaManager. Assuming that the call more likely fails at the quota check, it would be cheaper to check the available quota first and thereby fail early.  Consider applying the changes above to make the code a little bit more gas efficient.  Update: Resolved in pull request #17483 at commit 09e5508.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#gas-optimizations---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Code Quality and Readability Suggestions - Phase 3", "body": "The following opportunities to improve the codebase were identified:  The DO_TARGET_CALL_REVERTED error is unused and could be removed.  The BTOKEN_INVALID_TO_ADDR errors [1] [2] [3] are unused and could be removed.  The fee calculation in line 284 of Bridge.sol is calculated based on baseFee, maxFee, and _message.fee. The resulting minimal fee is determined through the in-place comparison between baseFee and maxFee, which harms readability. Instead, consider chaining two .min() expressions to simplify the code. For example: uint256 fee = _message.fee // the fee is at most as provided     .min(maxFee) // the capped fee if baseFee >= maxFee     .min((maxFee + baseFee) >> 1); // the capped fee if maxFee > baseFee, the profit is halved  The TokenSent event could include ctoken.chainid as canonical tokens are uniquely identified by the combination of their address and their source chain.  Consider applying the above changes to improve the clarity of the codebase.  Update: Resolved in pull request #17483 at commit 119ffd6 and pull request #17502 at commit 9dd90cc.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#code-quality-and-readability-suggestions---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Typographical Error - Phase 3", "body": "A typographical error was identified in Bridge.sol. \"Owner\" has been incorrectly written as \"Owenr\".  Consider fixing the error to improve the readability of the codebase.  Update: Resolved in pull request #17303 at commit b63c2c1.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#typographical-error---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestion - Phase 3", "body": "In the ERC20Vault, the btokenBlacklist mapping keeps track of token contracts that have been replaced. Consider renaming the mapping to btokenBlocklist or btokenDenylist, using a more neutral wording.  Update: Resolved in pull request #17331 at commit 8495f04.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#naming-suggestion---phase-3", "labels": ["OpenZeppelin"]}, {"title": "License Incompatibility in LibBytes - Phase 3", "body": "The toString function is used to decode abi encoded bytes32 or string data into a string. This function is taken from another codebase which is licensed under AGPL-3.0.  However, the current codebase is licensed under MIT, which is incompatible with code licensed under AGPL-3.0.  Consider using an MIT-licensed alternative to avoid such an issue (e.g., BoringERC20).  Update: Resolved in pull request #17504 at commit 8b6c137.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#license-incompatibility-in-libbytes---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Missing and Misleading Documentation - Phase 3", "body": "Several instances where some documentation was missing or misleading were found:  When processing a message through the bridge, the message's target and data are checked. While the accompanying comment says \"Handle special addresses that don't require actual invocation\", the message is simply rejected if the invocation conditions are not satisfied, some of which are not related to the target address. Consider clarifying the comment with the intention of the check.  The comment about reentrancy for the DelegateOwner's onMessageInvocation function is outdated as the function is not intended to be reentered any more and is protected from reentrancy through the Bridge contract.  The comment above the IBridgedERC20 interface may be outdated as USDC specifically no longer requires an intermediary adapter contract. Other tokens may require one still.  The _quota parameter of the updateQuota function is described as \"The new daily quota\", whereas the quota is measured by the quotaPeriod.  The fee calculation of the processMessage function is overall not documented. This makes it more difficult to reason about how the fee is constructed. Consider adding comments to each step of the calculation to explain why it is necessary.  The documentation around the IBridgedERC20 interface could add a list of specifications canonical tokens should respect. For example, the code assumes calls to burn or mint to increase/decrease the balance by exactly the amount given as argument. Tokens with fees on burn/mint, or taking type(uint256) to mean the balance of the sender, are not supported. Similarly, a bridged token should have the same name, symbol, and decimals as its canonical version if these are implemented. This list of specifications could be built up over time to reduce the risk of error with such tokens. An example of supported token specifications can be found here.  The comment about the amount of gas which should be associated with a transaction calling processMessage is misleading. The gas sent with a transaction can in fact be smaller than (message.gasLimit - GAS_RESERVE) * 64 / 63 + GAS_RESERVE if the invoked call uses way less gas than specified in the message's gas limit. Additionally, the calculation is not fully accurate as it neglects the message data length that is accounted for in the getMessageMinGasLimit function. In addition to correcting the calculation, consider rewording the comment as a recommendation, for example, as follows: \"To ensure successful execution, we recommend this transaction's gas limit not to be smaller than: [...]\".  Consider addressing the instances identified above to improve the clarity and readability of the codebase.  Update: Resolved in pull request #17483 and pull request #17546 at commit 7fa3b55.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#missing-and-misleading-documentation---phase-3", "labels": ["OpenZeppelin"]}, {"title": "Client Reported", "body": "Client Reported", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Deletion During Migration in \u2018ERC20Vault\u2019", "body": "The changeBridgedToken function can be called by the owner of an ERC20Vault contract to migrate a bridged token to another contract.  However, during this migration, a bridgedToCanonical mapping slot is deleted for the new token address instead of the old token. The old token is still correctly blacklisted, meaning that it can no longer be bridged, but the mapping should be cleared correctly to make the code clearer and save gas.  Update: Resolved at commit 42c279f.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#incorrect-deletion-during-migration-in-\u2018erc20vault\u2019", "labels": ["OpenZeppelin"]}, {"title": "Static Calls to \u2018proveSignalReceived\u2019 Revert on State Caching", "body": "proveSignalReceived function in the  called in the _proveSignalReceived function in the  cached.  Update: Resolved at commit dd8725f. The static call was removed, and two functions were made available in SignalService: a view function without caching, and a separate function with caching.", "html_url": "https://blog.openzeppelin.com/taiko-protocol-audit#static-calls-to-\u2018provesignalreceived\u2019-revert-on-state-caching", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Share Accounting When Rolling Options", "body": "An options roll can be used to burn a position and transfer the burned position's size to a new OTM position that may differ in only strike and width. Several scenarios can lead to the option owner being able to collect an undue profit or not receiving the profit/loss they are owed due to collateral share accounting during rolls.  When numeraire equals tokenType  The notional value will be equivalent to positionSize * optionRatio, independent of the strike value. When rolling a position to a different strike, the notional values, hence the long/short amounts will be the same. In this case, the net longAmounts and shortAmounts would be zero. This block will be skipped, thus resulting in zero change (other than premium) in the option owners share amount. If the original position is in profit or loss, the usual updates to the share balances during exercise will not happen. A more drastic scenario happens when a user first mints an ITM position at a strike price far away from the current tick, which can cause the swapped amount to be small relative to the short (or long) amount. This results in shares minted to the user. They can then roll the position and keep the new shares (which would normally be accounted for during exercise) which are redeemable for profit.  When numeraire does not equal tokenType  Consider modifying the share accounting logic during rolls to prevent unaccounted new shares from being minted to the option owner, as well as ensuring that the old position is exercised correctly.  Update: Resolved at commit 4e1de7a.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#incorrect-share-accounting-when-rolling-options", "labels": ["OpenZeppelin"]}, {"title": "Roll Token ID Validation Fails", "body": "When an oldTokenId is rolled into a newTokenId from the PanopticPool, the intention inferred from the ROLL_MASK is that only the width and strike can be different in each leg with all other parameters being the same. However, when rolledTokenIsValid is checked in the SFPM, when the roll validation fails, it will simply skip to the else block that assigns the old and new tokenId without any restriction.  Consider validating that the new token IDs exactly match the previous ones when a roll is done.  Update: Resolved at commit 4e1de7a.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#roll-token-id-validation-fails", "labels": ["OpenZeppelin"]}, {"title": "Shares Can Be Transferred With Open Positions", "body": "Shares can be transferred or redeemed from an owner's account while they have open positions. In several cases, msg.sender is used where it should be from or owner:  transferFrom  maxWithdraw used in withdraw  maxRedeem used in redeem  By approving a second account with no open positions, the owner can thus transfer/redeem their entire share balance with unexercised positions.  This can expose the Panoptic pool to potential losses when the owner transfers out the shares, leaving under collateralized positions in the pool.  The owner can collect an undue profit by, for example, minting an ITM position where more shares are minted and then redeeming them.  Consider correcting the logic of the previously mentioned functions to check the number of open positions for the right account.  Update: Resolved.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#shares-can-be-transferred-with-open-positions", "labels": ["OpenZeppelin"]}, {"title": "Liquidation Can Be Avoided Due to Unbounded Position List", "body": "Each account in the Panoptic Pool has a positionIdList associated with it, containing all active positions. This list is used to validate the input holdings via the positionHash, calculate collateral requirements as well as compute the premia when minting a new tokenId or liquidating an entire account. The positionIdList is an unbounded array that could potentially expose the Panoptic pool to the following key risks.  Underwater accounts with large positionIdList can avoid liquidation  Account liquidation requires the burning of all active options associated with an account. It is possible to avoid liquidation of a margin-called account by keeping a large array of dummy positions to use up the block gas limit. Due to the many loops involved in the liquidateAccount call, it takes less than 200 tokenIds to exceed the block gas limit of 30 million.  Well-collateralized account may not be able to mint further  When minting an option, all past positions in positionIdList are passed in mintOptions as a parameter with the new position to mint appended at the end. The past positions are used to validate the position hash for the msg.sender and check the solvency status of the account. When the list of past positions becomes too large, the gas expense of processing the past checks could exceed the block gas limit. This will disable the account to mint a further position. From our experimentation, the limit is approximately of the magnitude of 2000 tokenIds for the current implementation.  In summary, the asymmetry of being able to mint much further than getting liquidated could allow malicious actors to expose the pool to unwanted losses by blocking liquidation. Since it is crucial for the system to evaluate the past positions of an account, consider setting an upper limit on the length of positionIdList to ensure that the liquidation of an underwater account can be executed.  Update: Resolved.  High Severity", "html_url": "https://blog.openzeppelin.com/panoptic-audit#liquidation-can-be-avoided-due-to-unbounded-position-list", "labels": ["OpenZeppelin"]}, {"title": "Undercollateralized ITM Positions Can Be Minted", "body": "When minting short options, the collateral requirements are computed as amount * collateralRatio * maintenanceMarginRatio where amount is the number of options contracts denominated in the numeraire, collateralRatio is between 0.2 and 1 depending on the current pool utilization, and maintenanceMarginRatio is a fixed quantity (1.3333). The position can be liquidated if the required value is more than the token value of the account balance. These values are calculated from the token data returned by getAccountMarginDetails. This function will use an additional term in calculating the required collateral of a position to evaluate the profit/loss of that position when it is ITM, which can result in the required collateral being higher than when minting and can exceed the collateral balance of the user. The user is then immediately vulnerable to liquidation because their position is undercollateralized.  When minting a new ITM position, the profit/loss of the new position is not considered immediately in the collateral calculation, resulting in a position that can be liquidated right away following the mint. Consider calculating collateralization requirements the same way during both minting and when checking if an account is liquidatable.  Update: Resolved at commit 4e1de7a.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#undercollateralized-itm-positions-can-be-minted", "labels": ["OpenZeppelin"]}, {"title": "Premia Calculation Can Overflow", "body": "When calculating the accumulated premia for a position's leg, the accrued fees for the tick range are multiplied by the position's liquidity amount. Both quantities are of type uint128 and thus can overflow in the intermediate step of legPremia. This results in less premium received by option sellers and less premium paid by option buyers. Additionally, when a position is exercised, this resulting premium value will be passed in and so the locked amount will be updated incorrectly. Consider expanding to 256-bit integers for the leg premia multiplication.  Update: Resolved. Consider adding a comment to clarify the casting logic of both return values of the getAccountPremium function from uint128 to uint256.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#premia-calculation-can-overflow", "labels": ["OpenZeppelin"]}, {"title": "Leverage Not Available When Tick Is Negative", "body": "The available leverage for a newly minted option is based on the current pool utilization. A check is performed comparing the current tick with the median tick, and the utilization will be set to over 100% if there is too much deviation between the ticks. For short positions, this results in max_sell_ratio being used as the collateral ratio (i.e., 100%) so the required collateral will be the same as the shortAmounts. If the median tick and current tick are both negative and close together (the same, for example), the statement will return true not allowing leverage to be accessible. Consider accounting for negative tick values or checking price deviations instead of tick deviations to correctly set the collateral requirement.  Update: Resolved.  Medium Severity", "html_url": "https://blog.openzeppelin.com/panoptic-audit#leverage-not-available-when-tick-is-negative", "labels": ["OpenZeppelin"]}, {"title": "SFPM Token Transfer Can Fail With Multiple Touches to a Position Key", "body": "The position tokenId is minted to the caller as an ERC-1155 token and can be transferred with safeTransferFrom. The post-transfer hook will register the token transfer by validating the liquidity of each leg and updating the relevant state variables. For each leg, the netLiquidity of the from position should be equal to the chunk liquidity, otherwise the transfer will fail. This condition can be violated easily when the same position key is touched more than once, for instance, across multiple legs or across multiple tokenIds. The fromLiq.rightSlot() is a net quantity updated by all prior positions while liquidityChunk.liquidity() is a leg-specific quantity. Thus, one cannot expect them to be equal in general. Consider adjusting the required condition to allow legitimate transfer of SFPM tokens.  Update: Acknowledged, not fixed. The Panoptic team stated:  SFPM token transfers are only intended as a niche convenience feature primarily for transferring positions to new accounts and are limited by design. Transfers between accounts that share active position keys are not allowed because of security and accounting concerns regarding fee accumulation and integrators (i.e, the Panoptic pool). Legs with duplicate position keys in the same tokenId are very unusual and generally not advisable to mint (as an equivalent, more gas-efficient position can always be created by consolidating those legs), and as such we decided not to add extra logic to accomodate the transfer of these positions.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#sfpm-token-transfer-can-fail-with-multiple-touches-to-a-position-key", "labels": ["OpenZeppelin"]}, {"title": "Delegated Amount Does Not Consider Owed Premia During Force Exercise", "body": "An option seller is able to exit a position in the case of insufficient liquidity by force-exercising corresponding out-of-range long positions (from option buyers). The exercise will fail if the buyers position has accumulated fees in the other token (i.e., not tokenType) and there are not enough shares in the buyer's account to pay for it.  More concretely, assume that the long position has tokenType=1.  A buyer can mint a position by having collateral only in the tokenType token (i.e., if tokenType=1); only deposits in token1 are needed.  The long position can accumulate owedPremia in both tokens. During exercise, which occurs during the burning of options, the buyer needs to pay the owedPremia in both tokens as a multiple of collected fees. This will fail if there are not enough shares in token0. Thus, at this stage, the buyer could deposit more token0 to successfully exit.  If a seller wants to forceExercise this position, the seller needs to transfer to the buyer's account a delegatedAmounts, which is the longAmounts in the tokenType token (i.e., only in token1 for this instance). After the delegation, there still isnt enough token0 to exercise, and the force-exercise will fail.  This can be mitigated by the seller manually depositing shares to the buyer (set as receiver). However, this will cost the seller extra in mevTax.  Consider including owedPremia for both tokens in the delegatedAmounts during forced exercise.  Update: Resolved.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#delegated-amount-does-not-consider-owed-premia-during-force-exercise", "labels": ["OpenZeppelin"]}, {"title": "ETH Can Get Locked in Contracts", "body": "There are multiple occurrences throughout the codebase where ETH can become locked. For instance:  In the multicall function of Multicall.sol  In the constructor function of PanopticHelper.sol  Update: Acknowledged, not fixed. The Panoptic team stated:  This is intended. The functions are marked payable for a gas cost reduction, and there is no reason for end users to send ETH along with their calls. If they decide to do so, it is equivalent to burning ETH and has no effect on the operations of the protocol.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#eth-can-get-locked-in-contracts", "labels": ["OpenZeppelin"]}, {"title": "Available Assets Do Not Account For Long Positions", "body": "When a short position is minted, tokens are moved from the Panoptic Pool to the AMM pool thus reducing the balance of the pool. This amount is reflected in the reduction of the available assets, thus preventing withdrawals.  When a corresponding long position is minted, tokens are moved from the AMM pool to the Panoptic Pool, increasing the balance of the pool. The same amount is then added back to the available assets, allowing any LPs to withdraw their assets when the long position is still active.  With leverage, it is possible that after LP withdrawals, there may not be sufficient liquidity in the Panoptic Pool to transfer to the AMM pool when exercising the long position, thus disabling long positions from closing until further liquidity provision.  Consider accounting for the available assets used by both option buyers and sellers.  Update: Acknowledged, not fixed. The Panoptic team stated:  This is intended. Allowing removed long liquidity to be reused for short positions and withdrawals greatly enhances flexibility and user experience in most situations. It is possible for the pool to lack the funds necessary to exercise a long position in certain unusual circumstances, but users who wish to exercise their options have multiple options to free up funds in the event of a liquidity crunch. They can deposit more collateral, mint more long positons, close their short positions, or wait for other sellers to close positions.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#available-assets-do-not-account-for-long-positions", "labels": ["OpenZeppelin"]}, {"title": "Locked Funds May Become Inaccessible", "body": "The collected tokens from the AMM trading fees are locked every time a position is touched. In addition, the long position premia payment is also added to the lockedFunds when a position is exercised. The outflow of the locked tokens is for short position premia only computed in s_accountPremiumGross thus resulting in the possibility of accumulating a positive amount in the locked funds. Further, the calculation of total assets excludes the locked funds, thus withdrawing all shares will not enable access to the locked funds either. This creates the possibility that the locked tokens become inaccessible. Consider adding a way to funnel the locked tokens to the pool to mitigate this scenario.  Update: Acknowledged, not fixed. The explicit tracking of locked funds was replaced with a system that tracks asset balances in storage. This ignores donations, pending fee payouts, and any other untracked balance changes.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#locked-funds-may-become-inaccessible", "labels": ["OpenZeppelin"]}, {"title": "Initial Deposit to One Collateral Tracker Could Be Zero", "body": "While it is generally not possible to obtain enough liquidity to move a pool's tick to MAX_TICK or MIN_TICK, it is possible for pools with very low liquidity. Depending on the AMM pool, the cost of tick manipulation may be worth the potential profit. This enables the attacker to be the first depositor to the collateral tracker and launch the inflation attack as follows:  The attacker deposits 1 asset to the collateral tracker to get 1 share back.  A subsequent LP deposits some amount to the collateral tracker.  The attacker front-runs the transaction by transferring directly the same amount to the Panoptic pool. Thus, the LP from the previous step would get 0 shares in return due to rounding.  The attacker can then redeem his single share to get the combined amount of the LP deposit as well as the prior direct transfer.  Since a new Panoptic pool cannot be deployed with the same underlying AMM pool, it would be difficult to stop this attack once the attacker's initial deposit takes place. Consider ensuring that a minimum number of shares are minted in each collateral tracker during pool deployment to be resilient against the inflation attack.  Update: Resolved.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#initial-deposit-to-one-collateral-tracker-could-be-zero", "labels": ["OpenZeppelin"]}, {"title": "Liquidator Can Incur Loss During Liquidation", "body": "An account can be liquidated if it does not have enough collateral to cover its position(s), which is an important operation to ensure the health of the protocol. Administrating the insolvent account proceeds by first having the liquidator delegate an amount of shares to cover the account's position(s), then exercising the entire position list of the account, and finally returning the delegated amount plus a bonus to the liquidator. It's possible for a liquidator to lose money because when all positions are exercised, shares can be minted which increases the total supply of shares. This can result in the asset value of the delegated shares plus the bonus after the liquidation being less than the asset value of the delegated shares before the liquidation due to dilution of the share value. Consider ensuring that performing a liquidation always results in a net gain for the liquidator in order for there to be an incentive to perform the operation.  Update: Resolved at commit 02cd20d.  Low Severity", "html_url": "https://blog.openzeppelin.com/panoptic-audit#liquidator-can-incur-loss-during-liquidation", "labels": ["OpenZeppelin"]}, {"title": "Slippage Protection Should Allow Specifying Exact Tick", "body": "When minting options, a check is made where the current tick must be between the specified limits. If the upper limit and lower limit are equal, then the check passes regardless of where the current tick is. A minter may only desire to mint at a specific tick, and may assume this will happen if they set tickLimitLow == tickLimitHigh. Instead, this currently implies no slippage protection. Considering changing the logic of _getPriceAndCheckSlippageViolation to allow minters to specify a specific tick.  Update: Resolved.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#slippage-protection-should-allow-specifying-exact-tick", "labels": ["OpenZeppelin"]}, {"title": "Minting Fails When Width and Tick Spacing Are Both Equal to 1", "body": "When creating a tokenId, specifying a width equal to 1 and the underlying pool has a tickSpacing of 1, a rounding to zero occurs and the resulting lower and upper tick will be the same as the strike. This will eventually fail when the position is minted in Uniswap. Consider reverting with an error in asTicks to have more consistent behavior.  Update: Resolved in pull request #633 at commit 2fcae1e.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#minting-fails-when-width-and-tick-spacing-are-both-equal-to-1", "labels": ["OpenZeppelin"]}, {"title": "startPool Can Be Frontrun to Incorrectly Set medianTick", "body": "When a pool is started, the current tick is read from the Uniswap pool to assign to miniMedian. It is possible to front-run startPool and manipulate the current tick, affecting the medianTick for operations such as minting options (attacker could mint options at a discount for example). Consider adding additional logic for slippage protection when starting a pool.  Update: Acknowledged, not fixed. The Panoptic team stated:  If a pool is initialized with an out-of-sync median tick, it is up to the consumers of that pool not to interact until the tick is back in sync. This can be acheived by calling the poke function several times. Circumscribing the available current ticks that a pool can be created at does not guarantee protection against median tick manipulation and could cause difficulties when creating smaller pools. Users should decide whether or not to use a certain pool based on their personal risk criteria and preferences.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#startpool-can-be-frontrun-to-incorrectly-set-mediantick", "labels": ["OpenZeppelin"]}, {"title": "Assumptions on Validation Time With block.number", "body": "The mini-Median can be updated if at least 4 blocks have passed since the last update. This is supposed to correspond to approximately 1 minute (~13-second average validation time on Ethereum) according to the comment, but this may not always be the case:  Ethereum upgrades may change the validation time.  Deploying the protocol on other chains (L2s like Arbitrum for example), 4 blocks can take only several seconds.  Consider using block.timestamp instead of block.number for the mini-Median to more precisely ensure the desired time interval has passed. Current epoch time takes up about 30 bits to store as an integer so the 40 bits used to store the block information in s_miniMedian would be sufficient going forward.  Update: Resolved in pull request #2 at commit 3cd6bd6.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#assumptions-on-validation-time-with-block.number", "labels": ["OpenZeppelin"]}, {"title": "Writing Over Existing tokenId May Overflow Certain Assigned Bits", "body": "Consider adding overflow detection checks to prevent overwriting untargeted bit-constituents of the tokenId.  Update: Acknowledged, not fixed. The Panoptic team stated:  This is intended behavior. These functions are designed to be as gas-efficient as possible, and as such it is expected that user inputs will be validated before they are called. Specifically, they are only intended to be used on token ids with the respective slots cleared (such as when one is being built starting from uint256(0)). They are prefixed with add for a reason - if the functions cleared slots first and did overflow checks they would be prefixed with set instead.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#writing-over-existing-tokenid-may-overflow-certain-assigned-bits", "labels": ["OpenZeppelin"]}, {"title": "Missing Error Messages in revert Statements", "body": "Throughout the codebase, there are revert statements that lack error messages. For instance:  The revert statement within the poolData function on line 409 of PanopticPool.sol  The revert statement within the convertToTokenValue function on line 327 of PanopticMath.sol  Consider including specific, informative error messages in revert statements to improve the overall clarity of the codebase and to avoid potential confusion when the contract reverts.  Update: Partially fixed. The Panoptic team stated:  There is not a specific commit for this, but a search of the latest version of the contracts will find that these empty revert statements are no longer present. There are only two possible empty reverts, both found in assembly blocks in the mulDivDown and mulDivUp functions taken from Solmate and used in the CollateralTracker's ERC-4626 implementation. Solmate's standard ERC-4626 also reverts with no data on overflows, and the same behavior is kept here for consistency.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#missing-error-messages-in-revert-statements", "labels": ["OpenZeppelin"]}, {"title": "legIndex Is Not Modulo Four", "body": "When updating parameters in a tokenId (for example, in addNumeraire), a leg index can be specified which should be at most 3. During the left shift operation, the leg index is not taken modulo 4 and so providing a value greater than 3 will shift by more than 256 bits and will result in no change to the tokenId. This is inconsistent with how other parameters are handled which are always taken modulo their maximum value during the shift, for example, when updating the option ratio, token type, etc. Consider taking the leg index modulo four to remain consistent with other operations.  Update: Acknowledged, not fixed. The Panoptic team stated:  If a leg index greater than 3 is specified, the expected behavior is that the tokenId should not change because there are only 4 legs, so updating a fifth leg would have no effect. The leg parameters are constricted to their maximum values because a value greater than the maximum would be nonsensical and bleed into the other slots in the tokenId, but it is reasonable to expect that attempting to update a fifth leg would leave the tokenId unchanged and is therefore harmless.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#legindex-is-not-modulo-four", "labels": ["OpenZeppelin"]}, {"title": "Arguments Passed to Functions in Reverse Order", "body": "During the creation of some options strategies in PanopticHelper, the arguments passed to underlying functions are passed in a reversed order. This will cause users to set the wrong numeraire as well as the wrong leg type when creating options strategies. For instance:  In createJadeLizard, the arguments numeraire and isLong are passed to createStrangle in a reversed order.  In createBigLizard, the arguments numeraire and isLong are passed to createStraddle in a reversed order.  Consider passing the arguments numeraire and isLong in the correct order in the above-mentioned functions.  Update: Resolved at commit 2f2addf.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#arguments-passed-to-functions-in-reverse-order", "labels": ["OpenZeppelin"]}, {"title": "Casting Risk in Premia Values", "body": "Values packed into the right and left slots of legPremia (type int256) are unsigned 128-bit integers. Those values will be cast to int128 when written and then subsequently read as int128. If the original unsigned values have a non-zero most-significant bit then the result will be read incorrectly as a negative number. Consider verifying that all values cast to a signed integer are equal to their original unsigned values.  Update: Acknowledged, not fixed. The Panoptic team stated:  The protocol, for multiple reasons, makes the assumption that the premia will not exceed (2**127-1). The maximum feasible collateral that can be deposited is orders of magnitude smaller than that, and it is inconcievable that an amount of premium that large on any legitimate pool could be accumulated. Adding a safecast here would not resolve issues stemming from an extremely large amount of premium being accumulated and would also cause positions to get stuck.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#casting-risk-in-premia-values", "labels": ["OpenZeppelin"]}, {"title": "Considerations Regarding AMM TWAP Readings", "body": "Depending on the observation arrays from different AMM pools, the following scenarios may be worth considering.  When the oldest observation is too recent  The TWAP read will revert if the oldest observation is too recent (i.e., less than 600s). This happens when the observation array cardinality is small. For instance, at the time of writing, the DAI-WETH-100bps pool has an observation cardinality of 1, thus each new observation overwrites the current one. Hence, one can easily write a new observation via swapping in the AMM pool to DoS the TWAP read.  This is significantly mitigated in the deployment of the Panoptic pool as the observation cardinality is increased to a minimum of 100. However, this happens after _mintFullRange, which writes a new observation to the array before expanding it to 100. Thus, there may still be a brief window where TWAP reads can revert.  Consider putting increaseObservationCardinalityNext before _mintFullRange, as this will fill up one extra slot after expanding.  When the latest observation is older than TWAP_WINDOW  If the latest observation from the AMM pool was updated more than TWAP_WINDOW seconds ago, then the twapMeasurement will always be the currentTick. Thus by checking the timestamp of the latest observation, one could avoid the gas-intensive reads from the AMM.  In both small and large AMM pools, observations with gaps larger than 600s can happen more frequently than assumed. It would be good to consider the appropriateness of the TWAP_WINDOW length across different pools.  Update: Acknowledged, not fixed. The Panoptic team stated:  It is unusual for the latest observation to be older than the TWAP window except on very inactive pools. While it is possible to reduce gas in that situation by computing the TWAP with simpler logic, it is not common enough to warrant its own optimized branch. If it is common on a certain pool, it may be advisable for that pool to be deployed with a longer TWAP window.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#considerations-regarding-amm-twap-readings", "labels": ["OpenZeppelin"]}, {"title": "Potential Division by Zero When Checking Liquidity Spread", "body": "The function _checkLiquiditySpread ensures that the effective liquidity in a given chunk is above a certain threshold. However, when the liquidity spread is computed, the function will revert when netLiquidity is equal to zero. This can happen if a user tries to open a long position with all the available liquidity.  Consider preventing the division when netLiquidity is zero and reverting with an informative and user-friendly error message.  Update: Acknowledged, not fixed. The Panoptic team stated:  The Panoptic Pool enforces a maximum spread multiplier, meaning that at least 10% of a given liquidity chunk must remain in the AMM at all times. Therefore, netLiquidity will never be zero when this calculation is performed.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#potential-division-by-zero-when-checking-liquidity-spread", "labels": ["OpenZeppelin"]}, {"title": "Straddle Legs Are Not Risk-Partnered", "body": "In PanopticHelper.sol, the function createStraddle creates a call and a put leg with identical strike prices. Both the call and the put legs are expected to have each other assigned as risk partners, as described in this comment.  However, when creating the call leg and the put leg, each leg gets assigned as its own risk partner.  Consider partnering the call and put legs together.  Update: Resolved at commit 2f2addf.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#straddle-legs-are-not-risk-partnered", "labels": ["OpenZeppelin"]}, {"title": "Misleading or Incorrect Docstrings", "body": "There are some instances in the codebase where the comments are misleading or can be improved for clarity.  When the parameter collateralCalculation is true, the premium will be computed for all options regardless if isLong is 0 or 1, whereas the comment states that if true do not compute premium of short options.  The v in the formula derivation of Eqn 2 is in the wrong place. It should be gross_feesCollectedX128 = feeGrowthX128*N + feeGrowthX128*S*(1 + v*S/N) instead.  The variable name in Eqn 3 should be s_accountPremiumOwed instead of s_accountLiquidityOwed.  The account premium variables have 64 bits precision but these are not mentioned in the doc-string. This may cause confusion.  The comment above s_miniMedian should say the block number occupies the most significant 40 bits (not 32), and there are 8 interactions stored (the diagram shown starts from index 1 which would mean 7 interactions in total)  The comment for mintTokenizedPosition says that the function reverts if the position is not unique. However, it is possible to call the function twice with the same exact input.  When swapping 0 for 1 the price actually moves downwards (the price is token1/token0, token0 is added to the pool)  In CollateralTracker.sol, this comment has a typo. \"minNum(Half)RangesFromStrike\" should be \"maxNum(Half)RangesFromStrike\".  In TokenId.sol, this comment has a typo. \"incoming 16 bits\" should be \"incoming 24 bits\".  Update: Resolved at commit 993f4b5.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/panoptic-audit#misleading-or-incorrect-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Unused Named Return Variables", "body": "Named return variables are a way to declare variables that are meant to be used within a function body for the purpose of being returned as the function's output. They are an alternative to explicit in-line return statements.  Throughout the codebase, there are multiple instances of unused named return variables.  For instance:  The _symbol return variable in the symbol function in CollateralTracker.sol.  The assetTokenAddress return variable in the asset function in CollateralTracker.sol.  The totalManagedAssets return variable in the totalAssets function in CollateralTracker.sol.  The shares return variable in the convertToShares function in CollateralTracker.sol.  The assets return variable in the convertToAssets function in CollateralTracker.sol.  The maxAssets return variable in the maxDeposit function in CollateralTracker.sol.  The shares return variable in the previewDeposit function in CollateralTracker.sol.  The maxShares return variable in the maxMint function in CollateralTracker.sol.  The assets return variable in the previewMint function in CollateralTracker.sol.  The maxAssets return variable in the maxWithdraw function in CollateralTracker.sol.  The shares return variable in the previewWithdraw function in CollateralTracker.sol.  The maxShares return variable in the maxRedeem function in CollateralTracker.sol.  The assets return variable in the previewRedeem function in CollateralTracker.sol.  The required return variable in the _getRequiredCollateralSingleLeg function in CollateralTracker.sol.  The panopticPoolBalance return variable in the poolData function in PanopticPool.sol.  The totalBalance return variable in the poolData function in PanopticPool.sol.  The inAMM return variable in the poolData function in PanopticPool.sol.  The totalLocked return variable in the poolData function in PanopticPool.sol.  The currentPoolUtilization return variable in the poolData function in PanopticPool.sol.  The premium0 return variable in the calculateAccumulatedFeesBatch function in PanopticPool.sol.  The premium1 return variable in the calculateAccumulatedFeesBatch function in PanopticPool.sol.  The liquidationTick return variable in the findLiquidationPriceDown function in PanopticHelper.sol.  The liquidationTick return variable in the findLiquidationPriceUp function in PanopticHelper.sol.  Consider either using or removing any unused named return variables.  Update: Acknowledged, not fixed. The Panoptic team stated:  We use named return variables deliberately in various areas of the codebase to help with comprehension. They are sometimes used throughout the body of the function (as accumulators, for example) but are otherwise intended to assist with code comprehension, even if they are unused.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#unused-named-return-variables", "labels": ["OpenZeppelin"]}, {"title": "Unused Imports", "body": "Throughout the codebase, there are imports that are unused and could be removed. For instance:  Import FullMath of PanopticFactory.sol  Import PeripheryImmutableState of PanopticFactory.sol  Import FixedPoint96 of PanopticPool.sol  Import PoolAddress of INonfungiblePositionManager.sol  Import FixedPoint128 of FeesCalc.sol  Import FullMath of FeesCalc.sol  Import SqrtPriceMath of FeesCalc.sol  Import Errors of FeesCalc.sol  Import TickMath of LiquidityChunk.sol  Import TokenId of LiquidityChunk.sol  Import FixedPoint96 of PanopticMath.sol  Import FixedPoint128 of PanopticMath.sol  Import FullMath of PanopticMath.sol  Import SqrtPriceMath of PanopticMath.sol  Import Errors of PanopticMath.sol  Import TickMath of TickPriceFeeInfo.sol  Import TokenId of TickPriceFeeInfo.sol  Import PanopticMath of PanopticHelper.sol  Import PanopticMath of PanopticMigrator.sol  Consider removing unused imports to improve the overall clarity and readability of the codebase.  Update: Resolved at commit 993f4b5.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#unused-imports", "labels": ["OpenZeppelin"]}, {"title": "State Variable Visibility Not Explicitly Declared", "body": "Throughout the codebase, there are state variables that lack an explicitly declared visibility. For instance:  The state variable SFPM in PanopticHelper.sol  The state variable DUST_THRESHOLD in PanopticMigrator.sol  For clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved at commit 993f4b5.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Identical Custom Errors Used in Different Contexts", "body": "Within SemiFungiblePositionManager.sol, the custom error NotEnoughLiquidity() is used when there is not enough netLiquidity for a long position. It is also used in a different context when the specified liquidity amount for a position is lower than the DUST_THRESHOLD. Consider using specific, informative custom errors in different contexts to improve overall code clarity and to facilitate troubleshooting whenever a requirement is not satisfied.  Update: Resolved.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#identical-custom-errors-used-in-different-contexts", "labels": ["OpenZeppelin"]}, {"title": "Non-negative Values As Signed Integers In External Interface", "body": "Some variables are supposed to take only non-negative values but appear as signed integers in the interface of a function (i.e., either in the arguments or return variables).  Other examples include non-negative values for poolUtilization as LeftRight int128 return variable and non-negative bonusAmounts as LeftRight int256. These may be prone to casting issues for external integration in the future.  Consider keeping non-negative variables as unsigned integers in the external interface.  Update: Acknowledged, not fixed. The Panoptic team stated:  In certain situations it makes sense to represent values which can only be natural numbers as signed integers -- these values are often operated upon with and combined with values that must be signed, so making the types similar often reduces casting headaches and footguns.", "html_url": "https://blog.openzeppelin.com/panoptic-audit#non-negative-values-as-signed-integers-in-external-interface", "labels": ["OpenZeppelin"]}, {"title": "The Quotient Polynomial Shards Are Not Individually Blinded", "body": "constructing the shards of the quotient polynomial  h(  ) their KZG commitments are  added to the proof without blinding, as required by the  latest Plonk specification. As noted by  Sefranek, this means they do not provide the statistical zero-knowledge property.  Consider blinding the individual shards in the proof.  Update: Resolved in pull request #14.  The issue was fixed by applying the blinding of the h shards (h1,h2,h3) according to the latest version of the PLONK paper (February 23, 2024). In addition, a global StatisticalZK option was introduced which, when turned off, switches back to the previous version of the code (i.e., the one that does not blind the shards).  This is desirable since the new blinding increases the memory consumption of the prover due to the necessity to reserve three additional arrays of size n (where n is the size of the circuit) to store the three blinded polynomials. Previously, they were just sliced from the (already allocated) h polynomial.  Some recommendations to further improve the fix:  Make the StatisticalZK switch to control all blindings (i.e., also of the a,b,c,z polynomials) and not just of the t shards. This will further ease the memory requirements on the prover when blinding is not desirable and will also simplify the implementation and improve consistency.  Make the h3 polynomial the same size as the h1,h2 shards by setting its top coefficients to zero. This will remove the conditional logic in the innerComputeLinearizedPoly function (which is a bit unnatural, anyway), since all the hx[i] values will be valid, and will improve code readability.  The Linea team stated:  We made it an option to achieve zero knowledge-ness (see backend.WithStatisticalZeroKnowledge()) because it uses more memory. In cases where it is not needed, it is better to avoid it.  Medium Severity", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#the-quotient-polynomial-shards-are-not-individually-blinded", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent BSB22 Polynomial Blinding", "body": "In order to blind the BSB22 preimage polynomials, they are constructed with random evaluations in two positions. These positions are carefully chosen so that the evaluations are unused. In particular:  The first one corresponds to the \"hash injection\" constraint, where the final challenge is introduced into the circuit as a public input. This guarantees that the corresponding Qcpj\u200b\u200b selector position will be zero and so the random evaluation will be ignored.  The second one is simply the last constraint in the whole system. Since the circuit builder always constructs the \"preimage collection\" constraints before the \"hash injection\" constraints, the last constraint cannot be a \"preimage collection\" constraint and the corresponding Qcpj\u200b\u200b selector position will also be zero.  However, if the BSB22 gate is the last gate added to the circuit, both of these will correspond to the same position. This means that the corresponding preimage polynomial will only be blinded in one position instead of two.  We believe that one position is sufficient to maintain zero knowledge in this case. Nevertheless, in the interest of predictability and consistency, consider ensuring that all BSB22 preimage polynomials are blinded twice. This could involve choosing a different (unused) evaluation position or ensuring that the last constraint does not match a BSB22 gate.  Update: Acknowledged, not resolved. The Linea team stated:  For the moment, the polynomials are blinded in at least one spot no matter what. This should be enough (even if one in every case is enough).", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#inconsistent-bsb22-polynomial-blinding", "labels": ["OpenZeppelin"]}, {"title": "Incorrect UnmarshalSolidity Function", "body": "MarshalSolidity and  UnmarshalSolidity functions are intended to encode and decode a Go  Proof object so that it can be passed to a Solidity verifier contract. However, the  skips the opening of the linearized polynomial while the  does not. This means that the rest of the function will decode values into the wrong variables and will attempt to read past the end of the input.  Consider removing the linearized polynomial from the UnmarshalSolidity function so that it behaves as expected.  Update: Resolved in pull request #10.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#incorrect-unmarshalsolidity-function", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Plonk Implementation", "body": "The code under audit updates the Plonk implementation from a previous version to the latest version. Specifically:  The quotient polynomial h(X) is included in the linearized polynomial.  The corresponding opening \u02c9h\u02c9 (\\bar{h}) is no longer included in the proof.  The linearized polyenomial opening r(\u03b6) is no longer provided to the Solidity verifier.  However, the transition is incomplete:  The code uses the old definition of r(X) which disregards the constant terms. To see this, note the following:  The Plonk constraint term should include PI(\u03b6) The \u03b12z(X)L1\u200b(\u03b6) term should be \u03b12(z(X)\u22121)L1\u200b(\u03b6) The \u03b2S\u03c33\u200b(X) factor should be \u014d+\u03b2S\u03c33\u200b+\u03b3  The Go verifier still receives under the old definition of r(X)  In addition, previous inconsistencies have been retained:  The bottom two shards of the quotient polynomial have degree n+1 (instead of n\u22121)  The ordering constraint (\u03b1 term) is negated  The L1 term is actually computed as L0  The final v term is computed randomly in the Go verifier, rather than using the expected Fiat-Shamir derivation.  While internally consistent, this means that the code does not conform to either version of the Plonk protocol. It also uses terminology that spans both versions. This makes the codebase harder to understand, modify and maintain.  Consider strictly following the latest Plonk specification.  Update: Acknowledged, not resolved. The Linea team stated:  Acknowledged. We will leave it this way for the moment. The most important part is that there is no division anymore in the verifier since the quotient is included in the linearized polynomial. For the signs, it is arbitrary. For the degrees of the shards, it allows using a slightly smaller SRS.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#inconsistent-plonk-implementation", "labels": ["OpenZeppelin"]}, {"title": "Missing Proof Validation", "body": "The Verify function does not validate the following:  Whether the polynomial openings are valid field elements  Whether the public witness values are valid field elements  Whether the proof commitments are valid elliptic curve points  Whether the proof commitments are on the correct subgroup  Fortunately, bn curves do not have small subgroups (and therefore are not subject to small subgroup attacks), but this should be validated for the other curves in the library.  In the interest of reducing the attack surface and increasing compliance with the Plonk specification, consider introducing these checks.  Update: Partially resolved in pull request #11.  The fix validates that the commitments from the proof are elements of the correct subgroup. It does not check that the openings and the public values are valid field elements. The rationale is that these checks are done implicitly in Gnark during instantiation.  However, the implicit checks can still be bypassed (e.g., if one passes a 256-bit value with all the bits set as in a := fr.Element{ 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff}, that is still a valid 256-bit constant, but is not a BN254 field element).  Low Severity", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#missing-proof-validation", "labels": ["OpenZeppelin"]}, {"title": "Imprecise Domain Size", "body": "The larger domain size is identified by a simple calculation, but is then manually separated into two cases. Moreover, when sizeSystem is 5, direct calculation would result in a larger domain of size 32 rather than the currently computed 64.  Consider passing the desired number of evaluation points, (domain0.Cardinality + 2) * 3, in all cases.  Update: Acknowledged, not resolved. The Linea team stated:  We prefer leaving it this way. We remember that it led to weird issues back when we implemented it.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#imprecise-domain-size", "labels": ["OpenZeppelin"]}, {"title": "Off-by-One Indexing Error in Unmarshal Logic", "body": "In the UnmarshalSolidity function, there should be 6 rather than 7 positions reserved for standard batched polynomial openings. Similarly, the additional BSB22 openings should start at index 6. This is consistent with the proof construction.  Consider updating the index, ideally with a named global constant.  Update: Resolved in pull request #10.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#off-by-one-indexing-error-in-unmarshal-logic", "labels": ["OpenZeppelin"]}, {"title": "Implicit Modification of the Blinded Z Polynomial Inside innerComputeLinearizedPoly", "body": "The innerComputeLinearizedPoly function directly modifies the blindedZCanonical slice, which corresponds to the instance's blindedZ value, before assigning the result to the linearizedPolynomial variable.  Note that blindedZ is not part of the proof (which contains just the opening proof [W\u03b6\u03c9\u200b] and the opening Z(\u03b6\u03c9)). Thus, blindedZ getting modified inside innerComputeLinearizedPoly does not have adverse consequences (e.g., on the verifier side).  Consider cloning blindedZCanonical first so that blindedZ remains correct, or explicitly documenting that it is modified in place.  Update: Resolved in pull request #12. This issue was fixed by following our second suggestion. That is, by adding an explicit comment that the blindedZCanonical value is modified inside the function.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#implicit-modification-of-the-blinded-z-polynomial-inside-innercomputelinearizedpoly", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestions", "body": "There are multiple instances of functions and variables with misleading names:  divideByXMinusOne could be more appropriately renamed to divideByXnMinusOne or divideByZH.  verify_opening_linearised_polynomial does not perform any verification and could more appropriately be renamed to compute_opening_linearised_polynomial.  lagrangeOne is computed as \u03b6n\u22121/(n(\u03b6\u22121)), which is the evaluation L0\u200b(\u03b6) of the 0-th Lagrange basis polynomial. It could more appropriately be renamed to lagrangeZero.  Similarly, alphaSquareLagrangeOne could be more appropriately renamed to alphaSquareLagrangeZero.  Consider implementing the above renaming suggestions to improve code clarity.  Update: Resolved in pull request #9.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#naming-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Missing Error Check", "body": "The error associated with a failed MOD_EXP precompile appears to have been inadvertently removed.  Consider restoring the error.  Update: Resolved in pull request #8.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#missing-error-check", "labels": ["OpenZeppelin"]}, {"title": "Misleading or Erroneous Documentation", "body": "We have identified the following instances of misleading documentation:  The solveConstraints comment says that the function computes the (LRO) polynomials in canonical form whereas they are in Lagrange form.  kzg.Commit defined in the gnark-crypto library at gnark-crypto/ecc/bn254/kzg/kzg.go:L170, expects a polynomial in coefficient form according to the comment (in gnark-crypto kzg.go:L169), but in prove.go, it can also be in Lagrange form.  The domain size validation uses GetNbConstraints but the actual size includes the public inputs.  The comment explaining the \"gamma\" encoding is out-of-place now that there is an FS_GAMMA constant.  The fold_state comment still includes H(\u03b6) - a remnant from the previous version.  The STATE_FOLDED_DIGESTS_X comment still includes H.  The comment explaining a preimage size says 0x17 instead of 0x14.  The BSB22 proof layout comment is obsolete because the two preceding constants, namely PROOF_OPENING_QCP_AT_ZETA and PROOF_BSB_COMMITMENTS, already identify these values.  The quotient_polynomial_at_zeta comment is obsolete since it has been removed from the batched proof.  The getBlindedCoefficient function claims that it modifies the underlying polynomial coefficients. However, the append operation will resize the slice and so the original coefficients slice will remain unchanged.  The wire_committed_commitments refers to the following loop.  To improve the clarity and readability of the codebase, consider addressing the aforementioned inconsistencies in the documentation.  Update: Partially resolved in pull request #7.  The following recommendations were not addressed:  The kzg.Commit defined in the gnark-crypto library at gnark-crypto/ecc/bn254/kzg/kzg.go:L170 expects a polynomial in coefficient form according to the comment (in gnark-crypto kzg.go:L169). However, in prove.go, it can also be in Lagrange form.  The wire_committed_commitments refers to the wrong loop.  The getBlindedCoefficient function claims that it modifies the underlying polynomial coefficients. However, the append operation will resize the slice and so the original coefficients slice will remain unchanged. Note that the fix amends the comment, saying that only the size is modified, which is also incorrect. Since the append operation makes a local copy of p (which is then modified), the size of p remains the same.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#misleading-or-erroneous-documentation", "labels": ["OpenZeppelin"]}, {"title": "Code Simplifications", "body": "The following are some suggestions to simplify the code:  The polynomial Coefficients function is used to retrieve evaluations (e.g., here) when the polynomial is in Lagrange form. For clarity, consider creating an Evaluations function to be used instead.  The NewTrace function could read the domain's cardinality instead of recomputing the size.  The MarshalSolidity function hardcodes the proof size. If there are more than two BSB22 commitment gates, this will need to be resized. Instead, the correct size could be computed dynamically.  This if statement is redundant.  The fold_state function keeps recomputing add(state, STATE_FOLDED_DIGESTS_X) instead of using state_folded_digests. Similarly, add(state, STATE_FOLDED_CLAIMED_VALUES) could be saved so that it does not need to be recomputed.  The commitment constraint index could be included in the loop specification so it does not need to be recomputed.  The FoldProof function contains an if statement that could be naturally integrated into the following loop.  The batchOpening function waits for the channels chLRO and chLinearizedPolynomial. However, the first select statement is redundant because chLinearizedPolynomial cannot close before chLRO.  This variable assignment recomputes expo unnecessarily.  Consider implementing the aforementioned code simplification suggestions to improve the clarity and maintainability of the codebase.  Update: Partially resolved in pull request #6.  The following recommendations were not addressed:  The polynomial Coefficients function is used to retrieve evaluations when the polynomial is in Lagrange form. For clarity, consider creating an Evaluations function to be used instead.  The MarshalSolidity function hardcodes the proof size. If there are more than two BSB22 commitment gates, this will need to be resized. Instead, the correct size could be computed dynamically.  Similarly, add(state, STATE_FOLDED_CLAIMED_VALUES) could be saved so that it does not need to be recomputed.  The FoldProof function contains an if statement that could be naturally integrated into the following loop.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#code-simplifications", "labels": ["OpenZeppelin"]}, {"title": "Verifier Regressions", "body": "Our previous audit report included recommendations and fixes associated with the Solidity verifier. This corresponds to the output of the ExportSolidity Go function.  However, when reviewing the template, we identified the following regressions:  The sum_pi_commit function contains a final unnecessary pointer update.  The explanation for the \"beta\" offset incorrectly references \"gamma\" and has the wrong offset.  The polynomial openings are described as \"wire values at zeta\". It would be more accurate to describe them as \"evaluations of wire polynomials at zeta\".  The b0 and b0 ^ b1 comments incorrectly describe them as occupying 64 bytes.  The comment describing the fold_h function uses m instead of n as the group size.  This comment uses \"mPtr[32:]\" instead of \"mPtr[:32]\".  This comment is unclear and incorrectly suggests that \"b2\" is 16 bytes.  The n parameter of the batch_compute_lagranges_at_z function is the number of public inputs which conflicts with the domain size.  The H commitments should include com in their name to be consistent with the other constants.  There are several functions and variables that could remove the \"api\" decorator which is a reference to how they were constructed rather than what they represent.  Consider restoring the aforementioned corrections.  Update: Partially resolved in pull request #5.  The following regressions from the previous audit were not addressed:  The b0 and b0 ^ b1 comments incorrectly describe them as occupying 64 bytes.  This comment is unclear and incorrectly suggests that \"b2\" is 16 bytes.  There are several functions and variables that could remove the \"api\" decorator which is a reference to how they were constructed rather than what they represent.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#verifier-regressions", "labels": ["OpenZeppelin"]}, {"title": "Imprecise Calculation for Number of Gates", "body": "In the computeNumerator function, the number of BSB gates is computed using the size of the memory location where the gates are stored. However, the +1 term in this calculation is incorrect. This does not introduce incorrect functionality because the last bit is discarded during the final division.  Nevertheless, in the interest of clarity and simplicity, consider removing this extra term. Alternatively, consider reading the number of gates directly from the commitmentInfo parameter.  Update: Resolved in pull request #2.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#imprecise-calculation-for-number-of-gates", "labels": ["OpenZeppelin"]}, {"title": "Presence of Magic Numbers", "body": "constants for the precompiles are introduced. There are multiple instances where the constants should be used (e.g.,  1,  2,  3,  4). In addition, there are several instances (e.g.,  1,  2,  3 and 6 more places) where the hard-coded constant  fixed proof size should be its own constant or one could use  To minimize the possibility of issues arising from the use of magic numbers, consider applying the following changes:  Replace the hard-coded identifiers of the precompiles with their respective constants.  Introduce a new constant for the SHA2 precompile and use it instead of the hard-coded identifier 0x2.  Introduce a new constant for the fixed proof size or, alternatively, use PROOF_OPENING_QCP_AT_ZETA instead of hardcoding 0x300, as noted above.  Update: Partially resolved in pull request #3.  The following recommendation has not been addressed:  Replace the hard-coded identifiers of the precompiles with their respective constants.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#presence-of-magic-numbers", "labels": ["OpenZeppelin"]}, {"title": "Unused Variable in Solidity Verifier", "body": "The state variable in the point_acc_mul_calldata function is unused.  Consider removing the unused variable to improve code clarity.  Update: Resolved in pull request #4.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#unused-variable-in-solidity-verifier", "labels": ["OpenZeppelin"]}, {"title": "Use Templating Mechanism for all Buffer Offsets in the Solidity Verifier", "body": "In the solidity verifier, template offset variables are used to ensure that the constant offsets are specified correctly. Consider using the same mechanism for all buffers with hardcoded constants, such as:  when deriving \u03b3 (note that this would also remove the 544 and 576 \"magic\" constants),  when constructing the pairing check,  when deriving the linearization factor,  and at other places.  Update: Partially resolved in pull request #1.  The following recommendation has not been addressed:  Consider using the template offset variables mechanism for all buffers with hard-coded constants, such as when deriving the linearization factor and at other places.  The Linea team stated:  In compute_kzg, we left it as it was since there is a jump on the offset due to the calldataload. We prefer to leave the constants hard-coded as they do not depend on the number of custom gates.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#use-templating-mechanism-for-all-buffer-offsets-in-the-solidity-verifier", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "We identified the following typographical errors:  The word \"converts\" has two spaces in the middle.  The word \"numger\" should be \"number\".  Consider fixing any typographical errors to improve the readability of the codebase.  Update: Resolved in pull request #13.", "html_url": "https://blog.openzeppelin.com/linea-prover-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Last Rewards Cannot Be Collected", "body": "The collectRewards function of the FixedRateRewardsSource contract will attempt to release funds at a fixed rate per second regardless of how many tokens it owns. For the caller who attempts to collect the last remaining funds in the contract, the released amount may surpass the owned amount. Meaning, any call to collect rewards will revert and the owned tokens will never be released. It is possible to release owned tokens if the exact difference between released and owned tokens is transferred prior to collecting the rewards.  Consider adding logic to calculate the released tokens as the minimum between the calculated amount and the owned amount.  Update: Resolved in pull request #413. The Origin Protocol team stated:  We also detected this, and have already done a PR with this change during the audit.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#last-rewards-cannot-be-collected", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are multiple code instances that do not have docstrings.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. This includes all public variables as well. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Acknowledged, not resolved. The Origin Protocol team stated:  We will leave these as they are.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Code Clarity", "body": "Consider changing the double parentheses to single parentheses in line 269 of the ExponentialStaking contract.  Update: Resolved in pull request #421. The Origin Protocol team stated:  We have removed the double parentheses and simplified the calculation on this line.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#code-clarity", "labels": ["OpenZeppelin"]}, {"title": "Functions Rendered Ineffective by transfer", "body": "its ERC-20 transfer functions disabled. However, there are other functions like  Consider disabling the aforementioned functions to save gas during deployment and reduce the attack surface.  Update: Acknowledged, not resolved. The Origin Protocol team stated:  We will keep these functions as they are. It is a trade-off here between bytecode simplicity and Solidity code simplicity, and for this contract, we value the code simplicity more.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#functions-rendered-ineffective-by-transfer", "labels": ["OpenZeppelin"]}, {"title": "Lack of Input Validation", "body": "line 116 with an \"index out-of-bounds\" error.  Consider validating the lockupId input value to ensure that it is either equal to NEW_STAKE (-1) or is within the length of the lockups array for the input to address.  Update: Acknowledged, not resolved. The Origin Protocol team stated:  We will leave this as is given that the only impact is the error message shown from the contract and we would be duplicating checks that are already happening at the Solidity level.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#lack-of-input-validation", "labels": ["OpenZeppelin"]}, {"title": "Use Custom Errors", "body": "Since Solidity version 0.8.4, custom errors provide a cleaner and more cost-efficient way to explain to users why an operation failed.  For conciseness and gas savings, consider replacing require and revert statements in ExponentialStaking.sol and OgvStaking.sol with custom errors.  Update: Acknowledged, not resolved. The Origin Protocol team stated:  We will leave these as they are.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#use-custom-errors", "labels": ["OpenZeppelin"]}, {"title": "Constant Not Using UPPER_CASE Format", "body": "In ExponentialStaking.sol, the maxStakeDuration constant is not declared using the UPPER_CASE format.  According to the Solidity Style Guide, constants should be named using all capital letters with underscores separating the words. For better readability, consider following this convention.  Update: Acknowledged, not resolved. The Origin Protocol team stated:  Keeping this for backwards compatibility reasons.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#constant-not-using-upper_case-format", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease code clarity and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity file or when inheritance chains are long.  Throughout the codebase, global imports are being used:  The import \"OpenZeppelin/openzeppelin-contracts@4.6.0/contracts/token/ERC20/IERC20.sol\"; import in FixedRateRewardsSource.sol  The import \"OpenZeppelin/openzeppelin-contracts@4.6.0/contracts/token/ERC20/extensions/ERC20Burnable.sol\"; import in Migrator.sol  The import \"./Governable.sol\"; import in Migrator.sol  Following the principle that clearer code is better code, consider using the named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #424.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "State Variable Visibility Not Explicitly Declared", "body": "Throughout the codebase, there are state variables that lack an explicitly declared visibility:  The YEAR_BASE state variable in ExponentialStaking.sol  The NEW_STAKE state variable in ExponentialStaking.sol  The YEAR_BASE state variable in OgvStaking.sol  For improved clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #423. The Origin Protocol team stated:  Updated to be explicit.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Unused Errors", "body": "Throughout the codebase, there are unused errors:  The InvalidRewardRate error in FixedRateRewardsSource.sol  The MigrationIsInactive error in Migrator.sol  The MigrationNotComplete error in Migrator.sol  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #416 and pull request #422. The Origin Protocol team stated:  Removed these unused methods.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#unused-errors", "labels": ["OpenZeppelin"]}, {"title": "Gas Griefing Vector", "body": "The stake function of the ExponentialStaking contract is intended to allow gifts but is not intended to control others' stakes or rewards. However, there is one case where this does not hold. If a user wants to stake their rewards, their transaction can be front-run by a 1 wei gift so that the rewards are sent to the user's address and the original stake transaction fails.  While the user can still stake their rewards, doing so will require them to make another transaction. We decided to raise this as an informational finding because there is no clear incentive to exploit this behavior, and even if exploited, there is a recovery plan. Furthermore, mitigating this issue will require changing how the rewards work which may not be feasible in this case.  Update: Acknowledged, not resolved. The Origin Protocol team stated:  Acknowledged.", "html_url": "https://blog.openzeppelin.com/origin-ogv-and-ogn-merge-audit#gas-griefing-vector", "labels": ["OpenZeppelin"]}, {"title": "StateTransitionManager Cannot Unfreeze Chains", "body": "freeze and unfreeze the chains it manages. This is intended by calling the  respective function in the  leading to a revert. To recover from this frozen state, the  Consider correcting the unfreezeChain function to allow the StateTransitionManager to unfreeze any frozen ZK Chain instead of reaching out to the ZK Chain admin to do the unfreezing. Also, consider implementing a unit test for this functionality.  Update: Resolved in pull request #293.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#statetransitionmanager-cannot-unfreeze-chains", "labels": ["OpenZeppelin"]}, {"title": "Ambiguous PubdataPricingMode Configuration", "body": "setValidiumMode function of the  Batches can be committed but then reverted again to the initial state to set the mode differently.  The PubdataPricingMode can be set through the changeFeeParams function at any time.  Thus, when users request an L2 transaction through the Mailbox facet, they sometimes could get charged for L1 PubData, and sometimes not. Moreover, if the Validium mode is motivated by enterprise or privacy reasons, a mode change to Rollup would entail leaking sensitive data.  Consider clarifying the intention of when and how the PubdataPricingMode may be changed. For example, ensure that the PubdataPricingMode can only be changed until the first batch is written to storedBatchHashes, which is not deleted during a batch revert. In addition, consider checking that the mode is not changed during changeFeeParams.  Update: Resolved in pull request #292 and pull request #298. The Matter Labs team stated:  PubdataPricingMode can be changed only before the first batch is processed, this is also reflected in the comment and in the doc-comments introduced with the fix in L-06.  Low Severity", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#ambiguous-pubdatapricingmode-configuration", "labels": ["OpenZeppelin"]}, {"title": "Emitting Deleted Value", "body": "NewAdmin event. However, this event emits the old admin through the  Consider emitting the currentPendingAdmin stack variable as the new admin instead.  Update: Resolved in pull request #294.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#emitting-deleted-value", "labels": ["OpenZeppelin"]}, {"title": "Lack of Events", "body": "In the StateTransitionManager, the following functions change the storage of the contract but do not emit an event:  setValidatorTimelock  setInitialCutHash  setNewVersionUpgrade  setUpgradeDiamondCut  This updated information includes sensitive configuration such as how the chains are upgraded for a new version. Therefore, consider emitting an event for more transparency and better monitoring capabilities.  Update: Resolved in pull request #295.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#lack-of-events", "labels": ["OpenZeppelin"]}, {"title": "StateTransitionManager Role-Specific Functions Cannot Be Reached in Admin Facet", "body": "In the Admin facet, some functions are limited only to be called by the StateTransitionManager. For instance:  setValidator  setPorterAvailability  setPriorityTxMaxGasLimit  These functions will not be accessible as there are no such function calls from the StateTransitionManager contract. Furthermore, the following functions are callable by both the admin and the StateTransitionManager role, but currently not callable through the StateTransitionManager contract:  changeFeeParams  setTokenMultiplier  upgradeChainFromVersion  Consider adding these function calls to the StateTransitionManager contract to facilitate the StateTransitionManager role in changing the configuration of registered ZK Chains.  Update: Resolved in pull request #296 at commit 6c0c01c.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#statetransitionmanager-role-specific-functions-cannot-be-reached-in-admin-facet", "labels": ["OpenZeppelin"]}, {"title": "Lack of Validation", "body": "Throughout the codebase, the following instances were identified where stronger validation can be applied:  In the Admin facet, the setTokenMultiplier function allows the admin or StateTransitionManager to set the nominator and denominator which is used by the Mailbox to scale the L1 gas price. While the denominator can be freely set, the value 0 would lead to a revert in the Mailbox for any requested L2 transaction. Consider applying the same check when setting the value.  In the StateTransitionManager, the setNewVersionUpgrade function allows the owner to set a diamond cut for an old protocol version. Simultaneously, the new protocol version argument overwrites the protocolVersion of the StateTransitionManager and thereby determines which version the diamond cut upgrades to. The problem is that the diamond cut also contains a protocolVersion in the encoded ProposedUpgrade struct as the initCalldata that then sets the ZK Chain's s.protocolVersion. It is possible that the encoded protocolVersion is not consistent with the new protocol version from the function argument. This mismatch would lead to all ZK Chains of the StateTransitionManager not being able to commit more batches to their Executor facet due to a version check. Consider decoding the diamond cut argument to validate that the protocol versions of the upgrade align.  The DiamondInit contract initializes the storage of a ZK Chain. This includes the addresses of the verifier, admin, and validatorTimelock that are checked to not be zero. However, with the recent upgrade, more addresses were introduced: bridgehub, stateTransitionManager, baseToken, baseTokenBridge, and blobVersionedHashRetriever. These addresses are not checked to not be zero. While some of these addresses originate from trusted sources like the BridgeHub or the StateTransitionManager, consider double checking them for consistency with the existing addresses and guaranteeing the functional correctness of the chain.  The StateTransitionManager can set arbitrary addresses as registered ZK Chain contracts per chain ID. This may include overwriting a chain ID with the zero address. By the logic of this contract, this could allow creating a new chain for this ID by passing the zero address check. Although, this it not allowed by the BridgeHub in charge, consider checking that upon registration of already deployed ZK Chains, the address cannot be set to zero.  Update: Partially resolved in pull request #297. The Matter Labs team stated:  Partially fixed. We decided not to apply the suggestion for setNewVersionUpgrade to avoid additional complexity.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#lack-of-validation", "labels": ["OpenZeppelin"]}, {"title": "PubdataSource Does Not Account for Validium Mode", "body": "must be present. Despite operating in  public data input source, is required to be either 0 or 1 for calldata and blob source respectively. This is not accurate as the commitment data is supposed to be stored elsewhere off-chain.  PubdataSource enum with  does not meet a length of 1.  Update: Resolved in pull request #299. The Matter Labs team stated:  We added the third option (validium) case to the require statement.  We did not want to add the Validium/None case to the PubdataSource options, since the PubdataSource is a different concept from DA mode. DA mode refers to the fact that DA needs to be published or not, while PubdataSource is just the form of publishing it (if needed). This is shown by the fact that we have to read ValidiumMode from storage (since that depends on the chain permanently), while Pubdata source can be read from the function input, since it can change batch to batch.  We also updated the error message.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#pubdatasource-does-not-account-for-validium-mode", "labels": ["OpenZeppelin"]}, {"title": "Missing and Incomplete Documentation", "body": "Throughout the codebase, there are multiple code instances that do not have docstrings.  The upgradeChainFromVersion and setValidiumMode functions in Admin.sol  The registerAlreadyDeployedStateTransition and createNewChain (_diamondCut parameter especially) functions in StateTransitionManager.sol  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec). Furthermore, the comment \"new fields\" in ZkSyncStateTransitionStorage.sol could be more meaningful (e.g., by specifying a version).  Update: Resolved in pull request #298.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#missing-and-incomplete-documentation", "labels": ["OpenZeppelin"]}, {"title": "Unused Imports", "body": "The following imports are unused:  ERA_DIAMOND_PROXY and ERA_CHAIN_ID in StateTransitionManager.sol  UnsafeBytes, L2_BASE_TOKEN_SYSTEM_CONTRACT_ADDR, and IBridgehub in Mailbox.sol  FeeParams and ISystemContext.sol in DiamondInit  Consider removing unused imports for improved code clarity.  Update: Resolved in pull request #300.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#unused-imports", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Documentation", "body": "Throughout the codebase, there are several instances of incorrect documentation:  In the StateTransitionManager, the onlyOwnerOrAdmin modifier reverts with the message \"Bridgehub: not owner or admin\" on failed authorization, thus indicating the wrong contract.  The three revert strings of the upgradeChainFromVersion function indicate the main (Diamond) contract \"StateTransition: ...\" as the error source, whereas other facets usually indicate the facet as a source. Thus, consider changing the message to \"Admin: ...\".  The revert string in the requestL2Transaction function says \"legacy interface only available for era token\", while probably \"era chain\" is meant.  The revert string of the onlyBaseTokenBridge modifier does not specify the contract, whereas the other revert strings in ZkSyncStateTransitionBase do.  In the _requestL2Transaction function, the new scope as described in the comment \"Using a new scope to prevent 'stack too deep' error\" is not present anymore.  The docstrings of the _deriveL2GasPrice function refer to ETH, although the price is calculated in the base token.  The comment about the nonce for the L2CanonicalTransaction when creating a new chain says that the nonce is \"the priority operation id\" whereas it is the protocolVersion.  The Natspec of the StateTransitionManagerInitializeData struct parameters have leading underscores whereas the fields have no underscores.  Consider applying the above changes for a more correct documentation of the codebase.  Update: Resolved in pull request #304.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#incorrect-documentation", "labels": ["OpenZeppelin"]}, {"title": "Inexplicit Struct Declaration", "body": "When the StateTransitionManager is initialized, a StoredBatchInfo struct is declared and hashed for later use.  For better readability, consider declaring the struct with the more explicit key: value syntax as seen in the _setChainIdUpgrade function.  Update: Resolved in pull request #306.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#inexplicit-struct-declaration", "labels": ["OpenZeppelin"]}, {"title": "Redundant Code", "body": "Throughout the codebase, the following instances of redundant code were identified:  When requesting an L2 transaction through the Mailbox facet, two structs are handled: BridgehubL2TransactionRequest and WritePriorityOpParams. The former reflects the user input of the transaction, while the latter handles the additional fields txId, expirationTimestamp, and l2GasPrice that are derived during scheduling of the priority operation.  Despite the overlap of data, the fields are defined redundantly, thereby introducing an overhead in data handling and function arguments. Instead, the WritePriorityOpParams could simply be extended by a BridgehubL2TransactionRequest request field. Throughout the usage of the WritePriorityOpParams struct, its values are always read explicitly so that this change should not introduce any repercussions (e.g., from hashing the whole struct). Furthermore, the interface of the internal functions _requestL2Transaction, _serializeL2Transaction, and _writePriorityOp can be simplified as all arguments are given in the WritePriorityOpParams struct.  The onlyValidator modifier of the ValidatorTimelock has a slight redundancy of checking the mapping entry against true as it could also be evaluated directly.  The ValidatorTimelock functions commitBatches and commitBatchesSharedBridge as well as executeBatches and executeBatchesSharedBridge implement the same function body with the only difference of the _chainId. Instead, consider making the [...]SharedBridge functions' body an internal function that is called by their respective external functions by forwarding the _chainId argument or specifying the ERA_CHAIN_ID. This would ease maintenance, be less error-prone, and clarify the functional difference of the interfaces.  Some getter functions unnecessarily cast addresses, for instance the getBridgehub, getStateTransitionManager, getBaseToken and getBaseTokenBridge functions.  Update: Resolved in pull request #308.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#redundant-code", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "Throughout the codebase, the following typographical errors were identified:  In Executor.sol, a comment says \"With the protocol upgrade we expect 8 logs: 2^10 - 1 = 1023\", meaning 10 logs instead of 8.  In StateTransitionManager, the comment \"Cannot do it an initialization\" should say \"during initialization\".  Update: Resolved in pull request #303.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Missing Named Parameters in Mappings", "body": "Since Solidity 0.8.18, developers can utilize named parameters in mappings. This means mappings can take the form of mapping(KeyType keyName => ValueType valueName). This updated syntax provides a more transparent representation of a mapping's purpose.  Throughout the codebase, there are multiple mappings without named parameters:  The stateTransition state variable in the StateTransitionManager contract.  The upgradeCutHash state variable in the StateTransitionManager contract.  The committedBatchTimestamp state variable in the ValidatorTimelock contract.  Consider adding named parameters to the mappings to improve the readability and maintainability of the code.  Update: Resolved in pull request #305.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#missing-named-parameters-in-mappings", "labels": ["OpenZeppelin"]}, {"title": "Using int/uint Instead of int256/uint256", "body": "Within Executor.sol, int/uint is being used instead of int256/uint256.  In favor of explicitness, consider replacing all instances of int/uint with int256/uint256.  Update: Resolved in pull request #290 at commit 8d771cc.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#using-int/uint-instead-of-int256/uint256", "labels": ["OpenZeppelin"]}, {"title": "Lack of Indexed Event Parameters", "body": "Within ValidatorTimelock.sol, two events do not have indexed parameters:  The ValidatorAdded event  The ValidatorRemoved event  To improve the ability of off-chain services to search and filter for specific events, consider indexing event parameters.  Update: Resolved in pull request #309. The Matter Labs team stated:  We only added indexes to first params, which are \"chainId\".", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#lack-of-indexed-event-parameters", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestions", "body": "Throughout the codebase, the following naming suggestions are seen as more accurate:  In the code, the term \"StateTransition\" refers to DiamondProxy contracts that have access to facets just like the Era chain. However, the term seems to be closer to the Executor facet's functionality of handling the L2 state, which is just one aspect of the chain. Therefore, the more general term \"ZK Chain\" appears to be more fitting to refer to the DiamondProxy contract. Consider replacing \"StateTransition\" with \"ZK Chain\" in identifiers that use it.  The setValidiumMode function suggests that the mode can only be changed from Rollup to Validium, although it can be freely set. Therefore, consider naming the function setPubdataPricingMode.  The StateTransitionManagerInitializeData struct is used to initialize the StateTransitionManager. However, the governor address is used to set up the owner role of the contract, which can be confusing. For clarity, consider calling this field owner instead.  The s.baseTokenBridge is sometimes referred to as sharedBridge (e.g., in the Mailbox facet as well as in the error message in ZkSyncStateTransitionBase). To avoid confusion, consider using a consistent name for the same bridge.  Update: Resolved in pull request #307 and pull request #310. Most of the naming suggestions were applied, while the StateTransitionManager contract name and its references were left unchanged. The Matter Labs team stated:  In the future when there are multiple STMs each one will manage a single zone of ZK Chains, and what each zone will have in common is their State Transition function. The STMs do manage everything about the chains (I agree on this fact), but in the bigger picture the different zones will be zones of State Transitions, while every chain under the Bridgehub will be a ZK Chain. To me calling them ZK ChainManager would imply that they manage all ZK Chains, which is not true.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#naming-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Function Is Unnecessarily payable", "body": "The bridgehubRequestL2Transaction function of the Mailbox facet is callable by the BridgeHub to forward a user's L2 transaction request. The calls to this function are done without forwarding any value since the shared bridge is intended to hold all assets. As such, there is no reason for this function to be payable.  Consider removing the payable keyword from the function selector in order to reduce the chances of getting ETH locked in the ZK Chains.  Update: Resolved in pull request #301.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#function-is-unnecessarily-payable", "labels": ["OpenZeppelin"]}, {"title": "Use of Non-Upgradeable Library in Upgradeable Contract", "body": "The StateTransitionManager is an upgradeable contract to be used behind a proxy. It extends the Ownable2Step contract for the owner role management.  Ownable2Step is imported from  initialize function and as long as the storage layout of the extended contracts do not shift, which is unlikely for the  However, to be safe and to adhere to the best practice of using storage gaps, consider using the contracts-upgradeable version of Ownable2Step.  Update: Resolved at commit 4befd8a.", "html_url": "https://blog.openzeppelin.com/zksync-state-transition-diff-audit#use-of-non-upgradeable-library-in-upgradeable-contract", "labels": ["OpenZeppelin"]}, {"title": "Malicious Actor Can Steal Deposits of Tokens With Sender Hooks or Cause Lock Of Funds", "body": "The depositERC20 function can be used to deposit ERC-20 tokens. It first transfers the _msgSender()'s tokens to the contract and then calls the _deposit function. If the token implements sender hooks, a malicious attacker can leverage this to trick the smart contract into believing that they have deposited more funds than they actually had. Following are the steps to achieve this:  A malicious contract calls the depositERC20 function for a token with sender hooks and deposits an amount of 50 tokens.  During the token transfer, the caller reenters the depositERC20 function and deposits 50 tokens again.  The reentrancy check will not trigger as none of the calls has yet reached the _deposit function.  The second execution increases the user's balance by 50 and toggles the reentrancy guard on and then off.  The first execution increases the user's balance by 100, resulting in a total deposited balance of 150 whereas only 100 tokens made it to the contract.  There are two effects of this: if the smart contract contains enough tokens for sending the inflated amount of funds to L2, the batch deposit can be finalized on L2 and 150 tokens will be distributed to the malicious attacker. Alternatively, if the smart contract does not contain enough tokens, the executeBatchDeposit call would fail, without possibility of withdrawal and hence locking the funds.  Consider moving the reentrancy guard to both the depositERC20 and depositETH functions in order to prevent any reentrancy into these functions.  Update: Resolved in pull request #1334 at commit 3d08e40.  Low Severity", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#malicious-actor-can-steal-deposits-of-tokens-with-sender-hooks-or-cause-lock-of-funds", "labels": ["OpenZeppelin"]}, {"title": "Failed Funds Can Be Locked Inside L2BatchBridgeGateway", "body": "has been finalized on L2, the  distribute the funds. If distributing to a party fails, the failed amounts  are accounted for in order to rescue them later through the  withdrawFailedAmount function. Note that the  _transferToken function does not revert on failure but returns a  is not checked. As such, if the ETH or token transfer to the receiver fails, the  failedAmount[token] is still set to 0, locking the funds.  Consider checking the success value of _transferTokens and reverting if the transfer fails.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#failed-funds-can-be-locked-inside-l2batchbridgegateway", "labels": ["OpenZeppelin"]}, {"title": "Tokens Can Get Stuck While Finalizing Deposit", "body": "IL1ERC20Gateway.getL2ERC20Address retrieves the corresponding  tokenMapping is used to set and get the corresponding  IL2ERC20Gateway.getL1ERC20Address function. The token mapping is used by the  In the L2BatchBridgeGateway contract, the finalizeBatchDeposit function relies on the messenger to accurately map the l2Token address to the associated l1Token when a batch deposit of a token is executed and finalized for the first time. The function will revert in a subsequent call if the l1Token differs from the storedL1Token.  updatable. In a scenario where the tokens being bridged are handled by the  Consider removing the duplicated token mapping and supplying the l1Token as a parameter to the distribute function. Alternatively, consider either leveraging the IL2ERC20Gateway.getL1ERC20Address function or providing a function that enables the L2BatchBridgeGateway contract's token mapping to be updated.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority at the moment.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#tokens-can-get-stuck-while-finalizing-deposit", "labels": ["OpenZeppelin"]}, {"title": "Multiple Usages of Obsolete safeApprove", "body": "In the executeBatchDeposit function of L1BatchBridgeGateway, the function safeApprove is used to approve an amount of 0 and once again to approve the desired value. While this ensures compatibility with tokens that require the approval to be set to zero before setting it to a non-zero value(such as USDT), it hinders readability and is not the best practice. Furthermore, safeApprove will not be supported in future OpenZeppelin contracts.  Consider implementing best practices by using the SafeERC20 contract's forceApprove function.  Update: Acknowledged, will resolve. The Scroll team stated:  Acknowledged. Not a priority. We will document for better readability and update to forceApprover later.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#multiple-usages-of-obsolete-safeapprove", "labels": ["OpenZeppelin"]}, {"title": "Missing Event Emission After Configuration Change", "body": "The setBatchConfig function is used to add or update the batch bridge config for a given token. However, this function does not emit any event.  Consider emitting an event to be able to efficiently track configuration changes off-chain.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority due to gas.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#missing-event-emission-after-configuration-change", "labels": ["OpenZeppelin"]}, {"title": "Gas Inefficiencies", "body": "Across the codebase, there are some instances in which the code can be refactored to be more gas efficient:  The newConfig parameter of the setBatchConfig function can be made read-only. Consider changing its location from memory to calldata to save gas.  In order to improve code intentionality and reduce the gas cost in case of a revert, consider switching the order of the following instructions to prioritize the if statement.  The feeVault state variable of the L1BatchBridgeGateway contract is not changeable, consider declaring it as immutable.  Update: Resolved in pull request #1334 at commit b7cc5c2.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#gas-inefficiencies", "labels": ["OpenZeppelin"]}, {"title": "Unused Event", "body": "In the L2BatchBridgeGateway contract, the UpdateTokenMapping event is unused.  To improve the overall clarity, intentionality, and readability of the codebase, consider removing it.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#unused-event", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Usage of Upgradeable Interfaces", "body": "Using upgradeable interfaces does not provide significant benefits and can introduce unnecessary complexity to the codebase. Throughout the codebase, there are a few instances where upgradeable interfaces are being used:  SafeERC20Upgradeable and IERC20Upgradeable in the L1BatchBridgeGateway contract  IERC20Upgradeable in the L2BatchBridgeGateway contract  Moreover, upgradeable interfaces are no longer part of the newer releases of the OpenZeppelin Contracts Upgradable library.  Consider switching to non-upgradeable interfaces and libraries for better code compatibility.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#unnecessary-usage-of-upgradeable-interfaces", "labels": ["OpenZeppelin"]}, {"title": "Typos in Comments", "body": "86,  169, and  187 of  Update: Resolved in pull request #1334 at commit 7a21e29.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#typos-in-comments", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestions", "body": "In the L1BatchBridgeGateway contract, consider replacing the tokens variable name with tokenStates to favor explicitness and readability. In addition, consider renaming the pending struct member to pendingAmount.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#naming-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Unused Import", "body": "The AddressUpgradeable import inside the L1BatchBridgeGateway is unused. Consider removing it.  Update: Resolved in pull request #1334 at commit 900ed4f.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#unused-import", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for their maintainers to contact the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact:  The BatchBridgeCodec library  The L1BatchBridgeGateway contract  The L2BatchBridgeGateway contract  Consider adding a NatSpec comment containing a security contact above each contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Overly Permissive Function Visibility", "body": "The _deposit and _tryFinalizeCurrentBatch functions in the L1BatchBridgeGateway contract have unnecessarily permissive visibility.  To better convey their intended use, consider changing their visibility from internal to private.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#overly-permissive-function-visibility", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Consider adding docstrings to the BatchBridgeCodec library. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-batch-token-bridge-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, docstrings are missing at some places:  The FeeTaker contract declaration  The _getAuctionBump function declaration within BaseExtension.sol  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #311 (commit 76d0640) and pull request #153 (commit 2eef6f8).", "html_url": "https://blog.openzeppelin.com/1inch-settlement-refactor-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Documentation suggestions", "body": "In WhitelistExtension's _isWhitelisted function resolvers are valid only after specific points in time and not before. This is clearly and competently written in the workings of the function. But that this is intended design is not described in the description of the function and led to some confusion on our part. Consider elucidating this detail in the natspec comments of the function so that further readers know how this function is intended to behave.  Update: Resolved in pull request #153 at commit b599e1d.", "html_url": "https://blog.openzeppelin.com/1inch-settlement-refactor-audit#documentation-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Code layout not following Solidity Style Guide", "body": "To make locating contract elements easier by using a common layout, the Solidity Style Guide recommends adhering to the following order of elements within each contract:  Type declarations  State variables  Events  Errors  Modifiers  Functions  In the BaseExtension contract, private functions are declared before internal functions. This deviation from the commonly used layout may impact readability.  Consider moving the internal functions before the private functions.  Update: Resolved in pull request #153 at commit 51ed3ba.", "html_url": "https://blog.openzeppelin.com/1inch-settlement-refactor-audit#code-layout-not-following-solidity-style-guide", "labels": ["OpenZeppelin"]}, {"title": "Unused Named Return Variables", "body": "Named return variables are a way to declare variables that are meant to be used within a function's body for the purpose of being returned as the function's output. They are an alternative to explicit in-line return statements.  Throughout the codebase, there are multiple instances of unused named return variables:  The returnAmount return variable in the clipperSwap function in ClipperRouter.sol  The returnAmount return variable in the clipperSwapTo function in ClipperRouter.sol  Consider either using or removing any unused named return variables.  Update: Acknowledged, will resolve. The 1inch team stated:  We will make an effort to unify our usage of named return variable across all our active codebase somewhen later this year.", "html_url": "https://blog.openzeppelin.com/limit-order-and-aggregation-protocols-diff-audit#unused-named-return-variables", "labels": ["OpenZeppelin"]}, {"title": "Forged Event Emission", "body": "Users have two options to cancel their orders:  Via the cancelOrder function, which uses both the BitInvalidator and the RemaningInvalidator approaches for cancellation, and emits the OrderCancelled event.  Via the bitsInvalidateForOrder function, which uses only the BitInvalidator approach and does not emit any event regarding order cancellation.  Given that the BitInvalidator approach invalidates multiple orders at once and is not bound to a specific order hash, it is natural to skip emitting the OrderCancelled event within it. However, when using this approach via the cancelOrder function, the event will be emitted nonetheless. Furthermore, a malicious user may leverage this behaviour to confuse off-chain systems by emitting the OrderCancelled event for order hashes that are not actually cancelled.  OrderIsNotSuitableForMassInvalidation error.  Update: Resolved in pull request #292 at commit 29199d8. The 1inch team added a new BitInvalidatorUpdated event, which is triggered when orders with useBitInvalidator are cancelled. Normal cancellations by orderHash still trigger the old OrderCancelled event.  Low Severity", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#forged-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Makers May Profit off of Takers via Malicious makerPermit Extension", "body": "Makers have the option of giving allowance via permit, in which case the HAS_EXTENSION_FLAG from the MarketTraitsLib library would need to be set and the extension should contain the makerPermit payload.  When takers fill such an order, if no prior allowance exists, the SKIP_ORDER_PERMIT_FLAG needs to be set to zero in order to ensure the permit will be consumed right after verifying the signature.  In order to consume the permit, both the target address and the permit payload need to be extracted from the extension bytes. The first 20 bytes of the maker permit will be used as the target address, while the remaining bytes will be used as the payload.  Depending on the permit length, the call will be managed differently, always respecting the first 20 bytes of the makerPermit as the address to call, except when the payload indicates that it is a Permit2, in which case the proper contract will be called.  Malicious makers can inject a malicious makerPermit bytes parameter encoded within the order extension so that the tryPermit function calls a contract owned by them. When called, this contract can perform arbitrary actions at the expense of the taker, since they are the ones funding the gas fees. Potential gas-heavy actions that could be run for free include:  Contract deployment  Filling another limit order  Minting gas tokens on chains where they are still available in order to later sell them for a profit  This attack will be possible as long as:  The malicious contract actually ends up consuming the permit or giving the necessary allowance for the order filling to go through.  The expected profit for the taker will still be positive, even after accounting for the extra gas. This assumes that the takers are considering the total gas spent before the end of the transaction and reverting if a net profit cannot be achieved.  In order to mitigate this attack vector, consider disabling makers from being able to specify the target address within the makerPermit bytes. If makers want to use Permit2, the SafeERC20 library is already overriding the target value. For ERC-2612-compatible permits, or exotic permit structures such as with the DAI token, the target address should be the makerAsset. This will also help optimize gas consumption when using permits since extensions will use 20 bytes less of calldata.  Even though takers will still make a profit and this technique could be considered within the \"rules of the game\", consider following this recommendation in order to make the service fairer to all takers while also making the protocol slightly more gas efficient.  Update: Acknowledged, not resolved. The 1inch team stated:  We can't be sure that makerAsset is actually the token. When using proxies, for example, makerAsset is the address of the proxy and not the asset itself. And also, in that case, maker sets the allowance to the proxy address, not to the LimitOrderProtocol address.", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#makers-may-profit-off-of-takers-via-malicious-makerpermit-extension", "labels": ["OpenZeppelin"]}, {"title": "External Calls Have a Hard-Coded Gas Limit", "body": "Gas limits on calls are considered a bad practice for the following reasons:  Gas costs have changed over time (e.g., as per EIP-1884).  EVM side-chains and L2s can have different gas costs. This has previously caused funds to become stuck as transfers run out of gas and revert.  When receivers are smart contracts, they might implement further logic that exceeds the gas limit. This will become especially relevant when account abstraction becomes more popular.  These factors could lead to unreliable functionality over time and across chains. A smart contract wallet can have logic in its receive or fallback function which exceeds the 5000 gas limit, thereby disabling that wallet to use the limit order protocol for swaps where the native currency is involved.  The following calls have a hard-coded gas limit:  The call msg.sender.call{value: msg.value - takingAmount, gas: _RAW_CALL_GAS_LIMIT}(\"\") in the contract OrderMixin in OrderMixin.sol  The call order.getReceiver().call{value: takingAmount, gas: _RAW_CALL_GAS_LIMIT}(\"\") in the contract OrderMixin in OrderMixin.sol  To ensure expected behavior and prevent external calls from running out of gas, consider removing the gas limitation or providing an explicit reason in the documentation for such limit.  Update: Resolved in pull request #292 at commit fcd4732. The 1inch team decided to remove the hard-coded gas limit on both external calls.", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#external-calls-have-a-hard-coded-gas-limit", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Interface", "body": "The function permitAndCall in the OrderMixin contract is one of the main entry points for takers when filling orders if they want to execute a permit before filling an order. However, it is not part of the IOrderMixin interface.  Consider adding this function to the IOrderMixin interface in order to have a comprehensive API for third parties looking to integrate with the protocol.  Update: Resolved in pull request #292 at commit 1800be9.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#incomplete-interface", "labels": ["OpenZeppelin"]}, {"title": "Unused Named Return Variable", "body": "Named return variables are used in a function's body to be returned as the function's output. They are an alternative to explicit in-line return statements.  In ExtensionLib.sol, the result return variable for the _get function is unused.  Consider either using or removing any unused named return variables.  Update: Resolved in pull request #292 at commit 48c2cc1.", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#unused-named-return-variable", "labels": ["OpenZeppelin"]}, {"title": "Unused State Variable", "body": "In the OrderMixin contract, the _PERMIT2 state variable is unused.  To improve the overall clarity, intentionality, and readability of the codebase, consider removing any unused state variables.  Update: Resolved in pull request #292 at commit 69a7a08.", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#unused-state-variable", "labels": ["OpenZeppelin"]}, {"title": "Missing Named Parameters in Mappings", "body": "Since Solidity 0.8.18, developers can utilize named parameters in mappings. This means mappings can take the form of mapping(KeyType KeyName? => ValueType ValueName?). This updated syntax provides a more transparent representation of a mapping's purpose.  Throughout the codebase, there are multiple mappings without named parameters:  The _bitInvalidator state variable in the OrderMixin contract  The _remainingInvalidator state variable in the OrderMixin contract  Consider adding named parameters to the mappings to improve the readability and maintainability of the codebase. Particularly, the _remainingInvalidator mapping could benefit from being more explicit about the key names.  Update: Resolved in pull request #292 at commit 154519f.", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#missing-named-parameters-in-mappings", "labels": ["OpenZeppelin"]}, {"title": "Missing Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Furthermore, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to contact the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact:  The ExtensionLib contract  The LimitOrderProtocol contract  The MakerTraitsLib contract  The OrderLib contract  The OrderMixin contract  The RemainingInvalidatorLib contract  The TakerTraitsLib contract  Consider adding a NatSpec comment containing a security contact above the contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, will resolve. The 1inch team stated that they will follow this practice in the future.", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#missing-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Code Can Be Simplified", "body": "four parameters. However, there is a  shorter version of  Consider using the shorter version for conciseness.  Update: Resolved in pull request #292 at commit c83322c.", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#code-can-be-simplified", "labels": ["OpenZeppelin"]}, {"title": "Incorrect or Missing Documentation", "body": "Throughout the codebase, there are several parts that do not have docstrings:  Docstrings on line 16 in TakerTraitsLib.sol claim that four bits are used for flags and the remaining bits are used to store the threshold amount, whereas the threshold amount actually takes fewer bits. The same docstrings in TakerTraitsLib.sol are missing documentation for the _ARGS_HAS_TARGET flag, the _ARGS_EXTENSION_LENGTH_OFFSET and _ARGS_INTERACTION_LENGTH_OFFSET values, and bits from 250 to 248.  Docstrings on lines 14-15 in MakerTraitsLib.sol are missing documentation for the 253rd bit. While the bit is related to a removed feature and is not used anymore, this fact should nonetheless be stated explicitly.  Docstrings on line 460 in OrderMixin.sol claim that the function processes taker interaction while it also processes maker extensions. The same docstrings on line 461 in OrderMixin.sol claim to revert if the taker permit is invalid, whereas permits are not checked to begin with.  Docstrings on line 47 in OrderMixin.sol are missing.  Documentation for predicates mentions predicate2 twice on line 479 instead of mentioning predicate2 and predicate3 once.  Docstrings on line 77 in IOrderMixin.sol refer to the old way of storing the remaining amount.  The main description.md file has not been updated to reflect the new changes.  Consider updating the documentation so that it reflects all the newly introduced changes.  Update: Resolved in pull request #285 at commits b21a2e and ca2158d, and in pull request #292 at commits 1800be9, aa88e62, 46f4795 and 3c9b8ab.", "html_url": "https://blog.openzeppelin.com/limit-order-protocol-diff-audit#incorrect-or-missing-documentation", "labels": ["OpenZeppelin"]}, {"title": "Restricted External Calls Can Be Made on Behalf of AggregationRouter", "body": "The Aggregation protocol is supposed to integrate with any Curve pool. Given the variety of the pool types within the protocol, this provides users with a significant degree of control. For example, one of the external calls made on behalf of the protocol takes most of its parameters directly from untrusted user input. This includes the function selector, target address and parameters. This might become problematic because the protocol holds user token approvals. However, the two most significant parameters are restricted to just one byte (values 0-255) which limits the potential impact.  Consider further restricting the parameters of this external call.  Update: Resolved in pull request #268 at commits 8458b1e and 184ad46. The 1inch team removed the ability to freely specify any 4-byte selector within the dex parameter. Instead, users can now choose one of the 18 preconfigured selectors by specifying a 1-byte index from 0 to 17. This choice heavily reduces the ability to perform arbitrary external calls.", "html_url": "https://blog.openzeppelin.com/aggregation-protocol-diff-audit#restricted-external-calls-can-be-made-on-behalf-of-aggregationrouter", "labels": ["OpenZeppelin"]}, {"title": "Assembly Block Diverges from Solidity's Memory Model", "body": "One of the assembly blocks marked as memory safe contains operations that might be memory unsafe according to the Solidity documentation. The reason is that the return data size might be greater than the scratch space for some WETH implementations.  Consider using the free memory pointer to retrieve an unused memory location as implemented in the safeWithdraw function.  Update: Resolved in pull request #104 at commit ac7d637.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/aggregation-protocol-diff-audit#assembly-block-diverges-from-solidity's-memory-model", "labels": ["OpenZeppelin"]}, {"title": "Code Clarity Suggestions", "body": "The tokenBalanceOf function returns the balance of a specific token for a specific address, minus 1. However, the function name suggests that it simply returns the token balance of the provided address. This might be confusing for some readers.  Consider either moving the subtraction out of the function as implemented in the previous case within the same switch statement. Alternatively, consider renaming the function.  Update: Resolved in pull request #276 at commit 6c22250.", "html_url": "https://blog.openzeppelin.com/aggregation-protocol-diff-audit#code-clarity-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Reliance on External Slippage Protection", "body": "For swaps via Curve pools, the Aggregation protocol relies on slippage protection being implemented by the pools. While we were not able to bypass the slippage protection, the Aggregation protocol nonetheless allows for reentrancy.  Consider adding slippage protection at the protocol level in a way similar to how it is done for Uniswap pools.  Update: Resolved in pull request #270 at commit 9bd2950.", "html_url": "https://blog.openzeppelin.com/aggregation-protocol-diff-audit#reliance-on-external-slippage-protection", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact:  The AggregationRouterV6 contract  The ClipperRouter contract  The GenericRouter contract  The UnoswapRouter contract  Consider adding a NatSpec comment containing a security contact above the contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, will resolve. The 1inch team stated that they will follow this practice in the future.", "html_url": "https://blog.openzeppelin.com/aggregation-protocol-diff-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Unused Errors", "body": "Throughout the codebase, several unused errors were identified:  The ZeroReturnAmount error in GenericRouter.sol  The SwapAmountTooLarge error in UnoswapRouter.sol  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any unused errors.  Update: Resolved in pull request #276 at commits d6fac8e and 1a7ff67.", "html_url": "https://blog.openzeppelin.com/aggregation-protocol-diff-audit#unused-errors", "labels": ["OpenZeppelin"]}, {"title": "No Masking of Addresses in SafeERC20 Library", "body": "The SafeERC20 library is used to implement several ERC-20 functions (transfer, transferFrom, approve etc.) in a way that is both gas-efficient and maximally compatible with different ERC-20 token implementations. The library uses assembly for efficiency.  However, in multiple functions, the Address arguments are directly copied to memory without being masked in assembly blocks. Note that because the library functions are called internally in the codebase, the function calls are replaced by JUMP instructions but no bit cleaning operation is inserted by the compiler. Depending on the context in which the library is used, this could result in unexpected reverts.  For example, an address with dirty upper bits could be computed using assembly, after which the assembly block could be closed and safeTransferFrom called (assuming that the bits would get cleaned since it is a function call in Solidity). However, the call to transferFrom would revert with an \"EvmError: Revert\" message. A similar issue was reported in the Solmate library by several users. Libraries can be used in a wide variety of contexts and should aim to work well in all of them.  Consider masking the Address arguments in the SafeERC20 library preemptively to avoid such issues.  Update: Resolved at commit bcb0ace. Warnings that make the behavior explicit were added. This resolves the issue because the 1inch contracts are not affected by this behavior while potential users of the library are now explicitly aware of it. The 1inch team stated:  For now we have decided to only comment the behavior and add a warning everywhere it is relevant. We might rethink our approach in the future.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#no-masking-of-addresses-in-safeerc20-library", "labels": ["OpenZeppelin"]}, {"title": "Fee Regulation Might Not Work as Expected on Non-Mainnet Chains", "body": "The _isPriorityFeeValid function implements the fee regulation check proposed in 1IP-43. This check constrains the priority fee when interacting with the protocol, which should reduce the gas competition between resolvers and improve prices for users. Given the multi-chain nature of the protocol, however, the check might not work as expected on chains other than the Ethereum mainnet.  For example, Aurora, which is currently supported by 1inch, sets the base fee to zero for all blocks which would lead to reverts in the _isPriorityFeeValid function. Some other chains such as Scroll, which are not currently supported but might be in the future, revert when the base fee is accessed. Other chains like Optimism might have significantly different base fee dynamics which makes values hardcoded in the protocol less robust.  Before deploying the fee regulation on a new chain, consider validating that the check done by the _isPriorityFeeValid function works as intended. Alternatively, consider introducing the fee regulation only on the Ethereum mainnet.  Update: Resolved. The 1inch team stated:  The priorityFee limitation applies only to the mainnet, so the extension will be deployed on other chains without that check.  Low Severity", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#fee-regulation-might-not-work-as-expected-on-non-mainnet-chains", "labels": ["OpenZeppelin"]}, {"title": "Low Granularity of Voting Threshold", "body": "associated comment, a  However, assuming that token is the 1inch token with a total supply of 1,500,000,000, a 0.01% ownership at current prices would cost roughly $51,000. While the resolver role is likely to be restricted to a small set, $51,000 as the minimum increment seems high and the protocol may prefer a higher granularity when adjusting resolverPercentageThreshold.  Consider increasing the number of decimals of the BASIS_POINTS variable to increase the granularity with which the threshold can be changed and be more future-proof.  Update: Acknowledged, will resolve. The 1inch team stated:  Good find, we will increase granularity with the next whitelist release. However, the token that the whitelist is tracking is actually Delegated-Staked-1INCH and its total supply is unlikely to reach 1INCH total supply.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#low-granularity-of-voting-threshold", "labels": ["OpenZeppelin"]}, {"title": "Lack of Input Parameter Validation", "body": "The resolverPercentageThreshold variable stores the percentage of the total supply that an address has to stake in order to become a resolver. This percentage should never be higher than 100% but this is not enforced by the protocol. In extreme cases, this might prevent the whitelist from functioning. For example, if resolverPercentageThreshold is set to type(uint256).max, it is not possible to clean the whitelist anymore as the check overflows.  Consider adding a check that the percentage is less than 100% when setting it.  Update: Resolved in pull request #138 at commits 3196ff8 and 921a6b3. The resolverPercentageThreshold variable can no longer be set to a value larger than 100%.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#lack-of-input-parameter-validation", "labels": ["OpenZeppelin"]}, {"title": "Discrepancy Between Proposal and Implementation", "body": "The accepted 1IP-43 proposal states that \"for blocks with baseFee >104.1 gwei - priorityFee is capped at 65% of the blocks baseFee\". However, the implementation applies the cap if the base fee is greater than or equal to 104.1 instead of strictly being greater.  Consider adjusting either the proposal or the implementation to eliminate this discrepancy.  Update: Resolved in pull request #138 at commit 5e4652a.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#discrepancy-between-proposal-and-implementation", "labels": ["OpenZeppelin"]}, {"title": "Unused Interface", "body": "WhitelistRegistry contract maintains a list of whitelisted addresses which can act as resolvers. These are required to maintain a certain percentage ownership of the  IVotable, where  votingPowerOf function. However, this function is not used, making the use of this interface confusing.  If there is no need to use IVotable, consider replacing it with the regular ERC-20 interface to make the code clearer.  Update: Resolved in pull request #138 at commit 7f697df. The 1inch team decided to replace the unused IVotable interface with the more natural IERC20 interface.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#unused-interface", "labels": ["OpenZeppelin"]}, {"title": "Forged Event Emission", "body": "According to the documentation of the promote function, the whitelist registry allows resolvers to register a worker to fill orders on their behalf. At the end of the process, the Promotion event is emitted. However, one does not need to be a whitelisted resolver in order to register a worker. This allows anyone to emit Promotion events, which might confuse off-chain systems.  Consider only allowing resolvers to promote a worker.  Update: Acknowledged, not resolved. The 1inch team stated:  We want to allow resolvers to properly set up their workers even if they do not yet have enough balance to be whitelisted.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#forged-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Ordering of Functions", "body": "The SettlementExtension contract deviates from the Solidity style guide and has an inconsistent ordering compared to the rest of the codebase.  To improve the project's overall legibility, consider reordering the functions of this contract.  Update: Resolved in pull request #138 at commit e7d9771.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#inconsistent-ordering-of-functions", "labels": ["OpenZeppelin"]}, {"title": "Unused Error", "body": "The NotWhitelisted error defined in WhitelistRegistry.sol is unused.  To improve the overall clarity and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #138 at commit 95d6279.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#unused-error", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "We identified the following typographical errors in the codebase:  \"intergrationFee\" should be \"integrationFee\"  \"stores introduces\" should be \"introduces\"  Consider correcting the identified errors to improve the readability of the codebase.  Update: Resolved in pull request #138 at commit c8d6302.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Missing Named Parameters in Mapping", "body": "Since Solidity 0.8.18, developers can utilize named parameters in mappings. This means mappings can take the form of mapping(KeyType KeyName? => ValueType ValueName?). This updated syntax can provide a more transparent representation of the mapping's purpose.  The promotions mapping state variable in the WhitelistRegistry contract could be better documented by using named parameters.  Consider adding named parameters to the mappings to improve the readability and maintainability of the codebase.  Update: Resolved in pull request #138 at commit df5874e.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#missing-named-parameters-in-mapping", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  However, the SettlementExtension and WhitelistRegistry contracts do not provide a security contact.  Consider adding a NatSpec comment containing a security contact above the contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, will resolve. The 1inch team stated that they will follow this practice in the future.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "We identified several instances where additional documentation would make the code easier to understand:  The _clean function in the WhitelistRegistry contract  Most of the functions in the SettlementExtension contract (notably _getRateBump and _parseFeeData)  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #138 at commit 517b115.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports", "body": "The use of non-explicit imports in the codebase can decrease code clarity and may create naming conflicts between locally defined and imported variables. However, throughout the codebase, global imports are being used exclusively.  Following the principle that clearer code is better code, consider using named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #138 at commit 4529ed8.", "html_url": "https://blog.openzeppelin.com/limit-order-settlement-audit#non-explicit-imports", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are multiple instances of code that does not have docstrings. For instance:  The name state variable in EthereumVaultConnector.sol.  The version state variable in EthereumVaultConnector.sol.  The receive function in EthereumVaultConnector.sol.  The events in Events.sol.  The errors in Errors.sol.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #127.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "Throughout the codebase, there are several instances of incomplete docstrings. For instance:  In the isValidSignature function in IERC1271.sol not all return values are documented.  In the checkAccountStatus function in IVault.sol the collaterals parameter is not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of a contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #128.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Floating Pragma", "body": "Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.  Throughout the codebase there are multiple floating pragma solidity ^0.8.19 directives.  Consider using fixed pragma versions.  Update: Acknowledged, will resolve. The Euler team stated:  This is a known issue. The Solidity version will be fixed before the deployment of the Ethereum Vault Connector. Note that we are still waiting for a Solidity version supporting the transient keyword so that we can make use of transient storage without needing to rewrite already audited libraries in assembly.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#floating-pragma", "labels": ["OpenZeppelin"]}, {"title": "Collateral Removal Changes The Collaterals Order", "body": "The reorderCollaterals function allows users to reorder collateral according to their preferences. However, there is an issue when a user decides to remove one of the collaterals using the disableCollateral function. In such cases, the collateral list might be reordered using a common algorithm that swaps the last element with the removed one and then removes the last item from the list. This leads to a scenario where the remove function has unexpected side effects.  Consider either implementing logic to preserve the order of elements or documenting this behavior.  Update: Resolved in pull request #129. The Euler team stated:  This is a known behavior of the system. The NatSpec of the disableCollateral function has been refined to indicate that it does not preserve the order of collaterals. Note that this behavior does not pose any risk to a user and may only cause inconvenience if the user needs to call reorderCollateral after previously calling disableCollateral. Considering that both operations can be batched in one EVC call or as a part of a bigger batch, it should never be an issue.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#collateral-removal-changes-the-collaterals-order", "labels": ["OpenZeppelin"]}, {"title": "Deployment To Chains Other Than Ethereum", "body": "Below are some considerations to take into account when deploying this system to chains other than Ethereum.  The isSignerValid function implements logic to prevent precompiles from being used as signers in the permit function. It assumes that the addresses of precompiles are values of 0xFF or lower. This is true for Ethereum but may not be the case for other chains. For instance, on the zkSync Era chain system contract addresses start with 0x8000.  Typical address aliasing in chains like Arbitrum or Optimism might break the assumption of having the same prefix for different sub-accounts. Specifically, whenever an account is a contract and not an externally owned account (EOA), Layer 1 to Layer 2 (L1 -> L2) messages will have the msg.sender aliased with a mask. This might result in different aliased account prefixes. The EVC will need to integrate un-aliasing features if it is intended to support cross-chain messaging.  Some chains, like zkSync Era, employ different memory growth mechanisms. In Ethereum, memory grows in words of 32 bytes each, whereas in zkSync Era, memory grows directly in bytes. Consequently, opcodes like mstore and mload may yield different results when utilized.  Update: Resolved in pull request #133 by defining the isSignerValid function as virtual. The Euler team stated:  The isSignerValid function has been specifically added to the EVC in order to be overridden in case it is needed, depending on the chain to which the EVC is to be deployed. As you correctly noticed (i.e., for zkSync Era chain, the function will have to be overridden in order to invalidate signer addresses starting with 0x8000), depending on the chain to which the EVC is to be deployed, other contract modifications might be necessary. Deployment to each chain will have to be closely evaluated.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#deployment-to-chains-other-than-ethereum", "labels": ["OpenZeppelin"]}, {"title": "The Signature Can Be Used By Anyone", "body": "The permit function permits anyone to submit the signature created by the signer. While this behavior may be appropriate for many implementations, there may be cases where it is necessary to restrict the use of the signature to a specific account.  Consider whether it is worth including the submitter of the signature within the signature itself to enable the limitation of its use to the specific account.  Update: Resolved at commit ba286b2. The Euler team stated:  This issue has been pointed out by other auditors as well and has been fixed under the mentioned commit.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#the-signature-can-be-used-by-anyone", "labels": ["OpenZeppelin"]}, {"title": "Missing Converse Functions In ExecutionContext", "body": "get values and  insert values. Some functions also have a way to  clear the corresponding bit of a flag but this is missing for the  Consider providing these flags with the same functionality as the others.  Update: Acknowledged, not resolved. The Euler team stated:  Acknowledged. ExecutionContext is a custom library and only contains functions that are directly used and needed by the EVC. No action is necessary.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#missing-converse-functions-in-executioncontext", "labels": ["OpenZeppelin"]}, {"title": "Confusing NonceUsed Event", "body": "The user can utilize the setNonce function to invalidate a previously set nonce. This function permits setting the nonce only to a value higher than the current one. Once the new nonce is set, the function emits a NonceUsed event, similar to the permit function. However, this process may be confusing since the user can set the nonce to a much higher value than the signature they issued, resulting in an event emission with a nonce that does not correspond to any signature.  Consider using a different event within the setNonce function which includes the current nonce and the value to which the nonce was increased, such as nonceFrom and nonceTo.  Update: Resolved in pull request #130.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#confusing-nonceused-event", "labels": ["OpenZeppelin"]}, {"title": "Missing Input Validation", "body": "Throughout the codebase there are multiple instances of missing input validation.  Missing zero address check for operator parameter in setAccountOperator function.  Missing zero address check for evc parameter in EVCUtil's contract constructor.  Consider implementing input validation for the instances above to prevent unexpected behavior.  Update: Partially resolved at commit 4118c0f. The Euler team stated:  Acknowledged. Considering that the lack of input validation for the EVC functions like setAccountOperator, enableCollateral or enableController poses neither any risk to the user nor causes any unexpected behavior, we decided not to validate those functions inputs. No action is necessary. It lies in the user's best interest to provide correct parameters. As for the lack of address validation in the EVCUtil constructor, it was pointed out in the other audit and fixed under this commit.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#missing-input-validation", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact. For instance:  The EVCUtil abstract contract.  The Errors contract.  The EthereumVaultConnector contract.  The Events contract.  The ExecutionContext library.  The IERC1271 interface.  The IEVC interface.  The IVault interface.  The Set library.  The TransientStorage abstract contract.  Consider adding a NatSpec comment containing a security contact to the top of the contract's definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #131.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Use of Named Returns", "body": "The EthereumVaultConnector contract has inconsistent usage of named returns in its functions. To improve the readability of the contract, use the same return style in all functions.  Consider being consistent with the use of named returns throughout the codebase.  Update: Acknowledged, not resolved. The Euler team stated:  Acknowledged. No action necessary.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#inconsistent-use-of-named-returns", "labels": ["OpenZeppelin"]}, {"title": "File and Contract Names Mismatch", "body": "The IEthereumVaultConnector file name does not match the IEVC contract name.  To make the codebase easier to understand for developers and reviewers, consider renaming this file to match the contract name.  Update: Acknowledged, not resolved. The Euler team stated:  Acknowledged. Despite the inconsistency, naming the interface differently from the file name is convenient. The file name does not use the abbreviation and clearly indicates that the Ethereum Vault Connector interface can be found in it. On the other hand, the interface contained in that file uses the abbreviation, making it more convenient to use in other smart contracts due to its shortness. No action is necessary.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#file-and-contract-names-mismatch", "labels": ["OpenZeppelin"]}, {"title": "Repeated Code in Set Library", "body": "Within the Set library, the logic to retrieve the first element in the set, and the number of elements, is repeated in many functions.  Consider encapsulating this logic into a single internal function and using it when needed. This way, if anything changes, only the internal function needs to be modified, thereby improving the overall readability and quality of the codebase.  Update: Acknowledged, not resolved. The Euler team stated:  Acknowledged. The Set library has already been audited multiple times. Hence, unless absolutely necessary, we would not like to make any modifications in it. No action is necessary.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#repeated-code-in-set-library", "labels": ["OpenZeppelin"]}, {"title": "Non-explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease the clarity of the code, and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity files or when inheritance chains are long.  Throughout the codebase, global imports are being used. For instance:  The import \"../interfaces/IEthereumVaultConnector.sol\"; import in EVCUtil.sol.  The import \"./interfaces/IEthereumVaultConnector.sol\"; import in Errors.sol.  The import \"./Set.sol\"; import in EthereumVaultConnector.sol.  The import \"./Events.sol\"; import in EthereumVaultConnector.sol.  The import \"./Errors.sol\"; import in EthereumVaultConnector.sol.  The import \"./TransientStorage.sol\"; import in EthereumVaultConnector.sol.  The import \"./interfaces/IEthereumVaultConnector.sol\"; import in EthereumVaultConnector.sol.  The import \"./interfaces/IVault.sol\"; import in EthereumVaultConnector.sol.  The import \"./interfaces/IERC1271.sol\"; import in EthereumVaultConnector.sol.  The import \"./ExecutionContext.sol\"; import in TransientStorage.sol.  The import \"./Set.sol\"; import in TransientStorage.sol.  Following the principle that clearer code is better code, consider using named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #132.", "html_url": "https://blog.openzeppelin.com/ethereum-vault-connector-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "Redstone Oracle Adapter Is Flawed", "body": "The Redstone adapter works by locally caching the prices received through the Redstone pull-based oracle. The user supplies the off-chain verified price by calling the updatePrice function on the adapter. This call is supposed to be part of a batch transaction to the Ethereum Vault Connector. This design makes the RedstoneCore Adapter function like a push-based oracle.  The updatePrice function does not let you update the price if maxCacheStaleness has not passed since the time of the last update. During times of high volatility, the price cannot be updated in a timely manner opening the doors for:  Borrowing more of an underpriced asset  Borrowing more value due to overpriced collaterals  Not being able to liquidate in a timely manner  Another notable observation is that the adapter can return a price that is block.timestamp - (maxCacheStaleness + maxPriceStaleness) old. This can lead to prices being more stalled than assumed.  The impact and consequences of this issue are very high. However, the likelihood is ultimately determined by the maxCacheStaleness and maxPriceStaleness time periods. If these are short enough, combined with the low likelihood of flash crashes, the overall chances of this being a serious issue are contained.  cacheUpdatedAt and devising a way where the staleness check includes both the  Update: Resolved in pull request #40 at commit b422959.  Low Severity", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#redstone-oracle-adapter-is-flawed", "labels": ["OpenZeppelin"]}, {"title": "Code Behaves Inconsistently", "body": "The codebase incorporates several oracle adapters behind the same IPriceOracle interface. However, each specific adapter has its own set of assumptions and differences in the inner mechanics. There are also some inconsistencies between several adapters, specifically when it comes to prices being zero.  Chainlink and Chronicle oracles prohibit the price from being zero.  In the Lido oracle, if inAmount is small enough, the outAmount can be truncated to zero. The same can happen in the Dai/sDai oracle.  Pyth, Uniswap V3, and Redstone oracles can directly return a zero price.  Consider implementing either of the following two changes to make the adapter behavior consistent:  Prohibit the price from being zero (and negative) in all the adapters.  Allow the price to be zero (and positive) in all the adapters and handle the special case of zero prices in the vaults.  Update: Partially resolved in pull request #32. Prices being truncated to zero are not deemed incorrect. The Euler team stated:  We have modified PythOracle and RedstoneCoreOracle to reject a signed price of 0. Truncation to 0 is possible in all adapters and we consider it correct behavior. 0 is the correct answer for the question that getQuote answers: \"the amount of quote corresponding to inAmount of base\". Note that truncation is possible in all adapters, not just the ones mentioned.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#code-behaves-inconsistently", "labels": ["OpenZeppelin"]}, {"title": "Chainlink Adapter Can Return Incorrect Price During Flash Crashes", "body": "Some Chainlink price feeds might have a built-in minimum and maximum price that they can return. In the event the price falls below the minimum price or crosses the maximum price, the Chainlink oracle will return an incorrect price. This can lead to catastrophic consequences.  Consider allowing the deployer to define a percentage margin and if the price returned by Chainlink is within that narrow percentage of the minimum price or the maximum price, the adapter should revert. The minimum price and maximum price can be retrieved from the OffchainAggregator contract of the price feed at the minAnswer and maxAnswer variables.  Update: Acknowledged, not resolved. The Euler team stated:  Acknowledged. We chose not to use minAnswer and maxAnswer as indicators for the Chainlink oracle malfunctioning. It is unclear whether these values are expected to change, while reading them on every call would add a gas overhead to what would be a very hot path in production.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#chainlink-adapter-can-return-incorrect-price-during-flash-crashes", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for the maintainers of these libraries to contact the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact.  Consider adding a NatSpec comment containing a security contact above the contract definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #38. The Euler team stated:  Fixed by adding @custom:security-contact security@euler.xyz to all contracts.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Price Retrieval From Oracles Might Fail", "body": "call might fail if Chainlink decides to restrict  access to their oracles, Chronicle's oracle  call can fail if the calling address is  not whitelisted, and Pyth's  call might  fail for several reasons as well. Similarly, other oracles can fail for a variety of reasons.  These are just examples and it seems that the codebase in general does not catch potential failures gracefully. If this is intentional, consider explicitly stating it in the docstrings. Otherwise, consider wrapping price retrieval calls into try/catch blocks and fail with specific error messages.  Update: Acknowledged, not resolved. The Euler team stated:  We have added in-code documentation in ChronicleOracle detailing that the adapter must be whitelisted prior to use. We have also added other pieces of in-code documentation to list some of the revert conditions of the connected oracles. An adapter reverting is the only correct behavior when an external call fails. In such a scenario, the adapter cannot safely provide a quote, and therefore cannot answer the getQuote* query in a satisfactory manner. Other options are returning 0 or a magic value, however we believe that this would constitute behavior that is unexpected, flaky, and highly detrimental to an uninformed consumer contract. We have decided not to try/catch external calls in the adapters due to several reasons:  It is only a semantic change. The adapter will still revert but the revert data will contain a standardized error message instead of the propagated vendor revert data.  It increases the verbosity and complexity of the adapters. This is because an external call may need to catch and translate multiple vendor errors.  Some revert conditions are impossible to catch or interpret. For example, panic errors or empty revert data.  Errors are generally not considered breaking changes, thus the behavior of adapters may change due silently, affecting connected consumers.  It promotes consumer code that branches based on revert data, which is considered an anti-pattern in Solidity. This is because of the listed reasons and also because errors can be easily spoofed by external code.  We note that wherever possible, euler-price-oracle adapters revert with semantic custom errors (e.g., PriceOracle_InvalidConfiguration), and we agree that descriptive standardized errors are a best practice. Our disagreement is about mapping revert data of external calls to euler-price-oracle-specific errors.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#price-retrieval-from-oracles-might-fail", "labels": ["OpenZeppelin"]}, {"title": "Oracle Price Updates Can Be Sandwiched", "body": "Oracles are meant to provide pricing of assets for Euler's vaults. These prices are used to perform typical operations of a synthetic/lending protocol. A push-based oracle's (like Chainlink and Chronicle) price update transaction can be seen in the mempool and users might decide to front run and/or back run such price updates to benefit from a rapid shift in price.  While we did explore how this can be an attack vector into the vault codebase, we found no practical examples. However, we deem this information important enough to raise it as an issue. A lot of research has been done about the topic and common solutions involve either the use of fees or delays between actions to remove incentives from value extraction on sandwich attacks within the same block or between a couple of blocks.  Consider reviewing the topic and adding mitigations wherever the team deems it necessary for such types of attacks.  Update: Acknowledged, will resolve. The Euler team stated:  Acknowledged. All network-based oracles have a degree of information asymmetry as pending price data can either be observed from the node network itself or consumed at the source directly. We are looking into the viability of this sandwich opportunity on a per-oracle basis. A good way to reduce the likelihood of a sandwich attack is to deploy a vault with a more conservative loan-to-value ratio. This is because the sandwiched price update will have to deviate more than 1-LTV% to incur bad debt in the system. Adding delays to EVK vault actions would be unacceptable as it would negatively affect user experience and vault composability. We are currently experimenting with solutions in euler-price-oracle such as adding a spread to the mid-price in getQuotes that could also reduce the likelihood of a sandwich attack.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#oracle-price-updates-can-be-sandwiched", "labels": ["OpenZeppelin"]}, {"title": "updatePrice Is Updating the State Without Event Emission", "body": "The updatePrice function in the RedstoneCoreOracle contract is not emitting an event whenever a new price is set.  Consider adding an event emission every time a state variable changes its value.  Update: Resolved in pull request #32. The Euler team stated:  Fixed. The adapter now emits CacheUpdated(uint256 price, uint256 priceTimestamp) when the price is updated.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#updateprice-is-updating-the-state-without-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Docstrings", "body": "In the codebase, there are some cases in which docstrings are incorrect.  In line 20 of the IPriceOracle interface, \"get\" should be \"spend\".  In lines 78-79 of the PythOracle contract, \"exponent confidence is too wide\" is incorrect since the only existing confidence level is on the price and not in the exponent.  In line 81 of the RedstoneCoreOracle, it is mentioned that validateTimestamp will be called in getQuote but this is not true since getQuote does not update the price at all.  Consider reviewing the codebase for incorrect docstrings in order to improve its overall readability and correctness.  Update: Resolved in pull request #32. The Euler team stated:  We added all missing pieces of NatSpec to the contracts. We also added in-code comments around the logic wherever applicable. We fixed several typos, wording issues, and invalid and stale pieces of documentation.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#incorrect-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Missing Assumption", "body": "The UniswapV3Oracle assumes that enough in-range liquidity is present in the pool for the price to not suffer major slippage effects. In addition, it is assumed that the observations used to calculate the price are not outdated and stale but this is missing in the docstrings.  Consider adding the latter assumption to the list of assumptions in the UniswapV3Oracle contract.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#missing-assumption", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are several parts that do not have docstrings. For instance, the AggregatorV3Interface , IChronicle, IPot, and IStEth interfaces are all lacking any sort of docstrings.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #32. The Euler team stated:  We added all missing pieces of NatSpec to the contracts. We also added in-code comments around the logic wherever applicable. We fixed several typos, wording issues, and invalid and stale pieces of documentation.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Lido Adapter Can Be Front Run", "body": "Lido adapter uses the  stETH contract to price  Consider reviewing the architecture of the Lido ecosystem thoroughly to find out ways to secure the system against any attack vectors arising out of such information asymmetry. Alternatively, consider using a different price feed like Pyth's wstETH/USD feed to price wstETH.  Update: Acknowledged, not resolved. The Euler team stated:  Updates to the stETH exchange rate are triggered though the Lido AccountingOracle. A trusted oracle committee (5/9 multisig) submits data about the economic state of Lido validators. Updates currently happen every 225 epochs (~24 hours) for accounting updates and every 75 epochs (~8 hours) for withdrawal requests. Before a report is applied, it is sanitized to adhere to several consistency rules, including capping the size of the rebase to [-5%, +0.75%]. Historical data since 2023-04-25 shows that the largest rebase was 0.0228% at 2023-05-06 and the lowest was 0.0132% at 2023-04-25. Therefore, we can conclude that under normal functioning of the Lido system, the rebase rate is far too low to make sandwiching profitable.  There are several multi-billion lending protocols that use the stETH exchange rate without known adverse events. We consider this strong empirical evidence of the absence of a viable attack plan arising from the rebase mechanism under normal operating conditions.  As a side note, Aave implements additional validation on the combined exchange rate using their correlated-asset price oracle (CAPO). In Ethereum Mainnet Aave V3, the yearly growth of wstETH/ETH is capped to 9.68%. Interestingly, CAPO does not impose a limit in the downward direction. Implementing an exchange rate cap mechanism with IPriceOracle is possible. However, we believe no immediate action is necessary due to the analysis above.  EVK vault creators that do not wish to take the exchange rate from the Lido contracts can instead connect to one of many direct wstETH oracles such as the Chronicle wstETH/USD oracle, the Pyth wstETH/USD, or the Redstone Core wstETH/ETH oracle.  However, we cannot issue a recommendation to use one over the other since there are fewer data sources for wstETH and these direct oracles may thus be considered more manipulable.", "html_url": "https://blog.openzeppelin.com/price-oracle-audit#lido-adapter-can-be-front-run", "labels": ["OpenZeppelin"]}, {"title": "Missing Gap Between Borrow LTV and Liquidation Threshold", "body": "The protocol does not implement a gap between the LTV ratio at which borrowers are allowed to borrow and the liquidation threshold at which liquidation can be executed. This means that it is possible to borrow at the very edge of liquidation and be liquidated with a slight price change.  This opens the surface for an attack that could drain the vault of available assets by monitoring price updates. In case the price change is significant enough, the attacker could profit from the change by socializing the debt. When a user becomes eligible for liquidation, a third-party liquidator is rewarded for processing the repayment of their debt with a bonus. This bonus depends on the users health score, and as the users health score declines, the bonus grows.  This means that a users health score is lowered after liquidation if the bonus exceeds the relative over-collateralization of the position. For instance, if a user's position is 10% over-collateralized but the bonus is 11%, then the users health score declines after liquidation. This scenario allows an attacker, in case of a market stress situation where the price changes significantly, to front run the price change either by monitoring the mempool or through compatible oracles where prices can be updated by anyone like Pyth or Redstone. The attacker could borrow assets, allow the price change, and then liquidate themselves, retrieving all the collateral and profiting by creating bad debt for the protocol. This Proof of Concept was created to illustrate the attack.  Consider introducing a gap between the borrow LTV ratio and the liquidation threshold to prevent borrowers from borrowing assets at an LTV ratio close to liquidation. This gap should be flexible enough to accommodate both highly volatile and barely volatile assets. Specifically, the gap should be wider for high-volatility assets and narrower for low-volatility assets.  Update: Resolved in pull request #191 of the euler-vault-kit repository and pull request #157 of the ethereum-vault-connector repository. The Euler team stated:  We have made a set of 3 changes to the liquidation system in order to mitigate the issues discovered by our auditors.  The first issue raised is related to the \"Counterproductive Incentives\" issue described by OpenZeppelin in their 2019 Compound audit. Liquidation systems that incentivise liquidators with extra collateral value as a bonus (or discount) can, in some circumstances, leave violators more unhealthy than they were pre-liquidation. In the Euler system, the discount is proportional to how unhealthy the user is, which means that in these cases, a liquidator may improve their total yield by performing many small liquidations, rather than one large liquidation. Each smaller liquidation will decrease the user's health and therefore increase their discount for subsequent liquidations, up until the maximum liquidation discount is reached. As described in our Dutch Liquidation Analysis research paper, this scenario can be avoided by selecting an appropriately low maximum discount factor.  Change 1: With this in mind, we have added EVK functionality that allows governors to configure the vault's maximum discount factor. In many cases, governors will compute an appropriate maximum discount based on the highest configured LTV for the vault, although there may be other considerations involved. A governor must specify a value for this parameter, otherwise the liquidation system will not function properly.  The second issue raised is a general observation that price manipulation can be used to attack lending markets, and that some of the oracles we would like to support have special challenges. In particular, pull-based oracles like Pyth and Redstone provide more flexibility to attackers because they can typically choose to use any published prices within an N-minute window. For example, an attacker may be monitoring prices off-chain, waiting for a large decline in the price of a vault's collateral asset (or, equivalently, a large increase in the price of the liability asset). If the decline is sufficiently large, the attacker will search the previous N-minutes of prices and select the pair with the largest difference. The attacker will then submit a transaction that performs the following attack:  Updates the oracle with the old price  Deposits collateral and borrows as much as possible  Updates the oracle with the new price, causing the position to become very unhealthy  Liquidates the position from another separate account, leaving bad debt. This bad debt corresponds to profit from the attack at the expense of the vault's depositors  Although impossible to solve in the general case, to reduce the impact of this issue we have have made two modifications to the EVK:  Change 2: We now allow the governor to configure separate borrowing and liquidation LTVs. This requires the attacker to find correspondingly larger price jumps.  Change 3: We have added a \"cool-off period\" wherein a", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#missing-gap-between-borrow-ltv-and-liquidation-threshold", "labels": ["OpenZeppelin"]}, {"title": "Unhealthy Position Locks Collateral That Is Not Recognizable by the Controller", "body": "The protocol connects compatible vaults through the Ethereum Vault Connector (EVC) and ensures that sensitive actions triggered by the user on any of the vaults are validated through both account and vault status checks. If the user has a controller enabled, a call is made to ensure that the action does not jeopardize the user's position's health.  However, the issue arises when this check is also conducted in cases where the vault the user interacts with is not recognized as valid collateral for the user's position and has no impact on the user's position. Consequently, this prevents users with unhealthy positions from withdrawing assets or transferring shares of vaults not associated with their positions as the account status check is executed for these operations.  Consider redesigning the logic of managing vaults in a way that allows for the execution of actions on vaults not associated with the user's position. Alternatively, consider thoroughly documenting this behavior.  Update: Resolved. The Euler team stated:  We acknowledge the issue. When a user enables a vault as a controller for their account, presumably in order to take out a loan, they accept that their access to the account will be limited by the arbitrary rules encoded in the controller.  EVaults are implemented to primarily monitor collaterals they are explicitly configured to support, but if the account is unhealthy, a user should accept, as part of the contract with the controller, that any deposit they have in their account may be withheld.  Although such deposits do not influence the health score of the position, they may nonetheless be withdrawn by the user in a batch and sold for a recognized collateral, or the liability asset, to bring the account back to health. We have improved the documentation to emphasize this behavior to the users: https://docs.euler.finance/euler-vault-kit-white-paper/#non-collateral-deposits", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#unhealthy-position-locks-collateral-that-is-not-recognizable-by-the-controller", "labels": ["OpenZeppelin"]}, {"title": "Arbitrary unitOfAccount Asset Could Cause Liquidations or Erroneous Value Conversions", "body": "The Liquidation contract implements the functionality to calculate and liquidate debt positions a user might have. To do so, each vault proxy defines at deployment the unitOfAccount asset to be used as the reference. This allows converting two different assets (of supply and borrow) against a third asset to get the value of such positions.  However, the selection of this third asset is arbitrary and meant to be done by the Vault's admin when creating the new vault which, depending on the selection, might have a real impact on the liquidity or the liability of the positions. In particular:  Assets that might have a popular adoption in the market could get hacked, lose their peg (in the case of stablecoins), or face unexpected behavior that could end up resulting in strong price changes. If these changes ever come closer to zero, the precision could affect the calculations of the protocol, which would translate into wrong conversions between assets and shares, an imprecise health score on accounts, and a higher risk of positions' liquidations (even if in reality those are properly backed with collateral in real value terms).  The asset used might act as a wrapper for another asset or be a token that has malicious unknown behavior. In such a case, if this asset is used to carry out an underlying attack, or if its intrinsic value drops on purpose to leverage the price pair (e.g., the LP token of a protocol is used, but its behavior can drain the pool, changing its price) then the Vaults attached to that asset will again be subject to the value calculation effect.  Since the unitOfAccount asset is not meant to be replaced after the Vault's creation, there is no mitigation for affected vaults to allow positions to migrate unaffected once the unitOfAccount asset starts showing the price fluctuations. Moreover, contracts such as the BaseProductLine and the Core contracts do not perform any checks on the parameters then parsed to the GenericFactory contract.  Consider only allowing the usage of trusted and backed-by-industry tokens as the reference token and allowing the protocol to freeze operations and change it if a vault suffers from its effects.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. We agree that the choice of the unitOfAccount asset is a crucial security decision, but we think it is a part of the risk management framework and not something that should be enforced in the code. We also agree with the recommendation to only allow trusted tokens as reference assets, but think this filtering should happen at a different level than the vault code, which is un-opinionated and is built on purpose to accept a wide range of configurations. As for making the unit of account configurable, we expect only the most stable assets to pass through the aforementioned filters, in which case the gas costs of reading the configuration from storage, in every operation involving debt, would not be justified.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#arbitrary-unitofaccount-asset-could-cause-liquidations-or-erroneous-value-conversions", "labels": ["OpenZeppelin"]}, {"title": "Lack of Incentives to Liquidate Small Positions", "body": "There are currently no checks in place to regulate the size of the collateral that users can utilize to open positions. Consequently, users might open positions with collateral that is too small to be profitably liquidated in different vaults. Given the complex architecture and substantial gas costs associated with liquidation, these small positions may never be liquidated, leading to ongoing interest accumulation.  Consider implementing a minimum collateral deposit requirement. This would ensure that the collateral supporting the position maintains sufficient value to incentivize liquidation and overcome the gas cost of such a process.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. We acknowledge that there exists a risk of the vault holding small bad debt positions which are not profitable to liquidate. However, we think that the current code is sufficiently prepared to handle the issue.  Firstly, the problem of small positions has been discussed extensively in public, but so far it has not been confirmed to be an issue in practice. Our own experience from V1 confirms this. While we have definitely seen small debt positions which were not picked up by the liquidators, their overall impact on the lending pools was negligible.  Secondly, the recommended solution - minimum collateral deposit - can already be mostly enforced with a use of hooks. In the open EVC-EVK architecture, it would make more sense to enforce a minimum limit on the liability rather than collateral deposited, and it could be achieved by hooking operations which manipulate debt in conjunction with checkVaultStatus.  Lastly, with debt socialization, the vaults governor may be incentivized to liquidate the small positions at a loss in order to take the bad debt off the books for the benefit of the vault and its attractiveness to the users.  Low Severity", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#lack-of-incentives-to-liquidate-small-positions", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Event Emission", "body": "logBorrowChange function is expected to emit accurate events based on both the previously owed amount and the currently owed amount. However, within the  increaseBorrow,  decreaseBorrow, and  transferBorrow functions, the  logBorrowChange function is triggered with the value of  Consider passing the value of the owed amount after considering interest as the prevOwed parameter. This will help improve the readability of the logs for both users and off-chain systems.  Update: Resolved in pull request #160. The Euler team stated:  The fix consists of adding the InterestAccrued event which ensures that the Borrow and Repay events are always emitted in line with the function the user called, and that the amounts of the borrows/repays are included explicitly in the logs.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#incorrect-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Depositors Can Avoid Participating in Debt Socialization", "body": "The liquidate function implements logic for debt socialization when there is no more collateral to liquidate. Without delay in exiting positions, lenders can avoid participating in debt socialization by front running liquidation and withdrawing assets.  Consider redesigning the mechanism to ensure that lenders cannot evade participating in debt socialization, either by implementing delayed withdrawals or by incentivizing participation through a reward system that can be implemented using a balance tracker hook.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge this issue. In our view, the largest area of concern is collusion between liquidators and major active depositors: If liquidators were to give/sell advance notice of a liquidation, opportunistic depositors could withdraw beforehand and the remaining passive depositors would take unfairly large haircuts on their deposits. This threat is specifically described in our whitepaper and we have decided to accept the risk.  Vault creators who do not wish to accept this risk can enable the CFG_DONT_SOCIALIZE_DEBT flag which will mitigate this issue. Although in this case, an alternative strategy of handling bad debt should be designed. Finally, in the future, a custom hook contract could be developed that enforces a withdrawal delay, as suggested.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#depositors-can-avoid-participating-in-debt-socialization", "labels": ["OpenZeppelin"]}, {"title": "Debt Socialization Can Be Prevented", "body": "The current implementation of the liquidation process checks at the end of the liquidation process if the entire debt has been repaid, and if not, whether there is any remaining collateral that can be liquidated. If there is no more collateral to liquidate, the debt might be socialized, depending on the configuration.  However, the issue arises in the checkNoCollateral function responsible for checking if there is any collateral left. It iterates over the collateral and checks the balance for each. If the balance is greater than 0, it assumes there is still collateral to liquidate, thereby preventing the debt from being subject to liquidation. This creates a scenario where any violator who owns just 1 share of the recognized collateral can prevent debt socialization. Consequently, bad debt can continue accruing interest and worsen the situation.  Consider redesigning the debt socialization logic to ensure that the debt is correctly socialized, even in scenarios where just some dust of the collateral is present.  Update: Resolved. The Euler team stated:  We acknowledge the issue. Since the EVC enforces a limit on the number of collateral assets (and vaults can enforce a lower limit via hooks), somebody who wishes to socialise debt can construct a batch transaction that atomically liquidates each collateral asset without running into significant gas costs: Most of the gas costs will be amortised since storage is warmed by the first liquidation. This method can be used to socialise the debt of an active violator who front-runs 1 wei deposits.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#debt-socialization-can-be-prevented", "labels": ["OpenZeppelin"]}, {"title": "Collateral With No Value Can Be Claimed Through Liquidation", "body": "The liquidate function allows for the claiming of collateral that, according to the configured price oracle, holds no value. Liquidation plays a crucial role in maintaining the stability and solvency of DeFi lending protocols by ensuring that lenders are compensated in the event of borrower default and that the system remains collateralized. However, the liquidator's ability to claim the violator's collateral even when it holds no value does not align with the logic of the liquidation process.  Consider removing the ability to claim the violator's collateral when the price oracle returns zero as its value.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. We agree that removing the collateral without a value without reducing debt does not, on its own, align with the basic liquidation logic, which is to reward the collateral to the liquidator in order to reduce debt.  However, when debt socialization is taken into account, removing worthless collateral from the violators account frees up the bad debt to be removed from the system. In that sense, the behavior does align with the liquidation logic, which is to remove collateral in order to remove debt.  Note that the collateral may be worthless not only because the asset is literally worth nothing according to the oracles, which would be a very unlikely edge-case, but also because the oracle may respond with a zero amountOut when the collateral amount is so small that it is not representable in the reference asset. In the latter case, which is much more likely to occur, removing the dust collateral would be the only way to socialize the bad debt.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#collateral-with-no-value-can-be-claimed-through-liquidation", "labels": ["OpenZeppelin"]}, {"title": "LTV Duality Could Prevent Under-Collateralized Debt Mitigations", "body": "Each vault configures the LTV of each acceptable collateral used for taking borrows backed by them. To reduce the pressure when the admin reduces the LTV for a collateral, which could end up in massive liquidations on positions backed by that collateral, the LTVConfig library uses a ramp between the old value and the target value. However, if a user has two accounts and wants to temporarily reduce the liquidity pressure while the ramp is still operational, the protocol will not allow it.  Let us consider the following scenario:  originalLTV = 80  targetLTV = 50  rampDuration = 1 week  accountA_breakEven = 75  accountB_breakEven = 55  checkLiquidity function which uses the  BORROWING type for getting the LTV of the collateral. This means that all of its valuation will use the  Even though the opposite direction of the debt transfer might not be allowed (compromising accounts with more burden), reducing the pressure on the ones that are closer to the liquidation stage will allow the owner to have more time to find more collateral and have enough for when the ramp ends.  Consider using the LTV ramp when dealing with operations of debt transfer without increasing the actual overall debt to allow users the mitigation of the possible under-collateralized position due to a reduction in the LTV.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. In the current architecture it is not possible to discern what action triggered the account status check, so it would be difficult to perform a special case pullDebt during a ramp. While the ramp mechanism goes a long way in preventing user losses in events of LTV decreases, we acknowledge that in the specific edge-case situation described, the user's experience might be sub-optimal and note that instead of 'reducing pressure' the user would be encouraged to close the position.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#ltv-duality-could-prevent-under-collateralized-debt-mitigations", "labels": ["OpenZeppelin"]}, {"title": "Fees Should Be Distributed Before Change of the Fee Configuration", "body": "The convertFees function facilitates the distribution of accumulated fees between the protocol and the governor. This distribution is determined by the protocol's fee configuration and the address of the governor receiver. Consequently, any alterations to the fee configuration or the governor receiver address will have a direct impact on the distribution of fees.  Consider triggering convertFees function prior to making any changes to the fee distribution configuration or adjusting the governor receiver address to ensure that the accumulated fees are distributed according to the previous configuration.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. The roles of the governor, the fee receiver, and the DAO are not expected to be adversarial towards each other. So, we expect them to not abuse the current fee distribution logic intentionally, but rather cooperate to make sure the interests are aligned.  In the event that any party feels that it may be abused by a change to the settings, they are free to call the convertFees function more frequently to lock in the fee distribution more granularly. On the technical side, while a change to governor receiver could be easily handled by the vault, it would be challenging to do the same for the protocols fee share, which is configured in a different contract.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#fees-should-be-distributed-before-change-of-the-fee-configuration", "labels": ["OpenZeppelin"]}, {"title": "Enum Elements Sorting Is Not Consistent", "body": "The LTVType.sol file defines the LTVType enum. However, the LTVConfig.sol file does also define the same LTVType enum with the caveat that the order of the elements is inverted. Even though the first file is not used by the protocol, a third-party project might use it as an import, in which case the enum would return the wrong index when queried for the LTV type.  In order to mitigate such integration issues, consider either removing the duplicated file or switching the order of the elements inside the enum to be consistent in all places.  Update: Resolved in pull request #138.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#enum-elements-sorting-is-not-consistent", "labels": ["OpenZeppelin"]}, {"title": "Internal Accounting Mechanism is Incompatible With Tokens That Charge Fees", "body": "The vault implementation uses an internal accounting mechanism to keep track of the assets inside the vault and the shares minted during operations such as deposits. However, the same mechanism does not support fee-on-transfer tokens such as Tether (USDT) (the most widely known asset with this feature). This means that in case this asset is used and its feature is turned on, the accounting mechanism will inform more supplied assets than it has, potentially jeopardizing the last users in converting the shares back to the underlying asset.  Consider documenting that these vaults are not meant to be used with such assets, or using the balances before and after the operation to parse the actual values moved into the protocol.  Update: Resolved. The Euler team stated:  The white paper already documents this fact.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#internal-accounting-mechanism-is-incompatible-with-tokens-that-charge-fees", "labels": ["OpenZeppelin"]}, {"title": "Missing Check if the Returned Value From Price Oracle Is Zero", "body": "The GenericFactory allows the deployment of a vault with any price oracle. This means that there might be vaults created with custom-built oracles that do not correctly check for the calculated value, which could be zero.  Consider validating the value received from price oracle functions such as getQuote and getQuotes in getLiabilityValue,getCollateralValue, and calculateMaxLiquidation functions to ensure that it is not equal to zero.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. Zero values returned from the oracle calls do not signify an error. In the IPriceOracle interface, for the specified amountIn, the returned amountOut could be zero when either the base token is actually worthless or the value in quote token is not representable, both cases are valid. It is the vaults governors responsibility to properly select and configure the oracle. The vault itself has no means to verify the oracles suitability on-chain.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#missing-check-if-the-returned-value-from-price-oracle-is-zero", "labels": ["OpenZeppelin"]}, {"title": "Mismatch Between Documentation and Implementation", "body": "The NatSpec comment in the IEVault interface indicates that the list can contain duplicates. However, in the code, each element in the array is pushed when the initialized flag from the LTVConfig struct is down, and there is no mechanism provided to reset it back to false, even after calling the clearLTV function.  To avoid potential integration issues for other protocols, it is advisable to update the documentation to accurately reflect the current behavior.  Update: Resolved in pull request #139.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#mismatch-between-documentation-and-implementation", "labels": ["OpenZeppelin"]}, {"title": "Code-in-Address Does Not Guarantee Compatibility", "body": "In a few cases, the protocol checks if an address possesses code as a validation before proceeding with the assignment. However, this does not guarantee that it could be another contract implementing a totally different logic. In particular:  The initialize function from the Initialize contract module has code in what is supposed to be the Vault's underlying asset. However, it does not necessarily mean it is a compatible ERC-20 token.  The setHookConfig function does not verify if the newHookTarget implements the expected methods and complies with the rest of the hooks.  Consider using an introspection standard on the protocol-complementary contracts that interact with the Vaults, and take into consideration that addresses with code added as assets might not have a compliant ERC-20 token behind them.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. We acknowledge that checking for the existence of code at an address does not guarantee that the contract conforms to the required interface. The checks are not intended to provide guarantees, they are performed as a basic validation, making sure the user did not make an obvious mistake.  The check is a small improvement over a common practice to check for the zero address. We do not see a need to use introspection standards, which themselves do not provide strong guarantees about a contracts interface or implemented behavior. If the complementary contract does not implement the required functions, the vault will simply not function.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#code-in-address-does-not-guarantee-compatibility", "labels": ["OpenZeppelin"]}, {"title": "Unhandled Call Output", "body": "The BalanceUtils contract implements methods to handle share balances and allowances. When balances are changed, the tryBalanceTrackerHook function is called which makes an external call to the BalanceTracker contract.  However, the function returns an unhandled success output which is also not being handled in the methods that use it. Even though the name implies that it might be possible to have a non-successful call and continue with the execution, there is no explicit handling mechanism to catch the situation and inform the user or the protocol.  Consider handling such output in each function that makes use of the tryBalanceTrackerHook function, at least for logging the failed hook call so users can be aware of it.  Update: Resolved in pull request #140. The Euler team stated:  We have decided to not attempt to handle failed calls to the balance tracker contract. Instead, we will be using Certoras formal verification tools to prove that the balance tracker implementation we will be using will not revert.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#unhandled-call-output", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are multiple code instances that do not have docstrings:  The entire BeaconProxy contract in BeaconProxy.sol  The onFlashLoan function in Borrowing.sol  The entire DToken contract in DToken.sol  The entire Dispatch contract in Dispatch.sol  The entire EVault contract in EVault.sol  The IComponent interface and the entire GenericFactory contract in GenericFactory.sol  The events in Governance contract in Governance.sol  The IIRM interface in IIRM.sol  The entire IPermit2 interface in IPermit2.sol  The entire IPriceOracle interface in IPriceOracle.sol  The IProtocolConfig interface in IProtocolConfig.sol  The entire IRMLinearKink contract in IRMLinearKink.sol  The events defined in ProtocolConfig contract in ProtocolConfig.sol  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #149.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "Throughout the codebase, there are several instances of incomplete docstrings:  The interfaces defined in IEVault.sol are utilizing docstrings. However, not all functions are completely documented, lacking documentation for parameters and return values.  The function declared in the IProtocolConfig interface does not document all parameters of the functions.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of a contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #152.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Missing Input Validation", "body": "Throughout the codebase, there are multiple instances of missing input validation:  Missing zero address check for the admin_ and feeReceiver_ parameters in ProtocolConfig's contract constructor.  Missing zero address check for the admin parameter in GenericFactory's contract constructor.  Consider implementing input validation for the listed instances to prevent unexpected behavior.  Update: Resolved in pull request #142.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#missing-input-validation", "labels": ["OpenZeppelin"]}, {"title": "Floating Pragma", "body": "Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled. Throughout the codebase, there are multiple floating pragma directives of solidity ^0.8.0.  Consider using fixed pragma directives.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. We consider the Solidity pragma to specify the language version that the code was written for and its purpose is not to enforce a minimum compiler. As the contracts are meant to be a reusable kit, we prefer to leave the pragma at the lowest version that we expect this code to compile against. The compiler version will be chosen and locked in when the contracts are deployed, and we of course recommend to use the latest compiler version available at the time.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#floating-pragma", "labels": ["OpenZeppelin"]}, {"title": "Missing Named Parameters in Mappings", "body": "Since Solidity 0.8.18, developers can utilize named parameters in mappings. This means mappings can take the form of mapping(KeyType KeyName? => ValueType ValueName?). This updated syntax provides a more transparent representation of a mapping's purpose.  Throughout the codebase, there are multiple mappings without named parameters:  The proxyLookup state variable in the GenericFactory contract  The _interestFeeRanges state variable in the ProtocolConfig contract  The _protocolFeeConfig state variable in the ProtocolConfig contract  Consider adding named parameters to mappings in order to improve the readability and maintainability of the codebase.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. In the listed instances, the mapping targets are custom structs, whose names sufficiently specify the type of data the mapping holds. Naming the parameters would be redundant in these cases.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#missing-named-parameters-in-mappings", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "Consider addressing the following typographical errors:  In ProtocolConfig.sol:  The parameter in the SetFeeConfigSetting event should be vault not ault.  In the NatSpec comment, it should be interest not intereset.  In Events.sol:  In the NatSpec comment for the repayAssets param, it should be transferred instead of transfered.  In the NatSpec comment for the yieldBalance param, it should be transferred instead of transfered .  In Vault.sol:  In the comment, it should be withheld not witheld.  In Cache.sol:  In the comment, there is confusing information about MarkeStorage.  Update: Resolved in pull request #143.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease code clarity and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity file or when inheritance chains are long.  Throughout the codebase, global imports are being used:  The series of imports in Types.sol  The import of Types in AssetTransfers.sol, BalanceUtils.sol, Base.sol, BorrowUtils.sol, Borrowing.sol, Cache.sol, Governance.sol, Initialize.sol, LTVUtils.sol, Liquidation.sol, LiquidityUtils, RiskManager.sol, Token.sol, and Vault.sol  The import of Constants in Assets.sol, ConfigAmount.sol, Dispatch.sol, EVCClient.sol, Initialize.sol, Owed.sol, and ProxyUtils.sol  The import of IIRM in IRMLinearKink.sol  The import of IProtocolConfig in ProtocolConfig.sol  The import of Errors in RevertBytes.sol  Following the principle that clearer code is better code, consider using the named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. While we agree that named imports are generally advised, we believe that in certain cases, importing all of the contents of the file is more readable and concise. We believe that for the listed instances.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Cast", "body": "Within the EVCClient contract, the IEVC(evc) cast is unnecessary.  To improve the overall clarity, intent, and readability of the codebase, consider removing unnecessary casts.  Update: Resolved in pull request #144.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#unnecessary-cast", "labels": ["OpenZeppelin"]}, {"title": "Use Custom Error Parameters", "body": "Throughout the codebase, custom errors have been used to inform where an assertion or condition has not been met. However, none of the implemented custom errors use parameters. Being able to pass critical information to these parameters (such as addresses, values, or other criteria) provides a significant advantage when debugging and examining the details of a reverted call.  To add more detail to the failing transactions, consider using parameters alongside the custom errors.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. In our opinion, in the majority of errors in the codebase, adding parameters would not bring much benefit and we opted for a simple error pattern. Note that there is one exception: in SafeERC20Lib, the E_TransferFromFailed includes errors from both transfer attempts, which could be useful for UIs.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#use-custom-error-parameters", "labels": ["OpenZeppelin"]}, {"title": "Unsafe ABI Encoding", "body": "It is not an uncommon practice to use abi.encodeWithSignature or abi.encodeWithSelector to generate calldata for a low-level call. However, the first option is not typo-safe and the second option is not type-safe. The result is that both of these methods are error-prone and should be considered unsafe.  Within SafeERC20Lib.sol, there are multiples uses of unsafe ABI encodings:  The use of abi.encodeWithSelector in trySafeTransferFrom function  The use of abi.encodeWithSelector in safeTransfer function  Consider replacing all the occurrences of unsafe ABI encodings with abi.encodeCall, which checks whether the supplied values actually match the types expected by the called function and also avoids errors caused by typos.  Update: Resolved in pull request #145.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#unsafe-abi-encoding", "labels": ["OpenZeppelin"]}, {"title": "State Variable Visibility Not Explicitly Declared", "body": "Throughout the codebase, there are state variables that lack an explicitly declared visibility:  The protocolConfig, balanceTracker, and permit2 variables in Base.sol  The BEACON_SLOT, IMPLEMENTATION_SELECTOR, MAX_TRAILING_DATA_LENGTH, beacon, metadataLength, metadata0, metadata1, metadata2, and metadata3 variables in BeaconProxy.sol  The VIRTUAL_DEPOSIT_AMOUNT variable in ConversionHelpers.sol  The evc variable in EVCClient.sol  The REENTRANCYLOCK__UNLOCKED, REENTRANCYLOCK__LOCKED, MAX_PROTOCOL_FEE_SHARE, GUARANTEED_INTEREST_FEE_MIN, and GUARANTEED_INTEREST_FEE_MAX variables in Governance.sol  The INITIAL_INTEREST_ACCUMULATOR and DEFAULT_INTEREST_FEE variables in Initialize.sol  The MAXIMUM_LIQUIDATION_DISCOUNT variable in Liquidation.sol  For clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #146.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for their maintainers to contact the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are no contracts that specify a security contact.  Consider adding a NatSpec comment containing a security contact above each contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #147.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Magic Numbers", "body": "Throughout the codebase, there are instances where explicit values are used directly in arithmetic operations:  1e4 in the ConfigAmountLib library  1e4 in the Governance contract  1e18 in the Liquidation contract  1e27 in the Cache contract  In order to improve the readability of the codebase, consider using a constant to define such values and document their purpose.  Update: Partially resolved in pull request #148. The Euler team stated:  Fixed for 1e4, acknowledged for 1e18 and 1e27.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#magic-numbers", "labels": ["OpenZeppelin"]}, {"title": "Overflow in setOwed of UserStorage Library", "body": "The UserStorage library tries to fit a uint144-sized value into a field of size 2**143, leading to an overflow. While the protocol handles the necessary checks outside the library, the library itself remains vulnerable to overflow.  Consider incorporating essential checks within the UserStorage library to ensure its safe standalone usage.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. The UserStorageLib is coupled with the Owed type, not with its underlying uint144. One of the purposes of the Owed type is to make sure that the custom data size is enforced (2 ** 143).", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#overflow-in-setowed-of-userstorage-library", "labels": ["OpenZeppelin"]}, {"title": "Liquidators' Yield Might Be Zero", "body": "In the Liquidation contract module, the calculation done for getting the yield when repaying a certain amount might round the yield received by the liquidator down to zero. This can happen when the desiredRepay value is rather small compared to the maxRepay value and the conversion between both assets is not enough.  Even though there is a check against the minYieldBalance value to receive, the liquidator might default such input to zero. As such, the liquidator would end up repaying some debt and receiving nothing.  Consider rounding up the yield to be repaid to the liquidator during such an operation. This will help prevent such a scenario from happening in edge conditions and would incentivize liquidations.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. For the sake of simplicity, we prefer to allow this edge case. As mentioned, minYieldBalance should be used by the liquidator. If they forget to set it, the proposed solution would provide them with a single unit of collateral, which most probably would not change much for the profitability of the liquidation.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#liquidators'-yield-might-be-zero", "labels": ["OpenZeppelin"]}, {"title": "Missing Functionality for Recovering Tokens", "body": "The Vault lacks functionality for recovering tokens that were accidentally sent to it. Since one way to deposit assets is to transfer tokens to the Vault and then call the skim function, it is expected that users might mistakenly transfer certain tokens to the wrong vault and then be unable to recover those tokens.  Consider implementing a sweepTokens function that would allow the recovery of tokens that are not the underlying asset for that vault.  Update: Acknowledged, not resolved. The Euler team stated:  We acknowledge the issue. The fact that the skim function exists does not mean that the users are encouraged to simply send the tokens into the vault. Even if they send the correct asset to the vault, but do not claim them immediately, they risk the assets being taken over by someone else, presumably a bot looking for mistakes like this. So, if they do make a mistake in the vault address, but otherwise follow the intended logic, the transaction would not be successful.  Sweep functions have been found to carry security risks of their own. One way other cosystems approach this issue is to make the sweep function only callable by an admin, but we expect most EVaults to be non-governed. If the sweep function were permissionless, then just a single bot looking for opportunities in all the existing EVaults could undermine its intended use.", "html_url": "https://blog.openzeppelin.com/euler-vault-kit-evk-audit#missing-functionality-for-recovering-tokens", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent State Root Hash", "body": "previous and  new shnarfs, as well as the  previous and  new state root hashes. However, the shnarfs and state roots are not validated to match each other. In particular, the parent state root hash  must match the correct record in the  the final state root hash. It should be noted that this chain of state root hashes does not have to correspond to the actual L2 state root hashes that are validated through the shnarfs. Moreover, incorrect state root hashes would also cause invalid  BlocksVerificationDone events.  Consider validating that the final state root hash is consistent with the finalized shnarf.  Update: Resolved in pull request #3183.  Low Severity", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#inconsistent-state-root-hash", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Deprecation", "body": "The _messageSender contract variable has been deprecated but it is still being used in the old claimMessage function, and after this call, it is set to the DEFAULT_SENDER_ADDRESS.  Consider completing the deprecation as well as removing DEFAULT_SENDER_ADDRESS in favor of DEFAULT_MESSAGE_SENDER_TRANSIENT_VALUE.  Update: Resolved in pull request #3174.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#incomplete-deprecation", "labels": ["OpenZeppelin"]}, {"title": "Magic Numbers", "body": "The _computePublicInput function extracts several fields from a FinalizationDataV2 struct using hard-coded numeric offsets.  For code clarity, consider defining named offset constants next to the struct so they can be validated directly.  Update: Resolved. This is not an issue. The Linea team stated:  As the interface does not support constants, additional comments with expected struct parameter offsets were added to the public input computation function.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#magic-numbers", "labels": ["OpenZeppelin"]}, {"title": "Mutable Submission Record", "body": "In the submitDataAsCalldata function, duplicate submissions are prevented. However, a caller can reuse previous data corresponding to a known shnarf, but provide a different final block number in order to overwrite a previous submission.  Instead of strictly preventing duplicates, consider updating the check to prevent overwriting any non-zero record, such as in submitBlobs, to ensure the immutability of submitted data.  Update: Resolved in pull request #3175.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#mutable-submission-record", "labels": ["OpenZeppelin"]}, {"title": "Non-Standard Storage Locations", "body": "The codebase includes two pseudorandom storage locations (1, 2) specified as direct keccak256 outputs. Although these are used for transient storage and cannot overwrite existing storage records, address collisions could still cause unnecessary confusion.  Consider using the ERC-1967 mechanism to choose these locations.  Update: Resolved in pull request #3174.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#non-standard-storage-locations", "labels": ["OpenZeppelin"]}, {"title": "Unused Parameters", "body": "Consider removing the following unused parameters to improve code clarity and save gas:  The dataParentHash parameter in the SubmissionData struct  The dataParentHash parameter in the SupportingSubmissionData struct  The firstBlockInData parameter in the StoredSubmissionData struct  The finalDataHash parameter in the FinalizationDataV2 struct  Update: Resolved in pull request #3177 and pull request #3183.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#unused-parameters", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Computation", "body": "submitBlobs function or the  submitDataAsCalldata function. In both functions, the caller is required to pass in a  here and  here to compute the claimed parent shnarf. However, as the parent information is user-provided, and the user already provides the  SubmissionData and  SupportingSubmissionData structs, this computation is unnecessary and provides no additional security guarantees.  Consider removing the ParentShnarfData as a parameter to the submitBlobs and submitDataAsCalldata functions and using the parentShnarf field instead.  Update: Resolved in pull request #3177.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#unnecessary-computation", "labels": ["OpenZeppelin"]}, {"title": "Grammatical Error", "body": "The submitBlobs function has a grammatically incorrect clause, stating \"the intermediate are not stored\".  Consider correcting the above incorrect comment to improve the readability of the codebase.  Update: Resolved in pull request #3176.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#grammatical-error", "labels": ["OpenZeppelin"]}, {"title": "Redundant Check", "body": "In the submitDataAsCalldata function, there are multiple checks to ensure the consistency of the passed-in data, which is essential for the protocol. However, this validation is redundant as it has already been checked inside the _validateSubmissionData function.  Consider removing this redundant check to avoid code duplication and to reduce gas costs.  Update: Resolved in pull request #3177.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#redundant-check", "labels": ["OpenZeppelin"]}, {"title": "Client Reported", "body": "Client Reported", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Token Bridge Updates", "body": "After the audit was completed, the Linea team shared the following issues and optimizations reported by Cyfrin relating to the TokenBridge contract.  The _safeDecimal function defaults to 18 if the decimals cannot be retrieved. However, this could lead to an inconsistency between the L1 and L2 tokens. Moreover, ERC-721 tokens can only be bridged in one direction. The function should revert instead.  The setCustomContract function can override an existing nativeToBridgedToken record.  The removeReserved function should emit an event to facilitate off-chain processing.  The bridgeTokenWithPermit function modifiers are redundant because they are already included in the bridgeToken invocation.  The nativeToken variable is assigned but not used.  The sourceChainId record in the bridgeToken and removeReserved functions could be assigned to a local variable to avoid multiple storage reads of the same value.  This validation could reverse the two conditions so the more common case fails first.  Instead of assigning to the bridgedMappingValue variable and then optionally copying the result to the nativeToken variable, the nativeToken could be used in both case (and possibly overwritten).  Update: Resolved in pull request #3249.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#token-bridge-updates", "labels": ["OpenZeppelin"]}, {"title": "Reinitializer Synchronization", "body": "The initializeParentShnarfsAndFinalizedState function uses reinitializer version 4, which is consistent with the current mainnet version 3. However, the Sepolia deployment already uses version 4. For simplicity, the codebase should set it to version 5 so that the same deployment is valid on both chains.  Update: Resolved in pull request #3249.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#reinitializer-synchronization", "labels": ["OpenZeppelin"]}, {"title": "Event processing incompatibility", "body": "Pull Request #36 updated the BridgingInitiated and BridgingFinalized events to index the recipient parameter instead of the amount parameter. However, this is not a backwards-compatible change with existing off-chain event processing functionality. Instead, the original interface should be restored and the new interface can be implemented with a new event.  Update: Resolved in pull request #3288.", "html_url": "https://blog.openzeppelin.com/linea-gas-optimizations-audit#event-processing-incompatibility", "labels": ["OpenZeppelin"]}, {"title": "Lack of Input Validation", "body": "constructor of the  the _delegate address is validated for zero address in the OAppCore contract, the  To prevent initializing these addresses to zero, consider adding proper checks.  Update: Resolved in pull request #28 at commit 8242004.", "html_url": "https://blog.openzeppelin.com/morpheus-mor-oft-token-audit#lack-of-input-validation", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Docstring", "body": "To improve the readability of the codebase, consider correcting the docstring above the IMOROFT interface, which states that the token is capped, however, this is not reflected in the implementation of the MOROFT contract.  Update: Resolved in pull request #28 at commit 95b4217.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/morpheus-mor-oft-token-audit#incorrect-docstring", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstring", "body": "The MOROFT contract does not have a contract definition and none of its functions have docstrings.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Since the docstrings are present in the IMOROFT contract, this can be achieved by using the @inheritdoc tag as mentioned in the Ethereum Natural Specification Format (NatSpec).  Additionally, the MOROFT contract allows only the minter_ address to mint the tokens. Consider documenting this in the docstring above the mint function.  Update: Resolved in pull request #32 at commit 52c69c1.", "html_url": "https://blog.openzeppelin.com/morpheus-mor-oft-token-audit#missing-docstring", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  The MOROFT contract does not have a security contact.  Consider adding a NatSpec comment containing a security contact on top of the contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #29 at commit 8d8e771.", "html_url": "https://blog.openzeppelin.com/morpheus-mor-oft-token-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "This classification is applied when the issue\u2019s impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.", "body": "This classification is applied when the issue\u2019s impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#this-classification-is-applied-when-the-issue\u2019s-impact-is-catastrophic,-threatening-extensive-damage-to-the-client's-reputation-and/or-causing-severe-financial-loss-to-the-client-or-users.-the-likelihood-of-exploitation-can-be-high,-warranting-a-swift-response.-critical-issues-typically-involve-significant-risks-such-as-the-permanent-loss-or-locking-of-a-large-volume-of-users'-sensitive-assets-or-the-failure-of-core-system-functionalities-without-viable-mitigations.-these-issues-demand-immediate-attention-due-to-their-potential-to-compromise-system-integrity-or-user-trust-significantly.", "labels": ["OpenZeppelin"]}, {"title": "High Severity", "body": "High Severity", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#high-severity", "labels": ["OpenZeppelin"]}, {"title": "These issues are characterized by the potential to substantially impact the client\u2019s reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.", "body": "These issues are characterized by the potential to substantially impact the client\u2019s reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#these-issues-are-characterized-by-the-potential-to-substantially-impact-the-client\u2019s-reputation-and/or-result-in-considerable-financial-losses.-the-likelihood-of-exploitation-is-significant,-warranting-a-swift-response.-such-issues-might-include-temporary-loss-or-locking-of-a-significant-number-of-users'-sensitive-assets-or-disruptions-to-critical-system-functionalities,-albeit-with-potential,-yet-limited,-mitigations-available.-the-emphasis-is-on-the-significant-but-not-always-catastrophic-effects-on-system-operation-or-asset-security,-necessitating-prompt-and-effective-remediation.", "labels": ["OpenZeppelin"]}, {"title": "Full Deleverage Functionality Can Be Permanently Bricked", "body": "In the seaportCallback4878572495 function within the SeaportDeleverage contract, there is a requirement that the BASE token balance of the contract is 0 after a full deleverage.  However, this will always revert if a user has independently transferred any amount of BASE tokens into the SeaportDeleverage contract. Since there is no way to transfer the tokens out of the contract, a single transfer will permanently brick the contract.  Consider removing this check, or modifying it to instead check that the token balance of the contract has not changed since the beginning of the execution flow. Alternatively, consider either modifying the logic to transfer all unneeded BASE tokens to the user, or implementing a \"rescue\" function to remove stranded BASE tokens.  Update: Resolved in pull request #3. The sanity check was removed to prevent bricking of the contract.  Low Severity  Incomplete Docstrings  Throughout the codebase there are several parts that have incomplete docstrings. For instance:  The getPrice function in EzEthWstEthSpotOracle.sol the return value is partially documented  The flashswapAndMint function in UniswapFlashswapDirectMintHandlerWithDust.sol the deadline parameter is not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #76.  Floating Pragma  Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.  codebase there are multiple floating pragma directives. For instance, the files  IGemJoin.sol,  IIonPool.sol,  IUFDMHandler.sol,  IWhitelist.sol have the  solidity ^0.8.4 floating pragma directive.  Consider using a fixed pragma version.  Update: Acknowledged, not resolved. The Ion Protocol team stated:  The floating pragma was kept in order to allow other projects using a different Solidity version to use this repo as a submodule.  Inconsistent Use of ILK_INDEX in Seaport Leveraging Contracts  The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.  assumes an index of 0 in many places in both the  SeaportLeverage.sol uses ILK_INDEX. This inclusion of the  Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.  Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.  Notes & Additional Information  Incremental Update Could be Wrapped in an Unchecked Block  Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.  This applies to the following instances:  On line 157 of RenzoLibrary.sol  On line 249 of RenzoLibrary.sol  To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.  Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.  Unused Errors  Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #74 and pull request #5.  Unused Import  In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in p", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#full-deleverage-functionality-can-be-permanently-bricked", "labels": ["OpenZeppelin"]}, {"title": "In the seaportCallback4878572495 function within the SeaportDeleverage contract, there is a requirement that the BASE token balance of the contract is 0 after a full deleverage.", "body": "In the seaportCallback4878572495 function within the SeaportDeleverage contract, there is a requirement that the BASE token balance of the contract is 0 after a full deleverage.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#in-the-seaportcallback4878572495-function-within-the-seaportdeleverage-contract,-there-is-a-requirement-that-the-base-token-balance-of-the-contract-is-0-after-a-full-deleverage.", "labels": ["OpenZeppelin"]}, {"title": "However, this will always revert if a user has independently transferred any amount of BASE tokens into the SeaportDeleverage contract. Since there is no way to transfer the tokens out of the contract, a single transfer will permanently brick the contract.", "body": "However, this will always revert if a user has independently transferred any amount of BASE tokens into the SeaportDeleverage contract. Since there is no way to transfer the tokens out of the contract, a single transfer will permanently brick the contract.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#however,-this-will-always-revert-if-a-user-has-independently-transferred-any-amount-of-base-tokens-into-the-seaportdeleverage-contract.-since-there-is-no-way-to-transfer-the-tokens-out-of-the-contract,-a-single-transfer-will-permanently-brick-the-contract.", "labels": ["OpenZeppelin"]}, {"title": "Consider removing this check, or modifying it to instead check that the token balance of the contract has not changed since the beginning of the execution flow. Alternatively, consider either modifying the logic to transfer all unneeded BASE tokens to the user, or implementing a \"rescue\" function to remove stranded BASE tokens.", "body": "Consider removing this check, or modifying it to instead check that the token balance of the contract has not changed since the beginning of the execution flow. Alternatively, consider either modifying the logic to transfer all unneeded BASE tokens to the user, or implementing a \"rescue\" function to remove stranded BASE tokens.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-removing-this-check,-or-modifying-it-to-instead-check-that-the-token-balance-of-the-contract-has-not-changed-since-the-beginning-of-the-execution-flow.-alternatively,-consider-either-modifying-the-logic-to-transfer-all-unneeded-base-tokens-to-the-user,-or-implementing-a-\"rescue\"-function-to-remove-stranded-base-tokens.", "labels": ["OpenZeppelin"]}, {"title": "Update: Resolved in pull request #3. The sanity check was removed to prevent bricking of the contract.", "body": "Update: Resolved in pull request #3. The sanity check was removed to prevent bricking of the contract.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-resolved-in-pull-request-#3.-the-sanity-check-was-removed-to-prevent-bricking-of-the-contract.", "labels": ["OpenZeppelin"]}, {"title": "Low Severity", "body": "Low Severity", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#low-severity", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "Throughout the codebase there are several parts that have incomplete docstrings. For instance:  The getPrice function in EzEthWstEthSpotOracle.sol the return value is partially documented  The flashswapAndMint function in UniswapFlashswapDirectMintHandlerWithDust.sol the deadline parameter is not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #76.  Floating Pragma  Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.  codebase there are multiple floating pragma directives. For instance, the files  IGemJoin.sol,  IIonPool.sol,  IUFDMHandler.sol,  IWhitelist.sol have the  solidity ^0.8.4 floating pragma directive.  Consider using a fixed pragma version.  Update: Acknowledged, not resolved. The Ion Protocol team stated:  The floating pragma was kept in order to allow other projects using a different Solidity version to use this repo as a submodule.  Inconsistent Use of ILK_INDEX in Seaport Leveraging Contracts  The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.  assumes an index of 0 in many places in both the  SeaportLeverage.sol uses ILK_INDEX. This inclusion of the  Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.  Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.  Notes & Additional Information  Incremental Update Could be Wrapped in an Unchecked Block  Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.  This applies to the following instances:  On line 157 of RenzoLibrary.sol  On line 249 of RenzoLibrary.sol  To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.  Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.  Unused Errors  Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #74 and pull request #5.  Unused Import  In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.  Unchecked transfer/transferFrom Call  Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Errors  The following typographical", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Throughout the codebase there are several parts that have incomplete docstrings. For instance:", "body": "Throughout the codebase there are several parts that have incomplete docstrings. For instance:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#throughout-the-codebase-there-are-several-parts-that-have-incomplete-docstrings.-for-instance:", "labels": ["OpenZeppelin"]}, {"title": "The getPrice function in EzEthWstEthSpotOracle.sol the return value is partially documented", "body": "The getPrice function in EzEthWstEthSpotOracle.sol the return value is partially documented", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-getprice-function-in-ezethwstethspotoracle.sol-the-return-value-is-partially-documented", "labels": ["OpenZeppelin"]}, {"title": "The flashswapAndMint function in UniswapFlashswapDirectMintHandlerWithDust.sol the deadline parameter is not documented.", "body": "The flashswapAndMint function in UniswapFlashswapDirectMintHandlerWithDust.sol the deadline parameter is not documented.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-flashswapandmint-function-in-uniswapflashswapdirectminthandlerwithdust.sol-the-deadline-parameter-is-not-documented.", "labels": ["OpenZeppelin"]}, {"title": "Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).", "body": "Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-thoroughly-documenting-all-functions/events-(and-their-parameters-or-return-values)-that-are-part-of-any-contract's-public-api.-when-writing-docstrings,-consider-following-the-ethereum-natural-specification-format-(natspec).", "labels": ["OpenZeppelin"]}, {"title": "Update: Resolved in pull request #76.", "body": "Update: Resolved in pull request #76.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-resolved-in-pull-request-#76.", "labels": ["OpenZeppelin"]}, {"title": "Floating Pragma", "body": "Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.  codebase there are multiple floating pragma directives. For instance, the files  IGemJoin.sol,  IIonPool.sol,  IUFDMHandler.sol,  IWhitelist.sol have the  solidity ^0.8.4 floating pragma directive.  Consider using a fixed pragma version.  Update: Acknowledged, not resolved. The Ion Protocol team stated:  The floating pragma was kept in order to allow other projects using a different Solidity version to use this repo as a submodule.  Inconsistent Use of ILK_INDEX in Seaport Leveraging Contracts  The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.  assumes an index of 0 in many places in both the  SeaportLeverage.sol uses ILK_INDEX. This inclusion of the  Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.  Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.  Notes & Additional Information  Incremental Update Could be Wrapped in an Unchecked Block  Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.  This applies to the following instances:  On line 157 of RenzoLibrary.sol  On line 249 of RenzoLibrary.sol  To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.  Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.  Unused Errors  Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #74 and pull request #5.  Unused Import  In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.  Unchecked transfer/transferFrom Call  Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Errors  The following typographical errors have been identified:  On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".  On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"  Consider correcting the typos for better readability and a more professional codebase.  Update: Resolved in pull request #76 and pull request #5.  Conclusion  One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount s", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#floating-pragma", "labels": ["OpenZeppelin"]}, {"title": "Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.", "body": "Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#pragma-directives-should-be-fixed-to-clearly-identify-the-solidity-version-with-which-the-contracts-will-be-compiled.", "labels": ["OpenZeppelin"]}, {"title": "codebase there are multiple floating pragma directives. For instance, the files", "body": "codebase there are multiple floating pragma directives. For instance, the files", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#codebase-there-are-multiple-floating-pragma-directives.-for-instance,-the-files", "labels": ["OpenZeppelin"]}, {"title": "IGemJoin.sol,", "body": "IGemJoin.sol,", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#igemjoin.sol,", "labels": ["OpenZeppelin"]}, {"title": "IIonPool.sol,", "body": "IIonPool.sol,", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#iionpool.sol,", "labels": ["OpenZeppelin"]}, {"title": "IUFDMHandler.sol,", "body": "IUFDMHandler.sol,", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#iufdmhandler.sol,", "labels": ["OpenZeppelin"]}, {"title": "IWhitelist.sol have the", "body": "IWhitelist.sol have the", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#iwhitelist.sol-have-the", "labels": ["OpenZeppelin"]}, {"title": "solidity ^0.8.4 floating pragma directive.", "body": "solidity ^0.8.4 floating pragma directive.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#solidity-^0.8.4-floating-pragma-directive.", "labels": ["OpenZeppelin"]}, {"title": "Consider using a fixed pragma version.", "body": "Consider using a fixed pragma version.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-using-a-fixed-pragma-version.", "labels": ["OpenZeppelin"]}, {"title": "Update: Acknowledged, not resolved. The Ion Protocol team stated:", "body": "Update: Acknowledged, not resolved. The Ion Protocol team stated:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-acknowledged,-not-resolved.-the-ion-protocol-team-stated:", "labels": ["OpenZeppelin"]}, {"title": "The floating pragma was kept in order to allow other projects using a different Solidity version to use this repo as a submodule.", "body": "The floating pragma was kept in order to allow other projects using a different Solidity version to use this repo as a submodule.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-floating-pragma-was-kept-in-order-to-allow-other-projects-using-a-different-solidity-version-to-use-this-repo-as-a-submodule.", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Use of ILK_INDEX in Seaport Leveraging Contracts", "body": "The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.  assumes an index of 0 in many places in both the  SeaportLeverage.sol uses ILK_INDEX. This inclusion of the  Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.  Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.  Notes & Additional Information  Incremental Update Could be Wrapped in an Unchecked Block  Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.  This applies to the following instances:  On line 157 of RenzoLibrary.sol  On line 249 of RenzoLibrary.sol  To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.  Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.  Unused Errors  Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #74 and pull request #5.  Unused Import  In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.  Unchecked transfer/transferFrom Call  Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Errors  The following typographical errors have been identified:  On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".  On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"  Consider correcting the typos for better readability and a more professional codebase.  Update: Resolved in pull request #76 and pull request #5.  Conclusion  One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.  Appendix  Issue Classification  OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputati", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#inconsistent-use-of-ilk_index-in-seaport-leveraging-contracts", "labels": ["OpenZeppelin"]}, {"title": "The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.", "body": "The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-seaportdeleverage-contract-uses-an-immutable-ilk_index-which-is-set-in-the-constructor-of-the-inherited-seaportbase-contract.", "labels": ["OpenZeppelin"]}, {"title": "assumes an index of 0 in many places in both the", "body": "assumes an index of 0 in many places in both the", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#assumes-an-index-of-0-in-many-places-in-both-the", "labels": ["OpenZeppelin"]}, {"title": "SeaportLeverage.sol uses ILK_INDEX. This inclusion of the", "body": "SeaportLeverage.sol uses ILK_INDEX. This inclusion of the", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#seaportleverage.sol-uses-ilk_index.-this-inclusion-of-the", "labels": ["OpenZeppelin"]}, {"title": "Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.", "body": "Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-using-a-consistent-ilk-index-across-the-\"leverage\"-and-\"deleverage\"-contracts.", "labels": ["OpenZeppelin"]}, {"title": "Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.", "body": "Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-resolved-in-pull-request-#4.-the-seaportdeleverage-contract-was-modified-to-use-a-hardcoded-ilk_index-of-0.", "labels": ["OpenZeppelin"]}, {"title": "Notes & Additional Information", "body": "Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#notes-&-additional-information", "labels": ["OpenZeppelin"]}, {"title": "Incremental Update Could be Wrapped in an Unchecked Block", "body": "Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.  This applies to the following instances:  On line 157 of RenzoLibrary.sol  On line 249 of RenzoLibrary.sol  To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.  Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.  Unused Errors  Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #74 and pull request #5.  Unused Import  In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.  Unchecked transfer/transferFrom Call  Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Errors  The following typographical errors have been identified:  On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".  On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"  Consider correcting the typos for better readability and a more professional codebase.  Update: Resolved in pull request #76 and pull request #5.  Conclusion  One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.  Appendix  Issue Classification  OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.  High Severity  These issues are characterized by the potential to s", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#incremental-update-could-be-wrapped-in-an-unchecked-block", "labels": ["OpenZeppelin"]}, {"title": "Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.", "body": "Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#since-solidity-version-0.8.0,-any-arithmetic-operation-automatically-checks-for-over--and-underflows,-which-cost-gas.-since-it-is-highly-unlikely-that-a-positively-incrementing-variable-will-overflow-within-a-loop,-the-increment-could-be-wrapped-into-an-unchecked-block.", "labels": ["OpenZeppelin"]}, {"title": "This applies to the following instances:", "body": "This applies to the following instances:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#this-applies-to-the-following-instances:", "labels": ["OpenZeppelin"]}, {"title": "On line 157 of RenzoLibrary.sol", "body": "On line 157 of RenzoLibrary.sol", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#on-line-157-of-renzolibrary.sol", "labels": ["OpenZeppelin"]}, {"title": "On line 249 of RenzoLibrary.sol", "body": "On line 249 of RenzoLibrary.sol", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#on-line-249-of-renzolibrary.sol", "labels": ["OpenZeppelin"]}, {"title": "To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.", "body": "To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#to-improve-gas-consumption,-consider-wrapping-the-incremental-update-into-an-unchecked-block-to-save-the-gas-required-to-check-against-overflows.", "labels": ["OpenZeppelin"]}, {"title": "Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.", "body": "Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-resolved-in-pull-request-#74.-the-incremented-update-was-removed-in-an-unrelated-refactoring.", "labels": ["OpenZeppelin"]}, {"title": "Unused Errors", "body": "Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #74 and pull request #5.  Unused Import  In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.  Unchecked transfer/transferFrom Call  Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Errors  The following typographical errors have been identified:  On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".  On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"  Consider correcting the typos for better readability and a more professional codebase.  Update: Resolved in pull request #76 and pull request #5.  Conclusion  One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.  Appendix  Issue Classification  OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.  High Severity  These issues are characterized by the potential to substantially impact the clients reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.  Medium Severity  Issues classified as being of a medium severity can lead to a noticeable negative impact ", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#unused-errors", "labels": ["OpenZeppelin"]}, {"title": "Throughout the codebase, there are unused errors. For instance:", "body": "Throughout the codebase, there are unused errors. For instance:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#throughout-the-codebase,-there-are-unused-errors.-for-instance:", "labels": ["OpenZeppelin"]}, {"title": "The ZoneHashMustBeZero error in SeaportBase.sol.", "body": "The ZoneHashMustBeZero error in SeaportBase.sol.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-zonehashmustbezero-error-in-seaportbase.sol.", "labels": ["OpenZeppelin"]}, {"title": "The InvalidAmountIn error in RenzoLibrary.sol.", "body": "The InvalidAmountIn error in RenzoLibrary.sol.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-invalidamountin-error-in-renzolibrary.sol.", "labels": ["OpenZeppelin"]}, {"title": "To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.", "body": "To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#to-improve-the-overall-clarity,-intentionality,-and-readability-of-the-codebase,-consider-either-using-or-removing-any-currently-unused-errors.", "labels": ["OpenZeppelin"]}, {"title": "Update: Resolved in pull request #74 and pull request #5.", "body": "Update: Resolved in pull request #74 and pull request #5.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-resolved-in-pull-request-#74-and-pull-request-#5.", "labels": ["OpenZeppelin"]}, {"title": "Unused Import", "body": "In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.  Unchecked transfer/transferFrom Call  Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Errors  The following typographical errors have been identified:  On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".  On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"  Consider correcting the typos for better readability and a more professional codebase.  Update: Resolved in pull request #76 and pull request #5.  Conclusion  One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.  Appendix  Issue Classification  OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.  High Severity  These issues are characterized by the potential to substantially impact the clients reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.  Medium Severity  Issues classified as being of a medium severity can lead to a noticeable negative impact on the client's reputation and/or moderate financial losses. Such issues, if left unattended, have a moderate likelihood of being exploited or may cause unwanted side effects in the system. These issues are typically confined to a smaller subset of users' sensitive assets or might involve deviations from the specified system design that, while not directly financial in nature, co", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#unused-import", "labels": ["OpenZeppelin"]}, {"title": "In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.", "body": "In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#in-seaportdeleverage.sol,-the-import-of-iwhitelist.sol-is-unused-and-can-be-removed.", "labels": ["OpenZeppelin"]}, {"title": "Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.", "body": "Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-removing-unused-imports-to-improve-the-overall-clarity-and-readability-of-the-codebase.-alternatively,-if-it-is-intended-to-use-the-whitelist-within-seaportdeleverage.sol,-consider-implementing-it.", "labels": ["OpenZeppelin"]}, {"title": "Update: Resolved in pull request #5.", "body": "Update: Resolved in pull request #5.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-resolved-in-pull-request-#5.", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.  Unchecked transfer/transferFrom Call  Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Errors  The following typographical errors have been identified:  On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".  On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"  Consider correcting the typos for better readability and a more professional codebase.  Update: Resolved in pull request #76 and pull request #5.  Conclusion  One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.  Appendix  Issue Classification  OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.  High Severity  These issues are characterized by the potential to substantially impact the clients reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.  Medium Severity  Issues classified as being of a medium severity can lead to a noticeable negative impact on the client's reputation and/or moderate financial losses. Such issues, if left unattended, have a moderate likelihood of being exploited or may cause unwanted side effects in the system. These issues are typically confined to a smaller subset of users' sensitive assets or might involve deviations from the specified system design that, while not directly financial in nature, compromise system integrity or user experience. The focus here is on issues that pose a real but contained risk, warranting timely attention to prevent escalation.  Low Severity  Low-severity issues are those that have a low impact on the client's operations and/or reputation. These issues may represent minor risks or inefficiencies to the client's specific ", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#providing-a-specific-security-contact-(such-as-an-email-or-ens-name)-within-a-smart-contract-significantly-simplifies-the-process-for-individuals-to-communicate-if-they-identify-a-vulnerability-in-the-code.-this-practice-proves-beneficial-as-it-permits-the-code-owners-to-dictate-the-communication-channel-for-vulnerability-disclosure,-eliminating-the-risk-of-miscommunication-or-failure-to-report-due-to-lack-of-knowledge-on-how-to-do-so.-additionally,-if-the-contract-incorporates-third-party-libraries-and-a-bug-surfaces-in-these,-it-becomes-easier-for-the-maintainers-of-those-libraries-to-make-contact-with-the-appropriate-person-about-the-problem-and-provide-mitigation-instructions.", "labels": ["OpenZeppelin"]}, {"title": "Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.", "body": "Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-adding-a-natspec-comment-containing-a-security-contact-on-top-of-the-contracts-definition.-using-the-@custom:security-contact-convention-is-recommended-as-it-has-been-adopted-by-the-openzeppelin-wizard-and-the-ethereum-lists.", "labels": ["OpenZeppelin"]}, {"title": "Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.", "body": "Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-resolved-in-pull-request-#5-for-the-ion-seaport-repository-and-in-pull-request-#76-for-the-ion-protocol-repository.", "labels": ["OpenZeppelin"]}, {"title": "Unchecked transfer/transferFrom Call", "body": "Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Errors  The following typographical errors have been identified:  On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".  On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"  Consider correcting the typos for better readability and a more professional codebase.  Update: Resolved in pull request #76 and pull request #5.  Conclusion  One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.  Appendix  Issue Classification  OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.  High Severity  These issues are characterized by the potential to substantially impact the clients reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.  Medium Severity  Issues classified as being of a medium severity can lead to a noticeable negative impact on the client's reputation and/or moderate financial losses. Such issues, if left unattended, have a moderate likelihood of being exploited or may cause unwanted side effects in the system. These issues are typically confined to a smaller subset of users' sensitive assets or might involve deviations from the specified system design that, while not directly financial in nature, compromise system integrity or user experience. The focus here is on issues that pose a real but contained risk, warranting timely attention to prevent escalation.  Low Severity  Low-severity issues are those that have a low impact on the client's operations and/or reputation. These issues may represent minor risks or inefficiencies to the client's specific business model. They are identified as areas for improvement that, while not urgent, could enhance the security and quality of the codebase if addressed.  Notes & Additional Information Severity  This category is reserved for issues that, despite having a minimal impact, are still important to resolve. Addressing these issues contributes to the overall security posture and code quality improvement but does not require immediate action. It reflects a commitment to maintaining high standards and continuous improvement, even in areas that do not pose immediate risks.  Related Posts  ZK Stack VM1.5 Diff Audit  Smart contract Audit. We audited the change to the matter-labs/era-contracts repository between...  Security Audits  L2's  Solidity  Yul  Radiant Riz Audit  Smart contract audit. Audited the radiant-capital/riz repository originally at the v0.0.1-alpha...  Security Audits  Solidity  Across V3 and Oval Incremental Audit  smart contract audit. We audited the across-protocol/contracts repository at commit 95c4f92.  Security Audits  Solidit", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#unchecked-transfer/transferfrom-call", "labels": ["OpenZeppelin"]}, {"title": "Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.", "body": "Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#some-early-implementations-of-erc-20-tokens-would-return-false-instead-of-reverting-the-transaction-when-a-transfer-failed.-this-behavior-is-considered-unsafe-because-a-false-return-value-could-be-ignored-by-the-caller,-leading-to-unexpected-behavior.", "labels": ["OpenZeppelin"]}, {"title": "In SeaportDeleverage.sol, the transfer call is unchecked.", "body": "In SeaportDeleverage.sol, the transfer call is unchecked.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#in-seaportdeleverage.sol,-the-transfer-call-is-unchecked.", "labels": ["OpenZeppelin"]}, {"title": "Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.", "body": "Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-to-use-safeerc20-openzeppelin-library-to-perform-safe-token-transfers.-note-that-with-the-current-application,-only-eth-staking-derivatives-that-revert-on-transfer-are-being-called-with-transfer.-however,-in-the-case-that-the-code-is-modified-to-support-other-\"base\"-assets-in-the-future,-this-will-protect-against-unexpected-behavior-during-transfer-calls.", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors have been identified:  On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".  On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"  Consider correcting the typos for better readability and a more professional codebase.  Update: Resolved in pull request #76 and pull request #5.  Conclusion  One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.  Appendix  Issue Classification  OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.  High Severity  These issues are characterized by the potential to substantially impact the clients reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.  Medium Severity  Issues classified as being of a medium severity can lead to a noticeable negative impact on the client's reputation and/or moderate financial losses. Such issues, if left unattended, have a moderate likelihood of being exploited or may cause unwanted side effects in the system. These issues are typically confined to a smaller subset of users' sensitive assets or might involve deviations from the specified system design that, while not directly financial in nature, compromise system integrity or user experience. The focus here is on issues that pose a real but contained risk, warranting timely attention to prevent escalation.  Low Severity  Low-severity issues are those that have a low impact on the client's operations and/or reputation. These issues may represent minor risks or inefficiencies to the client's specific business model. They are identified as areas for improvement that, while not urgent, could enhance the security and quality of the codebase if addressed.  Notes & Additional Information Severity  This category is reserved for issues that, despite having a minimal impact, are still important to resolve. Addressing these issues contributes to the overall security posture and code quality improvement but does not require immediate action. It reflects a commitment to maintaining high standards and continuous improvement, even in areas that do not pose immediate risks.  Related Posts  ZK Stack VM1.5 Diff Audit  Smart contract Audit. We audited the change to the matter-labs/era-contracts repository between...  Security Audits  L2's  Solidity  Yul  Radiant Riz Audit  Smart contract audit. Audited the radiant-capital/riz repository originally at the v0.0.1-alpha...  Security Audits  Solidity  Across V3 and Oval Incremental Audit  smart contract audit. We audited the across-protocol/contracts repository at commit 95c4f92.  Security Audits  Solidit", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "The following typographical errors have been identified:", "body": "The following typographical errors have been identified:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-following-typographical-errors-have-been-identified:", "labels": ["OpenZeppelin"]}, {"title": "On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".", "body": "On Line 31 of UniswapFlashswapDirectMintHandlerWithDust, \"leverge\" should be \"leverage\".", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#on-line-31-of-uniswapflashswapdirectminthandlerwithdust,-\"leverge\"-should-be-\"leverage\".", "labels": ["OpenZeppelin"]}, {"title": "On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"", "body": "On Line 279 of SeaportDeleverage, \"to to\" should be \"to\"", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#on-line-279-of-seaportdeleverage,-\"to-to\"-should-be-\"to\"", "labels": ["OpenZeppelin"]}, {"title": "Consider correcting the typos for better readability and a more professional codebase.", "body": "Consider correcting the typos for better readability and a more professional codebase.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-correcting-the-typos-for-better-readability-and-a-more-professional-codebase.", "labels": ["OpenZeppelin"]}, {"title": "Update: Resolved in pull request #76 and pull request #5.", "body": "Update: Resolved in pull request #76 and pull request #5.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#update:-resolved-in-pull-request-#76-and-pull-request-#5.", "labels": ["OpenZeppelin"]}, {"title": "Conclusion", "body": "One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.  Appendix  Issue Classification  OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.  High Severity  These issues are characterized by the potential to substantially impact the clients reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.  Medium Severity  Issues classified as being of a medium severity can lead to a noticeable negative impact on the client's reputation and/or moderate financial losses. Such issues, if left unattended, have a moderate likelihood of being exploited or may cause unwanted side effects in the system. These issues are typically confined to a smaller subset of users' sensitive assets or might involve deviations from the specified system design that, while not directly financial in nature, compromise system integrity or user experience. The focus here is on issues that pose a real but contained risk, warranting timely attention to prevent escalation.  Low Severity  Low-severity issues are those that have a low impact on the client's operations and/or reputation. These issues may represent minor risks or inefficiencies to the client's specific business model. They are identified as areas for improvement that, while not urgent, could enhance the security and quality of the codebase if addressed.  Notes & Additional Information Severity  This category is reserved for issues that, despite having a minimal impact, are still important to resolve. Addressing these issues contributes to the overall security posture and code quality improvement but does not require immediate action. It reflects a commitment to maintaining high standards and continuous improvement, even in areas that do not pose immediate risks.  Related Posts  ZK Stack VM1.5 Diff Audit  Smart contract Audit. We audited the change to the matter-labs/era-contracts repository between...  Security Audits  L2's  Solidity  Yul  Radiant Riz Audit  Smart contract audit. Audited the radiant-capital/riz repository originally at the v0.0.1-alpha...  Security Audits  Solidity  Across V3 and Oval Incremental Audit  smart contract audit. We audited the across-protocol/contracts repository at commit 95c4f92.  Security Audits  Solidit", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#conclusion", "labels": ["OpenZeppelin"]}, {"title": "One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.", "body": "One high-severity vulnerability was found in the contracts which were quickly acknowledged by the Ion team. Both the ion-protocol and ion-seaport codebases were covered by unit and fuzz tests. The Renzo ETH contracts were designed to deposit the \"optimal\" amount such that no excess ETH is deposited for any amount of ezETH. We evaluated that Ion implemented this correctly. However, this optimised amount makes a very small difference compared to imperfect deposit amounts. The Ion team was very helpful in documenting and explaining the codebase and clarifying the system's design.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#one-high-severity-vulnerability-was-found-in-the-contracts-which-were-quickly-acknowledged-by-the-ion-team.-both-the-ion-protocol-and-ion-seaport-codebases-were-covered-by-unit-and-fuzz-tests.-the-renzo-eth-contracts-were-designed-to-deposit-the-\"optimal\"-amount-such-that-no-excess-eth-is-deposited-for-any-amount-of-ezeth.-we-evaluated-that-ion-implemented-this-correctly.-however,-this-optimised-amount-makes-a-very-small-difference-compared-to-imperfect-deposit-amounts.-the-ion-team-was-very-helpful-in-documenting-and-explaining-the-codebase-and-clarifying-the-system's-design.", "labels": ["OpenZeppelin"]}, {"title": "Appendix", "body": "Appendix", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#appendix", "labels": ["OpenZeppelin"]}, {"title": "Issue Classification", "body": "OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:  Critical  High  Medium  Low  Note/Information  Critical Severity  This classification is applied when the issues impact is catastrophic, threatening extensive damage to the client's reputation and/or causing severe financial loss to the client or users. The likelihood of exploitation can be high, warranting a swift response. Critical issues typically involve significant risks such as the permanent loss or locking of a large volume of users' sensitive assets or the failure of core system functionalities without viable mitigations. These issues demand immediate attention due to their potential to compromise system integrity or user trust significantly.  High Severity  These issues are characterized by the potential to substantially impact the clients reputation and/or result in considerable financial losses. The likelihood of exploitation is significant, warranting a swift response. Such issues might include temporary loss or locking of a significant number of users' sensitive assets or disruptions to critical system functionalities, albeit with potential, yet limited, mitigations available. The emphasis is on the significant but not always catastrophic effects on system operation or asset security, necessitating prompt and effective remediation.  Medium Severity  Issues classified as being of a medium severity can lead to a noticeable negative impact on the client's reputation and/or moderate financial losses. Such issues, if left unattended, have a moderate likelihood of being exploited or may cause unwanted side effects in the system. These issues are typically confined to a smaller subset of users' sensitive assets or might involve deviations from the specified system design that, while not directly financial in nature, compromise system integrity or user experience. The focus here is on issues that pose a real but contained risk, warranting timely attention to prevent escalation.  Low Severity  Low-severity issues are those that have a low impact on the client's operations and/or reputation. These issues may represent minor risks or inefficiencies to the client's specific business model. They are identified as areas for improvement that, while not urgent, could enhance the security and quality of the codebase if addressed.  Notes & Additional Information Severity  This category is reserved for issues that, despite having a minimal impact, are still important to resolve. Addressing these issues contributes to the overall security posture and code quality improvement but does not require immediate action. It reflects a commitment to maintaining high standards and continuous improvement, even in areas that do not pose immediate risks.  Related Posts  ZK Stack VM1.5 Diff Audit  Smart contract Audit. We audited the change to the matter-labs/era-contracts repository between...  Security Audits  L2's  Solidity  Yul  Radiant Riz Audit  Smart contract audit. Audited the radiant-capital/riz repository originally at the v0.0.1-alpha...  Security Audits  Solidity  Across V3 and Oval Incremental Audit  smart contract audit. We audited the across-protocol/contracts repository at commit 95c4f92.  Security Audits  Solidit", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#issue-classification", "labels": ["OpenZeppelin"]}, {"title": "OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:", "body": "OpenZeppelin classifies smart contract vulnerabilities on a 5-level scale:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#openzeppelin-classifies-smart-contract-vulnerabilities-on-a-5-level-scale:", "labels": ["OpenZeppelin"]}, {"title": "Critical", "body": "Critical", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#critical", "labels": ["OpenZeppelin"]}, {"title": "High", "body": "Severity  Full Deleverage Functionality Can Be Permanently Bricked  In the seaportCallback4878572495 function within the SeaportDeleverage contract, there is a requirement that the BASE token balance of the contract is 0 after a full deleverage.  However, this will always revert if a user has independently transferred any amount of BASE tokens into the SeaportDeleverage contract. Since there is no way to transfer the tokens out of the contract, a single transfer will permanently brick the contract.  Consider removing this check, or modifying it to instead check that the token balance of the contract has not changed since the beginning of the execution flow. Alternatively, consider either modifying the logic to transfer all unneeded BASE tokens to the user, or implementing a \"rescue\" function to remove stranded BASE tokens.  Update: Resolved in pull request #3. The sanity check was removed to prevent bricking of the contract.  Low Severity  Incomplete Docstrings  Throughout the codebase there are several parts that have incomplete docstrings. For instance:  The getPrice function in EzEthWstEthSpotOracle.sol the return value is partially documented  The flashswapAndMint function in UniswapFlashswapDirectMintHandlerWithDust.sol the deadline parameter is not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #76.  Floating Pragma  Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.  codebase there are multiple floating pragma directives. For instance, the files  IGemJoin.sol,  IIonPool.sol,  IUFDMHandler.sol,  IWhitelist.sol have the  solidity ^0.8.4 floating pragma directive.  Consider using a fixed pragma version.  Update: Acknowledged, not resolved. The Ion Protocol team stated:  The floating pragma was kept in order to allow other projects using a different Solidity version to use this repo as a submodule.  Inconsistent Use of ILK_INDEX in Seaport Leveraging Contracts  The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.  assumes an index of 0 in many places in both the  SeaportLeverage.sol uses ILK_INDEX. This inclusion of the  Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.  Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.  Notes & Additional Information  Incremental Update Could be Wrapped in an Unchecked Block  Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.  This applies to the following instances:  On line 157 of RenzoLibrary.sol  On line 249 of RenzoLibrary.sol  To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.  Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.  Unused Errors  Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #74 and pull request #5.  Unused Import  In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by th", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#high", "labels": ["OpenZeppelin"]}, {"title": "Medium", "body": "Medium", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#medium", "labels": ["OpenZeppelin"]}, {"title": "Low", "body": "Severity  Incomplete Docstrings  Throughout the codebase there are several parts that have incomplete docstrings. For instance:  The getPrice function in EzEthWstEthSpotOracle.sol the return value is partially documented  The flashswapAndMint function in UniswapFlashswapDirectMintHandlerWithDust.sol the deadline parameter is not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #76.  Floating Pragma  Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.  codebase there are multiple floating pragma directives. For instance, the files  IGemJoin.sol,  IIonPool.sol,  IUFDMHandler.sol,  IWhitelist.sol have the  solidity ^0.8.4 floating pragma directive.  Consider using a fixed pragma version.  Update: Acknowledged, not resolved. The Ion Protocol team stated:  The floating pragma was kept in order to allow other projects using a different Solidity version to use this repo as a submodule.  Inconsistent Use of ILK_INDEX in Seaport Leveraging Contracts  The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.  assumes an index of 0 in many places in both the  SeaportLeverage.sol uses ILK_INDEX. This inclusion of the  Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.  Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.  Notes & Additional Information  Incremental Update Could be Wrapped in an Unchecked Block  Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.  This applies to the following instances:  On line 157 of RenzoLibrary.sol  On line 249 of RenzoLibrary.sol  To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.  Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.  Unused Errors  Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  Update: Resolved in pull request #74 and pull request #5.  Unused Import  In SeaportDeleverage.sol, the import of IWhitelist.sol is unused and can be removed.  Consider removing unused imports to improve the overall clarity and readability of the codebase. Alternatively, if it is intended to use the whitelist within SeaportDeleverage.sol, consider implementing it.  Update: Resolved in pull request #5.  Lack of Security Contact  Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #5 for the ion-seaport repository and in pull request #76 for the ion-protocol repository.  Unchecked transfer/transferFrom Call  Some early implementations of ERC-20 tokens would return false instead of reverting the transaction when a transfer failed. This behavior is considered unsafe because a false return value could be ignored by the caller, leading to unexpected behavior.  In SeaportDeleverage.sol, the transfer call is unchecked.  Consider to use SafeERC20 OpenZeppelin library to perform safe token transfers. Note that with the current application, only ETH staking derivatives that revert on transfer are being called with transfer. However, in the case that the code is modified to support other \"base\" assets in the future, this will protect against unexpected behavior during transfer calls.  Update: Resolved in pull request #5.  Typographical Er", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#low", "labels": ["OpenZeppelin"]}, {"title": "Note/Information", "body": "Note/Information", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#note/information", "labels": ["OpenZeppelin"]}, {"title": "Summary", "body": "DeFi  From 2024-03-20  To 2024-04-02  Solidity  10 (9\u202fresolved)  0 (0\u202fresolved)  1 (1\u202fresolved)  0 (0\u202fresolved)  3 (2\u202fresolved)  6 (6\u202fresolved)  0 (0\u202fresolved)  Scope  We audited the Ion-Protocol/ion-seaport repository at commit 54110bb. In scope were the following files:  Additionally, we audited the Ion-Protocol/ion-protocol repository at commit 0a8c0d2. For files below labelled with \"diff\", only changes since the 1c42b94 commit were considered.  System Overview  The audited code within the \"ion-seaport\" repository centers around two contracts, the SeaportLeverage and SeaportDeleverage contracts. In the leverage case, a user is able to obtain collateral, deposit it into Ion and borrow against it, using the proceeds of the borrow to pay back the Seaport order creator. The deleverage case works in reverse, allowing a user to obtain the borrow asset, repay their borrow in Ion, and withdraw their collateral to repay the Seaport order creator. These contracts simply fulfill orders on Seaport, which must be created outside of the audited codebase prior to fulfilling them.  Both contracts utilize function selector clashing to hijack the transferFrom call that Seaport makes during order fulfillment. Within the \"leverage\" case, this is used to deposit tokens into Ion pools and borrow assets, which are then used to fulfill the remainder of the order. In the \"deleverage\" case, this is performed in reverse.  It should be noted that the Seaport protocol is complex, and thus various precautions are taken by Ion to constrain the order parameters and prevent unexpected behavior. The \"leverage\" functionality is limited to only whitelisted users, and both the \"leverage\" and \"deleverage\" functions can only be used to change the balances of the caller's own account.  The audited code within the \"ion-protocol\" repository implements the necessary contracts to allow Renzo \"ezETH\" and KelpDAO \"rsETH\" as collateral assets in the Ion system. There are new contracts which are the \"handlers\" and the \"libraries\" for these collaterals. For ezETH, there is a new version of the UniswapFlashswapDirectMintHandler contract called UniswapFlashswapDirectMintHandlerWithDust, which exists to help mitigate the problem of \"ezETH\" not being mintable in exact amounts. Due to the mathematics within ezETH, minting can only occur at certain values, and it is very likely that a user will not be able to receive exactly a specified amount out. Ion has also asked OpenZeppelin to investigate the error incurred in ezETH minting calculations, and some informal recommendations have been provided outside of this audit report. Contracts which price ezETH and rsETH against wstETH, the intended the borrow asset, have also been added. These contracts determine liquidation thresholds and maximal borrow amounts. They rely on internal state of the ezETH and rsETH contracts, as well as Chainlink and Redstone oracles, to compute fair values for both collaterals.  Integrations  Ion Protocol integrates with many other protocols deployed on Ethereum. As such, it is generally assumed that those protocols behave as documented. While there are many integrations associated with Ion, the integrations relevant to this specific engagement are:  Chainlink oracles for pricing ETH and wstETH  Redstone oracles for pricing ezETH and rsETH  Uniswap for flash-swaps to achieve leveraging positions in Ion  Seaport for resolving orders used to leverage positions in Ion  ezETH and its related contracts, such as the \"Renzo Oracle\" and \"Renzo Restake Manager\".  rsETH and its related contracts, such as the \"rsETH LRT Oracle\", \"rsETH LRT Config\" and \"rsETH LRT Deposit Pool\".  stETH and wstETH, where wstETH is the base token for all lending pools currently in Ion.  Security Model and Privileged Roles  As noted above, it is assumed that integrated contracts behave as described in their respective documentation. More specifically, we make the following assumptions:  All collaterals will continue to operate as described in their various smart contracts, without the addition of new functionality. For example, rsETH has the ability to accept new assets in exchange for minting rsETH, but for the purposes of this engagement it is assumed they will not.  It is assumed that all collaterals will slowly increase in ETH value, and certain parameters such as TVL or exchange rates within the collateral contracts will reflect this accurately.  It is assumed that values stored in collateral contracts will behave reasonably and remain similar to what they are now. For example, the TVL within ezETH, at time of writing, is about 550,000 ETH. It is assumed that this value will remain of a similar order of magnitude (for example, above 1000 ETH).  It is assumed that, should collateral values drop relative to the borrow asset (wstETH), they will do so slowly enough that liquidations can be performed given block space availability.  It is assumed that the \"base\" asset will remain wstETH for new markets.  It is assum", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#summary", "labels": ["OpenZeppelin"]}, {"title": "DeFi", "body": "DeFi", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#defi", "labels": ["OpenZeppelin"]}, {"title": "From 2024-03-20", "body": "From 2024-03-20", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#from-2024-03-20", "labels": ["OpenZeppelin"]}, {"title": "To 2024-04-02", "body": "To 2024-04-02", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#to-2024-04-02", "labels": ["OpenZeppelin"]}, {"title": "Solidity", "body": "10 (9\u202fresolved)  0 (0\u202fresolved)  1 (1\u202fresolved)  0 (0\u202fresolved)  3 (2\u202fresolved)  6 (6\u202fresolved)  0 (0\u202fresolved)  Scope  We audited the Ion-Protocol/ion-seaport repository at commit 54110bb. In scope were the following files:  Additionally, we audited the Ion-Protocol/ion-protocol repository at commit 0a8c0d2. For files below labelled with \"diff\", only changes since the 1c42b94 commit were considered.  System Overview  The audited code within the \"ion-seaport\" repository centers around two contracts, the SeaportLeverage and SeaportDeleverage contracts. In the leverage case, a user is able to obtain collateral, deposit it into Ion and borrow against it, using the proceeds of the borrow to pay back the Seaport order creator. The deleverage case works in reverse, allowing a user to obtain the borrow asset, repay their borrow in Ion, and withdraw their collateral to repay the Seaport order creator. These contracts simply fulfill orders on Seaport, which must be created outside of the audited codebase prior to fulfilling them.  Both contracts utilize function selector clashing to hijack the transferFrom call that Seaport makes during order fulfillment. Within the \"leverage\" case, this is used to deposit tokens into Ion pools and borrow assets, which are then used to fulfill the remainder of the order. In the \"deleverage\" case, this is performed in reverse.  It should be noted that the Seaport protocol is complex, and thus various precautions are taken by Ion to constrain the order parameters and prevent unexpected behavior. The \"leverage\" functionality is limited to only whitelisted users, and both the \"leverage\" and \"deleverage\" functions can only be used to change the balances of the caller's own account.  The audited code within the \"ion-protocol\" repository implements the necessary contracts to allow Renzo \"ezETH\" and KelpDAO \"rsETH\" as collateral assets in the Ion system. There are new contracts which are the \"handlers\" and the \"libraries\" for these collaterals. For ezETH, there is a new version of the UniswapFlashswapDirectMintHandler contract called UniswapFlashswapDirectMintHandlerWithDust, which exists to help mitigate the problem of \"ezETH\" not being mintable in exact amounts. Due to the mathematics within ezETH, minting can only occur at certain values, and it is very likely that a user will not be able to receive exactly a specified amount out. Ion has also asked OpenZeppelin to investigate the error incurred in ezETH minting calculations, and some informal recommendations have been provided outside of this audit report. Contracts which price ezETH and rsETH against wstETH, the intended the borrow asset, have also been added. These contracts determine liquidation thresholds and maximal borrow amounts. They rely on internal state of the ezETH and rsETH contracts, as well as Chainlink and Redstone oracles, to compute fair values for both collaterals.  Integrations  Ion Protocol integrates with many other protocols deployed on Ethereum. As such, it is generally assumed that those protocols behave as documented. While there are many integrations associated with Ion, the integrations relevant to this specific engagement are:  Chainlink oracles for pricing ETH and wstETH  Redstone oracles for pricing ezETH and rsETH  Uniswap for flash-swaps to achieve leveraging positions in Ion  Seaport for resolving orders used to leverage positions in Ion  ezETH and its related contracts, such as the \"Renzo Oracle\" and \"Renzo Restake Manager\".  rsETH and its related contracts, such as the \"rsETH LRT Oracle\", \"rsETH LRT Config\" and \"rsETH LRT Deposit Pool\".  stETH and wstETH, where wstETH is the base token for all lending pools currently in Ion.  Security Model and Privileged Roles  As noted above, it is assumed that integrated contracts behave as described in their respective documentation. More specifically, we make the following assumptions:  All collaterals will continue to operate as described in their various smart contracts, without the addition of new functionality. For example, rsETH has the ability to accept new assets in exchange for minting rsETH, but for the purposes of this engagement it is assumed they will not.  It is assumed that all collaterals will slowly increase in ETH value, and certain parameters such as TVL or exchange rates within the collateral contracts will reflect this accurately.  It is assumed that values stored in collateral contracts will behave reasonably and remain similar to what they are now. For example, the TVL within ezETH, at time of writing, is about 550,000 ETH. It is assumed that this value will remain of a similar order of magnitude (for example, above 1000 ETH).  It is assumed that, should collateral values drop relative to the borrow asset (wstETH), they will do so slowly enough that liquidations can be performed given block space availability.  It is assumed that the \"base\" asset will remain wstETH for new markets.  It is assumed that Seaport 1.5 will be the version which Io", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#solidity", "labels": ["OpenZeppelin"]}, {"title": "10 (9\u202fresolved)", "body": "10 (9\u202fresolved)", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#10-(9\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "0 (0\u202fresolved)", "body": "3 (2\u202fresolved)  6 (6\u202fresolved)", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#0-(0\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "1 (1\u202fresolved)", "body": "1 (1\u202fresolved)", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#1-(1\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "3 (2\u202fresolved)", "body": "3 (2\u202fresolved)", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#3-(2\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "6 (6\u202fresolved)", "body": "6 (6\u202fresolved)", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#6-(6\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "Scope", "body": "We audited the Ion-Protocol/ion-seaport repository at commit 54110bb. In scope were the following files:  Additionally, we audited the Ion-Protocol/ion-protocol repository at commit 0a8c0d2. For files below labelled with \"diff\", only changes since the 1c42b94 commit were considered.  System Overview  The audited code within the \"ion-seaport\" repository centers around two contracts, the SeaportLeverage and SeaportDeleverage contracts. In the leverage case, a user is able to obtain collateral, deposit it into Ion and borrow against it, using the proceeds of the borrow to pay back the Seaport order creator. The deleverage case works in reverse, allowing a user to obtain the borrow asset, repay their borrow in Ion, and withdraw their collateral to repay the Seaport order creator. These contracts simply fulfill orders on Seaport, which must be created outside of the audited codebase prior to fulfilling them.  Both contracts utilize function selector clashing to hijack the transferFrom call that Seaport makes during order fulfillment. Within the \"leverage\" case, this is used to deposit tokens into Ion pools and borrow assets, which are then used to fulfill the remainder of the order. In the \"deleverage\" case, this is performed in reverse.  It should be noted that the Seaport protocol is complex, and thus various precautions are taken by Ion to constrain the order parameters and prevent unexpected behavior. The \"leverage\" functionality is limited to only whitelisted users, and both the \"leverage\" and \"deleverage\" functions can only be used to change the balances of the caller's own account.  The audited code within the \"ion-protocol\" repository implements the necessary contracts to allow Renzo \"ezETH\" and KelpDAO \"rsETH\" as collateral assets in the Ion system. There are new contracts which are the \"handlers\" and the \"libraries\" for these collaterals. For ezETH, there is a new version of the UniswapFlashswapDirectMintHandler contract called UniswapFlashswapDirectMintHandlerWithDust, which exists to help mitigate the problem of \"ezETH\" not being mintable in exact amounts. Due to the mathematics within ezETH, minting can only occur at certain values, and it is very likely that a user will not be able to receive exactly a specified amount out. Ion has also asked OpenZeppelin to investigate the error incurred in ezETH minting calculations, and some informal recommendations have been provided outside of this audit report. Contracts which price ezETH and rsETH against wstETH, the intended the borrow asset, have also been added. These contracts determine liquidation thresholds and maximal borrow amounts. They rely on internal state of the ezETH and rsETH contracts, as well as Chainlink and Redstone oracles, to compute fair values for both collaterals.  Integrations  Ion Protocol integrates with many other protocols deployed on Ethereum. As such, it is generally assumed that those protocols behave as documented. While there are many integrations associated with Ion, the integrations relevant to this specific engagement are:  Chainlink oracles for pricing ETH and wstETH  Redstone oracles for pricing ezETH and rsETH  Uniswap for flash-swaps to achieve leveraging positions in Ion  Seaport for resolving orders used to leverage positions in Ion  ezETH and its related contracts, such as the \"Renzo Oracle\" and \"Renzo Restake Manager\".  rsETH and its related contracts, such as the \"rsETH LRT Oracle\", \"rsETH LRT Config\" and \"rsETH LRT Deposit Pool\".  stETH and wstETH, where wstETH is the base token for all lending pools currently in Ion.  Security Model and Privileged Roles  As noted above, it is assumed that integrated contracts behave as described in their respective documentation. More specifically, we make the following assumptions:  All collaterals will continue to operate as described in their various smart contracts, without the addition of new functionality. For example, rsETH has the ability to accept new assets in exchange for minting rsETH, but for the purposes of this engagement it is assumed they will not.  It is assumed that all collaterals will slowly increase in ETH value, and certain parameters such as TVL or exchange rates within the collateral contracts will reflect this accurately.  It is assumed that values stored in collateral contracts will behave reasonably and remain similar to what they are now. For example, the TVL within ezETH, at time of writing, is about 550,000 ETH. It is assumed that this value will remain of a similar order of magnitude (for example, above 1000 ETH).  It is assumed that, should collateral values drop relative to the borrow asset (wstETH), they will do so slowly enough that liquidations can be performed given block space availability.  It is assumed that the \"base\" asset will remain wstETH for new markets.  It is assumed that Seaport 1.5 will be the version which Ion integrates with for the Seaport leveraging contracts.  It is assumed that all oracle updates from Chainlink or Redston", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#scope", "labels": ["OpenZeppelin"]}, {"title": "We audited the Ion-Protocol/ion-seaport repository at commit 54110bb. In scope were the following files:", "body": "We audited the Ion-Protocol/ion-seaport repository at commit 54110bb. In scope were the following files:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#we-audited-the-ion-protocol/ion-seaport-repository-at-commit-54110bb.-in-scope-were-the-following-files:", "labels": ["OpenZeppelin"]}, {"title": "Additionally, we audited the Ion-Protocol/ion-protocol repository at commit 0a8c0d2. For files below labelled with \"diff\", only changes since the 1c42b94 commit were considered.", "body": "Additionally, we audited the Ion-Protocol/ion-protocol repository at commit 0a8c0d2. For files below labelled with \"diff\", only changes since the 1c42b94 commit were considered.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#additionally,-we-audited-the-ion-protocol/ion-protocol-repository-at-commit-0a8c0d2.-for-files-below-labelled-with-\"diff\",-only-changes-since-the-1c42b94-commit-were-considered.", "labels": ["OpenZeppelin"]}, {"title": "System Overview", "body": "The audited code within the \"ion-seaport\" repository centers around two contracts, the SeaportLeverage and SeaportDeleverage contracts. In the leverage case, a user is able to obtain collateral, deposit it into Ion and borrow against it, using the proceeds of the borrow to pay back the Seaport order creator. The deleverage case works in reverse, allowing a user to obtain the borrow asset, repay their borrow in Ion, and withdraw their collateral to repay the Seaport order creator. These contracts simply fulfill orders on Seaport, which must be created outside of the audited codebase prior to fulfilling them.  Both contracts utilize function selector clashing to hijack the transferFrom call that Seaport makes during order fulfillment. Within the \"leverage\" case, this is used to deposit tokens into Ion pools and borrow assets, which are then used to fulfill the remainder of the order. In the \"deleverage\" case, this is performed in reverse.  It should be noted that the Seaport protocol is complex, and thus various precautions are taken by Ion to constrain the order parameters and prevent unexpected behavior. The \"leverage\" functionality is limited to only whitelisted users, and both the \"leverage\" and \"deleverage\" functions can only be used to change the balances of the caller's own account.  The audited code within the \"ion-protocol\" repository implements the necessary contracts to allow Renzo \"ezETH\" and KelpDAO \"rsETH\" as collateral assets in the Ion system. There are new contracts which are the \"handlers\" and the \"libraries\" for these collaterals. For ezETH, there is a new version of the UniswapFlashswapDirectMintHandler contract called UniswapFlashswapDirectMintHandlerWithDust, which exists to help mitigate the problem of \"ezETH\" not being mintable in exact amounts. Due to the mathematics within ezETH, minting can only occur at certain values, and it is very likely that a user will not be able to receive exactly a specified amount out. Ion has also asked OpenZeppelin to investigate the error incurred in ezETH minting calculations, and some informal recommendations have been provided outside of this audit report. Contracts which price ezETH and rsETH against wstETH, the intended the borrow asset, have also been added. These contracts determine liquidation thresholds and maximal borrow amounts. They rely on internal state of the ezETH and rsETH contracts, as well as Chainlink and Redstone oracles, to compute fair values for both collaterals.  Integrations  Ion Protocol integrates with many other protocols deployed on Ethereum. As such, it is generally assumed that those protocols behave as documented. While there are many integrations associated with Ion, the integrations relevant to this specific engagement are:  Chainlink oracles for pricing ETH and wstETH  Redstone oracles for pricing ezETH and rsETH  Uniswap for flash-swaps to achieve leveraging positions in Ion  Seaport for resolving orders used to leverage positions in Ion  ezETH and its related contracts, such as the \"Renzo Oracle\" and \"Renzo Restake Manager\".  rsETH and its related contracts, such as the \"rsETH LRT Oracle\", \"rsETH LRT Config\" and \"rsETH LRT Deposit Pool\".  stETH and wstETH, where wstETH is the base token for all lending pools currently in Ion.  Security Model and Privileged Roles  As noted above, it is assumed that integrated contracts behave as described in their respective documentation. More specifically, we make the following assumptions:  All collaterals will continue to operate as described in their various smart contracts, without the addition of new functionality. For example, rsETH has the ability to accept new assets in exchange for minting rsETH, but for the purposes of this engagement it is assumed they will not.  It is assumed that all collaterals will slowly increase in ETH value, and certain parameters such as TVL or exchange rates within the collateral contracts will reflect this accurately.  It is assumed that values stored in collateral contracts will behave reasonably and remain similar to what they are now. For example, the TVL within ezETH, at time of writing, is about 550,000 ETH. It is assumed that this value will remain of a similar order of magnitude (for example, above 1000 ETH).  It is assumed that, should collateral values drop relative to the borrow asset (wstETH), they will do so slowly enough that liquidations can be performed given block space availability.  It is assumed that the \"base\" asset will remain wstETH for new markets.  It is assumed that Seaport 1.5 will be the version which Ion integrates with for the Seaport leveraging contracts.  It is assumed that all oracle updates from Chainlink or Redstone will be timely and accurate.  It is assumed that all contract addresses specified in Constants.sol are accurate and will match the values used in the deployed Ion contracts.  The operator of an account is able to borrow, repay and used approved tokens of the account.  The Seaport \"leverage\" and \"del", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#system-overview", "labels": ["OpenZeppelin"]}, {"title": "The audited code within the \"ion-seaport\" repository centers around two contracts, the SeaportLeverage and SeaportDeleverage contracts. In the leverage case, a user is able to obtain collateral, deposit it into Ion and borrow against it, using the proceeds of the borrow to pay back the Seaport order creator. The deleverage case works in reverse, allowing a user to obtain the borrow asset, repay their borrow in Ion, and withdraw their collateral to repay the Seaport order creator. These contracts simply fulfill orders on Seaport, which must be created outside of the audited codebase prior to fulfilling them.", "body": "The audited code within the \"ion-seaport\" repository centers around two contracts, the SeaportLeverage and SeaportDeleverage contracts. In the leverage case, a user is able to obtain collateral, deposit it into Ion and borrow against it, using the proceeds of the borrow to pay back the Seaport order creator. The deleverage case works in reverse, allowing a user to obtain the borrow asset, repay their borrow in Ion, and withdraw their collateral to repay the Seaport order creator. These contracts simply fulfill orders on Seaport, which must be created outside of the audited codebase prior to fulfilling them.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-audited-code-within-the-\"ion-seaport\"-repository-centers-around-two-contracts,-the-seaportleverage-and-seaportdeleverage-contracts.-in-the-leverage-case,-a-user-is-able-to-obtain-collateral,-deposit-it-into-ion-and-borrow-against-it,-using-the-proceeds-of-the-borrow-to-pay-back-the-seaport-order-creator.-the-deleverage-case-works-in-reverse,-allowing-a-user-to-obtain-the-borrow-asset,-repay-their-borrow-in-ion,-and-withdraw-their-collateral-to-repay-the-seaport-order-creator.-these-contracts-simply-fulfill-orders-on-seaport,-which-must-be-created-outside-of-the-audited-codebase-prior-to-fulfilling-them.", "labels": ["OpenZeppelin"]}, {"title": "Both contracts utilize function selector clashing to hijack the transferFrom call that Seaport makes during order fulfillment. Within the \"leverage\" case, this is used to deposit tokens into Ion pools and borrow assets, which are then used to fulfill the remainder of the order. In the \"deleverage\" case, this is performed in reverse.", "body": "Both contracts utilize function selector clashing to hijack the transferFrom call that Seaport makes during order fulfillment. Within the \"leverage\" case, this is used to deposit tokens into Ion pools and borrow assets, which are then used to fulfill the remainder of the order. In the \"deleverage\" case, this is performed in reverse.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#both-contracts-utilize-function-selector-clashing-to-hijack-the-transferfrom-call-that-seaport-makes-during-order-fulfillment.-within-the-\"leverage\"-case,-this-is-used-to-deposit-tokens-into-ion-pools-and-borrow-assets,-which-are-then-used-to-fulfill-the-remainder-of-the-order.-in-the-\"deleverage\"-case,-this-is-performed-in-reverse.", "labels": ["OpenZeppelin"]}, {"title": "It should be noted that the Seaport protocol is complex, and thus various precautions are taken by Ion to constrain the order parameters and prevent unexpected behavior. The \"leverage\" functionality is limited to only whitelisted users, and both the \"leverage\" and \"deleverage\" functions can only be used to change the balances of the caller's own account.", "body": "It should be noted that the Seaport protocol is complex, and thus various precautions are taken by Ion to constrain the order parameters and prevent unexpected behavior. The \"leverage\" functionality is limited to only whitelisted users, and both the \"leverage\" and \"deleverage\" functions can only be used to change the balances of the caller's own account.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#it-should-be-noted-that-the-seaport-protocol-is-complex,-and-thus-various-precautions-are-taken-by-ion-to-constrain-the-order-parameters-and-prevent-unexpected-behavior.-the-\"leverage\"-functionality-is-limited-to-only-whitelisted-users,-and-both-the-\"leverage\"-and-\"deleverage\"-functions-can-only-be-used-to-change-the-balances-of-the-caller's-own-account.", "labels": ["OpenZeppelin"]}, {"title": "The audited code within the \"ion-protocol\" repository implements the necessary contracts to allow Renzo \"ezETH\" and KelpDAO \"rsETH\" as collateral assets in the Ion system. There are new contracts which are the \"handlers\" and the \"libraries\" for these collaterals. For ezETH, there is a new version of the UniswapFlashswapDirectMintHandler contract called UniswapFlashswapDirectMintHandlerWithDust, which exists to help mitigate the problem of \"ezETH\" not being mintable in exact amounts. Due to the mathematics within ezETH, minting can only occur at certain values, and it is very likely that a user will not be able to receive exactly a specified amount out. Ion has also asked OpenZeppelin to investigate the error incurred in ezETH minting calculations, and some informal recommendations have been provided outside of this audit report. Contracts which price ezETH and rsETH against wstETH, the intended the borrow asset, have also been added. These contracts determine liquidation thresholds and", "body": "The audited code within the \"ion-protocol\" repository implements the necessary contracts to allow Renzo \"ezETH\" and KelpDAO \"rsETH\" as collateral assets in the Ion system. There are new contracts which are the \"handlers\" and the \"libraries\" for these collaterals. For ezETH, there is a new version of the UniswapFlashswapDirectMintHandler contract called UniswapFlashswapDirectMintHandlerWithDust, which exists to help mitigate the problem of \"ezETH\" not being mintable in exact amounts. Due to the mathematics within ezETH, minting can only occur at certain values, and it is very likely that a user will not be able to receive exactly a specified amount out. Ion has also asked OpenZeppelin to investigate the error incurred in ezETH minting calculations, and some informal recommendations have been provided outside of this audit report. Contracts which price ezETH and rsETH against wstETH, the intended the borrow asset, have also been added. These contracts determine liquidation thresholds and", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-audited-code-within-the-\"ion-protocol\"-repository-implements-the-necessary-contracts-to-allow-renzo-\"ezeth\"-and-kelpdao-\"rseth\"-as-collateral-assets-in-the-ion-system.-there-are-new-contracts-which-are-the-\"handlers\"-and-the-\"libraries\"-for-these-collaterals.-for-ezeth,-there-is-a-new-version-of-the-uniswapflashswapdirectminthandler-contract-called-uniswapflashswapdirectminthandlerwithdust,-which-exists-to-help-mitigate-the-problem-of-\"ezeth\"-not-being-mintable-in-exact-amounts.-due-to-the-mathematics-within-ezeth,-minting-can-only-occur-at-certain-values,-and-it-is-very-likely-that-a-user-will-not-be-able-to-receive-exactly-a-specified-amount-out.-ion-has-also-asked-openzeppelin-to-investigate-the-error-incurred-in-ezeth-minting-calculations,-and-some-informal-recommendations-have-been-provided-outside-of-this-audit-report.-contracts-which-price-ezeth-and-rseth-against-wsteth,-the-intended-the-borrow-asset,-have-also-been-added.-these-contracts-determine-liquidation-thresholds-and-maximal-borrow-amounts.-they-rely-on-internal-state-of-the-ezeth-and-rseth-contracts,-as-well-as-chainlink-and-redstone-oracles,-to-compute-fair-values-for-both-collaterals.", "labels": ["OpenZeppelin"]}, {"title": "Integrations", "body": "Ion Protocol integrates with many other protocols deployed on Ethereum. As such, it is generally assumed that those protocols behave as documented. While there are many integrations associated with Ion, the integrations relevant to this specific engagement are:  Chainlink oracles for pricing ETH and wstETH  Redstone oracles for pricing ezETH and rsETH  Uniswap for flash-swaps to achieve leveraging positions in Ion  Seaport for resolving orders used to leverage positions in Ion  ezETH and its related contracts, such as the \"Renzo Oracle\" and \"Renzo Restake Manager\".  rsETH and its related contracts, such as the \"rsETH LRT Oracle\", \"rsETH LRT Config\" and \"rsETH LRT Deposit Pool\".  stETH and wstETH, where wstETH is the base token for all lending pools currently in Ion.  Security Model and Privileged Roles  As noted above, it is assumed that integrated contracts behave as described in their respective documentation. More specifically, we make the following assumptions:  All collaterals will continue to operate as described in their various smart contracts, without the addition of new functionality. For example, rsETH has the ability to accept new assets in exchange for minting rsETH, but for the purposes of this engagement it is assumed they will not.  It is assumed that all collaterals will slowly increase in ETH value, and certain parameters such as TVL or exchange rates within the collateral contracts will reflect this accurately.  It is assumed that values stored in collateral contracts will behave reasonably and remain similar to what they are now. For example, the TVL within ezETH, at time of writing, is about 550,000 ETH. It is assumed that this value will remain of a similar order of magnitude (for example, above 1000 ETH).  It is assumed that, should collateral values drop relative to the borrow asset (wstETH), they will do so slowly enough that liquidations can be performed given block space availability.  It is assumed that the \"base\" asset will remain wstETH for new markets.  It is assumed that Seaport 1.5 will be the version which Ion integrates with for the Seaport leveraging contracts.  It is assumed that all oracle updates from Chainlink or Redstone will be timely and accurate.  It is assumed that all contract addresses specified in Constants.sol are accurate and will match the values used in the deployed Ion contracts.  The operator of an account is able to borrow, repay and used approved tokens of the account.  The Seaport \"leverage\" and \"deleverage\" contracts must be set as a user's operator to alter the balance of the user's vault.  Only whitelisted borrowers can use the Seaport \"leverage\" function.  Monitoring Recommendations  We encourage the Ion team to consider implementing monitoring for their deployed contracts.  Consider monitoring for any upgrades to the Renzo contracts, including all those defined in Constants.sol. If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the Renzo contract logic. Additionally, identify all changes to logic pertaining to values like TVL or ezETH total supply, which Ion also depends on.  Consider monitoring for any upgrades to the KelpDAO contracts (for rsETH). If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the rsETH contract logic. Additionally, identify all changes to logic pertaining to values like rsEthPrice (from the RSETH_LRT_ORACLE) which Ion also depends on.  Establish a plan to pause the Ion protocol or change specific parameters, such as the spot address for a given collateral, in the event of an upgrade to any collateral contracts.  Monitor for upgrades to any tokens which are utilized in the Seaport leveraging or deleveraging contracts.  Monitor for changes to ezETH's TVL and total supply, and identify maximal reasonable error for a predefined max deposit size. Consider the value of this error as compared to current gas prices on Ethereum mainnet to determine whether logic within the EzEthHandler should be updated.  Monitor for significant drops in the TVL of ezETH or rsETH, to identify smart contract bugs within collaterals quickly. Create a plan for pausing either the Ion protocol or modifying parameters for specific markets.  Monitor collateral prices using various sources such as Uniswap, Curve, and Coingecko to identify price disparities for collateral assets. These may signal smart contract bugs or \"black swan\" market conditions. Establish plans for pausing or modifying market parameters based on certain thresholds being reached. For example, \"pause all markets if the price for a collateral asset on Uniswap diverges from the price on Curve by more than 10% for more than 100 blocks\".  Monitor all transactions utilizing the Seaport leveraging contracts, specifically checking for token transfer events. Seaport is a complicated system, so special attention should be payed to it. Ensure that tokens are moving as intended. Consider removing the \"SeaportLeverage", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#integrations", "labels": ["OpenZeppelin"]}, {"title": "Ion Protocol integrates with many other protocols deployed on Ethereum. As such, it is generally assumed that those protocols behave as documented. While there are many integrations associated with Ion, the integrations relevant to this specific engagement are:", "body": "Ion Protocol integrates with many other protocols deployed on Ethereum. As such, it is generally assumed that those protocols behave as documented. While there are many integrations associated with Ion, the integrations relevant to this specific engagement are:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#ion-protocol-integrates-with-many-other-protocols-deployed-on-ethereum.-as-such,-it-is-generally-assumed-that-those-protocols-behave-as-documented.-while-there-are-many-integrations-associated-with-ion,-the-integrations-relevant-to-this-specific-engagement-are:", "labels": ["OpenZeppelin"]}, {"title": "Chainlink oracles for pricing ETH and wstETH", "body": "Chainlink oracles for pricing ETH and wstETH", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#chainlink-oracles-for-pricing-eth-and-wsteth", "labels": ["OpenZeppelin"]}, {"title": "Redstone oracles for pricing ezETH and rsETH", "body": "Redstone oracles for pricing ezETH and rsETH", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#redstone-oracles-for-pricing-ezeth-and-rseth", "labels": ["OpenZeppelin"]}, {"title": "Uniswap for flash-swaps to achieve leveraging positions in Ion", "body": "Uniswap for flash-swaps to achieve leveraging positions in Ion", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#uniswap-for-flash-swaps-to-achieve-leveraging-positions-in-ion", "labels": ["OpenZeppelin"]}, {"title": "Seaport for resolving orders used to leverage positions in Ion", "body": "Seaport for resolving orders used to leverage positions in Ion", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#seaport-for-resolving-orders-used-to-leverage-positions-in-ion", "labels": ["OpenZeppelin"]}, {"title": "ezETH and its related contracts, such as the \"Renzo Oracle\" and \"Renzo Restake Manager\".", "body": "ezETH and its related contracts, such as the \"Renzo Oracle\" and \"Renzo Restake Manager\".", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#ezeth-and-its-related-contracts,-such-as-the-\"renzo-oracle\"-and-\"renzo-restake-manager\".", "labels": ["OpenZeppelin"]}, {"title": "rsETH and its related contracts, such as the \"rsETH LRT Oracle\", \"rsETH LRT Config\" and \"rsETH LRT Deposit Pool\".", "body": "rsETH and its related contracts, such as the \"rsETH LRT Oracle\", \"rsETH LRT Config\" and \"rsETH LRT Deposit Pool\".", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#rseth-and-its-related-contracts,-such-as-the-\"rseth-lrt-oracle\",-\"rseth-lrt-config\"-and-\"rseth-lrt-deposit-pool\".", "labels": ["OpenZeppelin"]}, {"title": "stETH and wstETH, where wstETH is the base token for all lending pools currently in Ion.", "body": "stETH and wstETH, where wstETH is the base token for all lending pools currently in Ion.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#steth-and-wsteth,-where-wsteth-is-the-base-token-for-all-lending-pools-currently-in-ion.", "labels": ["OpenZeppelin"]}, {"title": "Security Model and Privileged Roles", "body": "As noted above, it is assumed that integrated contracts behave as described in their respective documentation. More specifically, we make the following assumptions:  All collaterals will continue to operate as described in their various smart contracts, without the addition of new functionality. For example, rsETH has the ability to accept new assets in exchange for minting rsETH, but for the purposes of this engagement it is assumed they will not.  It is assumed that all collaterals will slowly increase in ETH value, and certain parameters such as TVL or exchange rates within the collateral contracts will reflect this accurately.  It is assumed that values stored in collateral contracts will behave reasonably and remain similar to what they are now. For example, the TVL within ezETH, at time of writing, is about 550,000 ETH. It is assumed that this value will remain of a similar order of magnitude (for example, above 1000 ETH).  It is assumed that, should collateral values drop relative to the borrow asset (wstETH), they will do so slowly enough that liquidations can be performed given block space availability.  It is assumed that the \"base\" asset will remain wstETH for new markets.  It is assumed that Seaport 1.5 will be the version which Ion integrates with for the Seaport leveraging contracts.  It is assumed that all oracle updates from Chainlink or Redstone will be timely and accurate.  It is assumed that all contract addresses specified in Constants.sol are accurate and will match the values used in the deployed Ion contracts.  The operator of an account is able to borrow, repay and used approved tokens of the account.  The Seaport \"leverage\" and \"deleverage\" contracts must be set as a user's operator to alter the balance of the user's vault.  Only whitelisted borrowers can use the Seaport \"leverage\" function.  Monitoring Recommendations  We encourage the Ion team to consider implementing monitoring for their deployed contracts.  Consider monitoring for any upgrades to the Renzo contracts, including all those defined in Constants.sol. If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the Renzo contract logic. Additionally, identify all changes to logic pertaining to values like TVL or ezETH total supply, which Ion also depends on.  Consider monitoring for any upgrades to the KelpDAO contracts (for rsETH). If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the rsETH contract logic. Additionally, identify all changes to logic pertaining to values like rsEthPrice (from the RSETH_LRT_ORACLE) which Ion also depends on.  Establish a plan to pause the Ion protocol or change specific parameters, such as the spot address for a given collateral, in the event of an upgrade to any collateral contracts.  Monitor for upgrades to any tokens which are utilized in the Seaport leveraging or deleveraging contracts.  Monitor for changes to ezETH's TVL and total supply, and identify maximal reasonable error for a predefined max deposit size. Consider the value of this error as compared to current gas prices on Ethereum mainnet to determine whether logic within the EzEthHandler should be updated.  Monitor for significant drops in the TVL of ezETH or rsETH, to identify smart contract bugs within collaterals quickly. Create a plan for pausing either the Ion protocol or modifying parameters for specific markets.  Monitor collateral prices using various sources such as Uniswap, Curve, and Coingecko to identify price disparities for collateral assets. These may signal smart contract bugs or \"black swan\" market conditions. Establish plans for pausing or modifying market parameters based on certain thresholds being reached. For example, \"pause all markets if the price for a collateral asset on Uniswap diverges from the price on Curve by more than 10% for more than 100 blocks\".  Monitor all transactions utilizing the Seaport leveraging contracts, specifically checking for token transfer events. Seaport is a complicated system, so special attention should be payed to it. Ensure that tokens are moving as intended. Consider removing the \"SeaportLeverage\" contract from the protocol whitelist if unexpected behavior is detected, to prevent losses for users.  Additionally, before performing certain actions, we encourage Ion to validate the following:  Before integrating new tokens to the Seaport leveraging contracts, generally ensure that these tokens do not make calls to external contracts, as these could interfere with correct operation of the Seaport leveraging contracts. Pay special attention to \"before transfer\" and \"after transfer\" hooks on tokens.  Special considerations for ezETH  The Ion team specifically requested a review of the math used for ezETH integration within the Ion protocol. The audit team has relayed their findings regarding this asset to Ion outside of this audit report. In summary, the findings were that the minting of ezETH cannot ", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#security-model-and-privileged-roles", "labels": ["OpenZeppelin"]}, {"title": "As noted above, it is assumed that integrated contracts behave as described in their respective documentation. More specifically, we make the following assumptions:", "body": "As noted above, it is assumed that integrated contracts behave as described in their respective documentation. More specifically, we make the following assumptions:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#as-noted-above,-it-is-assumed-that-integrated-contracts-behave-as-described-in-their-respective-documentation.-more-specifically,-we-make-the-following-assumptions:", "labels": ["OpenZeppelin"]}, {"title": "All collaterals will continue to operate as described in their various smart contracts, without the addition of new functionality. For example, rsETH has the ability to accept new assets in exchange for minting rsETH, but for the purposes of this engagement it is assumed they will not.", "body": "All collaterals will continue to operate as described in their various smart contracts, without the addition of new functionality. For example, rsETH has the ability to accept new assets in exchange for minting rsETH, but for the purposes of this engagement it is assumed they will not.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#all-collaterals-will-continue-to-operate-as-described-in-their-various-smart-contracts,-without-the-addition-of-new-functionality.-for-example,-rseth-has-the-ability-to-accept-new-assets-in-exchange-for-minting-rseth,-but-for-the-purposes-of-this-engagement-it-is-assumed-they-will-not.", "labels": ["OpenZeppelin"]}, {"title": "It is assumed that all collaterals will slowly increase in ETH value, and certain parameters such as TVL or exchange rates within the collateral contracts will reflect this accurately.", "body": "It is assumed that all collaterals will slowly increase in ETH value, and certain parameters such as TVL or exchange rates within the collateral contracts will reflect this accurately.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#it-is-assumed-that-all-collaterals-will-slowly-increase-in-eth-value,-and-certain-parameters-such-as-tvl-or-exchange-rates-within-the-collateral-contracts-will-reflect-this-accurately.", "labels": ["OpenZeppelin"]}, {"title": "It is assumed that values stored in collateral contracts will behave reasonably and remain similar to what they are now. For example, the TVL within ezETH, at time of writing, is about 550,000 ETH. It is assumed that this value will remain of a similar order of magnitude (for example, above 1000 ETH).", "body": "It is assumed that values stored in collateral contracts will behave reasonably and remain similar to what they are now. For example, the TVL within ezETH, at time of writing, is about 550,000 ETH. It is assumed that this value will remain of a similar order of magnitude (for example, above 1000 ETH).", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#it-is-assumed-that-values-stored-in-collateral-contracts-will-behave-reasonably-and-remain-similar-to-what-they-are-now.-for-example,-the-tvl-within-ezeth,-at-time-of-writing,-is-about-550,000-eth.-it-is-assumed-that-this-value-will-remain-of-a-similar-order-of-magnitude-(for-example,-above-1000-eth).", "labels": ["OpenZeppelin"]}, {"title": "It is assumed that, should collateral values drop relative to the borrow asset (wstETH), they will do so slowly enough that liquidations can be performed given block space availability.", "body": "It is assumed that, should collateral values drop relative to the borrow asset (wstETH), they will do so slowly enough that liquidations can be performed given block space availability.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#it-is-assumed-that,-should-collateral-values-drop-relative-to-the-borrow-asset-(wsteth),-they-will-do-so-slowly-enough-that-liquidations-can-be-performed-given-block-space-availability.", "labels": ["OpenZeppelin"]}, {"title": "It is assumed that the \"base\" asset will remain wstETH for new markets.", "body": "It is assumed that the \"base\" asset will remain wstETH for new markets.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#it-is-assumed-that-the-\"base\"-asset-will-remain-wsteth-for-new-markets.", "labels": ["OpenZeppelin"]}, {"title": "It is assumed that Seaport 1.5 will be the version which Ion integrates with for the Seaport leveraging contracts.", "body": "It is assumed that Seaport 1.5 will be the version which Ion integrates with for the Seaport leveraging contracts.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#it-is-assumed-that-seaport-1.5-will-be-the-version-which-ion-integrates-with-for-the-seaport-leveraging-contracts.", "labels": ["OpenZeppelin"]}, {"title": "It is assumed that all oracle updates from Chainlink or Redstone will be timely and accurate.", "body": "It is assumed that all oracle updates from Chainlink or Redstone will be timely and accurate.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#it-is-assumed-that-all-oracle-updates-from-chainlink-or-redstone-will-be-timely-and-accurate.", "labels": ["OpenZeppelin"]}, {"title": "It is assumed that all contract addresses specified in Constants.sol are accurate and will match the values used in the deployed Ion contracts.", "body": "It is assumed that all contract addresses specified in Constants.sol are accurate and will match the values used in the deployed Ion contracts.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#it-is-assumed-that-all-contract-addresses-specified-in-constants.sol-are-accurate-and-will-match-the-values-used-in-the-deployed-ion-contracts.", "labels": ["OpenZeppelin"]}, {"title": "The operator of an account is able to borrow, repay and used approved tokens of the account.", "body": "The operator of an account is able to borrow, repay and used approved tokens of the account.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-operator-of-an-account-is-able-to-borrow,-repay-and-used-approved-tokens-of-the-account.", "labels": ["OpenZeppelin"]}, {"title": "The Seaport \"leverage\" and \"deleverage\" contracts must be set as a user's operator to alter the balance of the user's vault.", "body": "The Seaport \"leverage\" and \"deleverage\" contracts must be set as a user's operator to alter the balance of the user's vault.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-seaport-\"leverage\"-and-\"deleverage\"-contracts-must-be-set-as-a-user's-operator-to-alter-the-balance-of-the-user's-vault.", "labels": ["OpenZeppelin"]}, {"title": "Only whitelisted borrowers can use the Seaport \"leverage\" function.", "body": "Only whitelisted borrowers can use the Seaport \"leverage\" function.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#only-whitelisted-borrowers-can-use-the-seaport-\"leverage\"-function.", "labels": ["OpenZeppelin"]}, {"title": "Monitoring Recommendations", "body": "We encourage the Ion team to consider implementing monitoring for their deployed contracts.  Consider monitoring for any upgrades to the Renzo contracts, including all those defined in Constants.sol. If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the Renzo contract logic. Additionally, identify all changes to logic pertaining to values like TVL or ezETH total supply, which Ion also depends on.  Consider monitoring for any upgrades to the KelpDAO contracts (for rsETH). If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the rsETH contract logic. Additionally, identify all changes to logic pertaining to values like rsEthPrice (from the RSETH_LRT_ORACLE) which Ion also depends on.  Establish a plan to pause the Ion protocol or change specific parameters, such as the spot address for a given collateral, in the event of an upgrade to any collateral contracts.  Monitor for upgrades to any tokens which are utilized in the Seaport leveraging or deleveraging contracts.  Monitor for changes to ezETH's TVL and total supply, and identify maximal reasonable error for a predefined max deposit size. Consider the value of this error as compared to current gas prices on Ethereum mainnet to determine whether logic within the EzEthHandler should be updated.  Monitor for significant drops in the TVL of ezETH or rsETH, to identify smart contract bugs within collaterals quickly. Create a plan for pausing either the Ion protocol or modifying parameters for specific markets.  Monitor collateral prices using various sources such as Uniswap, Curve, and Coingecko to identify price disparities for collateral assets. These may signal smart contract bugs or \"black swan\" market conditions. Establish plans for pausing or modifying market parameters based on certain thresholds being reached. For example, \"pause all markets if the price for a collateral asset on Uniswap diverges from the price on Curve by more than 10% for more than 100 blocks\".  Monitor all transactions utilizing the Seaport leveraging contracts, specifically checking for token transfer events. Seaport is a complicated system, so special attention should be payed to it. Ensure that tokens are moving as intended. Consider removing the \"SeaportLeverage\" contract from the protocol whitelist if unexpected behavior is detected, to prevent losses for users.  Additionally, before performing certain actions, we encourage Ion to validate the following:  Before integrating new tokens to the Seaport leveraging contracts, generally ensure that these tokens do not make calls to external contracts, as these could interfere with correct operation of the Seaport leveraging contracts. Pay special attention to \"before transfer\" and \"after transfer\" hooks on tokens.  Special considerations for ezETH  The Ion team specifically requested a review of the math used for ezETH integration within the Ion protocol. The audit team has relayed their findings regarding this asset to Ion outside of this audit report. In summary, the findings were that the minting of ezETH cannot necessarily result in any arbitrary amount specified.  Generally, minting behavior of ezETH is determined by the intermediate value, inflationPercentage, which is used for computing the TVL growth of a deposit into ezETH and the subsequent growth of the supply of ezETH. Since inflationPercentage has a maximal value of 1e18 - 1, there are thus that many different values for the amount of ezETH which can be minted. There are possibly many more potential values for the amount of ETH which can be deposited, and thus the inflationPercentage is the limiting factor in potential values of ezETH minted.  We encourage the Ion team to assess the tradeoff between increased gas costs and potential savings to users when deciding to make computations more accurate. Consider the typical values of deposits into the Ion protocol and utilize these to compute potential error as a general range of values. In addition, extensively document the error considerations to reassure users who may be concerned about inaccuracy in the computations.  High Severity  Full Deleverage Functionality Can Be Permanently Bricked  In the seaportCallback4878572495 function within the SeaportDeleverage contract, there is a requirement that the BASE token balance of the contract is 0 after a full deleverage.  However, this will always revert if a user has independently transferred any amount of BASE tokens into the SeaportDeleverage contract. Since there is no way to transfer the tokens out of the contract, a single transfer will permanently brick the contract.  Consider removing this check, or modifying it to instead check that the token balance of the contract has not changed since the beginning of the execution flow. Alternatively, consider either modifying the logic to transfer all unneeded BASE tokens to the user, or implementing a \"rescue\" function to remove stranded BASE tokens.  U", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#monitoring-recommendations", "labels": ["OpenZeppelin"]}, {"title": "We encourage the Ion team to consider implementing monitoring for their deployed contracts.", "body": "We encourage the Ion team to consider implementing monitoring for their deployed contracts.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#we-encourage-the-ion-team-to-consider-implementing-monitoring-for-their-deployed-contracts.", "labels": ["OpenZeppelin"]}, {"title": "Consider monitoring for any upgrades to the Renzo contracts, including all those defined in Constants.sol. If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the Renzo contract logic. Additionally, identify all changes to logic pertaining to values like TVL or ezETH total supply, which Ion also depends on.", "body": "Consider monitoring for any upgrades to the Renzo contracts, including all those defined in Constants.sol. If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the Renzo contract logic. Additionally, identify all changes to logic pertaining to values like TVL or ezETH total supply, which Ion also depends on.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-monitoring-for-any-upgrades-to-the-renzo-contracts,-including-all-those-defined-in-constants.sol.-if-an-upgrade-is-detected,-scan-all-execution-flows-which-ion-depends-on-for-any-changes-in-the-renzo-contract-logic.-additionally,-identify-all-changes-to-logic-pertaining-to-values-like-tvl-or-ezeth-total-supply,-which-ion-also-depends-on.", "labels": ["OpenZeppelin"]}]