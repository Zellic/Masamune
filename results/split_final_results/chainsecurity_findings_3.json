[{"title": "6.9   Commented Code", "body": "  The contract FraxLocker includes a function vote which is commented out. Please elaborate on the cause and if this functionality should be implemented or the code removed completely.  Code corrected  The commented function was removed from the code base.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Mismatch of Specification With the Function", "body": " Modifier  The specification of the function createLock states that it can only be called by governance or proxy, however,  the  modifier  onlyGovernanceOrDepositor  is  used,  which  checks  if  the  msg.sender  is either the governance or fxsDepositor address. Additionally, the fxsDepositor contract does not implement any functionality which calls createLock currently.  Code corrected  The updated spec state that createLock can be called only by the governance. The respective modifier onlyGovernance is now used.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Revert Message on Modifier", "body": "  The  modifier  onlyGovernanceOrDepositor  checks  if  the  msg.sender  is  either  governance  or fxsDepositor address as shown:  modifier onlyGovernanceOrDepositor() {         require(                 msg.sender == governance || msg.sender == fxsDepositor,                 \"!(gov||proxy||fxsDepositor)\"         );         _; }  The error message claims that msg.sender is not proxy address, which is not declared in the contract.  Code corrected  The error message has been updated accordingly.  StakeDAO - StakeDAO-Frax-veSDT -   24  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f6.12   Unused Event Voted  The contract FraxLocker declares the event Voted, however, it is not used in the current codebase.  Code corrected  The unused event Voted has been removed from the code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Unused Imports: FxsDepositor", "body": "  The file FxsDepositor.sol (   Depositor contract) has the following unused import:  import \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; import \"@openzeppelin/contracts/utils/Address.sol\"; import \"@openzeppelin/contracts/utils/Context.sol\";  Code corrected  The unused libraries listed above have been removed from the updated code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Unused Imports: FxsLocker", "body": "  The contract FxsLocker has the following unused imports:  import \"@openzeppelin/contracts/math/SafeMath.sol\"; import \"@openzeppelin/contracts/utils/Address.sol\";  Code corrected  The unused libraries have been removed from the updated code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   Unused Imports: sdFXSToken", "body": "  The file sdFXSToken.sol (   sdToken) has the following unused imports:  import \"@openzeppelin/contracts/token/ERC20/IERC20.sol\"; import \"@openzeppelin/contracts/utils/Address.sol\";  StakeDAO - StakeDAO-Frax-veSDT -   25  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedVersion2DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedVersion2                                \fimport \"@openzeppelin/contracts/token/ERC20/SafeERC20.sol\"; import \"@openzeppelin/contracts/utils/Context.sol\";  Code corrected  The unused libraries listed above have been removed from the updated code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.16   createLock Access Control", "body": "  functions   The  modifier onlyGovernanceOrDepositor,  but  the  contract  FxsDepositor  never  calls  these  functions. Specifications covering use cases when these functions are called by the depositor are missing.  createLock,   execute   release   have   and   the   Code corrected  The modifier for the functions listed above has been updated to onlyGovernance.  StakeDAO - StakeDAO-Frax-veSDT -   26  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Admin's Weight on a Gauge Can Be", "body": " Overwritten  The function change_gauge_weight in GaugeController allows the admin to set the weight of any gauge to an arbitrary value. This value can be altered by voters of the gauge. If users vote for the gauge, its weight is increased to a higher value than set by the admin. Furthermore, if users that previously voted the gauge (before the admin called change_gauge_weight) remove their votes, the weight of the gauge is decreased to a lower value than set by the admin.  StakeDAO replied:  The weight, for a gauge already included into the GaugeController won't likely change, if it would happen, we will take care of managing it.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   All Gauges Should Be Trusted", "body": "  The gauges are added into the system by the admin of the GaugeController and they are considered to be non-malicious. If an untrusted gauge is added, then it can exploit a reentrancy vulnerability in the function SdtDistributor._distributeReward which can drain all rewards:  ILiquidityGauge(gaugeAddr).deposit_reward_token(address(rewardToken), sdtDistributed);  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Dust Amounts Not Accounted in veSDT", "body": "  function  veSDT._checkpoint   The  MAXTIME = 4 * 365 * 86400:  ignores   locked   tokens  with  an  amount  smaller   than  def _checkpoint(addr: address, old_locked: LockedBalance, new_locked: LockedBalance):     ...     u_old.slope = old_locked.amount / MAXTIME     ...     u_new.slope = new_locked.amount / MAXTIME     ...  If old_locked.amount or new_locked.amount is less than MAXTIME, the respective slope is set to 0.  StakeDAO - StakeDAO-Frax-veSDT -   27  NoteVersion3NoteVersion3NoteVersion3          \f7.4   Event Can Be Emitted Multiple Times  Several contracts follow the approach commit/accept to set a new admin for the contract. For such updates,  an  event  CommitOwnership/  CommitAdmin  is  emitted  on  the  commit  operation,  and ApplyOwnership / ApplyAdmin event is emitted when the new admin accepts the transfer. However, the accepting functions can be called multiple times, hence the respective events would be emitted for every call. We provide a list of such contracts here:   GaugeController   veSDT   FeeDistributor   LiquidityGaugeV4   veBoostProxy  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Outdated Compiler Version", "body": "  The  compiler  version:  0.8.7  is  outdated  (https://swcregistry.io/docs/SWC-102).  The  compiler  version has the following known bugs.  This is just a note as we do not see any severe issue using this compiler with the current code. At the time of writing the most recent Solidity release is version 0.8.13.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Possible Reentrancy in lockToken for Special", "body": " Tokens  The  function  Depositor.lockToken  performs  a  mint  operation  and  afterwards  emits  an  event  and updates the state variable incentiveToken:  if (incentiveToken > 0) {     ITokenMinter(minter).mint(msg.sender, incentiveToken);     emit IncentiveReceived(msg.sender, incentiveToken);     incentiveToken = 0; }  In the current code base, minter token is always the sdToken which extends the ERC20 standard and does  not  provide  any  callback  functionality  to  the  receiver,  hence  the  code  above  is  not  vulnerable  to reentrancy  attacks.  However,  if  in  the  future  versions  of  the  code  the  minter  token  is  supposed  to support callbacks, e.g., implement ERC777 standard and the mint operation provides an opportunity for reentrancy, the above function would be exploitable.  StakeDAO - StakeDAO-Frax-veSDT -   28  NoteVersion3NoteVersion1NoteVersion3              \f7.7   Reward Distribution Should Be Called Periodically for All Gauges  The  function  SdtDistributor.distributeMulti  works  correctly  only  if  it  is  called  periodically  (at least once a day) for all the gauges, otherwise the following two issues arise:  1. Failing to call distributeMulti for a gauge on a given day means that the gauge does not receive  its  share  of  rewards  for  the  respective  day  and  the  funds  are  locked  in  the  contract. Only the governance can recover these funds via recoverERC20 function.  2. On the time period that overlaps with the weekly event of updating votes for gauges, there is a time window for a malicious user to manipulate the rewards distributed to gauges. For example, if a gauge receives a higher weight for the following week, it is profitable for a malicious user to call  the  function  distributeMulti  when  the  new  weight  is  applied,  and  vice-versa.  This makes  the  accounting  of  rewards  in  SdtDistributor  incorrect  and  potentially  can  prevent legit gauges from receives any reward.  As  stated  in  the  System  Overview,  StakeDAO  should  run  a  bot  that  guarantees  the  function  is  called periodically and correctly for all gauges to prevent the issues above.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   Tautology in if Condition", "body": "  The function setFees in contracts Depositor and FxsDepositor verifies that _lockIncentive is greater than or equal to zero, however, as it is a unsigned integer, this condition will always hold.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   ClaimRewards Functions Should Be Called", "body": " Only With Enabled Gauges  The functions claimRewards and claimAndLock take a list of gauges as a parameter and check that each of them is enabled. If one of the gauges in _gauges is disabled by the governance, the functions revert.  Hence,  the  caller  should  always  guarantee  that  that  all  gauges  passed  into  the  functions  are enabled.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.10   safeApprove Usage", "body": "  The  contract  FxsDepositor  (Depositor  in  given to the gauge. As explained in the specifications of the function, safeApprove is deprecated.  )  uses  safeApprove  to  update  the  allowance  /**  * @dev Deprecated. This function has issues similar to the ones found in  * {IERC20-approve}, and its usage is discouraged.  *  * Whenever possible, use {safeIncreaseAllowance} and  StakeDAO - StakeDAO-Frax-veSDT -   29  NoteVersion3NoteVersion1NoteVersion3NoteVersion1Version2              \f * {safeDecreaseAllowance} instead.  */  StakeDAO - StakeDAO-Frax-veSDT -   30  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Redemption Blocked When No Rate Entry at", "body": " Maturity Exists  After  the  shutdown  of  the  ClaimFee  contract,  users  may  exchange  their  claim  balance  for  DAI  using cashClaim(),  if  it  has  a  maturity  after  the  closure  timestamp.  However,  this  requires  a  valid  entry  in ratio[ilk][maturity] which must be set manually for each ilk and maturity by the governance.  Since the function slice allows users to split their claim fee, many arbitrary maturity timestamps may exist.  If  the  user  still  holds  all  segments  up  to  the  maturity,  they  may  be  able  to  merge  them  using function merge(). However, these segments may not be available anymore: Individual segments may have  been  redeemed  already,  or  be  unavailable  to  the  user  as  they  have  been  transferred  using  the function moveClaim.  Overall, users may be blocked and unable to redeem their claim fee.  Risk accepted:  Deco accepts the risk that rate entries might be missing for maturity timestamps. They pledge to provide appropriate support to ensure all maturities have a valid ratio set in case of emergency shutdown.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Gate1 Withdraw Timestamp", "body": "  MakerDAO - Claim Fee Maker -   10  DesignCorrectnessCriticalHighMediumRiskAcceptedLowAcknowledgedRiskAcceptedRiskAcceptedDesignMediumVersion1RiskAcceptedDesignLowVersion1Acknowledged                  \fIn the Gate1 constructor, the withdrawAfter timestamp is set. The only check made using this value is to see if it is in the past. Thus, not setting the value at all would save gas and yield the same results.  Acknowledged:  The additional storage write is a one-time cost during deployment.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Leftover Claims", "body": "  ClaimFee.collect()  reimburses  the  stability  fee  accrued  between  the  issuance  and  collect timestamp. If the collect timestamp is not equal to the maturity, a new claim fee is issued from the collect timestamp to the maturity.  In  general,  it's  very  unlikely  that  a  valid  rate  is  stored  for  the  maturity  timestamp:  Apart  from  values manually inserted by the governance, rates stored through function snapshot() can only exist for valid block timestamps. The maturity of a claim fee could have been set months in advance upon issuance or the claim fee could have been sliced in various ways. Hence, most of the time, it's not possible to collect up to the maturity timestamp. This design will result in minting many small \"leftover\" claims.  Risk accepted:  There  will  be  standardized  maturity  timestamps,  e.g.the  first  day  of  the  month  at  12:00:00  UTC. Additionally, it is planned to run bots that regularly take snapshots to ensure that any leftover claims are sufficiently small to be negligible. Lastly, users will be warned against using functionality which creates non-standard maturity timestamps.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Slice at Timestamp With No Rate", "body": "  The function slice allows users to split their claim at a certain timestamp. However, it is possible that the  timestamp  at  which  they  split  their  claim  does  not  have  a  valid  rate.  Unless  they  later  merge  their claims again, or the governance adds a valid rate for the split timestamp, it may not be possible for the user to redeem the full value of the claims.  Risk accepted:  As stated previously, it is intended to have standardized maturity timestamps so that users can know in advance  which  timestamps  will  have  valid  rates.  Using  such  timestamps,  users  are  able  to  split  their claims  without  incurring  any  losses.  Should  the  need  arise  there  are  two  pathways  to  mitigate  the situation: Governance may insert snapshots at timestamp or users can use activate() to activate a claim  fee  balance  at  a  timestamp  with  a  rate  set.  Note  that  yield  earned  between  issuance  and  the activation timestamp becomes uncollectable and is permanently lost.  MakerDAO - Claim Fee Maker -   11  DesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  Increasing VAT Debt After Shutdown, After thaw()   -Severity Findings   Comments Regarding vow.heal()    Governance Can Burn From Users    Gate1.heal()   totalSupply Mapping Not Updated   -Severity Findings   Address of VOW    Duplicate Check    Maturity in the Past    Unused Constants and Function    Various Event Issues   this Keyword in initializeIlk   0  1  4  6  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Increasing VAT Debt After Shutdown, After ", "body": " thaw()  ClaimFee generates the required DAI by calling vat.suck() through the Gate1 contract which acts as a safeguard to enforce a limit on the maximum amount of DAI that can be generated by adding bad debt to the system.  vat.suck() is independent of the system status, notably whether the VAT is live or not. Hence, the call to  vat.suck()  will  add  more  bad  debt  and  generate  DAI  when  the  VAT  is  in  shutdown.  This  occurs even  after  end.thaw()  has  been  called  in  step  6  of  the  shutdown,  which  fixes  the  total  outstanding supply of DAI.  The Gate1 contract's purpose is to limit access of the ClaimFee contract in the core maker system: In order to draw bad debt using vat.suck() one needs to be a ward in the VAT to be able to pass the auth modifier. To avoid giving full privileges to the external ClaimFee contract, an intermediary contract Gate1 is introduced, which will be given the privileged role in the VAT. The code of the Gate1 contract enforces limitations in order to limit the risk for the core system. In its current state, the Gate1 contract is missing restrictions to prevent drawing more debt when the VAT is in shutdown.  For further reference:  MakerDAO - Claim Fee Maker -   12  CriticalHighCodeCorrectedMediumSpeci\ufb01cationChangedSpeci\ufb01cationChangedRiskAcceptedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedAcknowledgedCodeCorrectedDesignHighVersion1CodeCorrected               \fhttps://github.com/makerdao/dss/blob/master/src/end.sol#L410 https://docs.makerdao.com/smart-contract-modules/shutdown/end-detailed-documentation#6.-thaw https://github.com/makerdao/dss/blob/master/src/vat.sol#L230    A check for the condition VatAbstract(vat).live() == 1 was added to the accessSuck function in the ClaimFee contract. This prevents the debt from increasing after the VAT is in shutdown.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Comments Regarding vow.heal()", "body": "  One of the annotations of the Gate1 contract reads:   does  not  execute  vow.heal  to  ensure  the  dai  draw  amount  from  vat.suck  is  lower  than  the  surplus buffer currently held in vow  There is the following comment in Gate1.accessSuck():  // call suck to transfer dai from vat to this gate contract try VatAbstract(vat).suck(address(vow), address(this), amount_) {     // optional: can call vow.heal(amount_) here to ensure     // surplus buffer has sufficient dai balance      // accessSuck success- successful vat.suck execution for requested amount     return true; } catch {   vow.heal() uses surplus DAI of the VOW (= surplus buffer) to repay bad debt of the VOW at the  VAT   vat.suck() generates DAI by creating bad debt assigned to the VOW  Vat.suck() simply adds bad debt, there is nothing ensuring the amount of DAI drawn is lower than the surplus buffer.  Specification changed:  The annotation and comments were removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Governance Can Burn From Users", "body": "  The function ClaimFee.withdraw() allows the privileged ward role (the governance) to burn a claim of any user. However, the function's annotation contradicts this as it states the following:  /// Withdraws claim balance held by governance before maturity /// @dev Governance is allowed to burn the balance it owns  MakerDAO - Claim Fee Maker -   13  CorrectnessMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1Speci\ufb01cationChangedRiskAccepted                  \fFurthermore, this function can also withdraw/burn a claim balance upon/after maturity.  Risk accepted:  The annotation was changed to reflect the functionality. The risk of allowing the governance to burn any user's  balance  is  accepted,  as  they  plan  to  add  additional  contracts  with  functionalities  that  require burning claim fee balances.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Gate1.heal()", "body": "  Gate1.heal() is annotated with:  // Access to vat.heal() can be used appropriately by an integration  It simply calls vat.heal():  function heal(uint rad) external {     VatAbstract(vat).heal(rad); }  Vat.heal() heals bad debt of msg.sender()  function heal(uint rad) external {     address u = msg.sender;     sin[u] = sub(sin[u], rad);     dai[u] = sub(dai[u], rad);     vice   = sub(vice,   rad);     debt   = sub(debt,   rad); }   The Gate1 contract however doesn't accrue bad debt when generating DAI: Gate1 only draws bad debt using vat.suck(address(vow), address(this), amount_). The bad debt is assigned to the VOW, only the generated DAI is assigned to the Gate1 contract:  function suck(address u, address v, uint rad) external auth {     sin[u] = add(sin[u], rad);     dai[v] = add(dai[v], rad);     vice   = add(vice,   rad);     debt   = add(debt,   rad); }  If  the  Gate1  contract  doesn't  accrue  bad  debt  outside  of  its  own  functionality,  the  function  has  no purpose.  Furthermore,  if  Gate1  does  indeed  accrue  bad  debt,  the  intended  backup  DAI  balance  may  be compromised by the fact that anyone could call heal() and use some of this DAI balance to heal the bad debt.  MakerDAO - Claim Fee Maker -   14  DesignMediumVersion1CodeCorrected        \f  The heal() function of the Gate1 contract was removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   totalSupply Mapping Not Updated", "body": "  The ClaimFee contract has a totalSupply mapping which should track the total supply of claims per ilk. However, neither the mintClaim nor burnClaim functions update the mapping.    The totalSupply mapping is now updated accordingly in the mintClaim and burnClaim functions.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Address of VOW", "body": "  In the Gate1 Contract, both the VOW and the VAT addresses are stored as immutables. In contrast, the ClaimFee  contract  stores  both  addresses  in  storage  without  implementing  functionality  to  update  the address.  As  reading  from  storage  is  expensive,  variables  set  only  during  deployment  may  be  changed  to immutables. During the deployment, all immutable values are inserted into the bytecode of the deployed contract code. Hence, they can be accessed during execution without the need for an expensive SLOAD operation.  that   there  are  ongoing  discussions   Note  to  use  a  proxy: https://github.com/makerdao/dss/pull/241  As  such,  it  may  be  necessary  to  have  a  mutable  storage variable for its address.  to  change   the  VOW     The VAT address was made immutable in the ClaimFee contract, and the VOW address was removed. Instead, the VOW address is dynamically queried from the Gate1 contract when necessary.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Duplicate Check", "body": "  The function issue checks the following condition:  require(initializedIlks[ilk] == true, \"ilk/not-initialized\");  However,  the  mintClaim  function  checks  the  very  same  condition  and  hence  the  check  in  issue  is unnecessary.    The duplicate check was removed.  MakerDAO - Claim Fee Maker -   15  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f6.8   Maturity in the Past  The function issue places the following requirement on the maturity timestamp:  require(         issuance <= latestRateTimestamp[ilk] && latestRateTimestamp[ilk] <= maturity,         \"timestamp/invalid\"     );  However,  there  is  no  guarantee  that  the  value  latestRateTimestamp[ilk]  is  recent.  As  it  makes little  sense  to  issue  a  claim  with  a  maturity  in  the  past,  one  could  instead  check  that  the  maturity  is later than the current block timestamp.    The issue function now ensures the condition block.timestamp <= maturity.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Unused Constants and Function", "body": "  There are a few constants and a function that are unused or could otherwise be omitted.  1. The  MAX_UINT   constant   could  be   replaced  with   the  built-in  Solidity   constant:  type(uint256).max.  2. The constant RAD is never used.  3. The function wmul is never used.    The MAX_UINT constant was replaced as suggested; RAD and wmul were removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Various Event Issues", "body": "  There are a few functions in which events should be emitted or the event parameters should be indexed.  1. In  the  ClaimFee  constructor,  no  Rely  event  is  emitted  when  the  message  sender  is  added  as  a  ward.  2. No event is emitted by the close function. This is an important change regarding the functionality  of the contract and hence should emit an event.  3. No event is emitted by the calculate function. Again, this is an important storage change which allows  users  to  cash  out.  Indexing  the  events  would  allow  users  to  search  for  specific  ilks  and maturities.  4. The Kiss and Diss events in the Gate1 contract are not indexed.  5. The NewApprovedTotal and Draw events in the Gate1 contract could have indexed amounts.  MakerDAO - Claim Fee Maker -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedAcknowledged                          \f  1. A Rely event emission was added to the ClaimFee constructor.  2. A Closed event was added and is now emitted by the close function.  3. A NewRatio event was added and is now emitted by the calculate function.  4. The address parameter in the Kiss and Diss events in the Gate1 contract are now indexed.  Acknowledged:  5. The  NewApprovedTotal  event  was   indexed accessSuckStatus parameter, but the amount parameter is not indexed as Deco did not see the need for it.  removed.  The  Draw  event  now  has  an   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   this Keyword in initializeIlk", "body": "  The initializeIlk function makes the following call to the snapshot function:  function initializeIlk(bytes32 ilk) public auth {     // ...     this.snapshot(ilk); // take a snapshot }  Calling  a  function  in  this  way  incurs  an  extra  cross-contract  call.  In  order  to  make  an  internal  call,  the snapshot  function  would  have  to  be  declared  public  instead  of  external  and  the  this  keyword removed.    In  initializeIlk() has been updated accordingly.  the  snapshot   functions  visibility  has  been  changed   to  public,   the  call   in  MakerDAO - Claim Fee Maker -   17  DesignLowVersion1CodeCorrectedVersion3          \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Circumvent withdrawAfter Restriction", "body": "  Gate1  features  a  restriction  for  function  withdrawDai().  The  privileged  role  able  to  pass  the  auth modifier can only call withdrawDai() successfully when the withdrawal condition is satisfied:  bool withdrawalAllowed = (block.timestamp >= withdrawAfter);  The  privileged  role  able  to  pass  the  auth  modifier  can  always  add  any  address  as  a  bud  using  the function  kiss().  Such  an  account  can  then  pass  the  toll  modifier  and  successfully  call  suck()  / draw()  and  draw  DAI.  If  the  call  to  vat.suck()  is  unsuccessful  (e.g.  if  the  limit  has  already  been reached) this allows to withdraw the backup DAI balance of the contract.  Code partially corrected:  While  it  is  no  longer  possible  to  add  a  bud  when  the  withdrawal  condition  is  not  satisfied,  an  already existing bud would still be able to circumvent the restriction. For example, after the contract is created, a bud  could  be  added,  and  only  then  withdrawAfter  would  be  set  to  a  timestamp  in  the  future. Alternatively,  one  could  wait  for  withdrawAfter  to  be  in  the  past,  then  add  a  bud  and  set withdrawAfter  to  a  future  timestamp.  Therefore,  a  ward  is  still  able  to  withdraw  the  backup  DAI balance of the contract.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Discrepancy Between Reimbursed Amount", "body": " and Actual Stability Fee  The  stability  fee  paid  in  in  the  Maker  system  is  based  on  the  rate  increase  between  when  taking  and repaying the debt.  ClaimFee reimburses the stability fee based on stored snapshots of the rate.  There are corner cases where the rate stored may not match the actual rate debt was taken/repaid for at this  timestamp  and  hence  the  reimbursed  amount  of  DAI  is  not  the  amount  of  stability  fee  paid  by  the user.  Storing  the  current  rate  in  ClaimFee  does  not  trigger  the  update  of  the  rate  in  the  Maker  system (jug.drip()).  A  later  transaction  in  the  very  same  block  may  trigger  jug.drip()  and  further transactions modifiying a debt position of this ilk use the new rate.  Consider the following scenarios which must happen within the same block:  1.   ClaimFee.snapshot() is executed and rate A is stored   Jug.drip() is executed -> The rate is udpated to A+x   The user repays debt in the Maker system at rate A+x  MakerDAO - Claim Fee Maker -   18  NoteVersion1CodePartiallyCorrectedNoteVersion1RiskAccepted          \fWhen the user calls collect() on his claim fee balance he is reimbursed based on the \"old\" rate stored and receives less DAI than actual stability fee paid.  2.   User takes debt in the Maker system at rate A   Jug.drip() is executed -> rate is udpated to A+x   ClaimFee.snapshot() is executed and rate A+x is stored  Similarly,  the  user  may  not  be  compensated  for  the  full  stability  fee  in  this  scenario.  Note  that normally, with the stability fee based on the rate/time, the user has an incentive to increase the rate first using jug.drip() before taking on debt. However, unaware users with the impression that claim fee covers their stability fee may not do this.  We assume that jug.drip() is executed frequently and the resulting rate increase is small enough so the discrepancies arising in scenarios as described above can be neglected.  Risk accepted:  The risk is accepted based on the assumption that the rate increases are small enough to be negligible.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   No Connection Between ClaimFee and Actual", "body": " Debt  There  is  no  connection  between  an  issued  claim  fee  and  debt  in  the  VAT.  ClaimFee  reimburses  the stability fee its amount (art) would have accrued.  Note that the amount of claim fees issued per ilk should not exceed the amount of actual debt per ilk otherwise more stability fee is reimbursed than is actually accrued by the system.  Deco responded:  \u2013 Our goal is to help the Maker protocol find users who want to hold a vault open for the entire term of the claim fee so that the protocol can derive the benefits of a sticky user and collect the fixed-rate revenue upfront without having to make any re-imbursements later to these users from the revenue generated by variable-rate vaults held by others. We want to ensure claim fee supply stays matched to the vaults who signed up for fixed-rate debt at the issuance date.  \u2013 ClaimFee has a transfer function which already allows a vault owner who has claim fee balance and no longer wants to use it to transfer it to another regular vault owner. This would keep claim fee balance less than ilk debt and not trigger the excess reimbursement issue.  \u2013  We  originally  planned  to  avoid  reimbursements  that  exceed  stability  fee  accrual  to  the  system  when debt level drops directly at the urn that was supposed to use the claim fee balance, by combining both the urn and claim fee balance and routing all its usage through a CDP Manager style contract which can create and manage a fixed-rate vault. This CDP Manager can have the required state transitions to keep both debt and claim fee balance of the vault in sync over its lifetime.  \u2013  We  now  plan  to  design  and  deploy  a  much  simpler  and  standalone  \u201cLiquidation  Penalty\u201d  contract instead  of  the  modified  CDP  Manager.  Liquidity  Penalty  contract  can  withdraw  an  amount  of  claim-fee balance  (burn  it)  held  by  a  user  address  to  match  any  reduction  in  debt  on  a  regular  vault  the  same address  holds.  We  don\u2019t  want  addresses  holding  claim  fee  balances  standalone  without  also  holding vaults of the collateral type between the issuance and maturity timestamps of the claim fee balance. This liquidation  penalty  contract  could  re-imburse  the  claim  fee  balance  after  taking  a  haircut  on  its  current  MakerDAO - Claim Fee Maker -   19  NoteVersion1    \fvalue(let\u2019s say 75%, make it attractive for fixed-rate vault owners to abandon their claim fee balance, but not  set  it  too  high  at  like  100%  to  ensure  no  reimbursement  but  force  claim  fee  holders  to  find  buyers among other vault owners to avoid loss of value) to ensure claim fee in circulation stays below the debt held in urn at all times, thereby also solving the issue at the ilk level.  MakerDAO - Claim Fee Maker -   20  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Curve Price Oracle Manipulation", "body": "  When estimating the value of a Curve LP token, get_virtual_price() is queried which describes the value increase through fees since the pool was created. The function may return a manipulated value for some  pools  where  transfers  have  callbacks  or  other  callbacks  to  users  are  made  (e.g.  ETH,  ERC677, ERC223, ERC777, ...) as the state of the pool may be inconsistent during the callback.  Due to the limiter of the Pricefeed which enforces that the price remains within a certain bound, Gearbox is largely protected hence the low severity rating. Nevertheless, the manipulated state of the Curve pool could be detected (at this point the pool's reentrancy lock is set) by the pricefeed.  Curve  is  aware  of  this  issue  and  new  pools  are  no  longer  affected.  Existing  pools  however  remain vulnerable. This issue is currently being addressed and affects various integrations. As of today not all have  been  fixed  hence  please  treat  this  issue  confidential  for  the  time  being.  Full  public  disclosure  is expected to be released soon.  Gearbox Protocol responded as follows:  Due to the LP price limiters, the attacker cannot practically inflate the asset value more than 2% of its real value. This discrepancy can be included in the asset's LT - the LT represents the maximal asset price drop during the liquidation period, but is not dependent on whether this price drop comes from actual market conditions, or price manipulation within a bound known in advance.  Gearbox Protocol - Gearbox V2 -   13  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedCodePartiallyCorrectedSecurityLowVersion1Acknowledged             \f6.2   Enable Supported Token on Any CreditAccount  CreditFacade.addCollateral() allows anyone to deposit funds on behalf of another credit account owner. Using this function has a different effect compared to simply transferring the funds to the credit account directly: It additionally enables the token for this credit account.  This may be a risk factor: If there is ever a bad token supported by a CreditManager, this immediately affects  all  CreditAccounts  of  this  CreditManager.  Users  are  not  safe  when  they  don't  hold  the  affected token.  Code partially corrected:  CreditFacade.addCollateral()  is  now  only  allowed  for  users  for  which  are  authorized  in  the transferAllowed mapping.  Gearbox Protocol notes:  This change should address an attacker sending a bad token to other users in order to break health factor calculation. However, there still remains a narrow vector whereas a token that was already on Credit Account is broken and reverts on balanceOf() (for example, stETH and SNX use proxies, and can be potentially changed to a broken implementation contract).  Currently,  this  is  not  addressed,  however,  should  this  transpire,  CreditFacade  could  be  quickly updated  to  ignore  this  token  (or  error-handle)  in  calcTotalValue(),  which  would  allow  to  liquidate affected positions.  Gearbox Protocol - Gearbox V2 -   14  SecurityLowVersion1CodePartiallyCorrected        \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  3  22  -Severity Findings  -Severity Findings  -Severity Findings   Multicall Actions During Pauses    Pricefeed of Oracle May Be Updated    Unable to Handle Missing Return Value   -Severity Findings   CumulativeDrop Calculation Rounding   twvUSD Contains Value in Underlying    Free Flashloan upon Open/Close    Adapters Ignore User Input    Add Token Without Liquidation Threshold    Checking for Valid Token Indices for Curve Pools Is Too Loose    Credit Accounts Give Very High Approval to Contract    CreditAccount Calls approve() on Unsupported Token    Curve Registry    CurveV1 Adapters: TokenOut Might Not Be Enabled at CreditAccount    Duplicate Error Code Used   Incorrect Comment After Refactoring   Incorrect Descriptions    Outdated Function Description    PriceOracle: Unused Timestamp    Read-only Reentrancy    Redundant Event Emission    Redundant Initialization    Reentrancy Into CreditFacade    Sanity Check of New Pricefeed    Unused allowedContractsSet    YearnV2Adapter: Different Behavior of Functions   Gearbox Protocol - Gearbox V2 -   15  CriticalHighMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedAcknowledgedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected       \f7.1   Multicall Actions During Pauses  During  a  liquidation,  the  liquidator  can  call  CreditFacade._multicall.  When  this  happens,  the ownership  of  the  credit  account  is  temporarily  passed  to  the  CreditFacade  to  allow  it  to  properly interact with the adapters. By using this feature, liquidators can swap tokens of the credit account to the underlying and, thus, they don't have to supply the underlying by themselves. This is a useful feature for any  liquidator,  even  for  the  emergency  ones.  During  pauses,  however,  the  functionality  of  the  credit manager is limited. One of the limitations is that CreditManager.transferAccountOwnership fails. This means that the liquidators cannot make any calls to the adapters.    The CreditManager now allows multiple calls to be made while the system is paused as long as the call is related to an emergency liquidation (whenNotPausedOrEmergency).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Pricefeed of Oracle May Be Updated", "body": "  PriceOracle._addPriceFeed() is annotated with  /// @dev Sets price feed if it doesn't exist. If price feed is already set, it changes nothing /// This logic is done to protect Gearbox from priceOracle attack /// when potential attacker can get access to price oracle, change them to fraud ones /// and then liquidate all funds  The function does not enforce this, a second call to this function allows to update the pricefeed for the token.  Specification changed:  The description was erroneous and it was intended for the function to update the existing price feed. The description was updated to reflect that.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Unable to Handle Missing Return Value", "body": "  to  Gearbox  V1  safeApprove()  has  been  replaced  by  approve()  function Compared  CreditAccount.approveToken. The interface inherited expects a boolean return value as defined in the ERC-20 specification. However, there are tokens such as USDT or OMG which do not adhere to this specification and have no return value on approve() and transfer.  in   Calling CreditAccount.approveToken() with these tokens will revert as the function call does not return the expected return value. Hence it's not possible for the new credit accounts to give approval on such tokens.    Gearbox Protocol - Gearbox V2 -   16  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChangedDesignMediumVersion1CodeCorrected                      \fThe  new  CreditAccount  implementation  no  longer  features  an  approveToken  function.  Approvals through  CreditManager.approveCreditAccount()  now  use  the  execute  function  of  the CreditAccount  which  allows  arbitrary  calls.  This  works  for  both,  the  new  implementation  and  the  old already deployed credit accounts.  If present, the returned boolean is checked. In case the approval is unsuccessful the code attempts to reset the approval to 0 before attempting the to approve the intended amount. This accounts for some token implementations enforcing this.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   CumulativeDrop Calculation Rounding", "body": "  The new fast collateral check is described as follows:  The fast check now ensures that the HF has not decreased significantly, rather than pure collateral value. The decrease is also tracked cumulatively across multiple swaps (hence the sum) - as soon as liquidationFee of cumulative loss is occurred, a full collateral check is performed and the cumulative sum is reset.  The computation is done as follows:  // compute cumulative price drop in PERCENTAGE FORMAT uint256 cumulativeDrop = PERCENTAGE_FACTOR -     ((amountOutCollateral * PERCENTAGE_FACTOR) / amountInCollateral) +     cumulativeDropAtFastCheck[creditAccount]; // F:[CM-36]  ...  if (cumulativeDrop <= slot0.feeLiquidation) {     cumulativeDropAtFastCheck[creditAccount] = cumulativeDrop; // F:[CM-36]     return; }  PERCENTAGE_FACTOR is 10`000. This allows precision up to 2 decimals. Resulting rounding errors per division might be up to 0.009999% Drops up to 0.009999...% per fast check are not detected nor added to cumulativeDropAtFastCheck. This may be done repeatedly.  Hence the requirement  The decrease is also tracked cumulatively across multiple swaps (hence the sum) - as soon as liquidationFee of cumulative loss is occured, a full collateral check is performed  strictly  speaking  does  not  hold.  Other  protocols,  e.g.  Maker  work  with  significant  higher  precision internally.  Is the resulting precision sufficient / can the potential loss be tolerated?  The new fast check compares cumulativeDrop and feeLiquidation. While both are percentages, they are different: The feeLiquidation will be taken from the actual total value while the cumulative drop has  been  calculated  taking  into  account  the  liquidation  thresholds.  Given  the  liquidation  thresholds  are strictly lower than 100% there is a safety margin before the system takes a loss.    The precision of the calculation was increased in RAY. The relevant code snippet now looks like this:  Gearbox Protocol - Gearbox V2 -   17  CorrectnessLowVersion3CodeCorrected        \f// compute cumulative price drop in WAD FORMAT        uint256 cumulativeDropRAY = RAY -            ((amountOutCollateral * RAY) / amountInCollateral) +            cumulativeDropAtFastCheckRAY[creditAccount]; // F:[CM-36]         // if it drops less that feeLiquiodation - we just save it till next check        // otherwise new fullCollateral check is required        if (            cumulativeDropRAY <=            (slot0.feeLiquidation * RAY) / PERCENTAGE_FACTOR        ) {            cumulativeDropAtFastCheckRAY[creditAccount] = cumulativeDropRAY; // F:[CM-36]            return;        }  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   twvUSD Contains Value in Underlying", "body": "  The  public  function  CreditFacade.calcCreditAccountHealthFactor()  calculates  the  health factor in percent:  function calcCreditAccountHealthFactor(address creditAccount)     public     view     override     returns (uint256 hf) {     (, uint256 twvUSD) = calcTotalValue(creditAccount); // F:[FA-42]     (, uint256 borrowAmountWithInterest) = creditManager     .calcCreditAccountAccruedInterest(creditAccount); // F:[FA-42]     hf = (twvUSD * PERCENTAGE_FACTOR) / borrowAmountWithInterest; // F:[FA-42] }  The  naming  of  the  variable  twvUSD  is  misleading  since  the  total  weighted  value  returned  by calcTotalValue()  is  in  the  underlying.  Note  that  it  has  to  be  in  the  underlying  for  the  calculation hf = (twvUSD * PERCENTAGE_FACTOR) / borrowAmountWithInterest to be correct.    twvUSD was renamed into twv.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Free Flashloan upon Open/Close", "body": "   introduced a protection which prevents free flashloans by increasing/decreasing debt within the same multicall. A variable within _multicall() tracks whether debt has already been increased in this call and if true prevents reducing debt.  This prevention however is not effective in a corner case:   When  a  new  credit  account  has  just  been  opened  through  openCreditAccountMulticall()  debt can be reduced within the multicall (free flashloan).  Gearbox Protocol - Gearbox V2 -   18  CorrectnessLowVersion3CodeCorrectedDesignLowVersion2CodeCorrectedVersion2                \f  The  internal  variable  tracking  whether  debt  has  already  been  increased  is  now  an  additional  input parameter for _multicall(). This allows the calling function openCreditAccountMulticall() to pass the information that debt has already been increased and hence the prevention also works in this corner case described in the issue above.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Adapters Ignore User Input", "body": "  The design of the Adapters is that they implement the same interface as the contract they connect to.  Illustrated  with  the  following  examples  taken  from  the  YearnV2  adapter  this  issue  highlights  that  user inputs are sometimes silently ignored:  /// @dev Deposit credit account tokens to Yearn /// @param amount in tokens function deposit(uint256 amount, address)     external     override     nonReentrant     returns (uint256) {     address creditAccount = creditManager.getCreditAccountOrRevert(         msg.sender     ); // F:[AYV2-4]      return _deposit(creditAccount, amount); // F:[AYV2-7,12] }  deposit() allows the user to specify the address of the recipient of the yVault shares. Obviously, this is not allowed as the funds must remain with the CreditAccount. The implementation uses \"safe defaults\", and ignores the user input. This behavior should be documented.  A more critical example is function withdraw and parameter maxLoss. The user may intend to set the acceptable maxLoss to a lower value. The implementation of the adapter however ignores this value and proceeds with the default. The result may be unexpected for the user.  function withdraw(     uint256 maxShares,     address,     uint256 maxLoss ) public override nonReentrant returns (uint256 shares) {     address creditAccount = creditManager.getCreditAccountOrRevert(         msg.sender     ); // F:[AYV2-4]      return _withdraw(creditAccount, maxShares); // F:[AYV2-9,14] }  Gearbox Protocol - Gearbox V2 -   19  DesignLowVersion1CodeCorrected        \f  There  is  now  a  withdraw()  override  that  correctly  passes  maxLoss  to  the  corresponding withdraw(uint256,address,uint256)  internal function  _withdrawMaxLoss function.  the  Yearn  vault,  using  an   in   Note: There are other adapter functions where the inputs are ignored - this happens in 2 cases:   The  adapter  passes  unmodified  msg.data  to  the  target  contract,  and  doesn\u2019t  need  some  of  the  inputs for adapter-specific operations;   The  input  is  the  recipient  address,  which  is  always  replaced  by  the  credit  account  address  (same  cases as the deposit(uint256,address) function described in the original issue).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   Add Token Without Liquidation Threshold", "body": "  Configurators may add a token to a credit manager using the function addTokenAllowedList. Initially, this token has a liquidation threshold of zero, the configurator must set a liquidation threshold using the function setLiquidationThreshold.  When no liquidation threshold is set for a token, the balance of this token that the credit accounts hold doesn't count towards the weighted value.    The  function  in  question  is  now  called  CreditConfigurator.addCollateralToken().  It  now accepts  uint16  liquidationThreshold  as  input  and  calls  _setLiquidationThreshold() immediately after adding the token. _setLiquidationThreshold() checks that the passed LT value is larger than 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   Checking for Valid Token Indices for Curve", "body": " Pools Is Too Loose  When translating the token index required in Curve pools to the token as known to Gearbox, the following require is executed:  function _get_token(int128 i) internal view returns (address) {     require(i <= int128(uint128(N_COINS)), \"Incorrect index\");     return (i == 0) ? token0 : token1; }  This  check  passes  for  invalid  values  like  negative  indices  and  exactly  one  index  too  high,  e.g.  i  =  2 passes for pools with N_COINS = 2 like in this example, although only i = 0 and i = 1 should pass. While  in  our  understanding  Curve  will  fail  when  called  with  invalid  tokens,  it  is  safer  to  ensure  that  no wrong token indices can be passed to not have to rely on Curve preventing execution with those indices.    Gearbox Protocol - Gearbox V2 -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fThe code has been refactored, the __getToken() function in CurveV1AdapterBase is strict and reverts for invalid indices.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.10   Credit Accounts Give Very High Approval to", "body": " Contract  Credit accounts give very high (25% of uint96.max) approval to the contracts adapters connect to. This approval remains even when the credit account is returned to the factory or being assigned to the next user.  Giving  excess  approvals  introduces  a  risk:  The  third  party  system  must  be  fully  trusted  and reviewed  that  these  approvals  cannot  be  accessed  when  not  called  by  the  holder  of  the  funds.  If  this does not hold, e.g. due to a bug, the funds of credit accounts are at risk.  One  https://medium.com/gelato-network/sorbet-finance-vulnerability-post-mortem-6f8fba78f109  example   where   such   loss   bug   led   to   a   of   funds:  Gearbox uses a trust-minimized approach by validating effects of adapters for token transfers instead of relying on correct execution. The recently discovered UniswapV3 bug would also have been prevented in case targeted allowances are given. Infinite approvals can undermine this approach. Approving only the necessary  funds  each  time  also  saves  gas  as  the  increased  allowance  is  reset  to  the  original  value, resulting in a refund which is significantly larger than the overhead cost of calling into a \"hot\" contract.    Gearbox Protocol responded:  For more fine-grained security configuration, there are now 2 allowance models:  1. Max allowance For highly-trusted protocols (such as Curve or Uniswap) approvals are always set to  type(uint256).max.  For  swap-like  operations  the AbstractAdapter._executeMaxAllowanceFastCheck()  function.  After  each  operation,  the system  returns  allowance  to  the  maximal  possible  value.  This  significantly  improves  UX  for WalletConnect usage, since users wouldn\u2019t have  is  encapsulated   logic   this   in   to approve tokens in the Uniswap/Curve interface after each transaction.  2.  Limited  allowance  For  other  protocols,  approvals  are  set  to  the  available  balance  on  the  Credit Account  before  the  operation,  and  then  reset  to  1  in  the  end.  This  would  prevent  an  attacker  from withdrawing assets from Credit Accounts, if they manage to compromise the target contracts.  and   safe   fastCheck  Maximal  AbstractAdapter._executeMaxAllowanceFastCheck()  AbstractAdapter._safeExecuteFastCheck(),  fullCollateralCheck operations have to be done manually within adapter functions.  respectively.   allowances   operations   for   are   set   Allowances   in and for  This mitigation still allowed to be circumvented in the following way:  The limited allowance approach for semi-trusted third-party contracts might be circumvented: Using CreditFacade.approve() the current owner of a credit contract may approve a supported token for any supported target contract. Such an approval remains when the credit account is returned to the factory and still exists when the credit account is assigned to the next user.  Gearbox Protocol further improved the security in the following way:  In order to improve the security of the CreditFacade.approve() function, upgradeableContracts was added  to  the  Credit  Facade.  This  is  a  list  of  contracts  with  practices  potentially  detrimental  to  Gearbox Protocol - Gearbox V2 -   21  SecurityLowVersion1CodeCorrected        \fsecurity.  This  includes  upgradeable  contracts,  contracts  that  can  make  arbitrary  calls  (even  with admin-only access), etc.  approve  now  reverts  when  called  on  a  contract  in  upgradeableContracts.  Currently,  the  Gearbox team  intends  to  include  only  Lido  into  the  list,  as  no  other  supported  contracts  appear  to  be upgradeable, or able to call transferFrom on CA assets.  To additionally secure assets accounts that don't belong to the attacker but have allowances (e.g., some non-zero allowances may remain after previous use), the first iteration of the Universal Adapter was implemented, which allows users to revoke all allowances on a newly-opened account.  Note:  CreditFacade.approve  is  mainly  used  to  support  WalletConnect  with  dApp  frontends.  Most frontends require non-zero allowance of a token to the contract, and do not allow any further action before  approve  is  called.  Thus,  a  function  to  set  allowance  separately  from  adapter  actions  is required.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.11   CreditAccount Calls approve() on", "body": " Unsupported Token  CreditManager.approveCreditAccount() approves token transfers on behalf of a credit account. The function calls the CreditAccount which then executes a call to the given tokens approve() function.  The function is annotated with:  /// @dev Approve tokens for credit account. Restricted for adapters only  Note that the comment is incorrect as it can also be called by the CreditFacade.  While  CreditFacade.approve()  does  check  whether  the  token  to  be  approved  is  supported,  the adapters  generally  do  not  check  this.  CreditManager.approveCreditAccount()  itself  does  not perform such a check on the given token address.  The lack of token validation may be used in an exploit.  Note the following should also be taken into account:   CreditAccounts  may  receive  other  tokens  e.g.  as  an  airdrop.  How  should  users  be  able  to  access/trade them?   A token may have been \"forbidden\". Does this only apply to a new incoming asset or does this also  block usage as an outgoing asset?    Token being supported is now checked in CreditManager.approveCreditAccount(). This means that the token will be verified regardless of whether the call comes from the CreditFacade or an adapter.  On additional notes:  CreditFacade  now  has  an  enableToken()  function  which  allows  the  Credit  Account  owner  to  enable any  token  and  include  it  in  the  collateral  computation,  as  long  as  this  token  is  supported  by  the  Credit Manager and is not forbidden. This can be used to handle airdropped tokens.  Whether  the  token  is  forbidden  is  only  checked  when  a  new  token  comes  in  and  is  being  enabled  (in CreditManager.checkAndEnableToken()). Whether an outgoing token is forbidden is not checked. This is  Gearbox Protocol - Gearbox V2 -   22  SecurityLowVersion1CodeCorrected        \fdeliberately done in order to allow positions in a forbidden token to be unwound after it was forbidden, by selling the token on Uniswap, closing/liquidating the account, etc.  outdated: annotation  The  /// @dev Approve tokens for credit account. Restricted for adapters only. The CreditFacade is also eligible to call this function.  function   is   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.12   Curve Registry", "body": "  The factory contract CurveLPFactory which deploys the curve price feeds has the address of the Curve registry hardcoded. Similarly, CurveV1_Base uses the hardcoded address.  According to the Curve Documentation of their registry contracts, the central source of truth in the Curve system  is  the  address  provider.  That  contract  allows  changing  the  registry  through  set_address() when the id parameter is set to zero. Currently, the oracle stores the registry as an immutable. Hence, in case the registry changes, the contract will utilize a wrong registry.    The Curve Registry is no longer used either by the price feeds or CurveV1_Base and hence this issue no longer applies.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.13   CurveV1 Adapters: TokenOut Might Not Be", "body": " Enabled at CreditAccount  The  implementation  of  the  CurveV1_2/3/4  adapters  bears  the  risk  that  after  a  successful  action,  the incoming tokens might not be enabled at the CreditAccount.  Consider the following function:  function remove_liquidity(     uint256 amount,     uint256[N_COINS] memory min_amounts ) external virtual nonReentrant {     address creditAccount = creditManager.getCreditAccountOrRevert(         msg.sender     ); // F:[ACV1_2-3]      _enable_tokens(creditAccount, min_amounts);     _executeFullCheck(creditAccount, msg.data); //F:[ACV1_2-5,6] }  Parameter  min_amounts  serves  as  slippage  protection.  The  adapter  uses  it  to  enable  the  incoming tokens using the internal _enable_tokens function:  function _enable_tokens(     address creditAccount,     uint256[N_COINS] memory amounts ) internal {  Gearbox Protocol - Gearbox V2 -   23  CorrectnessLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                \f    if (amounts[0] > 1) {         creditManager.checkAndEnableToken(creditAccount, token0); //F:[ACV1_2-5,6]     }      if (amounts[1] > 1) {         creditManager.checkAndEnableToken(creditAccount, token1); //F:[ACV1_2-5,6]     } }  If  the  user  didn't  set  the  slippage  protection  (which  shouldn't  be  done  as  it  makes  the  transaction vulnerable to being sandwiched, resulting in worse exchange rates) the token might not be enabled in the credit account. This may remain undetected when the remaining assets at the credit account suffice to reach  a  health  factor  >  1.  Closing  such  a  credit  account  likely  leaves  those  tokens  behind  and  a  later borrower who realizes this could collect them. Also, if such a credit account becomes unhealthy and is liquidated, a liquidator could collect the tokens.    The function now enables all tokens of the pool, regardless of the min_amounts array. This is correct, since remove_liquidity() transfers tokens based on the current inventory of the pool, so there are only two scenarios in which it can return less than 2 tokens:  the user burns a very small amount of the LP token;  the pool is 100% unbalanced, which should not be practically achievable in Curve.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.14   Duplicate Error Code Used", "body": "  The library Errors contains error messages encoded as short strings to save on deployment cost and two  distinct  errors, contract  CC_INCORRECT_TOKEN_CONTRACT  and  CM_TOKEN_IS_ALREADY_ADDED,  which  prevents  users  from exactly determining the cause of the error.  size.  One  of   the  error   is  used   \"CFH\",   codes,   for     Text errors are being replaced with explicit Exceptions that are now being thrown on errors or constraint with in  violations.  IErrors.IncorrectTokenContractException  and ICreditManagerV2Exceptions.TokenAlreadyAddedException.  particular,   replaced   question   errors   were   In   In  the  current  version  of  the  code  the  library  Errors.sol  is  still  imported  and  used  by  several  system contracts, the duplicate error described above however has been corrected.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.15   Incorrect Comment After Refactoring", "body": "  in  CreditManager.manageDebt  mentions   function  sometimes  shifts A  comment  newBorrowedAmount. This comment refers to a previous version of the code and isn't describing the current system.  that   the   Gearbox Protocol - Gearbox V2 -   24  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f  The comment has been removed  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.16   Incorrect Descriptions", "body": "  PriceOracle:   The  function  description  of  addPriceFeed  in  both  the  contract  and  the  interface  definition  incorrectly mentions Eth  /// @param priceFeed Address of chainlink price feed token => Eth  In GearboxV2 the Chainlink pricefeed used is supposed to return a value in USD.  the return value in convertedToUSD() is incorrectly described as:  /// @return Amount converted to tokenTo asset  the  description  for  parameter  token  should  read  to  instead  of  from  in  the  convertFromUSD()` function   The description of fastCheck() is incorrect.   Not all functions in the interface are annotated.  CreditFacade:   The  description  of  both  functions  closeCreditAccount  and  liquidateCreditAccount  mention the outdated sendAllAssets.  CreditManager:   fastCollateralCheck still mentions WETH instead of USD   closeCreditAccount description mentions if sendAllAssets is true, this no longer exists.  Specification changed:  The aforementioned description issues have been rectified.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.17   Outdated Function Description", "body": "  There are frequent cases in which comments refer to previous functionality in the code which now has been  changed.  As  an  example,  the  description  of  function  closeCreditAccount  in  both  contracts, CreditFacade  and  CreditManager  describe  sendAllAssets  which  no  longer  exists.  Similarly  this applies  to  the  function  liquidateCreditAccount  of  the  CreditFacade  in  which  skipTokenMask allows this behavior now. .  Gearbox Protocol - Gearbox V2 -   25  CorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1Speci\ufb01cationChanged                  \fSpecification changed:  Function annotations have been brought up-to-date.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.18   PriceOracle: Unused Timestamp", "body": "  function _getPrice(address token) internal view returns (uint256) {     require(         priceFeeds[token] != address(0),         Errors.PO_PRICE_FEED_DOESNT_EXIST     );      (         ,         //uint80 roundID,         int256 price, //uint startedAt, , //uint80 answeredInRound         ,         uint256 timeStamp,      ) = AggregatorV3Interface(priceFeeds[token]).latestRoundData();      return uint256(price); }  }  latestRoundData()  returns  several  values,  all  unused  values  except  timesTamp  are  dropped.  The value for timeStamp is handled but remains unused.    PriceOracle.getPrice()  now  uses  roundId,  answer,  updatedAt  and  answereInRound  to perform sanity checks on round data. The unused startedAt value is dropped.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.19   Read-only Reentrancy", "body": "  When  integrating  with  Gearbox,  developers  should  be  aware  of  read-only  reentrancy  opportunities. Assume a credit account (CA) which is controlled by a protocol (P) integrating with Gearbox and holds WETH, and a malicious user (E). Assume now that at some point the account becomes liquidatable:   E liquidates the account by calling CreditFacade.liquidateCreditAccount where the to  address is a smart contract controlled by E and convertWETH is true.   During  closure,  CreditManager.closeCreditAccount  is  called,  which  converts  WETH  to  ETH and sends it to to as seen in the following snippet:  Gearbox Protocol - Gearbox V2 -   26  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f_transferAssetsTo(creditAccount, to, convertWETH, enabledTokensMask);   At this point, the control of the execution flow is passed to the smart contract of to address.   The smart contract makes a call to P which queries the state of CA. CA will seem like it holds less value than it actually used to at the beginning of the transaction. The reason is that its state hasn't been fully updated but part of its holdings has been sent to another address.   Based  on  this  intermediate  state  of  the  CA,  P  might  proceed  incorrectly  and  end  up  in  an  unexpected state.    The line ` delete creditAccounts[borrower]; // F:[CM-9] ` was moved to the beginning of the function, right after the Credit Account for the borrower is first retrieved. This will make any calls to CreditManager.getCreditAccountOrRevert() in the middle of closeCreditAccount execution fail, since the record no longer exists in the mapping.  While  third-party  protocols  that  directly  query  the  state  through  a  saved  CA  address  may  still  be vulnerable, we will advise all integrators to use CreditManager.getCreditAccountOrRevert() to retrieve the address dynamically, as a security best practice.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.20   Redundant Event Emission", "body": "  When CreditFacade._disableToken is called, a TokenDisabled event is emitted even if the token was already disabled.    CreditManager.disableToken()  now  returns  whether  the  token  was  actually  disabled.  This  is  used  in CreditFacade._disableToken() to emit the event conditionally.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.21   Redundant Initialization", "body": "  In CreditConfigurator.constructor the following line can be found:  creditManager.upgradePriceOracle(address(creditManager.priceOracle())); // F:[CC-1]  This line upgrades the price oracle of the CreditManager with the same price oracle. Hence, this call is redundant.    The line has been deleted.  Gearbox Protocol - Gearbox V2 -   27  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f7.22   Reentrancy Into CreditFacade  The new CreditFacade featuring the new multicall functionality allows executing multiple actions including calls  to  the  adapters.  A  health  check  of  the  credit  account  is  only  done  once  after  all  calls  have  been executed,  not  in  between  calls.  In  between  calls  credit  accounts  may  be  in  an  unhealthy  state.  The internal  multicall  function  of  CreditFacade  itself  is  not  protected  against  reentrancy,  nor  are  some functions  of  the  CreditFacade  using  this  multicall  functionality.  Reentrancy  protection  is  present  in  the called  adapter  and  during  the  execution  of  certain  functions  of  the  CreditManager.  Note  that  the reentrancy  protection  used  works  per  contract:  Reentrancy  into  the  specific  contract  is  locked  at  the beginning of the function and the lock is released when the function call completes.  Aside  from  certain  functions  of  the  CreditFacade  itself  (which  are  handled  differently),  multicall  allows calling any function on external contracts which are valid adapters.  Furthermore, note that attacks are limited as credit account cannot be returned in the very same block it has been borrowed.  Nevertheless, extra care should be taken especially as untrusted code can be reached via the adapters. It might be more cautious to prevent reentrancy into the CreditFacade as this is not intended to be done.  Code corrected and Acknowledged:  All  remaining  non-restricted  CreditFacade  functions  have  been  covered  with  a  nonReentrant  modifier. This ensures that:   At most one multicall can be performed within a single transaction (internal _multicall() can only be  called from non-reentrant functions);   Only one of debt-managing functions (addCollateral, increaseDebt and decreaseDebt) can be called externally  within  a  single  transaction  (internal  counterparts  can  be  called  multiple  times  within  a multicall, barring flash loan protections).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.23   Sanity Check of New Pricefeed", "body": "  PriceOracle._addPriceFeed() contains the following sanity check:  require(     AggregatorV3Interface(priceFeed).decimals() == 8,     Errors.PO_AGGREGATOR_DECIMALS_SHOULD_BE_8 ); // F:[PO-2]  This check helps to ensure that the intended kind of pricefeeds returning a price with 8 decimal is passed, which USD-denominated Chainlink pricefeeds do.  The  sanity  check  could  be  enhanced  to  check  if  the  pricefeed  actually  implements  the  required functionality of the AggregatorV3Interface, notably whether function latestRoundData is implemented which is the function called by the PriceOracle to query the price.    _addPriceFeed() now performs extensive sanity checks on the newly added feed and token:  Gearbox Protocol - Gearbox V2 -   28  SecurityLowVersion1AcknowledgedCodeCorrectedDesignLowVersion1CodeCorrected                \fChecks that neither feed nor token are zero addresses; Checks that the token is a contract; Checks that the  price  feed  is  a  contract;  Checks  that  the  token  implements  decimals();  Checks  that  the  feed implements decimals() and it is equal to 8; Checks that the feed implements dependsOnAddress(); Checks  implements latestRoundData() (and performs sanity checks on the answer if skipPriceCheck() == false);  implements  skipPriceCheck();  Checks   feed   feed   that   that   the   the   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.24   Unused allowedContractsSet", "body": "  EnumerableSet.AddressSet  private  allowedContractsSet;  defined  in  the  CreditFacade  is unused. The very same variable exists in the CreditConfigurator where it actually is used.    Removed unused variable and corresponding getters.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.25   YearnV2Adapter: Different Behavior of", "body": " Functions  Functions  transfer  and  transferFrom  approve() however behaves differently simply returns true.  revert  with  Errors.NOT_IMPLEMENTED.  Function    approve(),  transfer()  and  transferFrom()  of  the  YearnV2Adapter  now  return  false  without doing anything.  Gearbox Protocol - Gearbox V2 -   29  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Airdrops", "body": "  CreditAccounts may be eligible for airdrops, e.g. as they may have held a certain token when a snapshot was taken or as they may have interacted with a DeFi system a certain amount of times.  Users of a credit account must be aware that they lose participation in the airdrop when they return the credit account (close/liquidation).  At the moment when the information about an airdrop becomes public, this credit account may be in use or in the queue at the factory.  Depending on the value of the airdrop users may attempt to retrieve this credit account. The governance has the option to take out such accounts directly. Generally, airdrops can only be claimed by the credit account if this process can be triggered by a third party. Airdrops requiring the credit account to call a specific function generally won't work as no adapter supporting this exists.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Free Flashloans", "body": "  Gearbox prevents users from increasing and decreasing their debt during a multicall and thus taking a free  flashloan.  However,  a  user  could  still  create  a  contract  that  executes  two  separate  multicalls,  one that  includes  a  debt  increase  and  one  that  includes  a  debt  decrease.  This  way,  a  free  loan  is  still possible.  It  is  important  to  note  that  the  amount  to  be  borrowed  during  the  loan  is  still  limited  by  the checks performed when an amount is borrowed from the pool.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Renouncing Ownership", "body": "  In  Gearbox,  transfers  of  ownership  take  place  in  two  steps.  First,  the  previous  owner  defines  the  new owner  (pendingOwner)  and  the  new  owner  claims  the  ownership.  The  Claimable  contract  extends Ownable  meaning  that  the  old  owner  can  renounce  ownership.  Users  should  note  that  ownership renounce is ignored if a pending owner has been already defined since Claimable.claimOwnership does not check if the ownership has been renounced before.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   _safeTokenTransfer - Call to External", "body": " Address  When the boolean parameter convertToETH is set to true, WETH is unwrapped into Ether. This Ether is transferred  to  the  recipient  using  a  call,  the  gas  amount  passed  is  not  restricted.  At  this  point,  the execution may reach untrusted code.  Gearbox Protocol - Gearbox V2 -   30  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fThe function name \"safeTokenTransfer\" is due to the usage of OpenZeppelins SafeERC20 library. One must be careful to not misinterpret the function name and assume using this function is \"safe\" under all circumstances.  Gearbox Protocol - Gearbox V2 -   31  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Broken Integration With Special ERC20", "body": " Tokens  OFT  does  not  integrate  well  with  ERC20  tokens  that  have  special  behavior,  such  as  transferring  less tokens  than  the  specified  amount.  One  concrete  example  of  such  tokens  is  cUSDCv3.  This  token transfers  the  current  balance  of  a  user  when  type(uint256).max  is  passed  as  amount,  instead  of reverting. Since cUSDCv3 also uses 6 decimals (same as default shared decimals), there is a possibility of exploiting an OFT if deployed for this token.  CS-LZOFT-001  An attacker could perform the following steps:  1. Ensure a non-zero balance of cUSDCv3 in the source chain.  tries   2. Trigger a call to OFTCore.send() with amountToSendLD set to the maximum uint256. Function _debit()  from  attacker,  however  because  of amountToSendLD = type(uint256).max, the token will transfer only the existing balance of attacker. Given that cUSDCv3 uses 6 decimals, no dust is removed, and the shared amount send to the destination chain is max uint64.  input  amount   to  pull   the   3. On the destination chain, the OFT mints the maximum amount to the attacker.  Acknowledged:  LayerZero acknowledged the issue, and has added new comments to warn developers about these risks:  LayerZero - OFT/OApp -   11  SecurityDesignCorrectnessCriticalHighMediumAcknowledgedLowAcknowledgedAcknowledgedAcknowledgedSecurityMediumVersion1Acknowledged           \f@dev WARNING: The default OFTAdapter implementation assumes LOSSLESS transfers, ie. 1 token in, 1 token out. IF the 'innerToken' applies something like a transfer fee, the default will NOT work... a pre/post balance check will need to be done to calculate the amountToCreditLD/amountReceived.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Missing Event for New Delegatee", "body": "  The new function EndpointV2.setDelegate in  emitted in the OAppCore constructor when endpoint.setDelegate() is initially called.   does not emit an event. Similarly, no event is  It is recommended to emit events for important state updates and index the relevant parameters to allow integrators and dApps to quickly search for these and simplify UIs.  CS-LZOFT-010  Acknowledged:  LayerZero is aware about the missing event but has decided to keep the code unchanged.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Unsafe Casting in _toSD", "body": "  The function OFTCore._toSD casts unsafely a uint256 into uint64:  function _toSD(uint256 _amountLD) internal view virtual returns (uint64 amountSD) {     return uint64(_amountLD / decimalConversionRate); }  If  the  result  of  _amountLD  /  decimalConversionRate  is  equal  or  larger  than  2**64,  the  most significant bits are lost.  CS-LZOFT-005  Acknowledged:  LayerZero  has  acknowledged  the  issue  but  has  decided  to  keep  the  unsafe  casting  unchanged.  The following description has been added for function OFTCore.sharedDecimals:  @dev Sets an implicit cap on the amount of tokens, over uint64.max() will need some sort of outbound cap / totalSupply cap Lowest common decimal denominator between chains. Defaults to 6 decimal places to provide up to 18,446,744,073,709.551615 units (max uint64). For tokens exceeding this totalSupply(), they will need to override the sharedDecimals function with something smaller. ie. 4 sharedDecimals would be 1,844,674,407,370,955.1615  Developers should be aware that the maximum total supply should be limited by uint64 for OFT tokens (or  the  inner  token  of  an  OFTAdaptor).  However,  it  is  important  to  notice  that  if  this  constrain  is  not  LayerZero - OFT/OApp -   12  DesignLowVersion2AcknowledgedVersion2DesignLowVersion1Acknowledged                \frespected by the developers, this unsafe casting can lead to funds being burned (or locked) in the source chain without an equivalent amount being minted on the destination chain.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Update of lzToken", "body": "  Users  specify  the  amount  _lzTokenFee  they  pay  when  sending  a  transaction.  However,  if  owner  of EndpointV2 calls setLzToken to update the lzToken before the transaction is executed, users would pay the same amount in the new token (assuming the allowance is provided).  CS-LZOFT-011  Acknowledged:  LayerZero  has  acknowledged  the  issue,  and  has  decided  to  keep  the  code  unchanged  in  . LayerZero stated that in future versions a timelock will be used to inform users ahead of time in case of a token switch.  LayerZero - OFT/OApp -   13  SecurityLowVersion1AcknowledgedVersion2          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Limited Documentation and Specifications   -Severity Findings   Commented Code and Remaining ToDos    OFT Does Not Refund Excess Fees    Type Check for User Provided Options   Informational Findings  Inconsistent Solidity Compiler Version in IOAppReceiver   0  0  1  3  1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Limited Documentation and Specifications", "body": "  The  codebase  lacks  proper  documentation  and  inline  code  specifications  that  clearly  explain  pre/post conditions  of  functions  and  their  expected  behavior.  Complete  documentation  and  specifications  are important  for  OFT  and  OApp  contracts  because  other  developers  will  extend  them  and  the documentation/specifications  are  essential  to  reduce  the  likelihood  of  introducing  vulnerabilities  in  the derived contracts.  CS-LZOFT-002    LayerZero has extended significantly inline specifications for the contracts in scope of this review.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Commented Code and Remaining ToDos", "body": "  Commented out code is present in the contract OAppPreCrimeSimulator. Also, several ToDo notes are present in the codebase. Removing commented code and addressing remaining notes help improve the quality and readability of the code.  CS-LZOFT-003    LayerZero - OFT/OApp -   14  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \fLayerZero has removed commented-out code and ToDos in   .  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   OFT Does Not Refund Excess Fees", "body": "  Users  call  the  function  OFTCore.send  to  trigger  an  omnichain  operation.  The  function  send()  is payable  and  users  are  expected  to  send  enough  Ether  to  cover  for  the  native  fee.  The  function _payNative  caps  the  msg.value  to  the  amount  of  native  fee,  hence  the  diff  amount  between msg.value and _fee.nativeFee is not forwarded to the endpoint:  function _payNative(uint _nativeFee) internal virtual returns (uint256 nativeFee) {     if (msg.value < _nativeFee) revert NotEnoughNative(msg.value);     return _nativeFee; }  CS-LZOFT-004  The returned value is then forwarded to the endpoint:  uint256 messageValue = _payNative(_fee.nativeFee); ...  return     endpoint.send{ value: messageValue }(...);  However, if the user sends more Ether than nativeFee, the excess amount is locked.  Note that, if the nativeFee is higher than actual fee charged by the endpoint, the excess amount will be refunded.    LayerZero  has  changed  the  function  OAppSender._payNative  such  that  it  checks  that  msg.value  is exactly equal to _fee._nativeFee:  function _payNative(uint256 _nativeFee) internal virtual returns (uint256 nativeFee) {     if (msg.value != _nativeFee) revert NotEnoughNative(msg.value);     return _nativeFee; }  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Type Check for User Provided Options", "body": "  The  function  OAppOptionsType3.setEnforcedOptions  validates  that  options  provided  by  the owner are of type 3:  CS-LZOFT-014  uint16 optionsType = uint16(bytes2(_enforcedOptions[i].options[0:2])); // enforced not supported for options type 1 and 2 if (optionsType != OPTION_TYPE_3) revert OptionsTypeInvalid(optionsType);  LayerZero - OFT/OApp -   15  Version2CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fHowever,  when  combining  owner-provided  options  with  user-provided  options,  function OAppOptionsType3.combineOptions does not check that the user-provided options (_extraData) are of type 3. As a consequence, options of different types may be combined.  the     The  function  OAppOptionsType3.combineOptions  has  been  revised  to  check  the  type  of _extraOptions which are provided by the user when they are combined with enforced options. User options could be of legacy type (type 1 or 2) if there are no enforced options:  // No enforced options, pass whatever the caller supplied, even if it's empty or     legacy type 1/2 options. if (enforced.length == 0) return _extraOptions;  ...  // @dev If caller provided _extraOptions, must be type 3 as its the ONLY type that can be combined. if (_extraOptions.length >= 2) {     _assertOptionsType3(_extraOptions);     .... }  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Inconsistent Solidity Compiler Version in", "body": " IOAppReceiver  In  IOAppReceiver still presents the previous compiler version (^0.8.22).  , the Solidity compiler version for all files in scope was set to ^0.8.20. However, the contract  CS-LZOFT-012    LayerZero has changed the compiler version pragma in IOAppReceiver to ^0.8.20.  LayerZero - OFT/OApp -   16  InformationalVersion3CodeCorrectedVersion3      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Floating Pragma for Dependencies", "body": "  OFT/OApp uses the floating pragma ^4.8.1 || ^5.0.0 for OpenZeppelin contracts. The constructor of Ownable in versions 4.8.x does not take any argument and owner role is set to the deployer of the contract. However, in version 5.0.0 the implementation has changed and an address should be passed in the constructor. Therefore, developers extending OFT contracts are responsible to use the constructors correctly.  Contracts should be deployed with the dependencies version that were used during testing and auditing. Locking  the  pragma  helps  to  ensure  that  contracts  are  not  accidentally  deployed  using  a  different dependency version and help ensure a reproducible deployment.  CS-LZOFT-006  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Gas Optimizations", "body": "  The codebase could be more efficient in terms of gas usage. Reducing the gas costs may improve user experience. Below is an incomplete list of potential gas inefficiencies:  1. The function OAppCore.callEndpoint could be marked as external.  2. The function OFTCore.quoteSend is not called internally, hence potentially could be marked as  CS-LZOFT-007  external.  3. SetConfigParam is imported in file IOAppCore.sol but is not used.  4. The function OAppCore.setDelegate could be marked as external.  Code partially corrected:  The optimizations 1 to 3 in the list above have been applied in   .  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Magic Numbers in Codebase", "body": "  Some magic values are used in the codebase mainly for the version of contracts that could be declared as  constant.  For  instance,  function  OFT.oftVersion  returns  the  following  values  (1,  1).  Similarly, OFTAdapter.oftVersion()  returns  magic  values.  Such  values  can  be  replaced  with  constant variables to improve code readability.  CS-LZOFT-008  LayerZero - OFT/OApp -   17  InformationalVersion1InformationalVersion1CodePartiallyCorrectedVersion2InformationalVersion1Acknowledged              \fAcknowledged:  LayerZero has acknowledged the issue and has decided to keep the code unchanged in   .  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Possible Incorrect Return Value", "body": "  The function OAppReceiver.allowInitializePath performs the following check:  function allowInitializePath(Origin calldata origin) public view virtual returns     (bool) {     return peers[origin.srcEid] == origin.sender; }  Note that if origin.sender is 0 (default value) and there is no entry in peers for srcEid, the function returns incorrectly true.  CS-LZOFT-013  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Solidity Compiler Version", "body": "  The  solidity  compiler  is  fixed  to  0.8.22  in  the  config  file  foundry.toml  which  has  been  released recently.  The  new  opcode  PUSH0  has  been  added  since  compiler  version  0.8.20  but  it  is  not  widely supported by other EVM-compatible chains.  Deployers of OFTs are responsible to compile the smart contracts with the correct options for a target chain.  CS-LZOFT-009  LayerZero - OFT/OApp -   18  Version2InformationalVersion2InformationalVersion1        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Custom OFT Implementation", "body": "  Developers can extend the OFT contract and implement custom logic for new functionalities or different behaviors.  The  inline  comment  in  function  OFTAdapter._debitSender()  suggests  that  OFT implementations could also charge fees:  // @dev amountDebited could be 100, with a 10% fee, the credited amount is 90, // so technically the amountToCredit would be locked as outboundAmount  We would like to highlight that contracts extending OFT with new functions or new behaviors should be assessed  carefully.  For  instance,  charging  a  fee  for  OFTs  requires  developers  to  implement  additional functions that transfer such fees outside of the contract.  Furthermore, OFTAdapter does not work with innerToken that have special behaviors, e.g., fees on transfer. Developers should be aware of such behaviors and customize the OFTAdapter to integrate well with such tokens. For instance, function _debitSender() should be overridden if the underlying token charges fees on transfer, as the following comment suggests:  // @dev will need to override this and do balanceBefore, and balanceAfter IF the     innerToken has fees on transfers  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Delegatee Could Be Different From Owner", "body": "   to set the delegatee in the local endpoint. The The contract OAppCore added functionality in  delegatee  is  initially  set  to  the  owner  in  the  constructor.  However,  the  codebase  does  not  enforce  that both delegatee and owner are the same address. For instance, transferring ownership of OApp to a new address, does not automatically update the delegatee in endpoint.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Enforcement of Next Nonce", "body": "  The contract OAppReceiver declares a virtual function nextNonce that by default returns 0, however derived contracts can override it and implement a custom policy for nonces. Developers of OApps that implement  a  specific  policy  for  nonces  should  enforce  the  policy  by  validating  the  correct  nonce  when messages are received, for example in function _lzReceive.  Note that enforcing a specific policy for nonces increases the possibility of griefing attacks as one can send a transaction that will fail in the destination chain, hence owner of the OApp should skip/clear such transactions.  LayerZero - OFT/OApp -   19  NoteVersion1NoteVersion2Version2NoteVersion1            \f8.4   Failing Transactions on the Destination Chain  The OApp is responsible for implementing the receiving logic such that the incoming transactions do not revert,  however  there  are  cases  when  the  transaction  could  revert  even  if  the  OApp  does  not contemplate  this  possibility.  Whenever  this  happens,  funds  might  be  permanently  locked  in  the  source chain.  A  reason  for  reverting  might  be  in  the  underlying  token,  for  example  implementing  blocklists,  being paused,  or  rejecting  specific  transfer  amount  such  as  0.  For  instance,  if  USDC  is  an  inner  token  of  a OFTAdapter  and  the  recipient  of  a  USDC  transfer  is  in  the  blocklist  on  the  destination  chain,  the transaction will revert.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.5   Limitation on Shared Decimals", "body": "  As suggested in the Natspec of the function OFTCore.sharedDecimals, the shared decimals across all chains are capped by the lowest decimals of OFT deployments. For instance, if an OFT is deployed in 3 chains and they use 2, 8, and 18 decimals respectively, the shared decimals is capped at 2. Therefore, messages passed between OFTs with high decimals (8 and 18) use also a precision of 2 decimals.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.6   Precision Loss in Amounts Passed Between", "body": " Chains  The amounts shared between chains use type uint64 and limit the precision of values transferred to 6 decimals by default. If a user passes an amount that requires more decimals to be correctly represented, the function _debitView truncates it such that it fits the shared decimals. The rest is considered dust by the system.  For instance, if a user intends to transfer an amount 1.23456789 tokens into another chain, the actual amount transferred will be 1.23456 assuming the default 6 decimals, while the remaining 0.00000789 is considered dust. This dust is accumulated in the contracts OFT, or OFTAdapter, when users transfer tokens  directly  to  the  contract  and  the  respective  function  _debitThis  is  triggered.  The  dust accumulated  in  these  contracts  can  be  transferred  to  another  chain  and  claimed  by  anyone  by  calling OFTCore.send specifying sendParam.amountToSendLD = 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.7   Reentrancy Possibility When Sending", "body": "  The function OFTCore.send triggers a call in _lzSend() which calls EndpointV2.send(). In case the  user  specifies  a  higher  native  fee  than  the  one  that  will  be  charged  by  the  endpoint,  the  latter refunds the excess amount to the user. This poses a reentrancy possibility as the execution is passed to the _refundAddress specified by the user.  Developers that extend OFT contracts should be aware of this behavior and take measures to address the reentrancy.  LayerZero - OFT/OApp -   20  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   ERC165 Partially Implemented", "body": "  0  0  0  1  CS-POLTOKEN-001  contract   AccessControlEnumerable   The  contract PolygonEcosystemToken  that  inherits  AccessControlEnumerable  in  the  codebase  does  not extend  the  implementation  of  ERC165.  ERC165  should  either  return  true  for  all  the  interfaces  the contract implements or be completely disabled.  implements   ERC165   the   but   Acknowledged:  Polygon answered that:  PolygonEcosystemToken is planned to only support AccessControlEnumerable interface and ERC20 Permit but it isn't industry practice for it to extend ERC165 so far.  Polygon - Polygon Token (POL) -   10  DesignCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Missing Input Sanitization   Interfaces Are Missing Functions   0  0  0  2  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Missing Input Sanitization", "body": "  The respective arguments of the constructors of PolygonMigration and DefaultEmissionManager are not ensured to be non-zero.  CS-POLTOKEN-008    The constructors have been updated to check that the addresses are non-zero.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Interfaces Are Missing Functions", "body": "  CS-POLTOKEN-002  Some  of  the  interfaces  are  missing  functions  from  their  implementations  that  could  be  useful  for integrators. Here is a non-exhaustive list:  1. IPolygonEcosystemToken is missing updatePermit2Allowance() and the getter functions  for the storage variables  2. IPolygonMigration  is  missing  getVersion(),  burn(),  and  the  getter  functions  for  the  storage variables  3. IDefaultEmissionManager  is  missing  getVersion(),  inflatedSupplyAfter(),  and  the  getter functions for the storage variables    The interfaces have been updated to expose all relevant functions.  Polygon - Polygon Token (POL) -   11  CriticalHighMediumLowCodeCorrectedCodeCorrectedDesignLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                   \f6.3   Storage Gap Inconsistency  , the upgradable contracts __gap variables were updated with the intention that exactly 50 In  storage slots are used by each contract. In PolygonMigration, __gap was set to be 48 slots long as the contract contains two storage variables. However, as the storage variables are packed into one slot by the compiler, to have exactly 50 storage slots, __gap should have size 49.  CS-POLTOKEN-009    __gap was updated to have size 49.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Gas Optimizations", "body": "  1. In the contract DefaultEmissionManager, the storage variables migration, stakeManager, and  treasury  can  be  set  at  deployment  and  thus  be  immutable.  The  initialization  would  only need to set token. This would allow to reduce the number of SLOAD performed upon minting.  2. In the function DefaultEmissionManager.mint(), the storage variable token can be loaded  in memory to avoid multiple SLOAD.  3. In the contract PolygonMigration, the storage variable matic can be set at deployment and be  immutable, thus saving storage reads.  CS-POLTOKEN-004    All optimizations have been applied.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Inconsistent Event Emission", "body": "  In  the  codebase,  events  are  mostly  emitted  before  a  state  change.  However,  the  functions PolygonEcosystemToken._updatePermit2Allowance  and PolygonMigration.updateUnmigrationLock are not following that pattern.  CS-POLTOKEN-005    The two functions have been updated to emit events before performing state changes.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Initializable Is Inherited Twice", "body": "  Polygon - Polygon Token (POL) -   12  CS-POLTOKEN-007  InformationalVersion3CodeCorrectedVersion3InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                      \fThe  contract  DefaultEmissionManager  Ownable2StepUpgradeable. Direct inheritance is not necessary.  inherits  Initializable  directly  and  also   from    The DefaultEmissionManager now only inherits Initializable once.  Polygon - Polygon Token (POL) -   13  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Emission Manager Owner Has No Purpose", "body": "  Although the contract DefaultEmissionManager is ownable and an owner must be given when calling initialize, the owner has no specific permissions and the role is never used in the contract.  CS-POLTOKEN-003  Acknowledged:  Polygon is aware of this and explained that they want to proactively keep Ownable for now.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Planned Emissions Conflict With Supply Cap", "body": "  In  the  DefaultEmissionsManager,  the  planned  supply  increase  is  2%  of  the  supply  per  year, compounding.  The  PolygonEcosystemToken  contract  enforces  that  no  more  than  10  tokens  per second can be emitted. After about 22 years and 41 days, the manager will try to mint more tokens than what the cap allows, and the transaction will revert. To resume emissions, admin action will be needed to increase the cap.  CS-POLTOKEN-006  Acknowledged:  Polygon acknowledged and stated:  According to the current plan, it is expected that emissions will stop after 10 years (and hence all fuzz tests are done with a 10-year bound).  Polygon - Polygon Token (POL) -   14  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Approval Events Do Not Reflect Permit2", "body": " Allowance  The  implicit  infinite  allowance  granted  to  the  Permit2  contract  is  invisible  to  applications  that  rely  on Approval() events to track token allowances. Furthermore, when it is enabled or disabled, they will not be notified either since this action raises a different event.  Nothing  can  be  done  on-chain  about  this  since  the  ERC-20  interface  is  not  designed  to  support allowances on behalf of all users.  Polygon - Polygon Token (POL) -   15  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   EIP-170 Mix Up / Unlimited Contract Size", "body": "  EIP-170 has been introduced into the Ethereum mainnet with the Spurious Dragon hardfork in order to limit the maximum codesize of a contract.  The short specification of the EIP reads:  ... if contract creation initialization returns data with length of more than 0x6000 (2**14 + 2**13) bytes, contract creation fails with an out of gas error.  The data returned by the contract creation initialization is the code of the newly deployed smart contract that will be stored as the code of the smart contract. This is valid regardless wether the contract has been deployed  directly  from  a  transaction  or  a  during  code  execution  of  a  CREATE  /  CREATE2  opcode.  For more details please refer to chapter 7 of the Ethereum Yellowpaper.  The  TxPermissionBased  contract  _deployerInputLengthLimit. There is an annotated function for the owner to set this variable:  the  POSDAO  system  attempts   to  enforce  a  in   /// @dev Sets the limit of `input` transaction field length in bytes /// for contract deployment transaction made by the specified deployer. /// @param _deployer The address of a contract deployer.  POA Network - POSDAO -   15  DesignCorrectnessCriticalHighRiskAcceptedMediumRiskAcceptedAcknowledgedRiskAcceptedAcknowledgedLowAcknowledgedRiskAcceptedAcknowledgedAcknowledgedCorrectnessHighVersion1RiskAccepted            \f/// @param _limit The maximum number of bytes in `input` field of deployment transaction. /// Set it to zero to reset to default 24Kb limit defined by EIP 170.  And inside the _allowedTxTypes function which is annotated with:  /// @dev Defines the allowed transaction types which may be initiated by the specified sender with /// the specified gas price and data. Used by node's engine each time a transaction is about to be /// included into a block.  there is:  if (_to == address(0) && _data.length > deployerInputLengthLimit(_sender)) {     // Don't let to deploy too big contracts     return (NONE, false); }  There is a mixup here: What the TxPermission contract actually limits with this parameter is the lenght of  the  data  field  of  the  transaction,  not  the  limit  of  a  contract's  code  size.  This  has  nothing  to  do  with EIP-170. Hence if the limit is only \"enforced\" by the TxPermission contract and there is no further limit set in the chain specification anyone may deploy a contract of arbitrary size, limited only by the gas limit. EIP-170 is not activated in the template/spec.json chain sepcification file available in the repository.  Note that the Ethereum mainnet has no excplicit limit on the data field of a transaction (called input in the function description in POSDAO). This is only limited by the gas limit of a block.  Ethereum Yellowpaper: https://ethereum.github.io/yellowpaper/paper.pdf EIP-170 Specification: https://github.com/ethereum/EIPs/blob/master/EIPS/eip-170.md  Risk Accepted:  POA Network accepts this risk and states: Some popular projects on xDai require the abi lity to deploy contracts with size greater than 24 Kb. The limit on transacti on size is intended as an easy protection against script kiddies.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Changing Mining and Staking Addresses", "body": " While Banned  ValidatorSetAuRa  allows  to  change  the  mining  and  staking  address  while  a  pool  is  banned.  This updates the state, including:  idByStakingAddress[oldStakingAddress] = 0; idByStakingAddress[_newStakingAddress] = poolId;  or  idByMiningAddress[_oldMiningAddress] = 0; idByMiningAddress[_newMiningAddress] = _poolId;  The available specification does not cover this scenario and it remains unclear if this should be possible or not.  POA Network - POSDAO -   16  DesignMediumVersion1RiskAccepted        \fIn case of a change of the mining address while a pool is banned, the return value of following functions may be unexpected for the caller:  /// @dev Returns the block number when the ban will be lifted for the specified mining address. /// @param _miningAddress The mining address of the pool. function bannedUntil(address _miningAddress) public view returns(uint256) {     return _bannedUntil[idByMiningAddress[_miningAddress]]; }  bannedUntil() will return 0 if the mining address of the banned pool has been changed even though the pool is banned.  function isValidatorBanned(address _miningAddress) public view returns(bool) {     uint256 bn = bannedUntil(_miningAddress);     if (bn == 0) {         // Avoid returning `true` for the genesis block         return false;     }     return _getCurrentBlockNumber() <= bn; }  This holds similarly for this function which notably is querried by BlockRewardAuRaBase.reward().  Within the system one such address can only be used once for an unique purpose, e.g. an address that has been a mining or staking address once cannot be reused anymore.  This is tracked by following mappings:  mapping(address => uint256) public hasEverBeenMiningAddress; mapping(address => bool) public hasEverBeenStakingAddress;  The information to which pool the mining address once belonged to is availabe in this mapping.  Risk accepted:  POA Network states this is expected behavior in order to allow pools to change their staking or mining address if they are compromised during the ban period.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Incoherent Event ChangedMiningAddress", "body": " Emitted  To change a mining address, changeMiningAddress is called from the participants staking address. If the  participant  is  a  current  validator,  the  change  is  not  done  immediately.  This  emits  the InitiateChange.  Additionally,  the  function  will  always  emit  the  ChangedMiningAddress  event. Given the name of the event and that it is also emitted when the mining address is changed immediately because the participant is not part of the current validator set, this seems incoherent. As the event name suggests, the event should be emitted only when the mining address is changed or maybe renamed.  Acknowledged:  POA  Network  is  aware  that  the  ChangeMiningAddress  event  only  corresponds  to  the  immediate change of the mining address when a pool is not a validator. Unfortunately no events can be emitted at  POA Network - POSDAO -   17  DesignMediumVersion1Acknowledged        \fthe moment of the real change for the delayed case inside the system's finalizeChange function as events cannot be emitted during execution of this system operation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Limitations of the TxPermissions Contract", "body": "  The  _allowedTxTypes  function  of  the  TxPermissions  contract  is  applied  to  all  transactions  to  be include into a block. However this means all checks are only done on external transactions created from externally  owned  accounts,  internal  transactions  (calls  within  transactions)  are  not  subject  to  these checks.  Some of these checks including e.g.  if (validatorSetContract.isValidator(_to)) {     // Validator's mining address can't receive any coins     return (NONE, false); }  can  be  circumvented  by  internal  transaction.  Internal  transactions  are  calls  from  within  bytecode execution, e.g. during execution of a smart contract.  Risk Accepted:  POA  Network  is  aware  that  the  rules  defined  by  the  TxPermissions  contracts  are  only  applied  to transactions of EOAs.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Role Switch Needed", "body": "  The  TokenMinter  contract  calls  permissioned  functions.  These  are  mint, setBridgeContract, transferOwnership. To successfully call these functions, the TokenMinter contract needs to be the owner of the ERC677MultiBridgeToken contract.  token  contract   Regarding the setBridgeContract we have opened a separate issue because this call will always fail. But the ERC677MultiBridgeToken contract also implements other functions that are permissioned to be called only by the owner. Given the TokenMinter contract is the owner these functions could not be are:  addBridge,  removeBridge,  setBlockRewardContract, called.  These  setStakingcontract.  functions   To call this functions, the ownership needs to be transferred from the minter contract to an other contract and then back. This seems undesirable.  Acknowledged:  POA Network explains that the TokenMinter contract is used as an intermediate owner contract for the PermittableToken contract wich represents the STAKE token. To clarify this, comments where added to the TokenMinter contract.  POA Network - POSDAO -   18  DesignMediumVersion1RiskAcceptedDesignMediumVersion1Acknowledged                  \f6.6   Gas Inefficiency During Removal From Array  The staking contract keeps track of the pools using multiple arrays. When an entry has to be removed, this is done as in the following example:  uint256 indexToDelete = poolToBeRemovedIndex[_poolId];     if (_poolsToBeRemoved.length > indexToDelete && _poolsToBeRemoved[indexToDelete] == _poolId) {         uint256 lastPool = _poolsToBeRemoved[_poolsToBeRemoved.length - 1];         _poolsToBeRemoved[indexToDelete] = lastPool;         poolToBeRemovedIndex[lastPool] = indexToDelete;         poolToBeRemovedIndex[_poolId] = 0;         _poolsToBeRemoved.length--;     }  In case that the removed entry was already last in the list two SSTORE and one SLOAD operation could have been skipped.  Acknowledged:  Client states that this operation is quiet rare and, hence, will not change the implementation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Inconsistent Use of Safemath", "body": "  The code has multiple calculations including multiplications and divisions without safemath. Even though we  could  not  find  a  place  where  we  think  calculation  would  over  or  underflow,  the  consistent  use  of safemath would ensure this.  Risk accepted:  Safe math was not used intentionally in critical functions to not cause reverts and risk a network break down. Hence, POA network accepted the risk.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Potentially Compromised Key Needed to", "body": " Change Key  To change a potentially compromised staking key, the staking key is needed. Even though, the mining key is not used for tasks like key changes, in this case it might make sense from a security perspective. One reason to change a key is that it might be corrupted. In this case, it might be safer to use an other already existing key to change it.  Acknowledged:  POA network wants to keep the strong separation regarding the key usage.  POA Network - POSDAO -   19  DesignLowVersion1AcknowledgedDesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                        \f6.9   Superfluous Call of  _finalizeNewValidators  changeMiningAddress sets _finalizeValidators.list to the unedited _pendingValidators. In  finalizeChange  triggers _finalizeNewValidators.  _finalizeNewValidators  first  removes  all  validators  and  then  adds the same. This seems unnecessary. Additionally, the comment suggest another use case for the else if.  true  and   the  else   condition   to  be   causes   this   if   Acknowledged:  POA network acknowledged the issue but decided to leave the code unchanged.  POA Network - POSDAO -   20  DesignLowVersion1Acknowledged        \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  3  7  -Severity Findings  -Severity Findings  -Severity Findings   Failing Function Call    No Canonical Definition of Calldata for onTokenTransfer    claimOrderedWithdraw Not Always Successful   -Severity Findings  Incorrect Comment in finalizeChange   Incorrect Description    Make onTokenTransfer() External    Multiplication After Division    No Indexed Fields for ReportedMalicious    Unchecked Return Value of Transfer    certify Missing Sanity Check   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Failing Function Call", "body": "  The  TokenMinter  contract  implements  the  function  setBridgeContract  which  should  call tokenContract.setBridgeContract.  The  setBridgeContract  function  does  not  exists  in  the ERC677MultiBridgeToken contract. Hence, the function call would fail and the interface definition at the beginning is incorrect.  Specification changed:  POA Network explains that the TokenMinter contract is used as an intermediate owner contract for the PermittableToken contract wich represents the STAKE token. To clarify this, comments where added to the TokenMinter contract.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   No Canonical Definition of Calldata for ", "body": " onTokenTransfer  POA Network - POSDAO -   21  CriticalHighMediumSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1Speci\ufb01cationChanged                  \fThe function onTokenTransfer uses inline assembly to read the receiver and calldata from the calldata arguments.  The  assembly  strongly  relies  on  some  assumptions  about  the  argument  encoding  of  the Solidity.  One  of  them  is  that  there  are  no  \"garbage  bits\"  between  the  byte  offset  of  the bytes  calldata  _data  variable  and  the  length  field  of  the  bytes  calldata  _data  argument. This  assumption  will  hold  true  in  most  cases,  but  is  not  guaranteed  to  hold.  This  assumption  can  be eliminated  letting  the  compiler  copy  the  _data  into  the  memory  and  dealing  with  it  there.  Full expectations  about  the  expected  information  in  the  _data  argument  must  be  properly  documented,  to avoid the misinterpretation of the interface.  function onTokenTransfer(     address _from,     uint256 _value,     bytes calldata _data ) external returns (bool) {  A similar situation can be found in the TxPermissions contract.  Specification Changed:  The code has been commented as follows:  // It is assumed that the `_data` field contains the `length` field in its first 32 bytes. // There are data bytes right after the `length` field (without \"garbage bits\" between them).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   claimOrderedWithdraw Not Always", "body": " Successful  After  using  the  StakingAuRa.orderWithdraw()  function  the  validator  can  complete  the  withdrawal starting from the next epoch using claimOrderedWithdraw().  To prevent abuse, this function queries _isWithdrawAllowed once more in order to determined if the validator  may  have  been  banned  in  the  meantime.  However  _isWithdrawAllowed  also  includes  a check whether staking or withdrawals are currently allowed using areStakeAndWithdrawAllowed().  Normally such actions are not allowed near the end of a staking epoch in order to not interfere with the validator selection process. Note that claiming a previously ordered withdrawal has no influence on this and hence shouldn't be subject to this restriction. If a party happens to claim their withdrawal at the end of an epoch their withdrawal fails without apparent reason.    The _isWithdrawAllowed function has been refactored and parts of it's functionality has been moved into a new _isPoolBanned() function. This function is now querried in claimOrderedWithdraw() which resolves problem with the blocked withdrawals at the end of an epoch as described above.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Incorrect Comment in finalizeChange", "body": "  POA Network - POSDAO -   22  DesignMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \fThe  comment  in  the  else  if  branch  suggest,  it  is  only  been  executed  in  case  of  malicious  validator reporting.  But the code is also executed in case of mining address changes.    The code comments were corrected and elaborated.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Incorrect Description", "body": "  In StakingAuRaBase the function description of _stake(address, address, uint256) is  // @dev The internal function used by the `_stake` and `moveStake` functions.  But function is also used in initialValidatorStake, _addPool.    The code comments were corrected and elaborated.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Make onTokenTransfer() External", "body": "  Function StakingAuraTokens.onTokenTransfer() has visibility public. This means the function can be called externally and internally from within the contract.  Inside this function the calldata is read. This is the data passed alongside the call to the contract and remains unchanged if another function within the contract executes another contract as on a bytecode level  this  is  only  a  JUMP.  Function  onTokenTransfer  is  currently  only  called  from  externally  and  not internally  from  within  the  StakingAuraTokens  contract.  Hence,  the  calldata  consists  of  the  function arguments  as  expected.  Due  to  the  dependency  on  calldata  the  functions  visibility  may  be  external instead of public to avoid the function being called from within the contract accidentally during future code changes.    The function visibility as well as the reads from memory were changed accordingly.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Multiplication After Division", "body": "  In ValidatorSetAuRa.reportMaliciousCallable() a multiplication is performed after a division:  POA Network - POSDAO -   23  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \faverageReportsNumber = (reportsTotalNumber - reportsNumber) / (validatorsNumber - 1) [...] reportsNumber > validatorsNumber * 50 && reportsNumber > averageReportsNumber * 10  Due to possible precision loss, this should be avoided.    The multiplication is now done before division.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   No Indexed Fields for ReportedMalicious", "body": "  The  ReportedMalicious  event  has  multiple  fields  that  might  be  worth  indexing.  No  field  is  indexed. POA Network might re-evaluate if this is desired.    The event has now indexed fields.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   Unchecked Return Value of Transfer", "body": "  BlockRewardAuRaTokens.transferReward()  In  and StakingAuRaTokens._sendWithdrawnStakeAmount()  the  boolean  return  value  of  the  call  to erc677TokenContract.transfer() is ignored.  While  most  ERC-20  Tokens  (ERC-677  implements  the  ERC-20  Standard)  and  the  ERC677  token implementation  available  in  the  repository  revert  upon  failure,  the  standard  does  not  require  this  and returning false instead of reverting is valid according to the standard. As the POSDAO system is highly customizable the situation may arises where a token contract not reverting on failure is used.  Similarly  return  TokenMinter.mintReward() is also ignored.  value   the   of   the   call   to   tokenContract.mint()   inside    The transfer functions are wrapped into a require. The mint function remained as it is since it is called by the BlockReward.reward function which is critically sensible for reverting according to POA network.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.10   certify Missing Sanity Check", "body": "  The Certifier implements certify. The function allows certifying the same address multiple times. The Confirmed event would be emitted misleadingly multiple times.  POA Network - POSDAO -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  An appropriate sanity check was added.  POA Network - POSDAO -   25  \f8   Notes  We leverage this section to highlight potential pitfalls which are fairly common when working Distributed Ledger Technologies. As such technologies are still rather novel not all developers might yet be aware of these  pitfalls.  Hence,  the  mentioned  topics  serve  to  clarify  or  support  the  report,  but  do  not  require  a modification  inside  the  project.  Instead,  they  should  raise  awareness  in  order  to  improve  the  overall understanding for users and developers.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Avoiding Function Identifier Clashes", "body": "  The current proxy scheme is vulnerable to duplicated 4-byte function identifiers which could result in a function  identifer  clash.  POA  Network  prevents  this  by  using  an  off-chain  script  to  check  for  clashes. There are also on-chain solutions like the upgradable transparent proxy solution by OpenZeppelin which might be worth considering.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   ERC677 Standard Is a DRAFT", "body": "  The ERC677 standard is based on a eip having draft status since it's creation in 2017. Such standards are subject to changes before the eip's status is finalized.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Most of the RedBlackTree Library Functions", "body": " Unused  Following function of the RedBlockTree Library are unused and hence dead code.  BokkyPooBahsRedBlackTreeLibrary.first() BokkyPooBahsRedBlackTreeLibrary.getEmpty() BokkyPooBahsRedBlackTreeLibrary.getNode() BokkyPooBahsRedBlackTreeLibrary.isEmpty(uint256) BokkyPooBahsRedBlackTreeLibrary.next() BokkyPooBahsRedBlackTreeLibrary.treeMinimum()  Note as the functions are not used within the POSDAO system these were not reviewed as part of this audit.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Pragma Experimental ABIEncoderV2", "body": "  Contract  TxPriority  uses  pragma  experimental  ABIEncoderV2.  In  the  compiler  version choosen the new ABI encoder is still considered to be experimental.  POA Network - POSDAO -   26  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   UTF-8 Charset  The validator and the staking contract allow names to be set for pools. The charset for string is UTF-8. UTF-8  has  some  similar  looking  characters,  which  for  a  human  reader  some  of  these  letters  are indistinguishable.  This allows so called visual spoofing of names. Users and front-end developper should excercise extra caution.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.6   Unreliable Event Emission When Mining", "body": " Address Is Changed  When reporting a malicious validator, the mining address is used and the following event emitted.  The  _maliciousMiningAddress  might  change  between  multiple  reportings.  Hence,  the  mining address is no reliable information to process from across multiple events.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.7   Unused Code _removeMaliciousValidator", "body": "  The  ValidatorSetAuRa  contract  implements  the  function  _removeMaliciousValidator.  This function is not called at all. The only function it appears is in _removeMaliciousValidators. But it is commented  out  there.  Furthermore,  the  function  _removeMaliciousValidators  does  not  do anything  except  for  setting  lastChangeBlock.  Hence,  also  removeMaliciousValidators  is basically only setting this variable.  This also affects parts of reportMalicious. We were verbally informed that client is aware of this and this will be fixed for the final review. Else, this would turn into an issue.  POA Network - POSDAO -   27  NoteVersion1NoteVersion1NoteVersion1          \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Accrued Interest Is Not Accounted in ", "body": " trancheValue  CS-XENA-002  The interest that is owed to LPs by an open leveraged position is only accounted for when that position is updated (increased or reduced), in _calcPositionFee().  If a position is opened, but then no longer updated for a long time, a significant amount of interest may accrue.  This  pending  interest  will  not  be  calculated  in  _getTrancheValue(),  leading  to  an undervaluation of LP shares.  Consider the following situation:  There are 2 LPs, both with an equal amount of liquidity. A trader opens a position. The position is open for 1 year and is paying 50% APR in interest. After a year, one of the LPs leaves. One minute later, the trader closes their position. Now, the trader will pay the full interest amount to the remaining LP, even though the risk of the position was shared equally among both LPs.  Xena Finance - Xena -   14  DesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedAcknowledgedRiskAcceptedLowRiskAcceptedRiskAcceptedRiskAcceptedCodePartiallyCorrectedRiskAcceptedAcknowledgedAcknowledgedDesignMediumVersion1RiskAccepted           \fA third LP could even front-run the transaction which closes the position, depositing an equal amount as the remaining LP to the pool. The trader will now pay half of their accrued interest to the third LP, even though  they  did  not  take  any  risk.  The  third  LP  could  immediately  withdraw  their  liquidity  afterward, receiving a risk-free profit.  The  effect  of  this  will  be  larger,  the  longer  positions  remain  open  without  being  updated.  If  positions typically  do  not  stay  open  for  a  long  time,  the  accrued  interest  will  likely  be  small  enough  that  the undervaluation of LP shares is negligible.  Risk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Hardcoded Stablecoin Price", "body": "  CS-XENA-004  In _getCollateralPrice(), if the collateral asset is marked as a stablecoin, the value is hardcoded to 1 USD. The configured oracle is not queried.  In case a stablecoin loses peg, this price will not match the oracle price.  The PnL (against USD) of shorts is always paid out as if the stablecoin was worth 1 USD, no matter the actual value. The collateral is valued consistenly between increasing and decreasing a position.  However,  in  _getTrancheValue()  of  LiquidityCalculator,  the  stablecoins  are  valued  at  their oracle price. The PnL of shorts is calculated in USD, independently of the current stablecoin price.  Consider the following illustrative situation:  1. A pool has one tranche and no opening and trading fee, with 2000 USDC liquidity. A trader has an open short position with 100 USDC collateral. They currently have a positive PnL of 100 USD. The tranche  has  reserved  1000  USDC  of  collateralToken  from  LPs.  The  oracle  price  of  USDC  is 1 USD. The trancheValue will be calculated as (2000 - 1000) * 1 - 100 = 900.  2. The oracle price of USDC collapses to zero.  3. Now, the trancheValue will be calculated as (2000 - 1000) * 0 - 100 = -100.  4. The trader closes their short. They will be paid out their collateral and 100 USDC (worth 0 USD).  5. Now, the trancheValue will be calculated as (1900 * 0) = 0.  In this extreme (and unlikely) example, the system invariant that AUM (trancheValue) must always be positive,  can  be  broken.  This  would  lead  to  _getTrancheValue  always  reverting  when  casting toUint256(), which will make it impossible to add or remove liquidity from that tranche.  // aum MUST not be negative. If it is, please debug     return aum.toUint256();  A  price  collapse  of  the  stablecoin  to  zero  is  the  most  extreme  case,  but  the  same  effect  on trancheValue  happens  in  a  smaller  way  as  soon  as  the  oracle  price  of  the  stablecoin  is  not  exactly 1 USD.  The  incorrect  trancheValue  will  lead  to  LP  shares  being  over-  or  undervalued,  which  can  lead  to losses for LPs.  Xena Finance - Xena -   15  CorrectnessMediumVersion1RiskAccepted        \fRisk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   LP Fee Distribution Is Unfair", "body": "  CS-XENA-018  Upon  position  increase/decrease/liquidation,  the  LP  fee  is  scaled  and  distributed  according  to  the  risk factor, and not according to the distribution of the reserve amount across the tranches. In the case where the system has three tranches (junior, mezzanine, and senior) and the junior tranche is full, the risk for newly  opened  positions  will  only  be  distributed  across  the  mezzanine  and  senior  tranches.  But  in  this case, the junior tranche will still receive a share of the LP fee, although it does not participate in the risk, and the mezzanine and senior tranches will not get rewarded according to the new risk.  Consider the following situation:  1. There is a pool with two tranches. Tranche A has 2/3 of the total riskFactor, tranche B has 1/3.  Tranche A has only one LP, Alice.  2. Each  time  a  trader  wants  to  take  leverage,  Alice  front-runs  the  increasePosition  call  of  the  executor with removeLiquidity, removing her entire balance.  3. When  increasePosition  is  executed,  there  is  no  unreserved  liquidity  in  tranche  A,  so  the  full  amount is reserved in tranche B.  4. Alice deposits her balance again.  5. When the trader closes their leveraged position, Alice receives 2/3 of the positionFee, as well  as the borrowFee (interest), even though she did not provide any leverage to the trader.  Upon a swap, the LP fee is similarly scaled and distributed according to the risk factor, and not according to the distribution of the amountOut. So, the LP fee does not reflect the liquidity utilization.  Acknowledged:  Xena Finance acknowledged the issue with the following response:  This is intended behavior  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Missing Documentation", "body": "  The codebase is poorly documented and almost no natspec has been written.  Xena Finance did not supply any code-external documentation. Only a reference to a third-party project's documentation website with similar functionality was given.  A well-documented codebase helps integrators and improves the overall security by allowing readers to better understand the role of a piece of code, as well as any assumptions that are made.  CS-XENA-005  Xena Finance - Xena -   16  DesignMediumVersion1AcknowledgedDesignMediumVersion1RiskAccepted                \fRisk accepted:  Xena  Finance  understands  and  accepts  the  risk  posed  by  this  issue,  but  has  decided  not  to  make  a change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Contracts Not Implementing Their Interface", "body": "  Some contracts do not implement their interface, which could lead to problems when integrated.  CS-XENA-008   Pool should implement IPoolWithStorage   LPToken should implement ILPToken   Oracle should implement IPriceFeed   OrderManager should implement IOrderManagerWithStorage  Risk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Free Leverage Within Accrual Interval", "body": "  The interest for leveraged positions accrues once per accrualInterval.  As a result, a trader could avoid paying any interest by creating a leveraged position after interest has been  accrued,  then  closing  the  position  again  before  the  next  accrual.  The  positionFee  will  still  be paid.  CS-XENA-009  Risk accepted:  Xena Finance understands and acknowledges this issue, but has decided not to make a code change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Incorrect Fee Calculation When Oracles", "body": " Disagree  In  LiquidityCalculator,  _calcFeeRate()  calculates  the  fees  for  a  swap  based  on  if  the  swap moves the pool towards the targetWeight or away from it. For this, the value of the token is calculated based on tokenPrice. The targetWeight is calculated based on the Pool.virtualPoolValue.  In the normal case, these values are correct. However, in special conditions, the Oracle does not return the Keeper's posted price, but instead gives a price that is more favorable to the protocol. For example, the tokenPrice of tokenIn for a swap will be undervalued.  CS-XENA-011  Xena Finance - Xena -   17  DesignLowVersion1RiskAcceptedDesignLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                        \fThe Pool.virtualPoolValue is calculated as an average of undervaluing and overvaluing all tokens. This means that in virtualPoolValue, the tokenIn will not be undervalued in the same way.  MathUtils.average(liquidityCalculator.getPoolValue(true), liquidityCalculator.getPoolValue(false));  As  a  result,  the  weights  are  computed  incorrectly,  as  values  that  have  different  \"rounding\"  applied  to them are compared as if they were rounded the same.  Ultimately, this will lead to the fee calculated by calcFeeRate() to be either too high or too low.  Risk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.8   Missing Reentrancy Protection", "body": "  CS-XENA-014  functions Although  no  attack  vector  Pool.liquidatePosition  and  view  function  virtualPoolValue  should  implement  reentrancy protection to avoid any potential issue.  for  reentrancy  or  read-only  reentrancy  was   found,   the   Code partially corrected:  A reentrancy guard has been added to Pool.liquidatePosition.  virtualPoolValue() has not been changed, so integrators must be careful when calling this function.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.9   No Slippage Protection on poolSwap", "body": "  The _poolSwap function in OrderManager has a _minAmountOut argument, which can be used for slippage protection.  CS-XENA-015  However,  when  _poolSwap()  functionality is not used, always passing a _minAmountOut of 0.  is  called   from  _executeLeveragePositionRequest(),   this  Risk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.10   OrderLens Marks Inexistent Swap Orders as", "body": " Executable  Xena Finance - Xena -   18  DesignLowVersion1CodePartiallyCorrectedDesignLowVersion1RiskAcceptedCorrectnessLowVersion1Acknowledged                        \fThe  default  status  of  an  order  is  OPEN  and  the  values  of  an  uninitialized  order's  amountIn  and function  OrderLens.canExecuteSwapOrders  will  mark minAmountOut  will  be  0.  So,  non-existent orders as non-rejected, but they will fail if submitted to the OrderManager.  the   CS-XENA-019  Acknowledged:  Xena Finance answered:  We are aware of this. Contracts don't use this function so we keep that for convenience.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.11   OrderLens Missing Checks for Executable", "body": " Leverage Orders  The  function  OrderLens.canExecuteLeverageOrders  does  not  do  any  check  for  INCREASE requests  and  only  does  minimal  checks  for  DECREASE  requests,  e.g.,  the  fee  is  not  fully  computed. Therefore, it may happen that an order marked as executable by the function will fail if submitted to the OrderManager.  CS-XENA-017  Acknowledged:  Xena  Finance  acknowledged  this  issue  and  has  decided  not  to  make  a  code  change.  Xena  Finance states:  Contracts don't use this function. We keep it for compatibility with backend/frontend logic.  Xena Finance - Xena -   19  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Wrong Accounting upon Margin Account Top up   -Severity Findings   Hardcoded Contract Addresses    PriceReporter Will Not Execute Every Second Swap Order   -Severity Findings   CEI Pattern Not Applied   Incorrect Comments   Interest Rate Is Not Constrained    Missing Events   IPool Is Missing Signature for liquidatePosition()   0  1  2  5  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Wrong Accounting upon Margin Account Top", "body": " up  CS-XENA-001  When  collateral  is  added  to  a  long  position  without  changing  the  position's  size,  the  function _reservePoolAsset distributes the collateral in the tranches' poolAmount and guaranteedValue. The distribution is done according to the risk factor and current utilization of each tranche, calculated in _calcReduceTranchesPoolAmount().  Note  that  the  amount  of  collateral  that  can  be  added  to  a  tranche  is  limited  to  the  unreserved  amount available  in  that  tranche.  In  an  extreme  case  where  all  tranches  have  a  high  utilization,  it  will  be impossible  large  amount  of  collateral  while  keeping  position  size  equal,  as _calcReduceTranchesPoolAmount() will revert if the amount of collateral to add is higher than the total unreserved amount in all tranches.  to  add  a   When releasing the asset, the distribution is done according to the ratio of reserved amounts across the tranches.  In  the  case  of  a  collateral  top-up,  collateral  will  be  distributed  among  the  tranches,  but  no additional amount is reserved. This means the distribution of the collateral and reserved amount may not match. This may lead to a wrong accounting, incorrect pricing of LP shares, and reverting transactions.  Consider the following example:  There are 2 tranches, each with the same risk factor for a given asset. When a long position is opened, tranche 0 is at full utilization, so the entire collateralAmount and reserveAmount will be given to tranche 1. Time passes and now the trader wants to increase their collateral, while keeping the size the same. At this  point  in  time,  tranche  1  has  full  utilization,  so  all  the  extra  collateral  will  be  given  to  tranche  0.  No  Xena Finance - Xena -   20  CriticalHighSpeci\ufb01cationChangedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1Speci\ufb01cationChanged           \fadditional  amount  is  reserved.  Now,  the  trader  closes  their  position.  The  full  amount  of  collateral  (that they deposited over 2 transactions) will be withdrawn from tranche 1's poolAmount, as only the ratio of reserveAmount is taken into account when closing a position. This is incorrect, as a part of the collateral was actually attributed to tranche 0. Tranche 1 will have fewer funds than it should, while tranche 0 will have more.  The guaranteedValue for the tranches will also be incorrect.  Specification changed:  Xena Finance acknowledged the issue and changed the spec to use only one tranche, which resolves the issue. Xena Finance stated:  We will use 1 tranche model for this version.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Hardcoded Contract Addresses", "body": "  In LiquidityRouter, the address of the wrapped ether contract is hardcoded.  IWETH public constant weth = IWETH(0x82aF49447D8a07e3bd95BD0d56f35241523fBab1);  CS-XENA-003  The same is true in OrderLens:  address constant WETH = 0x82aF49447D8a07e3bd95BD0d56f35241523fBab1;  While this would be correct on Arbitrum One, this project is intended to deploy on Base Mainnet. On Base Mainnet, this address does not contain a deployment of WETH. As a result, the router will not work with WETH since the call to deposit() will fail and make the transaction revert.  Similarly, in Oracle, an address for a sequencer uptime feed is hardcoded.  /// @notice arbitrum sequence uptime feed AggregatorV3Interface public constant sequencerUptimeFeed =     AggregatorV3Interface(0xFdB631F5EE196F0ed6FAa767959853A9F217697D);  This feed is specific to Arbitrum One and does not function on Base Mainnet.  If  the  codebase  is  deployed  with  the  current  hardcoded  addresses,  no  funds  will  be  at  risk  since  the system will not work at all.  Furthermore, in OrderManager an address for EthUnwrapper is hardcoded.  address public constant ETH_UNWRAPPER = 0x1730CdEe8f86272eBae2eFD83f94dd9D5D855EeD;  A contract exists at this address on Base Goerli. Since no contract has been deployed at this address on Base Mainnet, we cannot determine whether it is correct.    Xena Finance - Xena -   21  CorrectnessMediumVersion1CodeCorrected        \fThe addresses are now given as an argument in the constructor, or in initialize() for contracts that will be used behind a proxy.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   PriceReporter Will Not Execute Every Second", "body": " Swap Order  CS-XENA-006  In postPriceAndExecuteOrders(), when looping over swap orders, i is incremented twice. Once in the post-loop expression, and once in the loop body.  As a result, half the orders will be skipped.  for (uint256 i = 0; i < swapOrders.length; i++) {     try orderManager.executeSwapOrder(swapOrders[i], payable(msg.sender)) {} catch {}     unchecked {         ++i;     } }    i is now only incremented once per loop.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   CEI Pattern Not Applied", "body": "  The  checks-effects-interactions  pattern  that  prevents  reentrancy  attacks  is  not  followed  in  the  function executeLeverageOrder().  The  status  of  the  order  is  set  to  FILLED  only  after  the  call  to _executeLeveragePositionRequest(), which may send ETH to the owner with full gas().  We  do  not  see  a  direct  attack  vector  through  this  reentrancy,  but  we  recommend  fixing  this  as  a preventative measure.  CS-XENA-007    The  code  has  been  updated  to  first  mark  the  order  as  FILLED,  and  then  make  the  call  to _executeLeveragePositionRequest().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Incorrect Comments", "body": "  1. The comment above the function OrderManager._createIncreasePositionOrder specifies the  construction  of  the  _data  field.  It  mentions  a  uint256  collateral,  but  no  such  field  is decoded from the _data.  CS-XENA-010  Xena Finance - Xena -   22  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                        \f2. In  the  struct  DataTypes.Position,  the  comment  on  the  member  reserveAmount  says  the  amount is in indexToken, but the amount is denominated in collateralToken.  3. In   PoolV1.md,   the   formula   for   long-side   ManagedValue   it   should   reads read  4. Some of the comments describing the constants in Oracle.sol do not represent the correct units.  For example:  MAX_CHAINLINK_TIMEOUT = 1 days; // 10%  Specification changed:  All mentioned comments have been corrected.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Interest Rate Is Not Constrained", "body": "  In Constants, an upper bound for the interest rate is provided:  uint256 public constant MAX_INTEREST_RATE = 1e7; // 0.1%  However, this value is not used anywhere. In particular, in InterestRateModel, there is no constraint on the interest rate parameter.  CS-XENA-012    The  interest  rate  in  SimpleInterestRateModel  is  now  constrained  to  be  strictly  smaller  than MAX_INTEREST_RATE in the constructor.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Missing Events", "body": "  1. When the OrderManager is initialized, the oracle is also set but no related event is emitted. This is  not consistent with the setOracle() function, which emits an event.  2. When the PriceReporter adds and removes reporters, no event is emitted. This is not consistent  with the similar functionality in Oracle, which emits events.  CS-XENA-013    1. The OracleChanged event is emitted at the end of initialize.  2. The  events  ReporterAdded  and  ReporterRemoved  are  emitted  when  a  reporter   is  added/removed.  Xena Finance - Xena -   23  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                    \f6.8   IPool Is Missing Signature for liquidatePosition()  The interface of the Pool, IPool, contains the events and errors relative to a liquidation, but is missing the signature of the function liquidatePosition.  CS-XENA-016    The missing function was added to the interface.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Duplicate Code", "body": "  LiquidityCalculator._calcDaoFee() is never called and is a copy of Pool._calcDaoFee().  CS-XENA-020    The function LiquidityCalculator._calcDaoFee() has been removed from the codebase.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Oracle Reporter Address Consistency", "body": "  The  function  Oracle.addReporter  allows  the  owner  to  add  the  address(0)  as  a  reporter,  but  the function Oracle.removeReporter does not allow to remove the address(0). This is not consistent with  the  behavior  of  the  same  functionality  in  PriceReporter,  which  does  not  allow  adding address(0).  CS-XENA-025    Oracle.addReporter no longer allows the address(0) to be added as a reporter.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Use of assert()", "body": "  The function Pool.setTargetWeight() is using assert(isAsset[item.token]); to ensure that a token is in the mapping of assets.  The Solidity documentation states the following:  CS-XENA-028  Xena Finance - Xena -   24  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                        \fAssert should only be used to test for internal errors, and to check invariants. Properly functioning code should never create a Panic, not even on invalid external input.  Moreover,  failing  assertions  will  consume  all  the  remaining  gas.  This  is  why  a  require()  statement should be used instead.    The assert has been replaced by a require statement;  Xena Finance - Xena -   25  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   EVM Version", "body": "  When  deploying  on  non-Ethereum  chains,  compatibility  with  the  different  EVM  versions  should  be considered. It must be checked that the target chain supports the used Solidity version. For example, not every  chain  supports  the  PUSH0  opcode,  introduced  in  Solidity  0.8.20.  If  the  Solidity  version  used  is changed  to  something  other  than  0.8.18  in  the  future,  these  differences  between  chains  should  be considered.  CS-XENA-021  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Gas Optimizations", "body": "  CS-XENA-022  The following is an incomplete list of possible gas optimizations:  1. Duplicated  slippage  protection:  OrderManager.executeSwapOrder()  implements  slippage  protection, but Pool.swap() already has the same functionality.  2. The  field  SwapOrder.price  is  assigned  in  OrderManager.placeSwapOrder()  but  never  used.  3. The  mappings  userLeverageOrderCount  and  userSwapOrderCount  are  redundant,  as  a getter  returning  the  length  of  the  userLeverageOrders  and  userSwapOrders  arrays  would accomplish the same thing with higher gas efficiency.  4. The storage slot SimpleInterestRateModel.interestRate can be immutable.  5. The parameters _minAmountOut and receiver of the function OrderManager._poolSwap are always 0 and address(this). They could be replaced by their fixed value to decrease the length of the calldata.  6. The  check  done  in  OrderManager._requireControllerOrOwner  could  be  transformed following  De  Morgan's  law  to  be  more  gas  efficient  and  leverage  the  lazy  evaluation  of  the parameters.  7. The function OrderManager.cancelSwapOrder could load only the specific fields of order that are needed into memory, instead of the whole struct, since not all the fields will be read. The same applies for request in OrderManager._expiresOrder().  8. In OrderLens.getOpenLeverageOrders(), an array of constant size is first filled, then another array is created which contains the same elements, except that empty items are removed. Instead, only  non-empty  could  be  added  to  a  dynamic  size  array  using  array.push().  This  could  avoid needing the second array. The same applies for OrderLens.getOpenSwapOrders().  9. In  most  for()  loops,  incrementing  the  counter  can  be  marked  as  unchecked  to  avoid  an  unnecessary overflow check. This is done in some places, but not systematically.  10. In certain callpaths, the oracle is queried multiple times for the same price. Caching certain prices could save gas. An example is the addLiquidity callpath, where the oracle is queried once for  Xena Finance - Xena -   26  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \feach  refreshVirtualPoolValue().  supported   token   from   calcAddLiquidity(),   then   twice  more   from  11. Most  uint256  storage  slots  in  PoolStorage  have  a  known  maximum  size.  For  example,  fee values  or  the  accrual  interval.  These  values  could  use  smaller  data  types,  which  would  allow packing them with other values to save gas.  12. The SwapOrder and LeverageOrder structs could be optimized by choosing a smaller data type  for some of the fields, e.g., submissionBlock, submissionTimestamp, or expiresAt.  13. Upon interest accrual, it could save gas to check whether the interest has already been accrued for  the current interval and return early if it has, avoiding the interest rate computation.  Acknowledged:  Xena Finance acknowledged this issue and has decided not to make a code change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Hardcoded Contract Address", "body": "  In OrderManager, an address for EthUnwrapper is hardcoded.  address public constant ETH_UNWRAPPER = 0x1730CdEe8f86272eBae2eFD83f94dd9D5D855EeD;  A contract exists at this address on Base Goerli. Since no contract has been deployed at this address on Base Mainnet, we cannot determine whether it is correct.  CS-XENA-023  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Misleading onlyController Name", "body": "  The onlyController/_onlyController modifier/function's name is misleading, as they will accept the owner address as well, not only the controller.  CS-XENA-024  Acknowledged:  Xena Finance understands and acknowledges the issue.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Tokens With Low Decimals", "body": "  All  computations  that  split  token  amounts  into  different  ratios  are  rounded  down,  which  is  safer  for  the system.  While  it  is  not  a  problem  for  tokens  with  enough  decimals,  it  could  impact  tokens  with  low decimals (e.g., GUSD has 2 decimals) or relatively low decimals compared to its value (e.g., WBTC has 8 decimals). Such rounding could result in value being locked in the contract.  Tokens used must be carefully chosen so the value lost in precision errors is not too high.  CS-XENA-026  Xena Finance - Xena -   27  InformationalVersion1InformationalVersion1AcknowledgedInformationalVersion1Acknowledged                \fAcknowledged:  Xena Finance understands and acknowledges the issue.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Tokens With Many Decimals", "body": "  As the normalized price in Oracle is stored as a 30 decimal USD value, tokens used must be carefully chosen so their price will have enough precision.  For example, a token with a number of decimals close to 30 will have a low price precision.  CS-XENA-027  Acknowledged:  Xena Finance understands and acknowledges the issue.  Xena Finance - Xena -   28  InformationalVersion1Acknowledged      \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Add Then Remove Liquidity May Be Cheaper", "body": " Than Swap  Adding or removing liquidity, as well as swapping, has a fee. These fees are separately configured.  For a swap, the fees for in and out token are calculated and the higher fee is used. For liquidity, there is a fee on add as well as on remove.  If the fees for liquidity adding/removing are sufficiently low, it may be cheaper to emulate a swap by first adding and then removing liquidity in another token, than it is to do a direct swap. In particular, there is a minimum fee that is enforced on swaps, but this minimum is not enforced on add/remove liquidity.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   LPs Are Not Always Able to Remove Liquidity", "body": "  removal   Liquidity  i.e. poolAmount  -  reservedAmount,  so  if  the  tranche  is  fully  reserved  or  the  LP  has  a  position  in  a tranche greater than the unreserved amount, removal of liquidity will be limited to that amount.  the  unreserved  amount,   is  only  possible  within   from  a   tranche   LPs do not have a way to force the closure of open positions, so they may be unable to withdraw for a long time in this situation. However, they will also be earning a high interest rate.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Market Manipulation of Listed Assets Must", "body": " Not Be Profitable  Xena relies fully on an external oracle to determine the prices it offers to traders. This is what enables the zero-price-impact trading feature.  However,  it  also  comes  with  significant  risks.  Unlike  spot  markets,  large  positions  can  be  opened  and closed without affecting the market price. This means that it is important that the price on the market from which the external oracle gets its prices must not be manipulatable by an attacker.  If an attacker is able to move the external market price by an amount larger than the fee paid to swap or open  and  then  close  a  position  in  Xena  combined  with  the  cost  of  the  manipulation,  this  could  be  a profitable attack. The loss from such an attack would be taken by LPs. The profit for the attacker is limited by the percentage they manipulate the market and the maximum size of a position (or swap) the attacker can create.  If the attacker keeps their position open for less than accrualInterval, they may not need to pay any interest. See Free Leverage Within Accrual Interval.  Xena Finance - Xena -   29  NoteVersion1NoteVersion1NoteVersion1          \fTo mitigate this attack vector, Xena has 2 features: A maxLiquidity, which limits the size of longs and swaps, and a maxGlobalShortSize, which limits the size of shorts. Each of these can be configured per token.  These  values  must  be  configured  carefully,  in  such  a  way  that  the  cost  of  manipulating  the  external market is always larger than the profit that can be made from exploiting projects relying on that market's price. Only assets with highly liquid markets should be listed on Xena. The less liquid the external market is, the lower the maxLiquidity and maxGlobalShortSize must be. If an asset becomes less liquid over time, it should be delisted, or the limits should be lowered. Additionally, the limits should be lowered if there is another project (for example another deployment of Xena) that also relies on the same asset's price.  In  this  case,  the  limits  must  be  coordinated  such  that  the  total  profit  among  all  projects  from manipulating the price is still smaller than the cost of manipulation.  A historical example of such an attack on another zero-price-impact DEX (GMX) can be found here: http s://web.archive.org/web/20221015123657/https://twitter.com/joshua_j_lim/status/1571554171395923968  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Outdated Virtual Pool Value", "body": "  If liquidity is not added or removed frequently, the virtual pool value may be outdated. Integrators relying on the virtual pool value should call refreshVirtualPoolValue before using the value.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.5   Pay Token and Returned Token May Differ", "body": "  When using ETH or WETH, users must be aware of the following behaviors:  If  the  tokenIn  of  a  swap  order  was  ETH,  then  WETH  will  be  transferred  back  to  the  owner  if  the order is cancelled.  If the payToken of a leveraged order was WETH, then ETH will be transferred back to the owner if the order is cancelled.  If the payToken of a leveraged order was WETH, then ETH will be transferred back to the owner if the order expires.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.6   Public Execution of Leverage Orders Does", "body": " Not Work if Keeper Is Down  The  publicExecution  flag  should  allow  order  owners  to  execute  their  own  orders,  even  when  the executor is inactive.  However, public execution of leverage orders will not work if the Keeper does not post prices anymore. Leverage orders can only be executed if a price update happened after it was placed.  Xena Finance - Xena -   30  NoteVersion1NoteVersion1NoteVersion1                 \f8.7   Senior Tranche Assumes Full Risk in Extreme Situations  Different  tranches  have  different  risk  exposures,  which  are  dependent  on  the  riskFactor  of  the tranche.  In normal circumstances, a tranche will only assume a percentage of risk of each trade according to their riskFactor.  However,  in  extreme  scenarios  where  the  other  tranches  are  already  fully  utilized,  the senior  tranche  can  be  exposed  to  100%  of  the  risk  of  a  trade.  These  extreme  situations  likely  have  a higher  risk  to  the  LP  compared  to  \"normal  conditions\".  This  leads  to  senior  tranches  having  lower  risk exposure  (and  lower  fee  revenue)  during  \"normal  conditions\"  and  full  risk  exposure  during  \"extreme conditions\".  This  may  lead  to  the  overall  risk/reward  ratio  for  senior  tranches  to  be  worse  than  for junior tranches.  Users should take this into account when deciding which tranche they want to participate in.  Xena Finance affirmed that they are aware of this and that it is the intended behavior.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.8   Swaps on Pool Should Be Done Atomically", "body": "  When users are directly using the swap function of the Pool, it must be done within one transaction. The swap function expects the user's funds to already have been transferred to the contract before the call. If users were to first send the funds and then call swap() in two separate transactions, they will likely be front-run and lose their funds.  The OrderManager and LiquidityRouter provide helper functions to transfer and swap in the same transaction.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.9   System Is Paused if Chainlink Is Down", "body": "  The system relies on Chainlink prices for every user action. Users must be aware that the system will not work if one of the following conditions is met:  the Chainlink price has not been updated for some time and is stale (every token has a configurable timeout)   The chain's (initially Base) sequencer is down according to the Chainlink sequencer uptime feed   The chain's sequencer restarted less than 1 hour ago according to the Chainlink sequencer uptime  feed  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.10   Transaction Ordering MEV", "body": "  Transaction ordering in Xena is very important. Similarly to other markets, the execution of a transaction depends on the transactions before it. For example, the fees charged for a swap are dependent on the current token ratios in the pool. This is also known in the context of Ethereum as MEV.  Xena Finance - Xena -   31  NoteVersion1NoteVersion1NoteVersion1NoteVersion1               \fIn Xena, any user can make a swap at any time. However, other order types can only be executed by the executor  role  while  publicExecution  is  disabled.  The  smart  contracts  do  not  enforce  any transaction  order,  so  the  executor  is  free  to  decide  in  which  order  they  execute  orders.  It  can  also decide to censor some orders, never executing them. This is comparable to the role of block builders in Ethereum.  The executor has the potential to use its privileged position to extract some of this MEV-comparable value that is present for itself. Additionally, it seems to be intended that the executor role is held by the PriceReporter,  which  also  has  the  powerful  role  of  providing  asset  prices  to  the  Oracle.  Using postPriceAndExecuteOrders,  the  PriceReporter  can  update  the  oracle  price  and  then immediately  execute  orders.  In  particular,  it  can  execute  swap  orders  immediately,  before  other addresses have a chance to swap using the updated prices.  Users  must  ensure  that  the  executor  and  PriceReporter  are  behaving  as  expected  and  are  not using their privileged position to extract value for themselves, for example by taking payments for quicker execution, censorship, or by executing their own transactions first.  The  executor  should  publish  its  transaction  ordering  methodology,  so  that  users  can  hold  it accountable if it does not behave accordingly. It would also be possible to enforce some ordering rules on the smart contract level.  Xena Finance - Xena -   32  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Push3 Used Where Push2 Would Be Sufficient", "body": "  The ring buffer size (8191 in  two bytes, a PUSH2 would also be sufficient. This would result in a minor size reduction of the bytecode.  ), is pushed to the stack using PUSH3, however, as it only occupies  CS-EIP4788-010  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Merge Failure Cases for Gas Savings", "body": "  Generally,  we  expect  the  most  common  get  execution  case  to  be  the  one,  where  the  get  call  will succeed.  Hence,  we  try  to  optimize  the  gas  cost  for  this  case.  In  the  current  implementation,  the successful get contains two executions of JUMPI that branch off to the corresponding revert statements. If  the  two  conditions  were  combined  using  an  OR  operation,  only  a  single  JUMPI  would  be  needed. Thereby execution gas costs could be lowered in the successful get execution.  CS-EIP4788-002  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Negate Failure Conditions to Save Gas", "body": "  The contract has two conditions that can revert the execution:  CS-EIP4788-003  Ethereum Foundation - EIP-4788 Contract -   9  DesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedAcknowledgedDesignLowVersion2Version2DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                        \f1. calldatasize == 32  2. sload(calldataload(0) % HISTORY_BUFFER_LENGTH) == calldataload(0)  Usually,  we  expect  the  good  case  where  both  conditions  will  evaluate  to  true  to  be  the  most  common one.  However,  on  EVM-level  the  conditions  are  currently  implemented  so  that  in  the  good  case  the JUMPI  performs  a  jump.  As  a  result,  in  the  good  case  two  JUMPDEST  operations  are  executed,  which consume one gas each. If the conditions would be negated on EVM level by using SUB instead of EQ, the gas consumed by the JUMPDEST operations could be saved.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Reorder Operations to Save Gas", "body": "  The contract's source code contains a swap1 operation, which swaps out elements of the stack. Through a  different  order  for  the  preceding  operations,  the  swap1  instruction  can  be  omitted.  This  results  in  a lower execution gas cost and smaller contract size.  CS-EIP4788-004  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Replace Push Command With Msize for Gas", "body": " Savings  Towards the end of the get() function there is the following instruction:  push1 32  It is supposed to push the current memory size (32 bytes) onto the stack, so that this can be used as size input  for  the  return  statement.  Instead  the  msize  instruction  could  be  used,  which  achieves  the  same and reduces execution gas costs as well as contract deployment costs.  CS-EIP4788-005  Ethereum Foundation - EIP-4788 Contract -   10  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Zero-Timestamp Can Be Queried Successfully   -Severity Findings  -Severity Findings  Implications of Ring Buffer Size   Informational Findings  Inconsistent Comment   0  1  0  1  1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Zero-Timestamp Can Be Queried Successfully", "body": "  The get() function can be queried with the Zero-Timestamp even though no value has ever been set for the Zero-Timestamp. This violates the important property that all returned values must have previously been  set.  This  happens  because  the  EVM  storage  is  initialized  with  zeroes  which  allow  the  timestamp check to pass.  Note that this remains possible until the corresponding storage slot is first used.  With  0  as  an  argument  for  get(),  The  returned  beacon  root  would  be  zero.  This  leads  to  integrators being tricked into accepting the Zero-Hash as a valid beacon root which might allow exploits depending on the protocol.  CS-EIP4788-001    An explicit check has been added to make sure that the get() function reverts when a Zero-Timestamp is provided as calldata.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Implications of Ring Buffer Size", "body": "  The EIP-4788 states:  The ring buffer data structures are sized to hold 8192 roots from the consensus layer at current slot timings.  CS-EIP4788-008  Ethereum Foundation - EIP-4788 Contract -   11  CriticalHighCodeCorrectedMediumLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCorrectnessHighVersion1CodeCorrectedDesignLowVersion1CodeCorrectedSpeci\ufb01cationChanged                      \fIn  at a current SECONDS_PER_SLOT = 12 on the mainnet.   the code implements the circular buffer, however out of 98304 slots, only 8192 will be utilized  Effectively  the  ring  buffer  behaves  as  a  ring  of  integers  modulo  n,  where  n  is  its  size.  The ( current_timestamp + X * SECONDS_PER_SLOT ) mod 98304 function will produce a cyclic subgroup  of  order  8192  the SECONDS_PER_SLOT would change to 16, the cyclic subgroup will have order 6144, which is less than 8192.  Furthermore,  many  old  entries  from  the  12-second  interval  would  uselessly  remain  in  the  ring buffer.  if  SECONDS_PER_SLOT   is  12.  However,   future,   the   in   if,   Thus, the requirement of the EIP-4788 to have 8192 roots available in the ring buffer will not be satisfied if the SECONDS_PER_SLOT changes to 16 seconds. If the SECONDS_PER_SLOT changes to 13 seconds, the cyclic subgroup will have order 98304, thus increasing the storage requirements for the ring buffer by 12 times.  To summarize, the 98304 as a group order for the ring buffer is not an ideal choice, as it is not a prime number.  Potential  changes  to  the  SECONDS_PER_SLOT  will  drastically  change  the  behavior  of  the  ring buffer.  If the ( current_timestamp + X * SECONDS_PER_SLOT ) mod 8209 function is used instead, the cyclic subgroup will always have order 8209, since it is a prime number. That would have two key advantages:   The  ring  buffer  could  always  hold  the  most  recent  8209  beacon  roots  independent  of  SECONDS_PER_SLOT   The storage consumption would remain constant even when SECONDS_PER_SLOT changes  If the primary objective is to make sure that the ring buffer can hold all beacon roots of the past 24 hours, then  a  prime  ring  buffer  size  still  makes  sense,  but  a  bigger  one  has  to  be  chosen,  according  to  the lowest value SECONDS_PER_SLOT might have in the future.  Please note that the changes discussed here would require a change in the specification.    The  specification  has  been  changed  to  make  the  ring  buffer  size  8191,  which  is  a  prime  number.  The code has been changed accordingly. Hence, the new implementation benefits from the positive effects described above.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Inconsistent Comment", "body": "  In the code comments inside src/main.etk for the get() function, the same loaded calldata is once referred to as time and once as input. To avoid confusion a consistent label could be used for it in both places.  CS-EIP4788-009    The comments have been updated and are more consistent.  Ethereum Foundation - EIP-4788 Contract -   12  Version1InformationalVersion1CodeCorrected      \f7   Informational  We utilize this section to point out informational findings that are technically not issues. As the EIP served as a specification, we primarily check whether the code correctly and securely implements the EIP. Here, however,  we  also  point  out  possible  improvements  to  the  EIP.  Furthermore,  an  inconsistency  in  the comments of the source code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Changes in Block Interval", "body": "  As  long  as  the  block  interval  (SECONDS_PER_SLOT)  remains  at  its  current  value  of  12  seconds  two properties will hold:  1. A successfully written beacon root can only be overwritten after 8191 blocks have passed.  2. All successfully written beacon roots from past 24 hours are available in the contract.  CS-EIP4788-011  However, different changes in the block interval are possible:  Different, Fixed Block Interval  If,  at  a  block  X,  the  block  interval  changes  to  a  different  value,  e.g.,  8  seconds,  the  following  holds regarding the properties mentioned above:  1. This  property  is  temporarily  violated.  A  beacon  root  written  in  the  blocks  [X  -  8190,  X]  might  be  overwritten sooner due to the change in the interval.  2. This  property  is  temporarily  violated  for  the  beacon  roots  written  in  the  24  hours  before  X. Furthermore, if the new block interval is smaller than 11 seconds, the property will no longer hold as more than 8191 beacon roots are produced in 24 hours.  Variable Block Interval  If  the  block  interval  becomes  variable,  e.g.  there  are  10  seconds  between  blocks  X  and  X+1,  but  9 seconds  between  blocks  X+1  and  X+2,  then  the  following  holds  regarding  the  properties  mentioned above:  1. This property is permanently violated.  2. This property is permanently violated.  However, in all cases mentioned above, the following property always holds:  A  successfully  written  beacon  root  can  only  be  overwritten  after  8191  seconds  have  passed.  Hence, even during network changes, each beacon root will be available for more than two hours.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Gas Savings in Ring Buffer Layout", "body": "  Currently, the two ring buffer storage location segments are laid out as follows:  1. Timestamps: [0 , HISTORY_BUFFER_LENGTH - 1]  2. Beacon Roots: [HISTORY_BUFFER_LENGTH , 2 * HISTORY_BUFFER_LENGTH - 1]  Hence, to compute the beacon root storage slot based on the timestamp storage slot, the code currently adds HISTORY_BUFFER_LENGTH. However, a more efficient approach would be to use the EVM's NOT  CS-EIP4788-007  Ethereum Foundation - EIP-4788 Contract -   13  InformationalVersion2InformationalVersion1      \fopcode on timestamp slot for the beacon root storage slot computation. By doing this, both the execution gas cost and the overall contract size could be reduced.  Please note that this would require a change in the specification.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Minor Inconsistencies in Specification", "body": "  A few documentation parts are outdated in   :   The subsection Size of ring buffers in the EIP-4788 contains an outdated ring buffer size.   The  bytecode  in  the  README.md  of  the  code  repository  is  incorrect  based  on  the  command  presented above it.   The  cfg.png  showing  the  control-flow  graph  in  the  code  repository  is  outdated  as  it  does  not  contain the latest code.  CS-EIP4788-012  Ethereum Foundation - EIP-4788 Contract -   14  InformationalVersion2Version2    \f8   Notes  We leverage this section to highlight issues that could potentially arise when interacting with this contract. First  from  the  perspective  of  smart  contract  developers  and  then  from  the  perspective  of  execution clients.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Integration Guidelines for Developers", "body": "  Smart  contract  developers  who  aim  to  interact  with  the  beacon  roots  contract  should  be  aware  of  the following pitfalls:  1. Unless  most  smart  contracts,  this  contract  has  no  4-byte  abi  calldata  signature  to  select  the function.  As  you  are  not  calling  from  the  SYSTEM_ADDRESS  your  call  is  automatically  calling  the get function.  2. The  calldata  has  to  be  exactly  32  bytes  and  should  only  contain  the  timestamp,  in  big-endian  format, which is the EVM default.  3. Due to the points above, smart contract developers might perform a low-level call in the respective smart contract language. That low-level call generally does not perform checks, such as sufficient return  data.  Hence,  smart  contracts  performing  such  a  low-level  call  should  check  that  the RETURNDATASIZE == 32 using the features of the respective language.  4. Beacon roots are only available for a limited time. This is because a ring buffer is used where old values  are  overwritten.  In  particular  this  also  implies  that  a  timestamp  which  was  queried successfully in one block might not be available in the next block.  5. The   ring  buffer  might  contain  outdated  entries.  At   the HISTORY_BUFFER_LENGTH  will  be  chosen  so  that  roughly  one  day  of  beacon  roots  is  available. However, developers cannot assume that successfully queried beacon roots are from the past day. They might be as old as the FORK_TIMESTAMP.  time  of  writing   the   6. There  is  a  beacon  root  available  for  the  current  timestamp,  but  it  is  not  the  beacon  root  of  the  current block. It is the beacon root of the preceding block.  7. There might be no beacon root for current timestamp - 12 or more generally: there might be no beacon root for the timestamp of a particular slot that occurred recently. This is because slots can be missed. Then no blocks will be produced and no beacon root will be inserted.  8. To get the beacon root from time X do not query X. Instead the timestamp of the succeeding block must  be  used.  That  timestamp  is  generally  unknown  it  could  be  X+12,  X+24,  or  something completely different once the block interval changes.  9. Do not send ETH to the contract. The ETH will be lost. A STATICCALL can be used, as it does not  allow the transfer of ETH.  Please note that we have only covered pitfalls related to the get function as this is the only one smart contract developers should be able to call.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Note for Execution Clients", "body": "  Execution clients need to perform the set operation as part of block construction. They should be aware that:  Ethereum Foundation - EIP-4788 Contract -   15  NoteVersion1NoteVersion1      \fset never reverts. Hence, a non-reverting execution of the set function does not imply a correct call. In particular set would not revert if called with no calldata or with too much calldata. If less than 32 bytes of calldata are provided, the calldataload operation will pad the missing bytes with zeros.  Ethereum Foundation - EIP-4788 Contract -   16  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Use of Atomic Transactions Only", "body": "  The  router  performs  critical  actions,  of  which  many  should  not  be  done  separately  in  multiple transactions. All critical operations must be done in one atomic transaction.  Yearn - Yearn ERC4626 Router -   10  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   StakingRewards rewardsDistribution", "body": " Ownership Inconsistency  StakingRewardsInit.init() is called by the deployer after StakingRewardsDeploy.deploy() to  p.owner,  which  should  be  Maker's  PauseProxy. has  been  called,  setting  StakingRewardsInit.init() is therefore not called by the owner (as the Foundry script cannot be run by a governance Spell) and will revert. If p.owner is the deployer, then the ownership is not correctly transferred to the PauseProxy anywhere in the script.  its  owner   CS-EGTKD-001  Specification changed:  MakerDAO informed us that the audited deployment script is currently meant for testing purposes. The deployer  will  therefore  be  an  EOA.  This  will  change  later  in  Phase  0  of  the  Endgame  Plan,  where  the contracts are initialized via governance Spell setting the owner of the contracts to the PauseProxy. The deployment scripts will be used as templates for the final Spell.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Vest Minting Not Possible", "body": "  MakerDAO - Endgame Toolkit -   12  CS-EGTKD-002  CriticalHighSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1Speci\ufb01cationChangedCorrectnessHighVersion1CodeCorrected                \fDssVestMintable.pay()  calls  the  NGT  token's  mint()  function  to  generate  tokens  for  the  vesting. The  functions  is  guarded  and  can  only  be  accessed  by  a  ward.  The  DssVestMintable  contract  is never set as a ward of the NGT contract.    The initialization script now performs the following call, setting the ward of the NGT contract:  RelyLike(ngt).rely(vest);  This call is only possible if the deployer is an EOA that has been set as ward in the NGT contract. Since the script is currently only deploying contracts for testing purposes, the supplied NGT contract will have the correct rights in the given environment.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Vest Ownership Not Transferred at", "body": " Deployment  StakingRewardsDeploy deploys DssVestMintable, whose ward has unlimited token minting ability for the vested token by creating arbitrary new vests. The ward of DssVestMintable is not transferred to Maker's PauseProxy after deployment. It remains at the address of the deployer.  CS-EGTKD-003    The owner of DssVestMintable is now transferred to the given admin address of the deployment script. Since  the  deployment  script  is,  in  a  first  step,  run  by  an  EOA  and  only  used  for  testing  purposes,  the ownership  will  not  be  transferred  to  the  PauseProxy.  This  will  be  different  later  in  Phase  0  of  the Endgame plan.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Missing Checks", "body": "  CS-EGTKD-007  Phase0StakingRewardsInitScript  does  not  check  the  correct  state  of  some  of  the  deployed contracts. In particular, the following checks are missing:   stakingToken in StakingRewards is not checked to be the actual NST contract.   dssVest and stakingRewards in VestedRewardsDistribution are not checked to be equal  to the actual DssVestMintable and StakingRewards contracts.  It  is  not  checked  that  the  rewardRate  in  StakingRewards  has  already  been  updated  (e.g.,  by checking  that  lastUpdateTime  is  0).  This  is  possible  if  the  deployer  adds  their  own  rewards distribution contract and calls notifyRewardAmount with it.    MakerDAO - Endgame Toolkit -   13  SecurityHighVersion1CodeCorrectedSecurityLowVersion2CodeCorrected                 \fWhile originally the scripts related to the deployment and initialization of the farming module (including Phase0StakingRewardsInitScript.sol of the issue above) have been intended for testing/demo   these  scripts  have  been  adapted  to  be  used  for  the  actual  deployment  in purposes  only,  in  phase 0. The missing checks have been added to the code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   SubProxy rely() to MCD End Instead of MCD", "body": " ESM During Initialization  In the SubProxyInit library, the init() function sets MCD End as a ward of the SubProxy. MCD End has no  ability  to  administrate  arbitrary  contracts,  such  as  the  SubProxy  in  question.  The  purpose  of  the rely() is therefore unclear.  CS-EGTKD-006    MCD  End  has  been  replaced  with  MCD  ESM  (Emergency  Shutdown  Module)  which  will  be  able  to remove the PauseProxy from the wards of the contract.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Vest Should Not Have a Cliff Period", "body": "  VestedRewardsDistribution  requires  the  configured  vest  to  not  have  a  cliff  period  past  the  beginning. StakingRewardsDeploy however supports a non-zero value for vestEta.  CS-EGTKD-004    The vestEta option has been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Redundant Imports", "body": "  VestInit.sol  imports  dss-test/ScriptTools.sol  that  is  redundant.  It  is  never  used  in  this library, in addition, it is built on top of the forge standard library that can only be used for off-chain testing.  CS-EGTKD-005    The redundant import has been removed.  MakerDAO - Endgame Toolkit -   14  Version3CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion3CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Deployment Verification", "body": "  Note: This is only relevant for the deployment in Phase 0/1 of the Endgame plan.  Since deployment of the contracts is not performed by the governance directly, special care has to be taken  that  all  contracts  have  been  deployed  correctly.  While  some  variables  can  be  checked  upon initialization through the PauseProxy, some things have to be checked beforehand.  We therefore assume that all mappings in the deployed contracts are checked for any unwanted entries (by  verifying  the  bytecode  of  the  contract  and  then  looking  at  the  emitted  events).  This  is  especially crucial for wards mappings.  In the case of DssVestMintable, special care also has to be taken to make sure that no extra awards have been added by the deployer. During initialization, the PauseProxy adds the contract as a ward to the NGT contract. After this, if the deployer added any awards with a controlled address as usr, they are able to mint tokens to themselves.  MakerDAO - Endgame Toolkit -   15  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Bypassing Antisnipping Protection", "body": "  The  AntisnippingManager  implements  logic  to  protect  against  so-called  liquidity-snipping  (Just-in-Time Liquidity)  attacks  to  prevent  attackers  from  adding  much  liquidity  before  a  swap  and  removing  it  right afterwards to collect most of the fees while not being exposed to LP risks.  Kyber Network removes the economic incentive of such an attack by locking fees for vestingPeriod which means an immediate withdrawal of liquidity should set the collected fees to zero.  Note,  that  AntiSnipAttack  protection  only  comes  in  play  if  feeGrowthInsideLast  of  the  position manager and the feeGrowthInsideLast of the position are not equal:  if (feeGrowthInsideLast != pos.feeGrowthInsideLast) {     ....     (additionalRTokenOwed, feesBurnable) = AntiSnipAttack.update(  Kyber Network - KyberSwap Elastic -   12  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedSecurityHighVersion1CodeCorrected         \f    ... }  Also, feesBurnable can only be non-zero if liquidity is removed:  if (isAddLiquidity) {     .... } else if (_self.feesLocked > 0) {     feesBurnable = (_self.feesLocked * liquidityDelta) / uint256(currentLiquidity);     _self.feesLocked -= feesBurnable; }  Thus, the following attack is possible:  1. Attacker sees a huge swap and mints an enormous position  2. Swap occurs.  3. An attacker adds a small amount of liquidity. The position's feeGrowthInsideLast is updated.  However, rTokens are now locked.  4. An attacker removes all his liquidity which does not enter the AntiSnipAttack code since there was  no fee growth. Liquidity is withdrawn and rTokens remain locked.  5. After vestingPeriod has passed the attacker can withdraw the newly generated fees.  Even  though  the  attacker  does  not  immediately  withdraw  the  fees,  his  liquidity  came  and  went immediately while generating a temporarily locked profit for the attacker.    In version 3 of the code, the Antisnipping protection logic is triggered on every call of removeLiquidity function.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Function Pool.burnRTokens Return Values", "body": "  Function burnRTokens of Pool contract has following definition:  /// @return qty0 token0 quantity sent to the caller for burnt reinvestment tokens /// @return qty1 token1 quantity sent to the caller for burnt reinvestment tokens function burnRTokens(uint256 qty, bool isLogicalBurn)   external   returns (uint256 qty0, uint256 qty1);  However the qty0 and qty1 value are not assigned in the implementation of this function. Thus 0 values will be returned instead.  The position managers rely on these return values as they implement slippage protection as follows:  (amount0, amount1) = pool.burnRTokens(rTokenQty, false); require(amount0 >= params.amount0Min && amount1 >= params.amount1Min, 'Low return amounts');  Ultimately, the transaction will revert if amount0Min > 0 && amount1Min >0 holds.  Kyber Network - KyberSwap Elastic -   13  CorrectnessHighVersion1CodeCorrected        \f  The values are now properly assigned to the return variables.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Locked Funds Remain Locked After ", "body": " vestingPeriod Update  The AntiSnipAttackPositionManager prevents profitable snipping attacks by locking rewards for a certain in amount  of  stored  AntiSnipAttackPositionManager:antiSnipAttack[tokenId].feesLocked.  However,  if vestingPeriod is set to zero, feesLocked remains locked.  in  a  position  with  tokenId  are   time.  The   locked   fees   Assume the following scenario:  1. vestingPeriod = 1 day  2. User mints a position.  3. After 12 hours, the User adds liquidity to a position. Assume that 1 rToken in fees has been earned  totally while half of it is locked.  4. vestingPeriod set to 0.  5. Whenever the user performs a position-modifying action, the following code gets executed.  if (vestingPeriod == 0) return (feesSinceLastAction, 0);  6. Only the newly accumulated fees become claimable while the locked fees remain locked. Hence,  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "0.5 rTokens will be unclaimable.", "body": "  Thus,  changes  to  the  vestingPeriod  can  potentially  allow  users  withdrawal  of  more  fees,  than  it  was intended.  Current  AntiSnipAttackPositionManager  and  AntiSnipAttack  library  rely  on  constant vestingPeriod. To conclude, the AntiSnipAttack library should be aware that the vesting period for fees could change.    If  vestingPeriod  is  zero  and  fees  are  still  locked,  feesLocked  is  added  to  the  claimable  fees  and feesLocked is set to 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Broken/Partial ERC165 Support", "body": "  The  ERC-721  specifies  that  the  ERC-165  interface  must  be  implemented  which  defines  a  standard method to publish and detect what interfaces a smart contract implements.  function supportsInterface(bytes4 interfaceID) external view returns (bool);  The more derived ERC-721 contracts of Kyber Network do not overwrite this function. Hence, querying the  support  of  the  additionally  implemented  interfaces  through  supportsInterface()  will  return false.  Kyber Network - KyberSwap Elastic -   14  CorrectnessHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f  The  issue  has  been  addressed.  Function  supportsInterface  will  return  true  for  the  following interfaces.   ERC721Enumerable  IERC721Permit  Thus, they are considered as supported by the contract according to ERC-165.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Function Pool.unlockPool Reentrancy", "body": "  Pools  are  created  in  a  locked  state  and  need  to  be  unlocked  first.  The  unlockPool  function  first removes  the  lock  and  then  perform  the  mintCallback.  The  _initPoolStorage  is  called  after  the callback.  This  is  an  important  function  that  finalizes  the  setup  of  storage  for  the  pool.  This mintCallback after unlock and before _initPoolStorage can be misused by the malicious parties, since  all  pool  functions  will  be  available  during  the  call.  Attacker  can  potentially  misconfigure  or  abuse intermediate state inconsistency for its own profit. In addition, the mintCallback is usually performed to whitelisted position managers, while in this case any contract can be called.    The callback has been removed for unlocking pools. Now, funds have to be transferred to the pool before unlocking the pool.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Function ERC721Permit.permit Payable", "body": "  The  function  permit  has  a  payable  modifier  while  abstract  class  ERC721Permit  does  not  have  any other functions that can withdraw funds. The BasePositionManager that inherits this class has a separate receive function for ether transfers. Hence, the payable modifier could be removed from permit.    The payable modifier was removed from the permit function.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Function Pool.burnRTokens Natspec", "body": "  The  burnRTokens  does  not  describe  the  bool  isLogicalBurn  argument  with  a  @param  tag.  This argument greatly influences the result of burn and thus should be described.  Specification changed:  Kyber Network - KyberSwap Elastic -   15  SecurityMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                         \fisLogicalBurn is now documented.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Function Pool.burnRTokens Potential", "body": " Reentrancy  Certain  ERC20  tokens  perform  callback  on  token  transfers.  For  example,  ERC777.  Performing  _burn after  transfers  is  then  can  be  recognized  as  a  reentrancy  pattern.  While  the  burnRTokens  and  other Pool contract functions have reentrancy lock protection, there is possibility, that external contracts called during  the  transfer  callback,  might  misinterpret  the  State  of  the  Pool  contract.  For  example,  the reinvestL / totalSupply ratio will be off during this callback.  if (tokenQty > 0) token0.safeTransfer(msg.sender, tokenQty); tokenQty = QtyDeltaMath.getQty1FromBurnRTokens(sqrtP, deltaL); if (tokenQty > 0) token1.safeTransfer(msg.sender, tokenQty);  _burn(msg.sender, _qty);    The transfers have been moved to the very end of the function.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Function SwapMath.calcFinalPrice", "body": " Rounding Down  The  calcFinalPrice  calculates  the  final  price  for  swaps,  when  the  used  amount  hits  the  specified amount limit. Depending on the starting price and direction of price movement during the swap, the price needs to be rounded either up or down. If isToken0 == false && isExactInput == true, sqrtP increases and thus price needs to be rounded down, in order not to 'overshoot' the target price.  But the tmp component of the final price is computed with rounding up division operator:  uint256 tmp = FullMath.mulDivCeiling(absDelta, C.TWO_POW_96, currentSqrtP); return FullMath.mulDivFloor(liquidity + tmp, currentSqrtP, liquidity + deltaL);  Thus the returned value with certain chance will be more than intended.    The code has been adjusted such that now division is rounding down.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Gas Inefficiency in insert()", "body": "  Kyber Network - KyberSwap Elastic -   16  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fInsertions  into  the  linked  list  through  LinkedList:insert()  occur  only  in  internal  function PoolTicksState:_updateTickList. In insert() the following storage read occurs:  However,  that  value  corresponds  to  the  last  nextTick  in  _updateTickList.  Thus,  storage  reads could be reduced by passing an additional argument to insert.    insert now takes nextTick as an additional argument, reducing the number of storage reads.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Pool swap Max Tick Distance", "body": "  In the main loop of the swap function, to ensure that the tickOutside value is interpreted correctly the currentTick variable needs to be adjusted if the swap moves the price down:  swapData.currentTick = willUpTick ? tempNextTick : tempNextTick - 1;  the  next   On  MAX_TICK_DISTANCE == 487:  iteration  of   the   loop,   the  new   target   tick  distance  should  not  exceed   the  int24 tempNextTick = swapData.nextTick; if (willUpTick && tempNextTick > C.MAX_TICK_DISTANCE + swapData.currentTick) {     tempNextTick = swapData.currentTick + C.MAX_TICK_DISTANCE; } else if (!willUpTick && tempNextTick < swapData.currentTick - C.MAX_TICK_DISTANCE) {     tempNextTick = swapData.currentTick - C.MAX_TICK_DISTANCE; }  If willUpTick == false and tempNextTick - 1, then the tempNextTick will have at most 488 ticks between the matching tick for sqrtP. Thus, desired Dx*fee / x < 0.0005 ratio can be violated.   The MAX_TICK_DISTANCE was changed to 480. This way the desired Dx*fee / x < 0.0005 ratio will be preserved.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Position Manager Storage Access", "body": "  AntiSnipAttackPositionManager  and  BasePositionManager  often  read  same  fields  inside  pos  storage variable  multiple  times  during  the  function  execution.  Since  this  struct  type  variable  is  defined  as  a storage  one,  this  will  lead  to  repeated  reads  from  the  same  work.  More  efficient  approach  would  be utilization of in memory variables.  Position storage pos = _positions[params.tokenId];    Kyber Network - KyberSwap Elastic -   17  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fIn  version  3  of  the  code  the  gas  is  saved  by  utilizing  memory  variable  for  data  access  during  the execution.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Solidity Compiler Pragma", "body": "  The smart contracts inside the repository utilize different compiler pragmas:   pragma solidity >=0.5.0;   pragma solidity >=0.8.0;   pragma solidity ^0.8.0;   pragma solidity >=0.8.0 <0.9.0;   pragma solidity 0.8.9;  Contracts should be deployed with the same compiler version and flags that they have been tested with thoroughly. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example,  an  outdated  compiler  version  that  might  introduce  bugs  that  affect  the  contract  system negatively.  In  addition,  fixed  pragma  ensures  that  the  testing  and  deployment  performed  on  code  that was compiled by the same compiler version.    Core and periphery contracts use now pragma solidity 0.8.9 while libraries use >=0.8.0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Specification Mismatches in SwapMath", "body": "  Some mismatches between the specifications and code occur in the SwapMath library. Some examples are:   The  Core  Library  Swap  Math  documentation  of  calcReachAmount()  distinguishes  four  cases. However, case 1 & 4 and case 2 & 3 are identical. That mismatches the technical documentation of the swap and the implementation.   The technical documentation does not specify that the absolute value of usedAmount (delta x tmp)  is to be used for the calculation of deltaL.   The technical documentation differs in the mathematical formula for calculating returnedAmount.  Specification changed:  The specification now better reflects the implementation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   flash() Sends Fees to feeTo", "body": "  The natspec documentation of flash() in IPoolActions specifies the following:  Kyber Network - KyberSwap Elastic -   18  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1Speci\ufb01cationChanged                        \f/// @dev Fees collected are distributed to all rToken holders /// since no rTokens are minted from it  However, the fees are transferred to the feeTo address stored in the Factory contract.  Specification changed:  The natspec specification has changed to specify that feeTo receives the fees from the flash loan.  Kyber Network - KyberSwap Elastic -   19  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Pools for Tokens With Multiple Addresses", "body": "  The factory creates pools for two token address. It reverts if either the two addresses are identical or the pool has been already initialized for the token pair and the fee. However, some tokens (e.g. TUSD) have two addresses for the token. That allows for the creation of TUSD / TUSD pools, and multiple TUSD / other token pools with the same fee.  Kyber Network - KyberSwap Elastic -   20  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Missing Sanity Checks", "body": "  0  0  0  3  Multiple  setter  functions  are  missing  sanity  checks.  The  setters  functions  are  permissioned  and  we assume  the  caller  to  be  trusted.  Still,  mistakes  can  happen  and  would  be  irreversible  in  the  following cases:   StrategyProxy.setGovernance   BalancerYBALVoter.setGovernance  In other cases it might be helpful to prevent setting an address accidentally to address(0) but it is easy to override the value because the role setting the new address is not changed and could reverse their mistake. E.g., in StrategyProxy.setFeeToken it is possible to accidentally set it to address(0) but it could be immediately corrected by governance. Still, this might cause side effects as transactions could be executed with incorrectly set values before the mistake is reversed.  In  BalancerYBALVoter,  neither  the  initializing  function  nor  the  setters  do  verify  that  their  address inputs  are  different  than  the  zero  address.  Using  sanity  checks  prevents  unfortunate  errors  that  could potentially brick the contract.  In the zapper contract the _recipient is not checked and might be address(0) through a UI problem or incorrect user call.  Code partially corrected  A sanity check was added in the zap function to prevent the _recipient from being address(0). All other sanity checks were acknowledged by client but remained unchanged.  Yearn - yBAL -   10  DesignCorrectnessCriticalHighMediumLowCodePartiallyCorrectedCodePartiallyCorrectedRiskAcceptedCorrectnessLowVersion1CodePartiallyCorrected            \f5.2   No Event Emitted for State Modifying Code  Events indicate major state changes. Hence, it might be useful for users to listen to certain events. But events do increase the gas costs slightly. Yearn might consider the option to add events in the following cases:   BalancerYBALVoter  smart  contract  allows  for  modification  of  the  governance  and  the  strategy variables, but does not emit any event along with such modifications.   Some of the StrategyStYBAL setters like setProxy might issue events  Code partially corrected  An event was added that indicated a change of the governance variable in BalancerYBALVoter. In all other cases Yearn decided to keep the code as it is.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Vault Withdrawal Could Fail in the Zapper", "body": "  Vaults  such  as  StYBAL  mint  some  shares  when  users  deposit  some  underlying  into  the  contract.  To withdraw underlying tokens from such vaults, user specify an amount of shares and the smart contract computes  the  underlying  value  by  using  an  exchange  rate  that  depends  on  total  funds  available  and profit/loss.  Note that in the zapper, there exists the following assertion after withdrawing _amount_in shares from a vault:  assert amount >= _amount_in # dev: fail on partial withdrawal  This code snipped could make a zapping transaction revert for two reasons:  1. A small rounding down can happen when computing the underlying value, which would make  amount a little bit smaller than _amount_in.  2. Some loss could have occured in the strategies, which could make 1 share of the vault worth  less than 1 underlying.  Risk accepted  Yearn is aware of the issue and accepts the risk as they rate the probability of the issue very low.  Yearn - yBAL -   11  DesignLowVersion1CodePartiallyCorrectedDesignLowVersion1RiskAccepted                \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Missing Parameter in JoinPool Struct    Outdated Comments Left   0  0  0  2  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Missing Parameter in JoinPool Struct", "body": "  The  userData  field  in  Balancer's  JoinPool  struct  depends  on  the  type  of  join,  in  the  case  of  an EXACT_TOKENS_IN_FOR_BPT_OUT  join  type,  the  field  must  be  organised  encoded  in  this  way: [EXACT_TOKENS_IN_FOR_BPT_OUT, amountsIn, minimumBPT].  In  the  zapper's  _lp_balweth()  function,  only  the  join  type  and  the  amounts  are  encoded  into  the userData:  user_data: Bytes[160] = _abi_encode(      convert(1, uint8), # EXACT_TOKENS_IN_FOR_BPT_OUT      _amounts,  )  Meaning that in the final encoding form, the length of the amounts will be accounted for as minimumBPT.  Code corrected  User data encoding was changed and convert(0, uint256) was added as minimumBPT amount.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Outdated Comments Left", "body": "  Some curve-related comments are left in the code:  1. StrategyStYBAL line 171  2. StrategyProxy line 60, 96  Code corrected  Yearn - yBAL -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \fCode comments were removed or changed accordingly.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Missing Capital Letter", "body": "  The  setdisableClaim()  function  in  the  StrategyStYBAL  contract  does  not  respect  the  camel casing. It should be setDisableClaim().  Code corrected  The function was renamed correctly.  Yearn - yBAL -   13  InformationalVersion1CodeCorrected      \f7   Open Questions  Here,  we  list  open  questions  that  came  up  during  the  assessment  and  that  we  would  like  to  clarify  to ensure that no important information is missing.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Inconsistent Call Behavior", "body": "  The  StrategyProxy  contract  calls  the  voter  (confusingly  referred  as  proxy  in  the  code)  to  execute various operations. The voter contract has a function to execute arbitrary calls. In most execution this is used.  E.g.,  vote_for_gauge_weights,  withdraw,  transfer,  approve,  deposit  and  mint.  But for increaseAmount a special function is defined in the voter contract. Why is this design chosen?  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   State Inconsistency for Safe Tokens", "body": "  The  functions  approveRewardToken  and  approveExtraTokenRecipient  check  if  a  token  is  safe by calling _isSafeToken. This guarantees that the tokens are considered safe at this moment in time (t0) when calling the functions. The check relies on the state of two other contracts to check if a token is safe. When operations with the tokens are performed later in time (t0 + x), the check is not repeated.  Hence,  it  implicitly  assumes  that  the  state  of  the  two  contracts  does  not  change  after  a  token  was checked in _isSafeToken. Please provide a brief explanation why this assumption will always hold.  Yearn - yBAL -   14  OpenQuestionVersion1OpenQuestionVersion1      \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   No Error Strings Returned in the Zapper", "body": "  Meaningful  error  messages  help  users  to  understand  why  a  traansaction  failed.  No  error  strings  are returned  for  assertions  in  the  Zapper  contract.  Some  might  be  helpful  for  the  users  to  be  able  to understand the reason for the failed transaction, especially in the case of slippage protection.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Variables Could Be Immutable", "body": "  Setting variables that are only set in the constructor and cannot be changed later to immutable will save gas as the value is hardcoded into the contract and no SLOAD is required. Such variables could be:   The name and the sweep_recipient variables of the Zap contract   The variables escrow, token and name of the Voter contract   The name, symbol and decimals variables of the yBAL smart contract  Core partially corrected  The sweep recipient variable was made immutable. Yearn left all other variables as they are because the contracts are already deployed.  Yearn - yBAL -   15  InformationalVersion1InformationalVersion1CodePartiallyCorrected        \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "9.1   Balancer LP Tokens Cannot Be Claimed as", "body": " Extra Token Rewards  The  StrategyProxy  's  _isSafeToken()  function  makes  sure  a  token  isn't  a  gauge  or  a  Balancer liquidity  token.  Because  of  that,  no  Balancer  liquidity  token  can  be  claimed  as  extra  rewards  in  the StrategyProxy. However, such extra rewards could potentially exist to claim (via a bribe for example), and would be lost in this case.  Yearn - yBAL -   16  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Offer/Listing Signature Valid for Any Loan", "body": " Contract  The current system requires the Offer or the ListingTerms struct to be signed. However, no information about for which contract address this struct is intended to be used. Thus, it allows the accepting party publishing a loan on-chain to decide whether the loan will be pro-rated or fixed (or other loan types in the future).  Assume the following scenario:  NFTfi - NFTfi Marketplace -   10  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSecurityHighVersion1CodeCorrected        \f1. Alice talks off-chain to Bob and makes her the offer to lend 100 DAI for her ERC-721 collateral token as a fixed loan where the maximum repayment amount is 200 DAI. Bob sets the loan interest rate to 0 since it is not needed for the loan.  2. Bob sends the signed offer to Alice.  3. Alice  now  calls  acceptOffer  on  the  pro-rated  contract.  Loan  terms  get  prepared  for  later  calculations. _acceptOffer is called internally.  4. Now lender signatures are verified for the offer. Since nothing changed, the call succeeds.  5. Alice can pay back the loan cheaper than Bob agreed to.  In this scenario, Bob would need to have had the pro-rated contract approved for some DAI (e.g. Bob could be an active lender).  Furthermore, the signature could be used on multiple contracts. However, this requires the NFT to be a ERC-1155 token. In such a scenario, Alice could receive a pro-rated and a fixed loan while having only one signature of Bob.  Similar  issues  may  arise  in  the  case  of  signing  listings  where  the  lender  could  for  example  make  a pro-rated  loan  a  fixed  loan.  Since  the  borrower  could  be  an  active  user  of  the  platform,  making  both lending contracts an operator is a plausible assumption. Again, double-loans can be created if the NFT is an  ERC-1155  token  (assuming  the  contracts  are  operators  of  the  user's  NFTs).  Especially,  this  is dangerous, since the documentation describes giving default NFT approvals for NFTfi contracts.  In conclusion, the system is unaware for which contract a signature is intended to be used. Nonces can be reused since they are not stored globally but per lending contract. Hence, replay attacks are possible.    Now,  the  contract  address  is  signed  by  the  party  signing.  Thus,  a  loan  can  be  only  created  on  the intended contract.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Broken/Partial ERC165 Support", "body": "  Through inheritance the contracts in the composable directory inherit from ERC165 which implements EIP-165 that defines a standard method for publishing and detecting supported interfaces.  function supportsInterface(bytes4 interfaceID) external view returns (bool);  Not all of the aforementioned contracts do overwrite this function to extend its extended functionality.   ERC9981155Extension  additionally   implements   the   IERC998ERC1155TopDown  and   the  IERC1155Receiver interface.   NftfiBundler implements the INftiBundler functions while it does not explicitly implement the interface  (however, the naming suggests otherwise).  ImmutableBundle further implements the IERC721Receiver interface.  Hence, supportsInterface() will not return true for some of the interfaceId it supports.    The supportsInterface return true for interfaceId of all the implemented interfaces.  NFTfi - NFTfi Marketplace -   11  DesignMediumVersion1CodeCorrected         \f6.3   No Sanity Check on Revenue Share  fee.  The  percentage  can  be  set  with Partners  can  earn  a  share  of  PermittedPartners.setPartnerRevenueShare(). However, this method does not check whether the share exceeds 100%.  the  administrator   Assume a loan starts where that is the case. Then, this percentage would be stored in the loan extras of a  loan  which  cannot  be  renegotiated  nor  modified  in  any  way  for  the  loan.  Paying  back  the  loan  will ultimately  revert  since  an  underflow  would  occur  when  computing  the  fee  left  for  the  administrator. Hence, the borrower cannot retrieve his collateral back and liquidation is the only possibility to exit the loan.    100% cannot be exceeded anymore.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Renegotiation Replays Possible", "body": "  Renegotiation is a feature that allows the lender to give the borrower an alternative offer after the loan has been created. However, replay attacks may be possible here.  As  more  loan  types  will  appear,  more  loan  coordinator  contracts  could  be  deployed.  Following  could occur:  1. Borrower A has a loan connected to Coordinator A. Borrower B has a loan connected to Coordinator  B. The lender is in both cases the same.  2. Borrower A and the lender renegotiate the lending terms.  3. Borrower B replays the signature while the signature is not expired yet.  4. The lender has renegotiated two positions instead of only one.  This attack works as long as the data provided to renegotiation functions is the same.    Now, the contract address is signed. Thus, the signature can only be used on the valid contract.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   SmartNFTs May Not Be Composable With", "body": " Other Protocols  When a loan is accepted, two SmartNFT tokens are issued: A promissory note NFT to the lender, and an obligation note NFT to the borrower. The NFT collateral is stored in the NFTfi loan contract until either the borrower  repays  the  loan,  or  the  loan  is  liquidated.  However,  when  either  of  these  events  happen,  the SmartNFT tokens are transparently destroyed, and the addresses owning the respective NFTs receive the collateral and payback. That makes the SmartNFTS untraceable by smart contracts. That could be  NFTfi - NFTfi Marketplace -   12  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                        \fhazardous since the documentation specifies that a possible use-case of these NFTS could be trading them (e.g. selling the loan).  Assume the following scenario:  1. Lender and borrower agree on a loan, create it, and receive the SmartNFTs.  2. As  time  passes,  the  lender  decides  to  sell  the  promissory  note  on  a  platform  as  a  fixed-income  debt-bearing asset. The promissory note is deposited into a smart contract.  3. Now, the borrower pays back the loan. Both SmartNFTs are burned. The collateral is transferred to  the borrower. The payback is transferred to the NFT trade platform.  Ultimately,  the  auction  of  the  promissory  note  cannot  be  ended.  Hence,  funds  could  get  locked  in  the other contract while the lender does not receive anything.  Similarly, if the SmartNFTs are whitelisted in the PermittedList, funds could get lost in the NFTfi system since SmartNFTs could disappear at any time while a loan contract owning them would be clueless. Also, in such a way ImmutableBundles could lose funds.  To conclude, the immediate burning of SmartNFTs could be hazardous for NFTfi and other platforms as they could disappear at any point in time.    Now,  only  whitelisted  contracts  or  EOAs  can  hold  SmartNFTs.  Thus,  governance  must  ensure  that whitelisted contracts hold SmartNFTs that handle the scenarios above correctly.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Undeployable SmartNFTs", "body": "  SmartNFTs  are  used  for  the  promissory  note  and  obligation  receipt.  This  contract  inherits  from OpenZeppelin's access control contract. The deployment of the contract may fail.  _setupRole(DEFAULT_ADMIN_ROLE, _admin); grantRole(LOAN_COORDINATOR_ROLE, _loanCoordinator);  It sets _admin as the default administrator for all roles. If _admin is not msg.sender, then grantRole will fail.    _setupRole() is now used instead of grantRole in the constructor.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Anyone Can Liquidate", "body": "  The  renegotiation  feature  allows  to  renegotiate  even  if  the  loan  has  expired.  However,  anyone  can liquidate a loan. Thus, it could be possible that the result is not what the users desired. Moreover, fees that could have been earned will not be received.    Now, only the lender can liquidate.  NFTfi - NFTfi Marketplace -   13  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f6.8   Double Getters  For  each  public  variable,  a  getter  is  automatically  generated.  However,  several  contracts  implement additional getter functions for public variables which leads to more code and, hence, higher deployment cost.  Some examples of double getters are:   partnerRevenueShare and getPartnerPermit in PermittedPartners.sol   nftPermits and getNFTPermit in PermittedNFTs.sol   erc20Permits and getERC20Permit in PermittedNFTs.sol  Similar  examples  can  be  also  found  in  other  contracts  such  as  DirectLoanCoordinator,  NftfiHub  and others. Removing double getters may reduce deployment cost.    The double getters have been removed by setting the public variables to private.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Event Issues", "body": "  Many  events  are  emitted  in  the  system  helping  users  and  front-ends.  However,  some  event  could  be indexed to improve the experience. For example:   The permitted list contracts could index the address of the permitted contract.   Registry and loan contracts could have also indexed events  Furthermore, some important state changes do not emit events (e.g. updateMaximumLoanDuration or updateMaximumNumberOfActiveLoans). Note that also the renegotiation lacks events.  Emitting more events and indexing some of their parameters could improve the user-experience.    The events are now indexed and more events are emitted.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Gas Inefficiencies", "body": "  Structs are passed to the loan functions as arguments. These structs are passed compactly since they use  for  example  uint32.  However,  some  state  variables  could  follow  this  principle.  For  example, adminFeeInBasisPoints will never be greater than 10000 but is a uint256. The structs store this as a  uint32.  However,  a  smaller  data  type  could  also  be  sufficient.  Similar  gas  optimizations  could  be made.  NFTfi - NFTfi Marketplace -   14  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fFurthermore,  since  the  hub  should  not  change,  it  could  be  made  immutable  in  all  contracts.  For example, DirectLoanCoordinator stores it as an immutable while DirectLoanBase does not. Similar gas savings could be achieved.  Also, some state variable may be redundant. For example, the loan status stored in the loan coordinator. It  is  only  used  for  checking  something  when  burning  the  receipt  NFTs.  However,  burning  requires  the NFT owner to not be zero. Thus, the burn requirements are equivalent to the status checks.  Several  retrieved  values  from  storage  and  from  other  contracts  could  be  cached  in  memory  instead  of reading it multiple times. For example:   The NFT wrapper is retrieved in loanSanityChecks and when setting up the loan terms.   loanIdToLoan[id]  is  read  from  storage  into  memory  in  payBackChecks  and  then  in  payBackLoan.  Further redundant storage reads can be found.  Moreover, DirectLoanFixed._payoffAndFee is computed as follows:  uint256 interestDue = _loanTerms.maximumRepaymentAmount - _loanTerms.loanPrincipalAmount; uint256 adminFee = _computeAdminFee(interestDue, uint256(_loanTerms.loanAdminFeeInBasisPoints)); uint256 payoffAmount = ((_loanTerms.loanPrincipalAmount) + interestDue) - adminFee;  However, the addition could be removed since its result should be the maximum repayment amount.  Overall, gas consumption could be reduced by storing data more compactly, by reducing the number of storage reads and writes, and by removing redundant calculations.    Gas consumption has been reduced.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Gas Inefficiencies in SmartNFTs ", "body": " supportsInterface()  NFTs must implement EIP-165's proposed method supportsInterface(). SmartNFT implement this method. Gas could be saved there by calling only the super method which would, in this case, evaluate all the implementations of the parent classes and cover all implemented interfaces.  Moreover,  deployment  cost  could  be  reduced  by  reducing  the  code  size  by  using  the  methods  and modifiers inherited from AccessControl. Thus, duplicated code could be removed.    The gas consumption of the code has been optimized.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Maximum Number of Loans May Be Violated", "body": "  The  administrator  is  allowed  to  specify  a  maximum  number  of  loans  allowed.  The  following  invariant should always hold:  NFTfi - NFTfi Marketplace -   15  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \ftotalActiveLoans <= maximumNumberOfActiveLoans  However,  that  could  be  violated.  Assume  that  these  are  equal.  Then,  the  administrator  calls updateMaximumNumberOfActiveLoan  to  reduce  the  maximum  number  of  active  loans.  Ultimately, the invariant could be violated.    An additional check was added to ensure that the invariant does not break.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Maximum Repayment Amount", "body": "  The maximum repayment amount is specified by the lender. For both existing loan types this is value is relevant for accepting an offer while unused for accepting listings. The maximum repayment amount is calculated as the sum of the principal loan amount and the interest rate. However, that could be irritating for lenders as they could expect the maximum repayment amount specified by them to be used as the maximum.  Furthermore,  in  the  pro-rated  contract,  renegotiation  could  lead  to  a  scenario  where  the  interest  could grow even after time has elapsed since the interest rate is not modified.    The maximum repayment amount specified by the lender is now always used. Also, the interest rate is now updated for the pro-rated loan.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Not Using safeTransfer for ERC-20", "body": " Transfers  Since  not  all  ERC-20  tokens  adhere  to  the  standard,  it  is  recommended  to  use  safeTransferFrom such  that  interactions  with  a  broader  range  of  tokens  are  possible.  However,  the  transfer  of  the renegotiation fee does not use the safe operation.    safeTransferFrom is now used.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   Renegotiation on Wrong Contract Possible", "body": "  Renegotiation is a feature that allows the lender to give the borrower an alternative offer after the loan has been created. However, it could be possible to renegotiate a loan on the wrong contract.  NFTfi - NFTfi Marketplace -   16  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThis becomes possible if the maximum loan duration is greater than the current block timestamp and no renegotiation fee is charged.  1. Lender and borrower agree on a direct fixed loan.  2. Lender signs the renegotiation with a high new loan duration for the pro-rated contract.  3. The borrower calls renegotiate on the pro-rated loan contract.  4. The correct SmartNFT ID is fetched from the shared coordinator while the loan data is empty as it is  stored per lending contract.  5. Thus,  if  the  maximum  loan  duration  and  the  new  loan  duration  are  sufficiently  high  and  the  renegotiation fee is 0 (no ERC-20 transfer occurs), all checks pass.  However,  as  the  NFT  wrappers  are  not  initialized,  this  leads  to  unnecessary  state  modifications  while funds cannot be transferred.    Now, the loan contract is compared to the stored contract in the loan coordinator disallowing such wrong renegotiations.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.16   Repetitive Validation on Batch Child Transfer", "body": "  safeBatchTransferChild()  allows  children  of  a  token  to  be  batch  transferred.  msg.sender  is validated in each loop iteration to be the root owner of tokenId. However, since only the children of one token id can be batch transferred at once, it is sufficient to validate only once. Ultimately, storage reads and, hence, gas consumption could be reduced.    The method has been optimized.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.17   Specification Mismatch", "body": "  The code has several occurrences of specification mismatch. Some examples are:   DirectLoanProRated._setupLoanTermsListing documents that it is a fixed loan.   ERC998TopDown.childExists  specifies  that  it  returns  true  if  a  child  exists.  However,  in  the  extended classes this will return false for ERC-1155 tokens.   ERC998TopDown.ownerOfChild  specifies  that  parameter  tokenId  while  it  has  only  parameter  childTokenId.  Specification changed:  The specification has been updated.  NFTfi - NFTfi Marketplace -   17  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Fee Avoidance", "body": "  The liquidation allows the administration fees to be avoided as follows:  1. The borrower transfers his receipt to a contract. As long as the lender has transferred his receipt to  the contract, the borrower can withdraw his receipt.  2. The lender signs a renegotiation and approves the cheating contract.  3. The  lender  calls  the  cheating  contract  method  that  takes  the  renegotiation  and  the  renegotiation  parameters as arguments (and checks whether the parameters are fair).  4. The contract, having the obligatory note, calls renegotiate.  5. The contract pulls the promissory note from the lender.  6. The loan gets liquidated and the contract holds the NFT collateral.  7. The  cheating  contract  implements  a  payback  function  that  is  cheaper  for  the  borrower  and  more profitable  for  the  lender  (splitting  the  admin  fee).  Moreover,  as  a  safeguard  for  the  lender  it implements a liquidation function.  Ultimately, no fees are distributed to the administration while the lender and borrower could profit.  This  behaviour  cannot  occur  anymore.  Since  only  EOA  addresses  could  hold  a  SmartNFT  in  such  a case, the lender would need to trust the borrower.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Front-running Offers", "body": "  Alice may receive an Offer of Bob for an ERC-1155 token. Charlie could call acceptOffer() with Bob's signature which would initiate a loan between Bob and Charlie for the same ERC-1155 token. However, Bob's  intend  could  have  been  to  only  allow  Alice  to  take  a  loan  from  him.  From  the  discussions  with NFTfi,  it  was  clarified  that  the  ERC-1155  tokens  to  be  supported  are  the  ones  that  have  at  most  one token per ID.  Hence, governance needs to be careful when whitelisting ERC-1155 contracts.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Outdated Compiler Version", "body": "  The solc version is fixed in the hardhat configuration to version 0.8.4. At the time of writing the most recent Solidity release is version 0.8.7.  NFTfi - NFTfi Marketplace -   18  NoteVersion1NoteVersion1NoteVersion1            \f7.4   Possible Inconsistencies After Registry Changes  Many values are stored such that the loan can be resolved, no matter the changes made to the system (e.g. whitelisting ERC-20 tokens). However, the loan registry is global for the whole system. That could introduce several issues:   Assume contract A is stored in the loan registry for loans of type B and Loans are still active. Now, administration  changes  the  contract  for  loan  type  of  B  to  contract  C.  That  could  lock  the  funds  in contract A and make the loans unresolvable or introduce other issues related to that.   The loan coordinator could change in the hub. Thus, loans could become all invalid since changing  the new loan coordinator could also change the smart NFT token contract address.   Loans could become unresolvable if the loan coordinator loses access to a Smart NFT contract.  These and similar issues could occur.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Supported Tokens", "body": "  The  protocol  supports  ERC-20  tokens  as  lending  capital.  However,  whitelisting  for  example  ERC-777 tokens (backward-compatible with EIP-20) may lead to unwanted behaviour. For example, paybacks of loan could be blocked by reverting on token reception.  Also,  borrowers  may  receive  less  than  expected  if  the  ERC-20  tokens  collect  transfer  fees  while  the paybacks could fail.  Furthermore,  some  NFTs  could  be  added  that  could  be  burnable  externally  or  have  other  unexpected non-standard behaviour.  In general, governance has to be careful with whitelisting tokens.  NFTfi - NFTfi Marketplace -   19  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Floating Dependencies Versions", "body": "  The versions of the contract libraries imported as git submodules by the foundry are not fixed. With new versions  being  pushed  to  the  dependency  repositories,  the  imported  code  can  change  (e.g.,  via forge update) and lead to unexpected behavior by the smart contracts of the project.  The version of the foundry dependency can be specified as described here.  Acknowledged:  Circle acknowledged this issue and decided to keep the code unchanged due to the following reason:  The dependencies in repository are pinned git submodules, which won't be changed without explicitly committing a new version to master, so no change is needed.  We would like to highlight that the pinned version of OpenZeppelin dependency is 4.3.1 which includes a vulnerability in signature handling, however the reviewed code is not affected.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Gas Optimizations", "body": "  Circle - Circle EVM Bridge -   13  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedCodePartiallyCorrectedCodePartiallyCorrectedAcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                    \f1. The  MessageTransmitter  contract  uses  a  mapping  of  boolean  values  to  keep  track  of  used nonces,  which  is  inefficient,  due  to  the  Solidity  compiler  automatically  padding  bool  values  with zeroes  when  writing  them  to  storage.  It  is  more  efficient  to  use  a  mapping  of  a  type  such  as uint256 that takes up an entire storage slot as the bool values anyway cannot be packed in this case.  2. Functions sendMessage and sendMessageWithCaller declare a return variable _nonce but it  remains unused as the variable _nonceReserved is returned in both cases.  3. Attestable  contract  has  a  constant  value  of  65  assigned   to   immutable  variable  signatureLength. Changing its type to constant reduces slightly the gas consumption.  4. At the sending end, MessageTransmitter keeps track of available nonces for each destination domain.  The  contract  could  be  made  more  efficient  in  terms  of  storage  used  if  a  single  global nonce is used for all remote domains.  5. Function  _recoverAttesterSignature  computes  a  hash  of  _message  and  then  calls recover from ECDSA library to get the address of the signer. This function is only called inside the for-loop  redundant computation of the hash for the same message.  function  _verifyAttestationSignatures,   therefore  causing   in   6. The  function  disableAttester  performs  two  calls  to  getNumEnabledAttesters  which performs  an  SLOAD  operation.  Although  the  second  SLOAD  costs  less  (100  gas)  due  to  storage being warm at that point, the function could be optimized by storing the value in memory.  7. Similarly,  the  function  addLocalTokenMessenger  performs  an  unnecessary  SLOAD  when  emitting the event.  8. The location of the following arguments can be changed from memory to calldata to make them and  MessageTransmitter.sendMessage;   messageBody  more  newMessageBody in MessageTransmitter.replaceMessage.  gas-efficient:   in   9. The function encodeHex in the library TypedMemView always checks if the iterator is not on the  16th byte:  for (uint8 i = 31; i > 15; i -= 1) {     uint8 _byte = uint8(_b >> (i * 8));     first |= byteHex(_byte);     if (i != 16) {         first <<= 16;     } }  As an improvement, the loop can iterate in the range i > 16 so the if statement inside the loop can be removed. The same optimization is possible for the next loop which iterates over the lower 16 bytes. By doing so, gas consumption would be decreased.  Acknowledged:  Circle has applied most of the optimizations listed above. More specifically, optimizations 1-6 and 8 were implemented in the updated codebase. Optimizations 7 and 9 were acknowledged but not addressed in code. We detail the fixes:  1. usedNonces is changed to be a mapping of bytes32 to uint256.  2. Circle has corrected both sendMessage and sendMessageWithCaller.  3. signatureLength is changed to be a constant.  4. MessageTransmitter  keeps  track  of  the  next  available  nonce  via  keeping  a  scalar  variable,  namely nextAvailableNonce.  Circle - Circle EVM Bridge -   14  \f5. In  _verifyAttestationSignatures  the  digest  of  the  message  is  firstly  calculated  and  sent  down to each call of _recoverAttesterSignature.  6. disableAttester  fetches  length  of  the  enabledAttesters  and  stores  it  in  a  memory  variable,  instead of accessing the storage twice.  7. Circle  has  acknowledged  this  optimization  but  has  decided  to  keep  the  code  unchanged  as  the  function addLocalTokenMessenger is not expected to be called often.  8. messageBody   originalMessage  MessageTransmitter.sendMessage,  newMessageBody in MessageTransmitter.replaceMessage are changed to calldata.  in   and  9. Circle has decided to keep the TypedMemView library as-is.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Inconsistent Natspec Descriptions", "body": "  The natspec description of the following functions is not consistent with the implementation:  1. _sendMessage: @dev Increment nonce, ... is not aligned with the implementation.  2. _getLocalToken:  @dev  Reverts  if  unable  to  find  an  enabled  local  token...,  but the implementation does not revert.  3. onlyWithinBurnLimit: ... burn limit per-transaction for given 'burnToken'. The modifier only checks that the limit is not exceeded in a single function call, however, if multiple calls are executed within a transaction, the limit per-transaction is not enforced.  4. BurnMessage library: version field is declared as 4 bytes, but the type is set to uint8 instead of  uint32.  5. To fetch the 12 bytes containing loc, a variable of TypedMemView should be shifted 120 bits (3 empty + 12 len = 15 bytes) to the right and be masked. The comment inside the assembly block has wrongly stated 12 bytes of the loc instead of len.  Code partially corrected:  The reported inconsistencies 1-4 have been fixed in the updated codebase, while the last one remains unchanged.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Missing Sanity Checks", "body": "  The following functions set important state variables or parameters, but do not perform any sanity check on input parameters:  1. MessageTransmitter.constructor.  2. TokenMessenger.constructor.  3. MessageTransmitter.setMaxMessageBodySize.  4. newMintRecipient in TokenMessenger.replaceDepositForBurn.  Code partially corrected:  Circle - Circle EVM Bridge -   15  CorrectnessLowVersion1CodePartiallyCorrectedDesignLowVersion1CodePartiallyCorrected                \fchecks   Sanity  and in  TokenMessenger.replaceDepositForBurn listed above, however no sanity checks were added for points 1 and 3.  TokenMessenger.constructor   added   were   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Potential Event Reordering Due to Reentrancy", "body": " in MessageTransmitter  The function sendMessage does not have any access restriction, and the caller can pass any arbitrary value for recipient. On the other side of the bridge, the function receiveMessage gives execution to recipient and emits an event afterward. Therefore, a malicious recipient could reenter the contract causing events to be emitted in an inconsistent order:  require(     IMessageHandler(_m._recipientAddress()).handleReceiveMessage(         _sourceDomain,         _sender,         _messageBody     ),     \"handleReceiveMessage() failed\" );  // Emit MessageReceived event emit MessageReceived(     msg.sender,     _sourceDomain,     _nonce,     _sender,     _messageBody );  Acknowledged:  Circle acknowledged the issue but has decided to keep the code unchanged.  Circle - Circle EVM Bridge -   16  SecurityLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Default Optimizer Configuration   Inconsistent Type Used for Nonce    Missing Event in Ownable   0  0  0  6   Unchecked Return Value for Functions From TypedMemView    Unrelevant Indexed Event Fields    Wrong Values Emitted in Event   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Default Optimizer Configuration", "body": "  The compiler optimizer is not enabled explicitly by the foundry configuration, hence the default optimizer enabled by the foundry with 200 runs is used:  [profile.default] src = 'src' out = 'out' libs = ['lib']  The  optimizer  uses  the  specified  number  of  runs  to  perform  a  trade-off  between  deployment  cost (bytecode  size)  versus  execution  costs.  A  high  number  of  runs  indicates  to  the  optimizer  that  the reduction of execution costs has a higher priority than deployment costs.    The configuration file foundry.toml has been updated to enable the optimizer with 10_000 runs.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Inconsistent Type Used for Nonce", "body": "  The  contract  MessageTransmitter  uses  type  uint64  for  storing  nonces,  however,  the  internal function _hashSourceAndNonce uses uint256 for the argument _nonce.  Circle - Circle EVM Bridge -   17  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \f  Type  of  _nonce  in  _hashSourceAndNonce  is  changed  to  uint64  and  is  consistent  throughout  the code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Missing Event in Ownable", "body": "  The constructor of Ownable sets the deployer of the contract as owner, however, the respective event is not emitted.    The constructor of Ownable now calls the internal function _transferOwnership which sets the new _owner and emits the respective event.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Unchecked Return Value for Functions From", "body": " TypedMemView  The  functions  ref  and  slice  of  the  library  TypedMemView  return  a  memory  view  of  type  bytes29. However,  both  functions  can  return  NULL  which  represents  an  invalid  type  (ff_ffff_ffff)  if  the memory  is  malformed.  The  calling  functions  in  MessageTransmitter,  TokenMessenger  and Message do not check for the invalid type.    libraries   functions The  _validateMessageFormat and _validateBurnMessageFormat. These functions are now used to validate the return values from functions ref and slice from the library TypedMemView.  extended  with   BurnMessage   Message   been   have   and   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Unrelevant Indexed Event Fields", "body": "  Only relevant fields of the events should be indexed, the ones which it makes sense to search for. The following events index also uint values:  1. amount in TokenMessenger.DepositForBurn  2. amount in TokenMessenger.MintAndWithdraw  3. oldSignatureThreshold   and   newSignatureThreshold   in  Attestable.SignatureThresholdUpdated  4. burnLimitPerTransaction in TokenController.SetBurnLimitPerTransaction  5. newMaxMessageBodySize in MessageTransmitter.MaxMessageBodySizeUpdated  Circle - Circle EVM Bridge -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fOn the other hand, the event OwnershipTransferred does not index its argument. EVM opcodes for logging  events  with  more  indexed  arguments  consume  more  gas.  We  suggest  for  each  event  field reevaluate if indexing is necessary.    All events listed above were revised such that uint arguments are no longer indexed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Wrong Values Emitted in Event", "body": "  Function  updateAttesterManager  uses  the  same  variable  newAttesterManager  in  the  emitted event. The natspec of the event specifies that the first parameter is the address of the previous attester manager, while the second parameter is the new attester manager.  Code partially corrected:    to  pass  msg.sender  and The  function  updateAttesterManager  has  been  revised  in  newAttesterManager  as  parameters  to  the  event  AttesterManagerUpdated.  However,  the  first parameter  msg.sender  is  the  owner  of  the  contract,  and  not  necessarily  the  previous  manager  as described in the event definition.    In  attesterManager role:  ,  the  following  code  is  used  to  emit  the  previous  and  new  addresses  for  the  address _oldAttesterManager = _attesterManager; _setAttesterManager(newAttesterManager); emit AttesterManagerUpdated(_oldAttesterManager, newAttesterManager);  Circle - Circle EVM Bridge -   19  CorrectnessLowVersion1CodeCorrectedVersion2Version3        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Compiler Version Not Fixed and Outdated", "body": "  The  solidity  compiler  is  fixed  only  in  contracts  Ownable,  Pausable  and  Rescuable,  while  other contracts use the following pragma directive:  pragma solidity ^0.7.6;  Although no later compiler version 0.7.x exist, it is a best practice to fix the compiler version in contracts or configuration file.  Known bugs in version 0.7.6 are listed here.  More information about these bugs can be found here: https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing the most recent Solidity release is version 0.8.17 which contains some bugfixes. However, version 0.8 introduced breaking changes and would require heavy refactoring of the contracts.   changes: All contracts now use the following pragma directive:  pragma solidity 0.7.6;  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Non-canonical Conversion of Bytes to", "body": " Address  The  function  Message.bytes32ToAddress  implements  the  following  statement  to  perform  the  type conversion:  function bytes32ToAddress(bytes32 _buf) public pure returns (address) {     return address(uint160(uint256(_buf))); }  Note that due to downcasting, higher bits of _buf will be omitted. Thus, it is possible to have different input values _buf map to the same address.   changes: Circle has decided to emphasize this behavior in the code by appending the following  description to the function's natspec:  * @dev Warning: it is possible to have different input values _buf map to the same address. * For use cases where this is not acceptable, validate that the first 12 bytes of _buf are zero-padding.  Circle - Circle EVM Bridge -   20  NoteVersion1Version2NoteVersion1Version2      \f7.3   Overflow and Underflow Occurring in TypedMemView  The  function  TypedMemView.index  takes  as  the  third  argument  the  length  of  the  returned  value  in bytes _bytes, which is of type uint8. The length in bits is computed as follows:  uint8 bitLength = _bytes * 8;  If _bytes is 32, the multiplication above overflows as the result 256 cannot be stored in a variable of type  uint8,  hence  bitLength  stores  0.  Furthermore,  when  bitLength  is  passed  to  function leftMask an underflow occurs in the following assembly code:  assembly {     mask := sar(         sub(_len, 1),         ...     ) }  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Potential Single Points of Failure", "body": "  Circle  EVM  Bridge  relies  on  a  centralized  attestation  service  (attesters)  to  guarantee  the  integrity  of messages  transmitted  between  chains.  The  protocol  assumes  that  an  adversary  cannot  compromise enough attesters (signatureThreshold) at the same time, otherwise, the bridge becomes vulnerable.  Besides  the  assumption  above,  we  would  like  to  highlight  below  the  accounts  that  are  potential  single points of failure for the security of the bridge.  Message  Transmitter:  Any  account  with  role  owner  or  attesterManager  should  be  carefully protected.  If  any  account  with  these  roles  gets  compromised,  it  can  freely  enable  new  attesters  and execute arbitrary cross-chain messages. Furthermore, the role pauser is critical to be protected in order to keep the bridge operational and avoid denial-of-service (DoS) attacks.  Token Messenger: The account with the role owner should be carefully protected, as if this account gets  compromised,  it  can  set  arbitrary  addresses  as  token  messengers  in  remote  domains  and  then process malicious messages.  Token Minter: The accounts with roles owner and tokenController should be carefully protected. If  any  of  these  accounts  get  compromised,  the  mapping  remoteTokensToLocalTokens  can  be manipulated, which can consequently create severe issues, e.g., an attacker can burn low value tokens in one chain but mint the same amount in high value tokens in the other chain.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Return Value of Burn Function", "body": "  The  system  supports  tokens  that  implement  the  IMintBurnToken,  i.e.,  functions  transfer, transferFrom and mint return a boolean value. However, burn function is assumed to not return a  Circle - Circle EVM Bridge -   21  NoteVersion1NoteVersion1NoteVersion1            \fvalue  but  revert  if  unsuccessful.  This  behavior  is  in  line  with  the  implementations  of  USDC  and ERC20Burnable from OpenZeppelin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Signature Threshold Restrictions", "body": "  The documentation states that the threshold for the required signatures should not be below 2, however, this is not enforced by the codebase. On deployment, the constructor of Attestable contract takes only one attester address as an argument and sets signatureThreshold = 1.  Furthermore,  the  function  setSignatureThreshold  does  not  enforce  that  the  threshold  is  set  to  at least 2. Circle is aware of this behavior and does not intend to enforce the minimum threshold in code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Visibility Modifiers for Constructors", "body": "  Contracts  Attestable  and  Ownable  declare  the  visibility  of  constructors  as  public,  however,  such visibilities in compiler version 0.7.6 are obsolete. More information.   changes: The visibility for constructors has been removed in the updated codebase.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   Attestable._recoverAttesterSignature", "body": " Function Visibility Can Be Pure  The  modifier  of  the  function  _recoverAttesterSignature  can  be  changed  to  pure,  as  it  neither writes nor reads the storage of the contract.   changes: The visibility of the function above has been changed to pure.  Circle - Circle EVM Bridge -   22  NoteVersion1NoteVersion1Version2NoteVersion1Version2            \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Unprotected Escrow Funds", "body": "  L1DAIBridge.deposit() transfers DAI from a user-specified address from to the L1Escrow contract to lock DAI on layer one. However, a malicious user could specify from to be the L1Escrow contract that holds all of the locked funds. The call to DAI.transferFrom() will succeed since the escrow must have had approved the bridge contract. Ultimately, unbacked DAI could be minted on L2 and funds from the escrow could be stolen.  Consider the following scenario:  1. User calls deposit() with from being the escrow contract.  2. The   to  amount <= allowance[escrow][bridge].  self-transfer   from   and   escrow   succeeds   as   long   as  3. The ceiling check passes as long as balanceOf(escrow) <= ceiling since the balance does  not change.  4. Ultimately, a message to L2 is sent and unbacked DAI on L2 is minted.  5. Repeat the process.  6. Withdraw DAI from L2 to L1, such that the escrow is emptied.  MakerDAO - StarkNet-DAI-Bridge -   12  CriticalCodeCorrectedHighCodeCorrectedMediumCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected            \fThe README.md file in the repository states:  ### Initial configuration      ... Unlimited allowance on `L1Escrow` should be given to `L1DAIBridge`.  Hence an attacker may drain all DAI out of the escrow.  Furthermore, e.g. by frontrunning a deposit transaction or exploiting an unlimited approval given by the user to the bridge it is possible to steal L1 DAI from users. Consider the following scenario:  1. User  A  intends  to  deposit  DAI  to  L2  and  approves  the  bridge  contract.  He  either  gives  an  exact approval  for  the  amount  he  wants  to  deposit  or  may  give  an  unlimited  approval  as  he  trusts  the bridge contract and intends to use it in the future. Next he crafts a transaction to deposit.  2. User B calls deposit() and specifies the from address to be user A. The call succeeds and B receives funds on L2. Note that the DAI locked on L1 are from user A. This transaction frontruns the deposit call coming from user A.  3. User A's deposit is executed but fails due to lack of allowance.  Note that although they are known to be potentially dangerous it is quiet common that users give infinite approval to such systems they trust and intend to interact with frequently.    The  from  parameter  has  been  removed  from  function  deposit.  The  DAI  amount  is  now  transferred from msg.sender to the escrow. Hence the issue described above no longer exists.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   L2 DAI Allows Stealing", "body": "  The transfer function of the L2 DAI contract allows stealing tokens from other users. The attack works as follows:  1. Within the amount field of the transfer function the user specifies an invalid Uint256. Note that uint256_check  is  never  called.  To  steal  i  token  wei,  the  attacker  specifies  P-i  to  be amount.low  and  0  to  be  amount.high.  The  low  amount  could  be  interpreted  as  the  negative number -i.  2. The  uint256_le(amount,  sender_balance)  check  will  be  passed  as  it  will  ultimately  compute the following:  1 - is_nn(amount.low - (sender_balance.low+1))  If for example the sender's (attacker's balance) is 0, that check will pass.  3. The  uint256_sub(sender_balance,  amount)  computation  will  result  in  an  increased  sender_balance due to the specially crafted amount.  4. The  uint256_add(recipient_balance,  amount)  computation  will  result  in  a  decreased  recipient_balance due to the specially crafted amount.  Note that the decrease of the recipient_balance is also the increase of the sender_balance. In other words, the sender gains as many tokens as the recipient loses. Or more concisely, the sender can steal all of the tokens of the receiver. So, if i==1 then one token wei is stolen. If i==2 then two wei are stolen.  MakerDAO - StarkNet-DAI-Bridge -   13  SecurityHighVersion1CodeCorrected        \fThe  only  precondition  for  the  attack  is  that  the  uint256_le(amount,  sender_balance)  can  be passed  for  manipulated  amount  values.  Note  that  the  current  hints  prevent  a  proof  generation  for  this attack in uint256_add, but hints can freely be changed and the verifier will accept it.    amount  is  now  validated  in  the  internal  function  _transfer.  Thus,  neither  transfer()  nor transfer_from  can  perform  computations  with  invalid  integers.  Ultimately,  the  Uint256  library functions receive the expected inputs and, thus, perform the documented computations.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Frontrun cancelDeposit()", "body": "  L1->L2   After  L1DAIBridge.startDepositCancellation()  L1DAIBridge.cancelDeposit() can be used to complete the cancellation and retrieve the DAI.  initiated  has   cancellation   message   delay   been   time   and   has   the   using passed,  The caller of the function must provide the details to retrieve the message (the amount, the l2Recipient and the nonce) and as parameter l1Recipient any address to receive the funds on L1.  There is no access control, the first caller can retrieve the DAI to any address.    msg.sender  is  now  included  in  payload  of  deposit(),  startDepositCancellation()  and cancelDeposit(). Hence, a successful cancellation requires that the same msg.sender in all three calls of the process. Otherwise, the payload would be different.  payload[3] = uint256(uint160(msg.sender)); StarkNetLike(starkNet).cancelL1ToL2Message(l2DaiBridge, DEPOSIT, payload, nonce);  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   ForceWithdrawal Needs Prior Approval", "body": "  In  the  case  that  a  user  believes  they  are  censored,  the  user  can  initiate  the  withdrawal  using  the forceWithdraw function of the L1DAIBridge. When the L2 network works as expected, the withdrawal request is handled.  This however has some prerequisites:  1. The  user  needs  to  have  registered  his  L1  address  in  the  L2  registry  prior  to  initiating forceWithdraw(). Note that this may no longer be possible when the L2 network is censoring transactions hence this should be done by the users before receiving DAI on L2.  2. The  execution  of  finalize_force_withdrawal  on  L2  in  case  the  Layer2  network  complies requires  that  the  user  has  previously  given  allowance  to  the  l2_dai_bridge.  Again,  giving  the approval  at  this  point  in  time  may  no  longer  be  possible  in  case  the  L2  network  censors transactions.  MakerDAO - StarkNet-DAI-Bridge -   14  SecurityMediumVersion4CodeCorrectedCorrectnessMediumVersion1CodeCorrectedSpeci\ufb01cationChanged                  \f# check allowance let (contract_address) = get_contract_address() let (allowance : Uint256) = IDAI.allowance(dai, source, contract_address) let (allowance_check) = uint256_le(amount, allowance) if allowance_check == 0:     return () end  This  requirement  is  not  documented  and  may  come  as  a  surprise  for  the  user.  Note  that  for  normal withdrawals  from  L2  using  withdraw  no  such  allowance  is  needed.  Furthermore  without  the  check  in finalize_force_withdrawal  the l2_dai_bridge  is  a  ward  in  the  DAI  contract  and  has  the  privilege  to  burn  the  DAI  of  any  address without the need for an approval.  the  DAI  would  work  as   the  withdrawal   /  burning  of   The case that the L2 network may only censors transactions other than forced withdrawals (in order to avoid detection of the misbehavior) and its implication must be considered.  Overall the ForcedWithdrawal process and it's restrictions is not documented enough.  Code corrected and specification changed:  and   hence   Issue  1)  was  addressed  by  improving  the  documentation.  The  documentation  now  clearly  states  what actions  are  required  before  a  forced  withdrawal  can  be  executed.  The  enhanced  documentation  also resolves 2), note that in the updated code a ward of the DAI contract no longer has the privilege to burn understand  why needed.  DAI  finalize_force_withdrawal  must  check  whether  the  approval  exists:  Burning  without  the allowance would result in the transaction to revert. The prover can't prove failed executions, reverts are indistinguishable  from  censored  messages.  By  checking  the  allowance  and  gracefully  terminate  the transaction  when  no  sufficient  allowance  exist,  the  transaction  can  be  executed.  Hence  the  message from L1 can be processed which allows to clear the message in the StarkNet contract on Ethereum. This proves that the transaction must have been executed on L2.  important   approval   the   It's   to   is   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   L2 Address Sanity Checks", "body": "  In StarkNet users do not have addresses. Transactions sent to the network have the 0 address as caller. In  order  to  identify  accounts  via  addresses,  each  user  deploys  his  account  contract  and  interacts  with contracts such as the DAI token using his account-contract.   The deposit() function of the L1DAIBridge contract allows users to deposit with the to address set to 0. The execution of finalize_deposit initiated by the l1_handler on l2 however will fail as minting DAI for the zero address will revert. As a result the deposited DAIs on L1 will be locked in the escrow.  Furthermore, note that to will be received as a felt on L2. Hence, the true to address on L2 will be to  %  R.  Therefore,  it  could  be  possible  to  for  example  specify  address  R  on  L1  which  will  map  to zero-address (similarly R+1 will map to address 1). Users could be protected from errors by restricting the allowed address range on L1.   L2 DAI allows to give approvals specifying the 0 address as caller. All holders of L2 DAI must be aware  that  this  is  very  dangerous  and  means  that  anyone  crafting  an  external  transaction  to  the network can transfer their DAI using this approval.  MakerDAO - StarkNet-DAI-Bridge -   15  DesignMediumVersion1CodeCorrected        \f A user could specify the l2_dai contract as the recipient of the funds on deposit. Since the L1 call would succeed while the L2 call to the l1_handler would fail, the cross-layer message would remain unconsumed.    The code does the following checks now on L1:   to != 0 to ensure that the address is non-zero.   to != l2Dai to prevent a failing mint.   to < SN_PRIME to prevent a possible StarkNet overflow.   All functions related to approvals in the l2 DAI contract now forbid approving the zero-address.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Relay Parameter Mismatch", "body": "  The  L1GovernanceRelay  is  used  to  send  messages  to  the  L2  GovernanceRelay  to  execute  spells. However,  the  parameters  sent  by  the  L1  contract  and  the  parameters  the  L2  contract  receives  do  not match. Ultimately, governance spells cannot be relayed to L2.  More specifically, the L1GovernanceRelay sends a message to L2 as follows:  uint256[] memory payload = new uint256[](2); payload[0] = to; payload[1] = selector;  StarkNetLike(starkNet).sendMessageToL2(l2GovernanceRelay, RELAY_SELECTOR, payload);  However, the L2 side of the governance relay consumes the message as follows:  @l1_handler func relay{   syscall_ptr : felt*,   pedersen_ptr : HashBuiltin*,   range_check_ptr  }(    from_address : felt,    target : felt  ):    let (l1_governance_relay) = _l1_governance_relay.read()    assert l1_governance_relay = from_address    let (calldata : felt*) = alloc()    delegate_call(target, EXECUTE_SELECTOR, 0, calldata)    return ()  end  The  arguments  of  the  L1  handler  should  consist  of  the  from_address  and  payload.  However,  the payload created on L1 has two elements. That ultimately lets the execution of a governance spell fail.  MakerDAO - StarkNet-DAI-Bridge -   16  CorrectnessMediumVersion1CodeCorrected        \f  The unused selector was removed from the payload, the payload now contains the spell only.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Unlimited Approvals and the Range of Uint256", "body": "  DAI on L1 supports unlimited approvals using uint256(-1) as magic value. When an approval for this magic value is given, the spender can spend the funds of the token holder without the allowance being reduced.  Similarly  the  DAI  contract  in  cairo  supports  an  unlimited  approval  using  a  different  magic  number.  As Uint256 work differently in cairo, it's possible to define a magic value outside the actual range of Uint256. In cairo, a Uint256 is represented by a struct containing two felt members:  struct Uint256:     # The low 128 bits of the value.     member low : felt     # The high 128 bits of the value.     member high : felt end  However note that a felt can store more than 128 bits, so a Uint256 represented by such a struct may contain a value exceeding the max uint256 value.  The code of the DAI cairo contract, however, takes advantage of this special property of the Uint256 type and defines the magic number for the unlimited approval as:  const MAX_SPLIT = 2**128 let MAX = Uint256(low=MAX_SPLIT, high=MAX_SPLIT)  Note  that  the  common  library  for  Uint256  offers  a  function  uint256_check  which  checks  if  the  given Uint256 is actually valid. The code of the DAI cairo contract uses this function to check whether amounts regarding  balances  are  valid.  In  contrast,  the  code  is  generally  not  using  uint256_check()  when handling or checking approvals. That results in following potentially intended and/or strange behaviour:   Function approve can be used to give allowance for a valid amount, the magic number or an invalid  uint256 value.   Function  increase_allowance  does  not  work  on  such  allowances  due  to  the  carry  over. However,  increasing  with  bad  input  values  could  decrease  the  allowance  (in  a  similar  fashion  as described in L2 DAI allows stealing).   Function  decrease_allowance  works.  However,  note  that  decreasing  to  the  magic  number  results in unlimited approval so that allowance has been increased instead of decreased.  Concluding, the selection of the magic value outside the valid range for Uint256 could lead to unexpected and  undocumented  behaviour  due  to  an  implied  lack  of  Uint256  validity  checks.  Furthermore,  the deviation from L1-DAI's magic value may confuse users.    MAX_SPLIT has been renamed to ALL_ONES and redefined to 2**128-1. Also, uint256_check() is called  now  in  the  functions  approve,  increase_allowance  and  decrease_allowance.  Since  the inputs  are  always  validated  and  allowance  cannot  be  out  of  the  valid  Uint256  range,  the  unintended behaviour cannot occur anymore.  MakerDAO - StarkNet-DAI-Bridge -   17  DesignMediumVersion1CodeCorrected        \f6.8   ERC-20 Functions Have No Return Values  EIP-20  specifies  that  for  example  transfer  has  a  boolean  return  value.  However,  L2  DAI  does  not return anything.    Return values have been implemented for the ERC-20 functions.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Inconsistent Version Pragma", "body": "  Different  to  the  L1Escrow  contract,  the  L1DAIBridge  and  the  L1GovernanceRelay  contract  feature following version pragma:  This allows the contracts to be compiled with any Solidity version >= 0.7.6 including more recent major version which may feature changes in the syntax.  The Solidity documentation states:  Source files can (and should) be annotated with a version pragma to reject compilation with future compiler versions that might introduce incompatible changes.  For  https://docs.soliditylang.org/en/develop/layout-of-source-files.html#version-pragma  information,   please   more   refer   to:    The pragmas have been changed to:  pragma solidity ^0.7.6;  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Inefficiency in Reading Allowances", "body": "  In  function  burn  of  the  DAI  cairo  contract  the  allowance  is  always  read.  However,  it  is  only  used  if check_allowances  ==  1  is  true.  Thus,  the  efficiency  of  the  functionality  could  be  improved. Similarly, that is the case for transferFrom().    In the updated code wards no longer have special privileges in dai.burn(). Due to the changed code, the issue described above no longer applies.  MakerDAO - StarkNet-DAI-Bridge -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                          \f6.11   Lack of L1-address Sanity Checks on L2  L1 addresses on L2 are of felt type. However, that could ultimately lead to bad user-input on L2 when passing L1 addresses since L1 addresses have 160 bits which is less than the number of bits the felt type is represented with.  For example, in function withdraw() of the L2 bridge contract a user passes an L1 address as felt which could to a bad address being passed to L1.    A check has been added to send_finalize_withdraw() with ensures that the destination is a valid L1 address. This function is used by both, withdraw and finalize_force_withdrawal.  In  the  initial  round  of  fixes  the  assert_l1_address  function  contained  unnecessary  declarations  of local syscall_ptr and local pedersen_ptr which now have been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Unused Code", "body": "  The L1DAIBridge contract defines the struct SplitUint256. However, it remains unused.    The unused struct was removed.  MakerDAO - StarkNet-DAI-Bridge -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Compiler Panicking for an Out of Range", "body": " Integer Node  For  exponentiation  of  unsigned  numbers,  the  following  IR  node  is  added  to  check  for  overflows  of  the computation:  CS-VYPER_JULY_2022-001  [\"lt\", x, upper_bound]  When a uint256 is raised to the power of 0 or 1, upper_bound is equal to MAX_UINT256+1, which is an output of calculate_largest_base. When trying to create a node for such value, the __init__ function of IRnode, will throw an exception as -(2 ** 255) <= self.value < 2 ** 256 is false.  @external def foo() -> uint256:     x: uint256 = 0     return x ** 1  Error compiling: Foo.vy vyper.exceptions.CompilerPanic: out of range  This is an unhandled internal compiler error. Please create an issue on Github to notify the developers. https://github.com/vyperlang/vyper/issues/new?template=bug.md  Vyper - Vyper Compiler -   9  CorrectnessCriticalHighMediumLowCorrectnessLowVersion1       \f5.2   Different Semantics for Raising to the Power of Negative Numbers  When  computing  the  power  of  0  or  1  by  a  negative  number,  if  the  compiler  knows  the  exponent  at compile time, it will output an exception. On the other side, if the compiler is only aware of the base, it will successfully compile and running the code will not revert. This behavior is due to the fact that the runtime checks  added  by  the  compiler  only  check  that  the  result  of  the  computation  is  in  bounds.  It  does  not check that the exponent is not negative to have the same semantic as the other case. The two examples below show the issue, compilation of foo will output the given exception while a call to bar will return 1.  CS-VYPER_JULY_2022-002  @external def foo() -> int16:     x: int16 = 1     return x ** (-2)  vyper.exceptions.InvalidOperation: Cannot calculate a negative power contract \"Foo.vy\", function \"foo\", line 4:17      3     x: int16 = 1 ---> 4     return x ** (-2) --------------------------^      5  @external def bar() -> int16:     x: int16 = -2     return 1 ** x  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Exponentiation Lead to CompilerPanic", "body": " Exception  CS-VYPER_JULY_2022-003  In  arithmetic.safe_pow,  when  literal,  either  x  in  (0,1),  either calculate_largest_power  is  called.  In  calculate_largest_power  however,  CompilerPanic is  raised  when  the  absolute  value  of  the  base  is  either  0  or  1.  This  behavior  results  in  powers  of  -1 raising the exception as its absolute value is 1.  the  base  x   is  a   a = abs(a)  # No longer need to know if it's signed or not if a in (0, 1):         raise CompilerPanic(\"Exponential operation is useless!\")  The following code snippet produces this behavior:  Vyper - Vyper Compiler -   10  CorrectnessLowVersion1CorrectnessLowVersion1            \f@external def foo():         x: int256 = 4         y: int256 = (-1) ** x  In addition the compiler does not handle the exception that is produced by this snippet:  Error compiling: Foo.vy vyper.exceptions.CompilerPanic: Exponential operation is useless!  This is an unhandled internal compiler error. Please create an issue on Github to notify the developers. https://github.com/vyperlang/vyper/issues/new?template=bug.md  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Folding Does Not Follow the Vyper Runtime", "body": " Semantics  AST  folding  is  performed  at  the  very  beginning  of  the  compilation  pipeline.  As  it  happens  before  the semantics validation, depending on the expression, it is possible that either the folding is too restrictive compared to the real semantics, or an expression that is not supposed to be valid is folded:  The following example shows the first case:  CS-VYPER_JULY_2022-004  @external def foo1() -> int8:     return 1 ** (-5)  @external def foo2() -> int8:     x: int8 = (-5)     return 1 ** x  Compiling foo1 outputs the following exception since folding does not allow exponents to be negative. On the other side, calling foo2 returns 1 as no folding is happening on the exponentiation.  Error compiling: Foo1.vy vyper.exceptions.InvalidOperation: Cannot calculate a negative power contract \"Foo1.vy\", function \"foo\", line 3:11      2 def foo1() -> int8: ---> 3     return 1 ** (-5) ------------------^      4  This example shows how some expression are folded even if they should not be valid:  @external def bar1() -> uint16:     return 1 - 2 + 2  Vyper - Vyper Compiler -   11  CorrectnessLowVersion1      \f@external def bar2() -> uint16:     x: uint16 = 2     return 1 - x + 2  In  this  example,  calling  bar1  returns  1  while  calling  bar2  reverts  since  no  folding  is  done  and  1-x results in an underflow.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   SafeMath Reverting on Valid Power", "body": "  When having the exponentiation of a signed number with the exponent y being a literal, safe_pow adds the following check to the intermediate representation:  CS-VYPER_JULY_2022-005  ok = [\"and\", [\"slt\", x, upper_bound], [\"sgt\", x, -upper_bound]]  Signed integers are represented using two's complement, one of the properties of this representation is that MIN_INT+1 == -MAX_INT.  For  values  of  y  for  which  there  exists  x'  such  that  x'**y==MAX_INT+1,  safe_pow  will  compute upper_bound=x',  which  is  result  of  calculate_largest_power.  If  the  event  that  the  base  of  the exponentiation  happens  to  be  x==-x',  although  there  is  no  overflow  as  x**y==MIN_INT,  the  check mentioned above will fail as [\"sgt\", x, -upper_bound] will return false since x==-upper_bound.  For instance, when the following code snippet is compiled and deployed, a call to foo will revert:  @external def foo() -> int16:         x: int16 = -8         y: int16 = x ** 5 return y  The produced IR check will be:  [seq, [assert, [and, [slt, x, 8], [sgt, x, -8]]], [exp, x, 5 <5>]]]]],  that   Note  upper_bound==MAX_INT+1 in this case:  the  same   issue  arises  when   trying   to  compute  MIN_INT**0  as  well  since  @external def foo() -> int16:         x: int16 = -32768         y: int16 = x ** 0 return y  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   SafeMath Reverting on Valid Power for ", "body": " int256  Vyper - Vyper Compiler -   12  CorrectnessLowVersion1CorrectnessLowVersion1            \fWhen  having  an  exponentiation  of  a  signed  number,  the  following  IR  node  is  added  to  check  for overflows and underflows of the computation:  CS-VYPER_JULY_2022-006  [\"and\", [\"slt\", x, upper_bound], [\"sgt\", x, -upper_bound]]  For int256, a similar issue as the one described in SafeMath Reverting on Valid Power can happen. For any exponentiation of a int256 by 0 or 1, upper_bound will be equal to MAX_INT256+1 and hence the left-hand side of the and will be the following node: N=[\"slt\", x, MAX_INT256+1]. This check will always evaluate to false as the EVM interprets MAX_INT256+1 as MIN_INT256. In the following code, a call to foo will always revert:  @external def foo() -> int256:     x: int256 = 2     return x ** 0  When  optimizations  are  enabled  an  _comparison_helper, the optimizer will check the following:  interesting  case  can  happen,  during   its  call   to  if is_strict and _int(args[1]) == never:     # e.g. gt x MAX_UINT256, slt x MIN_INT256     return (0, [])  As _int(MAX_INT256+1) evaluates to MIN_INT256, N will be replaced by the integer node 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Wrong Overflow Exception", "body": "  CS-VYPER_JULY_2022-007  When  having  an  exponentiation,  to calculate_largest_base  will  raise  a  TypeCheckFailure  if  y  happens  to  be  greater  than  the number of bits the given type can store. While this is a correct behavior in most cases, for bases equal to 0 or 1, such computation would not overflow.  literal,  safe_pow's  call   the  exponent  y   is  a   if   In  practice,  an  OverflowException  is  raised  earlier  when  the  same  check  is  performed  against  the Vyper AST in validate_numeric_op.  @external def foo():         x: uint256 = 1         y: uint256 = x ** 257  Error compiling: Foo.vy vyper.exceptions.OverflowException: Power is too large, the calculation will always overflow contract \"test_opti/02.vy\", function \"foo\", line 4:22      3     x: uint256 = 1 ---> 4     y: uint256 = x ** 257 -----------------------------^      5  Vyper - Vyper Compiler -   13  CorrectnessLowVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Calling permit on a Forbidden Token", "body": "  Tokens  can  be  set  to  forbidden  on  the  CreditFacade.  A  token  can  be  forbidden  for  various  reasons including security issues its logic. This means the allowed interaction with it should be as constrained as possible. To that end, many actions are not permitted while a credit account holds a forbidden token such as increasing the debt of an account. Note, however, calling addCollateralWithPermit with 0 amount is still  allowed  since  the  credit  account's  balance  will  not  be  increased.  During  this  call,  a  permit()  is executed on the token. In theory, this call can execute arbitrary logic which could be dangerous for both the  users  and  the  system.  Theoretically,  they  same  concern  holds  when  calling  transfer  and transferFrom on the problematic tokens.  CS-GEARV3CORE-001  Acknowledged:  Gearbox Protocol responded:  We do assume that tokens are not malicious because we allow users to decrease their exposure by withdrawing them or selling using adapters (both of which call transferFrom under the hood). And it's probably safe to assume that permit can't do more harm than transferFrom.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Missing Input Sanitization", "body": "  1. None  of  the  setMaxEnabledTokens()  functions  check  that  the  new  maxEnabledTokens  is  greater than zero. Setting zero as maxEnabledTokens would make the system unusable.  CS-GEARV3CORE-002  Gearbox Protocol - Gearbox V3 Core -   20  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedCodePartiallyCorrectedSecurityLowVersion1AcknowledgedDesignLowVersion1CodePartiallyCorrected                   \f2. The to parameter in GearStaking._processPendingWithdrawals is unsanitized.  3. The constructor of AddressProviderV3 take the address _acl as parameter, but the address is not checked to be non-zero. There is no security issue as the contract would simply be unusable.  Code partially corrected:  1. The  function  CreditConfigurator.setMaxenabledTokens  has  been  updated  and  reverts  if  the new value for maxEnabledTokens is 0.  Gearbox Protocol - Gearbox V3 Core -   21  Version3  \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Anyone Can Redistribute the Votes   -Severity Findings  -Severity Findings   Custom Health Factor Is Ignored    No Rate on New Quoted Tokens    Reserve Pricefeed Can Be Main Price Feed    Too Many Bots Can Block Liquidation   -Severity Findings   Debt Accrual on Quota Dust    Partial Liquidations When maxEnabledTokens Are Reduced    Arbitrary Bot Permissions    Debt Calculation Ignores Tokens With Fees on Transfer    Division By Zero    Global Quoted Tokens Mask Instead of Credit Account's Mask   Inconsistent Casting    Mint With Referral    Quota Increase Is Allowed for Forbidden Tokens    Updating Voter Contract May Lock GEAR   Informational Findings  Inconsistent Remaining Balance Check    Unused Code    Wrong Comments   Interest Accrued by Quota Dust    Code Duplication    Redundant and Missing Events Emission   Inconsistent Overflow Handling   1  0  4  10  7  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Anyone Can Redistribute the Votes", "body": "  Gearbox Protocol - Gearbox V3 Core -   22  CS-GEARV3CORE-021  CriticalCodeCorrectedHighMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignCriticalVersion2CodeCorrected            \fThe function GearStakingV3.deposit allows anyone to deposit GEAR tokens and execute a multivote for an arbitrary address to. The unrestricted call to _multivote in the name of to allows the caller to redistribute the votes of any to target address in the limits of totalStaked.    The to parameter of the deposit function has been removed. The deposit function can only make a deposit for msg.sender.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Custom Health Factor Is Ignored", "body": "  Note: This issue was discovered by Gearbox Protocol.  Users  have  the  option  to  perform  the  collateral  check  with  a  health  factor  (HF)  greater  than  1.  Let's assume  that  a  user  sets  HF  to  1.2.  A  multicall  should  fail  if  the  health  factor  ends  up  being  1.1. Nevertheless, this doesn't happen as the check compares the debt to the weighted collateral ignoring the min health factor. As a result, the account is still healthy from the system's perspective.  CS-GEARV3CORE-013  Code corrected*  The check has been updated as follows:  if (cdd.twvUSD < cdd.totalDebtUSD * minHealthFactor / PERCENTAGE_FACTOR) {     revert NotEnoughCollateralException(); // U:[CM-18B] }  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   No Rate on New Quoted Tokens", "body": "  When a new quoted token is added in the PoolQuotaKeeperV3, its rate is set to 0 by default and will keep its value until the minRate is set in the GaugeV3 and a new epoch has elapsed. This would allow an attacker to request a huge quota (up to the configured limit) without paying any interest to the protocol during the period where rate = 0.  CS-GEARV3CORE-015    The  function  PoolQuotaKeeperV3._updateQuota  has  been  updated  so  that  if  rate  ==  0  the quotaChange is zero as well, preventing users to increase their quota for a yet inactive quoted tokens.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Reserve Pricefeed Can Be Main Price Feed", "body": "  CS-GEARV3CORE-024  Gearbox Protocol - Gearbox V3 Core -   23  CorrectnessMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                        \fIn  the  function  PriceOracleV3.setReservePriceFeed(),  nothing  prevents  the  reserve  price  feed to  be  the  same, LPPriceFeed.updateBounds() could be used during a read-only reentrancy to trick the system into believing the exchange rate of the LP token is way too high.  the  base  price   the  same  as   feeds  were   to  be   feed.   two   the   If     No changes related to the issue have been done in PriceOracleV3 as it may complicate operations, but a check that the two feeds must be different has been added in LPPriceFeed.updateBounds().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Too Many Bots Can Block Liquidation", "body": "  It  is  possible  to  block  a  liquidation  by  adding  enough  bots  so  that  erasing  all  the  bot's  permission  on liquidation would be bigger than the block gas limit, thus blocking the liquidation process.  If such a scenario happens, a new BotList can always be redeployed and re-linked to the system, but all the bot users will have to withdraw their funds from the old BotList and set all the permissions again.  CS-GEARV3CORE-027    A  global  limit  of  5  bots  per  credit  account  has  been  added.  More  specifically CreditFacade.setBotPermissions reverts if the number of remaining bots exceeds the global limit.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Debt Accrual on Quota Dust", "body": "  The  function  QuotasLogic.calcAccruedQuotaInterest  returns  0  when  quoted  <=  1  and  thus does not account for the debt accrued on the quota dust. Previously, the interest accrued by 1wei left in the  quota  was  accounted  for  in  the  pool  quota  revenue  and  materialized  whenever  the  quota  was increased again in the CA. In the updated codebase, it is still accounted for in the pool quota revenue, but will  never  materialize  in  the  CA  debt.  This  will  create  a  small  discrepancy  that  will  increase  over  time between the expected pool quota revenue and the true pool quota revenue which will be lower, slightly over-evaluating the value of the LP shares.  CS-GEARV3CORE-019    The 1wei gas optimization when a quota is set back to 0 has been removed from the codebase, fixing this issue.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Partial Liquidations When maxEnabledTokens", "body": " Are Reduced  CS-GEARV3CORE-026  Gearbox Protocol - Gearbox V3 Core -   24  DesignMediumVersion1CodeCorrectedDesignLowVersion6CodeCorrectedDesignLowVersion3CodeCorrected                        \fA (bot) multi-call cannot execute successfully if the enabled tokens at the end of the execution exceed the maxEnabledTokens. Consider the case where the CreditConfigurator sets the maxEnabledTokens to a value lower than the current one. This means users who have more tokens enabled should disable some of them in order to execute a (bot) multi-call. Since partial liquidations are executed by the special permissioned bot, these will be blocked as well. The specification of the partial liqudations delivered to us does not handle such a case.    The  codebase  (CreditManager._saveEnabledTokensMask())  has  been  updated  so  that  the underlying  token  is  excluded  from  the  maximum  enabled  tokens  count,  making  partial  liquidation  by  a swap to the underlying token always possible.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   Arbitrary Bot Permissions", "body": "  When  setting  permissions  to  a  bot,  the  permissions  are  not  sanitized,  and  it  is  thus  possible  to  set arbitrary permissions that could be meaningless in the Gearbox system.  CS-GEARV3CORE-018    A  check  has  been  added  to  CreditFacadeV3.setBotPermissions  to  enforce  that  only  valid permissions can be set.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   Debt Calculation Ignores Tokens With Fees on", "body": " Transfer  Note: This issue was discovered by Gearbox Protocol.  CS-GEARV3CORE-023  CreditManager.fullCollateralCheck()  calculates  the  system denominated  in  the  pool's  underlying.  If  the  underlying  has  fees  on  transfer,  a  small  amount  will  be deducted when the debt is repaid. Even though the system is aware of this potential fee, it doesn't take it into account when it calculates the full debt during the full collateral check. This means that the health factor  could  be  slightly  overestimated  allowing  an  account  to  become  liquidatable  slightly  later  than  it should.  total  debt  owed   the   to   Code corrected  The fees are now accounted for in the debt calculation as follows:  uint256 totalDebt = _amountWithFee(cdd.calcTotalDebt());  Gearbox Protocol - Gearbox V3 Core -   25  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f7.10   Division By Zero  LinearInterestRateModelV3.availableToBorrow() calculates the U_WAD value by dividing with expectedLiquidity.  However,  the the  corner  case  exists  expectedLiquidity is 0.  for  an  empty  pool,  where   CS-GEARV3CORE-016    A check was added to take care of the case where expectedLiquidity is 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.11   Global Quoted Tokens Mask Instead of", "body": " Credit Account's Mask  The specification of CreditManagerV3._getQuotedTokensData() specifies that the returned value _quotedTokensMask should be the mask of the enabled quoted tokens of the Credit Account, but the actual returned value is the mask of all the quoted tokens in the Credit Manager.  CS-GEARV3CORE-014  Specification updated:  The nat spec has been updated to reflect the functionality of the code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.12   Inconsistent Casting", "body": "  CS-GEARV3CORE-028  In  the  function  CreditConfiguratorV3._revertIfContractIncompatible(),  _contract  is the  call  creditManager(),  but  _contract  can  be casted  CreditFacadeV3, AdapterBase, or CreditConfiguratorV3 as they all implement this call.  into  CreditFacadeV3   for   Spec changed:  A comment has been added in CreditConfiguratorV3._revertIfContractIncompatible() to justify the casting clarifying that all contracts implementing this interface can be used.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.13   Mint With Referral", "body": "  In  the  PoolV3,  the  function  depositWithReferral  is  available  for  users,  but  there  is  no  such equivalent for mint.  CS-GEARV3CORE-020  Gearbox Protocol - Gearbox V3 Core -   26  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                              \f  The function mintWithReferral has been added in the PoolV3.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.14   Quota Increase Is Allowed for Forbidden", "body": " Tokens  When a CA holds a forbidden enabled token, it is not allowed to increase its debt or the balance of such a token. However, the system allows the increase of the quota of an enabled forbidden token. While it does not increase the exposure of the system to the problematic token, it would make sense to disallow such quota updates for consistency.  CS-GEARV3CORE-029    CreditFacade._updateQuota reverts when a forbidden token is specified in callData.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.15   Updating Voter Contract May Lock GEAR", "body": "  Changing  the  voter  contract  of  a  Gauge  while  stakers  still  have  registered  votes  may  break  the  votes accounting and prevent stakers from withdrawing their funds from the voter contract.  CS-GEARV3CORE-022    The voter contract of a Gauge has been updated to be immutable.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.16   Code Duplication", "body": "  1. The computation of the value pctDiff in PolicyManagerV3._checkPolicy() is duplicated  2. The   computation   timestampRampStart   +   rampDuration   in  CreditLogic.getLiquidationThreshold() is duplicated  CS-GEARV3CORE-012    Code duplication has been removed.  Gearbox Protocol - Gearbox V3 Core -   27  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                        \f7.17   Inconsistent Overflow Handling  USDTFees.amountUSDTWithFee  handles  the  case  where  maximumFee  +  amount  overflows. However, there is no such a case when the amountWithBP is calculated. This is just an inconsistency issue as it is unlikely the amount value to be that big.  CS-GEARV3CORE-025    An operation which is less probable to overflow is currently used.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.18   Inconsistent Remaining Balance Check", "body": "  Different checks are implemented for checking if an amount is 0 or 1, amount < 2 or amount <= 1. It is recommended to always use the same way of checking for consistency and code maintainability.  CS-GEARV3CORE-008    All the checks mentioned above have been updated to be <= 1 in the codebase.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.19   Interest Accrued by Quota Dust", "body": "  For gas optimization reasons, the Credit Accounts quotas are reset to 1, and this 1 wei contributes to TokenQuotaParams.totalQuoted. This dusty wei has multiple effects:  CS-GEARV3CORE-011  this  1  wei  may  contribute  to  the  pool's  revenue  on  updateRates  because  it's  based  on TokenQuotaParams.totalQuoted, which sums up that dust.  if a CA was closed and leaves 1 wei of quoted tokenA in AccountQuota.quota, the next borrower that increases the quota for that tokenA on the same CA may have some interests due because the timeDelta * currentQuotedTokenRate combination may be enough so that calcAccruedQuotaInterest may return a non zero value, recall that the minimal period before one can reuse a CA is 3 days (259200 seconds).  if this quota is not reactivated for a long time, over multiple CA open and close cycles, the time delta between now and the last time the accountQuota.cumulativeIndexLU was updated can be significant.  Note, the above is a theoretical issue and mostly an inconsistency of the system and it is not expected to harm the users. It can happen that the pool revenue accounts for the 1 wei due to the reason above, but the computation in calcAccruedQuotaInterest yields 0.    Gearbox Protocol - Gearbox V3 Core -   28  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                   \fFrom Version 6 on, there is no 1 wei optimization so the issue is resolved.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.20   Redundant and Missing Events Emission", "body": "  There  are  multiple  instances  of  setter  functions  where  events  are  emitted  regardless  of  whether  they actually change the values. More specifically:  CS-GEARV3CORE-017  1. GaugeV3.setVoter  2. GaugeV3.changeQuotaTokenRateParams  3. GearStakingV3.setVotingContractStatus  Furthermore, an event is not emitted in PolicyManagerV3.setPolicy.    1. The function setVoter and event SetVoter have been removed.  2. The function GaugeV3._changeQuotaTokenRateParams has been updated to early return and  not emit any event if the updated values are the same as the old values.  3. The  function  GearStakingV3.setVotingContractStatus  has  been  updated  to  early  return  and not emit any event if the updated value is the same as the old value.  Events  PolicyManagerV3.disablePolicy(), and PolicyManagerV3.setGroup().  added   been   have   in   PolicyManagerV3.setPolicy(),  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.21   Unused Code", "body": "  1. The immutable GaugeV3.addressProvider is set but never used.  2. The functions externalCall and approveToken in the CreditManagerV3 are never called.  CS-GEARV3CORE-009    1. addressProvider has been removed.  Acknowledged:  2. Gearbox  Protocol  responded  that  these  functions  are  not  meant  to  be  used  within  the  current  codebase, but are prep work for the future.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.22   Wrong Comments", "body": "  CS-GEARV3CORE-010  Gearbox Protocol - Gearbox V3 Core -   29  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f1. USDT_Transfer._amountUSDTMinusFee():  the  value  returned  by  the  function  is  what  the  recipient would receive if amount was sent, not how much to send to reach amount  2. USDTFees.amountUSDTMinusFee():  the  value  returned  by  the  function  is  what  the  recipient  would receive if amount was sent, not how much to send to reach amount  3. CreditFacadeV3._revertIfOutOfTotalDebtLimit(): =   totalDebtLimit  totalDebtLimit = totalDebt.totalDebtLimit  totalDebt.currentTotalDebt   should   be  4. CreditManagerV3.calcDebtAndCollateral():  Therefore,  it  is  prevented  from  being  called  internally  should  be Therefore, it is prevented from being called externally    Comments for 1. and 2. were fixed.  Gearbox Protocol - Gearbox V3 Core -   30  \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Gas Optimizations", "body": "  1. The computations in GearStakingV3.getCurrentEpoch() can be unchecked.  2. The  computations  of  the  new  withdrawalsPerEpoch  in  GearStakingV3.withdraw  can  be  unchecked.  CS-GEARV3CORE-007  3. Disabling   in CollateralLogic.calcNonQuotedTokensCollateral() is redundant. There is no need to disable already disabled tokens.  outside   token   block   the   the   of   if   4. In  the  function  CreditLogic.calcDecrease,  the  condition  amountToRepay  >  quotaFees could  be  transformed  into  a  non-strict  inequality  to  save  a  bit  of  gas  since  SafeCast  will  not  be needed.  5. Assigning   branch amountToRepay  of CreditLogic.calcDecrease() has no effect since they will be reassigned later in the function.  newCumulativeIndex  +   in  the  quotaProfit   cumulativeQuotaInterest   newDebt   and   <   to   6. The  mapping  AccountFactoryV3._queuedAccounts  could  use  a  static  array  instead  of  a dynamic array. Its length is never read and there would not be the need for updating the length of a static array.  7. In CollateralLogic.calcCollateral(), one could use the first pass over the enabled token mask combined with the collateral hints on the quoted tokens, and use that information to optimize the  so CollateralLogic.calcNonQuotedTokensCollateral()  does  not  have  to  iterate  through the whole mask until it finds the last token.  unquoted   tokens   pass   the   on   8. The  function  PoolQuotaKeeperV3._updateQuota  does  not  implements  the  gas  optimization  trick of leaving 1 wei when the quota is manually reduced to 0.  9. The   function   has  signature.length==0, but signature is always assigned and never empty.  ControllerTimelockV3.executeTransaction   a   branch   if  Code partially corrected:  1. The computations have been moved in an unchecked block.  2. The  total  supply  of  GEAR  (10_000_000_000e18)  would  fit  in  type(uint96).max,  thus  an  overflow check is not needed.  3. The  line  tokensToCheckMask  =  tokensToCheckMask.disable(tokenMask);  could  be moved  into  the  preceding  if  block  to  save  gas.  If  done  outside  of  the  block,  this  line  will  be executed even for the tokenMask that are already disabled in the tokensToCheckMask.  4. The use of SafeCast has been removed from the else branch.  5. The redundant assignments have been removed.  6. The mapping has been updated to use a static array of size 2**32.  Gearbox Protocol - Gearbox V3 Core -   31  InformationalVersion1CodePartiallyCorrected    \f7. This issue does not arise with a well formatted collateralHints, Gearbox Protocol expects well  formatted collateralHints.  8. Gearbox Protocol specified that the optimization will be done at the UI level.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Missing Natspec", "body": "  Some of the natspec are missing or incomplete, here is a non-exhaustive list:  1. CreditFacadeV3.setDebtLimits():   natspec   for   parameter  _maxDebtPerBlockMultiplier is missing  2. CreditManagerV3.closeCreditAccount():  natspect  for  parameter  collateralDebtData  CS-GEARV3CORE-003  is missing  3. QuotasLogic.cumulativeIndexSince(),  QuotasLogic.calcAdditiveCumulativeIndex()  QuotasLogic.calcAccruedQuotaInterest(): natspec for the return value are missing  and  4. USDTFees: the library is missing natspec  5. BitMask: the library is missing natspec for return values and the calcIndex function  6. CollateralLogic.calcQuotedTokensCollateral():   natspec   for   parameters  quotedTokens and quotasPacked are missing  Gearbox Protocol said:  We're preparing a system-wide cleanup of NatSpec and comments.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Out-of-sync Configurators During Migration", "body": "  CS-GEARV3CORE-004  When  deploying  a  new  configurator  to  replace  an  old  one  for  a  credit  manager,  the  state  of  the  old to-be-replaced  configurator  is  copied  i.e.,  the  allowed  adapters  and  the  emergency  liquidators.  For  the migration  the  old  configurator  should  be  executed to  (CreditConfigurator.upgradeCreditConfigurator()).  In  the  meantime,  the  state  of  the  old credit configurator could have been changed. Hence, old and new credit configurators are out of sync. The governance of the protocol should be aware of this behavior.  to  complete  another   transaction   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Pricefeed Existence Consistency", "body": "  In  PriceOracleV3,  the  checks  for  the  existence  of  a  price  feed  differ.  Sometimes  the  check  is priceFeed != address(0), and sometimes decimals != 0.   getPriceRaw(), setReservePriceFeedStatus() are checking for pricefeed address  CS-GEARV3CORE-005  Gearbox Protocol - Gearbox V3 Core -   32  InformationalVersion1InformationalVersion1InformationalVersion1            \f priceFeedParams(), setReservePriceFeed() are checking for decimals  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.5   Timelock Delay Can Be Zero", "body": "  When  a  policy  is  set  in  PolicyManagerV3,  nothing  prevents  the  delay  to  be  0.  If  the  delay  is  0,  the policy admin can set the parameter and execute it in the same transaction, which would leave no change to  the  veto  admin  to  cancel  the  change  if  needed.  The  configurator  must  be  careful  when  setting  the delay for a critical policy.  CS-GEARV3CORE-006  Gearbox Protocol - Gearbox V3 Core -   33  InformationalVersion1    \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "9.1   Circular Swap With Full Balance Will Disable", "body": " the Token  If  a  user  makes  a  swap  such  X->Y->X  with  the  total  balance  of  token  X  within  the  same  call  in  the multicall, token X will be marked as disabled and unless explicitly marked as enabled with a later call in the multicall.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "9.2   Fees Parameters", "body": "  It  is  important  that  the  fees  are  set  correctly  for  the  system  to  behave  as  expected.  If  fees  are misconfigured, it could happen that certain unexpected behaviors may take place, for example, holders of unhealthy Credit Accounts could be incentivized to close their positions instead of liquidating themselves.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "9.3   Quota Activation Can Make Credit Accounts", "body": " Unhealthy  The  activation  of  quota  for  a  previously  whitelisted  token  in  the  Credit  Manager  can  make  Credit Accounts using that token as active collateral liquidatable, since their quotas will be 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "9.4   Quotas Are Independant Of Collateral", "body": "  A  credit  account  can  increase  its  quotas  by  consuming  all  the  available  amount,  independently  of  its collateral.  This  could  make  the  credit  account  very  quickly  liquidatable  as  the  quota  interest  will  be significant.  Moreover,  a  user  can  occupy  the  whole  quota  capacity  and  thus  prevent  other  users  from using the quota.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "9.5   Quotas for Derivative Tokens", "body": "  Each pool imposes a total amount of quota per token that can be used by all credit accounts related to that pool. This is done to limit the exposure of the system to specific risky assets. It's important to note that a token can derive its value from another underlying token. When setting the quota limit for either  Gearbox Protocol - Gearbox V3 Core -   34  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \ftoken this dependence should be taken into account, as the exposure of the system to a risky token can end up being greater than expected.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "9.6   Supported Tokens", "body": "   The system only supports standard ERC20 tokens without special behaviors, especially tokens with callbacks  (ERC777)  which  would  allow  arbitrary  code  execution.  More  explicitly,  tokens  with  two entry  points  should  also  be  avoided.  It  is  important  to  stress,  especially  in  the  absence  of  a withdrawal manager, that a reentrant token could allow read-only reentrancy attacks since the state of the credit account is not properly finalized and the full collateral check hasn't been performed.   The LP token of the Pool should not be allowed as collateral in the system.   Added  tokens  should  be  reviewed  regarding  gas  consumption.  For  example,  the  function UnsafeERC20._unsafeCall allows the callee to return a memory pointer that, if far in memory, would incur a huge gas cost for memory allocation.  Gearbox Protocol - Gearbox V3 Core -   35  NoteVersion1    \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Burn Function Redundant Checks", "body": "  In Dai contract, some gas savings are possible.  The  safeMath  operator  _sub  can  be  removed  in  totalSupply  =  _sub(totalSupply,  value);, because of the check:  uint256 balance = balanceOf[from]; require(balance >= value, \"Dai/insufficient-balance\");    The  redundant  check  was  removed.  Similar  check  in  mint  function  was  found  and  removed  by MakerDAO team themselves.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Contract L2GovernanceRelay Unnecessary", "body": " Statefulness  The  L2GovernanceRelay  contract  defines  the  l1GovernanceRelay  field  and  inherits  from  the messenger field from OVM_CrossDomainEnabled.  Those 2 fields could be declared as immutable as they are never changed after the initial assignment. The  L1GovernanceRelay  address  can  be  precomputed  and  passed  to  L2GovernanceRelay  as  a constructor variable.    MakerDAO - Optimism DAI Bridge -   9  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \fThe l1GovernanceRelay is an immutable field now. The messenger is still a storage field, because changing  it  will  require  a  change  in  the  Optimism  contracts  library,  that  are  out  of  scope  for  this assessment.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Init Function of L2GovernanceRelay", "body": "  The  function  init  for  L2GovernanceRelay  contract  is  needed  to  set  the  l1GovernanceRelay  field. This  function  is  not  protected  by  any  access  modifier  and  can  be  called  by  anyone.  The  attacker  can potentially call this function himself and ruin the deployment. Such attack will require the redeployment of L2GovernanceRelay contract and potentially of the L1GovernanceRelay. In addition the attacker can find a potential transaction that will revert the optimism history to such extend, where the L2GovernanceRelay deployment has happened, but init hasn't. This way attacker can init contract again himself, effectively getting a full control over the L2GovernanceRelay.    The L2GovernanceRelay now has only a constructor, where the immutable l1GovernanceRelay is set.  MakerDAO - Optimism DAI Bridge -   10  DesignLowVersion1CodeCorrected        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Constructors Marked Public", "body": "  L2DAITokenBridge.sol and dai.sol contracts have constructor with public modifier. This visability modifier will be ingnored by the solidity compiler.  MakerDAO - Optimism DAI Bridge -   11  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Compromised Guardian Can Block the", "body": " Executor  The guardian role has the privilege to cancel queued actions sets before they are executed. Updating the guardian  address  can  only  be  done  through  an  action.  If  the  guardian  account  is  compromised,  it  can always cancel an actions set which tries to update the guardian role to a new address. Effectively, once the guardian address is compromised it can block the Executor indefinitely.  Risk accepted:  Aave replied:  The guardian address is designed to be a multisig or governance executor (never an EOA) so having a compromised guardian is unlikely to happen.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Dangerous Delegatecalls", "body": "  Actions  sets  may  include  actions  (calls)  to  be  executed  as  DELEGATECALL  in  the  context  of  the BridgeExecutor. While this allows to aggregate multiple calls governed by code which can adapt to on chain  state,  should  the  called  contract  write  to  storage,  this  would  write  to  the  storage  of  the BridgeExecutor.  Hence  variables  of  the  contract  may  be  overwritten.  This  can  result  in  the  internal  Aave - Bridge Executors -   11  SecurityDesignCriticalHighMediumLowRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedSecurityLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \fvariables  being  changed  without  respecting  the  restrictions  enforced  in  their  setter  function,  e.g. updateGracePeriod() and the check for the minimum grace period.  Besides,  a  Delegatecall  is  also  able  to  modify/delete  existing  actions  sets,  insert  arbitrary  new  actions sets or manipulate entries in _queuedActions. The governance must be aware of this danger.  Untrusted code must never be called with DELEGATECALL.  Furthermore,  note  that  the  following  corner  case  exists:  An  action  consisting  of  a  call  to  the BridgeExecutor's executeDelegateCall function technically allows the governance to execute a call as a Delegatecall (with the risks mentioned above) despite the flag withDelegatecalls being set to false.  Risk accepted:  Aave replied:  The Executor contract assumes that any set of transactions that are queued by a successful proposal is legit. Thus, there are no bad actions that the contract can execute since the proposal passes multiple checks by the community, devs, white hats, auditors, etc.  The executeDelegateCall function is designed to be used for executing payload contracts, where a set of actions are described (instead of having multiple encoded calldatas). The governance should check that the delegate call execution does not update or alter any executor contract's state variable.  Apart from that, the correct way of doing a delegate call is through the action set and the execute function, instead of calling directly to executeDelegateCall. The community would detect and raise this concern if applicable.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Function Signature as String, Unicode", "body": " Charset  An action may contain the function signature as a string. This allows to display the function to be called in a  human  readable  way.  However,  this  can  be  dangerous  as  strings  support  the  unicode  charset  and many  lookalike  characters  of  different  alphabets  exist  in  this  charset.  Hence  users  might  be  tricked  to approve an action which seemingly contains the intended function call, but actually results in a different function  selector.  Given  a  function  selector  consists  of  4  bytes  only,  it  might  be  feasible  to  find  such  a collision.  For  characters,  into  https://util.unicode.org/UnicodeJsps/confusables.jsp?a=setReserveActive  lookalike   insights   more   please   refer   to:  Risk accepted:  Aave replied:  Governance should assess, test and simulate each proposal, checking the outcome of its changes without trusting string function signatures. Having the function signature human-readable is not a way of validating the legitimacy of proposals by any means.  Aave - Bridge Executors -   12  SecurityLowVersion1RiskAccepted          \f6.4   Potential Reentrancy on execute  The function execute is not protected against reentrancy. While the governance is trusted to not create actions sets which reenter into execute() and start executing another actions set, generally speaking an  action  may  reach  untrusted  third-party  code.  This  untrusted  code  may  reenter  the  BridgeExecutor. This would break the atomicity of sets of actions and may result in unexpected executions and states.  Risk accepted:  Aave replied:  The community and governance decide if an action set should execute any other action set of the same executor. The community should asses every governance proposal carefully.  Aave - Bridge Executors -   13  SecurityLowVersion1RiskAccepted      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Execution Order of Queued Actions Sets", "body": "  Multiple  queued  actions  sets  which  are  ready  for  execution  may  be  executed  in  an  arbitrary  order.  All actions which depend on a particular execution order must be placed within the same actions set where the  order  of  execution  is  defined.  If  multiple  actions  sets  exist  at  the  same  time,  they  must  be independent of each other.  Moreover,  updating  critical  system  variables  in  one  actions  set  might  change  the  behavior  of  other actions sets. For example, assume _delay is set to one day at the beginning. Actions set A is queued in the BridgeExecutor, A updates _delay to one second. On L1, the governance decides on actions set B. Governance should be careful, depending on whether A is executed before/after actions set B is queued on L2, a different _delay is applied before B can be executed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Impact of Rollback, Finality of Actions", "body": "  Especially  regarding  finality,  L2  solutions  based  on  optimistic  rollups  behave  differently  than  L1 Ethereum.  Should a rollback happen due to the discovery of an incorrect tx, this tx and all subsequent tx have to be reexecuted. This impacts the timestamp of the transaction. Most of the times incorrect transaction results are detected immediately and the rollback happens immediately, however in a worst-case scenario the rollback might happen just before the end of the fault proof period. In such cases the timestamp of the transaction changes significantly.  The  BridgeExecutor  heavily  relies  on  the  timestamps,  e.g.  to  determine  whether  an  action  can  be executed or if it already expired. Similarly the execution time is calculated based on the timestamp when queue() is executed. After a rollback the timestamps may have shifted and e.g. a previously executed actions set can no longer be executed as it has expired.  Furthermore,  the  order  of  transactions  after  a  rollback  is  not  guaranteed,  there  may  be  a  change  of sequence between a transaction to execute() or cancel() a pending actions set.  Validating  all  transactions  may  help  to  detect  incorrect  transactions  early,  however  in  a  worst-case scenario  (e.g.  a  bug  in  the  validator  software)  may  not  detect  such  a  wrong  transaction  and  an unexpected fraud proof may be submitted resulting in a rollback.  The  governance  needs  to  be  careful  about  finality  on  L2.  Overall  L2  solutions  are  still  considered  as experimental, interactions must be done with care.  Note that at the time of this review Optimism has not yet implemented fraud proofs while in Arbitrum only whitelisted addresses can create a challenge.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Potentially Resurrected ActionsSet", "body": "  Aave - Bridge Executors -   14  NoteVersion1NoteVersion1NoteVersion1          \fAn  actions  set  expires  if  the  _gracePeriod  has  elapsed  since  the  executionTime.  However,  an expired  actions  set  may  resurrect  if  the  _gracePeriod  is  extended  by  the  governance  later  in  the future. Resulting an expired actions set might be executable again.  It  should  be  carefully  thought  about  if  this  suspended  state  should  be  allowed,  especially  as  the guardian can only cancel queued actions set which have not yet expired.  Aave - Bridge Executors -   15  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Recent Stakers Get Unfair Yield", "body": "  0  0  1  1  CS-SQDC-001  In  the  DistributedRewardDistribution  contract,  the  rewards  being  committed  to  and  approved include the time range [fromBlock, toBlock] they were computed for. However, when the proposal is  executed  calls Staking.distribute(),  which  gives  out  yield  to  the  current  stakers  of  the  specified  worker, regardless of whether they were already staking during the relevant timeframe.  last  approve()  arrives),   the  distribute()   function   (when   the   This means that a staker joining after the period for which the rewards are computed, but before the last approve()  arrives  for  that  proposal,  gets  an  unfair  share  of  those  rewards.  Symmetrically,  a  staker leaving in the same window will lose their fair share of the rewards.  Code partially corrected:  Users are forced to stake for more epochs determined by epochsLockedAfterStake. This value is set by the admin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Gateway Operator Can Add 0 SQD to His", "body": " Stake  The function GatewayRegistry.addStake() does not revert if called with amount = 0; instead, it extends  the  lock  period  by  one  \"segment\",  starting  from  the  next  epoch.  This  behaviour  is  harmless per-se (it is roughly equivalent to enabling auto-extension), but it is undocumented.  CS-SQDC-002  Subsquid - Subsquid -   13  DesignCorrectnessCriticalHighMediumCodePartiallyCorrectedLowAcknowledgedDesignMediumVersion1CodePartiallyCorrectedDesignLowVersion1Acknowledged                  \fAcknowledged:  It is not an intended behaviour, but since there\u2019s no harm in that, we will keep that and add a comment.  Subsquid - Subsquid -   14    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Reward Distribution Can Run Out of Gas   -Severity Findings   Distribution With Multiple Commitments    Supporting the Same Worker in Subequal Strategies    Claiming Can Run Out of Gas    Delegation Limit Redundant With Soft Cap    Distributor Index    Gateway Operator Can Stake 0 SQD    Gateway Staking for Less Than an Epoch, With Autoextension    Missing Check When Removing Distributor    Retiring a Small Worker Can DOS the Reward Distribution    Stake Duration Is Not Sanity-Checked    Transferring the Ownership of Vesting   Informational Findings   Redundant Grant of Admin Role    Redundant Role-Granting Function    Event Rewarded Can Be Emitted With 0 Reward    Two Different Implementations of effectiveTVL()   0  0  1  11  4  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Reward Distribution Can Run Out of Gas", "body": "  The  reward  distribution  system  implicitly  requires  reward  proposals  to  cover  all  active  workers  for  their time  window:  this  is  because  proposals  have  to  cover  consecutive  timeframes  (enforced  through lastBlockRewarded),  therefore  one  cannot,  at  a  later  time,  \"go  back\"  and  integrate  an  old  proposal with worker rewards it did not include. If the system grows too big, the reward distribution would break because the one transaction to reward all workers would hit the block gas limit.  CS-SQDC-016    Subsquid - Subsquid -   15  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected        \fThe number of delegates is capped by maxDelegations which is settable by the admin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Distribution With Multiple Commitments", "body": "  CS-SQDC-017  2,   the   version   call In  DistributedRewardDistribution.commit()  for  the  same  block  range.  Other  distributors  can approve  this  commitment  for  this  range  only  once.  However,  if  a  second  commitment  takes  place  the approvals  are  reset.  Moreover,  the  distributors  already  have  approved  this  commitment  they  are  not allowed to reapprove it.  distributors   multiple   system   allows   to     A second commitment doesn't reset the number of approvals.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Supporting the Same Worker in Subequal", "body": " Strategies  Using the subequal strategy, gateway operators can choose to delegate their queries to a specific subset of workers by calling SubequalStrategy.supportWorkers(). Each time a worker is supported, the count  of  workers  increases.  However,  there's  no  check  that  a  worker  has  already  been  supported. Therefore, the worker count might be greater than the actually supported workers. The same issue exists for SubequalStrategy.unsupportWorkers(). Note that this issue could also lead to division by 0 when SubequalStrategy.computationUnitsPerEpoch() is called.  CS-SQDC-005    A check for worker duplication was implemented.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Claiming Can Run Out of Gas", "body": "  The function Staking.claim() iterates through all the workers this staker has staked into. There is no bound on the number of workers one can stake into: if it grows too large, the claiming transaction might hit the block gas limit, making it altogether impossible to claim yield without temporarily unstaking from some workers.  CS-SQDC-009    Subsquid - Subsquid -   16  DesignLowVersion2CodeCorrectedCorrectnessLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                           \fThe  contract  now  enforces  a  hard  limit  of  100  delegations  per  staker.  Note  that  the  number  of  max delegations can be changed by the admin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Delegation Limit Redundant With Soft Cap", "body": "  The Staking.deposit() function enforces a hard cap on the total amount of SQD staked in favour of any  single  worker.  This  is  redundant  with  the  soft  cap  induced  by  the  law  of  diminishing  returns implemented in SoftCap.  CS-SQDC-015    The hard cap was removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Distributor Index", "body": "  CS-SQDC-014  The  DistributedRewardDistribution.distributorIndex() which implements the following logic:  distributor   decides   system   current   who   the   by   is   calling  uint256 slotStart = block.number / 256 * 256; return uint256(blockhash(slotStart)) % distributors.length();  When the block.number is a multiple of 256, the slotStart equals to block.number. blockhash for the current block returns 0 instead. This means the distributor will always be the one with index 0 for the multiples of 256.    The distributor index is not determined by blockhash. It changes in a round-robin fashion as follows:  return (block.number / roundRobinBlocks) % distributors.length();  However, the distributor index might not change the way it's expected. For example, consider the case where roundRobinBlocks is a multiple of distributors.length() then the index is always going to be 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Gateway Operator Can Stake 0 SQD", "body": "  The function GatewayRegistry.stake() does not check that amount > 0, so a gateway operator can call it with amount set to 0 and have all his gateways be marked as active.  CS-SQDC-008  Subsquid - Subsquid -   17  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  The function now includes a check that the staked amount is greater than minStake which is initially set to 1. minStake can be changed by the admin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Gateway Staking for Less Than an Epoch,", "body": " With Autoextension  CS-SQDC-011  Gateway operators can set an \"autoextension\" option for their staking position, which is meant to prolong it indefinitely, in whole consecutive \"segments\" of the original duration, until the option is disabled. Yet, the  function  GatewayRegistry.computationUnitsAvailable()  does  not  play  well  with  this mechanism, if the stake duration is less than an epoch.  Say that the duration is one tenth of an epoch (and autoextension is enabled): then an epoch is \"tiled\" by 10 segments, so the available CUs in the epoch should be 10 times those afforded by a single segment (which is, instead, what the function returns). On the other hand, if it were actually implemented this way, one could spend all those CUs in less than an epoch, then \"prematurely\" disable the autoextension, and finally unstake, thus spending more CUs than what should be granted by the effective lock period.    Gateway locking cannot be shorter than one epoch. However, should the epoch duration be increased, for  stakers  who  have  staked  under  the  previous  configuration,  the  staking  duration  could  be  less  an epoch.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Missing Check When Removing Distributor", "body": "  In  the  DistributedRewardDistribution  contract,  the  function  removeDistributor()  does  not check that the resulting distributors.length() is greater than or equal to requiredApproves, as is instead done in the setApprovesRequired() function.  CS-SQDC-006    The check was added to the function removeDistributor() as well.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Retiring a Small Worker Can DOS the Reward", "body": " Distribution  The  function  Staking._distribute()  reverts  if  the  worker  in  question  has  no  SQD  staked  in  his favour. Therefore, a malicious actor can register a worker doing only a tiny amount of work (just enough to earn some rewards), and also stake some SQD in his favour (he needs to be the only staker for that  CS-SQDC-018  Subsquid - Subsquid -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fworker).  Then,  when  the  reward  proposal  arrives  to  DistributedRewardDistribution,  he  can unstake  everything  to  execute  because DistributedRewardDistribution.distribute() will revert, temporarily blocking the rewards for all other workers as well, until a new proposal is submitted to make up for it.  from  his  worker.  The  proposal  will   then   fail     The  function  Staking._distribute()  now  does  nothing,  instead  of  reverting,  if  the  worker's  total stake is 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Stake Duration Is Not Sanity-Checked", "body": "  In  the  function  GatewayRegistry.stake(),  the  parameter  durationBlocks  is  not  checked  to  lie within  some  reasonable  bounds.  A  user  can  therefore  inadvertently  plug  in  a  disproportionately  high value (e.g. thinking it is meant to be a duration in seconds) and lock their tokens for too long.  CS-SQDC-013    The stake duration is now checked not to exceed 3 years.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Transferring the Ownership of Vesting", "body": "  SubsquidVesting aims to limit the usage of $SQD only within the protocol. However, the ownership of SubsquidVesting  can  be  transferred  to  a  contract  which  could  issue  transferrable  shares  of SubsquidVesting and therefore create a derivative of $SQD that can be traded.  CS-SQDC-003    Ownership transferring was disallowed. We assume that the beneficiaries of the vesting accounts will not be contracts.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Event Rewarded Can Be Emitted With 0", "body": " Reward  In the Staking contract, the Rewarded event is emitted by the functions updateCheckpoint() and claim(). However, while the former checks for the reward to be positive before emitting the event, the latter does not.  CS-SQDC-010  Subsquid - Subsquid -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                      \f  The event is now only emitted for positive rewards.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Redundant Grant of Admin Role", "body": "  CS-SQDC-004  the   DistributedRewardDistribution   In  DEFAULT_ADMIN_ROLE  AccessControlledPausable, which DistributedRewardDistribution inherits from.  the  redundant  with   the  deployer.  This   constructor   contract,   the   to   is   grants   the constructor  of    The redundant statement was removed  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   Redundant Role-Granting Function", "body": "  In  contract  TemporaryHoldingFactory,  the  function  allowTemporaryHoldingCreator()  is redundant with the public grantRole() function (in OpenZeppelin's AccessControl), inherited from AccessControlledPausable.  CS-SQDC-007    The redundant function was removed  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.16   Two Different Implementations of ", "body": " effectiveTVL()  CS-SQDC-012  function  effectiveTVL()   The  in WorkerRegistration: in the former calculates the soft capped sum of the total bonded amount, the latter simply estimates the total bonded amount of all the workers.  in  RewardCalculation  and   implemented  both   is     The function was removed from the WorkerRegistration contract.  Subsquid - Subsquid -   20  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Cliff Value", "body": "  During vesting, the cliff depends on the totalAllocation i.e., the current balance of the token in the contract  and  the  released  amount.  However,  it  ignores  the  depositedIntoProtocol  amount.  This means, the value of the cliff and he vested amount varies depending on the amount of assets deposited into the system.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Computation Units Are Not Split Between an", "body": " Operator's Gateways  The function GatewayRegistry.computationUnitsAvailable() calculates the CUs available to a gateway by applying some mathematical formulas to the stake of its operator, regardless of the presence of  other  gateways  belonging  to  the  same  operator.  Therefore,  the  CUs  earned  by  an  operator  are \"replicated\" across all its gateways. According to Subsquid, the cluster is considered as a single instance of a gateway, with different endpoints. Therefore workers would have to track each cluster as a whole and monitor CU usage.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Incentives for Gateway Operators", "body": "  Gateway operators can lock their $SQD tokens for a period of time to get CUs in return. The number of CUs depends on the many factors:  the staked amount  the locked duration  the mana factor i.e., CUs per $SQD per epoch  the boost factor a step function for the most part with the exception of durations between 60 and 180 days where it's linear.  If the duration is set to a value greater than an epoch length then its effect is ignored. Therefore the CUs per epoch follow behave according to the graph below.  Subsquid - Subsquid -   21  NoteVersion1NoteVersion1NoteVersion1              \fNote that the operators have no incentive to stake for longer than an epoch unless they want to stake for longer  than  60  days.  Then  they  don't  have  an  incentive  to  stake  for  longer  than  180  days  unless  they want  to  stake  for  360  days.  Moreover,  an  operator  can  use  the  autoextension  option  so  their  $SQD remains staked until they decide otherwise.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Incorrect Behavior of Variable ", "body": " depositedIntoProtocol  The  function  Vesting._vestingSchedule()  is  the  sole  consumer  of  the  storage  variable depositedIntoProtocol  inherited  from  Executable.  It  is  meant  to  track  the  total  $SQD  that  are currently not in the Vesting wallet itself, but have been deposited elsewhere in the protocol and can be in later  withdrawn  at  a  _vestingSchedule()  to SQD.balanceOf(address(this))  OZ already-released  VestingWallet.vestedAmount()) does not include such deposited funds.  locking  $SQD  as  a  gateway  operator).  that   It  totalAllocation   is  used  (equal  see   (e.g.  compensate   time  to   funds,   plus   fact   the   the   However,  the  implemented  behaviour  for  this  variable,  defined  in  Executable,  does  not  match  the description.  Indeed,  if  after  a  call  into  the  protocol  (using  Vesting.execute())  some  $SQD  are returned  the  variable depositedIntoProtocol is simply reset to 0, instead of being decremented by the appropriate delta. This harms the user, in case they have multiple positions open in the protocol through the wallet, which will now be left unaccounted for in the vesting schedule  (e.g.  by  calling  GatewayRegistry.unstake()),   the  wallet   to   According  to  Subsquid,  this  is  not  considered  to  be  an  issue.  However,  users  should  be  aware  of  this particular behavior of SubsquidVesting contract.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Malleability of msg.data", "body": "  In  the  DistributedRewardDistribution  contract,  the  functions  commit()  and  approve() calculate  a  commiment  hash  as  keccak256(msg.data[4:]),  whereas  the  function  canApprove() calculates it by explicitly using abi.encode(), namely as keccak256(abi.encode(fromBlock, t oBlock, recipients, workerRewards, _stakerRewards)). This is a slight discrepancy, since msg.data is malleable: a caller to commit() or approve() can construct msg.data in many different ways,  (see https://docs.soliditylang.org/en/v0.8.25/security-considerations.html#minor-details).  On  the  other  hand, abi.encode() always serialises the parameters in the same way, regardless of how they are encoded in msg.data.  parameters   encoding   logical   same   the   all   Besides  the  two  calculations  potentially  mismatching  (which  leads  to  a  potentially  wrong  answer  by canApprove()),  the  very  exposure  to  the  malleability  of  msg.data  in  the  commit()  function  is  an  Subsquid - Subsquid -   22  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "0.010.10.4112510601803607201500Duration in days (log)02468CUs1e6Available CUs as a function of duration(amount=1000, mana=10)NoteVersion1NoteVersion1 ", "body": "       \fissue. The current distributor can inadvertently call the function with a \"non-default\" encoding: if the other distributors then try to approve() using the \"default\" encoding, the call will revert. Moreover, the current distributor can reset the approval count to 1, by re-submitting the same commit with a different encoding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Wrong Initialisation of Epoch Variables", "body": "  In  contract  NetworkController,  the  constructor  initialises  firstEpochBlock  as  nextEpoch(). However, the function nextEpoch() is not yet able to return the correct value at this early stage, since it itself relies on the value of firstEpochBlock being correct (and not 0).  This  leads  firstEpochBlock  to  take  a  value  lower  than  it  should  (although  still  in  the  future),  thus reducing the effective duration of epoch 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   addDistributor() and", "body": " removeDistributor() Change distributorIndex  the  DistributedRewardDistribution  contract,   functions  addDistributor()  and In  removeDistributor()  modify  distributors.length(),  thus  changing  the  return  value  of distributorIndex().  the   Subsquid - Subsquid -   23  NoteVersion1NoteVersion1        \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   WrappedAToken Does Not Implement Its", "body": " Interface  The interface IWAToken is defined in oracles-v3/contracts/interfaces/aave/IWAToken.sol and used to interact with WrappedAToken, but WrappedAToken does not implement fully this interface.  CS-GEARV3INTGRTNS-001  Acknowledged:  Gearbox Protocol responded:  The contract conforms to the interface, which is sufficient.(Note, however, that external interfaces in oracles are reduced to only have the functions necessary in price feeds).  Gearbox Protocol - Gearbox V3 Integrations -   13  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Back-running Redemption Approvals    Front-running the Redeem   -Severity Findings  -Severity Findings   Number of Underlying Tokens in Metapools   Informational Findings   Gas Optimizations   0  2  0  1  1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Back-running Redemption Approvals", "body": "  When redeeming assets a user calls redeem to the relevant zapper. They should give approval to the zapper to be able to redeem the assets. An attacker who sees the approval can the front-run the actual redemption redeem the assets of the user.  The  issue  was  reported  by  the  client  during  the  review  after  an  independent  assessment  of  the codebase.  CS-GEARV3INTGRTNS-004    Only the msg.sender can use their approvals.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Front-running the Redeem", "body": "  When redeeming a token with permit, a user specifies the receiver of the redeemed assets and submits a signature which is verified as follows:  try IERC20Permit(tokenOut()).permit(owner, address(this), tokenOutAmount, deadline, v, r, s) {} catch {} // U:[ZB-5]  CS-GEARV3INTGRTNS-005  Note that the signature verified is not connected to the msg.sender. Thus, an attacker who observes the mempool can front-run and submit the same signature. Since the receiver is freely set, an attacker can redeem the assets of a user.  Gearbox Protocol - Gearbox V3 Integrations -   14  CriticalHighCodeCorrectedCodeCorrectedMediumLowCodeCorrectedCodeCorrectedSecurityHighVersion2CodeCorrectedSecurityHighVersion1CodeCorrected                \fThe  issue  was  reported  by  the  client  during  the  review  after  an  independent  assessment  of  the codebase.    In the current implementation, only a signature belonging to the msg.sender can be verified.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Number of Underlying Tokens in Metapools", "body": "  The current implementation of CurveV1AdapterBase assumes the metapool to be a tricrypto pool, or at least have 3 underlying tokens. If the metapool has less than 3 underlying tokens, then the constructor will revert.  CS-GEARV3INTGRTNS-003    The function _getCoin will not revert if CurvePool.coin() reverts.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Gas Optimizations", "body": "  In the constructor of CurveV1AdapterBase, when the underlying tokens are queried for lending pools, the loop can break in the case !success as the calls to underlying_coins in following iterations will fail as well.  CS-GEARV3INTGRTNS-002    The loop now breaks the first time success is false.  Gearbox Protocol - Gearbox V3 Integrations -   15  CorrectnessLowVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Zappers Do Not Support Tokens With Fees", "body": "  Even though the pools can handle tokens with fees (USDT for now), the zappers do not support tokens with fees. If the fees on USDT were to be activated, the Underlying[Deposit|Farming]Zapper will stop working and users will have to deposit and withdraw manually.  Gearbox Protocol - Gearbox V3 Integrations -   16  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Temporary DOS Through Donations", "body": "  In Notional, depositing collateral for others is possible. For example, depositUnderlyingToken can deposit  collateral  to  another  address  than  msg.sender.  Hence,  it  is  possible  to  donate  collateral  to  a position  in  such  a  way  that  it  becomes  tracked  within  the  Notional  system.  Since  the  external  position computes  the  managed  assets  based  on  what  Notional's  getAccount  returns,  such  donations  will become visible to the external position. Hence, it could be possible to temporarily DOS the position by donating to it an unsupported token.  Acknowledged:  Avantgarde Finance replied:  Preventative measures for this are challenging and add complexity, so since the worst case is that the position will have a reverting price, and since the owner can resolve this state by removing that collateral, we will provide a fix if this ever becomes an issue in practice.  Avantgarde Finance - Sulu Extensions VI -   11  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Balancer Price Feed Vulnerable to Read-Only Reentrancy   -Severity Findings   Borrowing From cTokens With Same Underlying Can Lead to Unreported Debt   -Severity Findings   Remaining BPT in Adapter    mulUp Incorrect Comment   0  1  1  2  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Balancer Price Feed Vulnerable to Read-Only", "body": " Reentrancy  Balancer's system is vulnerable to read-only reentrancy. During the removal of liquidity, an inconsistency between the total supply and a pool's balances can be created (using native ETH transfers). That can be leveraged to manipulate the price feed upwards - leading to an over-evaluation of the fund.    Now, a reentrancy protected call to setRelayerApproval() is made when the price is computed to ensure that Balancer is not reentered.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Borrowing From cTokens With Same", "body": " Underlying Can Lead to Unreported Debt  Some  cTokens  may  have  the  same  underlying  (e.g.  cWBTC  and  cWBTC2).  The  parser  validates  the cTokens to borrow from as follows:  // validate ctokens for (uint256 i; i < cTokens.length; i++) {     address cTokenStored = ICompoundDebtPosition(_externalPosition)         .getCTokenFromBorrowedAsset(assets[i]);      if (cTokenStored == address(0)) {  Avantgarde Finance - Sulu Extensions VI -   12  CriticalHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedSecurityHighVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f        require(             CompoundPriceFeed(getCompoundPriceFeed()).getTokenFromCToken(cTokens[i]) ==                 assets[i],             \"parseAssetsForAction: Bad token cToken pair\"         );     } else {         require(             cTokenStored == cTokens[i],             \"parseAssetsForAction: Assets can only be borrowed from one cToken\"         );     } }  Note that the validation aims to prohibit borrowing from two cTokens that have the same underlying. In most cases, this works correctly. However, borrowing from both cTokens (with the same underlying) for the first time in the same action will bypass the validation. Consider the following scenario:  1. Borrow for the first time from both cWBTC and cWBTC2.  2. In the first iteration of the loop, cTokenStored will be 0x0 due to WBTC never being borrowed.  3. In  the  second  iteration  of  the  loop,  cTokenStored  will  still  be  0x0  since  the  mapping  in  the external position has not been updated yet. The update will happen in __borrowAssets, after the parser returns.  This will allow the external position to borrow from both cTokens. Note that __borrowAssets will only keep track of the first cToken. Hence, debt of the second cToken will not be tracked. The total debt will be underreported in such a scenario.    The parser now solely validates against the price feed while the library now validates against the stored cToken.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Remaining BPT in Adapter", "body": "  Avantgarde Finance reported an issue when redeeming Balancer LP tokens. It was possible to redeem BPTs so that a maximum amount of burned LP tokens is specified along with exact received underlying amounts. If the maximum was not reached, the BPT remained in the adapter.    After redemption, any surplus BPT remaining in the contract is sent back to the vault proxy.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   mulUp Incorrect Comment", "body": "   function mulUp(uint256 _a, uint256 _b) internal pure returns (uint256 res_) {     uint256 product = _a * _b;     require(_a == 0 || product / _a == _b, \"mul overflow\");  Avantgarde Finance - Sulu Extensions VI -   13  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                \f    if (product == 0) {         return 0;     } else {         // The traditional divUp formula is:         // divUp(x, y) := (x + y - 1) / y         // To avoid intermediate overflow in the addition, we distribute the division and get:         // divUp(x, y) := (x - 1) / y + 1         // Note that this requires x != 0, which we already tested for.          return ((product - 1) / ONE) + 1;     } }  The  comment  in  the  mulUp()  function  of  BalancerV2FixedPoint  mentions  divUp.  It  was  likely  copied from  there  and  not  changed.  This  issue  is  also  present  in  the  Balancer  contract  that  mulUp()  was adopted from.  Specification changed:  The comments in the files were adapted to reflect that the comments are not reviewed.  Avantgarde Finance - Sulu Extensions VI -   14  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   No Asset Check in requestDeposit()", "body": "  0  0  0  1  CS-SUL10-001  requestDeposit   The  a _depositAsset  argument.  This  asset  should  match  up  with  one  of  the  deposit  assets  of  the corresponding  vault.  to  call __depositFromQueue for that asset.  in  GatedRedemptionQueueSharesWrapperLib   they  do  not  match,   the  manager   it  will  be   impossible   function   takes   for   If   As  there  is  no  check  on  _depositAsset,  a  user  may  accidentally  deposit  an  incorrect  asset.  A  user accidentally making such a request can get their funds back by calling cancelRequestDeposit.  Note that in Enzyme V4 each vault only has a single deposit asset, but this may change in the future.  Risk Accepted:  Avantgarde  Finance  acknowledges  that  this  can  happen  and  accepts  the  risk  that  a  user  could  waste gas.  Avantgarde Finance - Sulu Extensions X -   10  SecurityDesignCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  Incorrect depositFromQueue Can Lead to Loss of User Funds   -Severity Findings  -Severity Findings  0  1  0  0  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Incorrect depositFromQueue Can Lead to", "body": " Loss of User Funds  depositFromQueue() in GatedRedemptionShareWrapper takes an array of addresses and processes their  deposit,  removing  them  from  the  DepositQueue.  It  reads  the  user's  position  index  in  the  queue from storage. Afterwards, the Request at index is deleted.  CS-SUL10-002  However, there is no check if the address actually had a Request in the queue to begin with. If a user has no request, their storage mapping will point to a Request with the default index of zero. This will result  in  the  first  Request  in  the  queue  being  deleted.  The  user  who  had  the  deleted  request  will  not receive any wrapped shares and their funds will be lost.  As  __depositFromQueue()  is  protected  with  __onlyManagerOrOwner(),  only  the  managers  can call the function with a non-existing address, which would cause the issue.  This could happen on 2 occasions:  1. The manager accidentally passes an incorrect address.  2. The  manager's  depositFromQueue  call  gets  frontrun  by  one  of  the  users  in  the  DepositQueue calling  cancelRequestDeposit().  Now  the  canceled  Request  no  longer  exists,  leading  to  a loss  of  funds  for  another  user.  If  the  manager  passed  all  users  in  the  queue  as  argument,  the attacker  will  also  need  to  deposit  again  from  another  address  after  they  cancel,  otherwise  the queue will not have a sufficient length and will revert. Note that the attack is more likely to happen when there's no whitelisting in place i.e., when useDepositApprovals is set to false.  depositAllFromQueue() is not affected, as here incorrect addresses cannot be passed.    The internal __removeDepositRequest function now validates that a Request has an assetAmount that is greater than zero. This ensures that the Request must exist before removing it. If a non-existant Request is passed, the function now reverts.  Avantgarde Finance - Sulu Extensions X -   11  CriticalHighCodeCorrectedMediumLowSecurityHighVersion1CodeCorrected         \f6.2   No minIncomingAsset Check for ZeroEx  In ZeroExV4Adapter, the parseAssetsForAction function returns a minIncomingAssetAmounts_ array with only a zero value. This means there is no internal check on the trade price, as is done in other adapters.  As only single orders with a fixed price can be taken on ZeroEx, there can be no slippage.  However, a vault admin may accidentally take an order with a lower price than they intended.  CS-SUL10-003    The  parseAssetsForAction  function  now  sets  the  minIncomingAssetAmounts_  to  the  amount that is expected to be received given the price of the order and the taker amount.  Avantgarde Finance - Sulu Extensions X -   12  InformationalVersion1CodeCorrected      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Cannot Pay ZeroEx Protocol Fee", "body": "  The ZeroEx protocol has a fee mechanism, where a fee in native ETH must be attached to fill limit orders. The ZeroExV4Adapter does not support sending ETH with the limit order call to pay this fee.  However, the fee is currently set to zero as of the time of this report and has been since September 29, 2021.  If the fee is set to a non-zero value again in the future, the adapter will no longer be able to make Limit Order trades.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Some ZeroEx Order Restrictions Not", "body": " Supported  ZeroEx  orders  have  taker  and  txorgin  fields,  which  restrict  who  can  take  a  particular  order.  These restrictions  cannot  be  used  to  specify  Enzyme  vaults  as  multiple  vaults  can  use  the  same ZeroExV4Adapter adapter.  If,  for  example,  the  taker  field  was  used  to  restrict  an  order,  it  would  be  set  to  the  address  of  the adapter. Any caller of the adapter would be able to take the order.  Avantgarde Finance - Sulu Extensions X -   13  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Locked Refunded Provision", "body": "  ISSUEIDPREFIX-007  When  a  maker  submits  an  order  to  the  Mangrove  orderbook,  they  need  to  provide  some  ETH,  also known as the provision, to compensate the takers in case the makerExecute hook reverts. A maker can update their offer by calling Forwarder.updateOffer. Note that at this point a maker can update most of the parameters of the order including gasreq, i.e. the gas required for the makerExecute hook to execute. A maker could reduce the gas requirements meaning that some provision will be refunded to them. Forwarder.updateOffer does not handle this refunding (the ownerData.weiBalance is not updated) and Mangrove system only sees MangroveOrder as a maker. This means that the refunded amount is essentially lost for the end-user of the MangroveOrder. Note that if the provision needs to be increased again, the end-user must provide extra ETH.  Code Corrected:  In the current implementation, the provision can only be increased therefore no funds are locked.  Mangrove Association (ADDMA) - MangroveOrder -   12  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected            \f6.2   Wrong Calculation of Locked Provision  When a user updates their offer through Forwarder.updateOffer, MangroveOrder tries to calculate the new gas price by calling deriveGasprice. The gas price depends on the total provision available for  this  order.  That  is  the  sum  of  the  extra  provision  attached  which  is  stored  in  args.fund  and  the already locked provision. Currently, the locked amount is calculated with the following snippet:  vars.offerDetail.gasprice() * 10 ** 9 * args.gasreq + vars.local.offer_gasbase()  ISSUEIDPREFIX-011  This formula is wrong for two reasons:  1. It depends on args.gasreq which is the updated gas requirement of the order as passed by  the user.  2. There are parentheses missing around args.gasreq + vars.local.offer_gasbase(),  as this entire term should be multiplied by the gas price.  This miscalculation can have multiple consequences:  1. Can allow users to steal funds (see relevant issue).  2. An  order  can  be  submitted  with  smaller  gasprice  since  the  calculated  total  provision  is  too  small.  Code Corrected:  Forwarder.updateOffer has been updated. Currently, users can only increase the provision for an order.  Users  cannot  determine  args.gasreq  as  it  is  set  to  be  equal  to  the  offerGasreq().  It  is important  to  notice  that  offerGasreq()  is  not  constant  but  depends  on  the  configuration  of  the MangroveOrder and in particular the gas requirements of the router.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Expiration Date Cannot Be Updated", "body": "  A  user  can  update  most  of  the  offer  details  by  calling  Forwarder.updateOffer.  However,  the expiration date cannot be changed. In order to change the expiration date of an order, one must retract it and submit a new one.  ISSUEIDPREFIX-003  Code Corrected:  MangroveOrder.setExpiry has been added to allow users to update the expiration date of the order.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Underflow in postRestingOrder", "body": "  ISSUEIDPREFIX-009  Mangrove Association (ADDMA) - MangroveOrder -   13  CorrectnessHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChanged                      \fOnce the market order part of GTC order has been filled as much as possible, the remaining amount the user  wants  to  trade  is  put  into  a  resting  order.  Note  that  if  fillWants  ==  true,  then  the  Mangrove engine will have stopped matching the order either when it is fully filled, there are no more orders on the books, or when the total average price of the order would fall below the threshold of the ratio between the order's initial wants and gives. Hence, if the matching stops before the order's wants are fully filled, we are  guaranteed  not  to  have  given  away  more  than  the  order  initially  had  (else  the  total  average  price would be below what we initially wanted).  However,  if  fillWants  ==  false,  this  condition  no  longer  holds.  The  order  can  receive  arbitrarily many tokens before giving away all the tokens it has to give away. As the price of a trade is defined by the  maker,  there  could  be  orders  on  the  books  which  give  away  arbitrarily  many  tokens  for  a  very  low price.  Hence,  the  user  can  receive  more  tokens  in  the  market  order  part  of  the  trade  than  they  were expecting to. As such, res.takerGot + res.fee can exceed tko.takerWants despite only having partially filled the order.  When we go to post a resting order, the following code is executed:  res.offerId = _newOffer(   OfferArgs({     outbound_tkn: outbound_tkn,     inbound_tkn: inbound_tkn,     wants: tko.makerWants - (res.takerGot + res.fee), // tko.makerWants is before slippage     gives: tko.makerGives - res.takerGave,     gasreq: offerGasreq() + additionalGasreq, // using default gasreq of the strat + potential admin defined increase     gasprice: 0, // ignored     pivotId: tko.pivotId,     fund: fund,     noRevert: true, // returns 0 when MGV reverts     owner: msg.sender   }) );  When  the  wants  for  the  resting  order  are  calculated,  an  underflow  can  occur  in  the  case  described above, as the market order part of the GTC order could have received arbitrarily many tokens. As Solidity ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "0.8.10  is  used,  this  will  simply  revert  the  transaction,  but  will  unnecessarily  prevent  the  user  from", "body": " completing their trade.  Specification Changed:  Currently,  the  order  is  posted  with  the  same  price  as  the  taker  originally  wanted.  Thus,  the  issue  has been mitigated.  Mangrove Association (ADDMA) replied:  this  problem  made  use  reevaluate  our  specification:  requiring  the  (instant)  market  order  and  the (asynchronous) maker order to respect a limit average price is not well defined. In some cases this would lead the maker order to be posted for a 0 price. We decided to change the specification and post the maker order at the price initially set by the taker for the market order (irrespectively of the obtained price).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Users Can Steal Funds From MangroveOrder", "body": "  The core Mangrove system maintains the balanceOf mapping which stores how much ETH is available for each maker to be used as a provision for their orders. Importantly, the MangroveOrder contract is seen  as  one  single  maker  by  the  system,  even  though  there  might  be  many  end  users  creating  their orders through it. Let us assume that at some point the balance of MangroveOrder is positive and an attacker has already submitted an order. It is possible as we show in another issue that there might be  ISSUEIDPREFIX-013  Mangrove Association (ADDMA) - MangroveOrder -   14  SecurityMediumVersion1CodeCorrected        \fsome non-claimable balance since updateOrder does not handle refunds. An attacker can steal money from mangrove by employing any of the following two vectors:  1. Updating an order without sending funds:   The attacker calls Forwarder.updateOrder for their order with msg.value == 0 and  they increase the gas requirement of their order.   This means that args.fund == 0 so gas price will remain the same, however, the total  provision needed has been increased as the gas requirements have been increased!   At this point MGV.updateOffer is called with msg.value == 0.   Mangrove core does not perform any check if there are enough funds attached to the call  since it relies on the balanceOf mapping by calling debitWei.   Mangrove core uses the amount stored in balanceOf for the extra provision.   The  attacker  now  retracts  the  order  and  withdraws  the  provision  of  the  order  which  includes the stolen amount.  2. Updating an order by attaching funds:   The attacker calls Forwarder.updateOrder for their order with msg.value != 0 and  they increase the gas requirement of their order.   Since funds have been attached to the transaction, the gas price will be recalculated.   The  new  provision  at  this  point  is  calculated  wrongly  since  the  provision  parameter passed  to  derivePrice  depends  on  args.gasreq  which  represents  the  updated  gas that requirements  of  args.gasreq can be freely set by the users so arbitrarily large value could be passed. As a result, the new gas price is greater than it should be but the extra funds passed are not enough to cover for the extra provision needed by the offer.  the  offer  and  not  vars.offerDetail.gasreq().  Note    Mangrove core uses the amount stored in balanceOf for the extra provision.   The  attacker  now  retracts  the  order  and  withdraws  the  provision  of  the  order  which  includes the stolen amount.  A  similar  attack  can  be  performed  when  some  of  the  global  parameters  change,  which  could  result  in inaccurate accounting of provisions. If the gasbase of the token pair related to an order changes in the core mangrove system, calling updateOffer can result in an increased (or decreased) provision without providing any additional funds. This will credit (or debit) funds to the MangroveOrder contract which aren't attributed  to  any  user.  In  particular,  if  the  global  gas  price  is  increased,  calling  updateOffer  of Mangrove core with an unchanged gasprice which is lower than the new global gas price, the mangrove core system will set the gas price higher without receiving any funds. This again changes the balance of the  MangroveOrder  contract,  without  attributing  it  to  any  individual  user.  While  _newOffer  and _updateOffer in Forwarder have checks to make sure the offer's gas price is higher than the global gas price, __posthookSuccess__ in MangroveOffer does not. Hence, if the global gas price changes, then an order is partially filled and attempts to repost, its provision will be increased with no additional submitted funds. While the amounts of funds are small, it is conceivable that a malicious user could be able to exploit a change in the global gas price or the gasbase in order to steal funds.  It  is  important  to  note  that  this  issue  cannot  result  in  users  losing  funds  since  the  excessive  provision which can be stolen cannot be claimed by any specific user. In the normal case, no excessive provision should  be  available.  Therefore,  it  is  expected  the  amount  that  can  be  stolen  to  be  low.  Hence,  we consider the issue as medium severity.  Code partially corrected:  The issue has been addressed in multiple different ways:  Mangrove Association (ADDMA) - MangroveOrder -   15  \f1. In the current implementation there shouldn't be unallocated users' funds in Mangrove core.  2. Users can only increase the provision of an order using MangroveOrder.updateOrder, not decrease  it.  Hence,  they  must  provide  additional  provision  and  can  not  submit  orders  which could make use of funds that are already stored in the Mangrove core.  3. The __posthookSuccess__ uses Forwarder._updateOffer.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Interpretation of type(uint24).max Not", "body": " Up-To-Date  ISSUEIDPREFIX-006  Before  Forwarder contract, i.e., gasreq = offerGasreq. In  is  removed  MangroveOffer.getMissingProvision  which  will  return  an  gasreq >= type(uint24).max.  ,  the  value  type(uint24).max  or  more  had  a  special  meaning  for  gasreq  in  the , the meaning of that value has been function the  if  called  with  incorrect  value   Forwarder,   present   from   still   the   but   in     The  function  has  been  removed.  It  has  been  suggested  that  MgvReader.getProvision()  can  be used as an alternative.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Wrong Comment", "body": "  The NatSpec of __posthookSuccess__ specifies for example \"posthook/filled\" as return data. However, the return data has changed its format.  ISSUEIDPREFIX-014  Specification changed:  The specification has been adapted.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Inaccurate Comment", "body": "  In MangroveOrder.checkCompleteness, the following is mentioned:  // when fillWants is true, the market order stops when takerWants units of outbound_tkn have been obtained;  However, this comment is inaccurate since part of the takerWants goes to cover the fees, so not the full takerWants amount can be obtained.  In AbstractRouter.push, the return value is described as follows:  ISSUEIDPREFIX-005  Mangrove Association (ADDMA) - MangroveOrder -   16  CorrectnessLowVersion4CodeCorrectedVersion4Version4CorrectnessLowVersion4Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \f///@return pushed fraction of amount that was successfully pushed to reserve.  However,  for  tokens  with  fees,  provided  the  TransferLib  is  used,  the  whole  amount  will  always  be reported.  Code Corrected:  The comments have been updated.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Missing Natspec", "body": "  The Natspec is missing in the following cases:   For AbstractRouter.bind, the maker parameter.   For AbstractRouter.unbind, the maker parameter.   For SimpleRouter.__pull__, the strict parameter.   For IOfferLogic.OfferArgs, the gasprice field.  Code Corrected:  The Natspec has been added to the respective functions.  ISSUEIDPREFIX-008  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Redundant pragma abicoder v2", "body": "  Many contracts include the pragma abicoder v2 directive. However, for solidity 0.8 the abicode v2 is the default one, so the pragma is redundant.  ISSUEIDPREFIX-010  Code Corrected:  The pragma has been removed from most of the contracts.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Setting Expiration Date", "body": "  A user can define the time-to-live of a resting order submitted through MangroveOrder by specifying the TakeOrder.timeToLiveForRestingOrder.  It  is  important  to  note  that  an  order  can  remain  in  the mempool  for  a  long  time  before  it's  executed.  Specifying  an  explicit  expiration  date  instead  of  the time-to-live might be more convenient for users since it's independent of the time it takes for a transaction to be included in a block.  ISSUEIDPREFIX-002  Mangrove Association (ADDMA) - MangroveOrder -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fCode Corrected:  The  expiration  date  is  now  absolute  and  no  longer  relative  to  the  time  the  transaction  is  added  to  the blockchain.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Forwarder.provisionOf Calculation Is", "body": " Wrong  ISSUEIDPREFIX-012  As its natspec suggests Forwarder.provisionOf computes the amount of native tokens that can be redeemed  when  In MgvOfferMaking.retractOffer, the provision is calculated as follows:  offer.  However,   deprovisioning   given   true.   this   not   is   a   provision = 10 ** 9 * offerDetail.gasprice() //gasprice is 0 if offer was deprovisioned   * (offerDetail.gasreq() + offerDetail.offer_gasbase());  The important part to notice is that provision depends on offerDetail.offer_gasbase().  This is not the same for Forwarder.provisionOf where the provision is calculated as follows:  provision = offerDetail.gasprice() * 10 ** 9 * (local.offer_gasbase() + offerDetail.gasreq());  Here,  offerDetail.offer_gasbase().  provision   the   depends   on   local.offer_gasbase()   instead   of  Code Corrected:  The provision is now calculated using the offerDetail.offer_gasbase().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Array Length Mismatch", "body": "  The batched functions of the TransferLib can take arrays differently sized arrays. The desired execution in that case is unclear.  ISSUEIDPREFIX-001    The batched functions have been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Explicit Variable Visibility", "body": "  Mangrove Association (ADDMA) - MangroveOrder -   18  ISSUEIDPREFIX-004  DesignLowVersion1CodeCorrectedInformationalVersion4CodeCorrectedInformationalVersion1CodeCorrected                    \fAccessControlled has now a state variable _admin. However, it does not have explicit visibility defined. Note that this does not lead to any double getters since its by default internal. However, specifying explicit visibility may make code clearer.  Note that this is the case also for boundMakerContracts in AbstractRouter.    The code has explicit variable visibility now.  Mangrove Association (ADDMA) - MangroveOrder -   19  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Updating Approvals on Order Update", "body": "  A  user  can  update  their  orders  by  using  Forwarder.updateOffer.  It  is  important  for  users  to remember  that,  in  case  the  makerExecute  hook  to  their  order  fails,  they  will  have  to  reimburse  the taker. A reason for an order to fail is that there is not enough allowance given to the router to transfer funds from the maker's reserve to MangroveOrder contract. This is highly likely to happen after a user updates their offer by having it give more funds to the taker.  Mangrove Association (ADDMA) - MangroveOrder -   20  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Missing Min/Max Checks in ChainlinkOracle", "body": "  CS-EULPO-002  Chainlink aggregators have a minimum and maximum price defined. Any updates to the aggregators are rejected  if  these  thresholds  are  crossed.  In  most  cases,  this  is  not  problematic.  There  are,  however, certain  feeds  for  which  the  thresholds  are  defined  in  a  way  that  could  be  reached  in  certain  market events.  If the thresholds are crossed, the oracle prices won't update anymore. Since most Chainlink feeds are configured  with  rather  high  heartbeats  (e.g.,  24  hours),  it  takes  some  time  until  this  can  be  reliably detected by the ChainlinkOracle.  In the rare case this happens, it can have catastrophic effects on any protocol relying on the oracle, as stale prices will be reported.  Risk accepted:  Euler accepts the risk with the following statement:  We have decided not to include minAnswer and maxAnswer bounds to ChainlinkOracle. It is unclear  whether  we  can  expect  these  value  to  change  so  we  cannot  safely  store  them  as immutable variables. We expect ChainlinkOracle to be a very hot contract for markets and we believe the gas cost increase associated with runtime fetching of minAnswer and maxAnswer is not worth  it.  Ultimately  we  believe  these  values  are  chosen  responsibly  by  the  Chainlink  team.  This opinion is evidently shared by the largest users of Chainlink, which also do not have minAnswer and maxAnswer checks.  Euler - Price Oracles -   11  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedSecurityLowVersion1RiskAccepted             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   RedstoneCoreOracle Update With Stale Data   -Severity Findings   RedstoneCoreOracle DoS   Informational Findings   Typographical Error    RedstoneCoreOracle Forced Package Ordering    Missing Uniswap Oracle Documentation   0  0  1  1  3  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   RedstoneCoreOracle Update With Stale Data", "body": "  CS-EULPO-001  RedstoneCoreOracle  implements  the  PrimaryProdDataServiceConsumerBase  of  Redstone's SDK. This contract manages the validation of submitted calldata to the updatePrice() function. Such calldata contains a minimum of three different packages that each contain a price for the requested feed, as well as a timestamp (and the signature of the associated Redstone signer). Timestamps, after being extracted  from  calldata,  are  handled  in  the  function  validateTimestamp()  which  checks  their staleness. This is done individually for each submitted package.  RedstoneCoreOracle  overrides  the  validateTimestamp()  function  to  add  custom  staleness checks as well as a storage write of the given timestamp. To avoid redundant writes, the function returns early when a given timestamp is equal to the timestamp that has been previously written to storage:  function _validateTimestamp(uint256 timestampMillis) internal {     // The `updatePriceContext` guard effectively blocks external / direct calls to `validateTimestamp`.     Cache memory _cache = cache;     if (_cache.updatePriceContext != FLAG_UPDATE_PRICE_ENTERED) revert Errors.PriceOracle_InvalidAnswer();      uint256 timestamp = timestampMillis / 1000;     // Avoid redundant storage writes as `validateTimestamp` is called for every signer in the payload (3 times).     // The inherited Redstone consumer contract enforces that the timestamps are the same for all signers.     if (timestamp == _cache.priceTimestamp) return;      if (block.timestamp > timestamp) {         // Verify that the timestamp is not too stale.         uint256 priceStaleness = block.timestamp - timestamp;          if (priceStaleness > maxStaleness) {             revert Errors.PriceOracle_TooStale(priceStaleness, maxStaleness);         }  Euler - Price Oracles -   12  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCorrectnessMediumVersion1CodeCorrected        \f    } else if (timestamp - block.timestamp > RedstoneDefaultsLib.DEFAULT_MAX_DATA_TIMESTAMP_AHEAD_SECONDS) {         // Verify that the timestamp is not too long in the future (1 min). Redstone SDK explicitly allows this.         revert Errors.PriceOracle_InvalidAnswer();     }      // Enforce that cached price updates have a monotonically increasing timestamp.     if (timestamp < _cache.priceTimestamp) revert Errors.PriceOracle_InvalidAnswer();     cache.priceTimestamp = uint48(timestamp); }  This  is  done  under  the  assumption  that  the  timestamps  on  all  submitted  packages  are  equal. PrimaryProdDataServiceConsumerBase,  however,  never  enforces  this,  leading  to  the  issue depicted by the following example:  1. updatePrice() is called with three packages containing the prices [1, 1, 1] and timestamps [1, 1,  1].  2. The cached price is set to 1, as is the cached timestamp.  3. After  some  time,  the  price  of  the  respective  asset  has  changed  a  lot.  A  new  price  update  would  contain three packages with the prices [2, 2, 2] and timestamps [2,2, 2].  4. A malicious user crafts calldata that contains two of the old prices and timestamps ([1, 1, 2] and [1,  1, 2]) and calls updatePrice() with it.  5. validateTimestamp(),  for  the  first  two  packages,  returns  early  because  the  timestamps  are equal to the old timestamp in the cache. For the third package, it performs staleness checks and writes the new timestamp 2 into the cache.  6. updatePrice() writes the median of the received prices ([1, 1, 2] -> 1) into the cache. The oracle  now contains the price 1 with a timestamp of 2.  7. The  user  can  now  call  getQuote()  to  retrieve  the  price  without  revert  as  the  price  is  not  stale  (assuming that the price would be stale with timestamp 1).  The longer the oracle has not been updated, the more severe this problem becomes, as the price can always be kept at the price of the last update while the timestamp is reset to a current one. The fact that prices are aggregated by median value exacerbate this problem further.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   RedstoneCoreOracle DoS", "body": "  RedstoneCoreOracle.updatePrice()  enforces  monotonically  increasing  timestamps.  If  a  user updates the price with a timestamp that is lower than the one stored in the cache, the transaction reverts.  Since price signatures are published rapidly, it is possible that two users submit price updates at roughly the  same  time  but  with  different  timestamps.  If  the  transaction  of  the  user  with  the  lower  timestamp  is executed last, it will revert. Users should be aware that even if their price update transaction fails, there may still be a valid price to read afterwards.  Consider the following example:  CS-EULPO-008  1. User Alice submits a multicall transaction that updates the price and then reads it.  2. Alice is frontrun by someone else who updates the price to an even newer value.  3. The updatePrice() call reverts.  4. As  the  transaction  has  reverted,  the  rest  of  Alice's  transaction  will  also  revert  even  though  it  could have used the more up-to-date price.  Protocol developers should consider catching reverts in price updates when executing them as part of a multicall. Otherwise unnecessary reverts could result in Denial of Service.  Euler - Price Oracles -   13  DesignLowVersion1CodeCorrected        \f  RedstoneCoreOracle.updatePrice()  no  longer  reverts  when  a  price  update  with  an  outdated timestamp occurs. It is worth to note that this now means that users' transactions might now be executed with a different price than anticipated.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Missing Uniswap Oracle Documentation", "body": "  The  documentation  of  UniswapV3Oracle  contains  a  warning  detailing  in  which  circumstances  the oracle can be used (mostly) safely. Among other things, the cardinality of the observation buffer and the need for enough liquidity is mentioned. While this is correct, it could be further extended:  CS-EULPO-004  1. The  buffer  must  not  only  have  enough  cardinality,  but  there  also  must  have  been  enough  observations since it was extended to fully fill it.  2. Not only the liquidity at the current time is relevant, but also the liquidity while the buffer was  filled with data.  Specification changed:  UniswapV3Oracle  now  contains  appropriate  documentation  to  make  users  aware  of  the  additional requirements.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   RedstoneCoreOracle Forced Package", "body": " Ordering  CS-EULPO-005  RedstoneCoreOracle.validateTimestamp()   Since  increasing timestamps, packages with differing timestamps must be ordered in the calldata so that the call does not revert.  enforces  monotonically   This  is  different  to  the  regular  Redstone  SDK  implementation  and  may  lead  to  incompatibilities. Developers should be aware of this restriction.  RedstoneCoreOracle now requires timestamps of all data packages to be equal.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Typographical Error", "body": "  The comments of RedstoneCoreOracle.updatePrice() contain the following line which is missing a comma: \"During execution the context flag is set to `FLAG_UPDATE_PRICE_ENTERED`.\".  CS-EULPO-007  Euler - Price Oracles -   14  InformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f  The comment has been removed as the respective functionality is no longer present.  Euler - Price Oracles -   15  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   L2 Sequencer Considerations", "body": "  CS-EULPO-003  The contracts will initially be deployed to Ethereum mainnet only but should eventually work on any L2.  Before deploying to L2s, consider that the L2 sequencer can have extended downtime.  The Chainlink docs suggest using the SequencerUptimeFeed to detect this and not consume any prices until the sequencer is back up.  Also, the Uniswap TWAP will have a high weight for the price that was present during the downtime (as it persisted  for  a  long  time).  This  could  be  a  problem  if  the  price  was  an  outlier  or  if  the  price  when  the sequencer recovers is significantly different from when it went down.  Additionally,  block.timestamp  may  have  slightly  different  behavior  on  other  chains.  This  should  be considered before deploying.  Acknowledged:  Euler acknowledges the risk associated with the mentioned markets.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Redundant Chronicle Adapter", "body": "  The ChronicleOracle communicates with Chronicle price feeds using the function readWithAge(). Chronicle,  however,  also  exposes  the  function  latestRoundData()  that  is  equivalent  to  Chainlink's feed  interface.  Since  only  positive  prices  are  used,  the  ChainlinkOracle  should  therefore  be compatible with Chronicle as well.  CS-EULPO-006  Acknowledged:  Euler acknowledges that the contract is redundant.  Euler - Price Oracles -   16  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Compounding Errors in CrossAdapter", "body": "  CrossAdapter  allows  chaining  oracle  calls  in  order  to  get  price  quotes  for  pairs  with  no  direct  feed available.  Users  should  be  aware  that  using  such  an  oracle  might  increase  the  margin  of  error  in comparison to using a single oracle. This is especially relevant for pull-based oracles that give users the ability to \"choose\" their price in a narrow margin, but also applies to push-based oracles.  Consider the following example:   A CrossAdapter chains two instances of PythOracle   Both  oracles  have  an  outdated  price  (that  is  not  stale  yet),  which  is  0.5%  different  from  the  newest price   Usually, a user would be able to choose between the old price and the new price, which gives  them a 0.5% choice.  In this case, the user can make this choice twice, so in the worst case, they may be able to use a price that is ~1% different from the current price.  Any errors in chained oracles will be accumulated when using CrossAdapter. The resulting wider error margin should be included in risk assessments by consumers.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Lido Oracle Staleness", "body": "  The  LidoOracle  converts  stETH  to  wstETH  and  vice  versa.  This  is  done  by  calling  the  functions getSharesByPooledEth() and getPooledEthByShares() respectively on the stETH contract.  The pooled ETH value in Lido is only updated periodically.  There are two main cases where the ETH per share will change:  1. Staking rewards accrue (small increase)  2. Validators are slashed (variable size decrease)  Both of these changes are possible to predict before they are reflected on-chain. Someone could frontrun the update and use the stale price, with knowledge of what the future price will be.  Protocols using the LidoOracle must take this into account and should especially consider the slashing case. A slashing event will only be reflected by LidoOracle long after it has happened.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   No Price Quote in Vault Tokens", "body": "  Euler - Price Oracles -   17  NoteVersion1NoteVersion1NoteVersion1           \fEulerRouter.resolveOracle()  allows  to  find  the  configured  oracle  for  a  given  asset  pair.  If  the base  token  is  the  token  of  an  ERC-4626  vault  and  the  vault  has  been  configured  in  the  router,  the corresponding oracle can be resolved by first converting the vault's token to the corresponding amount of the vault's asset and then solving for an oracle of the vault's asset.  Note that this is not supported for the quote token. Prices cannot be quoted in vault tokens even if the corresponding vault is be configured in the router.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Oracle Consumers Must Handle Reverts", "body": "  Most  of  the  implemented  oracle  adapters  have  certain  conditions  that  can  cause  reverts.  One  reason could be a price becoming stale.  Oracle consumers must be aware of this and should mitigate the impact of a reverting oracle as much as possible. Depending on design, a revert in the oracle may cause an unnecessary denial of service to the whole system.  For example, it should be considered if it is possible to allow withdrawals even when an oracle is down.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.5   Oracle Manipulation on FIFO L2s", "body": "  Price oracles must be robust and manipulation-resistant. It must be expensive to manipulate the markets which are used as price sources.  Usually,  the  factor  that  makes  price  manipulation  expensive  is  arbitrage.  If  a  manipulator  pushes  the price of an asset too high or too low, arbitrageurs will see this and make a profit by moving the price back to the \"true price\". Any profit made by arbitrageurs will be a loss to the manipulator.  This \"arbitrage assumption\" breaks down in two cases:  1. All markets for the token are manipulated simultaneously, so it is difficult to determine the \"true  price\". There is no other market to arbitrage against.  2. Arbitrageurs  are  not  able  to  see  the  manipulated  price  quickly  enough,  so  they  cannot  take  advantage of it.  Attacks that target condition 2. are known as \"Multi-block MEV\" attacks. The idea is that a manipulator could control the order of transactions in a block, which allows the following:  In block n, the manipulator sends a transaction (through a private mempool like Flashbots) that manipulates the price of an asset.  In block n+1, the manipulator ensures that the first transaction in the block is one where they revert the price back to the original value.  As a result, arbitrageurs will have no chance of reacting to the manipulation, as it will already be over by the time they can get a transaction included in the block. However, if there is an Oracle that reads the price at the beginning of block n+1, it will see the manipulated price.  This  attack  is  well-known  on  Ethereum,  but  is  generally  deemed  expensive  to  execute,  as  it  requires being  or  having  an  agreement  with  the  ETH  staker  that  is  chosen  to  propose  block  n+1.  If  the  attack should  be  repeated  multiple  times,  it  requires  being  chosen  as  block  proposer  multiple  times  within  a short time frame, which requires a significant amount of ETH staked.  Euler - Price Oracles -   18  NoteVersion1NoteVersion1          \fHowever, on L2s, block production works differently. Instead of a different proposer being chosen in each block, there is typically a single sequencer that decides on a block ordering policy. One commonly used policy  used  by  chains  such  as  Arbitrum,  Optimism  and  Base  is  \"FIFO\"  (First  In,  First  Out),  where transactions are included in the order they were received.  In FIFO ordering, the order of transactions is determined by time, not by the price a user is willing to pay. This can be taken advantage of to fulfill condition 2. above, without needing to be a block producer.  The FIFO attack looks as follows:  1. The manipulator experiments to figure out their latency to the sequencer (and ideally minimizes  it).  2. The  manipulator  sends  a  manipulation  transaction  at  a  time  such  that  it  will  arrive  at  the  sequencer towards the end of the period in which it is building block n.  3. The manipulator sends a second transaction so that it reaches the sequencer at the beginning  of the period in which it is building block n+1.  Arbitrageurs are only able to see the manipulated price once block n is published by the sequencer. By that  time,  the  manipulator  has  already  sent  the  second  transaction  that  reverts  the  price  back  to  the original value. As time is the only relevant factor, it is impossible for a transaction that is created later to be included in the block first (unless the arbitrageur has significantly lower latency to the sequencer).  The only cost to the attacker is the trading fees paid. As the attack cannot use a flashloan, they must also have sufficient capital available to manipulate the price by the percentage they aim for. The attack can be repeated as many times as the attacker wants, although repeated attacks could be speculatively frontrun by  arbitrageurs  if  they  detect  a  pattern.  Repeated  attacks  can  be  used  to  circumvent  outlier-detection mechanisms and TWAPs.  A policy that modifies transaction ordering to be based on a payment in addition to timing would make the attack significantly more expensive. For example, \"Arbitrum time-boost\" has been proposed, but not yet implemented. See Time Boost Medium post.  Note  that  Multi-block  MEV  attacks  have  historically  been  considered  mostly  in  the  context  of  TWAP manipulation. However, if there is an off-chain oracle, such as ChainLink, that uses an on-chain market as a primary price source, the attack also applies there. In fact, the effect will be much larger, as off-chain oracles typically do not use a time-weighted average. Instead, they read the spot price at a single point in time.  As  a  result,  executing  the  attack  once  could  lead  to  a  heavily  manipulated  price.  Some  off-chain oracles  may  implement  outlier-detection  to  mitigate  this,  but  this  is  often  not  clearly  documented,  if  it exists at all. If outlier-detection exists, the attack could be executed multiple times.  In  summary,  Multi-block  MEV  attacks  are  likely  much  more  realistic  to  execute  on  FIFO  L2s  than  on Ethereum, as they are possible without needing to be a block producer. They can affect on-chain TWAPs as well as any off-chain oracles that use L2 on-chain markets as a primary price source. This must be considered when deciding which assets have an oracle that is robust enough to allow lending.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.6   Potentially Incorrect Default Decimals", "body": "  BaseAdapter (and therefore all oracle adapters in the version of the protocol at the time of this report) fetches decimals of the underlying base and quote assets by using the function _getDecimals():  function _getDecimals(address asset) internal view returns (uint8) {     (bool success, bytes memory data) = asset.staticcall(abi.encodeCall(IERC20.decimals, ()));     return success && data.length == 32 ? abi.decode(data, (uint8)) : 18; }  Euler - Price Oracles -   19  NoteVersion1    \fThe  function  attempts  to  fetch  the  decimals  of  a  given  token  by  calling  the  associated  decimals() function. If this call fails, it instead uses a default of 18 decimals.  This  behavior  is  meant  to  support,  among  others,  asset  types  that  are  not  smart  contracts  (e.g.,  the native  asset  address  0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE).  There  is,  however,  a certain caveat that should be considered before deploying an oracle with such addresses:  Deployment  of  an  oracle  before  the  actual  ERC-20  asset  is  deployed  with  CREATE2  can  result  in wrong decimals.  Users should avoid using oracle adapters that are misconfigured in this fashion.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.7   Pyth Maximum Confidence", "body": "  The  PythOracle  allows  to  set  a  maxConfWidth  interval  that  defines  the  maximum  confidence  the oracle is allowed to have before reverting. Note that this interval should be initialized with a value that also  covers  possibly  wider  margins  than  can  be  usually  observed.  This  is  due  to  the  fact  that  the confidence  interval  naturally  widens  in  more  volatile  market  conditions,  which  are  exactly  the  market conditions  in  which  liquidations  should  occur  in  a  timely  manner.  If  the  threshold  prevents  swift liquidations in such a case, it could be counter-productive.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.8   RedstoneCoreOracle Hot-Swap", "body": "  RedstoneCoreOracle  contains  constant  signer  addresses.  Should  there  be  any  complications  with these signer addresses, the oracle has to be swapped for a new contract that contains an updated set of signers.  Since  the  contract  is  immutable  (i.e.,  not  deployed  behind  a  proxy)  it  is  important  that  any projects using it implement functionality that allows replacement of the oracle.  Euler - Price Oracles -   20  NoteVersion1NoteVersion1        \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Unkill Function Allows Claiming After Closing", "body": "  Function unKill(), only callable by the PlatformFactory contract owner, allows to reset isKilled to  false.  If  a  bribe  manager  calls  closeBribe()  while  the  Platform  is  killed,  and  the  platform  is  then unkilled, the bribe becomes claimable again, even though the left over funds have been transferred by closeBribe(). Users can claim their bribes and the funds will be taken from other bribes sharing the same tokens.  Risk accepted  StakeDao accepts the risk but already fixed the issue by removing the unkill function in the latest code version that was not included in the audit.  StakeDao - Bribe Platform -   9  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedLowAcknowledgedCodePartiallyCorrectedRiskAcceptedRiskAcceptedAcknowledgedAcknowledgedRiskAcceptedSecurityMediumVersion2RiskAccepted              \f5.2   Bribe Manager Can Deny Bribe by Decreasing maxRewardPerVote  The  bribe  manager  can  use  increaseBribeDuration()  to  queue  a  decrease  of maxRewardPerVote to close to 0 just before the start of a claiming period, to rug the expected bribe of users who have already voted.  Risk accepted  StakeDao states that they accept the risk.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   GaugeController Not Checkpointed Before", "body": " First Period Update  The GaugeController is not checkpointed in _updateRewardPerToken(). If no vote has been cast on the gauge before the first period, _getAdjustedBias() will return 0 instead of the actual value, or might  revert  if  blacklisted  users  cause  an  underflow  to  happen.  This  can  cause  the  reward  to  become unclaimable for some voters.  Risk accepted  StakeDao states:  While it would cause an issue for the first period with old vote users not being able to claim their rewards, it would be solved by the next period with the rolling over.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Repeated Addresses in Bribe Blacklist Cause", "body": " Total Bias Under Estimation  in   the  blacklist,   Newly  created  bribes  can  have  repeated  addresses  in  the  blacklist.  If  an  address  is  present  multiple times  in _getAdjustedBias(),  and  the  function  might  return  a  value  smaller  than  the  cumulative  bias  of potential  claimers.  rewardPerToken  can  therefore  be  manipulated  upward  by  inserting  repeated addresses in the blacklist.  its  bias  will  be  deducted  multiple   total  bias   times   from   the   Risk accepted  StakeDao states that they accept the risk.  StakeDao - Bribe Platform -   10  SecurityMediumVersion1RiskAcceptedCorrectnessMediumVersion1RiskAcceptedSecurityMediumVersion1RiskAccepted                        \f5.5   Error Messages and Event Usage  1. In  PlatformFactory,  StakeDao  might  consider  adding  an  event  to  the  state  change  in  setFeeCollector.  2. In Platform, the error messages INVALID_GAUGE is not used.  Acknowldeged  StakeDao acknowledges the issue. No actions are taken.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Gas Optimizations", "body": "  1. Double external call to vote_user_slopes in _claim(), at line 385 - 387  2. The  function  getActivePeriod  is  redundant  since  activePeriod  is  already  public  and  will  implicitly define an external getter  3. _updateRewardPerToken  calls  getCurrentPeriod  which  was  in  both  execution  flows  called  right before in the parent function  4. getPeriodsLeft and getActivePeriodPerBribe copy the entire Bribe struct from storage to memory, but only use 2 of the fields from the struct. This causes unnecessary SLOAD operations to be performed, at a cost that scales linearly with the size of the blacklist.  Code partially corrected  getCurrentPeriod() is now only called once. The two other potential optimizations were not applied.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Incorrect User Bias Calculation", "body": "  The  internal  _getAddrBias()  function  returns  0  if  currentPeriod  +  _WEEK  >=  endLockTime. However, as long as endLockTime is bigger than currentPeriod the user has voting power. Indeed, in its time progression, a user bias will incorrectly go from slope * 3 * WEEK to slope * 2 * WEEK to 0 while skipping slope * 1 * WEEK.  Risk accepted  StakeDao is aware of the issue but decided to accept the risk and leave the code as it is.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.8   Missing Sanity Checks", "body": "  The following arguments are not checked or are insufficiently checked if they make sense:  StakeDao - Bribe Platform -   11  DesignLowVersion1AcknowledgedDesignLowVersion1CodePartiallyCorrectedCorrectnessLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                              \fIn  Platform.createBribe  the  variable  manager  (address  zero  check),  maxRewardPerVote (zero  check)  and  a  check  for  rewardPerPeriod  as  it  could  be  zero  after  the  division  with numberOfPeriods  In Platform.updateManager there is no sanity check for address zero  In Platform._claim() it is not checked that the bribe exists  In  PlatformFactory  setting  the  fee  collector  and  transferring  the  owner  are  not  checked  for address zero  Risk accepted  StakeDao states that they accept the risk.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.9   Naming Issues, NatSpec Missings, Incorrect", "body": " Comments, Typos  In Platform.sol:  1. line 104, missing @notice for Upgrade struct  2. line 126, incorrect grammar: Minimum duration a Bribe  3. line  158,  rewardPerToken  naming  is  ambiguous,  the  variable  value  is  better  understood  as  the  reward per vote not the reward per token.  4. line 254, Target bias for the gauge, incorrect NatSpec on parameter maxRewardPerVote  5. In createBribe() NatSpec, missing parameters upgradeable and manager.  6. line 503: comment says called once per Bribe, however the function is called multiple times  on the first period, but the condition is only true on first call.  7. line 640: _additionnalPeriods declaration contains a typo  8. getActivePeriod  and  getActivePeriodPerBribe  are  named  ambiguously,  they  do  very  different things but share almost the same name  Acknowldeged  StakeDao acknowledges the issue. No actions are taken.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.10   Unused Imports", "body": "  The contract PlatformFactory imports ERC20 but does not use it.  Acknowldeged  StakeDao acknowledges the issue. No actions are taken.  StakeDao - Bribe Platform -   12  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                    \f5.11   safeTransfer Functions Do Not Check Contract Existence  The safeTransfer and safeTransferFrom functions of solmate's safeTransferLib do not check that the token contract actually exists. If called with a token address that doesn't contain code, the calls will succeed  even  if  no  transfer  is  performed.  This  could  be  an  issue  when  a  token  will  be  deployed  at  a predictable address.  Risk accepted  StakeDao states that they accept the risk.  StakeDao - Bribe Platform -   13  SecurityLowVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Adjusted Bias Measured Possibly Too Late   -Severity Findings   Queued Upgrade Still Taken in Account After Closing Bribe   -Severity Findings   closeBribe Does Not Refund Tokens Added in Upgrade   -Severity Findings  1  1  1  0  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Adjusted Bias Measured Possibly Too Late", "body": "  The  amount  of  excluded  votes  belonging  to  the  users  in  the  blacklist  are  counted  by  the  internal function  _getAdjustedBias  for  the  recently  concluded  period  when  _updateBribePeriod()  is called. However, the period update only happens when users interact with the contract. Between the start of  the  new  voting  period  (timestamp  /  WEEK  *  WEEK)  and  the  time  _updateBribePeriod()  is called,  a  blacklist  user  can  cast  a  new  vote  on  the  gauge,  which  is  incorrectly  counted  by ``_getAdjustedBias() as belonging to the previous period.  rewardPerToken at period T is computed as  rewardPerToken(T) = rewardPerPeriod / (total_bias(T) - omitted_reward(T_blacklisted_last_vote))  So the periods of total_bias and omitted_reward might not match.  Since the bribe creator has full control on who to include in the blacklist and what gauge to set the bribe on, they can make rewardPerToken as high as they desire by making the denominator arbitrarily small that with  bribe.totalRewardAmount is not exceeded when distributing the reward, a dishonest bribe creator can use this bug to steal funds from other bribes.  control.  Since  _claim()   blacklisted   doesn't   check   user   they   that   a   Code corrected  A  check  has  been  added  so  that  subtracting  the  bias  of  a  blacklisted  user  is  only  performed  if  the blacklisted user has voted before the start of the period. Otherwise bias is not deducted and rewarded users get a bit less.  _lastVote = gaugeController.last_user_vote(_addressesBlacklisted[i], gauge); if (period > _lastVote) {     _bias = _getAddrBias(userSlope.slope, userSlope.end, period);     gaugeBias -= _bias; }  StakeDao - Bribe Platform -   14  CriticalCodeCorrectedHighCodeCorrectedMediumCodeCorrectedLowSecurityCriticalVersion1CodeCorrected        \fA  check  is  also  bribe.totalRewardAmount.  introduced  so   that   the  cumulative  bribe  payout  never  exceeds   the  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Queued Upgrade Still Taken in Account After", "body": " Closing Bribe  A queued upgrade for a bribe can still be taken in account after the manager has closed the bribe with closeBribe. If it is the case, then part of the following rewards distributed are stolen from other bribes.  Once  the  bribe  is  closed  by  the  manager,  claiming  again  will  update  the  bribe  and  reset  the endTimestamp in the future, without taking in account the totalRewardAmount - amountClaimed amount withdrew by the manager.  Using this attack to steal all the funds of the contract is possible with no risks, but would necessitate at least the same amount of tokens that the attacker wants to steal and being able to lock them for multiple weeks.  Code corrected  The upgrade is now deleted from the queue when closeBribe() is called.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   closeBribe Does Not Refund Tokens Added in", "body": " Upgrade  When a bribe is closed while an upgrade is queued, the unclaimed amount will be refunded to the bribe manager, but not the additional _increasedAmount added in the queued upgrade.  Code corrected  During  the  closing  of  a  bribe,  if  there  is  an  upgrade  in  the  queue,  instead  of  transferring  back total reward amount - amount claimed, the total amount after the upgrade is used.  StakeDao - Bribe Platform -   15  SecurityHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Interface Definitions", "body": "  To indicate a file is an interface, the naming convention is to prepend an I to the file name. The interface SmartWalletChecker and VeToken is for test purposes only. Interfaces used only for test purposes are usually separated into test folders.  The following interfaces are defined but not used:  GaugeController:  In  gauge_relative_weight_write,  get_total_weight, get_gauge_weight, add_type (only in tests), admin.  gauge_relative_weight,   add_gauge   tests),   (only   for   WEIGHT_VOTE_DELAY, gauge_relative_weight,  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   claimable() Might Return Incorrect Values", "body": "  Due  to  the  nature  of  view  functions  not  being  able  to  change  state,  the  claimable()  view  function doesn't  checkpoint  the  gauge  nor  it  updates  the  period,  so  the  value  it  returns  could  be  invalid.  This should be made clear in the natspec.  StakeDao - Bribe Platform -   16  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Computation of ynLSD.getTotalAssets() Is", "body": " Wrong  The computation of ynLSD.getTotalAssets() has two issues:  CS-YNPROTO-001  YieldNest - YieldNest Protocol -   15  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected            \f1. The  index  used  in  the  inner  loop  to  get  the  asset  should  be  j  instead  of  i.  The  current implementation will either revert with an out-of-bound exception, or double count some assets, by adding the balance of token X as what should be the balance of token Y and ignore others.  2. The current implementation of LSDStakingNode does not allow it to use its own token balance, as it  will  always  pull  tokens  from  ynLSD  and  deposit  that  exact  same  amount  to  EigenLayer.  This means  that  outside  of  a  call  to  depositAssetsToEigenlayer()  the  tokens  in  each  of  the LSDStakingNodes  are  locked.  If  counting  them  to  the  totalAssets  is  correct  and  intended should be re-evaluated.  Put together, the two issues result in a wrong price calculation of the ynLSD shares.    1. The correct index j is now used in the loop.  2. The  function  LSDStakingNode.recoverAssets()  has  been  added.  The  function  sends  the token  balance  from  an  LSDStakingNode  to  ynLSD,  allowing  them  to  be  unlocked  from  the LSDStakingNodes and counted towards the totalAssets.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   First Depositor Gets More Shares", "body": "  In  ynETH  and  ynLSD,  the  first  depositor  sees  its  shares  minted  1:1  to  its  deposited  amount.  If exchangeAdjustmentRate  >  0,  the  following  depositors  will  have  their  shares  minted  at  a  lower ratio, basically gifting some of their deposited amount to the first depositor.  Please provide a detailed description of why would exchangeAdjustmentRate be needed and what was the intention.  CS-YNPROTO-002    The variable exchangeAdjustmentRate has been removed from the codebase.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Withdrawals That Are Not Self-Claimed Break", "body": " the Accounting  EigenLayer allows claiming withdrawals on behalf of arbitrary addresses. The current implementation of the  YieldNest  Protocol  does  not  take  this  into  account,  and  thus  any  withdrawn  amounts  that  are  not claimed through StakingNode.claimDelayedWithdrawals() are locked in the StakingNode.  The implementation of StakingNode can be updated, but the shares of ynETH would be underpriced until the accounting is corrected.  CS-YNPROTO-003    YieldNest - YieldNest Protocol -   16  CorrectnessHighVersion1CodeCorrectedDesignHighVersion1CodeCorrected                \fThe  function  StakingNode.claimDelayedWithdrawals  has  been  removed  from  the  codebase.  A new  function  StakingNode.processWithdrawals  has  been  added,  this  function  expects  that  the withdrawals are claimed by a third party and will simply send the balance of the StakingNode contract to the stakingNodesManager for further processing as before. This new function can only be called by the admin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   ynLSD Is Vulnerable to Donation Attack", "body": "  It  is  possible  for  the  first  user  of  the  pool  to  steal  the  next  deposited  amount.  The  ynLSD  reads  the balances  of  its  supported  assets  to  compute  totalAssets  and  the  _convertToShares  function does  not  add  an  offset.  This  makes  the  contract  vulnerable  to  a  donation  attack,  where  the  first  user mints  1  share  and  front-runs  the  second  user  in  their  deposit  by  transferring  the  deposited  amount  to ynLSD in order to force a minting of 0 shares to the second user.  CS-YNPROTO-004  Example:  1. ynLSD  is  deployed  and  accepts  token  T.  The  oracle  is  assumed  to  return  the  following  price:  1 T = 1 ETH.  2. Alice  deposits  1  wei  of  T  and  receives  1  share  for  it.  Now  totalSupply  =  1  and  totalAssets = 1.  3. Bob sends a transaction to deposit a big amount X of T.  4. Alice  sees  the  transaction  in  the  mempool  and  front-runs  it  with  a  transfer  of  amount  X.  Now  totalSupply = 1 and totalAssets = 1 + X.  5. Bob's transaction gets executed and the number of shares he receives is   .  6. Alice has now 1 share valued at 1 + 2 * X, and Bob lost his deposit.  Note  that  if  exchangeAdjustmentRate  >  0,  this  attack  would  be  cheaper  to  conduct  as  the totalSupply() would be considered smaller than what it actually is. Then the amount needed to round down to zero the shares of the next deposit is also reduced.    Upon  deployment,  the  code  now  enforces  a  bootstrap  deposit  of  10  units  of  assets[0]  that  must  be worth  at  least  1  ether.  The  shares  of  this  initial  deposit  are  sent  to  a  trusted  address depositBootstrapper.  Moreover,  exchangeAdjustmentRate  has  been  removed  the codebase.  from   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Incorrect Balance Transfers With Rebasing", "body": " Tokens  Rebasing  tokens  like  stETH  might  transfer  less  than  expected.  This  might  get  problematic  when  a contract  expects  to  receive  the  amount  specified  in  the  transfer.  E.g.,  in  ynLSD.deposit  the safeTransferFrom  might  transfer  one  or  two  wei  less  than  specified  in  amount.  But  before,  all calculations and the share distribution were done on the assumption that amount would be later an asset  CS-YNPROTO-005  YieldNest - YieldNest Protocol -   17  DesignHighVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fof the contract. In consequence, this might break the invariant between the amount of shares and assets such that there are shares but no assets.    ynLSD   YieldNest   of In  LSDStakingNode.depositAssetsToEigenlayer  the  issue  was  fixed  by  querying  the  pre-  and post-balance  of  the  contract  before  calling  depositIntoStrategy.  We  rate  this  issue  as  fixed  but created a note to document the behavior for ynLSD.  accepted   case   risk.   the   the   In   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Partial Withdrawals Claims Will Fail", "body": "  CS-YNPROTO-006  function  StakingNode.claimDelayedWithdrawals  allows   the The  maxNumWithdrawals,  but  totalClaimable  will  always  be  computed  as  if  maxNumWithdrawals was set to type(uint256).max. If the caller does not want to claim all the claimable withdrawals, the condition totalClaimable > claimedAmount will be evaluated to true and the function will revert.  to  specify   the  caller     The  function  StakingNode.claimDelayedWithdrawals  has  been  removed  from  the  codebase.  A new  function  StakingNode.processWithdrawals  has  been  added,  this  function  expects  that  the withdrawals are claimed by a third party and will simply send the balance of the StakingNode contract to the stakingNodesManager for further processing as before. This new function can only be called by the admin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Processing of Withdrawals Can Be DOSed", "body": "  The  function  StakingNode.processWithdrawals()  expects  a  precise  amount  of  ETH  as  its balance, if it differs from this amount the call will revert. The contract assumes it can only receive ETH from  the  DelayedWithdrawalRouter,  but  it  is  possible  to  force  send  ETH  to  the  contract  with selfdestruct.  CS-YNPROTO-021    function  StakingNode.processWithdrawals()  has  been  updated  such   The  that  only expectedETHBalance is processed. The difference between the balance and expectedETHBalance can be processed in another transaction.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   Discrepancy in the Value Check for maxAge", "body": "  CS-YNPROTO-007  YieldNest - YieldNest Protocol -   18  DesignMediumVersion1CodeCorrectedSecurityLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                        \fIn YieldNestOracle, the value of maxAge is required to be > 0 in setAssetPriceFeed, but no such check is done in the constructor.    The value of maxAge is now checked during construction of YieldNestOracle and redundancies have been resolved by reusing the code that was present in setAssetPriceFeed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   Ignored Return Values", "body": "  The following calls ignore the returned value:   LSDStakingNode.depositAssetsToEigenlayer  does  not  check   the   return  value  by  asset.approve   ynLSD.retrieveAsset does not check the return value from IERC20(asset).transfer  CS-YNPROTO-008    OpenZeppelin   The  LSDStakingNode.depositAssetsToEigenlayer  ynLSD.retrieveAsset (safeTransfer).  SafeERC20   library   is   used   for   ERC20   (forceApprove)   interactions  and   in in  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.10   Initializer Not Disabled", "body": "  Proxy  implementation  contracts  inheriting  OpenZeppelin's  Initializable  contract  should  call _disableInitializers  in  their  constructor  to  prevent  initialization  and  re-initialization  of  the implementation contract.  CS-YNPROTO-009    All contracts inheriting OpenZeppelin's Initializable contract now call _disableInitializers in their constructor.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.11   Oracle Price Sanity Check", "body": "  In  YieldNestOracle.getLatestPrice  the  price  returned  by  the  oracle  is  not  further  checked  if  it might be, e.g., zero.  CS-YNPROTO-010    YieldNest - YieldNest Protocol -   19  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe function has been updated such that the call reverts if price <= 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.12   Redundant Functionality", "body": "  The  functions  ynBase.pauseWhiteList  and  ynBase.isAddressWhitelisted  have  the  same logic.  CS-YNPROTO-011    The function isAddressWhitelisted was removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.13   Uninitialized Reentrancy Guard", "body": "  The  StakingNode  contract  __ReentrancyGuard_init() in initialize.  inherits  ReentrancyGuardUpgradeable.  But  does  not  call  CS-YNPROTO-012    The initialize function has been updated to call __ReentrancyGuard_init().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.14   Unused Code", "body": "  CS-YNPROTO-013  Some parts of the codebase are never used. To ease the comprehension of the code, it is good practice to keep it in its minimal form. Here is a non-exhaustive list of unused code:  1. the   errors   MinimumStakeBoundNotSatisfied,   StakeBelowMinimumynETHAmount,  DepositAllocationUnbalanced in StakingNodesManager  2. the errors MinimumStakeBoundNotSatisfied, StakeBelowMinimumynETHAmount in ynETH  3. the  errors  error  InvalidConfiguration,  error  NotOracle  and  error  Paused  in  RewardsDistributor  4. the errors StrategyIndexMismatch and WithdrawalAmountTooLow in StakingNode  5. the   storage   variable  pendingWithdrawnValidatorPrincipal   and   the   constant  GWEI_TO_WEI in StakingNode  6. the storage variable allocatedETHForDeposits in ynETH  7. the storage variables maxBatchDepositSize, stakeAmount in StakingNodesManager  8. the constant BASIS_POINTS_DENOMINATOR in ynBase  9. the  event  FeeReceiverSet  in  the  interface  definition  of  RewardsDistributorEvents  in  RewardsDistributor.sol  YieldNest - YieldNest Protocol -   20  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f10. the  events  WithdrawalStarted  and  RewardsProcessed  in  the  interface  definition  of  StakingNodeEvents in StakingNode.sol  11. the interfaces IOracle and IEigenLayerBeaconOracle  :  1. the error ValueOutOfBounds in ynETH    All the listed issues have been resolved.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.15   Complete Events", "body": "  We assume YieldNest checked when to emit events. Without clear specification on when events shall be emitted,  we  cannot  verify  if  the  events  are  emitted  correctly.  We  encourage  YieldNest  to  review  if  all relevant  state  changes  emit  events  as  intended  (e.g.,  RewardsDistributor.processRewards, ynBase._updatePauseWhitelist).  The  above  also  applies  to  indexing  events.  Most  events  index  relevant  fields  but  some  don't.  E.g., RewardsDistributorEvents.FeeReceiverSet.  CS-YNPROTO-014  Core corrected:  Events have been added throughout the codebase where important state changes are made.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.16   Incorrect Natspec", "body": "  The  natspec  of  StakingNodesManager.validateDepositDataAllocation  claims  the  function does:  /** * @notice Validates the allocation of deposit data across nodes to ensure the distribution does not increase the disparity in balances. * @dev This function checks if the proposed allocation of deposits (represented by `_depositData`) across the nodes would lead to a more * equitable distribution of validator stakes. It calculates the current and new average balances of nodes, and ensures that for each node, * the absolute difference between its balance and the average balance does not increase as a result of the new deposits * @param newValidators An array of `ValidatorData` structures representing the validator stakes to be allocated across the nodes. */  CS-YNPROTO-017  The implementation deviates from the description. The only check done is nodeId >= nodes.length for each node in newValidators.    The function name and natspec have been changed to reflect the implementation.  YieldNest - YieldNest Protocol -   21  Version2InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7.17   Missing Natspec Param Definition  The  natspec  definition  for  the  second  parameter  withdrawnValidatorPrincipal  of  the  function StakingNode.claimDelayedWithdrawals is missing.  CS-YNPROTO-018    The function StakingNode.claimDelayedWithdrawals was removed from the codebase.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.18   Overcomplicated Expression", "body": "  Expressions like assetDecimals < 18 || assetDecimals > 18 in ynLSD.convertToETH can be replaced by simpler variants, they add unnecessary complexity and should be avoided.  CS-YNPROTO-019    The expression has been simplified to assetDecimals != 18.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.19   Remaining Todos", "body": "  In  StakingNodesManager.isStakingNodesAdmin  we  // TODO: define specific admin.  CS-YNPROTO-020  found  a   left  over   to  do  comment    The todo was removed from the code.  YieldNest - YieldNest Protocol -   22  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Gas Optimizations", "body": "  We  highlight  gas  inefficiencies  when  we  see  them  but  highly  encourage  YieldNest  to  check  for  more inefficiencies as we did find quite a lot and expect more to be present. The following list are examples we found:  1. In the function LSDStakingNode.depositAssetsToEigenlayer, asset can be used in place  of assets[i].  CS-YNPROTO-015  2. In   the   function   LSDStakingNode.depositAssetsToEigenlayer,   the   address(strategy)  ==  address(0)  ynLSD.retrieveAsset().  is   redundant  with   the  one   3. The substration in the function ynETH.withdrawETH() can be unchecked.  implemented   check in  4. In the function ynETH.depositETH(), msg.value can be used in place of assets, as its gas  cost is only 2.  5. In   the   functions  StakingNodesManager.initializeStakingNode(),  call  node.getInitializedVersion() but the returned value is never used.  ynLSD.initializeLSDStakingNode()  a   is   made   and to  6. When   the   and StakingNodesManager.initializeStakingNode() are used, nodes.length is read twice, passing the nodeId as a function argument can save an SLOAD.  ynLSD.initializeLSDStakingNode()   functions   7. In   the   call function  ynETH.processWithdrawnETH()  if withdrawnValidatorPrincipal > 0, if partial withdrawals are expected to be more common than full withdrawals.  StakingNodesManager.processWithdrawnETH(),   done   only   can   the   be   8. In  the  function  RewardsReceiver.initialize(),  the  admin  of  the  WITHDRAWER  is  explicitly  set to be DEFAULT_ADMIN, but this is the case by default.  9. In  ynLSD.createLSDStakingNode  the  state  variable  nodes.length  is  read  multiple  times  including in initializeLSDStakingNode where it could be passed as argument.  10. StakingNodesManager.validateDepositDataAllocation   the   state   variable  nodes.length is read multiple times and could be cached.  11. When looping over assets, the asset array's length should be cached. When using the storage  variable as bounded in i < assets.length it will be read multiple times.  1. In  ynLSD.getTotalAssets()  the  state  variable  nodes.length  is  read  multiple  times  in  the  loop and could be cached to save SLOAD.  Code partially corrected:  YieldNest - YieldNest Protocol -   23  InformationalVersion1CodePartiallyCorrectedVersion3    \f1. Fixed.  2. Fixed.  3. No change.  4. The  cached  value  in  now  used  everywhere.  It  is  now  consistent  within  the  function,  but  not  gas-optimal.  5. Fixed. The value is used in the emitted event.  6. Fixed.  7. No change.  8. Fixed.  9. Fixed.  10. Fixed. Function name updated to StakingNodesManager.validateNodes.  11. Fixed.  1. Fixed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Incorrect Comments", "body": "  1. In  ynLSD._convertToShares  the  comment  was  copied  from  the  same  function  that  exists  in  ynETH and, hence, mentions deltaynETH instead of deltaynLSD.  CS-YNPROTO-016  2. In   ynLSD   states Retrieves a specified amount of an asset from the staking node. But actually, transfers the asset to the staking node (as @dev correctly describes).  retrieveAsset   explanation   incorrect.   the   of   is   It   Code partially corrected:  1. The comment has been corrected.  2. No change  YieldNest - YieldNest Protocol -   24  Version3InformationalVersion1CodePartiallyCorrected      \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "9.1   Slightly Deviating Balance to Share in Case of", "body": " Rebasing Tokens  Rebasing  tokens  like  stETH  might  transfer  less  than  expected.  This  might  get  problematic  when  a contract  expects  to  receive  the  amount  specified  in  the  transfer.  E.g.,  in  ynLSD.deposit  the safeTransferFrom  might  transfer  one  or  two  wei  less  than  specified  in  amount.  But  before,  all calculations  and  the  share  distribution  were  done  on  the  assumptions  that  amount  would  be  later  an asset of the contract. In consequence, this might break the invariant between the amount of shares and assets such that there are shares but no assets.  The  issue  was  rated  more  severe  in  Incorrect  balance  transfers  with  rebasing  tokens  and  fixed  for LSDStakingNode.depositAssetsToEigenlayer.  However,  in ynLSD.deposit but not considered severe enough to cause further issues.  is  still  present   the  behavior   YieldNest - YieldNest Protocol -   25  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Event Parameters Not Indexed", "body": "  The event ReferredBalanceIncreased emits the address of partnerId, vault and depositer. All three information might be relevant to later query specific deposits. Hence, it might be useful to index these parameters.    The updated event now indexes the parameters: partnerId, vault and depositer.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Missing Code Comments and Function", "body": " Descriptions  Even though the code base is simple and well structured, code comments as well as function description with parameter descriptions are part of good coding practice to help understanding the code. The current implementation lacks documentation and code comments.    The updated code contains specifications that describe the functions and their parameters.  Yearn Finance - Partner Tracker -   9  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.3   Missing Return Values  Both  external  functions  deposit  declare  a  return  value  of  type  uint256,  but  the  return  statement  is missing.    The  internal  function  _internalDeposit  is  modified  to  return  receivedShares,  which  is  then returned by both external functions deposit.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Unused Constant registry", "body": "  The constant registry is defined but not used in the current code base.    The unused constant has been removed from the updated code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Unused Imports", "body": "  The Math and Address libraries and the registry interface are imported but not used.  import \"@openzeppelin/contracts/math/Math.sol\"; import \"@openzeppelin/contracts/utils/Address.sol\"; import \"../interfaces/IYearnRegistry.sol\";    The unused imports have been removed from the updated code.  Yearn Finance - Partner Tracker -   10  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Contract Tracks Also Malicious Vaults and", "body": " Tokens  The input arguments for the vault to be deposited in and the token are provided by the user. Both can be malicious  contracts.  We  could  not  see  a  way  to  exploit  the  contract,  but  the  mapping  will  record everything  including  the  invalid/malicious  vaults.  Hence,  when  reading  the  mapping  the  correct  vaults needs to be carefully selected and invalid records neglected.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Outdated Compiler Version", "body": "  The compiler version is outdated (https://swcregistry.io/docs/SWC-102) and implicitly fixed in the brownie config file to version: 0.6.12. The contract has a floating pragma for the compiler version, although practically  there  is  no  newer  version  without  breaking  changes  (https://swcregistry.io/docs/SWC-103). This version has the following known bugs: https://docs.soliditylang.org/en/v0.6.12/bugs.html  This is just a note as we do not see any severe issue using this compiler with the current code.  Yearn Finance - Partner Tracker -   11  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Reentrancy to Circumvent Liquidation", "body": " Protection  When  a  borrow  is  no  longer  sufficiently  collateralized,  it  can  be  liquidated.  During  a  liquidation,  the function liquidateBorrowAllowed of the Comptroller is called to determine if the position can be liquidated.  This  check  basically  evaluates  whether  the  values  of  all  held  cTokens  times  their collateralRatio exceed the value of all borrowed assets. The function liquidateBorrowAllowed also determines whether the repaid amount does not exceed the closeFactor.  However, the following reentrancy attack is possible to circumvent the liquidation protection. We assume that the victim account V has two borrowed tokens A and B. Also, V has collateral deposits C and D and has just become liquidatable, due to a tiny shortfall. We call the respective cTokens cA, cB, cC, and cD. Lastly, A is contract with a callback, e.g. ERC777.  1. The  attacker  calls  liquidateBorrow  on  cA  with  collateral  cC.  liquidateBorrowAllowed  is evaluated by the comptroller and determines a small shortfall. Hence, the liquidation is allowed.  2. The token transferFrom of A is triggered and hence, the callback to the attacker is executed.  Compound - cToken -   10  SecurityDesignCorrectnessCriticalHighMediumAcknowledgedLowAcknowledgedAcknowledgedAcknowledgedRiskAcceptedAcknowledgedAcknowledgedSecurityMediumVersion1Acknowledged           \f1. As  part  of  the  callback,  the  attacker  calls  liquidateBorrow  on  cB  with  collateral  cD. liquidateBorrowAllowed is evaluated by the comptroller and determines a small shortfall (as no state changes have yet been performed). Hence, the liquidation is allowed.  2. The biggest possible amount of B tokens is repaid and cD tokens are received as reward. The  position of V is now safe again.  3. Despite the position being safe, the original liquidation continues and the biggest possible amount  of A tokens is liquidated to received cC as reward.  Please note that the attack also works against a single collateral, so if C == D. It also works with more than two borrowed tokens. In such cases more \"parallel\" liquidations are possible.  Acknowledged:  Compound has acknowledged the issue.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Deprecation Insufficiently Documented", "body": "  The deprecation of a cToken and its effects are insufficiently documented. The documentation says:  A user who has negative account liquidity is subject to liquidation  However,  liquidation  can  also  occur  once  a  cToken  has  been  deprecated.  As  users  aim  to  avoid liquidation, they should be made aware of this.  Acknowledged:  The Compound team has acknowledged this issue.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Extra Encoding and Decoding in", "body": " CErc20Delegator  The  CErc20Delegator  contract  will  be  used  as  a  proxy.  Hence,  it  generally  forwards  the  calls. However, it contains two ways of forwarding:  1. The generic forwarder using the fallback function  2. Explicit forwarders such as:  function borrow(uint borrowAmount) override external returns (uint) {     bytes memory data = delegateToImplementation(abi.encodeWithSignature(\"borrow(uint256)\", borrowAmount));     return abi.decode(data, (uint)); }  The explicit forwarders are less gas efficient as they perform extra decoding and encoding for inputs as well as decoding and encoding for outputs, which is not performed by the generic forwarder.  Acknowledged:  Compound - cToken -   11  CorrectnessLowVersion2AcknowledgedDesignLowVersion1Acknowledged                \fCompound  acknowledges  the  issue  but  claims  that  the  gas  savings  are  small  enough  to  not  be  worth fixing.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Extra Storage Operations", "body": "  Inside the function _acceptAdmin there is the following code:  // Store admin with value pendingAdmin admin = pendingAdmin;  // Clear the pending value pendingAdmin = address(0);  emit NewAdmin(oldAdmin, admin); emit NewPendingAdmin(oldPendingAdmin, pendingAdmin);  To emit the events, admin and pendingAdmin will be queried from storage which is unnecessary here. Hence, there is a certain (even though small due to EIP-2929) gas overhead.  Acknowledged:  Compound  acknowledges  the  small  gas  savings  but  deems  the  readability  of  the  code  to  be  more important.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   No Dynamic Bounds on Liquidation Incentive", "body": "  It  is  important  that  the  liquidation  incentive  is  sufficiently  high  in  order  to  provide  a  safe  protocol. However, the product of liquidation incentive and collateral factor also should not exceed 1. Otherwise, the protocol is sure to lose funds on liquidations.  Risk accepted:  Compound accepts the risk of possibly misconfiguring a protocol.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Reentrancy by Admin", "body": "  In  the  case  of  Compound,  the  admin  role  of  the  cTokens  is  held  by  the  governance.  Hence, admin-based  attacks  are  especially  unlikely.  However,  in  principle  the  admin  could  perform  certain reentrancy-based  or _setInterestModel. These functions do not have a reentrancy guard.  like  _setComptroller   functions   attacks   special   admin   using   In a general case, an admin could switch out the comptroller for the initial checks of a liquidation and then call _setComptroller while receiving a token-based callback. The corrected comptroller address would  satisfy  the  further  checks  during  seizing.  This  way  the  admin  of  one  market  could  attack  other markets.  Compound - cToken -   12  DesignLowVersion1AcknowledgedDesignLowVersion1RiskAcceptedSecurityLowVersion1Acknowledged                        \fAcknowledged:  This issue has been acknowledged.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Unnecessary Memory Copies", "body": "  In  some  parts  of  the  code  there  are  unnecessary  copy  operations  to  and  from  memory.  Consider  the following example:  function balanceOfUnderlying(address owner) override external returns (uint) {     Exp memory exchangeRate = Exp({mantissa: exchangeRateCurrent()});     return mul_ScalarTruncate(exchangeRate, accountTokens[owner]); }  The  exchangeRate  is  stored  in  memory  and  then  directly  afterwards  copied  back  onto  the  stack. However, as the gas overhead of memory operations is tiny, this is minor.  Acknowledged:  Compound  has  acknowledged  the  issue  but  decided  not  to  fix  it  at  this  time,  as  it  is  only  a  small  gas saving.  Compound - cToken -   13  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Anyone Can Disable TUSD Market   -Severity Findings  -Severity Findings  Incorrect Exchange Rates Due to Incorrect Accounting   Incorrect Return Value for mintFresh   -Severity Findings   Liquidation Incentive Has Imprecise Documentation   Ignored Return Values    Special Case Not Clearly Specified    Unclear Specification    Unnecessary Overflow Checks   1  0  2  5  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Anyone Can Disable TUSD Market", "body": "  The TrueUSD (TUSD) token has two addresses through which it can be called. Calling the transfer function on either address affects the balance of both addresses. Given that there is a Compound market for TUSD, it is important to note that anyone can disable this market by calling:  function sweepToken(EIP20NonStandardInterface token) override external {     require(address(token) != underlying, \"CErc20::sweepToken: can not sweep underlying token\");     uint256 balance = token.balanceOf(address(this));     token.transfer(admin, balance); }  Usually, this function is meant to collect stray tokens and send them back to the admin. However, in this case  anyone  can  call  this  with  the  second  address  of  TUSD  and  thereby  transfer  all  TUSD  inside  the market to the administrator.  The funds are not lost, as they reside with the administrator, but no more borrows or redemptions will be possible. However, this causes a sudden change in the exchange rate and the interest rate of the token, which are both calculated using the current balance of the contract.  The dropped exchange rate allows different attacks. Among other things, it allows:  liquidation of users who used cTUSD as collateral (if the collateral factor is bigger than 0)   borrowing TUSD, then executing the attack and paying back less TUSD   executing the attack, minting cTUSD, waiting for the exchange rate to be restored and redeeming  cTUSD for more TUSD than were used for minting  Compound - cToken -   14  CriticalCodeCorrectedHighMediumSpeci\ufb01cationChangedSpeci\ufb01cationChangedLowSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedSecurityCriticalVersion1CodeCorrected            \f  The sweepToken function can now only be called by the admin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Incorrect Exchange Rates Due to Incorrect", "body": " Accounting  Due  to  the  design  of  the  cToken  non-liquidatable  borrows  can  exist.  These  borrows  are  incorrectly accounted  leading  to  overly  high  exchange  rates,  which  can  have  different  consequences.  Please consider  the  following  example.  For  simplicity  of  the  calculation,  we  assume  rates  and  the  liquidation incentive to be zero. We also assume that the exchange rate is 1 cETH = 1 ETH.  1. User A deposits 1 ETH, to obtain 1 cETH. At this time 1 ETH is worth 2000 DAI.  2. User A borrows 1000 DAI.  3. The price of ETH drops a lot until it is 500 DAI. During this time user A is not liquidated (e.g., due to  high gas prices).  4. Now user B liquidates the DAI-borrow of user A.   User B pays 500 DAI.   The amount of seized collateral is computed as 1 cETH.   1 cETH is seized from user A.  5. As a result, user A now has the following status:   0 balance in cETH   500 borrowed DAI  6. Thereby,  user  A  has  a  non-liquidatable  borrow  as  any  liquidation  fails  in  the  following  line  of  seizeInternal due to an underflow:  accountTokens[borrower] = accountTokens[borrower] - seizeTokens;  7. This results in an incorrect exchange rate for cDAI. The 500 DAI borrowed by user A will never be repaid. However, they are still part of the totalBorrows of the accounting within cDAI. Hence, the calculated exchange rate is too large.  The  incorrect  exchange  rate  can  have  different  consequences.  One  example  (assuming  no  reserves) would be:   All borrowers (except for A) are repaying their loans.   All suppliers try to redeem their deposits. However, each supplier is receiving too much DAI for their  cDAI as the exchange rate is too large.  In the end the last supplier finds that there are 0 DAI inside the contract and still 500 DAI borrowed. As the last borrow is non-liquidatable and will never be paid back, the last supplier cannot redeem their cDAI.  Compound - cToken -   15  DesignMediumVersion2Speci\ufb01cationChanged         \fSpecification changed:  The Compound team will update the documentation to correctly reflect this behaviour.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Incorrect Return Value for mintFresh", "body": "  The  mintFresh  function  that  is  internally  responsible  of  minting  new  cTokens,  has  the  following specification regarding its return value:  * @return (uint) the actual mint amount.  At the end of the function, it says:  return actualMintAmount;  However, the actualMintAmount variable contains the amount of underlying tokens used for minting and not the amount of minted cTokens.  Specification changed:  The specification was changed to match the implementation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Liquidation Incentive Has Imprecise", "body": " Documentation  The documentation for the liquidation incentive says:  The  additional  collateral  given  to  liquidators  as  an  incentive  to  perform  liquidation  of  underwater accounts.  For  example,  if  the  liquidation  incentive  is  1.1,  liquidators  receive  an  extra  10%  of  the borrowers collateral for every unit they close.  this   However,  function liquidateCalculateSeizeTokens will calculate this amount with the liquidation incentive included, but in the function seizeInternal the protocol's share is deducted:  not  match   functionality   code.   does   The   the   the   of   uint protocolSeizeTokens = mul_(seizeTokens, Exp({mantissa: protocolSeizeShareMantissa})); uint liquidatorSeizeTokens = seizeTokens - protocolSeizeTokens;  Hence, liquidators receive less than 10% extra.  Specification changed:  The Compound team will update the protocol documentation to describe this behaviour more precisely.  Compound - cToken -   16  CorrectnessMediumVersion1Speci\ufb01cationChangedCorrectnessLowVersion2Speci\ufb01cationChanged                  \f6.5   Ignored Return Values  The return values of \"Internal\" functions such as repayBorrowInternal or mintInternal are being ignored  in  all  of  their  calls.  Hence,  it  could  be  checked  if  a  return  value  is  really  necessary  for  these functions and if so, whether it should be checked by the callers.    The unused return values of the relevant functions were removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Special Case Not Clearly Specified", "body": "  functions   repayBorrowBehalf, The  repayBorrowBehalfInternal,  repayBorrowFresh,  and  repayBorrowInternal  generally specify the input variable as:  repayBorrow,   concerning   repaying,   such   as   * @param repayAmount The amount to repay  However, this variable has a special meaning if it is -1 as then, the full amount is repaid. This should be documented more clearly in the code.  Specification changed:  The specification was changed for the relevant functions.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Unclear Specification", "body": "  The transferTokens function is specified as follows:  /* ...  * @return Whether or not the transfer succeeded  */ function transferTokens(address spender, address src, address dst, uint tokens) internal returns (uint) {  However,  as  the  return  value  is  not  boolean  but  uint  it  would  be  beneficial  to  explicitly  state  which values indicate success and failure.  The exitMarket function in the comptroller has a similar specification:  /* ...  * @return Whether or not the account successfully exited the market  */ function exitMarket(address cTokenAddress) override external returns (uint) {  Again, it would be good to specify which return values indicate success and failure.  Compound - cToken -   17  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1Speci\ufb01cationChanged                      \fSpecification changed:  The specification was changed to indicate what happens in case of success and failure.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Unnecessary Overflow Checks", "body": "  In the doTransferIn function of the CErc20 contract, the new balance is checked to be larger than the balance before the transfer.  require(balanceAfter >= balanceBefore, \"TOKEN_TRANSFER_IN_OVERF|l|\"); return balanceAfter - balanceBefore;   // underflow already checked above, just subtract  However, this check is now unnecessary because of the updated compiler version, which automatically checks for under- / overflows. Therefore, gas can be saved by omitting this check.  Additionally, in the _addReservesFresh function, there is still an overflow check.  totalReservesNew = totalReserves + actualAddAmount;  /* Revert on overflow */ require(totalReservesNew >= totalReserves, \"add reserves unexpected overflow\");  Because actualAddAmount is an unsigned integer, this condition can never occur, as any overflow will be caught by the automatic check by the solidity compiler.  Similarly, the _reduceReservesFresh function has an unnecessary check, since the subtraction would revert in case of an underflow.  totalReservesNew = totalReserves - reduceAmount; // We checked reduceAmount <= totalReserves above, so this should never revert. require(totalReservesNew <= totalReserves, \"reduce reserves unexpected underflow\");    The unnecessary checks have been removed.  Compound - cToken -   18  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics serve to clarify or support the report.  As  the  scope  of  this  report  was  limited  to  the  cToken,  we  also  list  issues  outside  of  the  scope  in  this section.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Compatibility With Different Tokens", "body": "  In the future, new tokens might be added. When markets for those are created, issues can appear. In this non-exhaustive list, we highlight some of those issues:   On-demand Balance Modification + Callback:  Different  token  types  (inflationary,  deflationary,  or  rebasing)  can  have  balances  which  change without a Transfer occurring. For some of these tokens there is a permissionless trigger to update everyone's balances. Tokens with such a permissionless trigger and a callback on transfer should not be added for the following reason. While receiving the callback of mint() the depositor could trigger  the  balance  adjustment  and  thereby  increase  the  ERC20  balance  of  the  market  without making a deposit.   Blacklist, Freezable, Seizable:  Tokens where some addresses can be blacklisted, certain funds can be frozen or some funds can be seized/burnt, need to be added with great consideration. A blacklisted market would stop working properly.  A  (partially)  frozen  market  would  not  function  correctly  (as  the  underlying  fungibility assumption is violated). Finally, seizing could lead to sudden drops in the exchange rate.   Transfer Fees:  In  principle  the  protocol  supports  tokens  with  transfer  fees.  However,  if  a  user  borrows  a  certain amount  of  tokens  with  transfer  fees,  it  will  be  almost  impossible  to  completely  repay  that  borrow. This is because the existing feature of providing -1 as the amount wouldn't work due to the transfer fees. Hence, a small borrow residue will most likely remain.  When  borrowing  tokens  with  transfer  fees,  the  requested  amount  will  not  be  received.  Similarly, when reducing the reserve of a token with transfer fees, there will be unexpected losses.   Tokens with potential for sudden increase in value:  If  a  token  whose  value  can  suddenly  increase  by  a  significant  amount,  can  be  borrowed,  then attacks  due  to  extremely  bad  positions  are  possible.  Such  tokens  include  UniswapV2  and  Curve pool  tokens,  but  also  DPI  tokens.  Extreme  care  has  to  be  taken,  when  adding  such  tokens  to  the protocol as they will most likely lead to an attack.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Hindering Liquidation", "body": "  Borrowers  can  do  different  things  to  make  their  own  liquidation  less  likely.  During  a  liquidation  the liquidator  receives  a  liquidation  reward,  determined  by  the  liquidationIncentiveMantissa variable. If X is the amount of borrowed tokens, the liquidator receives at most:  X * (liquidationIncentiveMantissa - 1) * closeFactorMantissa / 10**36  Example: If the liquidation incentive is 108% and the close factor is 50%, the maximum liquidation reward is 4% * X.  Compound - cToken -   19  NoteVersion1NoteVersion1      \fThe  liquidator  needs  to  pay  the  transaction  costs  which  will  vary  over  time.  At  the  time  of  writing  the transaction  costs  for  a  liquidation  are  around  80  USD.  Hence,  the  liquidation  incentive  only  provides  a sufficient incentive for borrows above 2,000 USD.  As this computation is performed per borrowed token a user might decide to borrow 2,000 USD worth of tokens  from  ten  different  tokens,  hence  borrowing  20,000  USD  but  making  liquidation  by  a  simple liquidator unlikely.  Note that due to partial liquidation, caused by the close factor, such small borrows can also be generated over time.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Impossible Event Orders", "body": "  In  case  that  one  of  the  underlying  tokens  has  a  callback  on  token  transfer,  the  doTransferIn  and doTransferOut  functions  can  lead  to  reentrancies.  This  can  lead  to  event  orders  that  would  not  be possible without reentrancies.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Incomplete Compatibility Check", "body": "  When adding a new market, the Comptroller checks compatibility using:  cToken.isCToken(); // Sanity check to make sure its really a CToken  However, as isCToken returns true and to be consistent with the isComptroller checks, the return value should also be checked.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Misplaced Comment", "body": "  The following comment can be found inside the seizeInternal function:  /* * We calculate the new borrower and liquidator token balances, failing on underflow/overflow: *  borrowerTokensNew = accountTokens[borrower] - seizeTokens *  liquidatorTokensNew = accountTokens[liquidator] + seizeTokens */  However,  this  comment  does  not  refer  to  the  code  where  it  is  located  but  to  the  code  further  down. Hence, it could be moved closer to the corresponding code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Reentrancy Checks Are Necessary", "body": "  of   part   Forum As  (https://www.comp.xyz/t/punitive-accounting-for-borrow-and-redeem/2247), it was proposed that punitive accounting may allow to remove the reentrancy checks.  the  Compound  Community   published   recently   post   on   a   Compound - cToken -   20  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \fWith  the  proposed  punitive  accounting  changes,  it  may  now  instead  be  possible  to  remove  the reentrancy  checks  altogether.  To  do  that,  the  community  should  prove  to  itself  that  the  protocol  is now safe to reentrancy attacks altogether. That can be done as an independent later step, after more thorough evaluation.  However, this would open up some reentrancy attacks. For example, the following sequence of actions could drain a CToken contract, assuming a token with a callback on transferFrom:  1. Provide collateral of some sort, then borrow some funds from the CToken.  2. Call  repayBorrow  to  pay  back  your  borrowed  funds.  Your  current  borrow  balance  is  stored  in  accountBorrowsPrev.  3. doTransferIn is called, which triggers the callback of transferFrom. In this callback function,  borrow more funds from the contract. This updates your borrow balance.  4. When   set  accountBorrowsPrev - actualRepayAmount, overwriting the updated borrow balance.  doTransferIn   balance   returns,   borrow   your   is   to  Therefore,  omitting  the  reentrancy  checks  could  lead  to  vulnerabilities  for  tokens  with  callbacks  on transferFrom.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Underlying as Immutable Variable", "body": "  The CErc20 contracts have the following storage variable:  address public underlying;  As  it  is  not  expected  to  change,  it  could  become  an  immutable  variable  to  save  gas  costs  during execution.  Note  that  while  this  change  would  reduce  the  execution  costs  of  nearly  every  CErc20 invocation  by  roughly  2200  gas,  it  also  implies  that  the  storage  layout  would  be  modified  which  would require  close  inspection.  Furthermore,  it  would  mean  that  not  all  CErc20  proxies  could  reference  the same implementation contract, as the implementation contracts would contain the specific underlying address.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   Unused Comptroller Functions", "body": "  The  following  Comptroller  functions  are  no  longer  being  used  by  the  cTokens  and  could  hence  be removed to reduce the code size and thereby the deployment costs:   mintVerify   borrowVerify   repayBorrowVerify   liquidateBorrowVerify   seizeVerify   transferVerify  Compound - cToken -   21  NoteVersion1NoteVersion1          \f7.9   Vote Delegation  Token holders who deposit into a CToken have to be aware that, in the case of governance tokens, they are  also  giving  away  their  voting  rights.  On  tokens  such  as  COMP  or  UNI,  the  governance  can  pick  a delegatee for the voting power which is accumulated inside the CToken contract.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.10   closeFactor Bounds Not Checked", "body": "  The Comptroller contract has a minimum and maximum bound for the value of closeFactor.  // closeFactorMantissa must be strictly greater than this value uint internal constant closeFactorMinMantissa = 0.05e18; // 0.05  // closeFactorMantissa must not exceed this value uint internal constant closeFactorMaxMantissa = 0.9e18; // 0.9  However, these bounds are never used. In fact, the closeFactor can be set to anything, as its value is not checked at all before setting it.  /**   * @notice Sets the closeFactor used when liquidating borrows   * @dev Admin function to set closeFactor   * @param newCloseFactorMantissa New close factor, scaled by 1e18   * @return uint 0=success, otherwise a failure   */ function _setCloseFactor(uint newCloseFactorMantissa) external returns (uint) {     // Check caller is admin     require(msg.sender == admin, \"only admin can set close factor\");      uint oldCloseFactorMantissa = closeFactorMantissa;     closeFactorMantissa = newCloseFactorMantissa;     emit NewCloseFactor(oldCloseFactorMantissa, closeFactorMantissa);      return uint(Error.NO_ERROR); }  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.11   maxAssets Not Enforced", "body": "  According to the documentation, a user should only be able to participate in a limited number of markets, namely no more than maxAssets.  /**  * @notice Max number of assets a single account can participate in (borrow or use as collateral)  */ uint public maxAssets;  Compound - cToken -   22  NoteVersion1NoteVersion1NoteVersion1          \fHowever,  this  is  not  enforced.  In  fact,  the  value  of  maxAssets  is  never  set  or  used.  In  particular,  the function  addToMarketInternal  in  the  Comptroller  blindly  adds  a  user  to  a  new  market  without checking that the user does not exceed this bound.  /**  * @notice Add the market to the borrower's \"assets in\" for liquidity calculations  * @param cToken The market to enter  * @param borrower The address of the account to modify  * @return Success indicator for whether the market was entered  */ function addToMarketInternal(CToken cToken, address borrower) internal returns (Error) {     Market storage marketToJoin = markets[address(cToken)];      if (!marketToJoin.isListed) {         // market is not listed, cannot join         return Error.MARKET_NOT_LISTED;     }      if (marketToJoin.accountMembership[borrower] == true) {         // already joined         return Error.NO_ERROR;     }      // survived the gauntlet, add to list     // NOTE: we store these somewhat redundantly as a significant optimization     //  this avoids having to iterate through the list for the most common use cases     //  that is, only when we need to perform liquidity checks     //  and not whenever we want to check if an account is in a particular market     marketToJoin.accountMembership[borrower] = true;     accountAssets[borrower].push(cToken);      emit MarketEntered(cToken, borrower);      return Error.NO_ERROR; }  Compound - cToken -   23  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Missing Events", "body": "  The following methods of the PegKeeperRegulator do not emit any event.  CS-CRVPKV2-003  1. set_price_deviation()  2. set_debt_parameters()  3. set_killed()  4. set_emergency_admin()  Moreover, setting a new admin, price_deviation, debt_parameters or emergency_admin in the constructor of PegKeeperRegulator, does not emit an event.    The following events have been added:  1. set_price_deviation emits a PriceDeviation event.  2. set_debt_parameters emits a DebtParameters event.  3. set_killed emits a SetKilled event.  4. set_emergency_admin emits a SetEmergencyAdmin event.  Moreover, the constructor emits now all the respective events.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Missing Sanity Checks", "body": "  The following sanity checks could be applied:  CS-CRVPKV2-004  Curve - PegKeeperV2 -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f1. PegKeeperV2.commit_new_admin() does not check that _new_admin is non-zero.  2. PegKeeperV2.set_new_regulator() does not check that _new_regulator is non-zero. Moreover, it is not guaranteed that the new regulator set will implement the interface required.  3. PegKeeperRegulator.add_peg_keeper() does not check if the new keepers to be added are  not  already  part  of  the  peg_keepers.  Moreover,  the  _peg_keepers  array  could  have duplicates.    1. _new_admin is checked to be non-zero.  2. _new_regulator is checked to be non-zero.  3. add_peg_keeper() checks if the peg keeper has already been added.  Curve - PegKeeperV2 -   13  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Gas Optimizations", "body": "  The following gas optimizations could be applied:  CS-CRVPKV2-001  1. PegKeeperV2.apply_new_admin():  self.new_admin_deadline  is  read  twice  from  storage but it could be cached.  2. PegKeeperV2._withdraw(): the function reads self.debt twice from storage but it could  be cached.  3. PegKeeperRegulator.withdraw_allowed(): This function is expected to be called often. Therefore, it could make sense to be able to store the peg keepers in a map so that their info can be retrieved in :math:O(1) instead of :math:O(n).    The optimizations are implemented as follows:  1. self.new_admin_deadline is cached in new_admin_deadline.  2. self.debt is cached in debt.  3. peg_keeper_i is introduced to allow access to peg keeper info in constant time.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Redundant Events", "body": "  The  following  methods  of  the  PegKeeperV2  emit  a  redundant  event  should  the  same  parameters  are set.  CS-CRVPKV2-002  1. set_new_caller_share()  2. set_new_regulator()  3. commit_new_admin()  4. set_new_receiver()  The  method  set_admin()  of  the  PegKeeperRegulator  emits  a  redundant  event  should  the  same admin be set.  Curve - PegKeeperV2 -   14  InformationalVersion1InformationalVersion1      \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   TVL Manipulation", "body": "  While the new system prevents price manipulation with the use of oracles through the regulator, it might still be possible to manipulate the TVL of a pool to trick the PegKeeper into providing more crvUSD than it should. Such manipulation could look like the following:  1. Provide a large amount of both assets to the pool in a balanced way.  2. Call   the   PegKeeper   to   provide   crvUSD,   the   result   of  (balance_peg - balance_pegged) / 5 will be inflated.  3. Remove the previously provided assets from the pool.  Curve - PegKeeperV2 -   15  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Allowances Enable Management of Both Base", "body": " Tokens and Collateral Assets  Users can give privileges to other accounts through the approve and allow functions. Both functions use the isAllowed mapping to store this information. Accounts for which isAllowed is set to true have full control over both the base tokens and the collateral assets of the user.  This is problematic for the following reasons:  It may not be clear to users who call the approve function (which is part of the ERC-20 interface) that this not only gives the spender access to their base tokens but also to their collateral assets. The function description does not specify this.   There is no means of giving partial privileges (i.e., access only to base tokens or only to collaterals)  to another account. This may force users to give unnecessary permissions to other accounts.   Given prior experiences with ERC-20 tokens, users might expect the approve function to allow the spender to transfer at most balanceOf tokens. However, this is not true here as an approval also allows  the  spender  to  borrow  funds.  As  a  result,  balanceOf  can  essentially  become  negative, which might not match the expectations of users or integrators.  Compound - Comet -   10  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedLowRiskAcceptedRiskAcceptedRiskAcceptedCorrectnessMediumVersion1RiskAccepted             \fTo  avoid  integration  issues  and  the  compromise  of  user  funds,  these  unexpected  behaviors  should  be clearly documented.  Risk accepted:  Compound has added dev notes documenting the special behaviour.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Oracle Timestamps Not Checked", "body": "  The function getPrice does not verify that the round data received from Chainlink oracles is up-to-date. If there is any problem with the oracles that results in outdated pricing data being returned. As a result critical calculations for allowed borrowing and liquidations would become inaccurate. It might be possible to liquidate safe positions or take out under-collateralized borrows.  Risk accepted:  Compound  acknowledges  the  risk  and  notes  that  even  if  a  defense  against  a  lack  of  updates  was implemented,  the  ability  to  report  false  prices  make  the  price  oracles  a  primary  risk  vector  for  the protocol.  Moreover,  Compound  encourages  governance  to  invest  in  improvements  upon  the  oracle system, especially ones which can also reduce gas costs.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   approve Only Allows the Values 0 and MAX", "body": "  The  approve  function  only  allows  the  values  0  and  type(uint256).max  which  could  lead  to  the following complications:  1. All  approvals  are  infinite.  In  the  past,  infinite  approvals  given  to  buggy  contracts  have  been exploited (e.g., in the case of Multichain). The risk of this is increased when only infinite approvals can be given.  2. All  other  approvals  will  fail.  This  breaks  integration  with  existing  DeFi  protocols,  which  approve  exact values. Comet Tokens would be incompatible with such protocols.  Risk accepted:  Compound accepts the risk and refers to its documentation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   baseBorrowMin Is Not Enforced for", "body": " Destination of Transfer  Borrows  have  a  minimum  threshold,  called  baseBorrowMin  to  ensure  that  it  remains  worthwhile  to liquidate them. However, this minimum threshold does not always hold.  If Base Tokens are transferred to another address using transferBase and the sender has to borrow tokens,  the  call  reverts  if  the  amount  of  borrowed  tokens  does  not  exceed  the  baseBorrowMin threshold. However, if a user receives tokens such that his balance is still negative but now violates the baseBorrowMin threshold, the call does not revert.  Compound - Comet -   11  SecurityMediumVersion1RiskAcceptedDesignMediumVersion1RiskAcceptedCorrectnessMediumVersion1RiskAccepted                        \fAs  a  consequence,  an  attacker  could  intentionally  set  up  many  accounts  with  borrows  below  the threshold in order to avoid liquidation. However, setting up such accounts would also consume a lot of gas and hence is unlikely to be financially beneficial.  Risk accepted:  Compound accepts the risk with the following statement:  The intention behind baseBorrowMin is to disallow initiating new borrows for which liquidation would likely not be worthwhile relative to gas costs. The destination of a transfer can only end up with 'dust' if a debt is partially repaid by another account almost fully. Both new positions would still need to be fully  collateralized  according  to  the  borrow  collateral  factor.  If  some  kind  of  griefing  attack  were attempted, governance could declare such tiny borrows as liquidatable at any point, and potentially seize or sell all the collateral immediately.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Balances Can Be Overflowed", "body": "  The  functions  presentValueSupply  and  presentValueBorrow  in  CometCore  allow  an  overflow due to unsafe casting to uint104. Consider the following scenario:   A user supplies type(int104).max Base Tokens to the protocol.   After some time, the baseSupplyIndex is equal to or greater than 2.   The user calls any of the functions that update their balance with 0 amount.   totalSupplyBase as well as the user's principal will be overflowed to a value smaller than the  current value.  If the base token uses the maximum of 18 decimals allowed in the protocol, around 10 trillion in principal balance  and  an  index  value  of  at  least  2  (otherwise  the  safe  cast  in  presentValue  will  kick  in)  are needed. This is practically infeasible for base tokens pegged to the USD. However, other base tokens (or USD-based  tokens  after  a  period  of  extreme  inflation)  can  bring  this  problem  into  the  realm  of possibilities.  Risk accepted:  Compound accepts the risk and extended the documentation to describe it.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Tracking Indices May Overflow on Large", "body": " Tracking Speed Values  The  state  variables  trackingSupplyIndex,  trackingBorrowIndex  as  well  as  each  user's baseTrackingIndex are of type uint64. The function accrueInternal updates these indices with the product of the passed seconds and baseTrackingSupplySpeed / baseTrackingBorrowSpeed divided  by  the  current  amount  of  totalSupplyBase  /  totalBorrowBase  (without  decimals). baseTrackingSupplySpeed / baseTrackingBorrowSpeed can be numbers with a decimal scale of up  to  15  which  will  result  in  an  overflow  after  a  non-negligible  time-frame  if  the  amount  of  supplied  / borrowed tokens is low and baseMinForRewards is set to a low value.  Compound - Comet -   12  CorrectnessLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                \fSuppose trackingIndexScale, trackingSupplyIndex and trackingBorrowIndex are all set to 1e15  (e.g.  1  COMP  per  second).  The  safe  cast  to  uint64  in  accrueInternal  will  revert  after  only approximately 5 hours after the baseMinForRewards has been reached resulting in a denial-of-service for the whole contract. This time is multiplied by the amount of full tokens supplied.  Risk accepted:  Compound accepts this risk with the following statement:  The  overflow  behavior  depends  on  several  parameters  which  do  need  to  be  chosen  carefully  by governance.  However,  we  believe  these  values  can  be  chosen  safely  and  need  not  often,  if  ever, change. In the worst case, in which governance fails to set these safely, there would be a denial of service until resolved by governance. We believe this is an acceptable risk, given that the very worst case in which bad parameters are chosen still does not result in any loss of funds.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   targetReserves Limit in buyCollateral", "body": " Can Be Circumvented  The  targetReserves  value  describes  the  expected  value  of  the  protocol  reserves  expressed  in  the base  asset.  The  function  buyCollateral  reverts  if  the  current  protocol  reserves  are  higher  than targetReserves as it doesn't allow the purchase of Collateral assets in this case. However, if any of the  collateral  tokens  has  a  callback  as  part  of  transferFrom  (e.g.  ERC777),  then  this  check  can  be circumvented  with  a  reentrant  call  to  buyCollateral.  As  a  consequence,  more  collateral  can  be bought than intended by the protocol as the check is not correctly performed for the reentrant call.  Additionally,  even  without  a  reentrancy,  the  purchased  amount  might  far  exceed  the  value  of targetReserves. At the time of writing it was unclear whether this is intended in all cases.  Risk accepted:  Compound accepts the risk with the following statement:  The reserves target is a mechanism for governance to prevent the sale of collateral after a sufficient number  of  reserves  have  been  reached.  The  risk  that  collateral  assets  may  be  sold  and  increase reserves beyond the target amount, is not a risk to the protocol health, in fact generally the opposite, as  it  guarantees  a  larger  amount  of  reserves.  The  issue  is  that  it  could  prevent  the  protocol  from being as profitable as it might otherwise be in the event that assets are liquidated and sold and later become much more valuable (as has been the case previously for many crypto assets), but we are not concerned about that risk.  Compound - Comet -   13  SecurityLowVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Wrong Computation of Borrow Balance   -Severity Findings   No Handling of Ecrecover Return on Wrong Input    No Sanity Checks for liquidationFactor    CometInterface Not Implemented by the Contracts   -Severity Findings   Accrued Interest Not Accounted for in Balance Functions    Floating Pragma    Missing Constructor Sanity Checks    Missing Events    No Recovery of Accidental Token Transfers Possible    Possible Contract Size Reductions    Possible Gas Savings    Rounding Errors Between User Balances and Total Balances    Unused Custom Error   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Wrong Computation of Borrow Balance", "body": "  function  borrowBalanceOf   The  baseBorrowIndex to compute the borrow balance:  inside   the  CometExt  uses  baseSupplyIndex   0  1  3  9  instead  of  function borrowBalanceOf(address account) external view returns (uint256) {     int104 principal = userBasic[account].principal;     return principal < 0 ? presentValueBorrow(baseSupplyIndex, unsigned104(-principal)) : 0;  As a consequence, the result is incorrect.    The borrowBalanceOf function now uses the correct index (i.e., baseBorrowIndex). In addition, unit tests  were  updated  to  catch  this  issue  by  using  a  different  value  for  baseSupplyIndex  and baseBorrowIndex.  Compound - Comet -   14  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected        \f6.2   No Handling of Ecrecover Return on Wrong Input  ecrecover returns 0 on error. This error value is not checked correctly within the allowBySig function. As a result anyone can call allowBySig with owner == 0 and thereby set approvals in the name of the  0-address.  Since  transfers  to  the  0-address  are  possible  in  the  contract,  falsely  sent  funds  to  this address could be recovered by an attacker.    The allowBySig function now reverts if the value returned by ecrecover is the 0-address.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   No Sanity Checks for liquidationFactor", "body": "  The  liquidationFactor  determines  the  liquidation  penalty  a  user  suffers  based  on  the  collateral asset. When setting the liquidationFactor in the function _getPackedAsset, it should be checked against  the  value  of  storeFrontPriceFactor.  The  storeFrontPriceFactor  describes  the discount  If liquidationFactor  >  storeFrontPriceFactor,  then  the  protocol  is  expected  to  lose  funds  on liquidations. Any user noticing this, could perform the following attack:  liquidated   collateral.   someone   protocol   when   gives   buys   the   Sandwich significant price updates which decrease any of the collateral prices or increase the base asset price using:   Supply a collateral and borrow the maximum   Absorb the account and liquidate  This would drain funds from the protocol. Hence, it should be ensured that this setting never exists.    liquidationFactor is now assured to be smaller than or equal to storeFrontPriceFactor.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   CometInterface Not Implemented by the", "body": " Contracts  The contracts Comet and CometExt contracts do not extend the CometInterface. This can lead to errors  during  development  and  integration  by  third  parties  as  the  interface  does  not  match  up  with  the implementations. One such error is that the contracts do not implement an accrue function even though it is defined in the CometInterface:  abstract contract CometInterface is CometCore, ERC20 {     ...     function accrue() virtual external;  Compound - Comet -   15  SecurityMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                        \f  CometInterface  was  split  into  CometMainInterface  and  CometExtInterface.  Comet  now implements CometMainInterface, and CometExt now implements CometExtInterface.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Accrued Interest Not Accounted for in", "body": " Balance Functions  The  functions  balanceOf,  borrowBalanceOf  and  baseBalanceOf  do  not  accrue  interest  before returning  the  respective  balances.  This  can  result  in  unexpected  behavior.  Consider  the  following example:  1. A contract queries its borrowBalanceOf of asset A. The function returns X.  2. The contract supplies X of asset A, expecting to have paid back all its borrows. However, unless accrueInternal  has  by  chance  been  called  within  the  same  block,  there  will  be  a  remaining borrow balance.  This behavior needs to be explicitly specified, currently the function descriptions do not indicate this in any way:  /**  * @notice Query the current negative base balance of an account or zero  * @param account The account whose balance to query  * @return The present day base balance magnitude of the account, if negative  */    balanceOf,  borrowBalanceOf  and  baseBalanceOf  now  calculate  baseSupplyIndex / baseBorrowIndex before converting them to present values.  the  current  values  of  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Floating Pragma", "body": "  Comet uses the floating pragma ^0.8.11. Contracts should be deployed with the compiler version and flags that were used during testing and auditing. Locking the pragma helps to ensure that contracts are not accidentally deployed using a different compiler version and help ensure a reproducible deployment.    Compiler version has been fixed to 0.8.13.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Missing Constructor Sanity Checks", "body": "  The following sanity checks could potentially be added to the constructor:   Base Token decimals should be at least 6 to prevent accrualDescaleFactor from becoming 0.  Compound - Comet -   16  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f A  comment  for  baseMinForRewards  suggests  the  value  should  be  sufficiently  large  but  is  only  checked to be non-zero.   reserveRate  should  be  lower  or  equal  to  FACTOR_SCALE  to  prevent  reverting  on  underflow  in  getSupplyRate.   kink should be lower than or equal to FACTOR_SCALE.     Corrected: baseScale is assured to be greater than or equal to BASE_ACCRUAL_SCALE.   Risk accepted: Governance is trusted to choose the correct value for baseMinForRewards.   Corrected: kink is assured to be smaller than or equal to FACTOR_SCALE.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Missing Events", "body": "  The following functions represent important state changes, for which an event might be helpful:   initializeStorage   pause   absorb   buyCollateral   withdrawReserves   allow   allowBySig  Additionally, if absorbing an account results in a loss of funds of reserves, because the collateral did not cover the borrow, an event could be emitted as well.    All  mentioned  functions  except  initializeStorage  and  buyCollateral  now  emit  events. Regarding the remaining events, Compound has issued the following statement:  Our view is that events should not be viewed as critical for tracking state changes, and that modern off-chain processors are capable of tracking all contract state transitions anyway.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   No Recovery of Accidental Token Transfers", "body": " Possible  In case an ERC-20 token other than the base tokens or collateral tokens is sent to the contract, then it cannot be recovered. Among other reasons, this might happen due to airdrops based on the base tokens or collateral tokens.    A new function approveThis has been introduced to allow the governance to approve any ERC20 token to any address.  Compound - Comet -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.10   Possible Contract Size Reductions  Instead  of  creating  an  empty  AssetConfig,  and  later  returning  (0,  0),  the  function _getPackedAsset could directly return (0, 0).   The  functions  isBorrowCollateralized,  getBorrowLiquidity,  isLiquidatable  and getLiquidationMargin share the same code with marginal modifications. The overlapping code could be factored out into new functions to save code size.   The baseScale variable is only needed internally and is derived from decimals and can thus be  defined as internal to reduce code size.   The   intialization  of  trackingSupplyIndex  and  trackingBorrowIndex   to  0   in   the  initializeStorage function can be omitted.     Corrected:  __getPackedAsset  now  directly  returns  (0,  0)  if  an  AssetConfig  element  is  empty.   Not  corrected:  Compound  claims  that  the  compiler  opimizations  already  account  for  a  sufficient getBorrowLiquidity,  isBorrowCollateralized,   size   in   contract  reduction  isLiquidatable and getLiquidationMargin.   Not corrected: Compound does not want to make an exception for one variable.   Corrected: trackingSupplyIndex and trackingBorrowIndex are no longer initialized to 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Possible Gas Savings", "body": "   The  function  _getPackedAsset  calls  the  decimals  function  of  the  asset  ERC20  contract  and checks  if  it  equals  the  provided  decimals  variable  in  AssetConfig.  Since  the  external  call  to asset  is  done  anyways,  there  is  no  need  to  provide  the  decimals  in  the  config  and  perform  this check.   The  function  supplyCollateral  calls  getAddressInfoByAddress  and  updateAssetsIn  which calls getAddressInfoByAddress for the same address again.   The  function  absorbInternal  calls  isLiquidatable  and  then  proceeds  to  perform  a  very  similar computation (including the same calls to the price oracles) again.   The function isBorrowCollateralized is expected to be commonly called for contracts with a non-negative  base  balance,  e.g.,  for  address(this)  in  buyCollateral.  In  those  cases, isBorrowCollateralized can return true as soon as presentValue is non-negative. Then, the call to the price oracle can be skipped.     Not  corrected:  The  additional  decimals  value  in  the  supplied  config  is  used  as  sanity  check  to  determine if the caller actually knows the decimals of the asset being configured.   Corrected:  updateAssetsIn  now  takes  AssetInfo  as  argument  and  does  not  load  asset  infos  itself anymore.  Compound - Comet -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected               \f Not corrected: Compound claims that the compiler already optimizes the functions.   Corrected: isBorrowCollateralized now checks if the user's present value is greater than or  equal to zero before performing any calculations.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Rounding Errors Between User Balances and", "body": " Total Balances  Due  to  the  balance  calculation  with  indices  and  principal  values,  rounding  errors  can  introduce  an inconsistency between the user balances and the total balances. Consider the following scenario:   totalSupplyBase is 100.   baseSupplyIndex is 1.085 (without decimals).   A user now supplies 10 Base Tokens with the supply function.   totalSupplyBase gets updated to 108.   The user's principal gets updated to 9.  If the protocol holds no reserves, the last user to withdraw their balance from the contract might not be able to withdraw the full amount.    The calculation of totals was modified to address this issue: Indices are now no longer translated to their present values, updated and trasnlated back to their principal values. Instead, they are now updated with the delta of users' principal values.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Unused Custom Error", "body": "  The Comet contract defines a BadAmount error that is never used.    Unused errors BadAmount in Comet and Unauthorized in CometExt have been removed.  Compound - Comet -   19  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Event Reordering Possible", "body": "  doTransferIn  and  doTransferOut  are  always  called  before  events  are  emitted.  If  the  respective ERC20  tokens  that  are  called  implement  callbacks  to  the  sender  or  receiver,  events  could  possibly  be reordered due to reentrancy. While this is not problematic for the contract itself, this can introduce errors in third-party applications that make certain assumptions about the emitted events.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Magic Numbers", "body": "  The  functions  _getPackedAsset  and  getAssetInfo  use  the  same  magic  numbers  for  packing  as well as descale and rescale factors:  uint256 word_a = (uint160(asset) << 0 |                   uint256(borrowCollateralFactor) << 160 |                   uint256(liquidateCollateralFactor) << 176 |                   uint256(liquidationFactor) << 192);  These numbers should be defined as constants to avoid errors during development.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Potential Incentive to Withdraw Supply", "body": "  In certain circumstances, users might have an incentive to actually withdraw parts of their supplied base tokens. Consider the following scenario:   kink is set to 80%.   interestRateSlopeLow is set to 10%.   interestRateSlopeHigh is set to 300%.   interestRateBase is set to 5%   For simplification, reserveRate is set to 0.   User A has supplied 100 base tokens to the contract.   User B has borrowed 80 of those base tokens, resulting in 80% utilization.   User A currently receives 10.4 base tokens interest per year.   User A now withdraws 20 base tokens such that utilization becomes 100%   User  A  now  receives  58.4  base  tokens  interest  per  year,  even  though  they  have  reduced  their  balance.  Compound - Comet -   20  NoteVersion1NoteVersion1NoteVersion1          \fIf User A holds a significant stake in supplied base tokens, they might be incentivized to withdraw some of their supply for as long as the utilization is high enough so that they earn more than 10.4 base tokens per year. However, obviously such a scenario incentivizes others to supply liquidity or repay borrows, so that it is unlikely to last.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Regular Use Expected", "body": "  For  the  sake  of  security,  the  protocol  assumes  that  each  contract  is  used  somewhat  regularly.  This  is required so that the function accrueInternal is called regularly. If there is no regular usage, e.g., if the contract is not called for a year, the following issue arises:  Collateral  that  normally  would  be  liquidatable  can  still  be  transferred  /  withdrawn.  This  is  because  the interest needs to be explicitly accrued to update the indexes. Transfers and withdrawals of collateral are allowed  without  explicit  accrual  and  hence  rely  on  recent  actions.  Theoretically,  this  can  lead  to under-collateralized  accounts,  but  given  typical  configurations,  this  would  take  years  of  inactivity.  The authors are aware of this requirement and added the following comment:  // Note: no accrue interest, BorrowCF < LiquidationCF covers small changes  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Supported Tokens", "body": "  Not  all  ERC20  tokens  can  act  as  base  and  collateral  tokens  for  Comet  contracts.  In  particular,  the following tokens are not supported:   Tokens with more than 18 decimals   Tokens with less than 6 decimals, e.g., GUSD   Tokens with transfer fees   Tokens where the balance can change without a transfer, these include:  Interest bearing tokens that increase balances   Deflationary tokens that decrease balances   Rebasing tokens   Tokens with a missing return value on transfer or transferFrom (e.g., USDT)   Tokens that require certain receiver functions to be implemented in contracts, e.g., ERC223   Tokens with rapidly increasing/positively manipulatable prices (cannot be used as base token)   Tokens with rapidly decreasing/negatively manipulatable prices (cannot be used as collateral token)   Tokens  with  multiple  entry  points  for  which  more  than  one  entry  point  has  been  added  to  the  contract's collateral assets.  Additionally the following tokens can break the protocol depending on their use:   Tokens with blacklisting in case a Comet contract is blacklisted   Pausable tokens when paused   Upgradable tokens that later introduce one of the problematic features  Compound - Comet -   21  NoteVersion1NoteVersion1           \f7.6   The Fallback Function Is Payable  The fallback function of Comet is payable even though none of the functions of CometExt are payable. Hence, there is no reason for the fallback function to be payable.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Transfers to 0-Address Allowed", "body": "  The  functions  transferInternal  and  withdrawInternal  do  not  revert  on  transfers  to  the 0-address. As a consequence, the base asset and the collateral assets might accidentally be transferred to the 0-address.  Compound - Comet -   22  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Incorrect Order of Evaluation of Arguments of", "body": " Builtin Function  The order of evaluation of the arguments of the builtin functions uint256_addmod, uint256_mulmod, ecadd and ecmul is incorrect.   For uint256_addmod(a,b,c) and uint256_mulmod(a,b,c), the order is c,a,b.   For ecadd(a,b) and ecmul(a,b), the order is b,a.  In the following contract, a call to foo() returns 1 while we would expect it to return 0.  CS-VYPER_MAY_2023-001  a:uint256  @internal def bar() -> uint256:     self.a = 1     return 8  @external def foo()->uint256:     return uint256_addmod(self.a, 0, self.bar()) # returns 1  In the following contract, a call to loo() returns False while we would expect it to return True.  x: uint256[2]  @internal def bar() -> uint256[2]:     self.x = ecadd([1, 2], [1, 2])     return [1,2]  @external def loo() -> bool:     self.x = [1, 2]      a:uint256[2] = ecadd([1, 2], [1, 2])     b:uint256[2] = ecadd(self.x, self.bar())      return a[0] == b[0] and a[1] == b[1] # returns false  Vyper - Vyper Compiler -   11  CorrectnessMediumVersion1       \f5.2   Make_setter Is Incorrect for Complex Types When the RHS References the LHS With a Function Call  Issue 2418 described a bug where, during an assignment, if the right-hand side refers to the left-hand side, part of the data to be copied may get overwritten before being copied.  Although PR 3410 fixed the issue in most of the cases, it can still happen with function calls as shown in the  example  below.  A  call  to  foo  returns  [2,2]  where  if  the  function  bar  would  be  inlined,  it  would return [2,1]  CS-VYPER_MAY_2023-002  a:DynArray[uint256,2]  @external def foo() -> DynArray[uint256,2]:     # Initial value     self.a = [1,2]     self.a = [self.bar(1), self.bar(0)]     return self.a #returns [2,2]  @internal def bar(i:uint256)->uint256:     return self.a[i]  In this second example, boo temporarily assigns values to a before emptying it. the values stored in a are however still readable from foo as a call to foo here returns [11,12,3,4].  a:DynArray[uint256, 10]  @external def foo()->DynArray[uint256,10]:     self.a = [1,2,self.boo(),4]     return self.a # returns [11,12,3,4]  @internal def boo() -> uint256:     self.a = [11,12,13,14,15,16]     self.a = []     # it should now be impossible to read any of [11,12,13,14,15,16]     return 3  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Metadata Journal Can Rollback Incorrectly", "body": "  To  fix  the  issue  of  incorrect  type  checking  of  loop  variables,  a  commit/rollback  scheme  for  metadata caching has been implemented to handle speculation when trying to type a loop.  When registering two consecutive updates for a given node, the journal can have an incorrect behavior.  CS-VYPER_MAY_2023-003  Vyper - Vyper Compiler -   12  CorrectnessMediumVersion1CorrectnessMediumVersion1          \fAssuming  that  the  compiler  has  entered  the  speculation  mode  (while  typing  a  loop  for  example),  and considering  an  AST  node  A  which,  at  the  time  of  entering  the  speculation  had  M0  as  metadata,  if  the following events happen, the cached metadata for A would become incorrect (considering M0!=M1):  1. The metadata of A is updated a first time (using register_update) resulting in M1.  2. The metadata of A is updated a second time resulting in M2 (which might or might not be equal to  M1).  3. _rollback_inner is called to roll back A's metadata to its state pre-speculation.  While the correct state of A's metadata should be M0, the resulting metadata will currently be M1 as the second call to register_update has \"overwritten\" the first one.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Assertion Could Be More Precise in", "body": " parse_Binop  CS-VYPER_MAY_2023-004  the   function   In  assertion in  is_numeric_type(left.typ) could be performed before the LShift and RShift cases are those operators are only defined for numeric types.  Expr.parse_BinOp   generation,   code   the   the   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Assertions Are Not Constant", "body": "  The definition of the class Context introduce the flag in_assertion which, when set, indicates that the context should be constant according to is_constant() definition. This flag is never set during the code generation, specifically, it is possible to have a non-constant expression in an assert statement. For example, the following contract compiles.  CS-VYPER_MAY_2023-005  x: uint256  @internal def bar() -> uint256:     self.x = 1     return self.x  @external def foo():     assert self.bar() == 1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Calls to State-Modifying Functions in Range", "body": " Expressions Are Not Caught by the Type-Checker  CS-VYPER_MAY_2023-006  Vyper - Vyper Compiler -   13  DesignLowVersion1CorrectnessLowVersion1CorrectnessLowVersion1                  \fThe  type  checker  does  not  catch  the  use  of  a  state-modifying  function  call  in  a  range  expression,  this leads  assertion: assert use_staticcall, \"typechecker missed this\"  generator   code   due   the   fail   an   to   to   The compiler fails to compile the following with the assertion mentioned above.  interface A:     def foo()-> uint256:nonpayable  @external def bar(x:address):     a:A = A(x)     for i in range(a.foo(),a.foo()+1):         pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Default Arguments Are Treated as Keyword", "body": " Arguments  validate_call_args takes kwargs, the list of valid keywords as an argument and makes sure that when a call is made, the given keywords are valid according to kwargs.  CS-VYPER_MAY_2023-007  When  being  called  from  ContractFunctionT.fetch_call_return,  the  defaults  arguments  of  the function  are  given  to  validate_call_args  in  kwargs  although  it  is  not  allowed  to  give  keywords for  gas,  value,  skip_contract_check  and arguments  default_return_value.  call  except   function   in  a   For example, when trying to compile the following contract, the call to validate_call_args made by fetch_call_return  will  succeed  although  an  invalid  keyword  argument  is  passed.  The  compilation will later fail (as it should) as fetch_call_return enforce that the kwargs should belong to the call site kwargs' whitelist.  @external def foo():     self.boo(a=12)  @internal def boo(a:uint256=12):     pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.8   Epsilon Is Not Documented", "body": "  The builtin function epsilon is not documented in https://docs.vyperlang.org/.  CS-VYPER_MAY_2023-008  Vyper - Vyper Compiler -   14  DesignLowVersion1DesignLowVersion1              \f5.9   IfExp Cannot Be Used in a Subscript  The  IfExp  AST  node's  case  in  util.py:types_from_Subscript  and annotation.py:visit_subscript.  The  following  example  does  not  compile,  and  the  compiler returns: vyper.exceptions.StructureException: Ambiguous type  is  missing   CS-VYPER_MAY_2023-009  @external def boo() :     a:uint256 = ([1] if True else [2])[0]  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.10   IfExp Fails at Codegen When Used With Self", "body": " or Environment Variables  Some complex expressions including the new IfExp node might typecheck, however, no corresponding case is implemented in the codegen leading the compiler to fail.  CS-VYPER_MAY_2023-010  The  (isinstance(contract_address.typ, InterfaceT)) in ir_for_external_call.  following   example   compile   fails   with   an   assertion   to   @external def foo():     (self if True else self).bar()  @internal def bar():     pass  The  vyper.exceptions.TypeCheckFailure: Name node did not produce IR.  following   example   fails   to   compile   error  with  @external def foo():     a:Bytes[10] = (msg if True else msg).data  Note:  In  case  the  first  example  was  to  be  allowed  by  Vyper,  one  would  need  to  be  careful  as  several analysis and sanity checks (e.g circularity checks) rely on the fact that function calls are always on the form self.FUNC_NAME.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.11   IfExp Not Annotated When Used as Iterable", "body": " for a Loop  CS-VYPER_MAY_2023-011  Vyper - Vyper Compiler -   15  DesignLowVersion1DesignLowVersion1DesignLowVersion1                \fThe  IfExp  AST  node's  case  the StatementAnnotationVisitor to omit the annotation of a IfExp node when used as iterable in a loop. The following example does not compile, and the compiler returns: KeyError: 'type'.  in  annotation.py:visit_For   is  missing   leading   @external def foo():     for x in [1,2] if True else [0,12]:         pass  Note  that  if  a  new  case  for  IfExp  is  created  in  annotation.py:visit_For  to  fix  this  issue,  the function  local.py:visit_For  should  be  updated  carefully  as  the  check  that  ensures  that  for  loops must have at least 1 iteration would not be performed on IfExp nodes.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.12   Implements Statement Does Not Enforce the", "body": " Same Indexation of Events  When  using  the  implements  statement,  the  contract's  events  fields  are  not  enforced  to  match  the interface's events fields on their indexation.  For example, the following code compiles although the spender field of Approval is not indexed.  CS-VYPER_MAY_2023-012  from vyper.interfaces import ERC20  implements: ERC20  event Transfer:     sender: indexed(address)     receiver: indexed(address)     value: uint256  event Approval:     owner: indexed(address)     spender: address     value: uint256  name: public(String[32]) symbol: public(String[32]) decimals: public(uint8)  balanceOf: public(HashMap[address, uint256]) allowance: public(HashMap[address, HashMap[address, uint256]]) totalSupply: public(uint256)  @external def __init__(_name: String[32], _symbol: String[32], _decimals: uint8, _supply: uint256): pass  @external def transfer(_to : address, _value : uint256) -> bool: return True  @external def transferFrom(_from : address, _to : address, _value : uint256) -> bool: return True  @external def approve(_spender : address, _value : uint256) -> bool: return True  Vyper - Vyper Compiler -   16  CorrectnessLowVersion1        \f5.13   Imported Contracts Are Not Fully Semantically Validated  When  importing  a  contract,  only  the  function  signatures  are  semantically  checked  (to  produce  the InterfaceT),  A  contract  that  does  not  compile  could  be  imported  in  another  one  which  would  then compile as long as the signatures of the imported functions are semantically correct.  For example, a.vy compiles although it imports b.vy which does not compile.  CS-VYPER_MAY_2023-027  #a.vy import b as B  @external def foo(addr:address):     x:B = B(addr)     x.foo()  #b.by @external def foo():     x:uint256 = \"foo\"  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.14   Incorrect Typing of Builtins Whose Return", "body": " Type Depends on Some of Its Argument's Types  CS-VYPER_MAY_2023-013  Builtin  functions  whose  return  type  depends  on  some  of  its  argument's  type  can  be  incorrectly  typed resulting in the compiler exiting with a TypeMismatch.  To achieve this behavior, the builtin function should be called with arguments such that:   At least one argument is not constant as the call would be folded otherwise.   get_possible_types_from_node  should  return  multiple  potential  types  for  the  arguments  on  which the return type of the builtin depends.  Below is a list of the builtins affected together with examples failing to compile although they should:   min and max:   a:uint256 = min(1 if True else 2, 1)   all unsafe builtins:   a:uint256 = unsafe_add(1 if True else 2, 1)   shift (deprecated as of v0.3.8):   a:uint256 = shift(-1, 1 if True else 2)   uint2str:  Vyper - Vyper Compiler -   17  CorrectnessLowVersion1CorrectnessLowVersion1          \f f:String[12] = uint2str(1 if True else 2)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.15   Incorrect Typing of Loop Iterable When It Is a", "body": " List Literal  when a loop iterates over a literal list, the function visit_For of the StatementAnnotationVisitor annotates it with a Static Array type whose value type is the last element of the list of common types of shared by the elements. To be consistent with the previously performed analysis, the list should be typed using the type of the loop iterator as it is done with range expressions.  In this code, although it compiles, i is typed as a uint8 while [1,2,3] is annotated with int8[3].  CS-VYPER_MAY_2023-014  @external def foo():     for i in [1,2,3]:         a:uint8 = i  When  doing  the  code  generation  of  a  for  loop  iterating  over  a  literal  list,  _parse_For_list  is overwriting  the  value  type  of  the  list  with  the  type  of  the  loop  iterator  inferred  at  type  checking.  This behavior  with: TODO investigate why stmt.target.type != stmt.iter.type.value_type. By solving the issue  above,  stmt.target.type  would  be  equal  to  stmt.iter.type.value_type  and  no overwriting would be needed.  commented   is   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.16   Incorrect Typing of Raw_Call When", "body": " Max_Outsize=0 in Kwargs  When  called  with  max_outsize  explicitly  set  to  0  (max_outsize=0)  the  compiler  wrongly  infers  that raw_call has no return type.  CS-VYPER_MAY_2023-015  @external @payable def foo(_target: address):      # compiles     a:bool = raw_call(_target, method_id(\"someMethodName()\"), revert_on_failure=False)      # does not compile but should compile     b:bool = raw_call(_target, method_id(\"someMethodName()\"), max_outsize=0, revert_on_failure=False)      # compiles but should not compile     raw_call(_target, method_id(\"someMethodName()\"), max_outsize=0, revert_on_failure=False)  Vyper - Vyper Compiler -   18  CorrectnessLowVersion1CorrectnessLowVersion1              \f5.17   Multiple Evaluations of DST Lead to Non-Unique Symbol Errors When Copying Bytes Arrays or DynArrays  The  destination  of  byte  arrays  and  DynArray  copying  cache_when_complex is not used. This includes the following functions:  is  evaluated  multiple   times  as  CS-VYPER_MAY_2023-016   make_byte_array_copier.   _dynarray_make_setter  src.value != \"multi\").  (both   cases:   src.value   ==   \"multi\"   and  For  AssertionError: non-unique symbols {'self.bar()2'}.  compiling   example,   following   the   Vyper   code   will   output  a:DynArray[DynArray[uint256, 2],2]  @external def foo():     self.a[self.bar()] = [1,2] @internal def bar()->uint256:     return 0  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.18   Nesting a Pop in Append Results in Incorrect", "body": " Behavior  CS-VYPER_MAY_2023-017  When modifying the size of a DynArray during a call to append, the initial length will be the one used to compute  the  new  length  and  the  compiler  won't  consider  any  change  of  length  done  by  the sub-expression.  In  the  example  below,  the  value  returned  by  a.pop()  is  used  but  its  side  effect  of decreasing a's length is omitted.  This behavior was introduced by the fix to the security advisory OOB DynArray access when array is on both LHS and RHS of an assignment. As the length of the append is cached before the evaluation of the pop and stored in memory after, the new length produced by the pop which is stored in the memory is not taken into account as it is overwritten by the cached length.  @external def foo() -> DynArray[uint256,3]:     a:DynArray[uint256,2] = [12]     a.append(a.pop())     return a # outputs [12,12] while the same in python outputs [12]  Vyper - Vyper Compiler -   19  CorrectnessLowVersion1CorrectnessLowVersion1            \f5.19   No Sanity Check on Storage Layout Files  CS-VYPER_MAY_2023-018  When  compiling  a  contract  with  the  flag  storage_layout_file,  some  basic  sanity  checks  could  be performed on the given JSON file as currently:   The  JSON  can  have  duplicated  entries.  In  this  case,  the  last  one  will  be  the  one  used  by  the  compiler.   The JSON can have entries not matching any storage slot of the contract   The  entries  of  the  JSON  do  not  necessarily  have  to  match  with  the  type  of  the  corresponding  variables in the contract.  For  example,  a  contract  only  defining  the  storage  variable  a:uint256  can  be  compiled  given  the following storage layout:  {     \"a\": {\"type\": \"uint16\", \"slot\": 10},     \"a\": {\"type\": \"uint8\", \"slot\": 1},     \"b\": {\"type\": \"uint256\", \"slot\": 1} }  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.20   Overriding Storage Layout Fails With", "body": " Immutables  The check used for ignoring immutable in set_storage_slots_with_overrides is ill-defined.  When compiling a contract with a custom storage layout file, if an immutable is defined in the contract (and is not present in the json), the compilation will fail with a StorageLayoutException.  For example, the following contract fails to compile if given an empty storage layout.  CS-VYPER_MAY_2023-019  a:immutable(uint256)  @external def __init__():     a = 1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.21   PR 3134 Has Been Reverted", "body": "  The PR 3134 has been reverted by the PR 2974 in the sense that neither the conflicting signatures nor the method ID are displayed when the multiple functions share the same selector.  Note however that PR 2974 fixed an issue where collision between functions having 0x00000000 has method ID were not detected since collision == 0 would be treated as collision == Null.  CS-VYPER_MAY_2023-020  Vyper - Vyper Compiler -   20  DesignLowVersion1CorrectnessLowVersion1DesignLowVersion1                \f5.22   Redundant and Incomplete Function Selector Collision Checks  CS-VYPER_MAY_2023-021  To ensure the method IDs are unique, the constructor of the ModuleAnalyzer performs two checks that are both incomplete but together cover every case:   The call to validate_unique_method_ids by the constructor of the ModuleAnalyzer does not  handle the public variable getters as they haven't been added to the AST yet.   The  generation  of  an  InterfaceT  from  the  top-level  node  has  as  a  side  effect  to  ensure  the uniqueness  of  method  IDs  of  public  variable  getters  and  external  functions  but  does  not  handle internal  variables  (not  really  required  at  the  moment  but  in  Vyper  semantics  to  prevent  breaking changes in case of a future change to their calling convention).  It would probably be better to have one check that covers everything for clarity purposes.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.23   References to Public Constant and", "body": " Immutables With Self Missed by the Typechecker  As  visit_VariableDecl  adds  public  constant  and  immutables  variables  to  self's  namespace, types_from_Attribute successfully typecheck references to constant and immutables using self. The compiler later fails during the codegen.  Compiling the following contract will fail with KeyError: 'a'.  CS-VYPER_MAY_2023-022  a:public(constant(uint256)) = 1  @external def foo():     b:uint256 = self.a  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.24   Semantic Analysis of the Imported Contract", "body": " Is Done With the Current Contract's Namespace  When  an  imported  interface  is  typed,  the  namespace  of  the  current  contract  is  used  to  generate  the interface  type  from  the  AST  of  the  imported  contract.  This  means  that  the  imported  contract's  function definitions may use the types and constants defined in the current contract.  For example a.vy would compile successfully although b.vy, which is imported by a.vy makes use of S and a, both defined in a.vy.  CS-VYPER_MAY_2023-023  Vyper - Vyper Compiler -   21  DesignLowVersion1DesignLowVersion1CorrectnessLowVersion1                  \f#a.vy import b as B  struct S:     x:uint256 a:constant(uint256) = 12  @external def bar(addr:address):     x:B = B(addr)     y:S = x.foo()  #b.vy @external def foo(a:uint256=a) -> S:     return S({x:12})  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.25   StateAccessViolation When \"Self\" Is Used as", "body": " a Struct Field Name  While it is allowed to use self as a field name for a struct, constructing such struct in a pure function will result in a StateAccessViolation as the compiler will consider that this is a reference to self, the address of the contract.  For example, the following contract fails to compile due to StateAccessViolation: not allowed  to query contract or environment variables in pure functions.  CS-VYPER_MAY_2023-024  struct A:     self:uint256  @external @pure def foo():     a:A = A({self:1})  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.26   TypecheckFailure When Using Address and", "body": " Self Members as Struct Field Name  Accessing  the  field  of  an  enum  named  after  an  address  or  self  member  (balance,  codesize, is_contract, codehash or code) results in a TypeCheckFailure.  CS-VYPER_MAY_2023-025  For  TypeCheckFailure: Attribute node did not produce IR.  example,   following   contract   fails   the   to   compile   due   to  Vyper - Vyper Compiler -   22  CorrectnessLowVersion1CorrectnessLowVersion1            \fstruct User:     balance:uint256  @external def foo():     a:User = User({balance:12})     b:uint256 = a.balance  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.27   in and Not in Cannot Be Used With DynArray", "body": " of Enums  When  trying  to  use  the  in  or  not  in  operator  with  a  Dynamic  Array  of  Enum,  the  compiler  fails  to compile the program with a TypeMismatch.  For example, the following contract does not compile due to the in operation.  CS-VYPER_MAY_2023-026  enum A:     a     b @external def foo():     f:DynArray[A,12] = []     b:bool = A.a in f  Vyper - Vyper Compiler -   23  CorrectnessLowVersion1      \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Note on PR 3388", "body": "  The  code  generation  of  the  constructor  of  a  contract  is  performed  before  the  code  generation  of  the deployment version of its called functions. It hence relies on the fact that the code generation of runtime internal  functions  properly  sets  the  frame  information  of  the  constructor's  callees.  If  the  runtime  code generation would be to skip the generation of internal functions that will not be included in the runtime code for example, the MemoryAllocator of the constructor would be incorrectly initialized.  Additionally, following PR 3388, the following comment in the function _runtime_ir is now outdated:  # create a map of the IR functions since they might live in both # runtime and deploy code (if init function calls them) internal_functions_ir: list[IRnode] = []  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Unused Parameters", "body": "   _is_function_implemented does not use its parameter fn_name.   struct_literals does not use its parameter name.  Vyper - Vyper Compiler -   24  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Dangling Approval", "body": "  0  0  0  6  CS-MKSPFL-004  In  the  constructors  of  both  FlapperUniV2SwapOnly  and  FlapperUniV2,  an  approval  is  granted  to daiJoin  tokens (vat.hope(address(daiJoin))).  its  vat.dai  balance,   facilitating  exiting  or   joining  of  Dai   for  moving   In the most recent version of these contracts, the interaction with daiJoin has been handed over to the Splitter  contract.  Now  Flappers  handle  received  ERC-20  Dai  tokens  directly,  the  dangling  approval  is never used in the current Flapper's logic.    The unnecessary hope() calls have been removed. At the same time vat and daiJoin (immutables) have been removed from flapper as they are no longer needed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Incorrect Specification", "body": "  Library  Babylonian.sqrt()  provides  an  efficient  way  to  approximate  the  square  root  of  an  uint256. Nevertheless, the following specification is incorrect because the last if branch incorrectly checks xx with 0x8.  // this block is equivalent to r = uint256(1) << (BitMath.mostSignificantBit(x) / 2);  CS-MKSPFL-007  MakerDAO - Dss Flappers -   13  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \fFor  instance,  consider  x==1515,  its  hexadecimal  representation  is  0x5eb  which  has  11  bits  in  total. Thus  its  0-indexed  most  significant  bit  divided  by  2  results  in  5  and  r  should  be  32  (2^5),  while  the following code yields 16 (2^4).  // this block is equivalent to r = uint256(1) << (BitMath.mostSignificantBit(x) / 2); uint256 xx = x; uint256 r = 1; if (xx >= 0x100000000000000000000000000000000) {xx >>= 128;r <<= 64;} if (xx >= 0x10000000000000000) {xx >>= 64;r <<= 32;} if (xx >= 0x100000000) {xx >>= 32;r <<= 16;} if (xx >= 0x10000) {xx >>= 16;r <<= 8;} if (xx >= 0x100) {xx >>= 8;r <<= 4;} if (xx >= 0x10) {xx >>= 4;r <<= 2;} if (xx >= 0x8) {r <<= 1;}  is  used  as   r  it  may  not  be uint256(1)  <<  (BitMath.mostSignificantBit(x)  /  2)  as  specified,  it  is  a  sufficient approximation to the true square root, hence the algorithm's convergence remains unaffected.  iterative  algorithm.  While   the  starting  value   the   for     The code has been updated to match the behavior described in the original comment. The condition of the last if branch has been set to xx >= 0x4.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Initialization Does Not Check Divisor", "body": "  The  divisor  is  used  to  scale  the  MKR  price  to  NGT  (the  re-denominated  governance  token).  This  is expected to match the rate stored in the MKR and NGT converter MkrNgt.sol.  This divisor is set by the (untrusted) deployer of the contract. However, this value is not checked during the contract's (trusted) initialization.  CS-MKSPFL-009    The initialization code now features a sanity check for the divisor.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Missing Check for Bump", "body": "  initSplitter() does not check if bump is a multiple of RAY. In case it is not, there would be a dust vat.dai balance on Splitter accumulating over time, which cannot be used up in kick().  CS-MKSPFL-006    A check has been added to verify that bump is a multiple of RAY.  MakerDAO - Dss Flappers -   14  SecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f6.5   Missing Check of Reward Token on Farm Contract  initSplitter()  does  not  check  if  the  reward  token  of  the  farm  contract  matches  the  Dai  token.  In case  it  is  not,  notifyRewardAmount()  may  revert  due  to  insufficient  reward  token  sent  to  the  farm contract, and Dai cannot be claimed as reward.  CS-MKSPFL-005    The code of the initialization script now ensures that the farm's rewards token is DAI.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Splitter.cage() Does Not Lock the Splitter", "body": "  The  Splitter  distributes  funds  to  two  contracts.  Splitter.cage()  cages  one  of  these  contracts,  the Flapper, by calling FlapLike(flapper).cage(). This sets the Flapper's state variable live to 0 and subsequent calls to the flapper.exec() will revert since the contract is no longer live.  Meanwhile,  the  Splitter  contract  itself  is  not  caged.  splitter.kick()  can  be  executed  but  reverts upon calling flapper.exec().  However, in case all funds are directed to the farming engine (burn==0), the call to flapper.exec() will  be  bypassed,  and  splitter.kick()  can  still  be  executed  successfully  to  distribute  funds  to  the farm.  CS-MKSPFL-008    The live flag has been moved from Flapper to the Splitter. In case Splitter.cage() is called, the flag will be reset to 0 and the funds flow to both burning engine and the farming engine will be stopped.  MakerDAO - Dss Flappers -   15  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Live Flag Is Not Checked", "body": "  All state except the live flag of the Flapper is checked in the initialization code.  CS-MKSPFL-001    A sanity check has been added for the live flag.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   No Revert Reason When SplitterMom Stops", "body": " Splitter  SplitterMom  can  inhibit  Splitter  in  an  emergency.  It  does  so  by  setting  the  minimum  time  between  two executions of kick() to type.max(uint256). kick() will then revert due to the addition overflow:  CS-MKSPFL-002  require(block.timestamp >= zzz + hop, \"Splitter/kicked-too-soon\");  Except  when  kick()  has  never  been  executed  before  and  zzz  is  still  equal  to  0,  the  overflowing addition  will  cause  the  execution  to  revert  and  the  require  statement  will  not  emit  the  message \"Splitter/kicked-too-soon\".  MakerDAO states:  This is deemed an acceptable trade-off as this solution allows not having to read an additional storage variable.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Redundant daiJoin Field in Config", "body": "  In FlapperInit.sol, two structs (FlapperUniV2Config and SplitterConfig) are passed as the initialization  configuration  for  initFlapperUniV2  and  initSplitter  respectively.  Both  contain  the daiJoin address. daiJoin is already present in another input struct dss (DssInstance) however. It is redundant in the configuration.  CS-MKSPFL-003  MakerDAO - Dss Flappers -   16  InformationalVersion1InformationalVersion1InformationalVersion1          \fMakerDAO states:  This parameter is necessary to allow initialisation using nstJoin in the future. nstJoin will ultimately be added to DssInstance but we might need to deploy the Splitter before that happens.  MakerDAO - Dss Flappers -   17  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Call to Vow.flap() Can Be Sandwiched", "body": "  Parameter want of the Flapper contracts provides slippage protection regarding the reference price feed. However,  depending  on  the  bump  and  want  parameters,  as  well  as  the  current  status  of  the  pool,  a kick()  operation  may  be  vulnerable  to  being  sandwiched  for  arbitrage  purposes.  Analysis  of  the parameters and pool status to prevent arbitrage is out of scope for this review.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Deployment Verification", "body": "  Since deployment of the contracts is not performed by the governance directly, special care has to be taken  that  all  contracts  have  been  deployed  correctly.  While  some  variables  can  be  checked  upon initialization through the PauseProxy, some things have to be checked beforehand.  We therefore assume that all mappings in the deployed contracts are checked for any unwanted entries (by  verifying  the  bytecode  of  the  contract  and  then  looking  at  the  emitted  events).  This  is  especially crucial for the wards mapping.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Oracle Rounds Down the Price", "body": "  In  case  the  gem  token  used  is  a  re-denominated  version  of  an  existing  token,  the  OracleWrapper  will scale  down  the  price  of  an  existing  oracle  (pip)  by  a  certain  divisor.  If  the  return  value  from pip.read() is not a multiple of divisor, the rescaled price may be lower than the actual price (due to precision loss in the conversion).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Semantics of Flapper in the System", "body": "  The semantics of Flapper has slightly changed due to the introduction of the Splitter.  1. The  Vow  will  be  connected  with  the  Splitter  instead  of  directly  to  the  Flapper.  After  a  successful deployment and initialization, the Flapper state variable on Vow will return the Splitter address.  2. The interface of Flapper has been changed compared to the docs. For instance, the surplus auction has been changed to swaps/deposits on UniswapV2. And the entry point has been changed from kick() to exec().  MakerDAO - Dss Flappers -   18  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Gas Optimizations", "body": "   The state variables _name, _symbol and _decimals could be declared as constants. As a result, the compiler does not reserve a storage slot for these variables, and every occurrence is replaced by  the  respective  value.  Compared  to  regular  state  variables,  the  gas  costs  of  constant  and immutable variables are much lower. For a constant variable, the expression assigned to it is copied to  all  the  places  where  it  is  accessed  and  also  re-evaluated  each  time.  This  allows  for  local optimizations. Immutable variables are evaluated once at construction time and their value is copied to all the places in the code where they are accessed. For these values, 32 bytes are reserved, even if  they  would  fit  in  fewer  bytes.  Due  to  this,  constant  values  can  sometimes  be  cheaper  than immutable values. (see Solidity docs)  CS-FRTK-001  recipient.  Because    _transfer() does not need to use safeMath when modifying the _balances of the sender and the  in detectTransferRestriction()  to  ensure  sufficient  funds  for  the  transfer.  And  the  recipient's balance is always less or equal to totalSupply, in case totalSupply does not overflow during minting, the recipient's balance will never overflow.  sender's   checked   balance   already   been   has   the    _mint() does not need to use safeMath when updating _balances[account]. The balance of any  account  is  always  less  or  equal  to  totalSupply.In  case  the  previous  update  to _totalSupply does not overflow, _balances[account] will not overflow as well. This applies to the updates of _totalSupply in _burn() as well.   The  check  of  onlyOwner  is  redundant  for  internal  function  _mint(),  because  _mint()  is  only called by the external function mintTo(), which is already marked with modifier onlyOwner. This applies to the internal function _burn() as well.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Indexed Fields of Events", "body": "  The events Burn, Mint, Block and Unblock do not mark the field code as indexed. Indexing fields in events allows to easily search for certain events. code is not a random number but is a limited set and could be indexed.  CS-FRTK-002  Fire Group Ltd. states:  The field code is more an add-on-info for the reason of events. At the time of writing the contract, searching based on codes seemed not to be a requirement. Thus, it was decided to not index the code part of the event.  Fire Group Ltd. - Firetoken -   10  InformationalVersion1InformationalVersion1        \f6.3   Missing Events of KYC Roles Updates  The  contract  owner's  call  to  addUserListToKycRole()  and  removeUserFromKycRole()  will update the KYC roles, nevertheless, no events will be emitted to reflect the storage modification.  CS-FRTK-003  Fire Group Ltd. states:  KYC data is stored off-chain while executing the KYC processes. Thus, it was decided to not emit events for adding and removing KYC roles as this information is available off-chain.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Redundant Transfer Restriction", "body": "  Without specifications it is unclear if address(0) is an address that has transfer restrictions in the _kyc set or not. In case it does have transfer restrictions and is not part of the set, the requires in _transfer are redundant.  CS-FRTK-004  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Unused Variable _propertyAmountLocks", "body": "  The contract defines a state variable called _propertyAmountLocks but it is not used.  CS-FRTK-005  Fire Group Ltd. - Firetoken -   11  InformationalVersion1InformationalVersion1InformationalVersion1          \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   No Way to Recover ETH or Token Sent to the", "body": " Contract  The  contract  has  no  functionality  to  recover  ETH  or  token  sent  to  the  contract.  All  funds  sent  to  the contract will be locked forever.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Reserve Code <100 for Contract Internal Use", "body": "  When  the  owner  inserts  a  new  code  into  the  mapping,  the  code  is  required  to  be  larger  than  100. Whereas only less than 6 are used in the constructor, the rest are unused.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Unusual Decimals", "body": "  The  token  has  only  5  decimals.  Most  contracts  have  18  decimals  which  is  the  standard  base  in  the Ethereum network. Many issues can arise when a token with other than 18 decimals shall be included in third party protocols. Hence, Fire Group Ltd. should carefully evaluate if it is necessary to use 5 decimals and state this very clearly everywhere (in-line documentation, online documentation, website and if other protocols are using the token) to mitigate future issues.  Fire Group Ltd. - Firetoken -   12  NoteVersion1NoteVersion1NoteVersion1          \f", "labels": ["ChainSecurity"], "html_url": "TODO"}]