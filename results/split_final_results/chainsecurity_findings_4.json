[{"title": "5.2   Double Evaluation of Range's Start", "body": "  CS-VYPER_FEBRUARY_2024-002  The start of a range is evaluated twice, the result of the first evaluation is used as the actual starting value of the iteration. The second evaluation, which happens after the evaluation of the end argument, is used to ensure that start<=end and to compute the amount of rounds to be done.  Below is an example of this behavior. The starting value of i is max_value(uint256), the amount of iterations to be done is end-start = 3 - 1 = 2. Calling the function returns hence [11579208923 7316195423570985008687907853269984665640564039457584007913129639935,  0].  This example further exploits this behavior to silently overflow the uint256 type with the iterator variable.  @external def foo() -> DynArray[uint256, 3]:     x:DynArray[uint256, 3] = [1,3,max_value(uint256)]     res: DynArray[uint256, 3] = empty(DynArray[uint256, 3])     for i:uint256 in range(x.pop(),x.pop(), bound = 3):         res.append(i)      return res  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Mistyped Loop Iterable", "body": "  Vyper - Vyper Compiler -   13  CorrectnessHighVersion1CorrectnessMediumVersion1CorrectnessMediumVersion1                \fIf a loop is defined over some non-literal static or dynamic array, the type obtained from the annotation of the  iterator  is  not  used  to  type-check  the  iterable.  If  the  iterable's  value  type  does  not  match  the annotation, the type-checker will miss it and the compiler will later panic during code generation due to some assertion.  CS-VYPER_FEBRUARY_2024-003  For  vyper.exceptions.CodegenPanic: unhandled exception , parse_For.  example,   following   crashes   code   the   the   compiler   with  @external @pure def foo() :     s:int256[3] = [1,-1,1]     for i:uint256 in s:         print(i)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Overriding Storage Allocator Does Not Handle", "body": " Reentrant Functions Properly  CS-VYPER_FEBRUARY_2024-004  OverridingStorageAllocator.set_storage_slots_with_overrides()  the FunctionDef  AST  nodes  of  the  top-level  module  to  find  non-reentrant  functions.  If  one  is  found,  the compiler reserves some slot according to what was provided in the JSON file of storage slots overrides and  annotates  the  function  type  with  the  given  reentrant  slot.  However,  for  the  next  functions,  the compiler will not annotate the function type with any slot. The issue is later caught at the code generation phase, where the compiler will crash.  iterates  over   For example, the following example would crash with AttributeError: 'ContractFunctionT' o bject has no attribute 'reentrancy_key_position'.  @nonreentrant @external def a():     pass  @nonreentrant @external def b():     pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Overriding Storage Allocator Does Not Handle", "body": " Stateful Modules  CS-VYPER_FEBRUARY_2024-005  Vyper - Vyper Compiler -   14  CorrectnessMediumVersion1CorrectnessMediumVersion1            \fOverridingStorageAllocator.set_storage_slots_with_overrides()  does  not  handle stateful module imports and initialization properly and will not allocate storage and transient storage slots for  variables  or  reentrant  functions  defined  in  a  sub-module.  The  issue  is  only  caught  at  the  code generation stage and would most likely result in the compiler panicking.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Ambiguous Imports", "body": "  CS-VYPER_FEBRUARY_2024-006  If a module is named after one of the built-in interfaces Vyper provides and if that module is accessed via the path ethereum.ercs, then the module will be shadowed by the built-in interface. For example, if a module is named ERC20 and is accessed via from ethereum.ercs import ERC20, the Vyper builtin ERC20 will be imported instead.  Similarly, if a module vyper.interfaces.ERC20 is defined and imported, the compiler would fail with  vyper.exceptions.ModuleNotFound: vyper.interfaces.ERC20 (hint: try renaming ` vyper.interfaces` to `ethereum.ercs`).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Assigning a Builtin to Itself Leads to Panic", "body": "  Assigning some builtin to itself is not prevented and leads to a compiler panic.  For  example,  compiling  the  following  code  leads  the  compiler  to  raise  the  following  exception: CodegenPanic: unhandled exception , parse_Name.  CS-VYPER_FEBRUARY_2024-007  @external def foo():     convert = convert  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.8   Codegen Fails for Raise and Assert With", "body": " Non-Memory Messages  The  code  generation  for  Raise  and  Assert  fails  if  the  reason  string  is  not  a  memory  variable.  This behavior is due to Stmt._assert_reason calling make_byte_array_copier with buf instead of an IR node whose value is buf and whose location is memory as it would be done by ensure_in_memory for example.  CS-VYPER_FEBRUARY_2024-008  For  example,  compiling  vyper.exceptions.CodegenPanic: unhandled exception 'int' object has no attribute 'typ', parse_Raise.  following  contract   leads   the   to   the  compiler  panicking  with  a:String[1] @external def foo():  Vyper - Vyper Compiler -   15  DesignLowVersion1DesignLowVersion1CorrectnessLowVersion1                  \f    self.a = \"a\"     raise self.a  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.9   Constants Cannot Be Imported From .vyi", "body": " Files  Constants  cannot  be  imported  from  .vyi  interface  files.  This  behavior  would  be  useful  as  one  would usually want this for types dependent on some value (for example a static array with some length).  CS-VYPER_FEBRUARY_2024-009  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.10   External Call Kwargs Allowed for Call to ", "body": " __init__  ContractFunctionT.fetch_call_return depends on self.is_internal to prevent or not the call  from  being  passed  some  external  call  reserved  kwargs  such  as  gas  or  value.  However,  an __init__ function has self.is_internal = False so it is possible to pass kwags when calling it although it should not be allowed.  For example, the contract below compiles:  CS-VYPER_FEBRUARY_2024-010  # main.vy import bar  initializes: bar  @deploy @payable def __init__():     bar.__init__(12, gas=14, value = 12, skip_contract_check= True)  # bar.vy a:uint256  @deploy @payable def __init__(x: uint256):     self.a = x  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.11   Immutables Allowed to Be Used as Default", "body": " Arguments  Vyper - Vyper Compiler -   16  DesignLowVersion1CorrectnessLowVersion1DesignLowVersion1                  \fAccording  to  the  documentation,  the  default  arguments  of  a  function  must  be  literals  or  environment variables, however, immutables are allowed to be used as default arguments.  CS-VYPER_FEBRUARY_2024-011  The following contract compiles:  x:immutable(uint256)  @deploy def __init__():     x = 1  @external def foo(val:uint256 = x):     pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.12   Imprecise Duplicate Import Check", "body": "  In  ModuleAnalyzer._load_import_helper(),  the  following  check  ensures  that  a  given  file  is  not imported multiple times:  if path in self._imported_modules:     previous_import_stmt = self._imported_modules[path]     raise DuplicateImport(f\"{alias} imported more than once!\", previous_import_stmt, node)  CS-VYPER_FEBRUARY_2024-012  However, the check is not performed using a normalized path as it is being done in the input bundle. This means that for a lib1 in the directory project, it can be bypassed as follows:  import lib1 from ..project import lib1 as lib2  Note however that since paths are normalized in the input bundle, if the two modules are initialized, for example, the compiler will raise an exception.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.13   Incorrect Error Messages", "body": "  In  VariableDecl.validate(),  instead  of  calling  the  method  self._pretty_location()  to pretty-print the location of the given variable, self._pretty_location is used.  In  _CreateBase.build_IR,  context.check_is_not_constant  should  be  called  with  an f-string and not a regular string to have self._id as the id of the built-in in the error message.  CS-VYPER_FEBRUARY_2024-013  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.14   Incorrect IR Identifier", "body": "  CS-VYPER_FEBRUARY_2024-014  Vyper - Vyper Compiler -   17  DesignLowVersion1CorrectnessLowVersion1CorrectnessLowVersion1                    \fThe new deploy visibility is used to abstract away the fact that the constructor can now behave either as an  actual  constructor  or  as  internal  functions  callable  in  the  deployment  context.  However, _FuncIRInfo.visibility()  has  not  been  updated  with  leading _FuncIRInfo.ir_identifier()  to  return  some  identifier  marked  as  external  although  the constructor might be treated as an internal function.  this  new  semantics,   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.15   Initialization Analysis Can Have False", "body": " Positive  CS-VYPER_FEBRUARY_2024-015  When analyzing that the constructor of an imported module is called in the constructor of a module that imports  and  initializes  it,  ModuleAnalyzer.validate_initialized_modules()  only  checks  that an  __init__  call  for  the  imported  module  appears  once  and  only  once  in  the  AST  of  the  importing module's  constructor.  For  similar  reasons  as  the  PR3162  issue,  this  is  not  enough  as  the  call  might appear in a loop or in an if else statement. It could hence be possible either to have some call path that never calls the constructor of the imported module or to have it called multiple times.  For example, given some module a with an __init__ function, the following code would compile without any  error  although  the  imported  module's  __init__  function  is  either  called  twice  or  never  called depending on the value of b.  import a initializes: a  @deploy def __init__(b:bool):     if b:         for i:uint256 in range(2):             a.__init__()     else:         pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.16   Misleading Error Message When Using ", "body": " @deploy on a Regular Function in an Interface  In ContractFunctionT.from_FunctionDef(), the following check is performed:  CS-VYPER_FEBRUARY_2024-016  if function_visibility == FunctionVisibility.DEPLOY and funcdef.name != \"__init__\": raise FunctionDeclarationException(     \"Only constructors can be marked as `@deploy`!\", funcdef )  this   check  moved   both Having  ContractFunctionT.from_FunctionDef() and ContractFunctionT.from_vyi() would allow performing  the  same  check  for  imported  interfaces.  Currently,  if  a  regular  function  in  an  interface  is decorated  as  @deploy,  fail  with  a  misleading  error  message Internal functions in `.vyi` files are not allowed!?  _parsed_decorators  which   compiler  will   called   the   by   to   is   Vyper - Vyper Compiler -   18  DesignLowVersion1DesignLowVersion1            \f5.17   Module Use Analysis Miss Nonreentrant Functions  When  a  module  is  never  initialized,  it  should  only  be  allowed  to  call  functions  that  are  stateless  in  the sense  that  they  do  not  access  storage  or  immutables.  However,  the  analysis  does  not  account  for non-reentrant decorators. If a non-initialized module's non-reentrant function is called, the compiler will crash during code generation after successfully passing semantic analysis.  Compiling the example below crashes the compiler with AttributeError: 'ContractFunctionT'  object has no attribute 'reentrancy_key_position'.  CS-VYPER_FEBRUARY_2024-017  # main.vy import lib  @external def foo():     lib.bar()  # lib.vy @nonreentrant @internal def bar():     pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.18   State Modifications Inside range Not Caught", "body": " at Type-Checking  Sub-expressions of a range expression should have a constant constancy, in other words, they should not be able to update the storage. However, this is not enforced during type-checking and is only caught by the following assertion in ir_for_self_call():  CS-VYPER_FEBRUARY_2024-018  # CMC 2023-05-17 this seems like it is already caught in typechecker if context.is_constant() and func_t.is_mutable:     raise StateAccessViolation(         f\"May not call state modifying function \"         f\"'{method_name}' within {context.pp_constancy()}.\",         stmt_expr,     )  This is the case of the example below:  x:uint256  Vyper - Vyper Compiler -   19  CorrectnessLowVersion1DesignLowVersion1            \f@internal def bar() -> uint256:     self.x = 1     return 1  @external def foo():     for i:uint256 in range(self.bar(), bound=10):         pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.19   Storage Variable of Type ModuleT and", "body": " InterfaceT Not Prevented  Since  ModuleT  is  a  Vyper  type,  and  since  ModuleT._invalid_locations  does  not  contain DataLocation.STORAGE, it is possible to use it as a type for a storage variable while this should not be possible.  The contract below will compile, and calling foo() will return (1,2).  CS-VYPER_FEBRUARY_2024-019  # main.vy import lib  initializes: lib  x:lib y:lib  @external def foo() -> (uint256, uint256):     return (self.x.bar(), self.y.bar())  # lib.vy a:uint256  @internal def bar()->uint256:     self.a += 1     return self.a  Note that a similar behavior can be observed for InterfaceT.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.20   Un-precise Interface Body Check", "body": "  CS-VYPER_FEBRUARY_2024-020  Vyper - Vyper Compiler -   20  DesignLowVersion1DesignLowVersion1            \fIn interface files (.vyi), function bodies should only contain the AST Ellipsis node (...). However given how the corresponding check is done, any statement node with a value field containing an Ellipsis node can be used in place of the Expr AST node.  if len(funcdef.body) != 1 or not isinstance(funcdef.body[0].get(\"value\"), vy_ast.Ellipsis):     raise FunctionDeclarationException(         \"function body in an interface can only be `...`!\", funcdef     )  For example, compiling a contract importing the following interface does not raise any exception:  @external def foo():     log ...  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.21   Variable Shadowing", "body": "  In InterfaceT._from_lists(), the argument name is shadowed by the different loop iterators. This leads  some  function,  event,  or  struct  name  to  be  used  as  the  name  of  the  InterfaceT  to  be constructed.  CS-VYPER_FEBRUARY_2024-021  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.22   IfExp's body and orelse Children Can Have", "body": " Arbitrary VyperType  The  ExprVisitor  does  not  enforce  any  type  on  the  IfExp's  body  and  orelse  children  except  that they should have the same type. This means that using arbitrary VyperType subclasses like ModuleT, BuiltinFunctionT  or  SelfT  is  not  prevented  and  either  results  in  a  successful  compilation  or  the compiler panicking during the code generation phase.  CS-VYPER_FEBRUARY_2024-022  Note that this issue relates to Issue_3513  For example, the following contract compiles successfully:  # main.vy import lib1  initializes: lib1  @external def foo():     (lib1 if True else lib1).bar(1)  # lib1.vy  @internal  Vyper - Vyper Compiler -   21  CorrectnessLowVersion1DesignLowVersion1            \fdef bar(x: uint256):     pass  The contracts below would fail to compile respectively with:   vyper.exceptions.CodegenPanic: unhandled exception None, parse_Attribute   vyper.exceptions.CompilerPanic: Unreachable  @external def foo():     x:uint256 = (self if True else self).balance  @external def foo():     x:uint256 = (min if True else min)(1,2)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.23   flag Can't Be Imported", "body": "  While it is possible to import events and struct types both from .vy and .vyi files, it is not possible to import flags.  For interfaces, this is because InterfaceT does not hold the flags defined in the interface and hence InterfaceT.get_type_member() only returns the set of events and struct types defined.  For modules, similarly, flag types are not added to the set of members of the ModuleT at construction time.  CS-VYPER_FEBRUARY_2024-023  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.24   range Over Decimal Is Not Prevented", "body": "  The  range()  built-in  function  should  only  accept  integer  types.  However,  this  is  not  enforced  and instead, only the AST type of the arguments of the range is checked: either both start and stop should be Num nodes, or bound should be a Num node. This means that having them as decimal numbers is not prevented since Vyper AST type Decimal is a subclass of Num.  CS-VYPER_FEBRUARY_2024-024  For example, the following code is valid:  @external @pure def foo():     end: decimal = 2.2     for i: decimal in range(1.1, end, bound=10.1):         pass  Vyper - Vyper Compiler -   22  DesignLowVersion1DesignLowVersion1            \f6   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Inconsistent Documentation", "body": "  The function parse_to_ast_with_settings is documented as taking a contract_name argument, but it does not. Additionally, the documentation mentions twice the source_id argument.  CS-VYPER_FEBRUARY_2024-025  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Misleading Function Name", "body": "  The function _parse_and_fold_ast is misleading as it does not perform any folding on the AST.  CS-VYPER_FEBRUARY_2024-026  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Range's bound Typing", "body": "  CS-VYPER_FEBRUARY_2024-027  When  the  compiler  type-checks  a  range  expression,  it  ensures  that  the  start,  stop,  and  bound expressions all have the same type and that this type matches the one provided in the annotation of the iterator. However, it might be that the bound is legitimately greater than the maximum value of the given type, in such case the compiler would raise an error.  For example, the following two programs should behave similarly, however, the first one would compile successfully and one could call foo() without any revert while the second one would not compile as 137 is not an int8.  @external def foo():     # the loop performs 137 iterations     for i:int8 in range(-10, max_value(int8)):         pass  @external def foo():     end:int8 = max_value(int8)     for i:int8 in range(-10, end, bound = 137):         pass  Vyper - Vyper Compiler -   23  InformationalVersion1InformationalVersion1InformationalVersion1            \f6.4   Redundant Check of Module Use  CS-VYPER_FEBRUARY_2024-028  In ExprVisitor.visit_Call(), the following is done:  if self.function_analyzer: self._check_call_mutability(func_type.mutability)  for s in func_type.get_variable_accesses():     if s.variable.is_module_variable():         self.function_analyzer._check_module_use(node.func)  if func_type.is_deploy and not self.func.is_deploy:     raise CallViolation(         f\"Cannot call an @{func_type.visibility} function from \"         f\"an @{self.func.visibility} function!\",         node,     )  The call to _check_module_use() is done as many times as there are variable accesses in the called function,  which  is  redundant  as  it  does  not  depend  on  the  variable  accesses  and  could  be  done  only once.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   ModuleT Cached Properties Dependent on", "body": " Properties  In  ModuleT,  several  cached  properties  such  as  variables,  functions  or  immutables  depend  on some  non-cached  properties.  This  means  that  if  a  cached  property  is  to  be  used  before  the  value returned  by  the  correspondent  property  is  final,  the  compiler  will  always  use  this  out-of-date  cached value. Although no example of this behavior was found, such a pattern can lead to issues if, in the future, some  of  these  properties  were  to  be  used  before  the  corresponding  cached  property  is  fully  set.  An example  would  be  if  functions  were  to  be  read  before  the  AST  expansion  which  updates function_defs.  CS-VYPER_FEBRUARY_2024-029  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   enum Not Renamed to flag", "body": "  PR3697 renames the enum keyword to flag however not all occurrences of enum are renamed in the code, comments and documentation.  For example FlagT._enum_members should be renamed to FlagT._flag_members.  CS-VYPER_FEBRUARY_2024-030  Vyper - Vyper Compiler -   24  InformationalVersion1InformationalVersion1InformationalVersion1          \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Ambiguous Imports Are Allowed", "body": "  In  InputBundle.load_file(),  once  a  valid  path  is  found,  the  method  returns  even  though  there might be multiple matching paths. It could be beneficial to raise an exception in case there are multiple paths to avoid any ambiguous import.  Vyper - Vyper Compiler -   25  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Chainlink Query May Revert", "body": "  The Pool contract relies on ChainLink assumptions that do not hold. Chainlink's round IDs do not always increase monotonically. Therefore, the getRoundData queries can revert. Relying on _roundId-- in GeometricBrownianMotionOracle.getHistoricalPrice is not correct, since querying an invalid ID will make the swap revert.    The  call  to  the  price  feed's  getRoundData  function  has  been  moved  in  a  try/catch  block  and  the function returns (0, 0) if the oracle call reverts.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Dynamic Weights Changing Problem", "body": "  Swaap Labs - Swaap Core V1 -   13  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedDesignHighVersion1CodeCorrectedSecurityHighVersion1CodeCorrected                 \fAssume the pool has 10 X and 10 Y tokens that both have weight of 1. Initial invariant:  10X * 10Y = 100 Now  assume  attacker  sees  an  update  in  oracle  price,  that  will  change  the  weight  of  X  tokens  to  2. Attacker performs a trade: in 990 Y, out 9.9 X. New constant product:  After ChainLink price update, the X tokens weight become 2. New invariant:  (0.1X)2 * 1000Y = 10  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "0.1X * 1000Y = 100", "body": "  In 0.9 X, out 990 Y. The invariant holds:  New constant product:  (1X)2 * 10Y = 10  With 2 these trades that surround the price update, attacker profited by 9 X tokens.  The sandwiching can be performed using the Flashbots service. This issue is similar to the one that was discovered in Curve.    Swaap Labs introduced 2 solutions:  1. The   relative   price  AfterSwapPoolPrice/OraclePrice <= 102% + fee  difference   between   oracle   and   pool   price   is   capped:  2. If the user sells token that is in shortage, and the token price experienced increase in the current  block, extra fee is applied to compensate for a possible impermanent loss of the pool.  Together these 2 solutions help with the weight change sandwich attack.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Geometric Brownian Motion Parameter", "body": " Estimation  For a returns R over time window T, the code estimates Geometric Brownian Motion parameters using these formulas:  Ri  N \u2211 i = 0 T  \u03bc =  N \u2211 i = 0  \u03c32 =  (Ri \u2212 \u03bc)2 + (T \u2212 N) * \u03bc2  T \u2212 1  According to specification, the second term in s computation is responsible for times, when the sample is missing and thus the return at that point is assumed to be 0.  Assuming dt is a regular sampling period, the N = T/dt - number of samples. In that case, a common way to estimate the GBM parameters using successive observations method is given by:  Ri  N \u2211 i = 0 N  \u0302\u03bc =  N \u2211 i = 0  \u0302\u03c32 =  (Ri \u2212 \u0302\u03bc)2  T N \u2211 i = 0  (Ri \u2212 \u0302\u03bc)2  T * dt N \u2211 i = 0  Ri  T + \u03c32  2  \u03c32 =  \u0302\u03c32 dt =  \u03bc =  \u0302\u03bc  dt + \u03c32  2 =  Swaap Labs - Swaap Core V1 -   14  DesignMediumVersion1CodeCorrected        \fComparing these estimations to code estimations, we can see following discrepancies:  1. Code m estimate lacks a 0.5 * s^2 term, and thus will be underestimated. 2. Code s estimate lacks a dt scaling factor, and thus will be overestimated. 3. Code  s  estimate  has  a  (T  -  N)/T  *  m^2  term,  that  also  doesn't  help  with  precision  of  the  estimate.  To  summarize,  the  outputs  of  GeometricBrownianMotionOracle.getStatistics  can  have  big errors, that might lead to impermanent losses of LPs as well as to overpriced swaps.  In addition, for Chainlink price oracles the sampling periods are not consistent and affected by Deviation and  Heartbeat  Thresholds.  Thus  the  code  computed  estimations  in  most  cases  will  fail  to  accurately estimate the price evolution process, even if it has the GBM nature.  Code modified:  The  parameters  estimation  method  has  been  modified  to  use  the  price  ratios  between  two  successive period instead of the return. The new implementation uses the following formulas:  Si = pricei \u0394i = timestampi \u2212 timestampi \u2212 1 T log(Sn  \u03bc = 1  )  S0  \u03c32 = 1  N \u2212 1 [\u22121  T log(Sn  )2 +  N \u2211 i = 1  log( Si Si \u2212 1 \u0394i  )2  ]  S0 These formulas come from the maximum likelihood estimation (MLE) for the GBM parameters. However to be the true MLE, mu should have a correction factor of + 0.5 * sigma^2. This correction factor is not  needed  here  because  Swaap  Labs  computes  the  z-percentile  of  the  lognormal  distribution,  which only needs mu + 0.5 * sigma^2 - 0.5 * sigma^2 = mu. Thus, the computed mu and sigma are consistent with their future usage.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Inverted Token Performance", "body": "  The signature of the function is:  _getTokenPerformance(uint256 initialPrice, uint256 latestPrice)  and  computes  the  performance  ratio  as  latestPrice  /  initialprice.  However,  the  function  is (latestPrice_param, always  initialPrice_param),  ratio initialPrice_param / latestPrice_param.  arguments  result  of   inverted  performance   the  call  will  yield   called  with   the  the   following   order   the   the   in     Natspec and _getTokenPerformance call input order was fixed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   View Functions Reentrancy", "body": "  Some  view  functions  don't  use  the  _viewlock_  modifier.  In  case  of  reentrancy  due  to  ERC20  token calls (e.g. ERC777), these getters can return unreliable data. This may break the integration with other contracts and systems that rely on these getters. Such getter functions are:  Swaap Labs - Swaap Core V1 -   15  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected                \f getAmountOutGivenInMMM  Please note, this list might be incomplete. Any function of a contract that does external call need to be lock or viewlock protected, if other external contract might rely on the data from this contract, such as spot prices, weights, etc.    View locks have been added to all view functions in the Pool.sol contract.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Zero Exit Fee Allows Just-In-Time Liquidity", "body": " Provision  Since the system is not totally impermanent loss resistant, liquidity providers are still exposed to a risk. To  cope  with  the  risk,  malicious  liquidity  providers  can  sandwich  large  swaps  transactions  and  collect most of the swap fee without the risk of an impermanent loss.    JIT liquidity provision is mitigated by the use of a cooldown timer of 2 blocks. A LP that provided liquidity to  a  pool  cannot  exit  the  pool  or  transfer  LP  tokens  (by  either  transfer  or  approval  and transferFrom) for a period of 2 blocks after the liquidity provision.  However, this may block proxy contracts to manage funds for users. To cope with this issue, Swaap Labs added the joinPoolForTxOrigin, a function that pulls funds from msg.sender, but deposits them to the  tx.origin.  Since  it  is  not  the  authorization  by  the  tx.origin,  this  does  not  raise  problems  like https://swcregistry.io/docs/SWC-115.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Num.abs Function Name", "body": "  The name of Num.abs function does not match its functionality.    The Num.abs function has been renamed Num.positivePart.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   getRoundData Function Duplication", "body": "  function  getRoundData  and   in functionality  The  GeometricBrownianMotion and in ChainlinkUtils. Functionality duplication should be avoided as it increases the amount of code to deploy and deteriorates code maintainability.  is  duplicated.   implemented   its   is   It   Swaap Labs - Swaap Core V1 -   16  DesignMediumVersion1CodeCorrectedCorrectnessLowVersion2CodeCorrectedDesignLowVersion2CodeCorrected                        \f  The getRoundData function in GeometricBrownianMotion has been removed and its use has been replaced by the getRoundData function from ChainlinkUtils.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   Compiler Version Not Fixed and Outdated", "body": "  The  solidity  compiler  is  not  fixed  in  the  contracts.  The  version,  however,  is  defined  in  the truffle-config.js to be 0.8.0.  In the Factory contract the following pragma directive is used:  pragma solidity ^0.8.0;  Known bugs in version 0.8.0 are:  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1531  More information about these bugs can be found here:  https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing the most recent Solidity release is version 0.8.12 which contains some bugfixes.    The compiler was fixed to version 0.8.12.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.10   Gas Inefficiency and Duplicated Checks", "body": "  1. In  the  GeometricBrownianMotionOracle.getHistoricalPrices  function,  idx  is  set  to hpParameters.lookbackInRound + 1 and then directly to 1. The second first assignation has no effect.  2. Math.getLogSpreadFactor checks horizon and variance for >= 0, this check is useless since  both values are uint256.  3. Math.getLogSpreadFactor does division by two with 5 * Const.BONE / 10, simply dividing  by 2 would save gas.  4. In  Math.getInAmountAtprice   it   is  possible   to  pack  computations   to  save  calls   to  LogExpMath.pow.  5. Some  state  variables  can   fit   in  smaller   types   (e.g.,  with   its  current  bounds,  dynamicCoverageFeesZ could fit in a uint64). Saving storage slots might save gas.  6. TokenBase's  _burn  and  _move  functions  check  that  there  is  enough  balance,  the  check  for  underflow is by default since compiler version 0.8.0.  7. PoolToken.transferFrom check that there is enough allowance, the check for underflow is by  default since compiler version 0.8.0.  8. PoolToken's  _name,  _symbol  and  _decimal  can  be  constant  and  their  respective  getter  functions can be external. This will save gas.  Swaap Labs - Swaap Core V1 -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f9. The overflow checks in numerous Num functions are not necessary anymore since compiler version ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "0.8.0,  which  features  automatic  overflow  check.  The  division  by  zero  checks  are  not  necessary,", "body": " solidity division will revert on a division by 0.  10. Elements  of  the  Pool.Record  struct  can  have  a  smaller  type  (e.g.  index,  denorm)  and  be  reordered to save storage.  11. The Pool's state variable _factory can be immutable.  12. Pool.joinPool, Pool.getAmountOutGivenInMMM, Pool.finalize can be external.  13. The  check  for  _controller  address  and  finalization  in  Pool.bindMMM  are  redundant  with  the  ones in Pool.rebindMMM.  14. When  resetting  storage  slots  on  mappings,  e.g.  in  unbindMMM,  the  use  of  delete  is  recommended for lower gas usage.  15. The  second  require  of  _getAmountOutGivenInMMMWithTimestamp  is  a  less  strict  version  of  the first requirement.  Version 2:  1. Const.MAX_IN_RATIO and Const.MAX_OUT_RATIO are never used in the code, they should be  removed.  2. getMMMWeight  is  always  called  with  shortage  =  true,  removing  the  argument  and  code  related to shortage = false will save gas.    1. idx is set to 1 at variable declaration.  2. Both checks for >= 0 have been removed.  3. The multiplication by 5 / 10 has been replaced by a division by 2.  4. The terms under w_o / (w_o + w_i) have been grouped together.  5. Acknowledged. Some state variables have been changed to use a smaller type.  6. The checks for sufficient balance have been removed.  7. The check for sufficient allowance has been removed.  8. PoolToken's  _name,  _symbol  and  _decimal  have  been  changed  to  constant  and  their  respective getter function have external visibility.  9. Unnecessary overflow checks in Num library have been removed.  10. index and denorm types have been reduced to uint8 and uint80 resp.  11. _factory state variable has been changed to immutable.  12. Pool.joinPool,  Pool.getAmountOutGivenInMMM,  Pool.finalize  visibility  has  been  changed to external.  13. The checks have been moved to the common _rebindMMM function.  14. delete is now used to reset the storage fields in the mappings.  15. Both require have been removed. The check has been replaced by the oracle update sandwich  protection.  Version 2:  1. Unused constants have been removed.  2. The shortage parameter of function getMMMWeight has been removed.  Swaap Labs - Swaap Core V1 -   18  \f7.11   Num Library Function Visibility  The functions of Num library have public visibility. This way, any contract that will need to deploy this library, will use it as an external contract. It means that any call to the library functions will result in quite expensive CALL opcode. If the visibility of those functions were internal, the function code would be then  inlined  at  the  point  of  use.  This  way  bytecode  size  of  Pool  will  be  smaller  and  gas  cost  for  each see: library  https://docs.soliditylang.org/en/latest/contracts.html#libraries  operation   smaller   more   well.   info   call   For   will   be   as     The visibility of the functions in the Num library has been changed to internal.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.12   Specification Mismatch", "body": "  1. The formula provided in the documentation for getInAmountAtPrice multiplies the desired price by  w_out  /  w_in  which  is  wrong,  however  the  implementation  correctly  multiplies  by w_in / w_out.  2. In the whitepaper, when the stochastic buy-sell spread is computed, the p-percentile of the random  variable is divided by the latest oracle price, this is not the case in the implementation.  3. The @dev natspec of getNextSample is incomplete  4. The @dev natspec of getRoundData makes a wrong assumption, the function will revert if no data  can be found as specified in https://docs.chain.link/docs/faq/#can-the-data-feed-read-revert.  5. The  specification  of  some  public  and  external   functions,  e.g.  joinPool,  finalize,  calcSpotPrice, is missing.  6. The @notice natspec of rebindMMM is incomplete.  7. The  natspec  of  Pool._getTokenPerformance  defines  twice  the  first  parameter  and  not  the  second one  Version 2:  1. The  @dev  natspec  of  GeometricBrownianMotionOracle.getHistoricalPrices  does  not reflect the implementation. If no historical data was found, the latest data and startIndex == 0 will be returned. If round data is 0, the round will simply be skipped, the algorithm will not stop filling prices/timestamps.  2. The _getParametersEstimation doesn't describe all @param.  Specification partially corrected:  1. The formula in the documentation has been corrected.  2. Specification changed.  3. The @dev natspec for getNextSample has been completed.  4. The implementation of getRoundData now matches the natspec.  Swaap Labs - Swaap Core V1 -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                \f5. Comments or natspec have been added for some public and external functions.  6. The natspec for rebindMMM has been completed.  7. The second parameter is now described in the natspec.  Version 2:  1. The @dev natspec has been updated to reflect the implementation.  2. The missing parameters natspec has been added.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.13   Time Window of 1 Will Revert", "body": "  A  time  window  of  1  second  will  make  getStatistics  revert  due  to  a  division  by  zero.  The Const.MIN_LOOKBACK_IN_SEC  limit  enforced  on  _priceStatisticsLookbackInSec  storage variable  in  setPriceStatisticsLookbackInSec  function  does  not  prevent  this  case  from happening.    If time window = 1, the variance and mean are considered to be 0.  Swaap Labs - Swaap Core V1 -   20  DesignLowVersion1CodeCorrected        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Compatibility Issues Due to tx.origin", "body": "  The use of tx.origin limits certain functionality of the contract. Such contracts can be not deployable on chains that don't support ORIGIN opcode, e.g. Optimism. In addition, usage of this contract by wallet contracts like Gnosis wallet can also be limited.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   ERC20 Compatibility", "body": "  The _pull/_pushUnderlying functions of the Pool expect transferFrom and transfer to always return  a  boolean.  However,  some  tokens,  for  example  USDT,  do  not  follow  this  pattern  and  are  thus incompatible with the system. OpenZeppelin has a SafeERC20 library, which helps with such tokens.  In addition, the usage of ERC20 tokens with fees, rebalancing tokens, or tokens with reentrancies can be problematic to integrate. Swaap Labs needs to carefully consider what tokens can be supported by the Pool.  The _pull/_pushUnderlying functions have been modified to use the SafeERC20 library for token transfer.  Swaap Labs - Swaap Core V1 -   21  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Inefficient Transfer Hook", "body": "  The  internal  function  ERC20Farmable.beforeTokenTransfer  is  called  before  any  transfer  logic  is executed. Assuming that user A is farming on n and user B is farming on m farms without any overlap in the sets, then,   m+n addresses are loaded from storage at the very beginning,   m+n external calls are made,   m+n storage writes to corrections,   and more reads and writes.  Furthermore,  m  and  n  are  not  limited.  A  token  transfer  could  end  up  being  very  expensive  without  the user noticing. Hence, token transfers could easily fail by running out of gas.  Risk accepted:  1inch accepts the risk.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Insufficient Documentation", "body": "  1inch - Farming -   9  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedAcknowledgedCodePartiallyCorrectedDesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                     \fDocumentation helps users, developers and others to understand a system in a shorter amount of time. Especially if the code is to be used as a library by other developers, it could help these to prevent errors. Otherwise, no assumptions on the code and its behavior can be made.  Currently, code is undocumented. Furthermore, no behavioral description is provided on what to expect from  a  function  call.  For  example,  it  is  undocumented  how  the  libraries  handle  errors  in  external contracts.  Acknowledged:  1inch replied:  Will be improved in the future.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Lack of Events", "body": "  Typically,  events  help  track  the  state  of  the  smart  contract.  Some  functions,  such  as  startFarming, emit events while others do not emit any event. Some examples lacking event emissions are:   ERC20Farmable.farm()   ERC20Farmable.claim() and FarmingPool.claim()   ERC20Farmable.exit()   Public checkpointing functions   BaseFarm.setDistributor()  Code partially corrected:  An event has been added only for setDistributor().  1inch - Farming -   10  DesignLowVersion1CodePartiallyCorrected          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  1  0  7  -Severity Findings  -Severity Findings   Gas Griefing   -Severity Findings  -Severity Findings   Commented Code    Farms Rely on Token to Checkpoint    Gas Inefficiencies   Ineffective period Check   Introduction of Batched Operations    Usage as a Library   farmingCheckpoint() Has No Functionality   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Gas Griefing", "body": "  ERC20Farmable  calls  farm  contracts  in  every  call  to  farmedPerToken()  to  query  information  with IFarm.farmedSinceCheckpointScaled() on how many rewards have been released so far. Even though  that  call  is  handled  with  a  try/catch  block  to  prevent  the  target  contract  from  reverting maliciously, it is still possible that the farm consumes all gas.  1. A malicious farm honeypots users into joining.  2. The malicious farm contract is upgraded through an upgradeability pattern.  3. Every call to farmedSinceCheckpointScaled() consumes all gas.  Now, following is not possible:   any ERC20Farmable transfer from an affected user   any ERC20Farmable transfer to an affected user   exiting the malicious farm   Claiming from the malicious farm  Ultimately, tokens will be locked for affected users.    1inch - Farming -   11  CriticalHighCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected           \fThe call to IFarm.famedSinceCheckpointScaled() now has a gas limit. If the gas limit of 200000 is exceeded, the failure is handled by behaving equivalently to a revert in the farm contract.  Additionally, the static-call was wrapped inside an assembly block to prevent the return data bomb issue in the Solidity compiler (documented here: https://github.com/ethereum/solidity/issues/12306).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Commented Code", "body": "  ERC20Farmable._getFarmedSinceCheckpointscaled  contains  commented  code.  Removing  the code could help keep the code cleaner such that it is easier to understand.    Commented out code has been replaced by calls to on onError().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Farms Rely on Token to Checkpoint", "body": "  Farm._updateFarmingState() calls checkpoint() of an external ERC20Farmable contract. Then, the  ERC20Farmable  contract  calls  Farm.farmingCheckpoint().  However,  a  malicious ERC20Farmable  to Farm.farmingCheckpoint(). Hence, the farm checkpoints could remain without updates.  implementation   purposefully   could   leave   call   the   out     farmingCheckpoint has been removed from the farm contracts. Hence, there is no need to call it.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Gas Inefficiencies", "body": "  In multiple locations code could be optimized to reduce gas cost. Some examples are:   Function UserAccounting.checkpoint() loads the stored update time and the store farmed per token  value  from  storage.  However,  to  correctly  call  that  function  it  is  required  to  first  call farmedPerToken() which also loads the same variable from storage. Hence, storage reads could be prevented.  In  function  FarmingPool.exit()  balanceOf  is  called  twice.  However,  the  second  time  it  is called it is evident that it must be zero.   _beforeTokenTransfer could exit early for self-transfers.   Casting  period  to  uint40  when  the  input  could  have  been  restricted  to  be  uint40  in  startFarming.    The overall gas consumption has been optimized.  1inch - Farming -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                         \f6.5   Ineffective period Check  FarmAccounting.startFarming() contains following code:  require(period < 2**40, \"FA: Period too large\"); require(amount < 2**176, \"FA: Amount too large\"); (info.finished, info.duration, info.reward) = (uint40(block.timestamp + period), uint40(period), uint176(amount));  However, the first check is insufficient for uint40(block.timestamp + period) not to overflow.    The precondition was changed to:  require(period + block.timestamp <= 2**40, \"FA: Period too large\");  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Introduction of Batched Operations", "body": "  Assume a user participates in 10 farms for a farmable token. To claim all rewards the user needs to call claim()  multiple  times.  Gas  consumption  could  be  reduced  by  allowing  batched  operations  for ERC20Farmable.    Following batched operations have been introduced:   claimAll: claims on all farms   quitAll: quits all farms  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Usage as a Library", "body": "  ERC20Farmable  is  intended  to  be  used  as  a  library  for  farmable  ERC-20  tokens.  As  such,  some functions may require to be overridden so their functionality can be enhanced. However, no function in the  supplied  codebase  has  a  virtual  modifier,  and  so  child  contracts  cannot  override  any  method, meaning code that inherits from ERC20Farmable cannot extend its core functionality.  On the other hand, for some functions it could make sense to disallow overriding. An example could be farmedPerToken()  which  specifies  the  distribution  among  token  holders.  Allowing  developers  to modify its behaviour could lead to subtle issues that may not be caught during testing.  Assuming there is a use-case of changing the semantics of computing the farmed amount, code would require changes in several functions. First, farmed() would require changes. Second, claim() would require  changes  as  it  calls  UserAccounting.farmed()  instead  of  farmed.  Hence,  wrapping functionality  from  libraries  in  the  abstract  ERC20Farmable  and  using  the  wrapper  functions  internally could ease the overriding process and prevent errors.  1inch - Farming -   13  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fFurthermore, it could be that some functions should not be callable by any child contracts, and there are certain  state  variables  that  should  not  be  set  in  child  contracts.  For  example,  farmTotalSupply  is  a public  variable,  querying  that  value  is  helpful  for  users  interacting  with  the  contract.  However, developers  could  unknowingly  interleave  writes  to  that  variable  in  between  updates  to  it  in  the  internal callflow  which  would  lead  to  inconsistent  state.  In  that  case,  it  could  be  helpful  to  have  a  public  getter while restricting writes in child contracts.  To  summarize,  1inch  provides  a  library  for  staking.  Since  documentation  is  also  part  of  writing  an application library, it would be helpful to explicitly document the overridability and the visibility of functions and variables, as well as their intended use.    The code has been adapted and functions have been marked as virtual.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   farmingCheckpoint() Has No Functionality", "body": "  FarmAccounting.farmingCheckpoint()  is  empty  and  has  no  functionality.  The  calls  to  it  further complicate the code. Moreover, replacing farm accounting logic through overriding is not easily possible.  Additionally, Farm._updateFarmingState() lacks checkpointing for a farm's state.    The function has been removed.  1inch - Farming -   14  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Calls to Farms", "body": "  Note that the system interacts with untrusted farms and untrusted contracts.  Changes  implemented  or  functionality  in  contracts  inheriting  from  ERC20Farmable  should  ensure  that there  is  no  possibility  of  re-entering  the  ERC20Farmable  contract  when  interacting  with  untrusted contracts since that could lead to possible unwanted modifications of farming state for other farms.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   farmedSinceCheckpointScaled() Decimals", "body": "  Note that farms may run into issues if a Farm's farmedSinceCheckpointScaled() does not return a value that is in the base of 10**(18 + rewardToken.decimals()):   Assume the call to farmedSinceCheckpointScaled() returns a value in the base of 10**x.   Then,   the   call   to   farmedPerToken  will   return   something   in   the   base   of  10**(x-ERC20Farmable.decimals()) which implies that corrections is in base of 10**x.  In farmed, the subtraction arguments will be both in base 10**x. However, the result of the division will be in the base of 10**(x-18).  Using Farm of 1inch, will ensure that x==18+rewardToken.decimals(). However, if that is not the case, errors could occur.  1inch - Farming -   15  NoteVersion1NoteVersion1       \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Unpermissioned Access to onlyMate Methods", "body": "  CS-MRT-001  If  the  may  role  is  assigned  to  address  zero,  methods  guarded  by  the  onlyMate  modifier  become unpermissioned.  The  purpose  of  this  is  unclear,  as  conflicting  functionality  can  be  accessed  through onlyMate methods. A user could call push() to transfer the whole balance to the configured recipient, or push(1) to transfer a very low amount to the recipient and disable further push() access, since the to and psm variables are reset to zero after push() is called. Likewise, a user could call quit(), which transfers the DAI balance to the configured quitTo address.  Since  mutually  exclusive  functionality  is  accessible  through  the  onlyMate  modifier,  leaving  it unpermissioned  opens  the  door  to  race  conditions  and  unpredictable  behavior.  Only  trusted  parties should be granted access to onlyMate guarded methods.  Similarly, but to a lesser extent, pick() and hook() are unpermissioned when address zero is granted the can role.    MakerDAO  realized  output  conduits  should  never  be  permissionless.  The  abilitiy  to  make  the  may  and can roles unpermissioned has been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Use of Unsafe Math Subject to Overflows", "body": "  Since the contract uses version 0.6.12 of solidity, unchecked arithmetics are used by default. Methods expectedGemAmt() and requiredDaiWad() are subject to possible artihmetic overflows. if their wad or amt parameters are set large enough.  Since  no  accounting  state  is  held  by  the  contract,  but  operations  are  performed  on  the  current  DAI balance, the overflows cannot be exploited, even by a malicious may user. However, external contracts  CS-MRT-002  MakerDAO - RWA Toolkit -   10  CriticalHighMediumCodeCorrectedLowCodeCorrectedSecurityMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fand off-chain users relying on the correctness of expectedGemAmt() and requiredDaiWad() might be negatively affected.    SafeMath  like  methods  were  introduced  to  ensure  the  calculations  in  expectedGemAmt()  and requiredDaiWad() cannot overflow.  MakerDAO - RWA Toolkit -   11  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   onTokenTransfer Wrong Accounting", "body": "  When triggering onTokenTransfer with only one deposit, stake_amount is assumed to be 32 STAKE but is not checked. This allows a depositor to call STAKE.transfer with 1 STAKE but to be accounted for 32 in the Merkle tree.  Code corrected  In case of a single transfer the amount is set to the transferred amount specified. In batch transfers it is set to 32 Ether. This behavior is coherent with the behavior of single deposits and batch deposits.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   EIP1967 Storage Addresses", "body": "  Hard-coding long strings could be error prone. The storage addresses of implementation and admin are hardcoded as hex values in multiple places. This adds complexity and is even more error prone. A clean  mitigation  would  be  to  set  the  storage  addresses  used  for  implementation  and  admin  as constants once and use this constant later on.  Code corrected  The hard coded strings were replaced by constants.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Interface Name Mismatch", "body": "  POA Network - SBC Deposit -   9  CriticalCodeCorrectedHighMediumLowCodeCorrectedCodeCorrectedCorrectnessCriticalVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                         \fThe name of the file and interface IERC667 should be IERC677 to be compliant with the transferAndCall Token Standard.  Code corrected  The file was renamed with the appropriate name.  POA Network - SBC Deposit -   10  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Admin Power", "body": "  The system is administrated. The admin account has the complete power including withdrawing all funds by updating the implementation contract. Hence, the security of the admin key is of utmost importance as well  as  the  trust  in  the  key  holder/s.  POA  network  provided  the  information  that  they  are  aware  of  this note and will keep the admin contract under control by a multisig.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Locked Tokens in Implementation", "body": "  The  admin  can  withdraw  all  tokens  balances  from  the  proxy,  but  funds  sent  to  the  implementation contract are stuck.  POA  Network  reasoned  that  from  their  past  experience  with  user  support  requests,  users  tend  to mistakenly  send  tokens  only  to  the  proxy  contract,  since  only  its  address  is  being  publicly  advertised. Implementation  contract  is  \u201chidden\u201d  from  regular  users,  so  they  are  unlikely  to  send  tokens  to  that address.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Proxy/implementation Separation", "body": "   The proxy takes care of the zero hashes initialization. To be consistent, this logic should belong into  the implementation contract.   The admin is able to act on both the proxy and implementation logics. It is usually a good practice to  separate roles of proxy from roles of implementation.  POA network is aware of this note and explained that this is the intended behavior.  POA Network - SBC Deposit -   11  NoteVersion1NoteVersion1NoteVersion1          \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Asymmetrical Norm in Price Update Threshold", "body": "  In the tweak_price function the norm value is calculated to determine whether the distance between price_oracle  and  price_scale  is  sufficiently  large  so  that  a  price  update  should  be  tried.  To calculate the norm, the ratios between the price_scale and price_oracle are used. However, the ratios aren't treated symmetrically, i.e. if price_oracle = price_scale * 1.1 then the value 0.1^2 is added to the norm, but if the ratio is reversed, price_oracle * 1.1 = price_scale, then the value 0.09^2 is added. This means the price update is more sensitive to changes where the price oracle is too high, than when it is too low.  Acknowledged:  As typical differences between price_scale and price_oracle are between zero and five percent, the  effect  is  not  as  large.  Hence,  Swiss  Stake  GmbH  decided  to  not  make  any  more  changes  at  the moment  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Missing Boundary or Sanity Checks When", "body": " Initializing  Most  variables  have  implicitly  or  explicitly  enforced  minimal  and  maximal  values  or  should  not  take certain values like address zero. These are enforced when changing the values or given the ownership through a claiming scheme. However, there are no sanity checks or any checks at all when initializing the contract. Mistakes can happen and silently set one of the values to an obviously incorrect value.  Swiss Stake GmbH - Tricrypto -   9  DesignCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedDesignLowVersion3AcknowledgedDesignLowVersion1Acknowledged                 \fAcknowledged  Swiss Stake GmbH is aware of the issue and confident no deployment errors will happen. In case of a factory contract the issue needs to be reconsidered.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Potential Gas Savings in tweak_price", "body": "  The following code is present in the tweak_price function:  xp: uint256[N_COINS] = empty(uint256[N_COINS]) xp[0] = D_unadjusted / N_COINS for k in range(N_COINS-1):     xp[k+1] = D_unadjusted * 10**18 / (N_COINS * price_scale[k]) xcp_profit: uint256 = 10**18 virtual_price: uint256 = 10**18  these   Most  of  condition old_virtual_price  >  0  is  true.  Hence,  these  variables  could  be  moved  inside  of  the  condition  to save gas in case the condition evaluates to false.  (except  xcp_profit)  are  only  used  when   variables   the   Acknowledged  Swiss  Stake  GmbH  acknowledges  the  issue  with  the  reasoning  that  gas  savings  are  not  significant enough to make a change.  Swiss Stake GmbH - Tricrypto -   10  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Certain Token Combination Cause Numerical Errors   -Severity Findings   Mismatched Bounds    Event Information Missing    Parameter Check Missing    Admin Fees Can Be Claimed Retroactively    Packed Getters Can Be More Restrictive    Slight Code Simplification   0  0  1  6  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Certain Token Combination Cause Numerical", "body": " Errors  If one of the tokens has very few decimals, e.g. Gemini USD which has 2 decimals, and another token either has more than 18 decimals or a fairly low token value, severe numerical errors can arise.  Example:   Token 0: Gemini USD (GUSD), 2 Decimals   Token 1: Another Token (AT), 18 Decimals, 1 AT = 0.005 USD  An exchange of 10,000 GUSD to 2,000,000 AT takes place. Note that the amounts don't matter as the error will occur based on the ratio. The price is computed as:   p = dx * 10**18 / dy   with dx = 10,000 * 10** 2   and dy = 2,000,000 * 10**18   hence, p = 0  In this case the calculated price is zero, which triggers no special checks or fallbacks.  This  situation  PRICE_PRECISION_MUL of 10**8.  is  even  more   likely  due   to   the  packing  of  calculated  prices  and   the  used  Another Example:   Token 0: USDC, 6 Decimals   Token 1: Another Token (AT), 18 Decimals, 1 AT = 1.00 USD  Swiss Stake GmbH - Tricrypto -   11  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected        \fAn exchange of 10,000 USDC to 10,000 AT takes place. Note that the amounts don't matter as the error will occur based on the ratio. The price is computed as:   p = dx * 10**18 / dy   with dx = 10,000 * 10** 6   and dy = 10,000 * 10**18   hence, p = 10 ** 6  However, during packing this price will be divided by 10**8 and hence become 0.  Overall, the project has a good test suite, but it would benefit from tests containing token contracts with different decimals.    The price calculation was refactored and changed. The token amounts are now scaled to 18 decimals always instead of relative to the other token.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Mismatched Bounds", "body": "  The minimum and maximum values for A in the swap contract and the math contract do not match. In fact, the bounds in the math contract are more restrictive, meaning it's possible to ramp to a new value such that the math contract will revert all calls to newton_y and newton_D, basically locking the system until a valid value for A is set. Additionally, the maximum value for gamma also is mismatched, but the bounds are more restrictive in the swap contract, which does not cause any issues.    The code was corrected to make sure that the bounds of the math contract and the swap contract match.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Event Information Missing", "body": "  The  CurveCryptoSwap  contract  emits  different  events.  When  parameter  ramping  starts,  a RampAgamma  event  is  emitted.  However,  contrary  to  expectations  based  on  the  name,  it  contains  no information about gamma.    The relevant information was added to the RampAgamma event.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Parameter Check Missing", "body": "  Swiss Stake GmbH - Tricrypto -   12  DesignLowVersion3CodeCorrectedDesignLowVersion2CodeCorrectedDesignLowVersion2CodeCorrected                        \fSystem parameters can be updated by the administrators of the system. When being updated the new values are checked. The price_threshold and the mid_fee can both be updated, however, the fact that:  assert new_price_threshold > new_mid_fee  will only be checked when the price_threshold is updated and not when mid_fee is updated.    The issue was resolved through refactoring.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Admin Fees Can Be Claimed Retroactively", "body": "  When users see the admin_fee variable of the pool being 0 they will probably assume that no admin fees are being charged at the moment. However, this is not correct. Let's consider the following scenario:  Time Action  0  10  11  12  the pool is started with admin_fee = 0  numerous swap have occurred and xcp_profit has grown  the admin fee is set to 1% using commit_new_parameters and apply_new_parameters  the function claim_admin_fees is called  Users might expect that the admin fees will only be claimed for the time period of 11-12. However, admin fees will be claimed for the time period 0-12. This is because xcp_profit_a hasn't been updated in the meantime.  Code corrected  When changing the admin fee, the admin fees are claimed for the period until the change. Admin fees are only paid for the period beginning at the last time they were claimed. Hence, the issue is resolved.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Packed Getters Can Be More Restrictive", "body": "  three   to  access  packed  values:  price_oracle,  price_scale,  and There  are  last_prices. All three functions take an integer as input and retrieve the value at the respective offset. They make sure that the provided integer is:  functions   assert k < N_COINS  However, k == N_COINS - 1 is not a valid input for any of these functions and could also be blocked.  Code corrected  A check to validate k < N_COINS - 1 has been added.  Swiss Stake GmbH - Tricrypto -   13  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f6.7   Slight Code Simplification  Within the claim_admin_fees function there is the following code:  frac: uint256 = vprice * 10**18 / (vprice - fees) - 10**18 total_supply: uint256 = CurveToken(token).totalSupply() claimed: uint256 = CurveToken(token).mint_relative(owner, frac) total_supply += claimed  During mint_relative the totalSupply will be updated. Hence, it could also be queried once after the call to mint_relative instead of querying it before and then updating it later.  Code corrected  The first total supply query was removed and the total supply is queried after the update.  Swiss Stake GmbH - Tricrypto -   14  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  minor  findings  that  should  be  noted  and  considered  for  further development, but don't necessarily require an immediate code change.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Possible Price Manipulations", "body": "  We see the following price manipulations as possible:  1. Pushing  price_scale  towards  price_oracle.  In  case  a  user  wants  to  perform  a  larger exchange and the price inside the price_oracle is significantly better for that exchange than the price inside price_scale, then the user can push price_scale towards price_oracle using small  trades.  This  works  as  the  update  for  price_scale  only  depends  on  its  distance  to price_oracle not on previous actions within the same block.  2. The price_oracle is only affected by the last price seen in each block. Hence, big exchanges can be \"hidden\" from the price_oracle if they are followed by other exchanges with a different rate. Note that these trailing exchanges can be way smaller. Such trailing exchanges, if reliably inserted, allow full control over the price_oracle and thereby (as mentioned in the previous comment) also over price_scale.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Potential Gas Saving for Balanced Liquidity", "body": " Additions  In  case  last_prices  did  not  change  because  liquidity  was  added  in  the  current  pool  ratios,  the following code part could be skipped.  __xp: uint256[N_COINS] = _xp     dx_price: uint256 = __xp[0] / 10**6     __xp[0] += dx_price     for k in range(N_COINS-1):         self.last_prices[k] = price_scale[k] * dx_price / ...  However, it is unclear whether this is a worthwhile addition as a perfectly balanced liqudity addition will be a rare case unless the UI encourages it to save gas costs.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Splitting up Exchanges", "body": "  For users it can be beneficial to split up a larger exchange into multiple smaller exchanges in order to save fees. Depending on the price constellation and the gamma value they can remain in the \"flat\" area of the curve and hence save fees. This is of course detrimental to the liquidity providers. The usefulness of the split depends on the gas costs and the curve parameters.  Swiss Stake GmbH - Tricrypto -   15  NoteVersion1NoteVersion1NoteVersion1            \f7.4   Supported Tokens  There  is  are  variety  of  different  token  implementations  on  the  Ethereum  blockchain.  Using  tokens  with unusual behavior will lead to unexpected changes of the curve or put the smart contracts into a bad state. In particular, the following token types will not work:   rebasing tokens, where balances can change without transfers. These tokens will lead to incorrect  accounting.  tokens with transfer fees. These tokens will lead to incorrect accounting.  tokens with incorrect ERC20 implementations.  tokens with more than 18 decimals  tokens with more than one address  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   The General Case of n Token Versus A", "body": "  The  audit  was  scoped  for  the  case  n=3  tokens.  Nonetheless,  we  like  to  highlight  our  concerns  for  a bigger  n.  The  contracts  are  written  very  generic  for  the  case  of  n  tokens.  However,  the  n  cannot  be simply increased. As an example, with larger n space for the packed variables becomes smaller. Hence, such cases need to be tested carefully.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Variable Naming", "body": "  Naming variables in a clear and understandable way supports the understanding of complex projects like this. Most variables have self explaining names. But some are confusing or used inconsistently like the use  of  x  and  xp.  The  value  (product  of  price  and  amount)  of  a  pool  token  is  usually  denoted  with  xp. However,  the  CurveCryptoMath3  contract  often  does  not  follow  this  naming  convention  consistently and  x  in reduction_coefficient which should be fee_gamma.  is  actually  ANN  *  A_MULTIPLIER  or  gamma   is  used.  Furthermore,  A  which   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   Vyper Is Still Beta", "body": "  Even though Vyper is used heavily in the latest DeFi projects (especially AMMs), the Vyper language is still  Beta  software  and  should  be  used  with  care  as  bugs  might  arise.  Nevertheless,  Curve  and  other AMMs have used recent Vyper versions successfully.  Swiss Stake GmbH - Tricrypto -   16  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   BatchTrade Should Revert on Error", "body": "  The  batchTrade  function  takes  a  revertOnError  config  parameter.  When  it  is  set  to  false,  the contract will not always revert on error. Instead, it will send the input tokens back to the caller. This could result in tokens remaining on the ThreeOneThirdAdapter.  In most cases, the failed BatchTrade will revert anyway, due to Enzyme's minIncoming check.  To  ensure  no  funds  can  be  left  on  the  adapter,  it  should  only  be  possible  to  call  batchTrade()  with revertOnError set to true.  CS-EZTOT-001    The revertOnError parameter has been removed from the enzyme input list. batchTrade() is now always called with revertOnError set to true.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Inaccurate minToReceive Computation", "body": "  The fee charged in 31Third protocol is computed and rounded down as:  feeAmount = (_receivedAmount * feeBasisPoints) / 10000;  CS-EZTOT-002  As  a  result,  parseAssetsForAction() the minimum amount to receive after fees is rounded down:  the  minimum  amount   to  receive  after   fees  will  be  rounded  up.  However,   in  Avantgarde Finance - Enzyme 31Third Adapter -   11  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected               \fassetChanges = assetChanges.addItem(int256(trades[i].minToReceiveBeforeFees *     (10000 - feeBasisPoints) / (10000)));  As a result, the amount to receive after fees will be slightly inaccurate.    The assetChanges calculation now correctly rounds up instead of down.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Redundant Pragma", "body": "  CS-EZTOT-004  ABIEncoderV2  and ThreeOneThirdActionMixin. After solidity v0.8.0, ABI encoder v2 is activated by default, thus the following pragma has no effect.  ThreeOneThirdAdapter   declared   explicitly   in   is   pragma experimental ABIEncoderV2;    The redundant pragma was removed.  Avantgarde Finance - Enzyme 31Third Adapter -   12  InformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Rebasing Tokens With Transfer Loss Are Not", "body": " Supported  The BatchTrade contract does pre- and post-balance checks when transferring tokens. This ensures at least fromAmount will be received.  CS-EZTOT-003  function _claimAndApproveFromToken(IExchangeAdapter, _exchangeAdapter,     Trade memory _trade) private {     if (_trade.from != ETH_ADDRESS) {         uint256 fromBalanceBefore = _getBalance(_trade.from);         IERC20(_trade.from).safeTransferFrom(             msg.sender,             address(this),             _trade.fromAmount         );         uint256 fromBalanceAfter = _getBalance(_trade.from);         if (fromBalanceAfter < fromBalanceBefore + _trade.fromAmount) {             revert NotEnoughClaimed(_trade, _trade.fromAmount,                 fromBalanceAfter - fromBalanceBefore);         }          IERC20(_trade.from).safeIncreaseAllowance(             _exchangeAdapter.getSpender(),             _trade.fromAmount         );     } }  However,  this  check  may  revert  on  transferring  rebasing  tokens  such  as  stETH.  Due  to  the  shares  to underlying  conversion,  there  may  be  1-2  wei  loss  during  the  transfer  and  the  receiver  will  receive  less than what is passed to safeTransferFrom(). A similar check is also performed in _callExchange.  This means that tokens such as stETH cannot always be traded using BatchTrade.  The  31Third  docs  explicitly  state  that  fee-on-transfer  tokens  are  not  supported,  but  does  not  mention rebasing tokens.  31Third responded:  The 31Third backend is aware of this. This will also be adressed in v2 of the 31Third protocol.  Avantgarde Finance - Enzyme 31Third Adapter -   13  InformationalVersion1Acknowledged      \f7.2   Replayable TradeSigner Signature  CS-EZTOT-005  The  BatchTrade  contract  (out  of  scope)  has  a  _preTradeCheck,  which  verifies  that  the to, tradeSigner  has  minToReceiveBeforeFees, and data.  fromAmount,   spender,   signed   from,   fields:   trade   the   The signed fields:   Do not contain the domain separator.   Are not bound to a msg.sender.   Do not contain a nonce or expiration timestamp.  As a result, a signature can be reused in multiple ways:   One user can reuse the signed trade data from another user.   A trade data signed for Ethereum contracts can be replayed and accepted by contracts on another  chain (e.g. Polygon) if they share the same tradeSigner.  Note that the same address may contain different code on different chains.  These scenarios should be carefully analyzed on 31Third protocol to ensure no unintended behavior is possible.  Risk accepted:  31Third responded:  Since only fund managers can rebalance their Enzyme funds this issue can be neglected.  Additionally, 31Third stated that they would change the signer on Polygon to be a different address than the one on Ethereum. This mitigates the cross-chain signature replay.  Avantgarde Finance - Enzyme 31Third Adapter -   14  InformationalVersion1RiskAccepted    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   The Adapter Should Not Be a Feeless Wallet", "body": " on 31Third BatchTrade  The  owner  of  the  31Third  BatchTrade  contract  has  the  privilege  to  set  feeless  wallets.  An  address registered as a feeless wallet has their fees waived in batch swaps.  In  addition  to  the  Enzyme  Integration  Manager,  anyone  can  use  the  adapter  for  batch  swaps,  as  it  is permissionless.  31Third should not set the adapter as a feeless wallet, otherwise anyone can use the adapter to trade without fees.  Avantgarde Finance - Enzyme 31Third Adapter -   15  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Solv's BUYER_PAY Fee Pay Type Is", "body": " Unsupported  When buying vouchers from the marketplace, fees are paid. Note that Solv has two fee pay types such that either the buyer or the seller pays fees. If the buyer pays, the fee is added to the amount transferred from  the  buyer.  Note  that  Solv's  internal  function  _buy()  will  transfer  transferInAmount  from  the buyer which is defined as amount_.add(fee_).  The  external  position  for  the  buyer  side  does  not  consider  that  which  leads  to  the  following consequences:  1. Action BuySaleByAmount is not supported if the fee type is BUYER_PAY as the approval made will  be insufficient.  2. Action BuySaleByUnits is not supported if the fee type is BUYER_PAY as the funds sent from the  vault will not be sufficient to perform the action.  with the exception that if some unreconcilled funds are available to the external position, the funds could be sufficient to perform the action.  Code partially corrected:  1. Not corrected: Note that buying by amount on Solv will not transfer in the passed in amount but the passed  in  amount  plus  fees.  However,  BuyByAmount  does  not  consider  fees.  See  the  code  of SolvConvertibleMarket.sol  here https://etherscan.io/address/0x29935f54a45f5955ad7bc9d5416f746c3d1b9d69 on line 502.  file   if (vars.feePayType == FeePayType.BUYER_PAY) {   vars.transferInAmount = amount_.add(fee_);   ...} ...  Avantgarde Finance - Sulu Extensions V -   15  DesignCorrectnessCriticalHighMediumLowCodePartiallyCorrectedRiskAcceptedCorrectnessLowVersion1CodePartiallyCorrectedRiskAccepted              \fERC20TransferHelper.doTransferIn(       sale_.currency,       buyer_,       vars.transferInAmount   );  Ultimately, insufficient funds could be moved and the approval given to Solv could be insufficient.  2.  The code has been adapted such that the fee is in included in the transferred in  amount.  Note  that  the  fee  computation  made  for  the  BuyByUnits  action  could  be  off.  There  is  a  special  case where  the  voucher's  underlying  could  be  also  the  currency.  In  such  situations  the  fee  is  computed differently and is based on repoFeeRate instead of the market's feeRate.  Risk accepted:  Avantgarde Finance states the following:  the Solv team says that they will upgrade to the version of `SolvConvertibleMarket` that is in their GitHub repo (b207d5e), which fixes this issue (buyer fee is deducted from `amount`, and there is no longer a `repoFeeRate`). The Enzyme Council will assure that the upgrade has occurred before adding the external position type. Even if no upgrade were to occur, the worst case is that `BuySaleByAmount` will revert when there is a buyer fee, which does not result in value loss for the fund.  Avantgarde Finance - Sulu Extensions V -   16    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Solv Issuer Double Accounting   -Severity Findings   Full Balance Is Pushed on Reconciliation    Offer ID and Voucher Mismatch    Solv Finance: No Support for Raw ETH as Currency    Solv Issuer Ignores Possibly Withdrawable Voucher Slots    getManagedAssets for Solv Buyer Side Reverts if Maturity Not Reached   -Severity Findings  Incomplete NatSpec for ManualValueOracleLib.init()    assetsToReceive Not Containing Assets   0  1  5  2  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Solv Issuer Double Accounting", "body": "  The  Solv  Issuer  external  position  keeps  track  of  the  offered  vouchers  on  the  convertible  offering marketplace. To compute their values it sums up  1. The   token  amounts   that  could  be  withdrawn  by   the   issuer  with   internal   function  __getWithdrawableAssetAmounts.  2. The  token  amounts  that  could  be  claimed  in  case  some  units  are  still  held  with  internal  function  __getOffersUnderlyingBalance()  3. The unreconciled token amounts.  __getWithdrawableAssetAmounts() iterates over all offers and further iterates over all issuer slots of the external position. There is a possibility of accounting withdrawable amounts multiple times.  for (uint256 i; i < offersLength; i++) {     // ...     ISolvV2ConvertibleVoucher voucherContract = ISolvV2ConvertibleVoucher(         INITIAL_CONVERTIBLE_OFFERING_MARKET_CONTRACT.offerings(_offers[i].offerId).voucher     );     ISolvV2ConvertiblePool voucherPoolContract = ISolvV2ConvertiblePool(         voucherContract.convertiblePool()     );     uint256[] memory slots = voucherPoolContract.getIssuerSlots(address(this));     // ...  Avantgarde Finance - Sulu Extensions V -   17  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedLowCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected         \f    for (uint256 j; j < slotsLength; j++) {         (uint256 withdrawCurrencyAmount, uint256 withdrawTokenAmount) = voucherPoolContract             .getWithdrawableAmount(slots[j]);         // logic for summing up         // ...  Consider the following example:  1. First offer is created with the voucher being X such that it has slot id 1.  2. Second offer is created with the voucher being X such that it has slot id 2.  3. The above code is executed.  4. The convertible pool of the voucher gives the slots 1 and 2.  5. The withdrawable amount is added twice since the inner loop for both offers will iterate over slot ids  1 and 2 and add the withdrawable amounts twice.  Ultimately, the withdrawable amounts may be added multiple times in the evaluation.    Now, not only offers are tracked but also issued voucher addresses. Hence, estimating the withdrawable amounts is done by iterating now over the issued voucher addresses which do not contain duplicates.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Full Balance Is Pushed on Reconciliation", "body": "  To  handle  direct  token  transfers  to  the  loan  contract  as  repayments  (and  to  handle  arbitrary  tokens received),  Avantgarde  Finance  introduces  a  reconciliation  functionality  for  arbitrary  loans,  which  allows moving  arbitrary  tokens  received  (e.g.,  insurance  payments)  to  be  moved  to  the  vault.  Furthermore,  it considers all surplus balance (compared to the borrowable amount) of the loan token as a repayment. However, it always moves the full loan token balance to the vault. While this makes sense when closing the vault, it may break the loan's logic when action reconcile is executed (e.g., borrowable amount > 0 but borrows are impossible).    Reconciliation  for  the  Reconcile  action  and  reconciliation  for  the  Close  action  are  now  performed differently.  A  boolean  _close  argument  was  added  to  the  __reconcile  function  to  make  this distinction.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Offer ID and Voucher Mismatch", "body": "  When  buying  an  offer  from  the  Solv  IVO,  the  fund  manager  can  specify  the  voucher  address  and  the offering  ID.  However,  the  voucher  address  could  mismatch  with  the  offer's  voucher  stored  in  the Offering struct.  Consider the following scenario:  1. Fund manager inputs an offer id such that Offer.voucher and the input voucher mismatch.  Avantgarde Finance - Sulu Extensions V -   18  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f2. The  SolvV2ConvertibleBuyerPositionParser  specifies  Offer.currency  as  the  asset  to  transfer  while specifying the amount to transfer as  uint256 amount = uint256(units).mul(voucherPrice).div(10**uint256(market.decimals));  3. The  nextTokenId()  is  queried  on  the  wrong  voucher  and  the  contract  maximum  approval  is  given to the IVO market.  4. buy() is called on the IVO market. As long as the amount computed in step 2. is sufficient, buying  will succeed.  5. The approval is revoked.  6. The input voucher and the token id from step 3 are pushed on the position's offers array.  While it requires an error by the fund manager, it could have consequences such as  tracking of a wrong voucher and token id leading to wrong estimations of the total value,   stuck tokens due to high amounts being moved also leading to wrong fund evaluations,   being stuck with the wrong voucher and token id   potential of double tracking of voucher and token id  Ultimately, to buy an offering it could be sufficient to specify solely the units and the offering id.    The voucher address is not an action argument anymore for buying from IVOs but is retrieved from the offering. Hence, the position parser and the position logic have been adapted accordingly.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Solv Finance: No Support for Raw ETH as", "body": " Currency  Raw ETH is not supported as a currency for the Solv convertible vouchers. This is problematic because Solv supports ETH through the doTransferOut function in the ERC20TransferHelper library, which uses a special constant address ETH_ADDRESS for such raw currency transfers. Given the lack of sanity checks for the assets in a voucher, it could be possible that such a voucher becomes unredeemable (e.g. claim action while fund currency is ETH).    The function __validateNotNativeToken was added to verify that the asset's address is not equal to the special value NATIVE_TOKEN_ADDRESS.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Solv Issuer Ignores Possibly Withdrawable", "body": " Voucher Slots  Avantgarde Finance - Sulu Extensions V -   19  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                 \fWhen  creating  an  IVO  offer,  a  slot  is  created  for  the  issuer  and  the  offer  which  gives  it  a  uniqueness property  given  the  slot  details.  Action  Withdraw  allows  the  fund  manager  to  claim  assets  from  the voucher contract after maturity while action Remove removes the offer from the offering market such that the overhead underlying for the unsold units is refunded. Moreover, Remove removes the offer from the offers  array  such  that  it  becomes  untracked.  While  it  is  still  possible  to  call  Withdraw,  the  value  of getManagedAssets has dropped even though assets could still be withdrawn.  Consider the following scenario:  1. An offer is created. Some units were sold but not all.  2. The offer can be removed and there are withdrawable amounts. Assume the refund amount is 10 X  and the withdrawable amounts are 10 X and 10 Y.  3. getManagedAssets() return 20 X and 10 Y.  4. Remove is executed. 10 X are moved to the vault proxy.  5. getManagedAssets() returns 0.  6. Withdraw is executed. The fund's value rises suddenly.  In general, such behaviour could be introduced.    Now, not only offers are tracked but also issued voucher addresses. Removing an offer does not remove the issued voucher and, thus, the voucher's slots remain tracked.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   getManagedAssets for Solv Buyer Side", "body": " Reverts if Maturity Not Reached  getManagedAssets  evaluates  the  value  held  by  the  position.  To  do  so,  it  iterates  over  all  vouchers held,  currently  held  or  being  sold,  and  computes  internal  method __getClaimableAmount() which contains the following code:  their  value  with   uint128 settlePrice = poolContract.getSettlePrice(slotId); require(settlePrice > 0, \"Price not settled\");  Note that Solv's convertible pool contract implements getSettlePrice() such that it reverts if maturity has not been reached or if the price is negative. Ultimately, no voucher that has not reached its maturity can be evaluated and hence getManagedAssets() will revert which will block several operations in the Enzyme system. Even if getSettlePrice() did not fail, the second requirement may lead to reverts.  Specification changed:  Avantgarde Finance states:  This is an architectural decision to revert upon price lookup for all Solv vouchers (in both Buyer and Issuer features) that are issued or held prior to maturity, rather than estimate the value of an unsettled voucher. Price-dependent fund functions will revert while any such voucher is issued/held.  Avantgarde Finance - Sulu Extensions V -   20  DesignMediumVersion1Speci\ufb01cationChanged          \f6.7   Incomplete NatSpec for  ManualValueOracleLib.init()  The documentation of ManualValueOracleLib.init() is:  /// @notice Initializes the proxy /// @param _owner The owner of the oracle /// @param _updater The updater of the oracle value  Note that the _description parameter is not documented and, thus, the NatSpec is incomplete.    The description parameter has been added to the NatSpec.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   assetsToReceive Not Containing Assets", "body": "  Both the parsers for Solv V2 Buyer positions and Solv V2 Issuer positions could lead to untracked assets. The library used for adding items to memory arrays, creates a new memory array with the old and new items. However, in some occasions, the return value is not assigned to assetsToReceive after an item is added. Hence, it could be possible the assets remain untracked.  Note that Avantgarde Finance reported the issue.    The return values are assigned.  Avantgarde Finance - Sulu Extensions V -   21  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Arbitrary Loan Powers", "body": "  While  all  addresses  involved  in  the  arbitrary  loan  mechanism  are  fully  trusted,  such  external  positions may give managers very high control about the fund. Some (incomplete) list examples:  1. Stealing funds very easily by giving the full balance as a loan to itself.  2. Manipulating the valuation of the fund to profit by specifying an accounting module that computes  the face value when queried as extremely high.  3. Increase the number of shares by using the loan to invest in the fund.  4. Reentrancy possibilities.  5. Blocking behaviour.  Avantgarde Finance - Sulu Extensions V -   22  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Administrators Can Make Non-Native Tokens", "body": " Native and Native Tokens Non-Native  When the function setCustomTokenAddressPair is called, the following checks are being performed:  require(!isTokenRegistered(_bridgedToken)); require(nativeTokenAddress(_bridgedToken) == address(0)); require(bridgedTokenAddress(_nativeToken) == address(0));  However, there is no check that the _nativeToken is not bridged token, i.e.:  require(nativeTokenAddress(_nativeToken) == address(0));  This can create a weird condition where the bridged token is again a native token. Once this occurs, the bridge fails to function correctly, as the bridged tokens are now handled as native tokens.  Similarly, administrators can also register an existing native token, as a non-native token. Consider the following example:  1. A native token T exists, which has already been bridged and where tokens of type T are locked up  inside the mediator contract.  2. An  administrator  call  setCustomTokenAddressPair  with  T  as  the  _bridgedToken  and  some  other fake token F as the supposedly native token on the other side.  POA Network - OmniBridge - ChainSecurity  9  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedLowAcknowledgedRiskAcceptedRiskAcceptedCorrectnessMediumVersion1RiskAccepted            \f3. The  attacker  transfers  a  lot  of  F  token  (which  can  be  freely  minted)  over  the  brige  and  thereby  unlocks the T tokens.  This allows administrators to steal all native tokens held by the bridge.  However, the overall risk is rather low as only administrators can call setCustomTokenAddressPair.  Risk accepted:  To address this problem, POA Network added a comment saying that the function arguments should be manually validated by the administrator, as no easy solution is available.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Tokens With More Than One Token Address", "body": " Can Be Stolen by Admins  Tokens that have more than one address, through which they can be called, can be stolen when they are bridged. An example for such a token is TUSD. The attack would work as follows:  1. The token is already bridged using the first token address. An amount X has been transferred across  the bridge.  2. An attacker bridges the token using another token address. The attacker also bridges X tokens. Now the mediator balance on the native side is X for both token addresses. However, the actual balance, when queried from balanceOf is 2*X for both of them.  3. The attacker colludes with the administrators, which trigger a call to fixMediatorBalance on the  native side and withdraw X amount of tokens.  4. Then, the attacker can withdraw X tokens, by sending back the bridged tokens.  Overall, turned X tokens into 2*X tokens, when ignoring fees. The attacker managed to withdraw the full amount  of  bridged  tokens.  At  the  time  of  writing  118,000  TUSD  have  been  bridged  which  are  at  risk under such an attack.  Risk accepted:  No  code  changes  were  done.  POA  Network  added  a  warning  comment  to  fixMediatorBalance method.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Documentation Mismatches", "body": "  The following mismatches with the documentation or within the documentation were found:  1. The  definition  of  native   is  different   in   the   code  and   in   the  documentation:  https://docs.tokenbridge.net/about-tokenbridge/features#chain-and-network-definitions  In the code, native refers to the origin of the token contract, in the documentation to the home side of the network.  2. Some documentation items mention a requiredBlockConfirmations of 8 while others mention  12.  POA Network - OmniBridge - ChainSecurity  10  SecurityMediumVersion1RiskAcceptedCorrectnessLowVersion1Acknowledged                \fAcknowledged:  Documentation will be re-worked with help of a technical writer.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Function onTokenTransfer Reentrancy Case", "body": "  The  main  contracts  have  a  lock()  function  with  a  corresponding  variable  that  aims  as  a  reentrancy guard. In case when lock() is true, the onTokenTransfer function will silently accept the funds. This can lead to a reentrancy that can break some invariants of the contract. In case, the callback happens during the safeTransferFrom in the _relayTokens function, the from address can perform a token transfer  to  the  Bridge  contract.  Note  that  the  same  or  a  different  token  can  be  used.  Such  callbacks during  safeTransferFrom  can  occur  with  tokens  that  implement  the  ERC777  or  similar  standards. Because  the  received  tokens  are  silently  accepted  and  _setMediatorBalance  is  not  called,  the mediatorBalance won't track the balance correctly.  Risk accepted:  The described behaviour is acceptable, as ERC-777 tokens are not supported by the OmniBridge.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Incompatible Tokens", "body": "  The following token types are incompatible with Omnibridge:   Rebasing tokens: If the balance of a token can change while it is stored inside the mediator contract, then basic assumptions no longer hold. Hence, such tokens as Ampleforth should not be bridged as the bridging might not be reversible.   Special  transfer  fees:  This  report  already  contains  issues  regarding  \"regular  transfer  fees\",  where upon transfer of X tokens, X-F tokens are transferred, while F tokens are paid to the fee receiver. In case of transfer fees, where upon transfer of X tokens, X+F tokens are subtracted from the senders balance and X tokens arrive at the receiver, the Omnibridge contracts will fail as they do not account for such fees.   Malicious tokens: Obviously, any malicious token contracts that do not follow sensible guidelines so that  for  example,  balances  can  be  arbitrarily  can  freely  manipulated,  cannot  be  bridged  in  a meaningful manner.  Users should be warned not to bridge such tokens.  Risk accepted:  POA Network manually reviewed the most important tokens to ensure their compatibility and will monitor the bridge and the bridged tokens. Furthermore, appropriate warnings will be added inside the UI.  POA Network - OmniBridge - ChainSecurity  11  SecurityLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Decimals in bridgeSpecificActionsOnTokenTransfer Are Not Used    ERC20 Function Calls Ignore Return Values    No Canonical Definition of Calldata for onTokenTransfer    Safe Transfers Are Not Used for All Token Transfers    Transferred Values in Case of Relaying Tokens With Fees   0  0  6   OmnibridgeFeeManager  Fee  Distribution  Reverts  in  Case  of  Tokens  With  Transfer  Fees  -Severity Findings   Code Simplification Possible    Name Collision Among Bridged Tokens With Different Origins   5   Reentrancy Into AMB    Restriction to Static Call    Superfluous Loads From Storage   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Decimals in ", "body": " bridgeSpecificActionsOnTokenTransfer Are Not Used  In  both  Home  and  Foreign  OmniBridge  contracts  the bridgeSpecificActionsOnTokenTransfer function during the token relaying. But this data is used only in few cases within this function:  the  decimals  are  queried   in    Token is not registered and limits need to be initialised.   Token is native to the current side of the bridge and its deployment is not yet acknowledged.  In case of non-native, acknowledged or initialised Tokens the queried decimals won't be used. Because such  cases  are  the  most  common  ones,  the  unused  data  introduces  extra  gas  costs  that  could  be avoided.    POA Network - OmniBridge - ChainSecurity  12  CriticalHighMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected        \fThe  use  of  TokenReader.readDecimals()  was  refactored  as  so  it  is  being  called  only  when deployAndHandleTokens messages are sent.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   ERC20 Function Calls Ignore Return Values", "body": "  The ERC20 specification states:  Callers MUST handle false from returns (bool success). Callers MUST NOT assume that false is never returned!  In some calls to the ERC20 tokens those return values are ignored:   IBurnableMintableERC677Token(_token).mint(address(manager),   fee)   in  _distributeFee function.   IBurnableMintableERC677Token(_token).transfer(address(manager),   fee)   in  _distributeFee function.   IBurnableMintableERC677Token(_bridgedToken).mint(address(this),   1)   in  setCustomTokenAddressPair function.   _getMinterFor(_token).mint(_recipient, _value) in _releaseTokens function.  In most cases that happens during the calls to non-native Tokens that were deployed via the factory. But due  to  the  setCustomTokenAddressPair  function  the  non-native  contracts  can  have  any  behavior and the return values need to be checked explicitly.    All calls to transfer and mint function now check the return values.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   No Canonical Definition of Calldata for ", "body": " onTokenTransfer  The function onTokenTransfer uses inline assembly to read the receiver and calldata from the calldata arguments.  The  assembly  strongly  relies  on  some  assumptions  about  the  argument  encoding  of  the Solidity.  One  of  them  is  that  there  are  no  \"garbage  bits\"  between  the  byte  offset  of  the bytes  calldata  _data  variable  and  the  length  field  of  the  bytes  calldata  _data  argument. This  assumption  will  hold  true  in  most  cases,  but  is  not  guaranteed  to  hold.  This  assumption  can  be eliminated  letting  the  compiler  copy  the  _data  into  the  memory  and  dealing  with  it  there.  Full expectations  about  the  expected  information  in  the  _data  argument  must  be  properly  documented,  to avoid the misinterpretation of the interface.  function onTokenTransfer(     address _from,     uint256 _value,     bytes calldata _data ) external returns (bool) {  POA Network - OmniBridge - ChainSecurity  13  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f  For  the  relevant  onTokenTransfer  function,  the  calldata  location  of  the  _data  variable  was replaced  with  the  memory  location.  Hence,  the  ABI  parsing  is  performed  by  the  compiler  and  only afterwards data is being parsed in inline assembly.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Safe Transfers Are Not Used for All Token", "body": " Transfers  For some transfers of ERC20 Tokens the SafeERC20 functions are not used. This includes:   The function _distributeFee in OmnibridgeFeeManagerConnector contract.   The function distributeFee in OmnibridgeFeeManager contract.  The first case only appears for non-native tokens at the Home side of the bridge, which in most cases should be ERC677 deployed by Factory. But due to the setCustomTokenAddressPair function, there are possible conditions when any other token can be called with this transfer.    All calls to the transfer function were replaced by a safe wrapper.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Transferred Values in Case of Relaying", "body": " Tokens With Fees  In a scenario with token relaying, the _relayTokens function is executed. A user provided _value is then transferred to the bridge contract via safeTransferFrom. If the token has fees on transfer (e.g. USDT-not currently charged, PAXG), the actual transferred value will be smaller than the bridged value. invariant This  Balance of bridge == total supply of bridged token.  effectively   break   the   will     This has been corrected by measuring the actually transferred token amount.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   OmnibridgeFeeManager Fee Distribution", "body": " Reverts in Case of Tokens With Transfer Fees  As part of the internal function _distributeFee of the OmnibridgeFeeManagerConnector contract calls  the  token  contract  to  transfer  or  mint  the  fee  amount  to  the  manager.  In  case  the  relevant  token contract  is  native  to  Home  side  it  might  have  transfer  fees.  Then,  a  value  less  than  fee  will  be  moved during  the  transfer  to  the  OmnibridgeFeeManager.  Later  the  OmnibridgeFeeManager  tries  to distribute this fee amount using distributeFee function. Because the actually transferred value will be  POA Network - OmniBridge - ChainSecurity  14  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                        \fsmaller in case of Tokens with transfer fees, the OmnibridgeFeeManager will not have enough assets to perform the reward distribution with the required values.  Hence, the whole transaction will fail and such tokens cannot be moved across the bridge.    The code has been rewritten so that  1. The  OmnibridgeFeeManager  determines   the  amount  of   fees   to  distribute  by  calling  token.balanceOf(address(this)).  2. Failure  of  the  transfer/mint  operation  during  the  fee  distribution  will  not  fail  the  Omnibridge  message processing.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Code Simplification Possible", "body": "  The following code can be simplified:  if (_token == address(0xb7D311E2Eb55F2f68a9440da38e7989210b9A05e)) {     // hardcoded address of the TokenMinter address     return IBurnableMintableERC677Token(0xb7D311E2Eb55F2f68a9440da38e7989210b9A05e); } return IBurnableMintableERC677Token(_token);  The if clause can be entirely omitted.  Specfication changed:  Before the OmniBridge is deployed for the ETH-xDAI instance the contract address in this check can be replaced  with  the  actual  minter  0x857DD07866C1e19eb2CDFceF7aE655cE7f9E560d  of  the  STAKE token  on  the  xDai  chain.  For  other  bridges  this  check  is  either  removed  at  all  or  did  not  have  any significant impact. A comment was added into the code to bring more clarity why this check is needed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Name Collision Among Bridged Tokens With", "body": " Different Origins  When  the  bridge  creates  token  contracts  on  the  Home  chain,  the  \"  on  xDai\"  string  is  appended  to  the Foreign token name. In case of multiple bridges to different Foreign chains, different tokens that have the same  name  on  different  Foreign  chains,  will  have  same  names  on  the  Home  chain.  As  an  example, \"1INCH Token\" from Ethereum Mainnet and Binance Smart Chain will both have the \"1INCH Token on xDai\"  name  on  the  Home  chain.  While  that  has  no  direct  code-related  problems,  this  increases  the human error chance during the user interactions.    POA Network - OmniBridge - ChainSecurity  15  DesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                \fNewly deployed Omnibridge contracts are using \"from X\" names where X is the respective blockchain. The Blockscout interface also renames such tokens in the UI. Unfortunately, it is not possible to change token names for already existing tokens. However such collisions are being mitigated in the UI.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Reentrancy Into AMB", "body": "  When  the  Arbitrary  Message  Bridge  contract  receives  a  message  from  the  other  side,  the  following  is performed code is used to execute the message call:  setMessageSender(_sender); setMessageId(_messageId); setMessageSourceChainId(_sourceChainId);  ...  bool status = _contract.call.gas(_gas)(_data); setMessageSender(address(0)); setMessageId(bytes32(0)); setMessageSourceChainId(0);  The  called  contracts  can  query  the  information  such  as  messageId  and  messageSender.  These information provide important authorization for the called contracts. As there is no reentrancy guard on this function, this code can be reentered in the following way:  1. Call A is made, correct information for A is available  2. A triggers the reentrancy and call B is made, now B is executing and the correct information for B is  available  3. The call B completes and the information are reset to 0  4. The execution of A continues, but now the queried information will be 0  Hence,  it  is  possible  that  during  the  execution  of  a  passed  message  the  wrong  context,  namely  0  is returned  when  queried  from  the  AMB  contract.  Furthermore,  events  are  emitted  in  an  interlaced  order which might confuse connected systems.  Please note the AMB contracts were outside of the scope of this review, however, we still note this as it can affect the OmniBridge.    The  issue  was  fixed  in  https://github.com/poanetwork/tokenbridge-contracts/pull/577.  It  ensures  that  no other message relay is currently being processed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Restriction to Static Call", "body": "  The contract contains the following code to determine the upgradabilityOwner:  address(this).call(abi.encodeWithSelector(UPGRADEABILITY_OWNER))  However, this function is defined as a view function:  POA Network - OmniBridge - ChainSecurity  16  SecurityLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                \ffunction upgradeabilityOwner() external view returns (address);  Hence, a staticcall can be used to avoid unexpected state modifications.    The call was replaced with a staticcall.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Superfluous Loads From Storage", "body": "  The Omnibridge contracts sometimes contain code like this:  require(!bridgeContract().messageCallStatus(_messageId)); require(bridgeContract().failedMessageReceiver(_messageId) == address(this)); require(bridgeContract().failedMessageSender(_messageId) == mediatorContractOnOtherSide());  As  there  is  a  storage  load  (SLOAD)  inside  the  bridgeContract()  function,  this  SLOAD  will  be executed  three  times  in  this  case.  Due  to  the  about-to-be  introduced  EIP-2929  the  additional  costs  of extra SLOADs from the same location are significantly lowered, but it could still be avoided to do it.    The return value of bridgeContract() was saved in a local variable to avoid repeated calls.  POA Network - OmniBridge - ChainSecurity  17  DesignLowVersion1CodeCorrected        \f7   Notes  We leverage this section to highlight potential pitfalls which are fairly common when working Distributed Ledger Technologies. As such technologies are still rather novel not all developers might yet be aware of these  pitfalls.  Hence,  the  mentioned  topics  serve  to  clarify  or  support  the  report,  but  do  not  require  a modification  inside  the  project.  Instead,  they  should  raise  awareness  in  order  to  improve  the  overall understanding for users and developers.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Differing Token Values", "body": "  The OmniBridge has limits on transfers per token. This means that only a certain amount of tokens can be  transferred  per  transaction  and  per  day.  Generally,  this  limits  are  initialized  as  a  number  of  tokens. Obviously, a certain number of tokens of one type can have a very different value than the same number of tokens from another type. Hence, these limits need to be carefully monitored.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Function requestFailedMessageFix", "body": " Performs Multiple Calls to bridgeContract  When a user detects a failed, bridged message, the function requestFailedMessageFix can be used to  fix  the  failed  call.  Therefore,  three  pieces  of  information  are  needed  which  are  currently  loaded  like this:     require(!bridgeContract().messageCallStatus(_messageId));    require(bridgeContract().failedMessageReceiver(_messageId) == address(this));    require(bridgeContract().failedMessageSender(_messageId) == mediatorContractOnOtherSide());  This code is execute both on Home and Foreign bridges.  Note that there are two levels of inefficiency here. First of all three separate calls are made, even though these information are generally always queried together. Second, this information is spread amount three storage  slots,  and  hence  requires  three  costly  SLOADs,  even  though  two  storage  slots  would  easily suffice, as only 321 bit of data are stored.  However,  as  this  needs  to  be  resolved  within  the  AMB  contracts,  it  is  outside  the  scope  of  this  code review.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Limits Can Be Compressed in Storage", "body": "  There are three storage slots being consumed on both sides of the bridge for the following information:  uintStorage[keccak256(abi.encodePacked(\"dailyLimit\", _token))] = _limits[0]; uintStorage[keccak256(abi.encodePacked(\"maxPerTx\", _token))] = _limits[1]; uintStorage[keccak256(abi.encodePacked(\"minPerTx\", _token))] = _limits[2];  These  information  are  often  accessed  together.  Given  the  value  ranges  they  could  probably  be compressed into two storage slots. This would also provide gas savings on the foreign side as it would avoid a costly SLOAD.  POA Network - OmniBridge - ChainSecurity  18  NoteVersion1NoteVersion1NoteVersion1          \f7.4   Proxy Fallback Redundant Operations  The Proxy contract does some redundant operations, such as:   let ptr := mload(0x40)   mstore(0x40, add(ptr, returndatasize()))  Preserving the free memory slot pointer at 0x40 is important when the assembly code is used together with Solidity code. But in case of the Proxy contract, this can be skipped, as no solidity code is executed after the assembly block.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Redundant Work Performed as Part of ", "body": " totalSpentPerDay  The  function  bridgeSpecificActionsOnTokenTransfer  has  the  following  code,  that  checks  and adjusts the totalSpentPerDay limit for a particular token.  require(withinLimit(_token, _value)); addTotalSpentPerDay(_token, getCurrentDay(), _value);  The code of those 2 functions are quite similar.  function withinLimit(address _token, uint256 _amount) public view returns (bool) {     uint256 nextLimit = totalSpentPerDay(_token, getCurrentDay()).add(_amount);     return         dailyLimit(address(0)) > 0 &&         dailyLimit(_token) >= nextLimit &&         _amount <= maxPerTx(_token) &&         _amount >= minPerTx(_token); }  function addTotalSpentPerDay(     address _token,     uint256 _day,     uint256 _value ) internal {     uintStorage[keccak256(abi.encodePacked(\"totalSpentPerDay\", _token, _day))] = totalSpentPerDay(_token, _day).add(         _value     ); }  The  function  withinLimit,  that  is  executed  first,  reads,  increases  and  checks  limits.  The  function addTotalSpentPerDay  reads,  increases  and  writes  the  increased  value  for  the  limit.  This  is  a  small redundancy that can potentially be eliminated.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Reentrancy Lock Is Gas Inefficient", "body": "  The  main  contracts  have  a  reentrancy  guard.  Setting  and  releasing  this  guard  inside  OmniBridge contracts is done via storage of a boolean true/false.  Please note that using locks which switch between the values 0 and 1 is more expensive than switching between the values 1 and 2 in case of a reverting transaction. However, the correct choice of this values  POA Network - OmniBridge - ChainSecurity  19  NoteVersion1NoteVersion1NoteVersion1            \fin  the  future  will  also  be  affected  by  the  currently  discussed  EIP-3298  which  is  concerned  about  the removals of refunds.  Based on EIP-2929 it would also be beneficial if the reentracy lock value would be packed into the same storage slot with another variable, but that is hard due to the chosen storage layout.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   State of Implementation Contract", "body": "  With  proxied  contracts,  the  state  generally  resides  in  the  proxy  while  the  code  resides  inside  the implementation contract. In principle, the state of the implementation contract is meaningless, unless the code  contains  selfdestruct,  callcode  or  delegatecall  opcodes.  Neither  of  these  opcodes  can  be  found inside the current Omnibridge contracts. However, we would still recommend to make the initialization of the state of the implementation contract part of the deployment scripts, as a best practice to avoid future issues.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   Token Creators Can Avoid Fee Payments", "body": "  Token  contracts  that  are  native  to  the  xDai  side  could  be  programmed  such  that  they  avoid  a  fee payment  to  the  bridge  validators,  e.g.  by  simply  ignoring  transfer  calls  to  and  from  the  fee  manager. Furthermore, existing tokens could be wrapped to avoid fees. However, as the fees are fairly low and as such tokens could be blocked on the bridge, the risk appears to be very low.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   Token With Transfer Restrictions", "body": "  Certain Tokens, especially regulated stable coins, have transfer restrictions, blacklists or even the power to seize funds. If some tainted funds would be bridged, the entire bridge balance of that particular token might become frozen or could get seized. As with any other contract where funds are deposited, users need to be aware of these potential risks.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.10   Weak Randomness", "body": "  The following function is used to pick a random number:  function random(uint256 _count) internal view returns (uint256) {     return uint256(blockhash(block.number.sub(1))) % _count; }  This is generally a bad way to sample randomness as, especially in the case of xDai, different attacks exist.  Furthermore,  there  randomness  is  extremely  slightly  skewed.  In  this  context,  however,  the randomness only serves to pick the account the receives the fee dust. As the corresponding monetary value is generally tiny, it seems acceptable.  POA Network - OmniBridge - ChainSecurity  20  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f7.11   onlyMediator Modifier  There is an onlyMediator modifier inside the BasicAMBMediator contract. It performs two checks:   Check that the call comes from AMB bridge contracts.   Check that the forwarded by AMB bridge the message sender is a mediator on the other side.  There are multiple concerns about this modifier.  Firstly, the MediatorOwnableModule has a modifier with the same name that performs only one check -  that  the  message  comes  from  OmniBridge  extension  contract.  That  can  potentially  cause misunderstandings and human errors.  Secondly,  it  seems  that  the  virtual  message  sender  is  always  needed.  This  is  currently  being  queried through  a  call  to  bridge.messageSender().  Here,  for  future  versions  of  the  AMB  protocol  a  more efficient design would be possible where this information is passed along.  /**  * @dev Throws if caller on the other side is not an associated mediator.  */ modifier onlyMediator {     _onlyMediator();     _; }  /**  * @dev Internal function for reducing onlyMediator modifier bytecode overhead.  */ function _onlyMediator() internal view {     IAMB bridge = bridgeContract();     require(msg.sender == address(bridge));     require(bridge.messageSender() == mediatorContractOnOtherSide()); }  POA Network - OmniBridge - ChainSecurity  21  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Execution Data Is Not Validated", "body": "  0  0  2  5  The executors always provide some execution data for the execution of the trigger. However, this data should correspond to the trigger's intention, but is not validated for the most part. Note that it still is limited in its ability to act maliciously because of the post-execution checks.  CS-OazoAutomV2-001  Risk accepted:  Summer.fi accepts the risk.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Execution Reentrancy May Be Possible", "body": "  Commands delegate calls to action smart contracts to act on the user's position. However, some of these action smart contracts can contain logic that would permit other external contracts.  CS-OazoAutomV2-002  Summer.fi - Automation V2 -   13  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedLowCodePartiallyCorrectedRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedSecurityMediumVersion3RiskAcceptedSecurityMediumVersion3RiskAccepted                     \fIn  this  case,  external  contracts  could  contain  malicious  code  that  could  reenter  the  core  contracts  to add/remove triggers, or simply temper with the user's position.  Risk accepted:  Summer.fi accepts the risk.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Future Debt Validation Does Not Take Bounds", "body": " Into Account  In  the  BasicSellCommand,  the  post-execution  debt  is  computed  in  isExecutionLegal()  to  validate that it will be bigger than the dust limit of the cdp's ilk:  CS-OazoAutomV2-003  uint256 futureDebt = (debt * nextCollRatio - debt * wad) /     (trigger.targetCollRatio.wad() - wad);  Note that in this computation the target collateralization ratio is accounted as is and used to predict future debt. However, the post-execution cdp's debt might not exactly correspond to this collateralization ratio, this is the reason behind the existence of the deviation parameter.  This makes it possible for the isExecutionLegal() function to return true even though execution will fail afterward because the debt is smaller than the dust limit.  Code partially corrected and risk accepted:  Now,  the  upper  bound  for  the  collateralization  ratio  is  used.  However,  this  will  yield  the  minimal  value futureDebt  could  reach.  Hence,  the  function  could  return  false  in  some  scenarios  where  the execution could be legal.  However, Summer.fi accepts the risk.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Negative gasRefund Possible", "body": "  gasRefund should be used to decrease the necessary coverage according to the gas refunds. However, it is of type int and, hence could be negative so that the computation  CS-OazoAutomV2-004  uint256(int256(initialGasAvailable - finalGasAvailable) - gasRefund);  could increase the gas used instead of lowering it.  Note that with the current trust model, the executor providing this gas refund value should not be trusted.  Risk accepted:  Summer.fi - Automation V2 -   14  DesignLowVersion1CodePartiallyCorrectedRiskAcceptedCorrectnessLowVersion1RiskAccepted                  \fSummer.fi states that no changes were made since calls come from trusted callers. However, disallowing negative numbers (e.g. by using uint256) could help. Hence, Summer.fi accepts the risk.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Overflow When Computing the Used Gas", "body": "  The cast from int256 to uint256 could overflow in the following code  uint256(int256(initialGasAvailable - finalGasAvailable) - gasRefund);  if gasRefund is greater than the computed gas used.  CS-OazoAutomV2-005  Risk accepted  The  gas  refund  is  limited  now  by  10**12.  However,  this  does  not  protect  against  bad  gasRefund argument since it could still be greater than (initialGasAvailable - finalGasAvailable).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Too Low execCollRatio", "body": "  In BasicSell, the execCollRatio could be below the liquidation ratio. Hence, the trigger validity check could allow an unexecutable trigger to be added.  CS-OazoAutomV2-006  Risk accepted:  Summer.fi replied that the data is validated with the calldata creation on the front-end.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Too Low slLevel", "body": "  In CloseCommand, the slLevel could be below the liquidation ratio. Hence, the trigger validity check could allow an unexecutable trigger to be added.  CS-OazoAutomV2-007  Risk accepted:  Summer.fi replied that the data is validated with the calldata creation on the front-end.  Summer.fi - Automation V2 -   15  CorrectnessLowVersion1RiskAcceptedDesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  2  3  2  14  -Severity Findings   Arbitrary Actions and Storage Manipulations    Executor Could Draw an Unbounded Amount of Coverage   -Severity Findings   Executing a DPM Command Reverts    Removing Arbitrary Triggers Possible    Upgrades Break AutomationBot   -Severity Findings   Possible Reentrancy Through Execution    addRecord() Does Not Unlock   -Severity Findings   Wrong Event Argument   Incorrect Argument for ApprovalGranted Event    Bad Trigger Ids Emitted    Command Validation Functions Can Revert    Contracts Do Not Extend the Interfaces    Group Counter Starts at 2    Left Comments    Missing Validation in AutoTakeProfitCommand    Redundant Approval    Removing Non-Callers Emits an Event    Specification Mismatches    Unequal Array Lengths    Unused Imports    Unused Parameter, Variable and Event   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Arbitrary Actions and Storage Manipulations", "body": "  CS-OazoAutomV2-011  The  owner  of  the  ServiceRegistry  could  perform  arbitrary  storage  manipulations  and  actions  on  any (in  executePermit()  and position.  Namely,  executeCoverage()) allows them to execute arbitrary code in the context of the storage contract. In  the  storage  contract   the  delegatecalls   in   Summer.fi - Automation V2 -   16  CriticalCodeCorrectedCodeCorrectedHighCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion3CodeCorrected         \faddition, a malicious command could be added along with its adapter so as to execute malicious actions on a user's position.  Let's consider different scenarios for understandability reasons:  Modifying storage in AutomationBotStorage:  1. Command X is added to the ServiceRegistry, it is a no-op command and is immediately executable.  2. Adapter X is also added.  3. The owner calls addRecord() to add a record for the command.  4. execute() happens. Arbitrary code is executed during the delegatecall made in adapter X.  Executing a malicious command:  1. Command X is added to the ServiceRegistry, it is a command that can, given a position, unwind all  funds to the owner's address and is immediately executable.  2. Adapter X is also added, its canCall() function always return true.  3. The owner calls addRecord() to add a record for the command and is allowed to do so.  4. execute() happens. Arbitrary code is executed during the execute made in AutomationBot and  funds are stolen.  Ultimately, the service registry owner may self-destruct the contract, change any storage locations, and execute any operations on any position that the AutomationBotStorage has allowance on.  Note that there are many possibilities when adding arbitrary commands and adapter, and the examples listed above are non-exhaustive.  ---    Summer.fi has changed the design. Users approve adapters which are callable by the automation bot.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Executor Could Draw an Unbounded Amount", "body": " of Coverage  CS-OazoAutomV2-026  The typical execution flow of a trigger is  1. Pre-condition checks.  2. Getting the coverage with getCoverage() so that the user pays for the fees.  3. Execution.  4. Post-condition checks.  Note that getCoverage() will typically create additional debt which changes also the collateralization ratio, and that the coverage amount is not bounded upwards.  A  trigger  could  potentially  be  non-executable  before  the  execution  but  become  executable  once getCoverage() has been called.  This gives the executor an ability to execute some triggers on demand.  Further  note  that  there  can  be  other  unforseeable  consequences,  but  they  are  limited  by  the post-execution validation.  Summer.fi - Automation V2 -   17  SecurityCriticalVersion3CodeCorrected        \f created an alternative for getting arbitrary coverage that severly amplifies the The changes in  owners  possibilities.  With  this  new  version,  the  executable  adapters  alway  holds  permissions  for  the position  (if  set  up  correctly),  so  that  it  can  draw  coverage  when  needed.  Now  consider  the  following scenario, where the governance would want to draw excessive coverage on a target position:  1. Governance adds a malicious command along with a malicious security adapter assigned to it. The malicious adapter returns true on canCall calls and the command allows execution but does not perform any operation. They also assign to the command a legit executable adapter, the one that the target position permitted to.  2. Governance adds a trigger record with the trigger data pointing to the target position, and using the  malicious command.  3. Execution occurs (governance has control over the executors) and the excecution adapter is called to get coverage and can (nearly) drain the target position. The maxCoverage variable was passed along the malicious triggerData in step 2, so can be arbitrary.    A user-defined maximum and a payment token has been introduced. The executable adapter is now only granted permissions when getting the coverage.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Executing a DPM Command Reverts", "body": "  A  typical  command  execution  flow  of  AutomationExecutor's  execute()  function  is  as  follows  (some steps are omitted for clarity):  CS-OazoAutomV2-016  1. Giving permissions to the command address  2. Calling the command to execute  3. Disallowing the command  Note  that  when  the  automation  bot  permits  the  command  address,  it  delegates  the  call  to  the  specific adapter.  This  should  work  because  the  automation  bot  was  already  permitted  when  the  trigger  was added.  In the case of the DPMAdapter, the permit() function starts with this line:  require(canCall(triggerData, msg.sender), \"dpm-adapter/not-allowed-to-call\");  This is executed in the context of the AutomationBot, so the msg.sender is still the AutomationExecutor, which has not been permitted by the owner of the proxy. The execution call will fail in all cases except when the owner of the proxy has manually permitted the AutomationExecutor.    Summer.fi changed msg.sender to address(this).  Summer.fi - Automation V2 -   18  Version4DesignHighVersion1CodeCorrected          \f6.4   Removing Arbitrary Triggers Possible  CS-OazoAutomV2-024  addRecord() adds a trigger and allows to replace a given trigger id and data with.  The following check is performed:  require(     replacedTriggerId == 0 || adapter.canCall(replacedTriggerData, msg.sender),     \"bot/no-permissions-replace\" );  However, following issues arise:  1. replacedTriggerData   is  not  validated   to  match   the  replacedTriggerId   (as   in  checkTriggersExistenceAndCorrectness()).  2. The  security  adapter  for  the  new  command  is  used.  However,  the  replaced  trigger  id  may  be  another command that has another adapter.  Users relying on the execution could be liquidated or miss out on profit scenarios.    replacedTriggerData is now checked against the hash of the replacedTriggerId since  . The original adapter is used since   .  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Upgrades Break AutomationBot", "body": "  The split of the storage from the AutomationBot intends to  [...] enable the upgradeability of AutomationBot implementation without the need for migration for all of the triggers.  However, note that the AutomationBot contract is given permissions for the positions but changing the address does not transfer the permissions. Ultimately, no previous triggers can be executed.  CS-OazoAutomV2-030    Now,  the  AutomationBot  does  not  hold  any  permissions.  However,  permissions  are  granted  to  the storage  contract.  Thus,  the  AutomationBot  calls  functions  on  the  storage  contract  that  can  grant commands the necessary rights.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Possible Reentrancy Through Execution", "body": "  CS-OazoAutomV2-015  Summer.fi - Automation V2 -   19  SecurityHighVersion1CodeCorrectedVersion2Version3CorrectnessHighVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected                      \fWhen a caller executes a trigger, the automation bot permits the specific command to act on the target position/cdp  for  the  execution  call  and  removes  this  permission  after  it.  To  execute  a  trigger  the execute() function is called on the command. Note that none of the implementations of this function have access control or reentrancy protection. On execution, external smart contracts that belong to third parties will be called and it can lead to reentrancy possibilities. Entering again the execute() function would then be possible.    Now, the AutomationBot and the commands have reentrancy locks. Given that only a command at a time is granted permissions, this protects commands from being malicously executed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   addRecord() Does Not Unlock", "body": "  addRecord() adds new triggers. It calls lock() to ensure that emitGroupDetails() has the right calldata.  However,  note  that  emitGroupDetails(),  which  unlocks  the  lock  counter,  is  only  called  if addRecord() is used through addTriggers(). Note that this is not necessarily the case. Hence, the contract  could  temporarily  be  locked  by  direct  calls  to  addRecord()  (without  using  the  proxy  actions function addTriggers()). Calling addTriggers() would revert because of the inconsistency between the emit group details and the lockCount.  CS-OazoAutomV2-021    The  lock  is  always  cleared  using  the  new  function  clearLock()  in  addTriggers()  and removeTriggers().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Wrong Event Argument", "body": "  In  the  AutomationBot  smart  contract,  both  events  ApprovalGranted  and  ApprovalRemoved  are emitted  with  the  AutomationBot  address  as  argument,  when  the  permission  is  actually  granted  to  or removed from adapters.  CS-OazoAutomV2-032    The correct argument is now used.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Incorrect Argument for ApprovalGranted", "body": " Event  CS-OazoAutomV2-019  Summer.fi - Automation V2 -   20  CorrectnessMediumVersion1CodeCorrectedCorrectnessLowVersion4CodeCorrectedCorrectnessLowVersion2CodeCorrected                        \fThe  event  ApprovalGranted(bytes  indexed  triggerData,  address  approvedEntity) should pass the approved entity as second argument. In AddTriggers(), the approval is granted to the AutomationBotStorage but the argument specifies the automationBot.  Code corrected  The correct argument is now used.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Bad Trigger Ids Emitted", "body": "  The addTrigger() function triggers a call to emitGroupDetails() with bad trigger ids.  CS-OazoAutomV2-013  Consider the following scenario:  1. addTriggers() is used.  2. firstTriggerId is 0 since no triggers have been added so far.  3. addRecord() is called.  4. appendTriggerRecord() is called. The trigger is added with id 1 and the trigger counter is set to  1. The call returns.  5. addRecord() emits an event with trigger id 1 and returns.  6. addTriggers() sets the local variable triggerIds[0] to 0.  7. An event is emitted with the wrong id.  Ultimately, events with errors are emitted.    The first trigger id is now computed correctly (triggers counter + one).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Command Validation Functions Can Revert", "body": "  Command  smart  contracts  implement  3  different  data/execution  flow  validation  functions  that  return  a boolean:  CS-OazoAutomV2-031   isTriggerDataValid()   isExecutionLegal()   isExecutionCorrect()  All of those are wrapped in a require() in the automation bot so that the trigger data is valid and the pre and post-execution conditions also are.  However,  some  of  these  functions  in  AutoTakeProfitCommand  fail  on  some  conditions  instead  of  just returning false:  1. If the owner of the cdp is the address 0 in isExecutionLegal()  Summer.fi - Automation V2 -   21  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f2. If the trigger execution price is greater than the next price in isTriggerDataValid()    The functions return false now.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Contracts Do Not Extend the Interfaces", "body": "  Most  of  the  contracts  interact  with  each  other  based  on  the  interface  definitions.  For  example,  the addTrigger()  call  BotLike.addRecord()  on  the  AutomationBot.  However,  the  AutomationBot contract  itself  does  not  explicitly  implement  the  BotLike  interface.  Similarly,  other  contracts  do  not implement interfaces.  Without this, there are no compile-time guarantees that the contract will be compatible with the calls to the functions that the interface defines. This can lead to potential runtime errors and exceptions that are hard  to  debug.  It  is  important  to  explicitly  define  that  the  contracts  implement  the  corresponding interfaces, to minimize such errors.  CS-OazoAutomV2-017    The usage of interfaces has been improved.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Group Counter Starts at 2", "body": "  Why does the group counter start at 2 when AutomationBot emits the first TriggerGroupAdded event?  CS-OazoAutomV2-018    The group counter starts now at 1.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Left Comments", "body": "  Several TODOs are left open. Additionally, other comments are left. For example,  or type ? do we allow execution of the same command with new contract - waht if contract rev X is broken ? Do we force migration (can we do it)?  CS-OazoAutomV2-020  Such comments can increase complexity.  Summer.fi - Automation V2 -   22  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  The comments have been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   Missing Validation in", "body": " AutoTakeProfitCommand  The AutoTakeProfitCommand smart contract takes care of closing a cdp when its collateral has reached a certain price. This kind of trigger should not be continuous because of the way this command works.  However, isTriggerDataValid() does not check wether it is or not.  CS-OazoAutomV2-012    Now, only non-continous triggers are valid for AutoTakeProfitCommand.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.16   Redundant Approval", "body": "  The  AutomationExecutor  approves  Uniswap's  router  contract  twice  which  increases  gas  consumption and adds additional complexity.  CS-OazoAutomV2-022    The redundant approval was removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.17   Removing Non-Callers Emits an Event", "body": "  Removing non-callers emits a CallerRemoved event. In contrast, adding callers that are already callers skips the event emission.  CS-OazoAutomV2-023    Only callers can now be removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.18   Specification Mismatches", "body": "  Note that there are multiple specification mismatches:  CS-OazoAutomV2-025  Summer.fi - Automation V2 -   23  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                                \f1. BasicSellCommand  implies  trigger.execCollRatio.wad()  >=  nextCollRatio  which  contradicts the code in the equality case.  2. The documentation describes maxBuyPrice instead of minSellPrice.  3. The  documentation  states  that  Automation  Bot  is  a  stateless  contract.  However,  it  has  a  state  variable lockCount.  4. The  adapter  section  specifies  that  adapters  are  delegatecalled  in  the  AutomationBot  context. However,  the  functions  introduced  functions  executePermit()  and  executeCoverage() changed this behaviour since they are delegatecalled from the storage contract now.  Specification corrected  All 4 points were correct in the documentation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.19   Unequal Array Lengths", "body": "  In  addTriggers(),  the  array  parameters  could  have  distinct  lengths.  The  execution  in  such  cases  is unspecified. Similarly, this holds for removeTriggers().  CS-OazoAutomV2-027    All arrays are not checked against for length.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.20   Unused Imports", "body": "  Some smart contracts have some unused imports, some examples are:  CS-OazoAutomV2-028  In AutomationExecutor:  1. FullMath  2. IExchange  3. ICommand  In BaseMPACommand:  1. AutomationBot  In McdView:  1. ICommand  2. BotLike  Note that this is an incomplete list of examples.    Summer.fi - Automation V2 -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fAll unused imports have been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.21   Unused Parameter, Variable and Event", "body": "  1. The function AutomationExecutor.execute() has an unused parameter cdpId.  2. AutomationExecutor stores the DAI address as an immutable which is unused.  3. The AutomationBot has an event ApprovalGranted that is not used.  4. AUTOMATION_BOT_STORAGE_KEY is unused in AutomationBot.  CS-OazoAutomV2-029    The event ApprovalGranted is now used and the others have been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.22   The CloseCommand Does Not Inherit", "body": " BaseMPACommand  The CloseCommand smart contract does not inherit the BaseMPACommand smart contract even though it executes through the MPA.  CS-OazoAutomV2-014    Inheritance was improved.  Summer.fi - Automation V2 -   25  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Floating Dependencies Version", "body": "  The  versions  of  the  contract  libraries  in  package.json  are  not  fixed.  Please  consider  the  following examples:  CS-OazoAutomV2-009  \"@openzeppelin/contracts\": \"^4.5.0\"  The caret ^version will accept all future minor and patch versions while fixing the major version. With new versions being pushed to the dependency registry, the compiled smart contracts can change. This may lead to incompatibilities with older compiled contracts. If the imported and parent contracts change the  storage  slot  order  or  change  the  parameter  order,  the  child  contracts  might  have  different  storage slots or different interfaces due to inheritance.  In addition, this can lead to issues when trying to recreate the exact bytecode.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Floating Pragma", "body": "  Summer.fi uses a floating pragma solidity ^0.8.13. Contracts should be deployed with the same compiler version and flags that have been used during testing and audit. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example, an outdated compiler version that might introduce  bugs  that  affect  the  contract  system  negatively,  see  https://swcregistry.io/docs/SWC-103 (snapshot).  CS-OazoAutomV2-010  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Unecessary External Calls", "body": "  The  AutomationBot  smart  contract  must  sometimes  call  itself  because  of  the  delegate  logic,  however there are cases where this is not necessary:  CS-OazoAutomV2-008  1. In the emitGroupDetails() function  2. In the addRecord() function  Note that both of these function call automationBot like an external contract, but will not be called in a delegate context.  Summer.fi - Automation V2 -   26  InformationalVersion1InformationalVersion1InformationalVersion4          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   AutomationBot Permission Handling", "body": "  It should be made clear to the user and in the documentation that the functions addTriggers() and removeTriggers() are only helper functions, and that data must be provided in certain ways so that the system works correctly.  For  example,  triggers  will  not  be  able  to  execute  if  a  user  adds  multiple  triggers  that  point  to  different positions/cdps through addTriggers() without manually granting permission to the AutomationBot for each of these (except the first one).  removing  multiple   Also,  through removeTriggers()  will  only  remove  the  allowance  for  the  first  position/cdp  pointed  by  the  trigger  at index 0.  the  removeAllowance   triggers  with   flag  set   true   to   Further,  a  user  could  have  cleared  all  of  their  triggers  but  still  have  some  active  permission  on  the AutomationBot for their positions.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Data for Execution", "body": "  The data for the execution can be freely selected by the callers. There are the following limitations:   Post-conditions of the command must hold.   Selectors are validated in commands.  However, users should be aware that the coverage token can be an arbitrary token (e.g. if Aave position is managed) and, hence, the execution could lead to unwanted risks (e.g. being exposed to very volatile tokens).  Further,  users  should  be  aware  that  the  execution  could  be  configured  so  that  re-executions could occur faster.  Ultimately,  users  should  always  consider  the  possibility  of  bad  execution  data.  However,  note  that  the callers are trusted addresses.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Oracle Not Suitable for On-Chain Usage", "body": "  AutomationExecutor  implements  an  oracle  for  Uniswap  V3  TWAP  prices.  This  is  intended  to  be  used off-chain. Using the oracle on-chain could lead to issues.  First,  the  TWAP  is  hardcoded  to  60  seconds  which  would  allow  for  simple  manipulations.  Second,  the function iterates over a list of pools and tries to choose the biggest one. It does so by selecting the one with the highest WETH balance. However, this is not a safe value for estimating actual pool size. Note that there are some further discrepancies compared to Uniswap V3's reference implementation of price oracle. For example, AutomationExecutor adds one to the TWAP interval array values (which Uniswap  Summer.fi - Automation V2 -   27  NoteVersion1NoteVersion1NoteVersion1          \fdoes not), does not round down to negative infinity (which Uniswap does) and does not have a precision of computation as high as Uniswap in some scenarios.  Generally, the oracle-like getters are not suitable for on-chain usage. Also, the off-chain usage must be done carefully.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   getCoverage() Implications", "body": "  The typical execution flow of a trigger is  1. Pre-condition checks.  2. Getting the coverage with getCoverage() so that the user pays for the fees.  3. Execution.  4. Post-condition checks.  Note that getCoverage() will typically create additional debt which changes also the collateralization ratio.  Users should be aware that in the BasicBuy command, where a precondition is that the collateralization ratio must be above a certain threshold, could technically be violated after getCoverage(). Hence, the execute function could be executed on a vault where the collateralization ratio is below the threshold.  Further  note  that  there  can  be  other  unforeseeable  consequences.  Users  should  be  aware  that  the configuration requires consideration of the coverage.  In  aware of this and configure their positions accordingly.  ,  Summer.fi  repeats  the  precondition  checks  after  getting  the  coverage.  Users  should  be  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.5   getTick Computes the Square Root Price", "body": "  The naming of getTick() suggests that a tick is returned. However, it computes the square root price.  Summer.fi - Automation V2 -   28  NoteVersion1Version4NoteVersion1        \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   EIP-4626 Non-Compliance", "body": "  The  functions  MultiWithdrawalController.maxWithdraw  and  maxRedeem  return  values  greater than 0 when the withdrawals are not allowed in the current status of the protocol. This is in violation of the following rule:  MUST return the maximum amount of assets that could be transferred from owner through withdraw and  not  cause  a  revert,  which  MUST  NOT  be  higher  than  the  actual  maximum  that  would  be accepted (it should underestimate if necessary).  Additionally,  MultiWithdrawalController._globalMaxWithdraw  sets  the  maximum  amount  of tokens  that  can  be  withdrawn  from  a  tranche.  This  maximum  is  determined  by  the  function TrancheVault.totalAssets.  In  Live  state,  this  function  returns  the  current  waterfall  value  of  the tranche which contains the virtualTokenBalance of the entire portfolio, as well as the value of active loans. The returned value can therefore be higher than the actual amount of assets that are available for withdrawal.    MultiWithdrawalController.maxWithdraw  and  maxRedeem  now  return  0  if  withdrawals  are disallowed in the current status of the protocol.  Archblock - Controllers for TrueFi Carbon -   10  CriticalHighMediumLowCodeCorrectedDesignLowVersion1CodeCorrected        \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Redundant Event Emission", "body": "  A manager can configure the floor and the withdrawalAllowed mapping by calling configure. In case  the  parameters  are  the  same  as  the  ones  already  set,  the  execution  of  the  actual  setter  i.e., setFloor and setWithdrawalAllowed, is skipped. However, the manager can call setFloor and setWithdrawalAllowed directly, where there are no checks if the new values are different than the ones stored. In this case, redundant events will be emitted.  Archblock - Controllers for TrueFi Carbon -   11  InformationalVersion1  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   No Asset Conversion", "body": "  MultiWithdrawalController.onRedeem  does  not  check  whether  the  given  assetAmount  of  an exception  matches  convertToAssets(sharesAmount).  If  the  manager  makes  a  mistake  or  a repayment  is  executed  on  the  contract  between  the  time  the  manager  sends  their  multiRedeem transaction and the time the transaction actually executes, the values will be wrong, resulting in either a loss or a gain for the given lender. This behavior is well documented by the specification provided to us.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Redeem Event Emission", "body": "  MultiWithdrawalController.onRedeem  can  be  called  by  any  user  (without  reverting)  using  the following arguments:   sender: The address of the controller contract.   shares: 0.   owner: address(0).  This  emits  a  Redeem  event  every  time.  The  assets  parameter  can  be  completely  arbitrary.  Off-chain systems reading these events should be aware of this behavior.  Archblock - Controllers for TrueFi Carbon -   12  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Note on PR 3211: Fix: Restrict STATICCALL to", "body": " View  CS-VYPER_JANUARY_2023-001  This issue was identified in an unmerged pull request which had not been fully reviewed internally yet, and  consequently  had  a  higher  likelihood  of  having  high  severity  issues  in  it.  It  should  not  be  directly compared  to  merged  pull  requests  to  assess  the  overall  security  of  Vyper.  The  pull  request  was  later abandoned.  Pull Request 3211 fails to fix the problem it is addressing. This PR would want to restrict @pure functions from using staticcall, since pure function should not be able to perform external calls, as they can't be statically checked to be pure.  Instead  of  forbidding  pure  functions  from  using  raw_call,  the  PR  restricts  raw_call  with is_static_call = True to view functions. Both payable and nonpayable functions should also, together with view functions, be allowed to perform static calls.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   EnumT Does Not Implement compare_type", "body": "  Any enum variable can therefore the assigned to any other. This compiles but should not:  CS-VYPER_JANUARY_2023-002  enum A:     a  enum B:     a     b  @internal  Vyper - Vyper compiler -   10  CorrectnessHighVersion1DesignMediumVersion1              \fdef foo():     a:A = B.b  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Function Type_From_Annotation Performs No", "body": " Validation  CS-VYPER_JANUARY_2023-003  Refactored  function  type_from_annotation  introduces  three  vectors  for  type  system  bugs  to  be introduced in the compiler:  1. The context of the annotation (data location) is not checked, which matters for HashMap and  Events.  HashMaps  should  only  be  declared  as  storage  variables  or  values  of  other  hashmaps,  and events should not be a valid type for variables, function arguments, or return types.  2. Does not check that annotations instantiate the type correctly  HashMap, String, DynArray, and Bytes should always be subscripted, however this is not currently enforced.  3. Does not check that the return value from the namespace is a valid type.  The last line return namespace[node.id], will return any namespace element instead of only types: beside types that need subscripts, this could be VarInfos or builtins.  Stricter validation should be performed on the input and outputs of type_from_annotation()  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Function _Check_Iterator_Modification Has", "body": " False Positive and False Negatives  Vyper  disallows  modifications  iterator  _check_iterator_modification python function.  to  an   CS-VYPER_JANUARY_2023-004  in   the  body  of  a   loop   through   the  Because  of  how  the  syntactic  structure  is  checked  to  perform  this  semantic  analysis  step, _check_iterator_modification is susceptible to both false positives and false negatives.  False  negative  example  (this  compiles  but  should  not  because  self.a.iter  is  modified  in  the  loop body):  struct A:     iter:DynArray[uint256, 5] a: A  @external def foo():     self.a.iter = [1,2,3]     for i in self.a.iter:         self.a = A({iter:[1,2,3,4]})  False positive example (this does not compile, but should):  Vyper - Vyper compiler -   11  DesignMediumVersion1CorrectnessMediumVersion1            \fa: DynArray[uint256, 5] b: uint256[10] @external def foo():     self.a = [1,2,3]     for i in self.a:         self.b[self.a[1]] = i  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   HashMap Are Declarable Outside of the", "body": " Storage Scope  The check that HashMaps are declared as storage variable has been suppressed after the frontend type refactor. The following is now commented out:  # if location != DataLocation.STORAGE or is_immutable: #    raise StructureException(\"HashMap can only be declared as a storage variable\", node)  CS-VYPER_JANUARY_2023-005  An  equivalent  check  has  not  been  type_from_annotation() not accepting the DataLocation anymore.  reinstated  elsewhere.  This   issue  originates   from  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Interface Does Not Accept Function Names", "body": " Used for Builtins  Instances  of  InterfaceT  are  instantiated  by  calling  VyperType.__init__()  and  passing  a  list  of members  to  be  added  to  the  type.  The  members  are  validated  through  validate_identifier(), which also checks that they do not collide with the builtin namespace. This is needlessly restricting for external interfaces. A Vyper contract will not be able to call some contracts without resorting to low level calls.  CS-VYPER_JANUARY_2023-006  The following does not compile:  interface A:     def send(): view  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   InterfaceT Does Not Implement Type", "body": " Comparison  Typechecking is not performed between interface types, a variable of any interface type can be assigned to  any  other  interface  typed  variable.  The  reason  is  that  InterfaceT  does  not  implement  a  custom  CS-VYPER_JANUARY_2023-007  Vyper - Vyper compiler -   12  CorrectnessMediumVersion1DesignMediumVersion1DesignMediumVersion1                  \fcompare_type(),  and  reuses  the  one  from  VyperNode,  according  to  which  two  instances  of InterfaceT represent the same type, regardless of their attributes.  The following should not compile, but does:  from vyper.interfaces import ERC20  interface A:     def f(): view  @internal def foo():     a:ERC20 = A(empty(address))  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.8   InterfaceT Type Comparison Is Incorrect for", "body": " Return Types  Method  compare_signature  of  ContractFunctionT  compares  two  functions  to  check  wether  an interface function is implemented in the module.  To  properly  implement  a  function  type,  we  should  be  able  to  receive  at  least  whatever  type  could  be passed as argument to the interface function, and we should return at most whatever could be returned by the interface function. This means that the type of arguments should be a supertype of the interface function argument type, and the type of return should be a subtype of the interface function return type.  CS-VYPER_JANUARY_2023-008  This  matters  with  hierarchical  DynArray[type, n]. When m < n, String[m] is a subtype of String[n].  types,  which   in  Vyper  are  String[n],  Bytes[n],  and  In term of a practical example, the following compiles but should not:  interface A:     def f() -> String[10]: view  implements:A  @external def f() -> String[12]:     return '0123456789ab'  Somebody wanting to interact with the contract through interface A expects that f() returns at most 10 characters,  however  here  f()  is  returning  12  characters.  The  order  of  compare_type()  for  return types should be reversed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.9   Note on Pull Request 3104: Refactor: Optimize", "body": " Calldatasize Check  CS-VYPER_JANUARY_2023-009  Vyper - Vyper compiler -   13  DesignMediumVersion1DesignMediumVersion1            \fThis PR removes an unconditional check that calldata.size >= 4 before the selector matching. It introduces an optional check that calldata.size > 0, which is included only if any of the selectors for the external functions is 0x00000000.  Every external function already checks that calldata.size >= 4 + argsize, the consequences of this PR are subtle differences in behavior when calldata.size < 4.  When calldata.size < 4, before, no selector would ever be matched, and we would end up in the fallback function. Now, when calldata.size < 4 we could happen to match a selector ending with zeros, for example selector 0x11223300 (4 bytes) is now matched by calldata 0x112233 (3 bytes). We now  execute  the  function,  which  guards  against  calldata.size  <  4  with  an  assert,  which  cause  a REVERT. So now, instead of unconditionally going to the fallback function with calldata.size < 4, we either go to fallback if nothing is matched, or we revert if something is matched.  This behavior is probably not what we expect after the refactor.  the An  alternative  possibility  calldata.size  >=  4  +  argsize  assert  when  argsize  is  0,  since  if  the  calldata.size  >=  4 initial check is kept, matching any selector implies passing the assert if argsize == 0.  for  optimization  which  could  be  evaluated   remove   to   is   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.10   Pure and View Functions Can Emit Events", "body": "  Event  emission  is  a  state  mutating  operation,  and  causes  STATICCALL  to  revert.  It  is  therefore disallowed in pure and view functions in Solidity. In Vyper however, a pure or view function can emit events  through  the  log  statement,  or  the  raw_log()  builtin.  If  a  pure  or  view  external  function  is called, vyper will try generating a STATICCALL to it, but if it emits an event the function will revert.  CS-VYPER_JANUARY_2023-010  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.11   implements Statement Does Not Check", "body": " Functions Mutability  the  implements  statement  checks  if  the  module's  interface  implements  the  functions  in  an  interface, either imported or defined with an interface statement. The type of the function arguments are checked, but  the  mutability  of  functions  is  not  considered.  The  mutability  could  be  seen  as  a  hierarchical  type, where  the  implementing  function  can  only  have  mutability  equal  or  lower  than  the  interface  function  it implements.  CS-VYPER_JANUARY_2023-011  This compiles but should not:  interface A:     def f(a:uint256): view  implements:A  @external def f(a:uint256): #visibility is nonpayable instead of view     pass  Vyper - Vyper compiler -   14  DesignMediumVersion1DesignMediumVersion1              \f5.12   AnnAssign Allows Tuples Assignment, Assign Forbids Them  visit_Assign  in  vyper.semantics.analysis.local  ensures  that  the  right  hand  side  of  an assignment is not a node of type tuple, but visit_AnnAssign does not. Is there a rationale behind this difference of behavior?  CS-VYPER_JANUARY_2023-012  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.13   Call to Self Check Replicated Twice in", "body": " FunctionDef Analysis  Lines  113-124  of  semantics/analysis/module.py  check  that  a  function  does  not  call  itself recursively. Line 126-144 replicate this check but with more generality, since a call to self is also a cyclic call. The check at line 113-124 is redundant.  CS-VYPER_JANUARY_2023-013  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.14   Code Duplication When Return Type of a", "body": " Function Is a Tuple  The  condition  at  line  322  of  semantics/types/function.py  treats  the  case  where  the  return annotation  of  a  function  is  a  tuple,  getting  the  type  by  iterating  over  the  individual  tuple  elements  and builing the TupleT:  CS-VYPER_JANUARY_2023-014  elif isinstance(node.returns, vy_ast.Tuple):     tuple_types: Tuple = ()     for n in node.returns.elements:         tuple_types += (type_from_annotation(n),)     return_type = TupleT(tuple_types)  However, calling type_from_annotation() directly with the ast.Tuple node as argument achieves the same result, using the equivalent code in TupleT.from_annotation():  values = node.elements types = tuple(type_from_annotation(v) for v in values) return cls(types)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.15   Comment Referring to Code as Dead Is", "body": " Incorrect  Vyper - Vyper compiler -   15  DesignLowVersion1DesignLowVersion1DesignLowVersion1DesignLowVersion1                      \fFunction types_from_BinOp in semantics/analysis/utils.py contains the comment:  CS-VYPER_JANUARY_2023-015  # CMC 2022-07-20 this seems like unreachable code  in the handling of rhs of a division/modulus operation being 0.  The code is indeed reachable. Example:  a:uint256  @internal def foo() -> uint256:     return self.a / 0  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.16   Comment Uses Outdated Type Classes", "body": " Name  Comment at line 91 of vyper/semantics/analysis/module.py uses the InterfacePrimitive class name which has been deprecated in favor of InterfaceT.  CS-VYPER_JANUARY_2023-016  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.17   Constant Can Be Declared With Same Name", "body": " as Storage Variable  A  constant  can  be  declared  to  have  the  same  name  as  a  storage  variable,  if  the  constant  declaration follows the storage variable declaration. However a storage variable can't be declared if a constant of the same  name  is  already  declared.  This  is  inconsistent  with  what  happens  with  immutables  (can't  have same name regardless of order).  CS-VYPER_JANUARY_2023-017  This compiles:  a: uint256 a: constant(uint256) = 1  But this doesn't compile, while having the same semantics:  a: constant(uint256) = 1 a: uint256  Vyper - Vyper compiler -   16  DesignLowVersion1DesignLowVersion1              \f5.18   ContractFunctionT Incorrect Namespace Argument Check  The  following  check  in  ContractFunctionT.from_FunctionDef()  is  redundant  for  contract function definitions, and wrong for interface function declarations:  CS-VYPER_JANUARY_2023-018  if arg.arg in namespace:     raise NamespaceCollision(arg.arg, arg)  At  this  point,  we  are  still  building  the  module  namespace,  so  the  check  could  pass  depending  on  the order of module body elements.  This doesn't compile:  a:constant(uint256) = 1 interface A:     def f(a:uint256): view  While this functionally equivalent code does compile:  interface A:     def f(a:uint256): view a:constant(uint256) = 1  With module function definitions, it will not compile in both cases, since the namespace is also checked in local analysis, but the error message will be different depending on order.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.19   Dead Code in _get_module_definitions", "body": "  In semantics/types/user.py, the code to validate that functions with the same name extend each other input in _get_module_definitions() is unused, since the same logic is already implemented in from_FunctionDef of ContractFunctionT. The code at lines 424-439 will never be executed, since the condition at line 424 is true, since functions with the same name are not allowed at the module level.  CS-VYPER_JANUARY_2023-019  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.20   Decorators Allowed Around Interface", "body": " Functions  In interface definitions, decorators can be used over function declarations. The decorator has however no effect on the compiler's behaviour. This compiles:  CS-VYPER_JANUARY_2023-020  interface A:     @asdfg     def f(): view  Vyper - Vyper compiler -   17  CorrectnessLowVersion1DesignLowVersion1DesignLowVersion1                \f5.21   Enum Members Are Not Valid as Keyword Argument Defaults  Function check_kwargable doesn't handle the case of Enum nodes. The following does not compile:  CS-VYPER_JANUARY_2023-021  enum A:     a  @external def f(a:A = A.a):     pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.22   Errors Misreport Column Offset for Vyper", "body": " Preparsed Keywords  The tokenizer output is annotated with lines and columns offsets, which are then used when annotating AST nodes. Some vyper keywords such as log, event, struct, and interface, are replaced with the python keyword class before parsing. The class tokens differ in position with the vyper tokens, so the column offset is misaligned for certain errors. For example the following code (which does not compile) produces an error that misreports the position of the undeclared variable d.  CS-VYPER_JANUARY_2023-022  event A:     b:uint256  @external def f():     log A(d)  The following error is raised, with the ascii art arrow pointing to the wrong location:  UndeclaredDefinition: 'd' has not been declared.   contract \"VyperContract:7\", function \"f\", line 7:12        6 def f():   ---> 7     log A(d)   -------------------^        8  Vyper - Vyper compiler -   18  DesignLowVersion1CorrectnessLowVersion1              \f5.23   ExprInfo for Tuple Allows Assigning to Immutables  Line  249-251  of  vyper/semantics/analysis/base.py  guard  against  assignment  to  an  already assigned  immutable  variable.  However  the  is_immutable  field  is  left  blank  when  creating  an ExprInfo for a tuple (vyper/semantics/analysis/utils.py:90-97).  The following code generates an error in code generation, instead of typechecking:  CS-VYPER_JANUARY_2023-023  c:(uint256, uint256) d: public(immutable(uint256)) e: immutable(uint256)  @external def __init__():     d = 1     e = d  @external def f():     d, e = self.c  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.24   Function Declaration Checks if Return Type", "body": " Annotation Is a Call Node  Function  semantics/types/function.py the following check:  from_FunctionDef   ContractFunctionT   of   CS-VYPER_JANUARY_2023-024  performs   at   line   320   of  elif isinstance(node.returns, (vy_ast.Name, vy_ast.Call, vy_ast.Subscript)):     return_type = type_from_annotation(node.returns)  However, node.returns has no reason to be a Call. No type annotation is a Call.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.25   HashMap Variable Can Be Left-Hand of", "body": " Assignment if Wrapped in Tuple  Line  249-251  of  vyper/semantics/analysis/local.py,  in  visit_Assign,  ensure  that  lhs  of assignment  cannot  be  a  hashmap  without  a  key.  However  this  check  is  skipped  if  the  hashmap  is wrapped in a tuple.  The  following  code  passes  the  check,  and  fails  compilation  during  code  generation,  in  a  check considered maybe redundant.  CS-VYPER_JANUARY_2023-025  Vyper - Vyper compiler -   19  CorrectnessLowVersion1DesignLowVersion1CorrectnessLowVersion1                \fa: HashMap[address, uint8] b: HashMap[address, uint8] c: HashMap[address, (HashMap[address, uint8], HashMap[address,uint8])] @internal def f():     (self.a, self.b) = self.c[empty(address)]  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.26   Import Level of ImportFrom Ignored", "body": "  The python ImportFrom ast node defines a field level which specifies the level of a relative import. This field is ignored in Vyper, so the following code is valid and compiles:  CS-VYPER_JANUARY_2023-026  from ......................vyper.interfaces import ERC20  implements: ERC20  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.27   Inaccurate Comment on TYPE_T", "body": "  Class TYPE_T is commented in semantics/types/base.py with  # A type type. Only used internally for builtins  CS-VYPER_JANUARY_2023-027  The  comment  is  inaccurate,  as  TYPE_T  is  also  used  to  wrap  other  callable  types,  such  as  events  or structs.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.28   Internal Functions Can Have Name Collision", "body": " With Builtins  If  a  function  visibility  is  @internal,  it  can  share  its  name  with  a  builtin,  if  the  visibility  is  @external, however,  a  compilation  error  is  raised.  There  is  no  valid  reason  it  should  be  so,  since  both  kind  of functions populate the self namespace and should behave consistently.  CS-VYPER_JANUARY_2023-028  This compiles:  @internal def block():     pass  This doesn't compile:  Vyper - Vyper compiler -   20  DesignLowVersion1DesignLowVersion1DesignLowVersion1                  \f@external def block():     pass  is   reason   The  true  when  calling self.add_member in visit_FunctionDef, which is used for internal and external functions, it is set to false when populating the interface of the module, which includes only external functions.  that  while  skip_namespace_validation   is  set   to   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.29   Invalid DataLocation for Tuple ExprInfo", "body": "  A  Tuple  is  the  only  type  of  node  whose  ExprInfo  is  the  aggregation  of  the  individual  ExprInfos  of  its nodes,  so  it  is  tricky  to  define  it  consistently.  The  ExprInfo  of  a  Tuple  containing  a  storage  and  an immutable variable has DataLocation CODE. This could cause problems if the ExprInfo was to be used in code generation.  CS-VYPER_JANUARY_2023-029  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.30   Lhs of AugAssign Not Visited by", "body": " _LocalExpressionVisitor  CS-VYPER_JANUARY_2023-030  _LocalExpressionVisitor is a legacy class whose sole current purpose is to check that msg.data and address.code are correctly accessed in a builtin that can handle them. The left hand side of an AugAssign  the _validate_address_code_attribute() and _validate_msg_data_attribute() checks, and causes a compiler panic:  is  not  visited  by  _LocalExpressionVisitor,  so   following  passes   the   a: HashMap[Bytes[10], uint256]  @external def foo(a:uint256):     self.a[msg.data] += 1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.31   Note on PR 3167: Fix: Codegen for Function", "body": " Calls as Argument in Builtin Functions  PR 3167 correctly fixes an issue where arguments of builtins would be included twice in the generated code, resulting in reverts because of duplicated labels. The fix is implemented for builtins floor, ceil, addmod, mulmod, and as_wei_value  Arguments  are  now  correctly  evaluated  and  cached  before  being  included  in  the  intermediate representation code.  CS-VYPER_JANUARY_2023-031  Vyper - Vyper compiler -   21  DesignLowVersion1CorrectnessLowVersion1CorrectnessLowVersion1                  \fHowever, builtin functions ecadd and ecmul are still affected by the same bug. The following code does not compile but should:  @external def foo() -> (uint256[2]):     a: Foo = Foo(msg.sender)      return ecmul(a.bar(), 2)  interface Foo:     def bar() -> uint256[2]: nonpayable  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.32   Pointless Assert", "body": "  get_expr_info() in vyper.semantics.analysis.utils contains the assert:  assert t is info.typ.get_member(name, node)  CS-VYPER_JANUARY_2023-032  Since  t  has  just  been  defined  as  t  =  info.typ.get_member(name.  node),  and  no  mutating operation has occured, the assert will always pass.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.33   Positional Only Arguments Are Allowed but", "body": " Ignored in Function Definitions  Python allows specifying positional only arguments in a function definitons, which are accessible through the posonlyargs field of the arguments AST node. Since the arguments VyperNode does not sets posonlyargs as a _only_empty_fields, the field can be populated but is ignored.  CS-VYPER_JANUARY_2023-033  The following code compiles:  @internal def f(a:uint256,/): #this does not actually defines argument a             return  @external def g():             self.f() #f is called without arguments  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.34   RawRevert Should Be Set as Terminal Node", "body": "  CS-VYPER_JANUARY_2023-034  Vyper - Vyper compiler -   22  DesignLowVersion1DesignLowVersion1DesignLowVersion1                  \fBuiltin raw_revert has field _is_terminus unset. _is_terminus specifies if the node can terminate the  branch  of  a  function  body  which  has  a  non  empty  return  type.  The  evaluated  function  is  left  when raw_revert  is  called,  so  its  _is_terminus  attribute  should  be  set  to  True,  as  is  the  case  for SelfDestruct.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.35   Safety Check for Bytestring Classes Not", "body": " Reacheable  CS-VYPER_JANUARY_2023-035  Function  from_annotation  in  class  semantics.types.bytestrings._BytestringT  validates that  the  bytestring  type,  such  as  String  or  Bytes,  is  not  being  used  without  a  length  specifier (String[5]).  However  in type_from_annotation()  if  the  type  annotation  is  an  ast.Name,  so  the  check  at  line  126  of semantics/types/bytestrings.py is not effective.  function  from_annotation()  of  a   is  not  called   type   the   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.36   Storage Location of Constants Set to", "body": " Storage  In  visit_VariableDecl  of  vyper.semantics.analysis.module,  the  DataLocation  of constant variables is set to STORAGE. While this has no immediate consequences, since constants can't be assigned, it could be misleading and generate problems in future code changes.  CS-VYPER_JANUARY_2023-036  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.37   Struct Creation Without Assignment Results", "body": " in Cryptic Error Message  The  check  at  lines  512-519  of  vyper/semantics/analysis/local.py  should  output  an  error message when builtins or structs are called without assignment, however the _id attribute of fn_type is accessed,  which  causes  another  exception  to  be  thrown  for  TYPE_T(StructT),  since  they  have  no ._id field.  CS-VYPER_JANUARY_2023-037  Example:  struct A:     a:uint256 @internal def aaa():     A({a:1})  Vyper - Vyper compiler -   23  CorrectnessLowVersion1DesignLowVersion1CorrectnessLowVersion1                    \f5.38   Tuple Node Input Does Not Work With Validate_Expected_Type  Function  validate_expected_type  has  a  branch  for  the  case  when  node  is  an  instance  of vy_ast.Tuple.  However,  it  is  not  clear  what  the  purpose  of  handling  Tuple  nodes  is,  since  the expected type has to be a dynamic or static array.  CS-VYPER_JANUARY_2023-038  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.39   VarInfo for self Not Constant", "body": "  While self contains mutable variables, it would make sense that its VarInfo was set as constant. The compilation of the following fails in code generation, while it could fail in type checking.  CS-VYPER_JANUARY_2023-039  @external def f():     self = self  Vyper - Vyper compiler -   24  CorrectnessLowVersion1DesignLowVersion1          \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Comments on PR 2974/3182", "body": "  These PR refactor the type system, and unify the front-end and back-end type systems.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Note on PR 3213: Fix: Constant Type", "body": " Propagation to Avoid Type Shadowing  Pull  Request  3213  correctly  fixes  an  issue  where  the  type  inference  for  the  iterator  of  for  loops  would result in validating conflicting types.  Instead of accessing the \"type\" metadata property of a node, which could be dirty with a provisional invalid type, get_possible_types_from_node() now accesses the new \"known_type\" metadata property, which is only assigned during constant folding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Note on PR 3215: Raise Clearer Exception", "body": " When Using a yet Undeclared Variable in a Type Annotation  This  PR  correctly  resolves  a  cryptic  error  message  cause  by  undeclared  variables  during  constant folding.  The  following  line  caused  problems,  when  name  was  not  in  the  namespace  and  self  had  not  been declared yet (during constant folding):  if name not in self.namespace and name in self.namespace[\"self\"].typ.members:  The  rhs  condition  name  in  self.namespace[\"self\"].typ.members  would  raise  an  exception when evaluated, because self.namespace had no self member yet.  Now the condition has been split in 3 conjunctions:  if (     name not in self.namespace     and \"self\" in self.namespace     and name in self.namespace[\"self\"].typ.members ):  When name is not in self.namespace, the condition \"self\" in self.namespace guards against raising accidentally when evaluating the 3rd conjunction.  Vyper - Vyper compiler -   25  NoteVersion1NoteVersion1NoteVersion1          \fA  more  body,  when t = self.namespace[node.id] is evaluated, since self.namespace does not containt node.id.  immediately   exception   legible   raised   after   the   is   if   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Note on Pull Request 3194: Fix Raise", "body": " UNREACHABLE  PR 3194 fixes a bug in code generation that would cause a raise UNREACHABLE statement to cause a compiler  panic.  It  is  implemented  correctly  and  the  resulting  code  is  correct.  We  noticed  that  in  the generated  code  a  STOP  unreachable  instruction  is  present  after  the  INVALID  instruction  generated  by the raise statement.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Note on Pull Request 3222: Fix: Folding of", "body": " Bitwise Not Literals  PR 3222 reimplements the binary inversion of literals during folding. The operation computes the 256 bits wide binary inverse, so that the result of the operation should always fits within uint256.  Vyper - Vyper compiler -   26  NoteVersion1NoteVersion1        \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Certain Inputs Unchecked in Constructor", "body": "  When  new  fees  are  committed  through  the  commit_new_fee  function  they  are  checked  against  the respective  maximum  values  to  prevent  mistakes.  However,  when  the  fees  are  initially  set  inside  the constructor no such check is performed. Hence, initial fees might be outside the permitted value range.  Similarly,  when  the  amplification  factor  is  changed  through  ramping,  it's  value  range  is  checked. However, during the constructor this check for the amplification factor does not take place.  Risk  accepted:  As  deployment  is  a  rare  event  and  as  deployed  contracts  will  be  checked  by  the development team, there is no immediate need to add these checks. An incorrect contract can be \"killed\".  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Ramping Down Might Incentivize Delayed", "body": " Liquidity  While  the  amplification  factor  is  ramping  down  in  an  imbalanced  pool,  liquidity  providers  have  an incentive to wait before providing extra liquidity. This is because they will receive more liquidity tokens in the  future  for  the  same  liquidity.  In  the  extreme  case  of  a  maximally  sharp  ramp  down  and  a  very imbalanced pool, waiting for ten minutes provides roughly 0.14% additional liquidity tokens.  However, this only holds as long as no further fees are accumulated during this time and as long as no re-balancing takes place inside the pool and hence constitutes a fairly unlikely scenario.  Curve.Finance - Curve ETH/sETH -   9  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedRiskAcceptedSecurityLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                   \fRisk accepted: As mentioned above this only applies for very sharp ramps. As the DAO will control the parameter  of  these  ramps,  the  DAO  can  also  ensure  that  the  sharpness  is  low  enough  to  avoid  any issues.  Curve.Finance - Curve ETH/sETH -   10    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Reentrancies   -Severity Findings   Redundant Use of RATES and PRECISION    _xp and _xp_mem Redundant Array Access    get_D Should Handle the Case of Non-convergence   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Reentrancies", "body": "  0  0  1  3  1. During the execution of remove_liquidity and remove_liquidity_imbalance multiple asset transfers are made. One of these assets is ETH, while the others are ERC-20 tokens. The transfer of  ETH  can  lead  to  the  following  reentrancy.  Through  the  transfer  of  ETH,  the  execution  might reenter the contract and call donate_admin_fees. Note that this requires owner privileges. Inside donate_admin_fees, the internal balances mapping for the ERC-20 tokens will be updated as follows:  self.balances[i] = ERC20(coin).balanceOf(self)  This assignment is incorrect in this context as the contract still holds the tokens that are about to be transferred  due  is  complete: self.balances[i] > ERC20(coin).balanceOf(self). This breaks an important invariant in the contract.  liquidity.  Hence,  after   transaction   removed   the   the   to   2. During the call to withdraw_admin_fees an ETH transfer takes place. The transfer of ETH can lead  to  the  following  reentrancy.  Through  the  transfer  of  ETH,  the  execution  might  reenter  the contract  and  call  donate_admin_fees.  Note  that  this  requires  owner  privileges,  but  these  were already needed for withdraw_admin_fees. As a result, the admin fees for some of the coins will be  donated  while  the  admin  fees  for  other  coins  will  be  withdrawn,  leading  to  a  state  that  is  only reachable through a reentrancy.  3. Certain admin functions have no reentrancy protection. Hence, they can be called in a reentrancy from any of the functions that transfers ETH. However, for those reentrancies the only effects are incorrectly  ordered  events.  As  an  example,  a  NewFee  event  could  be  emitted  in  between  multiple events belonging to a remove_liquidity call.  Code  corrected:  Additional  Reentrancy  Guards  were  added.  These  now  also  cover  the  functions donate_admin_fees and apply_new_fee among others.  Curve.Finance - Curve ETH/sETH -   11  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSecurityMediumVersion1CodeCorrected        \f6.2   Redundant Use of RATES and PRECISION  RATES  is  a  constant  vector  containing  in  all  cells  the  value  10**18.  PRECISION  is  a  constant  of  value 10**18.  There are cases, such as in exchange, where the value of a cell of RATES is divided by PRECISION. This division is redundant.  rates: uint256[N_COINS] = RATES # Both multiplication with rates[i] and division with PRECISION can be avoided x: uint256 = xp[i] + dx * rates[i] / PRECISION   The code was changed accordingly to remove the redundancies and to save gas.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   _xp and _xp_mem Redundant Array Access", "body": "  In  both  _xp  and  _xp_mem  the  array  results  is  initialized  with  the  array  RATES.  However,  results later  ends  up  equal  to  self.balance.  This  is  because  of  the  multiplication  (with  result[i])  and  a redundant division (with LENDING_PRECISION). Note, that RATES equals to LENDING_PRECISION for all i. In the general case this code is useful, however for this token pair, it provides no additional value. RATES and LENDING_PRECISION are constants, the gas overhead is fairly low.  result: uint256[N_COINS] = RATES for i in range(N_COINS):     result[i] = result[i] * self.balances[i] / LENDING_PRECISION return result   The code was changed accordingly to remove the redundancy and to save gas.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   get_D Should Handle the Case of", "body": " Non-convergence  The calculation of the invariant D is limited to 255 steps. If there is no convergence then a wrong invariant is returned. The invariant is used to mint liquidity provider tokens. Thus, incorrect number of tokens can be minted. For the case of non-convergence, a verification step of the computed solution could be added.  Code  corrected:  The  new  implementation  reverts  in  case  of  non-convergence.  This  ensures  that  no faulty results are used for further computation.  Curve.Finance - Curve ETH/sETH -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f7   Notes  We leverage this section to highlight further findings that are not necessarily issues.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Content of Events", "body": "  The events RemoveLiquidityImbalance and AddLiquidity contain the value D1 which represents the intermediate calculation of the invariant. Including D2 might be more helpful.  The  event  RemoveLiquidityOne  does  not  include  the  information  which  coin  was  removed  from liquidity. That might be relevant information.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Fee Avoidance", "body": "  It  is  theoretically  possible  to  avoid  fee  payments  completely  by  repeatedly  exchanging,  adding  or removing such small amounts that fees are zero due to arithmetic errors. This results in a loss of fees for both  fees  will  be overcompensated  by  the  additional  gas  costs.  Hence,  such  a  scenario  would  only  be  realistic  in  the context of Zero-Gasprice Transactions.  liquidity  providers  and  admins.  However,   in  almost  all  cases   the  saved   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Incentive to Remove Liquidity", "body": "  There  might  be  an  incentive  for  liquidity  providers  to  remove  liquidity  while  the  amplification  factor  is ramped  down.  In  case  of  a  really  imbalanced  pool  and  a  very  rapid  ramping  down  of  the  amplification factor,  the  following  sequence  might  leave  the  liquidity  provider  with  more  liquidity  tokens  that  they started with:  1. Remove liquidity by withdrawing only the non-scarce asset  2. Wait for the ramping to continue  3. Re-add the removed asset to regain liquidity tokens  In case of a very imbalanced pool and a sharp ramp, the liquidity provider could end up with 0.14% more liquidity tokens than they started with by waiting just ten minutes in step 2. This, however, only works if no other transactions take place inside the pool.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Inefficiencies When Removing Single Coin", "body": "  When removing just a single coin from the pool liquidity, the remove_liquidity_one_coin function can  be  used.  However,  the remove_liquidity_imbalance function and just setting all values except for the desired one to zero. In  our  limited  experiments,  the  biggest  difference  occurred  when  remove_liquidity_imbalance provided 0.00008% additionally withdrawn assets.  in  certain  cases   less  efficient   than  using   function   this   is   Curve.Finance - Curve ETH/sETH -   13  NoteVersion2NoteVersion1NoteVersion1NoteVersion1              \fis   the   difference   Hence,  the remove_liquidity_one_coin  function  is  generally  expected  to  have  lower  gas  costs.  Finally,  it  is functions  as fee  important  remove_liquidity_one_coin  will  coin,  while remove_liquidity_one_coin will pay a roughly equivalent amount of fees in all coins.  two  the  for  the  withdrawn   is  different  in   structure  only   and  mostly   Furthermore,   negligible.   to  note   small   fees   very   that   pay   the   Curve.Finance - Curve ETH/sETH -   14  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Possible Gas Optimization for Mappings", "body": "  Although the value for the mapping isOracle is of type bool which needs only 1 bit of storage, Solidity uses a word (256 bits) for each stored value and performs some additional operations when operating bool values (masking). Therefore, using uint instead of bool is slightly more efficient.  Acknowledged:  Maker acknowledged the issue.  MakerDAO - G-UNI LP Oracle -   9  DesignCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Missing Documentation   -Severity Findings   Unused Constant Variable   0  0  1  1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Missing Documentation", "body": "  The requirements about the oracles for the underlying tokens are not documented. In the supplied test file we see following oracles:  address constant USDC_ORACLE        = 0x77b68899b99b686F415d074278a9a16b336085A0; address constant DAI_ORACLE         = 0x47c3dC029825Da43BE595E21fffD0b66FfcB7F6e; address constant ETH_ORACLE         = 0x81FE72B5A8d1A857d176C3E7d5Bd2679A9B85763;  The oracles for USDC and DAI return the unit value of one. The ETH oracle is updated roughly once an hour hence the price returned is not live. For the proper working of the GUniLPOracle a live price feed is required, frequently updated and without a time delay. When GUniLPOracle.seek() is executed, the underlying price feeds must return live values.  Furthermore the underlying principle how the price is determined could be described more clearly in the Readme:  This price feed works by determining how many of token0 and token1 the underlying liquidity position in UniswapV3  held  by  the  GUniPool  has  at  the  current  price.  This  current  price  is  solely  determined  by Maker oracles and independent of the current state of the UniswapV3 pool. The assumption is that  1. The Maker oracles for the underlying tokens return the current market rate  2. In general, e.g. outside flashloan scenarios, the UniswapV3 pool will be balanced at the current market rate. This means that the GUnipool tokens can be redeemed at this current market rate.  Hence  such  a  GUnipool  token  collateral  is  priced  based  on  its  underlying  tokens,  independent  of  the state of the GUni/Uniswap V3 pool. The documentation may be expanded to explain and motivate this.  Specification changed:  Maker responded:  It was a mistake that the test was referring to the ETH/USD OSM. It should have referenced the ETH/USD Medianizer to get a live price feed.  MakerDAO - G-UNI LP Oracle -   10  CriticalHighMediumSpeci\ufb01cationChangedLowCodeCorrectedDesignMediumVersion1Speci\ufb01cationChanged        \fFurthermore the readme has been updated and now contains:  Underlying price oracles `orb0` and `orb1` should refer to either a Medianizer, DSValue or some other `read()` compliant oracle. OSMs should not be used to the double delay.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Unused Constant Variable", "body": "  The  variable  WAD  is  declared  as  constant  and  initialized  to  10  **  18,  however  it's  never  used  in  the code.    The unused constant has been removed.  MakerDAO - G-UNI LP Oracle -   11  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Misleading Function Name link", "body": "  The  function  name  link(uint256  _id,  address  _orb)  is  misleading  as  it  gives  the  impression that the token _id is linked to the respective oracle initially by this function. However, this function only updates an existing link of the token with the respective oracle (initialized in the constructor).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   NewGUniLPOracle Indexed Fields", "body": "  The  event  NewGUniLPOracle  has  two  indexed  parameters  corresponding  to  the  token  addresses.  In practice, it might be useful if the field address owner is indexed also, as it would allow users to easily filter oracles from a trusted owner.  MakerDAO - G-UNI LP Oracle -   12  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   file() Has No Access Control", "body": "  Function  file()  can  add  and  remove  valid  domains  and  should  be  called  carefully  by  governance. However, the function lacks access control.    Access control was added to file().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   finalize_register_teleport() Only", "body": " Possible When Open  Calling finalize_register_teleport() on Starknet allows users to take the slower route through Starknet message passing to L1 to prevent censorship by the oracles and ensure availability if oracles are down. However, given that the function is not callable if the bridge is closed, the system, in contrast to the Teleport for Optimism and Arbitrum, is not fully trustless, as users could be censored by closing the teleport instance. Further, censored users that had their L2 DAI burned, will not be able to recover it.    The precondition of finalize_register_teleport() has been removed.  MakerDAO - Starknet Teleport -   10  CriticalHighMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedSecurityMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                    \f6.3   No Event for finalize_teleport()  finalize_teleport() emits no event in contrast to other functions (e.g. initiate_teleport()). Emitting more events could lead to a better user-experience and easier integration with front-ends.    An event has been added.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Unused Code", "body": "  l2_dai_teleport_gateway  prepares  a  payload  in  initiate_teleport()  even  though  it  remains unused.  l2_dai_teleport_gateway has several unused imports:   BitwiseBuiltin   hash2   assert_le  is_not_zero   get_contract_address   uint256_lt   uint256_check    Unused imports and unused code were removed.  MakerDAO - Starknet Teleport -   11  DesignLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected               \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Gas Inefficiencies", "body": "  0  0  0  9  We have found some gas inefficiencies that could be optimized:   Lido saves several contract addresses (e.g., the ETH deposit contract) in the storage. Since Lido is upgradeable, the mentioned variables could be exchanged with constants or immutables that can be updated with a Proxy upgrade to save storage reads on various interactions.   Lido.handleOracleReport  updates  the  BEACON_VALIDATORS_POSITION  even  when  the  amount of validators has not changed.   StakeLimitUtils.calculateCurrentStakeLimit  performs  stake  limit  calculations  even just  return  the  prevStakeBlockNumber   the  current  block  number.   It  could   is   when  prevStakeLimit in that case.   NodeOperatorsRegistry.removeSigningKeys  and  removeSigningKeysOperatorBH  are inefficient if 0 < (totalSigningKeys - 1) - _index < (_amount - 1) as more swaps from the last to the current position are performed than necessary.   NodeOperatorsRegistry._removeSigningKey  assigns  the  new  totalSigningKeys  value to a value that is loaded from storage, while the same value has already been loaded from storage before (lastIndex).  Lido - Lido -   11  DesignTrustCriticalHighMediumLowAcknowledgedRiskAcceptedAcknowledgedRiskAcceptedRiskAcceptedAcknowledgedAcknowledgedAcknowledgedRiskAcceptedDesignLowVersion1Acknowledged           \f NodeOperatorsRegistry.assignNextSigningKeys   calculates stake  +  1  >  entry.stakingLimit  while  stake  >=  entry.stakingLimit  would  be sufficient.   NodeOperatorsRegistry.assignNextSigningKeys finds the operator with the smallest stake with  the  statement  bestOperatorIdx  ==  cache.length  ||  stake  <  smallestStake. This  can  be  simplified  to  stake  <  smallestStake  by  initially  setting  smallestStake  to  the maximum value of uint256.   NodeOperatorsRegistry._storeSigningKey  and  _loadSigningKey  load  signatures  by iterating  over  the  words  of  the  signature  and  loading  them  from  the  memory  location  at add(_signature, add(0x20, i)) on every iteration. This can be simplified to i by setting the 32  +  loop  to to  i <= signature + SIGNATURE_LENGTH.  signature   execution   condition   variable   and   the    LidoOracle  pushes  reports  to  the  CompositePostRebaseBeaconReceiver  which  pushes reports to the SelfOwnedStETHBurner. Since the SelfOwnedStETHBurner is currently the only receiver, this indirect route is not necessary.   SelfOwnedStETHBurner._requestBurnMyStETH  uses  Lido.transfer  and  calculates  the share  amount  by  calling  Lido.getSharesByPooledEth.  This  second  call  could  be  avoided  by using the transferShares function.  Acknowledged:  Lido states:  Thank you for the suggestions, we will take them into consideration for the next protocol upgrade.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Inconsistent Event Order", "body": "  The  order  in  which  the  Transfer  and  TransferShares  events  are  emitted  is  inconsistent.  In  the transferShares  function  in  StETH,  the  TransferShares  event  is  emitted  first.  In  all  other  cases, Transfer is emitted first.  Note also that these events are always emitted after calling the _transferShares function. To avoid the duplication of emitted events and reduce code size, it would also be possible to emit the events within the _transferShares function itself.  Risk accepted:  This change is scheduled for the next update.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   LidoOracle Initialized With Wrong Epoch", "body": "  In the initialize function of the LidoOracle, the expectedEpoch is set as follows:  uint256 expectedEpoch = _getFrameFirstEpochId(0, beaconSpec) + beaconSpec.epochsPerFrame;  Lido - Lido -   12  DesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                \fHowever,  _getFrameFirstEpochId  will  always  return  0  here.  So  the  first  expected  epoch  is  set  to beaconSpec.epochsPerFrame. However, it would make little sense for a member to report an epoch before the contract was deployed. Instead, the expectedEpoch could be set to an epoch which occurs after the contract is deployed, for example using _getCurrentEpochId.  Acknowledged:  The  initialize  function  can't  be  called  again  on  the  Lido  contract,  which  is  already  deployed. Therefore this is only an issue if a redeployment becomes necessary.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Malicious Node Operators", "body": "  Node operators are trusted entities in the Lido ecosystem. They are responsible for correctly running the validators as well as distributing MEV rewards to the contract. They can only be incentivized to behave decently  so  it  is  possible  that  certain  economic  opportunities  could  incentivize  them  to  behave maliciously.  For example, it can be hard to verify the amount of MEV rewards node operators generate with the nodes they  are  running.  Malicious  node  operators  could  choose  to  not  distribute  these  rewards  but  instead pocket them themselves.  Furthermore, and most importantly, node operators have no ownership of the ETH that are locked in their validators. This means that whatever incentive they have to run the nodes benevolently could be offset by a more financially lucrative incentive. One example could be a short position in stETH that becomes profitable. As the staked ETH are not owned by the operators, this is very much possible due to slashing as can be seen in the following example (assuming the Merge has already happened and according to current spec):   A  malicious  node  operator  executes  2  attestations  to  the  same  target  on  all  of  their  controlled validator nodes. At the time of this writing, single validators run up to ~8,000 nodes of the ~400,000 nodes currently on the Beacon Chain).   Each node gets slashed by 1 ETH, reducing the amount of ETH in the protocol by ~8,000 or ~0.1%  of Lido's total supply.   After 18 days, the validators get slashed again based on the amount of validators that have been  slashed in the previous 16 days: Each validator loses ~1.8 ETH.  In total, the supply of Lido drops by ~0.5%.  If 2 node operators collude, the total supply drops by ~1.7%. If 3 operators collude, it drops by ~3.6%.  Depending  on  the  market  reaction,  the  value  of  stETH  could  decrease  dramatically  following  these events, making a decently sized short position in stETH (or more likely wstETH) profitable.  Risk accepted:  Lido states:  The  risk  is  mitigated  by  maintaining  healthy  validators  set  with  monitoring  and  DAO  governance processes. There is a set of policies and management actions:   onboarding new NOs to decentralize further;  limiting the stake amount per single NO;  Lido - Lido -   13  TrustLowVersion1RiskAccepted          \f developing  dashboards  and   tools   to  monitor  network  pasticipation  performance  (now  open-sourced https://github.com/lidofinance/ethereum-validators-monitoring)   developing  dashboards  and  tools  to  monitor  MEV  and  priority  fee  distribution  (approaching  testing stage for the upcoming Merge)  Despite  the  fact  that  Ethereum  staking  is  not  delegation-friendly,  Lido  DAO  already  has  on-chain levers  to  address  malicious  NO  behavior:  excluding  them  from  the  new  stake,  disabling  fee distribution, excluding them from the set, considering penalties on other chains if applicable, and so on.  Once  and  if  withdrawal-credentials  initiated  exits  are  implemented,  there  will  appear  additional on-chain enforcement mechanics which would allow building more permissionless schemes for the validators set.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   No Events on Important State Changes", "body": "  The DepositSecurityModule does not emit events on the following important state changes:  1. When the owner calls setLastDepositBlock.  2. When depositBufferedEther is called.  Risk accepted:  Lido states:   setLastDepositBlock will be used only if re-deploy is needed, so we may add the event for  future versions.   depositBufferedEther emits the Unbuffered event in the Lido contract which is still enough  for indexers, though, will consider the change if an upgrade is needed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Typing Errors", "body": "   NodeOperatorsRegistry._loadOperatorCache returns an error message with a typing error:  INCOSISTENT_ACTIVE_COUNT.   Lido._setProtocolContracts emits the event ProtocolContactsSet.  Acknowledged:  This will be fixed in the next major protocol upgrade.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Unused Imports", "body": "  Lido imports SafeMath64.sol which is not used in the contract.  Lido - Lido -   14  DesignLowVersion1RiskAcceptedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                        \fAcknowledged:  This will be fixed in the next major protocol upgrade.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.8   memcpy Optimizations", "body": "  The memcpy function in the MemUtils library is quite critical for gas costs. It is called by copyBytes, which  in NodeOperatorsRegistry.assignNextSigningKeys. The function itself also contains a loop, for a total of three nested loops.  nested   called   within   loops   from   turn   in   is   While it is already written in assembly, it can be optimized further. First, let's take a look at the loop.  for { } gt(_len, 31) { } {     mstore(_dst, mload(_src))     _src := add(_src, 32)     _dst := add(_dst, 32)     _len := sub(_len, 32) }  As  it  stands,  there  are  three  variables  which  are  modified  per  loop  iteration.  Ideally,  one  would  only change one variable per iteration, and use a loop bound based on this variable. However, this change would add additional overhead outside the loop, which may not pay off in general. Currently, the loop is only executed 1-3 times per call, as the _len parameter is only ever 48 or 96. One may also consider creating functions specifically for copying byte arrays of length 48 and 96, as this would allow a complete unrolling of the loop.  After the loop, the following code is executed:  if gt(_len, 0) {     let mask := sub(shl(1, mul(8, sub(32, _len))), 1) // 2 ** (8 * (32 - _len)) - 1     let srcMasked := and(mload(_src), not(mask))     let dstMasked := and(mload(_dst), mask)     mstore(_dst, or(dstMasked, srcMasked)) }   As _len is a uint256, it is more efficient to just check the condition if _len {.   The  mask   could   also   be  written   as  shr(0xff..ff,  shl(3,  _len))   or  shr(not(0), shl(3, _len)).  Acknowledged:  Lido states:  We decided to leave the assembly code as is to prevent possible peculiarities.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.9   sharesAmount Can Be Zero", "body": "  Lido - Lido -   15  DesignLowVersion1AcknowledgedDesignLowVersion1RiskAccepted                \fDue  to  rounding  errors,  the  value  returned  by  getSharesByPooledEth  can  be  zero.  In  the  function _submit in Lido, the check sharesAmount == 0 is made. This is assumed to hold either on the first deposit,  or  in  the  case  of  a  complete  slashing.  However,  this  can  also  occur  if  rounding  errors  lead  to getSharesByPooledEth returning 0. Thus, a user would receive a disproportionate amount of shares, as they would get a 1:1 rate of ETH to StETH, despite the share value being lower. Note that with the current state of the live contracts, this can only occur if msg.value == 1.  Risk accepted:  Lido is aware of rounding errors, however chooses not to fix them as they are difficult to correct without sacrificing gas efficiency or backwards compatibility.  Lido - Lido -   16  \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Deposits Can Be Blocked by Node Operators", "body": "  DepositSecurityModule  requires  the  keysOpIndex  to  not  change  between  creation  of  a depositBufferedEther transaction and its execution:  uint256 onchainKeysOpIndex = INodeOperatorsRegistry(nodeOperatorsRegistry).getKeysOpIndex(); require(keysOpIndex == onchainKeysOpIndex, \"keys op index changed\");  Since the keysOpIndex can be changed by node operators using addSigningKeysOperatorBH or removeSigningKeysOperatorBH, malicious node operators can delay depositing even when they are not  activated.  The  only  way  to  counter  this  problem  is  to  change  the  rewardAddress  of  such  node operators.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   No Quorum Sanity Checks", "body": "  LidoOracle and DepositSecurityModule allow the addition of members / guardians and the setting of  a  quorum  that  has  to  be  reached  by  these  entities.  The  quorum  can  however  be  set  to  any  value (except for 0 in the case of LidoOracle) independently of the number of members / guardians.  Lido - Lido -   17  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Race Condition on Approvals", "body": "  Since there is no direct way to increase and decrease allowance relative to its current value, the function AllowanceTransfer.approve()  has  a  race  condition  similar  to  one  of  ERC-20  approvals.  Further details regarding the race condition can be found here.  Risk accepted:  Uniswap responded:  We opted not to address this issue. If users really care about this attack vector it means they are likely signing a spender they don\u2019t fully trust, and they can always approve(x), approve(0), approve(y). We also expose a lockdown function that can batch remove approvals for users, before setting new approvals.  Uniswap - Permit2 -   11  SecurityDesignCriticalHighMediumRiskAcceptedLowDesignMediumVersion1RiskAccepted            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Permit2Lib Argument Casting   -Severity Findings  -Severity Findings   CALL to DOMAIN_SEPARATOR()   0  1  0  1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Permit2Lib Argument Casting", "body": "  The  functions  permit2  and  transferFrom2  of  Permit2Lib  both  take  uint256  amount  as  an argument. The lib will first attempt to call the token directly and falls back to the call to Permit2 if it fails. However,  the  Permit2.permit  and  Permit2.transferFrom  take  uint160  amount  as  an argument. The initial uint256 amount will be cast to uint160 for that call. Assuming some contract A relies on transferFrom2 for token transfers, the following can happen:  1. The user calls a function on A that attempts to pull funds from the user using transferFrom2. For  amount, the user specifies 2**170.  2. A direct call to token.transferFrom fails.  3. Permit2Lib falls back to Permit2.transferFrom with uint160(2**170) == 0 as an amount.  4. The call is successful. No value is actually transferred.  5. Contract A now thinks that 2**170 tokens were actually transferred.  Similar casting happens in the permit2 function.    The SafeCast library is now used for casting to a uint160 before the Permit2 contract is called. The casting of a value that is greater than type(uint160).max would revert now.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   CALL to DOMAIN_SEPARATOR()", "body": "  EIP-712 defines the function DOMAIN_SEPARATOR() as a view function. Hence, it is expected to always work  properly  with  STATICCALL.  However,  Permit2Lib.permit2()  queries  the  domain  separator with CALL, allowing the state to change in sub-calls as well as reentrancy. The contracts that will use the Permit2Lib could break unexpectedly.  Uniswap - Permit2 -   12  CriticalHighCodeCorrectedMediumLowCodeCorrectedSecurityHighVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f  The STATICCALL is used to query the DOMAIN_SEPARATOR in    of the code.  Uniswap - Permit2 -   13  Version2\f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Overflow Theoretically Possible for ", "body": " AllowanceTransfer.nonces  nonce   Nonces  are  incremented  with  unchecked  arithmetic.  This  means  that  incrementing  them  may  lead  to overflows, allowing for replay attacks. This is unlikely to happen solely through permit, which increases uint32.  However,  with the  AllowanceTransfer.invalidateNonces() overflows could happen after 65537 calls since it uses type uint16. Thus, signers can potentially endanger themselves by misusing the invalidateNonces function.  nonce   since   type   one   the   by   of   is    changes: nonce is of type uint48 in updated code. Thus, while the overflow is theoretically still  possible, practically it is highly unlikely to happen.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Signature Malleability if Misused", "body": "    of  the  code  the  SignatureVerification.verify  function  accepts  EIP-2098 In  the  compact 64 byte signature in addition to the traditional 65 byte signature format. If the replay protection mechanism  is  implemented  using  the  signature  itself,  an  attack  can  be  performed.  The  contracts  of Permit2  use  nonces  the SignatureVerification library must be done with this attack in mind. OpenZeppelin library had such an incident before.  thus  are  safe.  But  any   replay  protection  and   reuse  of   for   Also, the SignatureVerification does not perform checks described in Appendix F of the Ethereum Yellow  paper  e.g.  0  <  s  <  secp256k1n  \u00f7  2  +  1.  Thus,  for  any  given  signature  a  signature  with s-values in the upper range can be calculated. If the replay protection mechanism is implemented using the signature itself, an attack can be performed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   invalidateUnorderedNonces Possible", "body": " Arguments  SignatureTransfer.invalidateUnorderedNonces  can  invalidate  nonces  with  wordPos  values up  to  uint256.max.  However  _useUnorderedNonce  can  only  invalidate  up  to  uint248.max.  This allows the invalidation of nonces that can never be used.  Uniswap - Permit2 -   14  NoteVersion1Version2NoteVersion2Version2NoteVersion1          \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Blank Votes Not Counted", "body": "  0  1  5  4  4  In InclusionVote, the winner is determined as follows:  if votes > winner_votes:         candidate: address = self.candidates[epoch][i]         if self.rate_providers[candidate] in [empty(address), APPLICATION_DISABLED]:             # operator could have unset rate provider after             continue         winner = candidate         winner_votes = votes  CS-YEGOV-013  Yearn - yETH Governance -   14  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCorrectnessHighVersion1CodeCorrected         \fThe zero (blank) candidate will not have a rate provider set. The condition for continue will be fulfilled and the winner_votes will not be set to the blank votes.  As  a  result,  the  blank  votes  are  ignored  and  a  candidate  with  fewer  votes  than  the  blank  votes  can become the winner.    A special case has been added for candidate == 0x0. Now, the votes of the zero address are counted. Additionally,  the  zero  address's  rate_provider  is  not  set  to  APPLICATION_DISABLED  when  the  zero address is the winner.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Balance Used Instead of Voting Weight in ", "body": " DelegateMeasure  When  computing  the  voting  weight  of  an  account,  if  the  account  has  been  delegated  to,  the  following formula is used to compute the additional weight.  weight += Staking(staking).balanceOf(delegated) * self.delegate_multiplier / DELEGATE_SCALE  CS-YEGOV-018  Since the balance can be altered without delay simply by acquiring the staking token on the spot, the call to balanceOf is prone to manipulation.  This  issue  was  found  during  the  review.  It  was  also  reported  independently  by  Yearn  while  the  review was still ongoing.    This  was  fixed  in  vote_weight at the end of the week.    by  storing  delegated  stake  in  a  separate  vault,  which  only  updates  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Griefing by Flooding Malicious Proposals", "body": "  In GenericGovernor, as long as an attacker holds at least propose_min_weight tokens, they can submit as many proposals as they want, paying only gas.  If these proposals would hurt the protocol, other users are forced to vote nay each time, to ensure the proposal does not pass. There is no quorum needed to pass a proposal.  It  may  also  be  problematic  if  the  same  proposal  is  submitted  multiple  times.  Voters  will  need  to coordinate and choose which of these they want to pass, while rejecting the others. See also: Voters trust proposal author not to retract.  CS-YEGOV-015    Yearn - yETH Governance -   15  CorrectnessMediumVersion1CodeCorrectedVersion2DesignMediumVersion1CodeCorrected                \fA quorum has been added to the GenericGovernor, meaning that a minimum number of yes + no votes is now  required  for  a  proposal  to  pass.  Governance  functions  for  setting  the  quorum,  as  well  as  view functions to read it have also been added.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   InclusionVote Operator Trust", "body": "  CS-YEGOV-016  The  InclusionVote  contract  has  an  operator  role,  which  is  tasked  with  setting  rate  providers  for proposed tokens.  In the current implementation, the operator can change the rate provider at any time. In particular, it can change the rate provider even after voters have already voted.  This design results in the operator role needing to be fully trusted to set a correct rate provider.  If an alternative design was chosen where the rate provider can no longer change between the beginning of the voting period and finalize_epoch(), the voters could ensure that they are voting for a correct rate provider and that it cannot change after their vote. This would reduce the trust assumption on the operator role.    Now, the operator can only change a rate provider that was previously set if:  1. The voting period of the current epoch has not started  2. The previous epoch has already been finalized  If the rate provider has never been set (still 0x0), it can still be added at any time.  This means that voters can now independently check that the operator has set a correct rate provider, and can be sure that it will not change after they vote. This reduces the trust required in the operator.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Proposals Can Be Enacted After More Than", "body": " One Epoch  CS-YEGOV-014  To enact proposals in the GenericGovernor via enact, the proposal state is checked and asserted to be  PASSED  by  calling  _proposal_state().  The  function  _proposal_state  explicitly  returns PASSED  only  if  current_epoch  ==  vote_epoch  +  1.  Consequently,  a  proposal  must  be  enacted one epoch after vote_epoch.  However, by calling update_proposal_state() on a proposal that just passed, it is possible to set the state of this proposal to PASSED in storage. In this case, it is possible to circumvent the condition that a proposal needs to be enacted one epoch after vote_epoch, because _proposal_state() returns PASSED from now on due to: if state != STATE_PROPOSED return state.  This will allow the execution of the proposal forever, even though it should revert if it is not executed in the epoch after passing.    Yearn - yETH Governance -   16  TrustMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fThe  state  is  now  reevaluated  when  calling  _proposal_state(),  even  if  the  storage  was  set  to PASSED.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Voters Trust Proposal Author Not to Retract", "body": "  CS-YEGOV-012  In  GenericGovernor,  a  proposal  can  be  retracted  by  its  author  at  any  point  up  until  the  end  of  the voting period. This means that the author can grief voters by retracting maliciously.  Consider the following situation:  1. The community decides off-chain that a certain proposal is something they want to vote on.  2. Alice has propose_min_weight votes and anonymously submits the proposal.  3. The proposal receives 99% yea votes.  4. One hour before the vote period ends, Alice retracts the proposal.  5. Now the proposal will not be executable and it will take at least another epoch until it can be voted  on again and pass.  To avoid this, the proposal author needs to be trusted by the voters.  As a possible countermeasure, the same proposal could be submitted multiple times by different authors. However,  this  could  be  problematic  if  the  proposal  does  something  which  should  not  happen  multiple times, (e.g., send some tokens) and more than one of the proposals pass.    Proposals can now no longer be retracted once the voting period has begun.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Access Control Can Have Invalid Value", "body": "  The access control in Executor is set using the Access enum. When something should have a whitelist, the enum is set to a value of 1, when it should have a blacklist, it is set to a value of 2. If neither is true, it should be set to the default value of 0.  However, in Vyper it is also possible to set enum in such a way that multiple \"flags\" are set at once, not just  one.  set_access()  has  no  sanity  check  for  the  access  argument.  As  a  result,  set_access() could be called by the management with a value of 3, which is a valid value in Vyper and represents the states whitelist and blacklist being true at the same time.  However, the contract is not designed to handle this value and will treat it the same as 0.  CS-YEGOV-009    A  check  has  been  added  that  disallows  values  that  are  greater  than  2.  Now  the  only  possible  enum values are default, whitelist and blacklist.  Yearn - yETH Governance -   17  TrustMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.8   Delegation Could Allow Double Voting  CS-YEGOV-011  In DelegateMeasure, an address that has given a delegation to another address, has a vote_weight of 0, which means it can no longer vote directly.  However,  the  delegate()  function  does  not  check  if  the  address  that  is  giving  delegation  has previously voted during the current epoch. As a result, it is possible that an address first votes with its own vote_weight, then delegate() is called. This would allow the voting power to be used a second time by the address receiving the delegation.  Note  that  delegate()  can  only  be  called  by  the  management  role,  which  is  expected  to  be  used through the GenericGovernor. In this case, the issue can be avoided by calling enact() before the VOTE_PERIOD starts, given that the delay is smaller than VOTE_START.    This  was  fixed  in  vote_weight at the end of the week.    by  storing  delegated  stake  in  a  separate  vault,  which  only  updates  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Number of Assets Could Change During Vote", "body": "  In WeightVote, the number of assets in the Pool is queried once when the first vote in a voting period happens. The value is cached and not updated for the rest of the epoch.  If the number of assets changes within the voting period, it will be impossible to vote for the newly voted asset. This would only happen if the execute function of PoolGovernor is called late (in the last week of the epoch) by the operator.  CS-YEGOV-010    Yearn removed the caching of the number of tokens and now queries them directly from the pool.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Race Condition in GenericGovernor", "body": "  If a proposal is passed that stops another proposal in the same epoch from being enacted, whether by explicitly  canceling  it  or  by  modifying  common  parameters  such  as  majority,  then  a  race  condition occurs whereby depending on the order in which the proposals are enacted, the end result is different.  Note that enact() can be called by anyone, thus this ordering is also subject to MEV.  Yearn found and reported this issue while the review was ongoing.  CS-YEGOV-005    Yearn - yETH Governance -   18  DesignLowVersion1CodeCorrectedVersion2DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \fIn  epoch.  , enact() uses the values of majority and delay snapshotted at the end of the previous  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Majority Parameter Can Be Less Than Fifty", "body": " Percent  In GenericGovernor, the majority parameter can counterintuitively be set to less than 50%.  This would mean that a proposal with more no votes than yes votes can pass.  CS-YEGOV-006    Yearn now enforces a range betweeen VOTE_SCALE / 2 and VOTE_SCALE for majority.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Missing Events", "body": "  The  constructors  of  DelegateMeasure,  Executor,  GenericGovernor,  InclusionIncentives, InclusionVote, OwnershipProxy, PoolGovernor, WeightIncentives and WeightVote do not emit the SetManagement() event.  CS-YEGOV-008  Specfication changed  Yearn answered:  This is intentional, as it would require to also emit events for a lot of other parameters during the constructor to be fully consistent. For example, in the generic governor constructor we set a value for measure, delay, quorum, majority and delay.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Sanity Checks", "body": "  Multiple  functions  do  not  sanitize  their  input.  E.g.,  the  Executor  contract  in  set_access(), set_governor(),  whitelist()  and  blacklist()  do  not  check  for  address  zero.  We  advise reviewing which functions would benefit from a sanity check, even if they are permissioned.  CS-YEGOV-007    Yearn  changed  the  listed  functions  and  implemented  sanity  checks.  We  additionally  assume  Yearn checked all other potential functions and added checks.  Yearn - yETH Governance -   19  Version2InformationalVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrected                    \f6.14   Should Governance Be Able to Evict the Treasury  CS-YEGOV-017  the   setTreasury()   In  and WeightIncentives,  the  management  role  has  the  power  to  change  the  treasury  address  to  an arbitrary  value.  The  yETH  protocol  is  designed  to  be  governed  by  st-yETH  holders.  At  the  same  time, YIP-72 says that the treasury should be the \"Yearn Treasury or an autonomous splitter contract directed by yBudget.\" Is it intended that holders are able to direct the treasury revenue away from Yearn?  InclusionIncentives   InclusionVote,   function   of   Specification changed  This described behavior was originally intended. But after being raised and careful consideration, Yearn decided that only the treasury shall be allowed to call setTrasury and changed the code accordingly.  Yearn - yETH Governance -   20  InformationalVersion1Speci\ufb01cationChanged    \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Gas Optimisations", "body": "  We discovered the following potential gas optimizations:  1. The Proxy interface in Executor uses Bytes[65536] as data argument, but the OwnershipProxy only  supports  Bytes[2048].  The  calldata  variable  in  execute()  also  uses  this  large  Array size.  In  Vyper,  arrays  reserve  memory  slots  for  their  maximum  size,  even  when  many  of  the elements are zero. As a result, the memory will be extended by 65536 Bytes as soon as another variable is placed in memory after the array. This is very expensive.  2. uint could be used instead of boolean values. E.g., as governor flag in Executor.  CS-YEGOV-003  Code partially corrected  Yearn decided to decrease the overall max script size to Bytes[2048]. In the rare case that a proposal requires  a  script  larger  than  this,  they  can  work  around  it  by  deploying  a  one-time  use  contract  that  is granted a temporary governor role during execution.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   PoolGovernor Can Skip Epochs", "body": "  The  PoolGovernor's  execute  function  always  executes  the  vote  results  for  epoch  -  1.  This  means that  if  execute()  is  not  called  during  an  epoch,  the  preceding  epoch's  vote  results  will  never  be executed.  The winner in InclusionVote has its rate_provider set to APPLICATION_DISABLED, so if an asset wins but then the execution of the winning epoch is skipped, that asset cannot be proposed again unless the operator of InclusionVote sets the rate_provider again.  The  execute  function  can  only  be  called  by  the  operator  of  PoolGovernor.  If  the  operator  is unavailable or malicious, it may not be called.  CS-YEGOV-001  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Unused Code", "body": "  The following code is not used:   WeightVote: the interface definition of Measure.total_vote_weight   InclusionVote: the interface Measure.total_vote_weight  CS-YEGOV-004  Yearn - yETH Governance -   21  InformationalVersion1CodePartiallyCorrectedInformationalVersion1InformationalVersion1CodePartiallyCorrected              \f InclusionIncentives:   the   interface  voting.candidates_map  and   the  constants  VOTE_START and VOTE_LENGTH.   WeightIncentives: the constants VOTE_LENGTH and VOTE_START   GenericGovernor: the interface definition Measure.total_vote_weight  Code partially corrected  The unused interfaces were removed. The unused constants still exist in WeightIncentives.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   DelegatedStaking Does Not Strictly", "body": " Conform to ERC-4626  maxDeposit() and maxMint() return  . Per ERC-4626, \"MUST NOT be higher than the actual maximum that would be accepted\". The balance is eventually stored packed in only 240-bits. Therefore, . However, this is not enforced in the code, rather the supply of ETH the theoretical maximum is  is assumed to upper-bound the system.  CS-YEGOV-002  Yearn - yETH Governance -   22  InformationalVersion1    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Epoch Boundary Agreement", "body": "  To prevent double voting, VOTE_LENGTH should always be at most one week, EPOCH_LENGTH should always be a multiple of one week, and genesis should be set to a multiple of one week. This is to be consistent with the current Staking contract which provides voting weights.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Governance Proposal Passes In The Event Of", "body": " A Tie  In GenericGovernor, the condition for a proposal to be treated as passed is as follows:  if votes > 0 and yea * VOTE_SCALE >= votes * self.majority:     return STATE_PASSED  Assuming majority is 50% and a proposal has one yea and one nay vote, it will pass.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Limted Number of Pool Tokens", "body": "  Pools have 32 slots. This sets a cap to the maximum number of tokens to add. Once included, a token can never be removed from the protocol. Removing tokens from a pool would need a redeploy.  In PoolGovernor, the execute function will get the winner of the InclusionVote and try to add it to the Pool.  If there are already 32 assets in the Pool and InclusionVote has a winner, execute() will revert. This will also make it impossible to change the weights during that epoch.  The management of InclusionVote should call disable() once there are 32 assets to avoid this.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Power of the PoolGovernor Operator", "body": "  The specifications currently say that the operator of PoolGovernor has limited power. This is true but the operator role is still extremely powerful as it must be trusted to set the pool values like amplification and ramping in a non-exploitable way. The parameters the operator role can set are critical in a yETH pool and related to other parameters. Hence, as mentioned in the system assumptions, ths role needs to be fully trusted.  Yearn - yETH Governance -   23  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   Ramp_Duration Should Be Chosen Carefully  The ramp_duration variable in PoolGovernor should be chosen carefully. If it is too short, it may be possible to make profitable sandwich attacks.  It  should  also  not  be  too  long.  In  particular,  it  must  be  shorter  than  the  length  of  an  epoch,  as  assets cannot be added to the Pool while there is an ongoing ramp. The operator of PoolGovernor should call  execute()  at  least  ramp_duration  before  the  end  of  the  epoch,  so  that  the  ramp  ends  by  the time execute() is callable again.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.6   Rebasing and Fee-On-Transfer Tokens Cannot", "body": " Be Used as Incentives  Both  InclusionIncentives  and  WeightIncentives  keep  internal  balances  for  tokens  used  as incentives. This is done in such a way that, if the contract ends up with more tokens than expected, then the  leftover  amount  will  be  lost.  If  the  contract  ends  up  with  fewer  tokens  than  expected,  then transfer() will fail and the last user to claim will not be able to receive the incentives they are owed.  Yearn - yETH Governance -   24  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   CRV Not Locked When Used to Mint YCRV", "body": "  When YCRV is minted with the mint() function, CRV is not locked.  In yveCRV, CRV is locked upon minting. In YCRV.mint(...) it is not locked immediately, but a separate call to StrategyProxy.lock() is needed.  assert ERC20(CRV).transferFrom(msg.sender, VOTER, amount)  # dev: no allowance self._mint(_recipient, amount) log Mint(msg.sender, _recipient, False, amount) return amount  Not locking the CRV immediately in the CRV voting escrow implies a mismatch between the total supply of  YCRV  and  the  effective  voting  power  and  total  rewards  of  VOTER.  It  also  imposes  increased  trust requirements towards governance, which might sweep the not yet locked CRV from the VOTER.  Risk accepted  Yearn states:  Locking CRV is gas intensive. Decision was made to have locking occur at some periodic interval via external process rather than burden each user with gas costs.  Yearn - yCRV and ZapYCRV -   10  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedLowRiskAcceptedCorrectnessMediumVersion1RiskAccepted             \f5.2   Trades During ZapYCRV.zap Conversions  The ZapYCRV.zap function can involve multiple Curve pools during the conversion.  First, CRV -> LPYCRV conversions will involve up to 2 trades in LPYCRV pool:  1. Trade of all CRV to yCRV  2. Trade of some yCRV to CRV, during the unbalanced deposit into the pool  Compared to trade of some CRV to yCRV and a balanced deposit, the 2 trades double pay the fees.  Second,  in  the  case  when  CVXCRV  is  an  input,  these  2  trades  are  preceded  by  a  trade  on CVXCRVPOOL.  Please  note,  that  due  to  number  of  pools  and  exchanges  during  the  conversion  process  the  min_out argument  can  be  hard  to  specify  precisely.  In  addition,  imprecise  min_out  specified  would  allow  3rd parties to front run the zap.  Risk accepted  Yearn states:  Realize that for some specific paths, this can be inefficient. However, hardcoding paths will lead to more contract complexity and overall gas consumption (including for users who\u2019s zap path touches neither of these tokens) which we view as undesirable. We agree that users can potentially lose more due to swap fees, but ultimately most of those same fees get realized to the pool LPs, helping to repay them over time.  Yearn - yCRV and ZapYCRV -   11  SecurityLowVersion1RiskAccepted        \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   LPYCRV Outputs Not Transferred to User   -Severity Findings  Incorrect relative_price When Input Is Not Legacy and Output Is LPYCRV   -Severity Findings   ZapYCRV _min_out LPYCRV Limit   -Severity Findings   ERC20 Return Values Not Checked    ZapYCRV.zap Natspec   1  1  1  2  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   LPYCRV Outputs Not Transferred to User", "body": "  In the zap function of ZapYCRV, converting to LPYCRV as _output_token will not transfer LPYCRV to the user but leave it in the ZapYCRV contract instead.  When  LPYCRV  is  the  output  token,  ZapYCRV  should  first  deposit  YCRV  as  liquidity  in  the  POOL StableSwap pool, receiving the POOL liquidity token. The POOL liquidity token should then be deposited in the LPYCRV vault and the issued shares transferred to the user.  The following line of code in _convert_to_output is responsible for the specified logic.  amount_out: uint256 = Vault(LPYCRV).deposit(self._lp([0, amount], _min_out,     _recipient))  which calls the self._lp(...) function, defined as  @internal def _lp(_amounts: uint256[2], _min_out: uint256, _recipient: address) -> uint256:     return Curve(POOL).add_liquidity(_amounts, _min_out)  The  _recipient  argument  is  passed  to  the  _lp  function,  but  never  used.  The  _lp  function  doesn't actually need the _recipient argument, because ZapYCRV will still need to deposit the liquidity token into the LPYCRV vault.  The Vault(LPYCRV).deposit function is called without specifying the recipient argument, which therefore  defaults  to  msg.sender,  which  is  the  ZapYCRV  contract  in  the  context  of  the  deposit  call. Finally the zap function returns and the issued shares of LPYCRV are never transferred to the user, but left to ZapYCRV instead.  Yearn - yCRV and ZapYCRV -   12  CriticalCodeCorrectedHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCorrectnessCriticalVersion1CodeCorrected         \fCode corrected  The recipient argument of the _lp function has been removed.  @internal def _lp(_amounts: uint256[2]) -> uint256:         return Curve(POOL).add_liquidity(_amounts, 0)  A  recipient  value  _convert_to_output function.  is  now  specified   in   the  deposit  call   to   the  LPYCRV  vault   in   the  amount_out: uint256 = Vault(LPYCRV).deposit(self._lp([0, amount]), _recipient)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Incorrect relative_price When Input Is Not", "body": " Legacy and Output Is LPYCRV  In relative_price the relative price for the POOL liquidity token is returned instead of the relative price of LPYCRV when _input_token is not a legacy token and _output_token is LPYCRV.  The relative price for _input_token not in legacy_tokens and _output_token equal to LPYCRV is computed as follow:  return amount * 10 ** 18 / Curve(POOL).get_virtual_price()  This doesn't take into account that the output token is LPYCRV and not POOL, so the POOL tokens need to be used to purchase LPYCRV shares at price Vault(LPYCRV).pricePerShare().  When _input_token is a legacy token, it is computed correctly as follows:  lp_amount: uint256 = amount * 10 ** 18 / Curve(POOL).get_virtual_price() return lp_amount * 10 ** 18 / Vault(LPYCRV).pricePerShare()  Code corrected  return amount * 10 ** 18 / Curve(POOL).get_virtual_price()  is replaced with  lp_amount: uint256 = amount * 10 ** 18 / Curve(POOL).get_virtual_price() return lp_amount * 10 ** 18 / Vault(LPYCRV).pricePerShare()  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   ZapYCRV _min_out LPYCRV Limit", "body": "  In ZapYCRV.zap, the _min_out argument of the zap function asserts a lower bound on the amount of output token received by the user. When _output_token is LPYCRV it incorrectly asserts the amount of liquidity tokens issued as an intermediate conversion step by Curve(POOL).add_liquidity.  Yearn - yCRV and ZapYCRV -   13  CorrectnessHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \fIn the LPYCRV branch of _convert_to_output, _min_out gets first passed to _lp(), which uses it as a lower bound to the amount of liquidity tokens issued by Curve(POOL).add_liquidity()  @internal def _lp(_amounts: uint256[2], _min_out: uint256, _recipient: address) -> uint256:     return Curve(POOL).add_liquidity(_amounts, _min_out)  It is then used again as a lower bound for amount_out issued by Vault(LPYCRV).deposit().  amount_out: uint256 = Vault(LPYCRV).deposit(self._lp([0, amount], _min_out, _recipient)) assert amount_out >= _min_out # dev: min out  This  basically  makes  _min_out  used  for  limit  of  LPYCRV  vault  shares  and  POOL  LP  shares.  Due  to how the share values are computed, in the general case they will be not worth 1:1. Thus, _min_out as a limit is not practical.  Code corrected  The _min_out argument of the _lp function has been removed. Thus it is not used as a lower bound to the amount of liquidity tokens issued by Curve(POOL).add_liquidity() anymore.  @internal def _lp(_amounts: uint256[2]) -> uint256:     return Curve(POOL).add_liquidity(_amounts, 0)  Yearn notes:  Hardcode the minimum to 0 in add_liquidity, as we will rely on subsequent check to compare user inputted min_out.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   ERC20 Return Values Not Checked", "body": "  According to EIP-20, Callers MUST NOT assume that false is never returned. However, not all calls to ERC20 assert that true is returned. ZapYCRV and yCRV do not check bool success values for calls to ERC20.approve  and  ERC20.transfer.  Even  though  in  most  cases  the  contracts  are  known  in advance and it is safe not to check this value, new features and codebase reuse can lead to potential problems.  In function sweep in both contracts the return value of ERC20.transfer can be missing, if for example USDT is used. In that case the call will fail.  Code corrected  Asserts have been added to the approve and transfer calls to make sure that true is returned.  Compiler  version  has  been  increased  to  vyper  0.3.6  in  order  to  use  the  external  call  keyword argument  default_return_value=True,  which  ensures  that  transfer  calls  do  not  revert  when calling non EIP-20 compliant tokens such as USDT which do not return a boolean value.  Yearn - yCRV and ZapYCRV -   14  CorrectnessLowVersion1CodeCorrected          \f6.5   ZapYCRV.zap Natspec  The  @param  _input_token  for  zap  function  does  not  describe  that  cvxCRV  can  be  used  as  input token.  Code corrected  The cvxCRV has been added to the @param _input_token in the zap function's natspec.  Yearn - yCRV and ZapYCRV -   15  CorrectnessLowVersion1CodeCorrected      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Some but Not All Fees Are Accounted for in ", "body": " calc_expected_out  The natspec of calc_expected_out says that fees are not accounted for when computing the result. But  actually,  almost  in  all  cases,  when  the  Curve  pools  are  used,  they  are  accounted.  The  only  case when the fees are not taken into account is when the output token is LPYCRV. Then the deposit of YCRV in POOL is simulated with Curve(POOL).calc_token_amount(...), which does not account for the fees.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   ZapYCRV Curve StableSwap Token Indices", "body": " Sanity Check  ZapYCRV  contract  uses  POOL  contract,  that  is  assumed  to  be  Curve  Finance  StableSwap  contract.  In StableSwap  the  tokens  can  be  in  any  order.  The  yCRV/CRV  pool  is  not  yet  deployed.  Thus,  the assumption that CRV will be index 0 and yCRV will have index 1 might be violated. A sanity check in the constructor  of  ZapYCRV  contract  can  prevent  human  and  misconfiguration  errors  and  lower  the  costs associated with redeployment.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   ZapYCRV Return Values Ignored", "body": "  the   ZapYCRV._zap_from_legacy   In  to IYCRV(YCRV).burn_to_mint  are  ignored.  Return  value  is  assumed  to  be  same  as  the  amount argument  that  the  function  takes.  However,  in  case  when  the  amount  is  equal  to  MAX_UINT256,  the burn_to_mint  might  return  other  value.  In  the  current  version  such  situation  should  never  happen, because  this  case  is  handled  by  the  zap  function  itself.  In  ZapYCRV._zap_from_legacy,  amount should never be equal to MAX_UINT256. However use of return value will prevent potential bugs in case of code reuse or if new features are added.  function   return   value   calls   the   of   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   yCRV as an ERC20 Implementation", "body": "  There are 2 things we would like to note regarding the yCRV token.  1. The approve function has a known race condition attack vector described here  Yearn - yCRV and ZapYCRV -   16  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f2. The  transferFrom  function  does  not  emit  Approval  event.  While  this  is  compliant  with specification,  one  cannot  reconstruct  the  state  of  user  allowances  based  only  on  events,  since transferFrom does not emit any special events that show that approval was used.  Yearn - yCRV and ZapYCRV -   17  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Gas Savings Part 2", "body": "  0  0  0  3  Trading._fillFacingExchange now transfers the fee from the contract to the operator on every call. When multiple maker orders are processed, there is a fee transfer for every one of them. The fee could be sent after all orders have been processed instead.  Acknowledged:  The client acknowledges the possible gas savings and chooses to keep the code as-is.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Accidental Token Transfers", "body": "  Tokens that have been accidentally sent to the contract can not be recovered.  Furthermore, if either the collateral token or one of the outcome tokens have been accidentally sent to the  contract,  the  next  executed  taker  order  will  receive  these  tokens  due  to  the  implementation  of Trading._updateTakingWithSurplus.  Risk accepted  Polymarket states:  Polymarket - Exchange -   10  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedRiskAcceptedCodePartiallyCorrectedDesignLowVersion2AcknowledgedDesignLowVersion1RiskAccepted                   \fRecovering tokens sent to the contract will require adding a permissioned ``withdrawTokens`` function, which introduces an unacceptably large trust assumption.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Gas Savings", "body": "  The following parts can be optimized for gas efficiency:   The OrderStructs.OrderStatus struct occupies 2 words in storage. Decreasing the size of the remaining field by 1 byte could reduce the space requirement to 1 word. This fix has to be applied with caution using safe casts where appropriate.   The field token in the Registry.OutcomeToken struct is redundant as a specific struct can only  be accessed with that value.   The call to validateTokenId(token) in Registry.validateComplement is redundant as the  very same call is performed in the following call to getComplement.   Trading._matchOrders  and  _fillMakerOrder  redundantly  compute  the  order  hash  again,  after it has already been computed by _validateOrderAndCalcTaking.   Trading._updateOrderStatus   performs  multiple   redundant   storage   loads   of  status.remaining.   Trading._updateTakingWithSurplus  performs  a  redundant  calculation   in   the  return  statement. Returning actualAmount yields the same result at this point.   Assets.getCollateral(),   Fees.getFeeReceiver(), Assets.getCtf(),  Fees.getMaxFeeRate()  are  redundant  since  the  variables  they  expose  are  public  and  already define equivalent accessors.  Code partially corrected:  OrderStructs.OrderStatus  still  occupies  2  storage  slots.  All  other  gas  savings  have  been implemented sufficiently.  Polymarket - Exchange -   11  DesignLowVersion1CodePartiallyCorrected          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  2  1  3  10  -Severity Findings   Signatures Are Valid for Any Address    ORDER_TYPEHASH Is Incorrect   -Severity Findings   Fee Rate Not Hashed   -Severity Findings   Fee Approval Required    Unintended Order Types Possible    Zero Address EOA Signer Considered Valid   -Severity Findings   FeeCharged Event Not Emitted in fillOrder    OrderStruct.taker Specification Inconsistent    Code Replication    Domain Separator Cached    Floating Pragma    Non-optimized Libraries Used    Order Status Possibly Incorrect    Struct Order Has Redundant Fields    Wrong Notice on Order.feeRateBps   isCrossing Incorrect When takerAmount Is 0   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Signatures Are Valid for Any Address", "body": "  Signatures.isValidSignature checks the validity of a given order's signature. For signature types POLY_GNOSIS_SAFE and POLY_PROXY, the code makes sure that an order's maker address belongs to the same account that signed the order.  This is not true for the signature type EOA. Any account can create a signature for an order that contains an arbitrary maker address. Since users give token approval to the protocol on order creation, malicious actors can generate orders for an account that already generated an order, but, for example, with a more favorable price. This order will then be executable although the account in question did not authorize it.  Code corrected  Polymarket - Exchange -   12  CriticalCodeCorrectedCodeCorrectedHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSecurityCriticalVersion1CodeCorrected         \fSignatures.verifyEOASignature  has  been  added,  which  additionally  ensures  Order.maker == Order.signer for EOAs.  that   the  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   ORDER_TYPEHASH Is Incorrect", "body": "  The  ORDER_TYPEHASH  in Hashing.hashOrder. It is used to calculate an EIP-712 compliant hash for an order which is then used to recover the signer of the given order. Since the typehash is incorrect, this mechanism will not work for correctly signed orders.  in  OrderStructs  does  not  equal   the  actual  encoded  data   Code correct  OrderStructs.ORDER_TYPEHASH is now computed at compile time on the correct structure signature.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Fee Rate Not Hashed", "body": "  Hashing.hashOrder does not include the fee rate of an order into the hash. If the signatures are also generated this way and users do not recognize this, operators can always specify MAX_FEE_RATE_BIPS fees.  Code correct  Order hash computation now includes feeRateBps.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Fee Approval Required", "body": "  Fees are charged by transferring the respective amount of tokens from the receiving user's account to the fee receiver.  The  user  has  to  give  additional  approval  for  the  token  they  actually  want  to  receive,  which  is counter-intuitive  and  also  opens  up  additional  security  risks.  Since  the  fee  is  always  smaller  than  the amount  of  tokens  sent  to  the  user,  this  special  behavior  is  not  necessary  as  the  fees  could  also  be deducted from the amount sent to the user.  Code correct  Fees are deducted directly on the exchange, instead of being pulled from the order maker. Additionally, _fillOrder implicitly collects fees by transferring the taking amount minus the fee from the operator.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Unintended Order Types Possible", "body": "  Polymarket - Exchange -   13  CorrectnessCriticalVersion1CodeCorrectedDesignHighVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                                \fTrading._matchOrders  and  _fillOrder  miss  sanity  checks  for  combinations  of  makerAssetId, takerAssetId and side in the passed order structs.  of   in combinations  Eight  [ConditionalToken,  in [ConditionalToken,  Collateral]  are  possible,  but  only  two  of  them  should  be  allowed.  This seems  possible  as  the  side  seems  redundant  or  colliding  with  the  combinations  (struct  Order  has redundant fields).  takerAssetId   Collateral],   makerAssetId   SELL],   [BUY,   side   and   in   This  allows  for  matching  of  orders  that  are  not  intended.  For  example,  matching  of  a  BUY  order  with maker asset YES and taker asset USDC to a SELL order with maker asset USDC and taker asset YES is perfectly possible as long as the YES price in these orders is over 1 USDC (otherwise, the fee calculation reverts).  Code correct  Unintended order types are no longer possible as fields makerAssetId and takerAssetId have been replaced by a single field tokenId.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Zero Address EOA Signer Considered Valid", "body": "  isValidSignature() returns true for signer equal to zero address, signatureType EOA and invalid signature.  The  check  is  performed  at  line  70  of  Signature.sol,  SilentECDSA.recover  returns  0  on  error. Setting the signer to zero address will incorrectly validate the signature.  Code correct  Signature  verification  now  uses  Openzeppelin's  ECDSA.recover  instead  of  SilentECDSA.  Invalid signatures now revert instead of returning the 0-address.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   FeeCharged Event Not Emitted in fillOrder", "body": "  in _fillOrder, the fee is charged implicitly by deducting it from the amount that is transferred to the order  maker  but  a  FeeCharged  event  is  not  emitted.  For  consistency  and  to  allow  proper  accounting based on events, FeeCharged should be emitted.    The event is now emitted.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   OrderStruct.taker Specification Inconsistent", "body": "  Polymarket - Exchange -   14  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion2CodeCorrectedCorrectnessLowVersion2Speci\ufb01cationChanged                        \fThe taker field of the Order struct actually identifies the operator which can fill the order, not the taker that can be matched with the order as it seems to be intended from the natspec notice.  Specification changed:  The natspec of taker has been modified to reflect its actual usage.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Code Replication", "body": "  Trading._fillOrder  same  _validateOrderAndCalcTaking. For maintainability reasons, code replications should be avoided.  contains   present   already   code   that   the   is   in  Code correct  Duplicated  refactored  _performOrderChecks (renamed from _validateOrderAndCalcTaking).  in  Trading._fillOrder   been   code   has   into   the   function  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Domain Separator Cached", "body": "  Hashing exposes the domainSeparator with an implicit public getter for an immutable variable. When the chain id changes, for example due to a hardfork, the domainSeparator will not be correct on the new chain.    The domainSeparator is now re-calculated in case of a change of the chain id.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Floating Pragma", "body": "  Exchange uses the floating pragma <0.9.0. Contracts should be deployed with the compiler version and flags that were used during testing and auditing. Locking the pragma helps to ensure that contracts are not accidentally deployed using a different compiler version and help ensure a reproducible deployment.  Code correct  Solidity version has been fixed to 0.8.15 in all instantiated contracts. Interfaces, libraries, and abstract contracts are left floating.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Non-optimized Libraries Used", "body": "  Polymarket - Exchange -   15  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                                \f TransferHelper re-implements transfer functions while there already exists an optimized library  (SafeTransferLib) implementing these functions in the dependencies of the project.   Signatures uses SilentECDSA, a modified version of an outdated OpenZeppelin ECDSA version. The current version of this library could be used instead since it provides all required functionalities.     TransferHelper now utilizes the optimized library for transfer functions.   Signatures utilizes the OpenZepplin library.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Order Status Possibly Incorrect", "body": "  Trading.getOrderStatus  returns  an  OrderStatus  struct  containing  a  variable  isCompleted  for any order hash. As the protocol has two distinct mechanisms of invalidating orders, this function might return that an order is still not completed, while in fact it has been invalidated by a nonce increase.    The field isCompleted has been renamed to isFilledOrCancelled which describes the behavior in an adequate way.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Struct Order Has Redundant Fields", "body": "  In struct Order, the fields side, makerAssetId, and takerAssetId coexist redundantly.  If side is BUY, makerAssetId is implied to be 0. If side is SELL, takerAssetId is implied to be 0. a single  AssetId  field  would  therefore  be  sufficient  to  fully  specify  the  order,  or  similarly  side  can  be removed from the struct and be derived from makerAssetId and takerAssetId.  Redundant input arguments increase code complexity and facilitate potential bugs.    The fields makerAssetId and takerAssetId have been removed in favor of a new field tokenId.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   Wrong Notice on Order.feeRateBps", "body": "  The notice of feeRateBps says:  If BUY, the fee is levied on the incoming Collateral  However, the fee is always charged in the takerAssetId, which is not necessarily the collateral.  Specification changed:  The  Fee rate, in basis points, charged to the order maker, charged on proceeds.  feeRateBps   notice   now   for   reads:  Polymarket - Exchange -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                          \f6.16   isCrossing Incorrect When takerAmount Is 0  In the event of a SELL-SELL matching, where tokens should be merged to provide collateral back to the sellers,  CalculatorHelper.isCrossing  returns  true  when  at  least  one  side's  order  has takerAmount == 0. In the case that the other side's order has a price greater than ONE, the matching is not crossing since no sufficient amount of collateral can ever be redeemed to cover price > ONE, however the isCrossing returns true.    isCrossing now returns false in the mentioned cases.  Polymarket - Exchange -   17  CorrectnessLowVersion1CodeCorrected      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Incorrect Dense Selector When One Bucket Is", "body": " Empty  CS-VYPER_SEPTEMBER_2023-001  When generating a selector table with the codesize optimization, _dense_jumptable_info() tries to generate buckets and their corresponding magic number given a number of buckets. This function is called by generate_dense_jumptable_info() with different numbers of buckets to produce a table with as few buckets as possible. In the case where _dense_jumptable_info() is given some number of buckets to generate n but ends up with only m non-empty buckets (m < n), the returned python dict only contains m elements. As the code generation for the selector table uses m as the number of buckets, the latter will not behave as it should since:  Vyper - Vyper Compiler -   11  SecurityDesignCorrectnessCriticalHighMediumLowCorrectnessHighVersion1            \f To  get  the  bucket  of  a  method  id  x,  x  mod  m  is  computed  at  runtime  although  the  function  was  placed in the bucket x mod n at compile time.   The data section for the buckets header will miss one row for the empty bucket, meaning that even if there is some function with an id x such that r = x mod m = x mod n, if r > b where b was the of the empty bucket's id, the bucket r - 1 will be searched instead of the bucket r.  As m < n, the bucket information (bucket data section, bucket magic number and bucket size) copied at runtime  will  always  be  some  valid  bucket  and  won't  be  some  random  data  out  of  the  header's  data section. From there, the provided method ID is compared to the method ID of the function of the bucket whose  magic  number  matches,  the  execution  should  revert  as  in  the  case  where  the  wrong  bucket  is being  used,  no  function  will  match  the  method  ID.  In  other  words,  this  issue  makes  functions  of  the contract  revert  when  they  should  not,  but  does  not  allow  for  unexpected  or  restricted  actions  on  the contract.  For  example,  calling  the  function  aJ3EJUYUK  on  the  following  contract  compiling  with  the  codesize optimization will revert.  @external def aJ3EJUYUK()->uint256:     return 1 @external def a9XXCI8PW()->uint256:     return 2 @external def aOBAJXNGO()->uint256:     return 3 @external def a0FUKH9AF()->uint256:     return 4 @external def a5ELEP7F4()->uint256:     return 5 @external def a3Y10PU1H()->uint256:     return 6 @external def aKX7ATQCX()->uint256:     return 7 @external def aT12B3E6Y()->uint256:     return 8 @external def a7U1B9OBW()->uint256:     return 9 @external def aGLOLGNUZ()->uint256:     return 10 @external def a7V3L4VPT()->uint256:     return 11 @external def aREJI588E()->uint256:     return 12 @external def a7XVZOF81()->uint256:     return 13  Vyper - Vyper Compiler -   12  \f@external def aNJK5DHE9()->uint256:     return 14 @external def aDJT6R9PE()->uint256:     return 15  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Incorrect Re-Entrancy Lock When Key Is", "body": " Empty String  The nonreentrant decorator does not protect functions in the case that the provided key is the empty string. Note that this issue is being tracked in a security advisory 1  CS-VYPER_SEPTEMBER_2023-002  @nonreentrant(\"\") # unprotected @external def bar():     pass  @nonreentrant(\"lock\") # protected @external def foo():     pass  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Memory Corruption in Builtins Utilizing msize", "body": "  CS-VYPER_SEPTEMBER_2023-003  As Vyper memory is statically allocated, in the cases where some data whose size is unknown at compile time must be stored in memory (calldata, extcodecopy), the compiler uses msize as the starting index of the memory that will be allocated for the data. In the general case, this solution is sufficient, however, in some edge cases, the compiler will allocate and use memory inside this buffer for other purposes after storing the data and before using them, thus, overwriting them.  The affected builtins are raw_call, create_from_blueprint and create_copy_of.   For raw_call, the argument buffer of the call can be corrupted, leading to incorrect calldata in the sub-context.  In  this  case,  when  the  data  to  pass  with  the  raw_call  is  msg.data,  as  there  is  no way to know the size of the calldata of the current context at compile time, the compiler uses msize as the beginning of the argument buffer for the call. As the argument to and the kwargs value and gas are evaluated after the calldatacopy and before the call, if their evaluation was to store to memory, it could overwrite the copied calldata.   For create_from_blueprint and create_copy_of, the buffer for the to-be-deployed bytecode can be corrupted, leading to deploying incorrect bytecode. Again, the kwargs value and salt are evaluated after the extcodecopy or codecopy and before executing create or create2. If they were to store to memory, they could overwrite the buffer for the bytecode to be deployed.  Vyper - Vyper Compiler -   13  SecurityHighVersion1SecurityHighVersion1            \fBelow are the conditions that must be fulfilled for the corruption to happen for each builtin:  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3.1   raw_call", "body": "   The data argument of the builtin is msg.data.   The to, value or gas passed to the builtin is some complex expression that results in writing to the  memory.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3.2   create_copy_of", "body": "   The value or salt passed to the builtin is some complex expression that results in writing to the  memory.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3.3   create_from_blueprint", "body": "   Either no constructor parameters are passed to the builtin or raw_args is set to True.   The value or salt passed to the builtin is some complex expression that results in writing to the  memory.  Note that more details and examples on the issue are described in the corresponding security advisory 2.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   _abi_decode Return Values Are Not Clamped", "body": "  The  returned  values  of  the  builtin  _abi_decode  are  not  clamped  and  can  be  out  of  bound  for  the specified Vyper type.  CS-VYPER_SEPTEMBER_2023-004  function  foo  of   The  the  contract  below  returns  3,  meaning  max_value(uint256) which is out of bounds for uint8 and that the addition overflowed 256 bits.  that  _abi_decode  returned  @external def foo() -> uint8:     x: Bytes[32] = _abi_encode(max_value(uint256), ensure_tuple = False)     y: uint8 = _abi_decode(x, uint8, unwrap_tuple=False) + 4     return y  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   ecrecover Can Return Undefined Data in", "body": " Some Edge Case  CS-VYPER_SEPTEMBER_2023-005 This  issue  is  an  edge  case  of  the  recent  security  advisory  3  for  ecrecover  that  was  missed  in  the corresponding fix 4.  As the ecrecover precompile does not fill the output buffer (memory location 0) if the signature does not verify, the ecrecover builtin would return whatever was in the buffer before. This issue was fixed by cleaning any dirty bytes at memory location 0 before evaluating the builtin.  Vyper - Vyper Compiler -   14  CorrectnessMediumVersion1SecurityMediumVersion1            \fAs the arguments of ecrecover are evaluated after this cleaning, if one of the arguments of the builtin was to be compiled to some bytecode storing to memory location 0, the data stored there would be the returned value of ecrecover in case of a signature that does not verify.  In the following contract, a foo would not revert as owner is stored at slot 0 by get_v().  owner: immutable(address)  @external def __init__():     owner = 0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf  @internal def get_v() -> uint256:     assert owner == owner # force a dload to write at index 0 of memory     return 21  @payable @external def foo():     assert ecrecover(empty(bytes32), self.get_v(), 0, 0) == owner # True  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Arguments Buffer Size Too Large When", "body": " Calling ecmul  CS-VYPER_SEPTEMBER_2023-006 PR3583  5 fixes an issue with the order of evaluation of the side effect of several builtins arguments  6. Although  the  issue  has  been  fixed  with  the  PR,  the  builtin  ecmul  is  performing  a  static  call  to  the corresponding precompile with an argument buffer size too large (128 bytes instead of 96 bytes).  Note that this issue has been communicated and fixed before the PR was merged.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.7   Arguments Passed to _abi_decode Are Not", "body": " Type-Checked  The type of arguments passed to _abi_decode are not validated and ensured to match the expected argument types of the builtin.  CS-VYPER_SEPTEMBER_2023-007  # should not compile but compiles @external def bar(j:String[32]) -> bool:     s:bool = _abi_decode(j, bool, unwrap_tuple= False)     return s  # should not compile but the compiler panics with: # AttributeError: 'IntegerT' object has no attribute 'maxlen'  Vyper - Vyper Compiler -   15  CorrectnessLowVersion1CorrectnessLowVersion1            \f@external def foo(j:uint256) -> bool:     s:bool = _abi_decode(j, bool, unwrap_tuple= False)     return s  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.8   Builtins' varargs Are Not Properly", "body": " Type-Checked  CS-VYPER_SEPTEMBER_2023-008  The builtins create_from_blueprint, print and _abi_encode use varargs to be able to accept an  arbitrary  number  of  additional  arguments.  The  compiler  only  checks  that  these  arguments  have  a proper Vyper type but does not enforce anything else. Passing for example an Hashmap or types in the varargs will make the compiler crash.  f:HashMap[uint256, uint256] @external def foo(blueprint: address):     # vyper.exceptions.TypeCheckFailure: assigning HashMap[uint256, uint256] to HashMap[uint256, uint256] 128 0 <self.f>     g:address =  create_from_blueprint(blueprint, self.f)  @external def bar():     # AttributeError: 'IntegerT' object has no attribute 'typ'     print(uint16)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.9   Compiler Panics When Overflowing the", "body": " Memory  Given  some  expression  that  overflows  the  memory,  the  compiler  panics  instead  of  exiting  with  some custom error.  CS-VYPER_SEPTEMBER_2023-009  For  vyper.exceptions.CompilerPanic: out of range.  compiling   example,   the   following   contract   results   in  @external def bar():     s:String[max_value(uint256)] = \"a\"  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.10   Documentation Inconsistencies", "body": "  CS-VYPER_SEPTEMBER_2023-010  Vyper - Vyper Compiler -   16  CorrectnessLowVersion1DesignLowVersion1CorrectnessLowVersion1                  \fIn  the  documentation  for  create_from_blueprint,  the  keyword  argument  raw_args  is  not documented.   create_from_blueprint's example code snippet does not compile in the latest Vyper versions  as the type String is used without maximum length.   The  documentation  of  raw_call  mentions  that  in  case  gas  is  not  set,  all  remaining  gas  is  forwarded while in reality \"all but one 64th\" of the current contract's gas is forwarded.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.11   Incorrect Typing of Literal Arrays When Used", "body": " With len  When  trying  to  get  the  length  of  a  literal  array  with  the  builtin  len,  the  compiler  fails  with  an InvalidType exception although literal arrays can usually be typed as dynamic arrays.  For example, the following contract fails to compile with an InvalidType exception.  CS-VYPER_SEPTEMBER_2023-011  @external def foo():     a: uint256 = len([1,2,3])  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.12   Outdated or Incorrect Comments", "body": "  CS-VYPER_SEPTEMBER_2023-012  The following comments are inconsistent with the compiler's behaviors.  In  ModuleAnalyzer.__init__(),  \"check  for  collisions  between  4byte  function  selectors\"  is referring to a removed check.  In _MinMaxValue.evaluate(), \"TODO: to change to known_type once #3213 is merged\" refers to a pull request that has been superseded and hence is outdated.   The  documentation  for  generate_ir_for_external_function()  is  not  up  to  date  as  it mentions for example check_nonpayable which has been removed with the new selector table.   The   layout  CreateFromBlueprint._build_create_IR() is incorrect.  described   memory   in   the   comment   of  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.13   Warning and Error Messages", "body": " Inconsistencies  The following warning and error messages could be improved.  In BitwiseNot.evaluate(), the warning mention the bitwise xor operator ^ instead of ~.  CS-VYPER_SEPTEMBER_2023-013  Vyper - Vyper Compiler -   17  DesignLowVersion1CorrectnessLowVersion1CorrectnessLowVersion1                      \fIn _validate_msg_data_attribute(), the first raised exception do not mention that msg.data can be used with raw_call.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.14   extract32 Return Type Can Be Any byteM", "body": "  CS-VYPER_SEPTEMBER_2023-014  to   both   in According  Extract32.infer_kwargs_types(),  extract32  can  have  as  return  type  bytes32,  address  or any integer type. However, given the check-in Extract32.infer_kwargs_types, it is possible to specify as return type any bytesM.  documentation   exception   raised   and   the   the   For example, the following code compiles:  @payable @external def foo(b:Bytes[32]):     x: bytes8 = extract32(b, 0, output_type = bytes8)  Vyper - Vyper Compiler -   18  CorrectnessLowVersion1       \f1 2 3 4 5 6  https://github.com/vyperlang/vyper/security/advisories/GHSA-3hg2-r75x-g69m https://github.com/vyperlang/vyper/security/advisories/GHSA-c647-pxm2-c52w https://github.com/vyperlang/vyper/security/advisories/GHSA-f5x6-7qgp-jhf3 https://github.com/vyperlang/vyper/commit/019a37ab https://github.com/vyperlang/vyper/pull/3583 https://github.com/vyperlang/vyper/security/advisories/GHSA-4hg4-9mf5-wxxq  Vyper - Vyper Compiler -   19  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Infinite Minting of Position Tokens With No", "body": " Value  For any resolved condition it is possible to mint an infinite amount of tokens for the losing outcomes from  token (i.e., a token with a collection ID of 0x0). For this to work, one outcome must receive all a single  the payout and the other outcomes must receive none.  ,  it  is For  example,  for  a  condition  with  binary  outcomes  ( possible to mint an infinite amount of   tokens have no value at this point, it is not an issue by itself but it should always be taken into account when designing a market around conditional tokens.  ),  if  the  condition  resolves  to    tokens from a single    token. Because the   We will now explain how to mint an infinite amount of losing tokens from a single    token.  From a previous audit on the conditional tokens contracts, we learn how to obtain one  collateral token (Chapter 6). Furthermore, it is stated that a  used with any position tied to CT.   token from one  token, tied to collateral token CT, can be  In case a particular market is created using Polymarket's NegRiskAdapter (instead of directly working with  the  ConditionalTokens  contract),  the  conversion  of  a    token  to  a  token  representing  a Polymarket condition must be tied to wrapped collateral. Polymarket uses wrapped collateral tokens as collateral  for  conditional  tokens.  Users  can  obtain  wrapped  collateral  tokens  by  redeeming  conditional tokens directly on the used ConditionalTokens instead of the adapter.  We assume that we have a condition with a conditionId C with two possible outcomes ( ) and that the condition has resolved to True. Furthermore, the notation H(T) represents the elliptic curve   while  H(F)  represents  the  same  for  outcome multi-hash  set  of  conditionId  C  with  outcome   .  The  first  step  of  converting  a  following arguments:    token  to  a     token  is  a  call  to  redeemPositions()  with  the   collateralToken: The collateral token CT used when creating the    token.   parentCollectionId:   , the additive inverse of    on the given elliptic curve.   conditionId: C.   indexSets: [0b01].  Because  the  condition  has  resolved  to  calculation  the tokens that should be redeemed) to one  possible as it would require redeeming an index set of     token  (the  result  of  the  that is performed in redeemPositions() to calculate the collectionId of  tokens is not   which does not have a payout vector.   token. We note that redeeming to   ,  the  function  will  convert  one   The next step is a call to splitPosition() with the following arguments:   collateralToken: CT.   parentCollectionId:   .   conditionId: C.   partition: [0b01, 0b10].  Polymarket - Conditional Tokens -   11  NoteVersion1  \f amount: The amount of obtained    tokens.   tokens and one  Equal amounts of  with the first step of this conversion.   tokens are created. The new    tokens can be re-used    tokens  can  be  split  in  another  step  to  equal  amounts  of     and     tokens  using splitPosition():   collateralToken: CT.   parentCollectionId:   .   conditionId: C.   partition: [0b01, 0b10].   amount: The amount of obtained    tokens.  The following graphic gives an overview of the conversion steps:  We notice that from a single  token can be transformed to a  two outcomes where all losing outcome tokens can be minted infinitely from a single    token we can obtain an infinite amount of    and a    token. The same issue arises for conditions with more than   tokens, since a single    token.  It is therefore important that, once a condition is resolved in the ConditionalTokens contract, there should  no  longer  exist  any  arbitrage  opportunities  for  the  respective  tokens  and  no  external  contract's accounting should rely on the token amounts to be correct.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   No Irregular ERC-20 Tokens Supported", "body": "  The  ConditionalTokens  contract  does  not  support  ERC-20  tokens  that  do  not  return  values  in  the transfer/approval functions (e.g., USDT).  Polymarket - Conditional Tokens -   12  NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Provoking an Aave Liquidity Crisis", "body": "  AaveKandel  stops  providing  liquidity  if  too  much  is  borrowed.  Generally,  market  makers  should  be aware of that. However, one can throw Aave temporarily into a liquidity crisis by  ISSUEIDPREFIX-001  1. flashloaning the entire balance  2. borrowing the entire balance  That  could  allow  an  attacker  to  create  a  temporary  liquidity  crisis  wrapping  a  sniping  operation  on Mangrove core for his profit.  However, note that the flashloaning attack is to some degree by the economic factor of Aave flashloans while the other operation can be achieved even for free by taking out free flashloan for collateral assets on other protocols. Such attacks are however limited by the borrow caps that Aave can impose. Namely, the attack can be carried out as long as the Aave's available capital after the borrow cap is reached is less than an offer's promised amount. Note that 1. and 2. can be combined to reduce the total cost of an attack with 1. so that the limit set by the borrow caps can be bypassed.  Risk accepted:  Mangrove Association (ADDMA) replied:  1/ deploy 80 offers from AAVE kandel (WETH,USDC) on mangrove  Note 1: 80 offers is the limit beyond which one cannot collect all failing offers because of stack overflow Note 2: WETH has borrow cap on AAVE so the attack has to be on offers that have USDC outbound  Mangrove Association (ADDMA) - Kandel Strats -   11  SecurityDesignCorrectnessCriticalHighRiskAcceptedMediumLowAcknowledgedSecurityHighVersion1RiskAccepted           \f2/ attacker supplies enough DAI on AAVE to be able to borrow the whole supply of USDC  Note 1: the script mocks up a flashloan of DAI to obtain enough collateral. There is currently no real way to flashloan DAIs on polygon. In the overall cost of the attack we add 400K gas as an estimate of the flashloan cost plus the cost of repaying the borrow on AAVE which is not scripted here (AAVE on polygon still does not allow repay and borrow on the same block, although ethereum deployment does). The attack using AAVE native flashloan has also been tested but result in a prohibitive cost for the attacker (around 1000 USD worth of fees).  Note 2: there is currently a supply cap on AAVE for DAI which is just enough to do this, but supplying a bit too much DAI actually reverts  3/ attacker borrows USDC supply and triggers a market order  4/ all 80 aave kandel offers trigger a failure cascade and the bounty is sent to the attacker Assuming a tx.gasprice == Mangrove\u2019s gasprice at 90 gwei, we get:      Attack collects 0.84691197 matics for 9 936 879 gas units     cost of the attack: 0.89431911 native tokens  Conclusion:    - Under favorable gas conditions for the attacker, drying up the AAVE pool can be profitable (when tx.gasprice is     significantly lower than Mangrove\u2019s). However the profit is quite low compared to traditional flashloan attacks     and not iterable: failing Aave Kandel\u2019s offer do not repost themselves. Yet the attack would at least be griefing     users as it would result in losing provision and having their offers unpublished from Mangrove.    - We believe the best protection relies on launching AAVE Kandel Strats on markets that have a borrow cap,     which would force the attacker of going through the costly AAVE flashloan mechanism to bypass the cap.    - The above script is included in the test AaveKandel.t.sol (test_liquidity_borrow_marketOrder_attack)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Posthook Revert Due to Overflow in Dual", "body": " Offer Computation  The maker posthook of Kandels can revert due to a potential overflow in dualWantsGivesOfOffer() in extreme scenarios. Consider the following example:  ISSUEIDPREFIX-002   Assume that the previously computed gives is equal to 2**96-1.   Assume that r is equal to (2*10**5)**8 = 2**8 * 10**40.   Hence, the first computed givesR will be (2**104-2**8) * 10**40, which needs 237 bits.  In  the  else  branch,  assume  that  order.offer.wants()  is  small,  e.g.  1,  the  updated  givesR now needs 256 bits   Hence,  with  offerGives  >=  2**19,  the  computed  wants  will  be  >  2**256  which  leads  to  a  reverting overflow.  Ultimately, the posthook for small offers could revert.  Acknowledged:  Mangrove Association (ADDMA) replied:  The scenario that yields an overflow occurs with unlikely values. The outcome of the overflow is to make offer logic\u2019s posthook fail and hence entails no penalty for maker.  Mangrove Association (ADDMA) - Kandel Strats -   12  DesignLowVersion1Acknowledged           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Depositing ATokens Allows Stealing Them   -Severity Findings  -Severity Findings   Wrong Dual Price Computation on Crossing Boundaries   -Severity Findings   Balance in Router Can Be Present    More Precision Can Be Used for wants    Reserve Balance Does Not Include Kandel's Balance    Tokens Without Return Values    AaveKandelSeeder Missing Active Market Check   1  0  1  5  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Depositing ATokens Allows Stealing Them", "body": "  The Aave v3 pooled router, allows arbitrary tokens. Tokens that are not supported by Aave are kept in the  router  contract  directly  and  treated  equivalent  to  buffered  tokens  coming  from  Aave  withdrawals. However,  depositing  aTokens  leads  to  accounting  issues,  treating  the  aTokens  received  from  actual supply operations as donations and, hence, buffered tokens.  ISSUEIDPREFIX-007  Consider the following scenario:  1. 1M aDAI held by the router (DAI was supplied).  2. Attacker creates Kandel and uses depositFunds() to supply 1 aDAI.  3. Since not shares exist for aDAI, the INIT_MINT will be minted. The supply fails but the code does  not revert since noRevert is true.  4. The attacker now uses withdrawFunds() to redeem aDAI.balanceOf(router) aDAI.  5. The  router's  withdraw  function  realizes  that  there  is  enough  buffered  amount  of  aDAI.  Hence,  toRedeem is 0.  6. _burnShares() first computes the shares to burn. Since there is no overlying for aDAI, the input amount will match the aDAI balance of the contract. Hence, the total shares for aDAI will be burned which are equal to INIT_MINT and thus equal to the attacker's shares. All shares are burned since the attacker is the only holder.  7. toRedeem is 0. Hence, withdrawing from Aave will not be tried. All the aDAI balance is sent to the  attacker.  Ultimately, all funds in the Aave pooled router could be at risk.  Mangrove Association (ADDMA) - Kandel Strats -   13  CriticalCodeCorrectedHighMediumCodeCorrectedLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected        \f  On  deployment,  the  AaveKandel  tries  to  call  UNDERLYING_ASSET_ADDRESS()  on  the  base  and  the quote token. In case staticcall does not revert, the token is classified as an aToken and the deployment will  revert.  In  case  the  staticcall  reverts,  the  error  is  caught  and  execution  proceeds.  Note  that  the staticcall could revert without the error message if the base or quote token are EOAs.  Further, only the base and quote tokens can be deposited to and withdrawn from the AaveKandel.  Both restrictions combined, prevent aTokens from being deposited to the router from Kandels.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Wrong Dual Price Computation on Crossing", "body": " Boundaries  When the dual price is computed, the function GeomertricKandel.dualWantsGivesOfOffer is not aware of how many steps the price should move to stay within the defined boundaries and will always move it by ratio**spread. Whenever steps <= spread holds, this can lead to prices that are off by factors of ratio on the boundary of the indices, thus breaking the assumption that each index should be at a distance ratio from its neighbors.  ISSUEIDPREFIX-013  Consider the following example:  1. The following setup is active:  pricePoints = 6 spread = 3 compoundRate = p = 10 ** PRECISION  2. A trade occurs against a Bid at index = 4 so that the dual offer parameters are (note that since  the pricePoints limit of 5 is exceeded, it is set to the maximum value allowed):  virtual_dual_index = 7 => dual_index = 5  dualOffer = Ask  Hence,  we  jump  by  only  1  index  and  expect  a  price  update  of  ratio  /  p.  Hence,  the expected price is the expected price at index 5  expected_wants / expected_gives = (order.wants * ratio**1 / p**1) / (order.gives)  3. The gives of the dual offer are computed (assume now that at index 5 gives had been 0):  new_gives = order.gives * compoundRate * ratio**spread / (ratio**spread * p) <=> new_gives = order.gives  4. The wants of the dual offer are computed:  new_wants = order.wants * new_gives * ratio**spread / (order.gives * p**spread) <=> new_wants = order.wants * order.gives * ratio**spread / (order.gives * p**spread) <=> new_wants = order.wants * ratio**spread / p**spread  Mangrove Association (ADDMA) - Kandel Strats -   14  CorrectnessMediumVersion1CodeCorrected        \f5. The price at index 5 is now:  new_wants / new_gives = (order.wants * ratio**spread / p**spread) / (order.gives)  Note that the new price at index 5 is distinct from the expected price.    The spread applied to the ratio is now updated by GeometricKandel.transportDestination for the price to stay within bounds.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Balance in Router Can Be Present", "body": "  Note that the documentation of AavePooledRouter.__pull__() specifies:  ///@dev outside a market order (i.e if `__pull__` is not called during offer logic's execution) the `token` balance of this router should be empty. /// This may not be the case when a \"donation\" occurred to this contract /// If the donation is large enough to cover the pull request we use the donation funds  ISSUEIDPREFIX-012  However, note that this is not necessarily the case since the posthook of the first puller could revert and leave the funds inside the router without pushing them out. However, after the next execution or the next deposit, the funds should be moved to Aave if everything works correctly.  Note that an attacker could force a balance into the router without donating to it by  increasing the total supply on Aave such that the supply cap makes the first puller's flushing revert.  trading  against  an  attacker-strategy-owned  Kandel  and  then  trading  against  the  attacker  strategy that changes the router of the Aave Kandel so that the Aave Kandel does not push and supply on the Aave router.  Specification Changed:  The comment has been adapted.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   More Precision Can Be Used for wants", "body": "  ISSUEIDPREFIX-009  When  computing  is  used  when uint160(givesR)  ==  givesR  ||  order.wants  <  2  **  18,  but  the  second  condition  can  be relaxed to be order.wants < 2 ** 19 to allow full precision more often.  the  wants  amount  of   the  dual  offer,   full  precision     The second condition has been relaxed to accept values < 2 ** 19.  Mangrove Association (ADDMA) - Kandel Strats -   15  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                    \f6.5   Reserve Balance Does Not Include Kandel's Balance  The  reserveBalance()  is  the  available  balance  for  a  strategy  of  an  offered  token.  Note  that  Direct strategies try to use the local balance always first, see function __get__().  ISSUEIDPREFIX-011  uint amount_ = IERC20(order.outbound_tkn).balanceOf(address(this)); if (amount_ >= amount) {   return 0; }  However, the AaveKandel does not account for the local balance (potentially received through donations) in reserveBalance().    The  function  AaveKandel.reserveBalance()  has  been  updated  to  take  its  own  balance  into account.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Tokens Without Return Values", "body": "  The Mangrove core system and the transfer libraries used in Kandel handle tokens without return values on transfers. However, for approvals return values are always expected. Note that this is not always the case due to tokens implementing the ERC-20 standard incorrectly (e.g., USDT).  ISSUEIDPREFIX-008    The approve() function handles now the case where no return value exists.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   AaveKandelSeeder Missing Active Market", "body": " Check  Only  the  (BASE,QUOTE)  market  is  checked  to  be  active  on  Mangrove,  but  the  (QUOTE,BASE)  base market should also be checked as it is used as well. If the inverse market is inactive, initial Ask and the Bid dual offers will fail to be posted.  ISSUEIDPREFIX-006    The two markets are now checked to be active on Mangrove in AbstractKandelSeeder.sow().  Mangrove Association (ADDMA) - Kandel Strats -   16  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f6.8   Explicit Variable Visibility  Several variables have undeclared visibility which results in variables being internal. Note that clear specifying clear visibility can help maintain code.  ISSUEIDPREFIX-005    Variables have now explicit visibility.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Gas Inefficiencies", "body": "  1. The internal function DirectWithBidsAndAsksDistribution.populateChunk initializes i to  0, this is a redundant assignment.  ISSUEIDPREFIX-004  2. When  using  tokenPairOfOfferType()  with  both  offer  function,  e.g., DirectWithBidsAndAsksDistribution.populateChunk  or DirectWithBidsAndAsksDistribution.retractOffers,  one  of  the  function  calls  can  be avoided by assigning the inverted token pair.  types   in  a   3. In the function CoreKandel.retractAndWithdraw the modifier onlyAdmin is unnecessary    For 3, the modifier was not removed by choice.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   NatSpec", "body": "  The  NatSpec  documentation  is  extensive.  However,  there  at  several  places  the  NatSpec  is  missing  or incomplete.  For  _supply,  checkAsset,  _totalBalance  or  balanceOfReserve  return  value  undocumented.  For  _sharesOfAmount,  mintShares  or  _burnShares  an  argument  undocumented. depositFunds or withdrawFunds do not have any NatSpec.  the   is is  Note that the examples are an incomplete list of lacking NatSpec documentation.  ISSUEIDPREFIX-010  Documentation changed:  The documentation has been adapted.  Mangrove Association (ADDMA) - Kandel Strats -   17  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChanged                  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Magic Values", "body": "  The use of magic numbers in the codebase is not recommended, they should be replaced by variables with a self-explanatory name. Examples are:  ISSUEIDPREFIX-003   \"mgv/writeOffer/density/tooLow\"   \"mgv/tradeSuccess\"  Acknowledged:  Mangrove Association (ADDMA) replied:  since these magic values are part of mangrove\u2019s specification, we assume they won\u2019t change.  Mangrove Association (ADDMA) - Kandel Strats -   18  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Maker Should Oversupply Due to Aave Being", "body": " off by 1  The maker should oversupply AaveKandel by some WEI to account for Aave internal loss of precision, that can lead the token amount to be off by 1 on redemption, as it could make the trade revert if they are the only one to use the Aave pool from a given AavePooledRouter.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Supplying Caps Not Considered", "body": "  Aave V3 has supply caps. However, these are not considered when supplying. Hence, supplying could fail so that tokens are treated as buffered.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   AaveKandelSeeder Missing Existence Check", "body": " of Pool for Asset  No check is done on strategy deployment for a pool of BASE or QUOTE on AaveV3. If such pools cannot be supplied, the AaveKandel strategy can be deployed but there will be no yield from the deposits to the router.  Mangrove Association (ADDMA) - Kandel Strats -   19  NoteVersion1NoteVersion1NoteVersion1          \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Impossibility to Create One-Side Token1", "body": " Liquidity  The DeposiorUniV3 funnel has a uniswapV3MintCallback() function for properly integrating with Uniswap V3 and move the funds. However, it only moves funds if the owed amount in token0 is greater than 0. Hence, if the current tick is outside of the position's tick range so that it leads to one-sided liquidity in  token1,  no  funds  will  be  transferrable.  Ultimately,  one-sided  token1  liquidity  cannot  be  added.  Thus, deposits could be temporarily DOSed.  CS-MKALLOC-002    amt1Owed is now used for transfers of token1.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Incorrect Uniswap V3 Path Interpretation", "body": "  The swapper callback contract for UniswapV3 interprets the last tokens as follows:  lastToken := div(mload(sub(add(add(path, 0x20), mload(path)), 0x14)), 0x1000000000000000000000000)  CS-MKALLOC-003  Namely, it loads the last 20 bytes as the last token. However, the path may have some additional unused data so that the last token does not have any effect on the execution. Consider the following example:  1. The path is encoded as [srcToken fee randomToken dstToken].  2. The swapper will interpret dstToken as the last token.  3. However, in UniswapV3, randomToken will be received.  Maker - DSS Allocator -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f4. In case no slippage requirements for the amount out are present, randomToken will be received  successfully and will be stuck in the swapper contract.  Ultimately,  the  path  is  wrongly  interpreted  which  could,  given  some  configurations,  lead  to  tokens  lost unnecessarily due to bad input values.    The check towards the correctness of path encoding has been removed, as it provides a false sense of security. Ultimately, the swap is protected by the minimum output token amount requirement.  Maker states:  These checks were only meant to provide more explicit revert reasons for a subset of (common) path misconfigurations and were not meant to catch all possible incorrect path arrays. Ultimately the \"\"Swapper/too-few-dst-received\"\" check is the only one that matters. But since that seems to cause confusion, we just removed the checks.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Gas Inefficiencies", "body": "  Below is a non-exhaustive list of gas inefficiencies:  1. In AllocatorVault.wipe(), the call vat.frob() takes address(this) as an argument for the gem balance manipulation. However, due to the gem balance not being interacted with, using address(0) may improve gas consumption minimally.  2. In  the  withdrawal  and  deposit  functions  of  the  UniV3Depositor,  an  unnecessary  MSTORE operation is performed when caching era into memory. Using only the SLOAD could be sufficient.  CS-MKALLOC-004    Code has been corrected to optimize the gas efficiency.  Maker - DSS Allocator -   13  InformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Lack of Sanity Checks", "body": "  The code often lacks sanity checks for setting certain variables. The following is a non-exhaustive list:  1. On deployment, the conduit mover does not validate whether the ilk and the buffer match against  CS-MKALLOC-001  the registry.  2. Similarly, that is the case for the allocator vault.  Maker states:  The sanity checks are done as part of the init functions (to be called in the relevant spell).  Maker - DSS Allocator -   14  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   1T NST Minting", "body": "  The  documentation  specifies  that  a  maximum  of  1T  NST  should  be  placed  and  that  at  most  1T  NST should be mintable. However, that may not be the case if the spotter has mat and par set to unsuitable values. Technically, Vat.rate could be decreasing (depending on the jug). Hence, with a decreasing rate, more than 1T NST could be minted. Additionally, governance is expected to provide the allocator vault with a gem balance through Vat.slip(). Calling this multiple times would allow to re-initialize the allocator vault multiple times to create more ink than intended (and, hence, allowing for more debt than expected).  Ultimately, governance should be careful when choosing properties.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Deposit and Withdraw Share the Same", "body": " Capacity  The governance can set a PairLimit in DepositorUniV3, which limits the maximum amount of a pair of tokens that can be added or removed from the pool per era. Instead of setting two capacity parameters for adding liquidity and removing liquidity respectively, both actions share the same capacity.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Potentially Outdated Debt Estimation", "body": "  In contract AllocatorVault, debt() returns an estimation of the debt that is on the Vault's urn. This estimation  could  be  outdated  if  the  vat's  rate  has  not  been  updated  by  the  jug.drip()  in  the  same block.  The getter debt() has been removed (along with line() and slot()). Maker states that they are not strictly needed and can be implemented in another contract as well.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Shutdown Not Considered", "body": "  The shutdown was not in scope and users should be aware that consequences of a potential shutdown have not been investigated as part of this audit.  Maker - DSS Allocator -   15  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   Topology May Break the Intended Rate Limit  The keepers' ability to move funds between conduits/buffer and swapping tokens is limited by the triplets (from, to, gem) and (src, dst, amt) respectively. However, the actual funds flow between from and to (src and dst) could exceed the config dependent on the topology of the settings.  Assume  there  is  a  config  that  limits  moving  NST  between  conduits  CA  and  CB  to  100  per  hop: (CA,  CB,  100).  If  there  are  another  two  configs  (CA,  CX,  40)  and  (CX,  CB,  60)  exist,  then keepers can move at most 100 + 40 = 140 DAI from CA to CB per hop.  The  same  situation  applies  to  Swapper.  Therefore,  the  topology  of  the  configs  should  be  carefully inspected.  Maker states:  The rate limit for each swap/move pair is an authed configuration of the allocator proxy. It is therefore assumed to know what it is doing and is allowed to set any configuration regardless of paths or duplication.  Maker - DSS Allocator -   16  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Provoking an Aave Liquidity Crisis", "body": "  AaveKandel  stops  providing  liquidity  if  too  much  is  borrowed.  Generally,  market  makers  should  be aware of that. However, one can throw Aave temporarily into a liquidity crisis by  CS-MGVSTRATS-004  1. flashloaning the entire balance  2. borrowing the entire balance  That  could  allow  an  attacker  to  create  a  temporary  liquidity  crisis  wrapping  a  sniping  operation  on Mangrove core for his profit.  However, note that the flashloaning attack is to some degree by the economic factor of Aave flashloans while the other operation can be achieved even for free by taking out free flashloan for collateral assets on other protocols. Such attacks are however limited by the borrow caps that Aave can impose. Namely, the attack can be carried out as long as the Aave's available capital after the borrow cap is reached is less than an offer's promised amount. Note that 1. and 2. can be combined to reduce the total cost of an attack with 1. so that the limit set by the borrow caps can be bypassed.  Risk accepted:  Mangrove Association replied:  1/ deploy 80 offers from AAVE kandel (WETH,USDC) on mangrove  Note 1: 80 offers is the limit beyond which one cannot collect all failing offers because of stack overflow Note 2: WETH has borrow cap on AAVE so the attack has to be on offers that have USDC outbound  Mangrove Association - Mangrove Strategies -   9  SecurityDesignCorrectnessCriticalHighRiskAcceptedMediumLowAcknowledgedSecurityHighVersion1RiskAccepted           \f2/ attacker supplies enough DAI on AAVE to be able to borrow the whole supply of USDC  Note 1: the script mocks up a flashloan of DAI to obtain enough collateral. There is currently no real way to flashloan DAIs on polygon. In the overall cost of the attack we add 400K gas as an estimate of the flashloan cost plus the cost of repaying the borrow on AAVE which is not scripted here (AAVE on polygon still does not allow repay and borrow on the same block, although ethereum deployment does). The attack using AAVE native flashloan has also been tested but result in a prohibitive cost for the attacker (around 1000 USD worth of fees).  Note 2: there is currently a supply cap on AAVE for DAI which is just enough to do this, but supplying a bit too much DAI actually reverts  3/ attacker borrows USDC supply and triggers a market order  4/ all 80 aave kandel offers trigger a failure cascade and the bounty is sent to the attacker Assuming a tx.gasprice == Mangrove\u2019s gasprice at 90 gwei, we get:      Attack collects 0.84691197 matics for 9 936 879 gas units     cost of the attack: 0.89431911 native tokens  Conclusion:    - Under favorable gas conditions for the attacker, drying up the AAVE pool can be profitable (when tx.gasprice is     significantly lower than Mangrove\u2019s). However the profit is quite low compared to traditional flashloan attacks     and not iterable: failing Aave Kandel\u2019s offer do not repost themselves. Yet the attack would at least be griefing     users as it would result in losing provision and having their offers unpublished from Mangrove.    - We believe the best protection relies on launching AAVE Kandel Strats on markets that have a borrow cap,     which would force the attacker of going through the costly AAVE flashloan mechanism to bypass the cap.    - The above script is included in the test AaveKandel.t.sol (test_liquidity_borrow_marketOrder_attack)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Unsafe Casts for Geometric Kandels", "body": "  CS-MGVSTRATS-003  KandelLib.createGeometricDistribution()  performs  several  unsafe  casts.  Namely,  there  are casts from uint to int for _baseQuoteTickOffset and indices.  The unsafe casts for _baseQuoteTickOffset may create problems and wrong results for the usage of GeometricKandel.createDistribution(). Additionally, the parameters specified are not validated (e.g. price points could be less than or equal to the step size or they could be too high). However, the other  functions  defined  ensure  that  the  reasonable  restrictions  for  the  geometric  parameters  are enforced.  The casting of indexes, however, may even create problems for the populating functions. Consider, the following.  int tick = -(Tick.unwrap(baseQuoteTickIndex0) + int(_baseQuoteTickOffset) * int(index));  Assume that index == 2**256-1-x, then the cast will return -1-x. Ultimately, a positive tick will be turned into a negative one, only to turn it back into a positive one. That positive tick will be used for bids. The following will become the tick for the bid in such a scenario.  int tick = Tick.unwrap(baseQuoteTickIndex0) + int(_baseQuoteTickOffset) * (1+x);  As a consequence, the bid prices increase with increasing indices (worse for market makers) instead of decreasing. Hence, the bids would bid a too high price.  Note that indices can reach that size (e.g. from is high).  Ultimately, the behaviour is undefined and may create bad setups.  Acknowledged:  Mangrove Association - Mangrove Strategies -   10  CorrectnessLowVersion1Acknowledged        \fMangrove  Association  acknowledged  the  behaviour  and  indicates  that  these  parameters  should  be validated off-chain similar to other ones:  In general parameters are considered validated off-chain, e.g., through simulation before passing to the contracts, so it is up to the caller to ensure correct usage.  Mangrove Association - Mangrove Strategies -   11    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Lack of Router Sanity Check    Specification Mismatch   Informational Findings   Gas Optimisations    Lack of Events   0  0  0  2  2  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Lack of Router Sanity Check", "body": "  While the MangroveOffer library does not enforce a router to be set, more derived contracts such as Forwarder strictly require a router. However, setRouter() is not adapted to enforce such a check.  CS-MGVSTRATS-001    A  check  has  been  added  to  Forwarder  and  to  AaveKandel  which  are  the  strategies  that  require  a router to be set.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Specification Mismatch", "body": "  The specification of RESERVE_ID states that  ///@dev RESERVE_ID==address(0) will pass address(this) to the router for the id field.  CS-MGVSTRATS-002  However, RESERVE_ID will never be address(0) as it is set to address(this) if the corresponding constructor argument is address(0).  Additionally,  the  documentation  of  the  geometric  price  of  baseQuoteTickIndex0  describes  the following  Mangrove Association - Mangrove Strategies -   12  CriticalHighMediumLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                \f///@param baseQuoteTickIndex0 the tick of base per quote for the price point at index 0 [...]  However, that may be misinterpreted. Namely, considering the two markets for asks and bids, the ask's price will be denominated in quote per base (ratio of inbound and outbound) while the bids' prices will be denominated in base per quote. The documentation, thus, suggests that the tick is defined for the market of the bids. However, that contrasts the implementation where the tick is used for the ask markets.  Specification changed:  The NatSpec has been adjusted.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Gas Optimisations", "body": "  Below is an incomplete list of potential gas optimisations:  1. In  Forwarder.sol,  deriveGasprice()  evaluates  1e6  *  (offerGasbase  +  gasreq)  to  compute a value that is already in num.  CS-MGVSTRATS-005  2. In   CoreKandel.sol,   casting guards  newParams.pricePoints to uint32. This is unnecessary since newParams.pricePoints is already an uint32.  setParams   truncation   against   when   3. setExpiry()  and  retractOffer()  in  MangroveOrder  have  the  mgvOrOwner  modifier.  However, the core will never call these functions.    The code has been adjusted to include the above gas optimisations.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Lack of Events", "body": "  While the codebase emits events on many occasions, a SetAdmin is missing in the constructor of the AccessControlled contract.  CS-MGVSTRATS-006    The event is now emitted.  Mangrove Association - Mangrove Strategies -   13  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Magic Values", "body": "  The use of magic numbers in the codebase is not recommended, they should be replaced by variables with a self-explanatory name. Examples are:  CS-MGVSTRATS-007   \"mgv/writeOffer/density/tooLow\"   \"mgv/tradeSuccess\"  Acknowledged:  Mangrove Association replied:  since these magic values are part of mangrove\u2019s specification, we assume they won\u2019t change.  Mangrove Association - Mangrove Strategies -   14  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Hypothetical Bad Setups for Kandels", "body": "  While we exclude \"weird\" setups for the Kandel from scope, we would like to give an incomplete list of examples of such breaking setups:  1. populate() does not enforce the geometric price progression over indices. The distribution could  be arbitrary.  2. populate() does not enforce that for every index a bid and ask exist. Hence, one could create  setups where the updating of dual offers would always fail due to a lack of offer ID.  3. The geometric population functions have assumptions such as the tick spacing of the market being  respected by the arguments.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Maker Should Oversupply Due to Aave Being", "body": " off by 1  The maker should oversupply AaveKandel by some WEI to account for Aave internal loss of precision, which can lead the token amount to be off by 1 on redemption, as it could make the trade revert if they are the only one to use the Aave pool from a given AavePooledRouter.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Supplying Caps Not Considered", "body": "  Aave V3 has supply caps. However, these are not considered when supplying. Hence, supplying could fail so that tokens are treated as buffered.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Updating Approvals on Order Update", "body": "  A user can update their orders by using Forwarder.updateOffer. Users need to remember that, in case the makerExecute hook to their order fails, they will have to reimburse the taker. A reason for an order to fail is that there is not enough allowance given to the router to transfer funds from the maker's reserve to the MangroveOrder contract. This is highly likely to happen after a user updates their offer by having it give more funds to the taker.  Mangrove Association - Mangrove Strategies -   15  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   AaveKandelSeeder Missing Existence Check of Pool for Asset  No check is done on strategy deployment for a pool of BASE or QUOTE on AaveV3. If such pools cannot be supplied, the AaveKandel strategy can be deployed but there will be no yield from the deposits to the router.  Mangrove Association - Mangrove Strategies -   16  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Consistency on Zero Amount Transfers", "body": "  The  function  BasicDelegationPod._updateBalances  does  not  trigger  mint/burn/transfer  of delegation shares (an ERC20Pods token) on 0 amount. The ERC20 standard specifies Note Transfe rs of 0 values MUST be treated as normal transfers and fire the Transfer even t..  1inch - Delegation -   9  SecurityDesignCorrectnessCriticalHighMediumLowDesignLowVersion2           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Possible Frontrunning on Registration    Pod.updateBalances() Cannot Transfer ERC20Pods   -Severity Findings   Allowances Not Completely Disabled   -Severity Findings   Broken C-E-I Pattern   Inconsistency and Zero Address Check on register()    No Event upon Registering Delegatee   0  2  1  3  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Possible Frontrunning on Registration", "body": "  If  a  delegatee  already  deployed  its  DelegatedShare  contact  on  its  own  and  want  to  register  it  with register(IDelegatedShare  shareToken,  address  defaultFarm),  another  user  could  front run the transaction and register the already deployed contract in place of the true delegatee, who won't be able to register the contract for itself.  This can become problematic if the DelegatedShare contract already has some accounting done.    The  register(IDelegatedShare  shareToken,  address  defaultFarm)  function  has  been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Pod.updateBalances() Cannot Transfer", "body": " ERC20Pods  least  one  pod   involved):  Using   Pod.updateBalances() cannot transfer (including mint or burn) tokens of another ERC20Pods (with to at  updateBalances() of a pod is executed with _POD_CALL_GAS_LIMIT amount of gas. Currently this value is hardcoded to 200_000. A transfer of an ERC20Pods within updateBalances() would trigger _updateBalances()  of  this  ERC20Pods.  The  current  call  executing  with  this  amount  of  gas  cannot forward another 200_000 gas and hence the execution reverts.  implementation  of  ERC20Pods   the  default   the  call   1inch - Delegation -   10  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedDesignHighVersion1CodeCorrectedDesignHighVersion1CodeCorrected                 \ffunction _updateBalances(address pod, address from, address to, uint256 amount) private {      bytes4 selector = IPod.updateBalances.selector;      bytes4 exception = InsufficientGas.selector;       assembly {  // solhint-disable-line no-inline-assembly          let ptr := mload(0x40)          mstore(ptr, selector)          mstore(add(ptr, 0x04), from)          mstore(add(ptr, 0x24), to)          mstore(add(ptr, 0x44), amount)           if lt(div(mul(gas(), 63), 64), _POD_CALL_GAS_LIMIT) {              mstore(0, exception)              revert(0, 4)          }          pop(call(_POD_CALL_GAS_LIMIT, pod, 0, ptr, 0x64, 0, 0))      }  The design of RewardableDelegationPod however requires this and hence cannot work.  Despite   Within  RewardableDelegationPod.updateBalances()  the  call  to  the  DelegatedShare  token (which  is  ERC20Pods,  and  the  accounts  are  connected  to  at  least  the  farm  pod)  is  wrapped  within try/catch.  with best  effort  of  having  consistent  shares  the  accounting  is  totally  off.  A  transfer  of  the underlying  ERC20Pod  which  triggers  RewardableDelegationPod.updateBalances()  will  never successfully execute registration[_delegate].burn(from, amount)/ registration[_del egate].mint(from,  amount).  These  calls  only  succeed  when  updateBalances()  is  called  with sufficient gas, e.g. using DelegatedShare.addPod().  annotated   function   being   itself   the     The  root  of  the  issue  has  been  addressed  in  ERC20Pods.  The  amount  of  gas  for  each  of  the  calls  in ERC20Pods._updateBalances()  is  no  longer  hardcoded  in  ERC20Pods  but  passed  as  constructor parameter.  The  ERC20Pods  that  is  DelegatedShare  has  a  fixed  100_000  gas  for  each  of  the in callbacks.  ERC20Pods->RewardableDelegationPod->ERC20Pods``, developers must be careful to set the correct amount of gas in each of them for the system to work.  ERC20Pods   stacked   When   two   like   are   function  RewardableDelegationPod.updateBalances  has  been  updated   to  call The  mint()/burn() without try/catch blocks so that every call to DelegatedShare.mint()/burn() must be successful.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Allowances Not Completely Disabled", "body": "  BasicDelegationPod  overwrites  and  inhibits  functions  transfer,  transferFrom  and  approve.  The increaseAllowance  and  decreaseAllowance  functions  inherited  from  OpenZeppelin's  ERC20 implementation are not overridden and hence can be used.    The functions increaseAllowance and decreaseAllowance have been explicitely disabled.  1inch - Delegation -   11  CorrectnessMediumVersion1CodeCorrected          \f6.4   Broken C-E-I Pattern  in  The  check-effects-interaction  pattern  delegated  mapping  after  _updateAccountingOnDelegate, this could lead to reentrancy or other unexpected behaviors.  function  BasicDelegationPod.delegate.  The upon contract   interaction   possible   updated   is   is   a     The mapping update and event have been moved before the call to _updateAccountingOnDelegate.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Inconsistency and Zero Address Check on ", "body": " register()  In function register(IDelegatedShare shareToken, address defaultFarm), it is possible to provide  shareToken=address(0),  this  would  allow  one  user  to  add  a  default  farm  for  the  zero address, and to call on of the register() functions once again, which should not be possible.    The  register(IDelegatedShare  shareToken,  address  defaultFarm)  function  has  been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   No Event upon Registering Delegatee", "body": "  Events  are  used  to  be  informed  of  or  to  keep  track  of  transactions  changing  the  state  of  a  contract. Generally, any important state change should emit an event.  Both functions used to register delegatees do not emit an event, hence for an observer it`s hard to track new delegatees.    Two  events  RegisterDelegatee  and  DefaultFarmSet  have  been  added,  and  are  emitted  resp. when a new delegatee registers, and when a default farm is added.  1inch - Delegation -   12  SecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Users Must Add Farm if Default Farm Is", "body": " Updated  The deployed DelegatedShare contracts may not have a farm associated with them directly. If a farm is added later on, the users must either re-delegate or manually add the farm Pod on the DelegatedShare contract themselves.  possible   using It's  DelegatedShare.remove/removeAll()  but  still  keep  delegating  to  this  delegatee.  Users  must  be careful and understand the consequences of their actions.  remove   himself   default   from   farm   user   the   for   an   to   1inch - Delegation -   13  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Unused Import", "body": "  In the Lido rate provider, ERC4626 is imported and never used.  CS-YRNPR-001  Yearn - yETH Periphery -   10  InformationalVersion1  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Implementation Might Change for Proxies", "body": "  Multiple  rate  providers  are  proxy  contracts.  Their  implementation  might  change.  In  consequence, incorrect rate updates or reverts might happen. Constant monitoring and updates as well as contact with the development teams of the corresponding projects might be useful for mitigation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Providers Might Revert Instead of Returning", "body": " Values  When the total amount of staked tokens is null, providers behaviours can vary, some of them will return a rate of 1 to 1 with ETH while other will revert. Such a corner case should be carefully evaluated.  Yearn - yETH Periphery -   11  NoteVersion1NoteVersion1      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Gain Exceeds Max_Debt", "body": "  In contract VaultV3, any strategy gains upon process_report() will be reported by increasing the strategy's  current_debt  and  the  vault's  total_debt  regardless  of  the  strategy's  max_debt parameter. In this case, the debt of a strategy can exceed its upper bound.  CS-YVV3-001  Acknowledged:  Yearn states:  This is deemed acceptable if caused by profits. Since debt can be lowered at any time after by the DEBT_MANAGER.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Reentrancy and process_report()", "body": "  CS-YVV3-002  process_report()  to IAccountant(accountant).report(). Note that these are trusted roles, however, if the accountant can dispatch a call from the (FORCE_)REVOKE_STRATEGY_MANAGER role, a strategy could be revoked during the process of reporting it, which breaks the correct execution flow.  the  Vault   functions   external   reenter   can   call   the   of   in   Yearn - V3 Vaults -   11  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedRiskAcceptedCorrectnessLowVersion1AcknowledgedSecurityLowVersion1RiskAccepted                   \fFurthermore,  similarly  a  strategy  may  enter  into  proces_report()  while  an  update  of  its  debt  is  in process  (update_debt()).  Roles  are  trusted  to  not  misbehave,  the  smart  contract  implementation however does not prevent this scenario.  Risk accepted:  Yearn states:  Reentrancy was intentionally left off process_report() so that an accountant can reenter \u2018deposit\u2019 if need be to issue refunds. It is expected that the accountant never be set to a role other than accountant. And be given no other permissions.  Yearn - V3 Vaults -   12    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Disproportional Unrealized Loss on Redemption   Inconsistent Debt Accounting on Withdrawal From Strategies   -Severity Findings   Add Self as a Strategy   Incorrect Return Type of Decimals   Incorrect Return Value   Incorrect and Missing Specification    Missing Event upon Role Change    Non ERC-4626 Compliant Functions    Unchecked Profit Max Unlock Time    Unprotected Sweep Function   0  0  2  8  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Disproportional Unrealized Loss on", "body": " Redemption  If total_idle is insufficient to fulfill a user's withdrawal, _redeem() attempts to retrieve assets from the  strategies  a  user  defined  or  overridden  by  the  queue_manager.  Should  a  queried  strategy  have unrealized loss, the user will take part of the unrealized loss. However, the user may take the loss in a disproportional way as shown in the code.   First, the user's share of the unrealized loss is computed based on assets_to_withdraw.   Afterwards, assets_to_withdraw is capped by its upper bound.  CS-YVV3-014  Yearn - V3 Vaults -   13  CriticalHighMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrected            \funrealised_losses_share: uint256 = self._assess_share_of_unrealised_losses(strategy, assets_to_withdraw) if unrealised_losses_share > 0:     # User now \"needs\" less assets to be unlocked (as he took some as losses)     assets_to_withdraw -= unrealised_losses_share     requested_assets -= unrealised_losses_share     # NOTE: done here instead of waiting for regular update of these values because it's a rare case     # (so we can save minor amounts of gas)     assets_needed -= unrealised_losses_share     curr_total_debt -= unrealised_losses_share  # After losses are taken, vault asks what is the max amount to withdraw assets_to_withdraw = min(assets_to_withdraw, min(self.strategies[strategy].current_debt, IStrategy(strategy).maxWithdraw(self)))  If  assets_to_withdraw  is  restricted  to  strategy.maxWithdraw(self),  the  user  will  cover  more than his proportional share of the loss. In addition, the updated current_debt of this strategy as well as the  vault's  total  debt  will  diverge  from  the  real  debt  because  unrealised_losses_share  has  been overestimated.  current_debt: uint256 = self.strategies[strategy].current_debt new_debt: uint256 = current_debt - (assets_to_withdraw + unrealised_losses_share)  # Update strategies storage self.strategies[strategy].current_debt = new_debt    When  max_withdraw  is  the  limiting  factor  for  assets_to_withdraw,  the  unrealised  loss  the  user takes is now adjusted proportionally. As a result, the user no longer bears more than their fair share of the loss, and the update to current_debt is done using the correct value.  # If max withdraw is limiting the amount to pull, we need to adjust the portion of # the unrealized loss the user should take. if max_withdraw < assets_to_withdraw - unrealised_losses_share:     # How much would we want to withdraw     wanted: uint256 = assets_to_withdraw - unrealised_losses_share     # Get the proportion of unrealised comparing what we want vs. what we can get     unrealised_losses_share = unrealised_losses_share * max_withdraw / wanted     # Adjust assets_to_withdraw so all future calcultations work correctly     assets_to_withdraw = max_withdraw + unrealised_losses_share  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Inconsistent Debt Accounting on Withdrawal", "body": " From Strategies  If total_idle is insufficient to fulfill the redemption, _redeem() attempts to retrieve assets from the strategies.  Should  a  queried  strategy  have  an  unrealized  loss,  the  user  has  to  take  a  part  of  this  loss, which  is  regarded  as  realized  and  deducted  from  curr_total_debt.  At  the  end  of  the  loop, self.total_debt is updated to curr_total_debt.  # CHECK FOR UNREALISED LOSSES # If unrealised losses > 0, then the user will take the proportional share and realise it # (required to avoid users withdrawing from lossy strategies) # NOTE: assets_to_withdraw will be capped to strategy's current_debt within the function # NOTE: strategies need to manage the fact that realising part of the loss can mean the realisation of 100% of the loss !!  CS-YVV3-006  Yearn - V3 Vaults -   14  CorrectnessMediumVersion1CodeCorrected        \f#  (i.e. if for withdrawing 10% of the strategy it needs to unwind the whole position, generated losses might be bigger) unrealised_losses_share: uint256 = self._assess_share_of_unrealised_losses(strategy, assets_to_withdraw) if unrealised_losses_share > 0:         # User now \"needs\" less assets to be unlocked (as he took some as losses)         assets_to_withdraw -= unrealised_losses_share         requested_assets -= unrealised_losses_share         # NOTE: done here instead of waiting for regular update of these values because it's a         # rare case (so we can save minor amounts of gas)         assets_needed -= unrealised_losses_share         curr_total_debt -= unrealised_losses_share  # After losses are taken, vault asks what is the max amount to withdraw assets_to_withdraw = min(assets_to_withdraw, min(self.strategies[strategy].current_debt, IStrategy(strategy).maxWithdraw(self)))  # continue to next strategy if nothing to withdraw if assets_to_withdraw == 0:     continue  However, in case the strategy with unrealized loss reports 0 on maxWithdraw(), it will jump to the next iteration  debt code  which  (strategies.current_debt).  Consequently,  the  sum  of  all  strategies.current_debt  will exceed self.total_debt and result in an accounting inconsistency.  strategy-specific   following   updates   skip   and   the   the   current_debt: uint256 = self.strategies[strategy].current_debt new_debt: uint256 = current_debt - (assets_to_withdraw + unrealised_losses_share)  # Update strategies storage self.strategies[strategy].current_debt = new_debt # Log the debt update log DebtUpdated(strategy, current_debt, new_debt)    The updated code ensures accurate accounting before proceeding to the next loop iteration when it is not possible to withdraw funds from a strategy:  1. If funds are simply locked, the users share of the loss to cover is zero and all accounting is correct.  2. If the strategy has a complete loss, the user realiszes this loss and the strategies debt is updated.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Add Self as a Strategy", "body": "  The vault should not add itself as a strategy. Otherwise, update_debt will revert when funds are to be deposited into the strategy, as the recipient of the shares cannot be the vault itself.  CS-YVV3-012    In the updated code it is no longer possible to add the vault itself as a strategy.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Incorrect Return Type of Decimals", "body": "  decimals() of contract VaultV3 returns an uint256 which does not comply with the ERC20 standard where an uint8 is returned.  CS-YVV3-009  Yearn - V3 Vaults -   15  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f  The type of the return value has been changed to uint8 which is compliant with the specification.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Incorrect Return Value", "body": "  CS-YVV3-011  mint()  returns  the  calculated  amount  of  assets  to  deposit,  instead  of  the  actual  amount  of  assets into  assets  equal  max(uint256), deposited.  self._deposit()  considers  this  a  \"magic  value\"  and  will  only  deposit  the  user's  balance.  mint() however will return max(uint256) and not the actual amount of assets deposited.  If  a  user  mints  shares  which  converted   The  same  issue  exists  for  withdraw()  when  the  amount  of  assets  converted  to  shares  equals max(uint256).  The possibility of these scenarios depends on the exchange rate between shares and assets. The caller might rely on the returned values for further calculations or decision-making processes, which could lead to unintended consequences due to the discrepancy in the returned and actual deposited or withdrawn assets.    Yearn has removed the ability to pass MAX_UINT as a \"magic value\" to use the full balance.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Incorrect and Missing Specification", "body": "  In contract VaultV3, mint() returns the amount of assets deposited instead of shares according to its specification. In addition, the specifications of withdraw() and redeem() are missing.  CS-YVV3-010  Specification changed:  The  specification  of  mint()  has  been  corrected.  Specification  has  been  added  for  withdraw()  and redeem().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Missing Event upon Role Change", "body": "  In  contrast  to  other  sections  of  the  code,  role  management  functions  (with  the  exception  of accept_role_manager)  do  not  emit  events  upon  these  important  state  changes.  Emitting  events would enable external parties to observe these important state changes more easily.  CS-YVV3-013  Yearn - V3 Vaults -   16  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \f  Events  have  been  added  to  set_role(),  set_open_role()  and  close_open_role().  Note  that transfer_role_manager() does not emit an event, an event is emitted upon the completion of the role transfer in accept_role_manager() only.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Non ERC-4626 Compliant Functions", "body": "  In case the vault is in shutdown mode, no further deposit can be made. However, maxDeposit() does not return 0 when the vault is shutdown.  The ERC-4626 specification however requires the function to return 0 in this case:  CS-YVV3-007  ... if deposits are entirely disabled (even temporarily) it MUST return 0.  In addition, maxWithdraw() assumes a full withdrawal is possible if queue_manager is set regardless of the unrealized loss. This conflicts with the specification which reads:  MUST NOT be higher than the actual maximum that would be accepted (it should underestimate if necessary)  Besides, convertToShares() does not distinguish the following cases when total_assets is 0:   This is the first deposit where price per share is 1.   The vault is dead where there are shares remaining but no assets. The price per share is 0 because  further deposit would revert in _issue_shares_for_amount.  This  would  be  misleading  convertToShares() but fail on deposit().  for  external  contracts   to  see  a  non-zero  value  when  using  More  informational,  the  ERC-4626  specification  is  loosely  defined  in  these  corner  cases  for  these functions. Nevertheless we want to highlight the potentially unexpected amounts returned:  previewRedeem(): In case totalAssets is zero, the conversion is done at a 1:1 ratio. At this point either no shares exist (I) or the value of the existing shares has been diluted to 0 (II). For (I) the returned value  of  0  is  appropriate.  For  (II)  previewRedeem()  does  not  revert  while  redeem()  reverts;  the specification reads:  MAY revert due to other conditions that would also cause redeem to revert.  previewWithdraw()  returns  the  amount  in  a  1:1  exchange  rate  when  assets==0  but  shares!=0. Again for non-zero values the amount returned may be misleading.  Strictly  speaking  the  value  returned  is  not  breaking  the  specification  but  might  be  unexpected  by  the caller.  The  caller  should  be  aware  of  this  and  any  external  system  should  exercise  caution  when integrating with these functions.  The full specification can be found here: https://eips.ethereum.org/EIPS/eip-4626    The  code  has  been  changed  so  that  the  deposit  limit  is  set  to  0  when  the  vault  is  shutdown,  thus maxDeposit() would return 0 in this case. convertToShares() has been adjusted to distinguish the case  when  the  vault  is  dead.  The  potentially  misleading  return  value  of  previewWithdraw()  is acknowledged.  Yearn - V3 Vaults -   17  CorrectnessLowVersion1CodeCorrected        \fYearn also acknowledged the risk of maxWithdraw() and states:  It is deemed acceptable for maxWithdraw() to not take into account unrealized losses. Since this would be very gas intensive for a function potentially used on chain, and is not possible to accurately account for vaults that allow custom withdraw queues.  The  external  system  is  expected  to  exercise  caution  with  the  features  of  this  contract  during  their integration.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Unchecked Profit Max Unlock Time", "body": "  In  contract  VaultV3,  profit_max_unlock_time  is  not  checked  at  initialization.  A  faulty  value  may lead  to  unexpected  behaviors.  In  case  profit_max_unlock_time==0,  the  profit  of  the  vault  will  be locked forever. In case profit_max_unlock_time is too large, the weighted average computation of new_profit_locking_period may revert, which blocks process_report() as a consequence.  CS-YVV3-015    profit_max_unlock_time  is  now  checked  in  the  vault  constructor  and  setter  ensuring  that  it  is greater than 0 and less than 1 year.  # Must be > 0 so we can unlock shares assert profit_max_unlock_time > 0 # dev: profit unlock time too low # Must be less than one year for report cycles assert profit_max_unlock_time <= 31_556_952 # dev: profit unlock time too long  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Unprotected Sweep Function", "body": "  sweep()  is  not  protected  by  the  reentrancy  guard.  If  trusted  roles  misbehave  it's  possible  to  sweep assets  of  the  vault  at  a  time  when  the  value  of  total_idle  is  stale.  No  direct  issue  has  been uncovered, however this permits excessive access which may introduce unnecessary risks.  CS-YVV3-008  deposit(),   In  of by  erc20_safe_transfer_from() only if the weird underlying token calls back to the sender after transferring the token.  sweep()   reenter   calling   could   hook   one   the   in    Another case is that a strategy reenters sweep() when update_debt() calls withdraw() on the strategy.  As  the  balance  withdrawn  is  determined  based  on  the  delta  of  the  actual  balance,  this shouldn't have any negative impact, apart from potentially spurious events.    A guard has been added for extra safety.  Yearn - V3 Vaults -   18  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                 \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Loose Token Decimal Restriction", "body": "  The  vault's  share  token  has  the  same  token  decimal  as  the  underlying  token.  The  underlying  token decimal is restricted (<= 38) in the VaultV3 constructor.  Token decimals are only for user representation and front-end interfaces. At the smart contract level, all balances  maintain  token  decimal  precision.  Overflows  could  potentially  occur  if  a  token  permits sufficiently large balances, leading to an overflow when these balances are multiplied. Importantly, this issue is unrelated to decimals, so the check in the constructor cannot prevent it.  Note  that  we  are  not  aware  of  any  meaningful  token  with  this  behavior,  this  is  more  a  theoretical consideration.  CS-YVV3-003  Yearn  understand  that  overflows  are  still  possible  no  matter  the  token  decimal  value  used.  The  check was updated, it now only ensures that the decimal value does not exceed an uint8. Legitimate vaults with a normal underlying token will not trigger any overflows.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Updating Queue_Manager", "body": "  CS-YVV3-004  The  queue_manager  smart  contract  defines  the  withdrawal  sequence  for  a  vault.  Whenever  a  new calling informs  strategy  queue_manager.new_strategy(address strategy).  queue_manager   added,   vault   the   the   by   is   The  queue  manager  for  the  vault  can  be  updated  using  set_queue_manager().  Note  that  the  new queue manager is not informed about all existing strategies of the vault; in this case the queue manager must be configured correctly manually.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   yv<Asset_Symbol> Not Enforced", "body": "  The  system  specification  requires  the  shares  to  be  named  yv<Asset_Symbol>.  Note  that  this  isn't enforced by the code, the share name can be freely defined when deploying a new Vault.  CS-YVV3-005  Yearn - V3 Vaults -   19  InformationalVersion1InformationalVersion1InformationalVersion1          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Debt Rebalanced in a Linear Way", "body": "  During update_debt(), if the target debt value cannot be reached given the vault and strategy specific limitations on the idle and debt, it will not revert. Instead, it will rebalance the debt to the closest value towards  the  target.  This  behavior  assumes  it  is  always  better  to  be  closer  to  the  target.  However,  the assumption may not always be true for different strategies.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   No User Protection on Shares Redemption", "body": "  If during redemption funds must be pulled from a strategy at a loss, the user must cover his share of this not  yet  realized  loss.  Additionally,  in  case  the  call  to  strategy.withdraw()  results  in  less  than  the requested assets, the user takes the full loss.  Unaware  users  may  redeem  their  shares  for  less  of  the  underlying  than  they  expect.  There  is  no protection e.g. in form of a parameter which allows the user to specify the minimum amount of underlying to receive / shares to be burned he tolerates before the transaction should revert.  Yearn states:  It is expected that off chain users interact with the vaults through an ERC-4626 router which has logic to set minimums and slippage tolerance for deposits and withdrawals. And on chain users can either use the router or set their own limits.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   Queue Manager Can Pause Withdrawals From", "body": " Strategies  A faulty or malicious queue_manager with should_override enabled can pause users' withdrawals from  strategies  by:  (1)  directly  revert.  (2)  return  a  non-existing  strategy.  queue_manager  must  be properly configured and trusted if enabled.    the  should_override  option  has  been  removed  so  users  can  always  bypass  the In  queue_manager  if  a  customized  withdraw  queue  is  specified.  Otherwise,  the  withdraw  queue  will  be queried from the queue_manager.  Yearn - V3 Vaults -   20  NoteVersion1NoteVersion1NoteVersion1Version2          \fif queue_manager != empty(address):     if len(_strategies) == 0:         _strategies = IQueueManager(queue_manager).withdraw_queue(self)  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   Race Condition on Withdrawal From", "body": " Strategies  If total_idle is insufficient to fulfill the redemption, _redeem() attempts to retrieve assets from the strategies. Should a queried strategy have unrealized loss, the user has to take a part of this loss. In case the vault has global unrealized loss, users may engage in a race to withdraw from the optimal strategies.  In  case  the  queue_manager  is  disabled,  users  will  race  to  withdraw  from  the  strategies  without unrealized loss. As a consequence, the tardy users will take more unrealized loss.  In case the queue_manager is enabled, withdrawals may be biased across all strategies depending on the actual construction of the withdraw_queue.  Users  will  only  share  the  unrealized  loss  of  a  strategy  in  a  fair  way  if  it  is  reported  by  the REPORTING_MANAGER.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.5   Tokens With a Blacklist", "body": "  Tokens such as USDC maintain a blacklist that prohibits the transfer of tokens to and from the addresses listed  on  it.  Assuming  a  vault  utilizes  such  a  token,  a  blacklisted  address  would  be  unable  to  be  the recipient when funds are withdrawn. If a strategy is blacklisted, withdrawal of allocated funds would be impossible.  Furthermore,  if  a  vault  itself  is  blacklisted,  the  withdrawal  of  all  deposited  funds  would  be prevented.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.6   Trade-off in Profits Distribution", "body": "  All profits getting paid to vault depositors are retroactive:   New joiners of a vault will share part of the locked profits accumulated before they entered.   The locked profits generated by their deposits will be forfeited upon their withdrawals.  This is a trade-off to improve the gameability and avoid intensive gas to track specific accounts for the time they deposit. As long as the profits are distributed slowly and continuously, no whales are expected to game the system by deposit right before a profit harvest and realize full gains.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.7   User-Selected Strategies", "body": "  If no queue manager is configured, when idle funds are insufficient for a withdrawal, users can specify which strategies should be used to retrieve funds.  Yearn - V3 Vaults -   21  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \fThis  could  enable  users  to  substantially  interfere  with  the  planned  allocation  of  assets,  necessitating frequent intervention from the debt_manager.  Yearn - V3 Vaults -   22  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Read-only Reentrancy", "body": "  It  can  be  possible  to  construct  examples  where  certain  properties  of  the  SV  mismatch  reality.  For example, during reallocations, a temporary devaluation of SVTs occurs due to SSTs being released. Due to reentrancy possibilities, certain values retrieved could be inaccurate (e.g. SV valuation).  CS-SpoolV2-024  Acknowledged:  While  the  read-only  reentrancy  does  directly  affect  on  the  protocol,  it  could  affect  third  parties.  Spool replied:  The mentioned view functions are not intended to be used while the reallocation is in progress.  Spool - Spool V2 -   20  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  1  7  5  19  -Severity Findings   Lack of Access Control in recoverPendingDeposits()   -Severity Findings   DOS Synchronization by Dividing With Zero Redeemed Shares    DOS on Deposit Synchronization    Donation Attack on SST Minting    Donation Attack on SVT Minting    Flushing Into Ongoing DHW Leading to Loss of Funds    No Deposit Due to Reentrancy Into redeemFast()    Wrong Slippage Parameter in Curve Deposit   -Severity Findings   Curve LP Token Value Calculation Can Be Manipulated    Deposits to Vault With Only Ghost Strategies Possible    Ghost Strategy Disables Functionality   Inconsistent Compound Strategy Value    Strategy Value Manipulation   -Severity Findings   Distribution to Ghost Strategy    Lack of Access Control for Setting Extra Rewards    Wrong Error IdleStrategy.beforeRedeemalCheck()    Access Control Not Central to Access Control Contract    Asset Decimal in Price Feed    Bad Event Emissions    Broken Conditions on Whether Deposits Have Occurred    Deposit Deviation Can Be Higher Than Expected   Inconsistent Handling of Funds on Strategy Removal    Misleading Constant Name    Missing Access Control in Swapper    Missing Event Fields    No Sanity Checks on Slippage Type    Precision Loss in Notional Finance Strategy    Redemption Executor   Spool - Spool V2 -   21  CriticalCodeCorrectedHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected  \f9   State Inconsistencies Possible    Unused Functions    Unused Variable    Validation of Specification   Informational Findings   Reverts Due to Management Fee    Simplifying Performance Fees    Strategy Removal for an SV Possible That Does Not Use It    Errors in NatSpec    Distinct Array Lengths    Gas Optimizations    Nameless ERC20    NFT IDs    Tokens Can Be Enabled Twice   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Lack of Access Control in ", "body": " recoverPendingDeposits()  DepositManager.recoverPendingDeposits()  has  no  access  control  (instead  of  being  only callable by the SV manager). Thus, it allows arbitrary users to freely specify the arguments passed to the function. Ultimately, funds from the master wallet can be stolen.  CS-SpoolV2-039    Access control was added. Now, only ROLE_SMART_VAULT_MANAGER can access the function.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   DOS Synchronization by Dividing With Zero", "body": " Redeemed Shares  _sharesRedeemed describes the SSTs redeemed by an SV. That value could be zero due to rounding. Hence,  uint256 withdrawnAssets =                 _assetsWithdrawn[strategy][dhwIndex][j] * strategyShares[i] / _sharesRedeemed[strategy][dhwIndex];  CS-SpoolV2-001  could be a division by zero.  Consider the following scenario:  1. Many deposits are made to an SV.  Spool - Spool V2 -   22  CodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion3CodeCorrectedSecurityHighVersion1CodeCorrected                \f2. The attacker makes a 1 SVT wei withdrawal.  3. The attacker flushes the SV.  4. The   redeemed   as strategyWithdrawals[i] = strategyShares * withdrawals / totalVaultShares. strategyShares corresponds to the shares held by the SV. Hence if the SV's balance of SSTs is lower than the total supply of SSTs (recall, the withdrawal is 1), the shares to be withdrawn is 0.  computes   SSTs   are   5. The  withdrawal  manager  passes  it  to  the  strategy  registry  which  then  stores  these  values  in  _sharesRedeemed.  6. No other SV tries to withdraw.  7. The division reverts on synchronization.  Ultimately, funds will be locked and SVs could be DOSed.    Now,  in  every  iteration  of  the  loop  in  StrategyRegistry.claimWithdrawals(),  it  is  checked whether the strategy shares to be withdrawn from the SV (strategyShares) are non-zero. In the case of strategyShares being zero, the iteration is skipped. If not the case, _sharesRedeemed > 0 will In  other  words, hold.  That  strategyShares_SV > 0 => _sharesRedeemed > 0.  sum  of  all  SV  withdrawals.   is  because   the   is   it   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   DOS on Deposit Synchronization", "body": "  After  the  DHW  of  an  SV's  to-sync  flush  cycle,  the  SV  must  be  synced.  The  deposit  manager  decides, based on the value of the deposits at DHW, how many of the minted SSTs will be claimable by the SV. It is computed as follows:  result.sstShares[i] = atDhw.sharesMinted * depositedUsd[0] / depositedUsd[1];  CS-SpoolV2-002  The  depositedUsd  has  the  total  deposit  of  the  vault  in  USD  at  index  zero  while  at  index  1  the  total deposits of all SVs are aggregated.  To calculate result.sstShares[i] the following condition should be met:  /// deposits = _vaultDeposits[parameters.smartVault][parameters.bag[0]][0]; deposits > 0 && atDhw.sharesMinted > 0  which means that the first asset in the asset group had to be deposited and that at least one SST had to be  minted.  Given  very  small  values  and  front-running  DHWs  with  donations  that  could  be  achieved. Ultimately, a division-by-zero could DOS the synchronization.  Consider the following scenario:  1. Only withdrawals occur on a given strategy.  2. An attacker sees a DHW incoming for that strategy.  3. The attacker frontruns the transaction and makes a minor deposit so that deposits > 0 holds. Additionally,  the  assetToUsdCustomPriceBulk()  should  return  0  which  is  possible  due  to rounding. See the following code in UsdPriceFeedManager.assetToUsdCustomPrice:  Spool - Spool V2 -   23  SecurityHighVersion1CodeCorrected        \fassetAmount * price / assetMultiplier[asset];  Under  the  condition  that  assetAmount  *  price  is  less  than  assetMultiplier  (e.g.  1  wei  at  0.1 USD for a token with 18 decimals), that will return 0.  4. Additionally, the attacker donates an amount so that Strategy.doHardWork() so that 1 wei SST will  be  minted  (note  that  the  Strategy  mints  based  on  the  balances  and  does  not  receive  the amount that were deposited).  5. Finally, DHW is entered and succeeds with 1 minted share.  6. The vault must sync. However, it reverts due to depositedUsd[1] being calculated as 0.  Ultimately, an attacker could cheaply attack multiple SVs under certain conditions.    deposits  >  0  has  been  replaced  by  checking  whether  there  are  any  deposits  made  to  any  of  the underlying assets. Additionally, a condition skips the computation (and some surrounding ones) in case the deposited value is zero.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Donation Attack on SST Minting", "body": "  The SSTs are minted on DHW and based on the existing value. However, it is possible to donate (e.g. aTokens to the Aave strategy) to strategies so that deposits are minting no shares.  CS-SpoolV2-003  A simple attack may cause a loss in funds. Consider the following scenario:  1. A new strategy is deployed.  2. 1M USD is present for the DHW (value was zero since it is a new strategy).  3. An attacker donates 1 USD in underlying of the strategy (e.g. aToken).  4. DHW  on   the depositShareEquivalent  will  be  computed  using  multiplication  with  total  supply  which  is  0. Ultimately, no shares will be minted.  strategies  happens.``usdWorth[0]``  will  be  non-zero.  Hence,   the   Ultimately, funds could be lost.  An attacker could improve on the attack for profit.  1. A new strategy is deployed.  2. An attacker achieves to mint some shares.  3. The attacker redeems the shares fast so that only 1 SST exists.  4. Now, others deposit 1M USD.  5. The attacker donates 1M + 1 USD in yield-bearing tokens to the strategy.  6. No  shares  are  minted  due  to  rounding  issues  since  the  depositSharesEquivalent  and  the  withdrawnShares are zero.  The deposits will increase the value of the strategy so that the attacker profits.  Ultimately, funds could be stolen.  Spool - Spool V2 -   24  SecurityHighVersion1CodeCorrected        \f  While the total supply of SSTs is less than INITIAL_LOCKED_SHARES, the shares are minted at a fixed rate.  INITIAL_LOCKED_SHARES  are  minted  to  the  address  0xdead  so  that  a  minimum  amount  of shares is enforced. That makes such attacks much more expensive.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Donation Attack on SVT Minting", "body": "  The  SVTs  that  are  minted  on  synchronization  are  minted  based  on  the  existing  value  at  the  flush. However, it is possible to donate to SVs so that deposits are minting no shares.  CS-SpoolV2-004  A simple attack may cause a loss in funds. Consider the following scenario:  1. A new SV is deployed.  2. 1M USD is flushed (value was zero since it is a new vault).  3. An  attacker,  holding  some  SSTs  (potentially  received  through  platform  fees),  donates  1  USD  in  SSTs (increases the vault value to 1 USD). Frontruns DHW.  4. DHW on the strategies happens.  5. The  SV   gets   of if  (totalUsd[1]  ==  0)  since  the  value  is  1  USD.  The  SVTs  are  minted  based  on  the  total supply of SVTs which is zero. Hence, zero shares will be minted.  synchronization   synced.  The   branch   enter   does   the   not   6. The depositors of the fund receive no SVTs.  Ultimately, funds could be lost.  An attacker could improve on the attack for profit.  1. A new SV is deployed.  2. An attacker achieves to mint some shares.  3. The attacker redeems the shares fast so that only 1 SVT exists.  4. Now, others deposit 1M USD, and the deposits are flushed.  5. The attacker donates 1M + 1 USD in SSTs to the strategy.  6. Assume there are no fees for the SV for simplicity. Synchronization happens. The shares minted for  the deposits will be equal to 1 * 1M USD / (1M + 1 USD) which rounds down to zero.  The deposits will increase the value of the vault so that the attacker profits.  Finally,  consider  that  an  attack  could  technically  also  donate  to  the  strategy  before  the  DHW  so  that totalStrategyValue is pumped.    While the total supply of SSTs is less than INITIAL_LOCKED_SHARES, the shares are minted at a fixed rate.  INITIAL_LOCKED_SHARES  are  minted  to  the  address  0xdead  so  that  a  minimum  amount  of shares is enforced. That makes such attacks much more expensive.  Spool - Spool V2 -   25  SecurityHighVersion1CodeCorrected          \f6.6   Flushing Into Ongoing DHW Leading to Loss of Funds  The DHW could be reentrant due to the underlying protocols allowing for reentrancy or the swaps being reentrant. That reentrancy potential may allow an attacker to manipulate the perceived deposit value in Strategy.doHardWork().  Consider the following scenario:  1. DHW is being executed for a strategy. The deposits are 1M USD. Assume that for example the best  off-chain computed path is taken for swaps. An intermediary token is reentrant.  2. The  strategy  registry  communicated  the  provided  funds  and  the  withdrawn  shares  for  the  DHW  CS-SpoolV2-005  index to the strategy.  3. Funds are swapped.  4. The  attacker  reenters  a  vault  that  uses  the  strategy  and  flushes  1M  USD.  Hence,  the  funds  to  deposit and shares to redeem for the DHW changed even though the DHW is already running.  5. The funds will be lost. However, the loss is split among all SVs.  6. However, the next DHW will treat the assets as deposits made by SVs. An attacker could maximize his profit by depositing a huge amount and flushing to the DHW index where the donation will be applied. Additionally, he could try flushing all other SVs with small amounts. The withdrawn shares will be just lost.  To summarize, flushing could be reentered to manipulate the outcome of DHW due to bad inputs coming from the strategy registry.    Reentrancy protection has been added for this case.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   No Deposit Due to Reentrancy Into ", "body": " redeemFast()  CS-SpoolV2-006  The DHW could be reentrant due to the underlying protocols allowing for reentrancy or the swaps being reentrant. That reentrancy potential may allow an attacker to manipulate the perceived deposit value in Strategy.doHardWork().  Consider the following scenario:  1. DHW  is  executed  for  a  strategy.  The  deposits  are  1M  USD.  Assume  that  for  example  the  best  off-chain computed path is taken for swaps. An intermediary token is reentrant.  2. DHW checks the value of the strategy, which is 2M USD and fully controlled by the attacker's SV.  3. The DHW swaps the incoming assets. The attacker takes control of the execution.  4. The attacker redeems 1M USD with redeemFast(). The strategy's value drops to 1M USD.  5. DHW proceeds, a good swap is made and the funds are deposited into the protocol.  6. DHW retrieves the new strategy value which is now 2M USD.  Spool - Spool V2 -   26  SecurityHighVersion1CodeCorrectedSecurityHighVersion1CodeCorrected              \f7. The perceived deposit is now 0 USD due to 2. and 6. However, the actual deposit was 1M USD.  Ultimately, the deposit made is treated as a donation to the attacker since zero shares are minted.  Similarly, such attacks are possible when redeeming SSTs with redeemStrategyShares().  Also,  the  attack  could  occur  in  regular  protocol  interactions  if  the  underlying  protocol  has  reentrancy possibilities  (e.g.  protocol  itself  has  a  swapping  mechanism).  In  such  cases,  the  reallocation  could  be vulnerable due to similar reasons in depositFast().    Reentrancy protection has been added for this case.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Wrong Slippage Parameter in Curve Deposit", "body": "  Curve3CoinPoolBase._depositToProtocol() calculates an offset for the given slippage array. This  offset  is  then  passed  -  without  the  actual  array  -  into  the  function  _depositToCurve().  The add_liquidity()  function  of  the  Curve  pool  is  then  called  with  this  offset  parameter,  setting  the slippage to always either 7 or 10:  CS-SpoolV2-007  uint256 slippage; if (slippages[0] == 0) {     slippage = 10; } else if (slippages[0] == 2) {     slippage = 7; } else {     revert CurveDepositSlippagesFailed(); }  _depositToCurve(tokens, amounts, slippage);  pool.add_liquidity(curveAmounts, slippage);  DHW calls can be frontrun to extract almost all value of this call.    Curve3CoinPoolBase._depositToProtocol()  now  passes  the  correct  value  of  the  slippages array to _depositToCurve().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Curve LP Token Value Calculation Can Be", "body": " Manipulated  CS-SpoolV2-008  Spool - Spool V2 -   27  CorrectnessHighVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fCurve3CoinPoolBase._getUsdWorth()  calculate the value of available LP tokens in the following way:  and   ConvexAlusdStrategy._getTokenWorth()  for (uint256 i; i < tokens.length; ++i) {     usdWorth += priceFeedManager.assetToUsdCustomPrice(         tokens[i], _balances(assetMapping.get(i)) * lpTokenBalance / lpTokenTotalSupply, exchangeRates[i]     ); }  This  is  problematic  as  the  pool  exchanges  tokens  based  on  a  curve  (even  though  it  is  mostly  flat). Consider the following scenario (simplified for 2 tokens):   The pool's current A value is 2000.   The pool holds 100M of each token.   The total LP value according to the given calculation is 200M USD.   A big trade (200M) changes the holdings of the pool in the following way:   300M A token   ~160 B token   The total LP value according to the given calculation is now ~300M USD.  A  sandwich  attack  on  StrategyRegistry.doHardWork()  could  potentially  skew  the  value  of  a strategy dramatically (although an enormous amount of tokens would be required due to the flat curve of the StableSwap pool). This would, in turn, decrease the number of shares all deposits in this DHW cycle receive, shifting some of this value to the existing depositors.  All  in  all,  an  attacker  must  hold  a  large  position  on  the  strategy,  identify  a  DHW  that  contains  a  large deposit to the strategy and then sandwich attack it with a large amount of tokens. The attack is therefore rather unlikely but has a critical impact.    The  Curve  and  Convex  strategies  now  contain  additional  slippage  checks  for  the  given  Curve  pool's token  balances  (and  also  the  Metapool's  balances  in  the  case  of  ConvexAlusdStrategy)  in beforeDepositCheck. As this function is always called in doHardWork, the aforementioned sandwich attack can effectively be mitigated by correctly set slippages. It is worth noting that these slippages can be  set  loosely  (to  prevent  the  transaction  from  failing)  as  some  less  extreme  fluctuations  cannot  be exploited due to the functionality of the underlying Curve 3pool.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Deposits to Vault With Only Ghost Strategies", "body": " Possible  Governance  can  remove  strategies  from  vaults.  It  happens  by  replacing  the  strategy  with  the  ghost strategy.  However,  if  an  SV  has  only  ghost  strategies,  deposits  to  it  are  still  possible  (checking  the deposit  ratio  always  works  since  the  ideal  deposit  ratio  is  0  or  due  to  the  \"one-token\"  mechanics). However, flushing would revert. User funds could unnecessarily be lost. Similarly, redemptions would be possible. Additionally, synchronization could occur if the ghost strategy is registered (which should not be the case).  CS-SpoolV2-009  Spool - Spool V2 -   28  CorrectnessMediumVersion1CodeCorrected        \f  The case was disallowed by making a call to the newly implemented function _nonGhostVault, which also  gets  called  when  redeeming  and  flushing.  Hence,  depositing  to,  redeeming  and  flushing  from  a ghost vault is disabled.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Ghost Strategy Disables Functionality", "body": "  Governance can remove strategies from SVs by replacing them with the ghost strategy. This may break redeemFast() on SVs due to StrategyRegistry.redeemFast() trying to call redeemFast() on the ghost strategy.  CS-SpoolV2-010    The iteration is skipped in case the current strategy is the ghost strategy. Hence, the function is not called on the ghost strategy anymore.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Inconsistent Compound Strategy Value", "body": "  CompoundV2Strategy  calculates  the  yield  of  the  last  DHW  epoch  with  exchangeRateCurrent() which returns the supply index up until the current block:  uint256 exchangeRateCurrent = cToken.exchangeRateCurrent();  baseYieldPercentage = _calculateYieldPercentage(_lastExchangeRate, exchangeRateCurrent); _lastExchangeRate = exchangeRateCurrent;  CS-SpoolV2-011  On the other hand, _getUsdWorth() calculates the value of the whole strategy based on the output of _getcTokenValue() which in turn calls Compound's exchangeRateStored():  if (cTokenAmount == 0) {     return 0; }  // NOTE: can be outdated if noone interacts with the compound protocol for a longer period return (cToken.exchangeRateStored() * cTokenAmount) / MANTISSA;  This behavior has been acknowledged with a comment in the code. However, it can become problematic in the following scenario:   The compound protocol did not have interaction over a longer period.   A user has deposited into a SmartVault that contains the CompoundV2Strategy.  In the doHardWork() call, the strategy's _compound function does not deposit to the protocol (i.e. the index is not updated in Compound). This can happen in the following cases:   No COMP rewards have been accrued since the last DHW.   The  ROLE_DO_HARD_WORKER  role  has  not  supplied  a  SwapInfo  to  the  strategy's  _compound function.  Spool - Spool V2 -   29  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                 \fIn this case, the following line in Strategy.doHardWork() relies on outdated data:  usdWorth[0] = _getUsdWorth(dhwParams.exchangeRates, dhwParams.priceFeedManager);  usdWorth[0]  is  then  used  to  determine  the  number  of  shares  minted  for  the  depositors  of  this  DHW epoch:  mintedShares = usdWorthDeposited * totalSupply() / usdWorth[0];  Since some interest is missing from this value, the depositors receive more shares than they are eligible for, giving them instant gain.    _getcTokenValue() now retrieves the current exchange rate instead of the stale one.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Strategy Value Manipulation", "body": "  CS-SpoolV2-043  SmartVaultManager.redeemFast() allows users to directly redeem their holdings on the underlying protocols  of  the  strategies  in  a  vault.  The  function  calls  to  Strategy.redeemFast()  in  which  the totalUsdValue of the respective strategy is updated.  This value can be manipulated in several ways:  If  the  given  Chainlink  oracle  for  one  of  the  assets  is  not  returning  a  correct  value,  the  user  can provide exchangeRateSlippages that would allow these false exchange rates to be used.  If the strategy's correct value calculation depends on slippage values to be non-manipulatable, the strategy's value can be changed with a sandwich attack as there is no possibility to enforce correct behavior (see, for example, Curve LP token value calculation can be manipulated). Furthermore, this sandwich  attack  is  particularly  easy  to  perform  as  the  user  is  in  control  of  the  call  that  has  to  be sandwiched (i.e., all calls can be performed in one transaction).  A  manipulated  strategy  value  is  problematic  for  SmartVaultManager.reallocate()  because  the totalUsdValue is used to compute how much value is moved/matched between strategies.  Note: This issue was disclosed by the Spool team during the review process of this report.    reallocate() now computes the value of strategies directly, rather than relying on totalUsdValue (which is now completely removed from the codebase),  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Distribution to Ghost Strategy", "body": "  DepositManager._distributeDepositSingleAsset  assigns  all  dust  to  the  first  strategy  in  the given array. There are no checks present to ensure that this strategy is not the Ghost strategy.  CS-SpoolV2-040  Spool - Spool V2 -   30  SecurityMediumVersion1CodeCorrectedCorrectnessLowVersion4CodeCorrected                  \f  The code has been adjusted to add dust to the first strategy with a deposit.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   Lack of Access Control for Setting Extra", "body": " Rewards  setExtraRewards() has no access control. However, an attacker could set the extra rewards to false for a long time. Then, after their SV's first deposit to the strategy, could set it to true, so that they receive more compounded yield than they should have received.  CS-SpoolV2-041    The code has been corrected.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.16   Wrong Error ", "body": " IdleStrategy.beforeRedeemalCheck()  CS-SpoolV2-028  range-check   The  the IdleBeforeDepositCheckFailed error. However, IdleBeforeRedeemalCheckFailed would be the suiting error.  IdleStrategy.beforeRedeemalCheck()   reverts   with   in     The correct error is used.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.17   Access Control Not Central to Access", "body": " Control Contract  The specification defines that access control should be centralized in SpoolAccessControl:  All access control is handled centrally via SpoolAccessControl.sol.  CS-SpoolV2-012  However,  implementation which does not use the central access control contract.  factory  as  an  UpgradeableBeacon   the   implements  access  control   for  changing  Spool - Spool V2 -   31  CorrectnessLowVersion3CodeCorrectedCorrectnessLowVersion3CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                        \fSpecification changed:  The documentation has been clarified:  Access control is managed on three separate levels:      - All privileged access pertaining to usage of the platform is handled       through SpoolAccessControl.sol, which is based on OpenZeppelin\u2019s       AccessControl smart contract      - Core smart contracts upgradeability is controlled through       OpenZeppelin\u2019s ProxyAdmin.sol      - SmartVault upgradeability is controlled using OpenZeppelin\u2019s       UpgradeableBeacon smart contract  Hence, the access control for upgrading the beacons is now accordingly documented.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.18   Asset Decimal in Price Feed", "body": "  The  asset  decimals  are  given  as  an  input  parameter  in  setAsset().  Although  being  cheaper  than directly querying ERC20.decimals(), it is more prone to errors. Fetching the asset decimals through the ERC20 interface could reduce such risks.  CS-SpoolV2-013    ERC20.decimals() is now called to fetch the underlying asset decimals.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.19   Bad Event Emissions", "body": "  In  StrategyRegistry.redeemFast(),  the  StrategySharesFastRedeemed()  is  emitted.  The assetsWithdrawn  parameter  of  the  event  will  be  set  to  withdrawnAssets  on  every  loop  iteration. However,  that  does  not  correspond  to  the  assets  withdrawn  from  a  strategy  but  corresponds  to  the assets withdrawn up to the strategy i.  CS-SpoolV2-014    The event takes now strategyWithdrawnAssets as a parameter.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.20   Broken Conditions on Whether Deposits", "body": " Have Occurred  Spool - Spool V2 -   32  CS-SpoolV2-015  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fDepositManager.flushSmartVault(),   In  condition _vaultDeposits[smartVault][flushIndex][0]  ==  0  checks  whether  at  least  one  wei  of  the first token in the asset group has been deposited. However, the condition may be imprecise as it could technically be possible to create deposits such that the deposit of the first asset could be zero while the others  are  non-zero.  A  similar  check  is  present  in  DepositManager.syncDepositsSimulate() during deposit synchronization.  the   Note  that  this  would  lead  to  deposits  not  being  flushed  and  synchronized  (ultimately  ignoring  them). While  the  user  will  receive  no  SVTs  for  very  small  deposits  in  general,  the  deposits  here  would  be completely  ignored.  Further,  this  behavior  becomes  more  problematic  for  rather  large  asset  groups (given the checkDepositRatio() definition).    checks   The  of _vaultDeposits[smartVault][flushIndex]  to  all  assets  rather  than  only  considering  the  first asset in the group.  summation   improved   consider   been   have   the   to   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.21   Deposit Deviation Can Be Higher Than", "body": " Expected  The  deviation  of  deposits  could  be  higher  than  expected  due  to  the  potentially  exponential  dropping relation between the first and last assets. Note that the maximum deviation is the one from the minimum ideal-to-deposit ratio to the maximum ideal-to-deposit ratio. Ultimately, given the current implementation, this maximum deviation could be violated.  CS-SpoolV2-016    The following mechanism has been implemented. First, a reference asset is found with an ideal weight non-zero (first one found). Then, other assets are compared to that asset. Ultimately, each ratio is in the range of the reference asset.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.22   Inconsistent Handling of Funds on Strategy", "body": " Removal  When  a  strategy  is  removed  from  the  strategy  registry,  the  unclaimed  assets  by  SVs  are  sent  to  the emergency  wallet.  However,  the  funds  flushed  and  unflushed  underlying  tokens  are  not  (similarly  the minted shares are not).  CS-SpoolV2-018    Spool - Spool V2 -   33  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fConsistency was reevaluated. The corner case of an SV with non-flushed deposited assets was handled by  introducing  a  recovery  function,  namely  DepositManager.recoverPendingDeposits().  The other cases were specified as intended.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.23   Misleading Constant Name", "body": "  In SfrxEthHoldingStrategy the constant CURVE_ETH_POOL_SFRXETH_INDEX is used to determine the coin ID in an ETH/frxETH Curve pool. Since the pool trades frxETH instead of sfrxETH, the naming of the constant is misleading.  CS-SpoolV2-019    Spool has changed CURVE_ETH_POOL_SFRXETH_INDEX to CURVE_ETH_POOL_FRXETH_INDEX.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.24   Missing Access Control in Swapper", "body": "  The  Swapper.swap()  function  can  be  called  by  anyone.  If  a  user  accidentally  sends  funds  to  the swapper or if it was called with a misconfigured SwapInfo struct, the remaining funds can be sent to an arbitrary address by anyone.  CS-SpoolV2-020    introduced  a  new   to Spool  has  Swapper.swap()  holds  ROLE_STRATEGY  or  ROLE_SWAPPER  role.  ROLE_SWAPPER  must  now additionally be assigned to the DepositSwap contract.  function  _isAllowedToSwap,  which  checks   the  caller   if   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.25   Missing Event Fields", "body": "  The events PoolRootAdded and PoolRootUpdated of IRewardPool do not include added root (and previous root in the case of PoolRootUpdated).  CS-SpoolV2-021    The code has been adapted to include the added root.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.26   No Sanity Checks on Slippage Type", "body": "  Spool - Spool V2 -   34  CS-SpoolV2-022  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                                \fSome functions do not verify the value in slippages[0]. Some examples are:  1. IdleStrategy._emergencyWithdrawImpl does not check if slippages[0] == 3.  2. IdleStrategy._compound does not check if slippages[0] < 2.    All relevant functions now check that slippages[0] has the expected value and revert otherwise.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.27   Precision Loss in Notional Finance Strategy", "body": "  NotionalFinanceStrategy._getNTokenValue()  calculates  the  value  of  the  strategy's  nToken balance in the following way:  (nTokenAmount * uint256(nToken.getPresentValueUnderlyingDenominated()) / nToken.totalSupply())     * underlyingDecimalsMultiplier / NTOKEN_DECIMALS_MULTIPLIER;  CS-SpoolV2-023  nToken.getPresentValueUnderlyingDenominated()  returns  values  similar  or  notably  smaller than  nToken.totalSupply.  On  smaller  amounts  of  nToken  balances,  precision  is  lost  in  this calculation.    The implementation of _getNTokenValue() has been changed to the following:  (nTokenAmount * uint256(nToken.getPresentValueUnderlyingDenominated()) * _underlyingDecimalsMultiplier)     / nToken.totalSupply() / NTOKEN_DECIMALS_MULTIPLIER;  All divisions are now performed after multiplications, ensuring that precision loss is kept to a minimum.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.28   Redemption Executor", "body": "  CS-SpoolV2-025  the   redeemer   Redemptions will enter WithdrawalManager._validateRedeem() that will run Withdrawal guards through with  executor.  when  SmartVaultManager.redeemFor()  with is  ROLE_SMART_VAULT_ALLOw_REDEEM.  This  address  through  RedeemBag  nor RedeemExtras.  In  this  case,  WithdrawalManager._validateRedeem()  runs  the  guards  with  the executor being set as the redeemer.  is  neither  sent   However,   executor   actual   called   user   the   the   as   a     The executor is now more accurately handled.  Spool - Spool V2 -   35  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f6.29   State Inconsistencies Possible  CS-SpoolV2-042  SmartVaultManager.redeemFast()  allows  users  to  redeem  their  holdings  directly  from  underlying protocols.  In  contrast  to  StrategyRegistry.doHardWork(),  users  can  set  the  slippages  for withdrawals themselves which could potentially lead to users setting slippages that do not benefit them.  This  is  problematic  because  the  amount  of  shares  actually  redeemed  in  the  underlying  protocol  is  not accounted for. Since some protocols redeem on a best-effort basis, fewer shares may be redeemed than requested (this is, for example, the case in the YearnV2Strategy). If this happens, and the user sets wrong slippages, the protocol burns all SVTs the user requested but does not redeem all the respective shares of the underlying protocol leading to an inconsistency that unexpectedly increases the value of the remaining SVTs.    The code for the Yearn V2 strategy has been adapted to check for full redeemals.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.30   Unused Functions", "body": "  The following functions of MasterWallet are not used:  1. approve  2. resetApprove    These functions have been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.31   Unused Variable", "body": "  CS-SpoolV2-026  1. DepositSwap.swapAndDeposit()   takes  an   input  array  of  SwapInfo,  which  contains  amountIn. This function however takes an input array of inAmounts.  2. The  mapping  DepositManager._flushShares   is  defined  as   internal  and   its  subfield  flushSvtSupply is never read.  3. WithdrawalManager._priceFeedManager is set but never used.  CS-SpoolV2-044    The code has been adapted to remove the unused variables.  Spool - Spool V2 -   36  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f6.32   Validation of Specification  CS-SpoolV2-027  The  specification  of  an  SV  is  validated  to  ensure  that  the  SV  works  as  the  deployer  would  expect  it. However, some checks could be missing. Examples of such potentially missing checks are:  1. Request type validation for actions: Only allow valid request types for action (some request types  are not used for some actions).  2. If  static  allocations  are  used,  specifying  a  risk  provider,  a  risk  tolerance  or  an  allocation  provider may  not  be  meaningful  as  they  are  not  stored.  Similarly,  if  only  one  strategy  is  used  it  could  be meaningful to enforce a static allocation.  3. Static  allocations  do  not  enforce  the  100%  rule  that  the  allocation  providers  enforce.  For  consistency, such a property could be enforced.    The code has been adapted to enforce stronger properties on the specification.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.33   Distinct Array Lengths", "body": "  CS-SpoolV2-029  Some  arrays  that  are  iterated  over  jointly  can  have  distinct  lengths  which  lead  to  potentially  unused values and a result different from what was expected due to human error or a revert.  Examples of a lack of array length checks in the specification when deploying an SV through the factory are:  1. actions  and  actionRequestTypes  in  ActionManager.setActions()  may  have  distinct  length. Some request-type values may remain unused.  2. Similarly, this holds for guards.  3. In the strategy registry's doHardWork(), the base yields array could be longer than the strategies  array.  4. In assetToUsdCustomPriceBulk() the array lengths could differ. When used internally, that will not  be  the  case  while  when  used  externally  that  could  be  the  case.  The  semantics  of  this  are unclear.  5. calculateDepositRatio()  and  calculateFlushFactors()  in  DepositManager  are  similar to 4.    The missing checks in 1-3 have been added. However, for 4-5 which are view functions, Spool decided to keep as is.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.34   Errors in NatSpec", "body": "  Spool - Spool V2 -   37  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChanged                  \fCS-SpoolV2-030  At  several  locations,  the  NatSpec  is  incomplete  or  missing.  The  following  is  an  incomplete  list  of examples:  1. IGuardManager.RequestContext: not all members of the struct are documented.  2. IGuardManager.GuardParamType: not all items of the enum are documented.  3. _stateAtDhw has no NatSpec.  4. IDepositManager.SimulateDepositParams:  documentation   line  of  bag  mentions  oldTotalSVTs along with flush index and lastDhwSyncedTimestamp.  5. StrategyRegistry._dhwAssetRatios:  is  a  mapping  to  the  asset  ratios,  as  the  name  suggests; however, the spec mentions exchange rate.  6. StrategyRegistry._updateDhwYieldAndApy(): it only updates APY and not the yield for a  given dhwIndex and strategy.  7. RewardManager.addToken():   or only  ROLE_SMART_VAULT_ADMIN  of  an  SV  and  not  \"reward  distributor\"  as  mentioned  in  the specification.  either  DEFAULT_ADMIN_ROLE   callable   by   Specification changed:  The  NatSpec  was  improved.  Naming  of  StrategyRegistry._updateDhwYieldAndApy()  was changed to _updateApy().  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.35   Gas Optimizations", "body": "  CS-SpoolV2-031  Some parts of the code could be optimized in terms of gas usage. Reducing gas costs may improve user experience. Below is an incomplete list of potential gas inefficiencies:  1. claimSmartVaultTokens() could early quit if the claimed NFT IDs are claimed. Especially, that may  be  relevant  in  cases  in  the  redeem  functions  where  a  user  can  specify  W-NFTs  to  be withdrawn.  2. The FlushShares struct has a member flushSvtSupply that is written when an SV is flushed. However, that value is never used and hence the storage write could be removed to reduce gas consumption.  3. swapAndDeposit()  queries  the  token  out  amounts  with  balanceOf().  Swapper.swap()  returns the amounts. However, the return value is unused.  4. RewardManager()  inherits  from  ReentrancyGuardUpgradeable.  It  further  is  initializable,  initializing only the reentrancy guard state. However, reentrancy locks are not used.  5. The constructor of SmartVaultFactory checks whether the implementation is 0x0. However, in  UpgradeableBeacon an isContract() check is made.  6. In  redeemFast()  the  length  of  the  NFT  IDs  and  amounts  is  ensured  to  be  equal.  However,  in  DepositManager.claimSmartVaultTokens() the same check is made.  7. In   the   internal   public  method flushSmartVault() is used. The _onlyRegisteredSmartVault() check will be performed twice.  SmartVaultManager._redeem(),   function   the   8. IStrategy.doHardwork()  could  return  the  assetRatio()  with  the  DHW  info  so  that  a staticcall to IStrategy.assetRatio() in StrategyRegistry.doHardwork() is not needed.  Spool - Spool V2 -   38  InformationalVersion1CodeCorrected      \f9. In  _validateRedeem()  the  balance  of  the  redeemer  is  checked.  However,  that  check  is  made  when the SVTs are transferred to the SV.  10. The input argument vaultName_ in SmartVault.initialize can be defined as calldata.  11. SmartVault.transferFromSpender()  gets  called  only  by  WithdrawalManager  with  spender equal to from.  12. SmartVault.burnNFT() checks that the owner has enough balance to burn. The same condition  is later checked as it calls into _burnBatch.  13. The  struct  SmartVaultSpecification  in  SmartVaultFactory  has  an  inefficient  ordering  of elements.  For  example,  by  moving  allowRedeemFor  below  allocationProvider  its  storage layout decreases by one slot.  14. The struct IGuardManager.GuardDefinition shows an inefficient ordering.  15. Where  ReallocationLib.doReallocation()  computes  sharesToRedeem,  it  can  replace  totals[0] - totals[1] with totalUnmatchedWithdrawals.  16. SmartVaultManager._simulateSync()   increments   the   memory   variable  flushIndex.toSync which is neither used later nor returned as a return value.  17. SmartVaultManager._redeem()  calls  flushSmartVault.  However,  the  internal  function  _flushSmartVault could directly be called.  18. SmartVaultManager._redeem()   storage  _flushIndexes[bag.smartVault] twice. It could be cached and reused once.  accesses   the   variable  19. StrategyRegistry.doHardWork() reads _assetsDeposited[strategy][dhwIndex][k]  twice. Similar to the issue above, it could be cached.  20. UsdPriceFeedManager.assetToUsdCustomPriceBulk() could be defined as external.  21. WithdrawalManager.claimWithdrawal() can be defined as an external function.  22. RewardManager.forceRemoveReward()   rewardConfiguration[smartVault][token],  _removeReward().  eventually  is   which   already   removes in  removed   23. RewardPool.claim()   can   simply   rewardsClaimed[msg.sender][data[i].smartVault][data[i].token]  data[i].rewardsTotal.  set to  24. SmartVaultManager._simulateSyncWithBurn()  can  fetch  fees  after  checking  all  DHWs  are completed.  25. Strategies are calling AssetGroupRegistry.listAssetGroup in multiple functions. The token  addresses could instead be cached in the strategy the avoid additional external calls.  26. REthHoldingStrategy._emergencyWithdrawImpl() reverts if slippages[0] != 3. This  check can be accomplished at the very beginning of the function.  27. REthHoldingStrategy._depositInternal()   if amounts[0] < 0.01 ETH. It is mentioned in its documentations, that the smallest deposit value should be 0.01 ETH  return   have   early   can   an   28. The  input  parameter  strategyName_  of  SfrxEthHoldingStrategy.initialize()  can  be  defined as calldata.  29. Strategy  calls  _swapAssets  and  then  loads  the  balances  of  each  token  again.  Since _swapAssets is not used in all of the strategies, the subsequent balanceOf calls by checking if _swapAssets actually performed any actions.    Spool - Spool V2 -   39  \fWhile not every improvement has been implemented, gas consumption has been reduced.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.36   NFT IDs", "body": "  The NFT IDs are in the following ranges:   D-NFTs: [1, 2**255 - 2]   W-NFTs: [2**255 + 1, 2**256 - 2]  CS-SpoolV2-032  Note  that  the  ranges  could  be  technically  increased.  Further,  in  theory,  there  could  be  many  more withdrawals  than  deposits.  The  sizes  do  not  reflect  that.  However,  in  practice,  a  scenario  with  such  a large  number  of  redemptions  does  not  seen  to  be  realistic.  Additionally,  getMetaData()  will  return deposit meta data for ID 0 and 2**255 - 1. However, these are not valid deposit NFT IDs. Similarly, the  function  returns  metadata  for  invalid  withdrawal  NFTs.  However,  these  remain  empty.  Last, technically  one  could  input  such  IDs  for  burn  (using  0  shares  burn).  Similarly,  one  could  burn  others' NFTs (0 amounts).  Ultimately, the effects of this may create confusion.    The range of valid NFT-IDs has been increased.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.37   Nameless ERC20", "body": "  The  SVT  ERC-20  does  not  have  a  name.  Specifying  a  name  may  help  third-party  front-ends  (e.g. Etherscan) to display useful information to users for a better user experience.  CS-SpoolV2-033    The SVT now has a name and symbol for its ERC-20. Additionally, the ERC-1155 has a URI now.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.38   Reverts Due to Management Fee", "body": "  An SV can have a management fee that is computed as  totalUsd[1] * parameters.fees.managementFeePct * (result.dhwTimestamp - parameters.bag[1])                 / SECONDS_IN_YEAR / FULL_PERCENT;  It  could  be  the  case  that  more  than  one  year  has  passed  between  the  two  timestamps.  Ultimately  the condition  parameters.fees.managementFeePct * (result.dhwTimestamp - parameters.bag[1]) > SECONDS_IN_YEAR * FULL_PERCENT  CS-SpoolV2-035  Spool - Spool V2 -   40  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \fcould hold if at least around 20 years have passed. That would make the fee greater than the total value.  Ultimately,  result.feeSVTs = localVariables.svtSupply * fees / (totalUsd[1] - fees);  could revert.    The code was corrected by limiting the dilution of SVTs so that the subtraction cannot revert.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.39   Simplifying Performance Fees", "body": "  The performance fees could further be simplified to  strategyUSD * interimYieldPct / (1 + interimYieldPct * (1-totalPlatformFees))  which is equivalent to the rather complicated computations made in the current implementation.  CS-SpoolV2-036  Code improved:  The readability of the code has been improved by simplifying the computation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.40   Strategy Removal for an SV Possible That", "body": " Does Not Use It  The event StrategyRemovedFromVaults gets emitted for a strategy even if the SV does not use the strategy.  CS-SpoolV2-037    The event is now emitted per vault that uses the strategy. Furthermore, the name of this event has been changed to StrategyRemovedFromVault.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.41   Tokens Can Be Enabled Twice", "body": "  In  AssetGroupRegistry,  the  same  token  can  be  allowed  multiple  times.  Although  it  does  not  make any difference, regarding the internal state, it emits an event of TokenAllowed again.  CS-SpoolV2-038  Spool - Spool V2 -   41  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f  The event is not emitted anymore in such cases.  Spool - Spool V2 -   42  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Packed Arrays With Too Big Values Could", "body": " DOS the Contract  The  packed  array  libraries  could  technically  DOS  the  system  due  to  reverts  on  too  high  values.  For storing DHW indexes this is rather unlikely given the expectation that it will be only called every day or two (would generally require many DHWs). It is also expected that the withdrawn strategy shares will be less  than  or  equal  to  uint128.max.  Though  theoretically  speaking  DOS  on  flush  is  possible,  the conditions on the practical example are very unlikely.  CS-SpoolV2-034  Risk accepted:  Spool replied:  We agree that theoretically packed arrays could overflow and revert, however, we did some calculations and this should never happen in practice.  Spool - Spool V2 -   43  InformationalVersion1RiskAccepted    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.1   Bricked Smart Vaults", "body": "  Some Smart Vaults may be broken when they are deployed.  An example of such broken SVs could be that a malicious SV owner could deploy a specification with guards that allow deposits but disallow withdrawals (e.g. claiming SVT). Moreover, the owner may deploy a  specification  that  is  seemingly  safe  from  the  user's  perspective  while  then  maliciously  changing  the behaviour of the guard (e.g. removing from the allow list, upgrading the guard).  Another example could be where transfers between users could be allowed while the recipient could be blocked from redemption.  Similarly, actions or other addresses could be broken.  Users,  before  interacting  with  an  SV,  should  be  very  carefully  studying  the  specification.  Similarly, deployers should be knowledgeable about the system so that they can create proper specifications to not create bricked vaults by mistake.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.2   Curve Asset Ratio Slippage", "body": "  Curve strategies return the current balances of the pool in their assetRatio() functions. These ratios are  cached  once  at  the  end  of  each  DHW.  For  all  deposits  occurring  during  the  next  DHW  epoch,  the same  ratios  are  used  although  the  ratios  on  the  pool  might  change  during  that  period.  It  is  therefore possible, that the final deposit to the protocol incurs a slight slippage loss.  Given the size and parameters of the pools, this cost should be negligible in most cases.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.3   DOS Potential for DHWs Due to External", "body": " Protocols  DHWs could be blocked in case external protocols cannot accept or return funds. For example, if Aave v2 or Compound v2 have 100% utilization, DHWs could be blocked if withdrawals are necessary. This can in turn prolong the time until deposits earn interest and become withdrawable again.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.4   ERC-1155 balanceOf()", "body": "  The balanceOf() function of the SV's ERC-1155 returns 1 if the user has any balance. The standard defines  that  the  function  should  return  the  balance  which  in  this  case  is  defined  as  the  \"fractional  Spool - Spool V2 -   44  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fbalance\". Depending on the interpretation of EIP-1155, this could still match the standard. However, such a deviation from the \"norm\" could break integrations.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.5   Management Fee Considerations", "body": "  Users should be aware that the management fee is not taken based on the vault value at the beginning of the flush cycle but at the end of it (hence, including the potential yield of strategies, however not including fresh deposits).  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.6   Ordering of Swaps in Reallocations and", "body": " Swaps  The privileged user doing reallocation or swaps (e.g. the one holding ROLE_DO_HARD_WORKER) should take an optimal path when performing the swaps, as depositing to/withdrawing from a strategy changes its value.  Also, note that some strategies could be affected more by bad trades due to the swaps being performed in the order of the strategies. For example:  1. depositFast() to the first strategy happens. The swap changes the price in the DEX.  2. depositFast() to the second strategy happens. The swap works at a worse price than the first  strategy.  Ultimately, some deposits could have worse slippage.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.7   Price Aggregators With More Than 18", "body": " Decimals  Setting  decimals  with  UsdPriceFeedManager.setAsset(). Such are not supported by the system.  aggregators   more   price   than   18   will   revert   in  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.8   Public Getter Functions", "body": "  Users  should  be  aware  that  some  public  getters  provide  only  meaningful  results  with  the  correct  input values (e.g. getClaimedVaultTokensPreview()). When used internally, it is ensured that the inputs are set such that the results are meaningful.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.9   Reentrancy Potential", "body": "  Spool - Spool V2 -   45  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                    \fWhile  reentrancy  protection  was  reentrancy-based attacks may still exist. However, it highly depends on the underlying strategies. Future unknown strategies could introduce vulnerable scenarios.  the  code,  some  potential   implemented     of   in   for  An  example  could  be  a  strategy  that  swaps  both  on  compounding  and  on  deposits  in  DHW.  If  it  is possible  to  manipulate  the  USD  value  oracle  of  the  strategy  (e.g.  similar  to  Curve),  then  one  could effectively generate a scenario that creates 0-deposits or \"bypasses\" the pre-deposit/redeemal checks.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.10   Reward Pool Updates", "body": "  The ROLE_REWARD_POOL_ADMIN should be very careful, when updating the root of a previous cycle (if necessary), as it could break the contract for certain users.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.11   Slippage Loss in alUSD Strategy", "body": "  ConvexAlusdStrategy  never  invests  alUSD  into  the  corresponding  Curve  pool.  This  can  result  in  a slight  slippage  loss  due  to  unbalanced  deposits.  Both  deposits  and  withdrawals  are  subject  to  this problem.  The  loss  is  negligible  up  to  a  certain  amount  of  value  deposited/withdrawn.  After  that,  there  is  no  limit though.  At  the  time  this  report  was  written,  a  withdrawal  of  10M  LP  tokens  to  3CRV  incurs  a  loss  of roughly 25%.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.12   Special Case: Compound COMP Market", "body": "  Compound  v2  currently  has  an  active  market  for  the  COMP  token.  In  this  case,  deposits  to  the CompoundV2Strategy  would  be  absorbed  by  the  _compound()  function  if  a  compoundSwapInfo has  been  set  for  the  strategy.  The  correct  handling  is  therefore  completely  dependent  on  the  role ROLE_DO_HARD_WORKER and is not enforced on-chain.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "8.13   Unsupported Markets", "body": "  Some markets of the supported protocols in Spool V2's strategies might be problematic:   Aave markets in which the aToken has different decimals than the underlying. While this is not the case for any aToken currently deployed, Aave does not guarantee that this will be the case in the future.   Compound supports fee-taking tokens. If such a market would be integrated into Spool V2, it could be  problematic  as  the  CompoundV2Strategy._depositToCompoundProtocol()  does  not account for the return value of Compound's mint() function.   Compound's  cETH  market  is  unsupported  due  to  it  requiring  support  for  native  ETH  and  hence  having a different interface than other cTokens.  Spool - Spool V2 -   46  Version2NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f8.14   Value of the alUSD Strategy's Metapool LP Token Overvalued  The  Curve  metapool  that  is  used  in  the  ConvexAlusdStrategy  allows  to  determine  the  value  of  LP tokens,  function calc_withdraw_one_coin(). This is used in the strategy to determine the value of one token which is then scaled up by the actual LP token amount.  is  withdrawn,  with   the  2  underlying   if  only  one  of   tokens   the   The function, however, does not linearly scale with the amount of LP tokens due to possible slippage loss with higher amounts. The LP tokens are therefore overvalued.  Spool - Spool V2 -   47  NoteVersion1  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Failing to Untrack Offers of Cancelled", "body": " Auctions  RemoveOffers can untrack offers when the auction has not started yet or when it has been cancelled for withdrawal. Redeem can only untrack offers when repo tokens can be redeemed and at least one repo token is in the contract. Sweep can only untrack offers if the auction has completed and if the balance of repo tokens is zero.  If the auction has been cancelled, offers cannot be untracked. While action sweep can be used to return the purchase tokens to the vault, it does not untrack the offer. Ultimately, that may lead to increased gas consumption.  CS-SUL14-001  Risk accepted:  Avantgarde Finance replied:  After consultation with the Term Finance team, this risk is accepted since (1) there is no way to observe cancelled auctions on-chain, (2) cancellations are rare (has not occurred on mainnet yet), and (3) the worst case is gas cost bloat (i.e., not security or correctness)  Avantgarde Finance - Sulu Extensions XIV -   11  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Double Tracking Term Contracts, Inflation of EP Valuation   -Severity Findings   Term EP Incorrect Loan Value   -Severity Findings   Delta Is Not Applied on Current State   Informational Findings  Inconsistent Array Lengths for Term Finance EP   0  1  1  1  1  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Double Tracking Term Contracts, Inflation of", "body": " EP Valuation  CS-SUL14-005  The  AddOrUpdateOffers  action  in  the  Term  Finance  EP  is  responsible  for  publishing  new  offers  or updating existing ones. When this action is called for a term auction without any tracked offers and with an empty \"submittedOfferIds\" parameter (represented as empty bytes32[]), no checks are done, the term auction  is  simply  added  to  the  array  termAuctions.  This  process  can  be  repeated  multiple  times, essentially pushing the same term auction address into the termAuctions array on each call.  Afterwards actual offers can be added for this termAuction.  getManagedAssets() iterates through the array of tracked \"termAuctions\" and assesses the individual offers. It depends on the assumption that the \"termAuction\" contract exists in the array only once. Due to the  repetitive  presence  of  the  same  \"termAuction\"  address  in  the  array,  the  same  offers  are  counted multiple times. As a result, this leads to an inaccurate and inflated valuation for the external position.  This could be abused by a malicious manager to inflate the positions valuation.    It  is  now  ensured  that  the  submitted  offer  IDs  is  not  empty.  As  a  consequence,  at  least  one  ID  is published to Term Finance. Hence, no term contract can be added without having at least one offer ID.  Avantgarde Finance - Sulu Extensions XIV -   12  CriticalHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected           \f6.2   Term EP Incorrect Loan Value  In  getManagedAssets(),  __getLoanValue()  is  used  to  calculate  the  value  of  a  loan.  Before maturity  of  a  loan,  the  valuation  of  the  offers  may  be  inaccurate.  Namely,  a  multiplication  with redemptionValue() is missing. Hence, the repo tokens are treated as 1:1 to the underlying during the lifespan of a loan. Once expiry has been reached, redemptionValue() is taken into account (this is in line with what the tokens may be redeemed for).  CS-SUL14-002  As a consequence, the value per offer will evolve as follows:  1. Before auction completion: offer.amount.  2. Right  after  auction  completion  offer.amount  /  redemptionValue  (assuming  the  auction completion happened right at the term start. Note that value is the combination of the formulas of how many repo tokens Term Finance mints and how Enzyme valuates them - resulting in a function based on the offer's amount).  3. Linear  increase  for  the  principal  amount  computed  in  2.  over  time  according  to  interest  rate (offer.amount/redemptionValue*(1+clearingPrice*timePassedSoFar)  -  again  this formula  is  a  combination  of  formulas  to  result  in  a  formula  based  on  the  initial  offered  amount). Right before the end of the term, the value should be roughly what 4. is as nearly no time needs to pass.  4. offer.amount * (1+clearingPrice*totalTime)  To summarize, during the life time the loan value is not scaled by redemptionValue() which will lead to an undervaluation of the position. It is best visible at the borders of the lifespan of a loan where the value suddenly jumps to lower/higher values.    The code now multiplies with redemptionValue() where the multiplication was missing.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Delta Is Not Applied on Current State", "body": "  CS-SUL14-003  When adding an offer or updating it's amount, the delta may be applied to outdated values, leading to potentially undetected decreases. Consider the following example:  1. An offer submission is created with a delta of 100 (assume the offer ID will be X). That will lead to  an offered amount of 100 for the submission.  2. The offer at X is updated with an offer submission with a delta of 50. Since the submission of 1. has not  been  published,  this  computation  will  work  on  \"outdated\"  values.  Namely,  this  will  lead  to  an offered amount of 50.  3. The changes applied on the corresponding Term contract. Ultimately, one offer will be present with  X having 50 tokens offered.  4. As a consequence, 50 tokens are left in the contract and not swept (no decrease detected).  Note that tokens could unnecessarily be left in the EP.  Avantgarde Finance - Sulu Extensions XIV -   13  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f  The code has been adjusted. In case the offer IDs returned by the term auciton offer locker contract are not unique in the array, the execution reverts. Hence, the scenario of modifying two times the same offer ID in one go is not allowed anymore.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Inconsistent Array Lengths for Term Finance", "body": " EP  The _actionArgs of action AddOrUpdateOffers consists of three arrays that should have the same length.  However,  that  is  not  enforced  and,  hence,  unexpected  behaviour  could  occur.  Namely,  if  the amounts have a length greater than the offer IDs, the parser will compute a too high amount of funds to be  transferred  to  the  EP.  The  price  hashes  could  also  have  a  length  greater  than  the  offer  IDs  which results in some price hashes not being used (unspecified behaviour).  CS-SUL14-004    It is now validated that the arrays have the same length.  Avantgarde Finance - Sulu Extensions XIV -   14  InformationalVersion1CodeCorrected      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Jump in Value at Auction Completion", "body": "  An auction could be completed after the term start. As a consequence, once the auction is completed, the value of the EP may jump from the constant value of the offered amounts to a value that includes some interest.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   TermFinance: Permissionless Redemption", "body": "  calling After  maturity,  TermRepoServicer.redeemTermRepoTokens().  Resulting  int  the  external  position  receiving  the purchase token. Using action Sweep, these tokens can be returned to the vault.  redemption   anyone   tokens   trigger   repo   can   the   by   of   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   ZeroEx V4 OTC Order Type Incompatible With", "body": " GasRelayer  In ZeroEx v4, OTC orders include a field tx.origin which must match the actual tx.origin of the execution. This verification ensures that only the authorized party can execute the order. Executing an order through the adapter, this is typically the fund manager (the caller of callOnExtension).  Consequently the GasRelayer is unusable in this scenario.  Avantgarde Finance - Sulu Extensions XIV -   15  NoteVersion1NoteVersion1NoteVersion1          \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Skim in _Free()", "body": "  0  0  0  3  For  End.free()  to  be  successful,  the  proxy's  art  must  be  zero.  However,  the  following  code  of DssProxyActionsEnd._free() does not strictly enforce that.  function _free(     address end,     uint256 cdp ) internal returns (uint256 ink) {     bytes32 ilk = manager.ilks(cdp);     address urn = manager.urns(cdp);     uint256 art;     (ink, art) = vat.urns(ilk, urn);     // If CDP still has debt, it needs to be paid     if (art > 0) {         EndLike(end).skim(ilk, urn);         (ink,) = vat.urns(ilk, urn);     }     // Approves the manager to transfer the position to the proxy's address in the vat     if (vat.can(address(this), address(manager)) == 0) {         vat.hope(address(manager));     }     // Transfers position from CDP to the proxy address     manager.quit(cdp, address(this));     // Frees the position and recovers the collateral in the vat registry     EndLike(end).free(ilk); }  First,  in  case  that  art  is  non-zero,  end.skim()  is  executed  on  the  urnproxy.  Next,  the  position  is transferred  to  the  proxy.  Note  that  the  proxy  could  have  non-zero  art.  Hence,  the  call  end.free() which frees the collateral of its msg.sender and requires that art is zero could revert.    MakerDAO - DSSProxyActions -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrected        \fNow,  skim()  is  called  for  the  proxy  and  after  the  CDP  has  been  transferred  from  the  urn.  Thus,  it  is enforced that art will be zero.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Unused Function _sub()", "body": "  The internal function _sub is never used.    The unused function was removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Use Defined Constant", "body": "  Contract Common defines:  uint256 constant RAY = 10 ** 27;  Instead of using the constant, function _toRad has this value hardcoded:  function _toRad(uint256 wad) internal pure returns (uint256 rad) {     rad = _mul(wad, 10 ** 27); }    This function has been removed in the final version of the code reviewed.  MakerDAO - DSSProxyActions -   13  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Dust Amount of DAI to Be Drawn Leads to", "body": " Revert  There is a known issue in functions that use _getDrawDart(): In case the additional amount of DAI to be drawn leads to a dusty urn, the transaction reverts. This is a known edge case.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   dai Shadowed", "body": "  Contract Common defines the immutable dai. The internal functions _getDrawDart, _getWipeDart and _getWipeAllWad each define a local uint256 dai which consequently shadows the immutable.  In    the variables in the functions have been renamed.  MakerDAO - DSSProxyActions -   14  NoteVersion1NoteVersion1Version2      \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Incorrect Liquidity Decrease", "body": "  PoolCollection._calcTargetTradingLiquidity  decreases  the  BNT  trading  liquidity  if  the current funding of a certain pool is greater than its funding limit. This is done in a way that could possibly reset the pool:  uint256 excessFunding = currentFunding - fundingLimit; targetBNTTradingLiquidity = MathEx.subMax0(liquidity.bntTradingLiquidity, excessFunding);  Consider the following example:   The funding limit is 40,000 BNT.   The current funding of the pool is 40,000 BNT.   bntTradingLiquidity is 20,000 BNT (for example after the value of BNT to the corresponding  token has quadrupled).   The funding limit is now lowered to 20,000 BNT by governance.   bntTradingLiquidity is now set to 0 and the pool is reset on the next deposit.  Bancor - Bancor v3 -   13  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedLowAcknowledgedRiskAcceptedCodePartiallyCorrectedCodePartiallyCorrectedRiskAcceptedRiskAcceptedDesignMediumVersion2RiskAccepted             \fRisk accepted  Bancor plans to fix this issue in a future version and accepts the risk for now.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Missing Slippage Protection", "body": "  The following functions do not guarantee any slippage protection for users and are thus susceptible for front-running attacks:   BancorPortal._uniV2RemoveLiquidity   functions  removeLiqudity  and removeLiquidityETH  of  UniswapV2Router02  with  1  wei  slippage  protection  at  all circumstances.  calls   the    BancorV1Migration.migratePoolTokens   calls  removeLiquidity  StandardPoolConverter with 1 wei slippage protection at all circumstances.  in  Bancor   v1's  Risk accepted:  The client accepts the risk, stating the following:  Similar to how liquidity removal is processed on these 3rd party protocols, it is assumed that users will migrate their liquidity immediately and will be prompted with its results.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.3   Missing Getter for Average Rates", "body": "  The function PoolCoollection.poolData is commented as follows:  there  is  no  guarantee  that  this  function  will  remain  forward  compatible,  so  relying  on  it  should  be avoided and instead, rely on specific getters from the IPoolCollection interface  This  indicates  that  all  data  from  the  struct  that  is  returned  by  this  function  is  also  available  via independent getters. There is, however, no getter function available that returns the AverageRates.  Acknowledged  Bancor acknowledged the issue and plans to fix it in a future version.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.4   Fake Pool Token Migration", "body": "  BancorV1Migration.migratePoolTokens does not check if the given pool token is registered in the ContractRegistry. For this reason, an attacker could call the function with a fake pool token contract that returns a fake StandardPoolConverter:  IBancorConverterV1 converter = IBancorConverterV1(payable(poolToken.owner()));  Bancor - Bancor v3 -   14  SecurityMediumVersion1RiskAcceptedDesignLowVersion2AcknowledgedSecurityLowVersion1RiskAccepted                        \fThis converter can then in turn return reserve amounts of tokens that do not exist:  uint256[] memory reserveAmounts = converter.removeLiquidity(amount, reserveTokens, minReturnAmounts);  If the BancorV1Migration contract holds only tokens for some reason, these tokens can then be sent to  token  balances  before  calling converter.removeLiquidity.  the  contract  does  not  check   the  attacker  as   its   Risk accepted:  The client accepts the risk noting that the contract is not supposed to receive any tokens.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.5   Gas Savings", "body": "  The following list contains suggestions on how the gas consumption of Bancor v3 can be improved:   The fields of MigrationResult in BancorPortal can be rearranged to achieve tighter packing.   BancorNetwork.addPoolCollection  loads  the  latest  pool  collection  from  storage  then  calls  _setLatestPoolCollection which loads the same pool collection from storage again.   BancorNetwork.createPools loads the same pool collection on each iteration from storage.   BancorNetwork._depositBNTFor  transfers  BNT  to  the  BNTPool  which  then  burns  them.  The  tokens could be burned by BancorNetwork instead.   BancorNetwork.withdraw   to BancorNetwork. _withdrawBNT then approves BNTPool for the tokens and transfers the tokens to BNTPool. The tokens could be directly transferred from PendingWithdrawals to BNTPool.  PendingWithdrawal   transfers   tokens   from   pool    BancorNetwork._withdrawBNT transfers vBNT from the provider to BNTPool which then burns  them. The tokens could be burned directly from the provider's address.   BancorNetwork.withdraw   to BancorNetwork. _withdrawBaseToken then approves PoolCollection for the tokens which burns them. The tokens could be directly burned from PendingWithdrawals.  PendingWithdrawal   transfers   tokens   from   pool    Some  or  all  fields  in  NetworkSettings  could  be  immutable  and  updated  via  proxy  upgrade,  depending on how frequently they are updated and loaded.   Many  call  chains  unnecessarily  validate   than  once.  For  example, BancorNetwork.initWithdrawal  validates  the  pool  token  address  and  amount,  then  calls PendingWithdrawals.initWithdrawal  which  performs  the  same  validations  again  even though it can only be called by the BancorNetwork contract.  input  data  more    PoolCollection.depositFor  loads  data.liquidity.stakedBalance  from  storage  and then loads the whole data.liquidity struct from storage with no change of the data in-between.   PoolCollection.depositFor  reads  data.liquidity  from  storage,  updates  the  fields  on  storage and then loads the struct again two times from storage.   PoolMigrator.migratePool  retrieves  the  target  pool  collection  of  a  given  pool  by  calling BancorNetwork.latestPoolCollection.  It  then  calls  PoolCollection.migratePoolOut which performs the same call to check if the given target pool collection is valid.   PoolCollection._poolWithdrawalAmounts takes the Pool struct as memory copy. Since not all  words  are  accessed  and  the  function  is  only  called  with  storage  pointers,  the  data  argument could be a storage pointer and the necessary fields could be cached inside the function.  Bancor - Bancor v3 -   15  DesignLowVersion1CodePartiallyCorrected        \f PoolCollection._executeWithdrawal loads stakedBalance from storage even though it is  already cached in prevLiquidity   PoolCollection._updateTradingLiquidity calls _resetTradingLiquidity which loads liquidity.bntTradingLiquidity  from  storage  even  though  an  overloaded  version  of  the function  exists  which  takes  that  variable  as  an  argument  and  there  is  a  cached  version  of liquidity available.   PoolCollection._performTrade  loads  the  liquidity  struct  from  storage  even  though  the  values are already present in the TradeIntermediateResult argument.   PoolMigrator._migrateFromV1  translates  the  Pool  struct  from  the  old  version  to  the  new  version. Since the structs are identical, this is not necessary.   PoolToken._decimals can be immutable.  pools    Because   address, PoolTokenFactory.createPoolToken could take the override variables as arguments instead of using storage variables.  added   admin   only   can   the   be   by    AutoCompoundingRewards.terminateProgram loads ProgramData from storage to check if the given program exists. As the pool is later removed from _pools, the call would revert anyways if the the pool program did not exist.  In  AutoCompoundingRewards  some  ProgramData struct from storage even though not all words are required.  (e.g.  enableProgram)   functions   load   the  whole  In StandardRewards some functions (e.g. createProgram) load the whole ProgramData struct from storage even though not all words are required.   The fields _bntPool, _pendingWithdrawals and __poolMigrator in BancorNetwork could be  immutable  if  they  are  set  up  either  directly  in  the  constructor  of  BancorNetwork  or  with pre-known addresses.  In BancorNetwork.flashloan, the user could pay the loaned amount directly back to the master vault.   During  a  withdrawal  of  base   in PendingWithdrawals instead of burning a part of them, sending the rest to BancorNetwork and finally burning them in PoolCollection.  tokens  (not  BNT),  all  pool   tokens  could  be  burned   Code partially corrected:  The client has addressed some of the suggestions. Additionally, some are no longer relevant due to other code changes.   Corrected: The fields of MigrationResult in BancorPortal are now tightly packed.   Corrected: latestPoolCollection has been completely removed from the code.   Corrected: BancorNetwork.createPools takes the respective pool collection as argument.   Not corrected: BancorNetwork._depositBNTFor still transfers BNT to the BNTPool which then  burns them.   Corrected:   BancorNetwork._withdrawBNT   directly   transfers   pool   tokens   from  PendingWithdrawal to BNTPool.   Not  corrected:  BancorNetwork._withdrawBNT  still  transfers  vBNT  from  the  provider  to  BNTPool which then burns them.   Partially corrected: BancorNetwork._withdrawBaseToken directly transfers pool tokens from  PendingWithdrawal to PoolCollection.   Not corrected: All fields in NetworkSettings are still storage variables.  Bancor - Bancor v3 -   16     \f Not corrected: There are still many call chains that validate input multiple times.   Not   corrected:   PoolCollection.depositFor   still   redundantly   loads  data.liquidity.stakedBalance from storage.   Not  corrected:  PoolCollection.depositFor  still  redundantly   loads  data.liquidity  multiple times from storage.   Corrected: latestPoolCollection has been completely removed from the code.   Corrected: PoolCollection._poolWithdrawalAmounts takes only relevant and cached data  as input.   Not  corrected:  PoolCollection._executeWithdrawal  still  loads  stakedBalance  from  storage.   Corrected:  PoolCollection._updateTradingLiquidity  uses  the  overloaded  version  of  _resetTradingLiquidity.   Not  corrected:  PoolCollection._performTrade  still  loads  the  liquidity  struct  from  storage.   Not   corrected:   PoolMigrator._migrateFromV1   has   been   renamed   to  PoolMigrator._migrateFromV5 but still unnecessarily translates equal structs.   Not corrected: PoolToken._decimals is still a storage variable.   Not corrected: PoolTokenFactory.createPoolToken still uses storage for override variables.   Not  corrected:  AutoCompoundingRewards.terminateProgram  still  redundantly  checks  for  pool existance.   Not  corrected:  In  AutoCompoundingRewards  some  functions  (e.g.  pauseProgram)  still  load  more data from storage than required.   Not corrected: In StandardRewards some functions (e.g. _programExists) still load more data  from storage than required.   Not  corrected:  The  fields  _bntPool,  _pendingWithdrawals  and  __poolMigrator  are  still  stored in storage.   Not  corrected:  In  BancorNetwork.flashloan,  the  loaned  amount  is  still  paid  back  to  the  contract and then sent to the master vault.   Corrected: PendingWithdrawals.completeWithdrawal does not burn tokens anymore.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.6   Inconsistent Reentrancy Protection", "body": "   AutoCompoundingRewards.createProgram  has  a  reentrancy  protection,  while  the  functions  terminateProgram and enableProgram do not.   BancorNetwork.withdrawNetworkFees  does  not  have  reentrancy  protection,  while  other  functions that are restricted to callers with certain roles have.  Code partially corrected  function Although  all  mentioned  AutoCompoundingRewards.setAutoProcessRewardsCount  lacks  reentrancy  protection  while  all other functions restricted to the admin are protected.  functions  are  now  protected  against  reentrancy,   the  new   Bancor - Bancor v3 -   17  DesignLowVersion1CodePartiallyCorrected          \f5.7   Rounding Error Can Lock Tokens  When  creating  a  StandardRewards  program,  both  the  reward  rate  and  the  remaining  rewards  are computed as follows:  uint256 rewardRate = totalRewards / (endTime - startTime); _programs[id] = ProgramData({     ...     rewardRate: rewardRate,     remainingRewards: rewardRate * (endTime - startTime) });  Depending  on  the  token's  number  of  decimals  and  the  duration  of  the  program,  remainingRewards can be smaller than totalRewards due to the divide-then-multiply scheme. In practice, this means that in  such  cases,  totalRewards  -  remainingRewards  tokens  won't  be  distributed  and  will  never  be deduced  from  _unclaimedRewards.  This  results  in  the  tokens  being  locked  in  the  contract  and  not being able to be used for future programs.  Risk accepted:  The client accepts the risk, stating the following:  The  amount  of  tokens  which  can  be  locked  due  to  a  rounding  error  is  negligible.  We  are  also considering revamping the whole mechanism, which will also affect this code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.8   BNTPool.renounceFunding Division by 0", "body": "  In  PoolCollection._executeWithdrawal,  if  the  protocol  has  to  renounce  BNT  funding  and  this results  in  the  BNT  staked  balance  being  reset  to  0,  but  the  BNT  trading  liquidity  is  still  greater  than  0, _resetTradingLiquidity  is  called  which  tries  to  renounce  BNT  funding  again.  As  the  staked balance has already been set to 0, this second call to BNTPool.renounceFunding will now revert due to a division by 0.  Consider the following case:   User A deposits TKN liquidity into an empty pool.   Trading is enabled.   User B trades a certain amount of TKN for BNT.   User A now withdraws all his supplied TKN.   The withdrawal fails due to the mentioned problem.  Risk accepted:  The client accepts the risk, stating the following:  This  is  a  rare  case  that  we  don\u2019t  expect  to  happen  in  practice,  since  trading  can\u2019t  be  enabled immediately and usually involves many depositors. In any case, we will consider addressing this in the future as well.  Bancor - Bancor v3 -   18  DesignLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Oracle Manipulation   -Severity Findings   BNT Burned Twice    Locked vBNT    Pool Denial of Service   -Severity Findings  0  1  3  18   BNT Deposit Allows msg.value > 0    Consistency Issues Between Implementation, Excel Demonstration and Documentation Regarding  the Withdrawal    Different Programs Can Share the Same Reward    Emission of Events With Arbitrary Amounts   Impossible to Migrate ETH Position   Inconsistent Naming   Inconsistent Use of ERC20.transfer    Misleading Comment    Misleading Comment in PoolCollection.enableTrading    Problematic Loop Continuation During Pool Migration    Undocumented Behavior    Unused Imports / Variables    Wrong Function Name in BancorPortal    Wrong Interface    AutoCompoundingRewards Can Burn More Pool Tokens Than Expected    BNTPool.renounceFunding Fails on Insufficient BNT Pool Token Balance    ERC20Permit Handling    MathEx.reducedFraction Can Turn Denominator to 0   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Oracle Manipulation", "body": "  To  prevent  manipulation,  Bancor  v3  calculates  a  moving  average  of  each  pool's  spot  price  that  is adjusted  once  per  block.  Critical  actions  like  the  increase  of  trading  liquidity  or  withdrawal  of  funds  Bancor - Bancor v3 -   19  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected           \frequires  the  spot  rate  of  a  pool  to  not  diverge  from  this  moving  average  by  more  than  a  certain percentage.  Since the moving average is calculated as an arithmetic mean, it is subject to manipulation. Consider the following scenario:   An attacker funds a pool with some tokens with a spot rate of 1 BNT : 1 token.   They perform a trade from BNT to the token by providing an amount of BNT that changes the spot  rate to 10 BNT : 1 token. The average rate is now 2.8 BNT : 1 token.  In the next block, they perform another trade from token to BNT to bring the spot rate back to 2.8 BNT : 1 token.   Since the spot rate now equals the average rate, the attacker can withdraw his supplied tokens.   The  pool  does  not  contain  enough  tokens  to  satisfy  the  withdrawal,  so  the  attacker  gets  compensated in BNT for the outstanding amount.   This compensation is calculated with the average rate of the pool which now is 2.8 BNT to 1 token  instead of the real 1 : 1 rate.   The attacker will receive 2.8 times the amount of BNT he is actually eligible to receive.  The  attacker  is  required  to  split  both  trades  in  2  consecutive  blocks.  In  the  first  block,  they  create  an arbitrage opportunity that can be utilized by an arbitrageur. To make sure, their initial investment will not be lost, they must selfishly mine 2 blocks in a row. This is possible with around 1.5% of the total hashrate of Ethereum. Renting this amount of hashrate is in the realm of possibilities and we estimate that the cost of renting the hashrate and losing out on the reward of the additional mined blocks results in a total cost of ~150.000 USD.  Alternatively, an attacker could try to spam transactions to the Ethereum network in order for their second transaction to be executed before the transactions of any arbitrage bot.  Furthermore, after Ethereum's transition to Proof-of-Stake, the attack becomes simpler: As the attacker now knows when it is their turn for validation, they could submit their first transaction right to the block before. Using Flashbots, the transaction could actually be hidden so that no arbitrage bots would see it before it is included in the block. The next block is then in the hand of the attacker.  While this attack is hard to carry out and requires a lot of capital, it can also create immense losses.    A second moving average for the inverse rate has been introduced. Averages for the rate and the inverse rate are calculated independently which prevents the aforementioned attack. The resulting inverse rate in the example would diverge from the inverse spot rate by ~100%.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   BNT Burned Twice", "body": "  Withdrawals  from  PoolCollection  can  result  in  the  burning  of  double  the  amount  of  BNT  than intended. This happens any time a withdrawal occurs that results in the protocol removing BNT from the this  case,  both  amounts.bntProtocolHoldingsDelta.value  and protocol  equity.  amounts.bntTradingLiquidityDelta.value are set to the same value greater than 0, resulting in a  call  to BNTPool.burnFromVault which burns the same amount of BNT again.  to  BNTPool.renounceFunding  which  burns   the  amount  of  BNT  and  a  call   In     Bancor - Bancor v3 -   20  CorrectnessMediumVersion1CodeCorrected         \fboth   If  and amounts.bntTradingLiquidityDelta.value  are  greater  than  0,  only  the  former  value  triggers token burning (via BNTPool.renounceFunding).  amounts.bntTradingLiquidityDelta.value   ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Locked vBNT", "body": "  the   StandardRewards   In  or depositAndJoinPermitted to deposit underlying tokens and stake the obtained pool tokens in one single transaction. To perform such aggregation, the protocol transfers the tokens from the user to itself and calls BancorNetwork.depositFor to get the pool tokens that will then be used for staking.  depositAndJoin   contracts,   users   can   call   If the token being deposited is BNT, BancorNetwork will send both bnBNT and vBNT to the contract. As there is no handling for vBNT, it will stay locked into the contract, preventing the user to ever withdraw his BNT from the network.    depositAndJoin  now  keeps  the  pool  tokens,  but  sends  vBNT  back  to  the  provider  if  BNT  are deposited.  Additionally,  a  temporary  function  transferProviderVBNT  has  been  added  to  allow distribution of already accumulated vBNT to their owners by the contract admin.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Pool Denial of Service", "body": "  The  first  user  to  deposit  into  a  newly  created  pool  can  immediately  burn  his  pool  tokens.  In  this  case, depositing into the pool no longer works, because the following check will revert:  if (poolTokenSupply == 0) {     if (stakedBalance > 0) {         revert InvalidStakedBalance();     } }  A malicious user could create a bot that performs this attack cheaply by instantly depositing 1 wei base tokens into any newly created pool.    New deposits now reset the pool when pool token supply is 0 and staked balance is greater than 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   BNT Deposit Allows msg.value > 0", "body": "  BancorNetwork.depositFor is payable. While the _depositBaseTokenFor function makes sure that it reverts if the sent token is not equal to ETH and msg.value is greater than 0, the same check is not applied in _depositBNTFor.  Bancor - Bancor v3 -   21  DesignMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f  _depositBNTFor now reverts if msg.value is greater than 0.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Consistency Issues Between Implementation,", "body": " Excel Demonstration and Documentation Regarding the Withdrawal  1. Deviating Calculation of BNT Burned  The  formula  for  BNT  trading  liquidity  to  be  burned  from  the  pool  defined  in  the  excel  spreadsheet renounce nothing method.A11 is deviating from the white paper and the implementation. It seems like the sign in front of B10*E10 needs to be removed.  The documented and implemented formula is:  P =  ax(b + c + e(2 \u2212 n)) (1 \u2212 m)(be + x(b + c \u2212 e(1 \u2212 n)))  The formula used in excel is:  2. Incorrect Denominator  P =  ax(b + c + e(2 \u2212 n)) (1 \u2212 m)(\u2212be + x(b + c \u2212 e(1 \u2212 n)))  The documentation on page 39 has the following formula documented for hmax  supr  hmaxsurp = be(en + m(b + c \u2212 e)) (1 \u2212 m)(b + c \u2212 e(1 \u2212 n))  The formula's denominator is missing the additional term (b+c-e)  Specification changed  Bancor replied the following:  Both issues outlined here were actually typing errors in the spec, while the implementation is correct. The spec was updated.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Different Programs Can Share the Same", "body": " Reward  AutoCompoundingRewards ensures that only one program exists for a specific pool at a given time. In practice, this means that the pool tokens allocated for such programs cannot be used by another one.  Bancor - Bancor v3 -   22  CorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1CodeCorrected                          \fSimilarly, using _unclaimedRewards, StandardRewards makes sure that if multiple programs have the same reward token, the external reward vault must contain enough tokens to cover all of them.  However,  if  StandardRewards  and  AutoCompoundingRewards  contain  programs  for  the  same reward token and the address for the _externalRewardsVault is the same in both contracts, correct funding cannot be ensured because both programs only check that there are enough funds in the vault.    StandardRewards  now  only  distributes  BNT  via  minting.  _externalRewardsVault anymore.  It  does  not  access   the  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   Emission of Events With Arbitrary Amounts", "body": "  BancorNetwork._initWithdrawal does not check if the supplied pool token address belongs to a pool. An attacker could call the function with a fake pool token that returns a valid pool address:  Token pool = poolToken.reserveToken(); if (!_network.isPoolValid(pool)) {     revert InvalidPool(); }  The contract would then transfer the fake pool tokens from the attacker while the attacker keeps the real pool tokens and emit a WithdrawalInitiated event with arbitrary pool token amounts. While this is not  a  problem  for  the  protocol  itself  and  is  also  not  exploitable  in  the  final  withdrawal,  third  party applications relying on the emitted events could be affected.    _initWithdrawal now correctly checks if the supplied pool token is valid.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Impossible to Migrate ETH Position", "body": "  When  trying  to  migrate  a  Uniswap  or  SushiSwap  position,  if  one  of  the  tokens  is  the  protocol  defined native token address 0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE, the call to the factory to obtain  transaction  will  revert  with the  NoPairForTokens as this custom address is not used in these protocols.  the  pair's  address  will  return   the  address  zero  and   Code corrected  Bancor now interacts with Uniswap and SushiSwap using the WETH address instead of 0xEee...EEeE.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Inconsistent Naming", "body": "  Bancor - Bancor v3 -   23  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fBancorPortal.migrateSushiSwapV1Position returns a struct with \"Uniswap\" in one of its field's names.    migrateUniswapV2Position and migrateSushiSwapPosition now both return a struct with the name PositionMigration.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   Inconsistent Use of ERC20.transfer", "body": "  In some cases a normal transfer is used. Some of these occurrences have the comment:  // transfer the tokens to the provider (we aren't using safeTransfer, since the PoolToken is a fully // compliant ERC20 token contract) p.poolToken.transfer(provider, poolTokenAmount)  But the pool token is also transferred with a safe transfer in another case  poolToken.safeTransferFrom(provider, address(_pendingWithdrawals), poolTokenAmount)  The assumption that all tokens behave as expected should be carefully evaluated against gas savings between a normal transfer and a safe transfer.    BancorNetwork._initWithdrawal  now  transfers  the  pool  tokens  using  a  regular  transferFrom call.  Since  all  pool  tokens  are  PoolToken  contracts,  they  revert  on  failure  making  it  safe  to  use  the regular transferFrom function.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.12   Misleading Comment", "body": "  _latestPoolCollections in BancorNetwork has the following comment:  a mapping between the last pool collection that was added to the pool collections set and its type  Since the function setLatestPoolCollection allows the governance to set to latest pool collection to any pool collection, the comment is incorrect.  Furthermore, when the the \"latest\" pool collection is set to an older version, multiple pool collections with the same version can be added through addPoolCollection.    The latestPoolCollections mechanism has been completely removed.  Bancor - Bancor v3 -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.13   Misleading Comment in  PoolCollection.enableTrading  A comment of PoolCollection.enableTrading states:  if  the  price  of  one  (10**18  wei)  BNT  is  $X  and  the  price  of  one  (10**6  wei)  USDC  is  $Y,  then  the virtual balances should represent a ratio of X to Y*10**12  The explanation is ambiguous and could be misunderstood in a way that both virtual balances must be represented with the same number of decimals.    The addressed documentation has been improved to clarify possible misunderstandings.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Problematic Loop Continuation During Pool", "body": " Migration  BancorNetwork.migratePools  checks  if  newPoolCollection  is  equal  to  the  0-address.  In  the current setup this can never happen.  Furthermore,  if  the  PoolMigrator  implementation  changes  for  future  PoolCollection  versions  so that  the  migratePool  function  could  indeed  return  the  0-address,  the  mentioned  check  leads  to  a continuation of the migration loop:  if (newPoolCollection == IPoolCollection(address(0))) {     continue; }  In this case, the pool data of the old pool would be lost and _collectionByPool would point to a pool collection that does not contain the migrated pool anymore.    The  lastPoolCollection  mechanism  has  been  completely  removed  and  migrations  to  new  pools now require the caller to pass an explicit pool collection to the migratePool function.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   Undocumented Behavior", "body": "  The  trade  functions  in  BancorNetwork  allow  the  user  to  declare  a  beneficiary.  If  the  user  sets  this beneficiary  to  the  0-address,  the  beneficiary  is  replaced  with  the  user's  address.  This  behavior  is  not documented.    Bancor - Bancor v3 -   25  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \fAll trade functions now explain the mentioned special behavior.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.16   Unused Imports / Variables", "body": "  The following types have been imported but not used inside the respective contracts:   BancorNetwork:   WithdrawalRequest   BancorV1Migration:   Upgradeable   BNTPool:   Utils   Fraction   IPoolCollection   Pool   PoolToken   PoolMigrator:   Fraction   AutoCompoundingRewards:   AccessDenied   StandardRewards   AccessDenied  Additionally,  BNTPool  twice,  PoolMigrator  defines  a  private  constant INVALID_POOL_COLLECTION  that  is  not  used  and  StandardRewards  defines  an  unused  error PoolMismatch.  imports  Token     All unused imports and variables have been removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.17   Wrong Function Name in BancorPortal", "body": "  BancorPortal contains a function migrateSushiSwapV1Position indicating calls to SushiSwap v1 even though the referenced contracts belong to SushiSwap v2.    V1 and V2 strings have been removed from all function, event and variable names related to SushiSwap.  Bancor - Bancor v3 -   26  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.18   Wrong Interface  BancorV1Migration.migratePoolTokens  v3's types  IPoolToken interface. While this is not a problem right now, future changes in the interface might create problems here.  legacy  DSToken  addresses  with     BancorV1Migration now uses a separate interface for legacy pool tokens.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.19   AutoCompoundingRewards Can Burn More", "body": " Pool Tokens Than Expected  On creation of a program in AutoCompoundingRewards, the caller provides the amount of tokens that should  be  distributed  during  the  lifetime  of  the  program.  Depending  on  the  token  to  be  distributed, createProgram  and PoolCollection.poolTokenAmountToBurn.  Both  functions  use  the  same  formula  to  calculate  the amount of pool tokens that have to be burned in order to distribute the given token amount:  BNTPool.poolTokenAmountToBurn   either   calls   function poolTokenAmountToBurn(uint256 bntAmountToDistribute) external view returns (uint256) {     if (bntAmountToDistribute == 0) {          return 0;      }       uint256 poolTokenSupply = _poolToken.totalSupply();      uint256 val = bntAmountToDistribute * poolTokenSupply;       return          MathEx.mulDivF(              val,              poolTokenSupply,              val + _stakedBalance * (poolTokenSupply - _poolToken.balanceOf(address(this)))          ); }  The formula allows for the burning of high amounts of pool tokens (up to the total), which can become problematic for new deposits as the value of the pool tokens now far exceeds the value of the underlying tokens, potentially leading to large rounding errors for token suppliers. To highlight this problem, consider the following example:   bnBNT total supply is 20000   The protocol holds all bnBNT (i.e. no user has supplied any BNT)  In this case  _stakedBalance * (poolTokenSupply - _poolToken.balanceOf(address(this))  is now 0. The formula is therefore reduced to:  bntAmountToDistribute * poolTokenSupply * poolTokenSupply     / bntAmountToDistribute * poolTokenSupply  Bancor - Bancor v3 -   27  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected              \fThe amount of tokens to be distributed is now completely factored out of the equation. It will therefore always return poolTokenSupply to be burned, no matter the amount of tokens to distribute.    If the amount of pool tokens to be burnt in a single program exceeds 50% of the total supply, the program is  now  terminated.  This  ensures  that  the  value  of  pool  tokens  does  not  appreciate  too  much  in comparison to the underlying.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.20   BNTPool.renounceFunding Fails on", "body": " Insufficient BNT Pool Token Balance  BNTPool.renounceFunding  removes  a  given  amount  of  BNT  and  burns  the  corresponding  pool tokens. Because the pool tokens will be distributed to BNT liquidity providers, there can be circumstances where the protocol does not hold enough pool tokens for a given amount BNT that has to be burned. This will result in reverting transactions.  Consider the following example:  Liquidity  provider  withdrawals  that  exceed  the  amount  of  excess  tokens  in  a  given  pool  require  the protocol  to  decrease  the  liquidity  of  the  pool.  If  the  amount  of  BNT  liquidity  that  must  be  removed  is greater than the amount of BNT pool tokens the protocol holds (because enough users have provided BNT liquidity in exchange for BNT pool tokens), the call will revert.    renounceFunding  now  burns  at  most  the  amount  of  pool  tokens  available  and  updates  the  staked balance accordingly.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.21   ERC20Permit Handling", "body": "  The permit function of ERC20Permit tokens is called expecting them to revert if the given signature is incorrect.  While  this  is  the  correct  behavior  according  to  the  EIP  2612  specification,  numerous  token projects  have  shown  that  specifications  are  not  always  adhered  to  completely  (e.g.  the  transfer function in USDT). Therefore, it might be possible that some token project exists that does not revert but rather returns a boolean value on calls to permit.    ``ERC20Permit` support has been completely removed from the project.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.22   MathEx.reducedFraction Can Turn", "body": " Denominator to 0  Bancor - Bancor v3 -   28  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fMathEx.reducedFraction  equally  scales  down  two  uint256  values  so  that  the  higher  value  does not exceed a defined maximum. It computes the factor by which the values have to be divided with the following code:  uint256 scale = Math.ceilDiv(Math.max(fraction.n, fraction.d), max);  In the case that fraction.d is smaller than scale, the fraction's denominator will be set to 0 causing undefined behavior. Since the function is always used with a max value of type(uint112).max, this can  only  happen  in  edge  cases  where  the  numerator  of  the  fraction  is  type(uint112).max  times greater than the denominator.  Code Corrected:  reducedFraction now reverts if the denominator is set to 0.  Bancor - Bancor v3 -   29  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   32 Bit Timestamps in Storage", "body": "  Some contracts (e.g. AutoCompoundingRewards) keep timestamps with the type uint32 in storage. This will render the contracts unusable and make them hard to upgrade after the year 2106.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Impermanent Loss Protection Can Be", "body": " Disabled  PoolCollection.enableProtection  can  be  called  by  Bancor  v3's  governance  to  disable Impermanent  Loss  protection.  This  can  result  in  liquidity  providers  not  being  able  to  withdraw  the  full amount of tokens they are owed. In fact, LPs can end up with less tokens than originally provided and without any compensation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Implementations Not Initialized", "body": "  Bancor deploys some if its contracts using a proxy pattern. However, the deployed implementations are not initialized by default. This is also evident on the current live version of the protocol. While this is not a problem  currently,  later  changes  might  introduce  DELEGATECALL  op-codes.  In  this  case,  a  malicious user  could  claim  ownership  of  the  contract  and  generate  a  DELEGATECALL  to  a  contract  containing  a SELFDESTRUCT op-code, causing a denial of service.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Inconsistent Interface", "body": "  PoolCollection  defines  a  function  enableDepositing  with  a  boolean  argument  to  determine  if depositing  should  be  enabled  or  disabled.  On  the  contrary,  it  defines  the  distinct  functions enableTrading and disableTrading.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Liquidity Growth Not Restricted", "body": "  When a pool gets enabled for trading, the starting liquidity is set to a pre-determined amount of BNT and not  set  to  the  full  amount  possible.  On  certain  actions,  the  trading  liquidity  is  allowed  to  grow  by  the LIQUIDITY_GROWTH_FACTOR  liquidity  by  calling  factor.  However,  anyone  can  grow   the   Bancor - Bancor v3 -   30  NoteVersion1NoteVersion2NoteVersion1NoteVersion1NoteVersion1                  \fBancorNetwork.depositFor  with  the  minimum  amount  of  1  wei  token.  Thus,  this  mechanism  only protects against accidents and not against deliberate manipulation.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Missing Access Control in postUpgrade", "body": "  postUpgrade  has  no  access  restrictions.  Using  it  in  an  upgrade  needs  to  happen  in  one  transaction  if frontrunning should be mitigated. Bancor has a deploy script that will automatically call this function in the upgrade transaction. But this is not guaranteed and might fail. We cannot see a case that it should be callable by everyone.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   More vBNt Than bnBNT Obtainable", "body": "  If the protocol does not have any bnBNT, it should be impossible to deposit BNT and hence obtain vBNT. However, in this case, a user can first send some bnBNT to the BNTPool and then deposit some BNT to obtain both the pre-owned bnBNT and newly minted vBNT. Although the BNT the user just deposited is not  withdrawable  anymore  as  he  does  no  longer  own  the  corresponding  bnBNT,  he  is  able  to  obtain additional vBNT at this cost.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.8   No Recovery of Accidental Token Transfers", "body": " Possible  In  case  an  ERC20  token  other  than  the  BNT  or  one  of  the  base  tokens  is  sent  to  the  contract,  then  it cannot  be  recovered.  Among  other  reasons,  this  might  happen  due  to  airdrops  based  on  the  base tokens.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   Potential External Contract Manipulation", "body": "  functions   The  and BancorNetworkInfo.withdrawalAmounts  are  subject  to  manipulation  by  reentrancy.  If  the mentioned  functions  are  used  in  any  way  to  alter  the  state  of  an  external  contract  (for  example  an investment protocol that supplies liquidity to Bancor v3), the values they return can be manipulated by calling the external contract in the onFlashLoan callback of BancorNetwork.flashloan.  PoolCollection.withdrawalAmounts   This is possible because of the following call in PoolCollection._poolWithdrawalAmounts:  int256 baseTokenExcessAmount = pool.balanceOf(address(_masterVault)) -     data.liquidity.baseTokenTradingLiquidity;  onFlashLoan  will  be  called  after  the  balance  of  _masterVault  has  already  been  reduced  by  the flashloan amount.  Bancor - Bancor v3 -   31  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f7.10   Redundant Role Management  Most  contracts  are  upgradable.  Hence,  they  have  their  own  admin  account.  There  is  no  central management checking these roles are set accordingly. An admin change needs to be done individually and redundantly.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.11   Unequal Token Burning", "body": "  Withdrawal  of  supplied  tokens  is  subject  to  a  7-day  waiting  period.  In  this  period,  newly  generated interest is not accrued to the withdrawing user. This means, that after 7-days, the pool tokens sent to the PendingWithdrawals  contract  are  worth  slightly  more  than  the  amount  of  tokens  the  user  actually receives. Because PoolCollection completely burns all of these pool tokens, while BNTPool keeps them, the outcome of a withdrawal of BNT differs to withdrawals of other tokens. Consider the following 2 examples:  BNT:   totalSupply of bnBNT is 100.   _stakedBalance in the BNTPool is 100.   A user initiates a withdrawal with 50 bnBNT, allowing them to withdraw 50 BNT after 7 days.   After 7 days, 100% interest has accrued and the new _stakedBalance is now 200.   The  user  withdraws  their  50  BNT  (which  get  minted)  and  the  50  bnBNT  are  repossessed  by  BNTPool.   _stakedBalance is now 200.   totalSupply is now 100.  TKN:   totalSupply of bnTKN is 100.   _stakedBalance in the PoolCollection is 100.   A user initiates a withdrawal with 50 bnTKN, allowing them to withdraw 50 TKN after 7 days.   After 7 days, 100% interest has accrued and the new _stakedBalance is now 200.   The user withdraws their 50 TKN and the 50 bnTKN are burned.   _stakedBalance is now 150.   totalSupply is now 50.  Both examples illustrate the same scenario but in the BNT case, a pool token is worth 2 BNT in the end, while in the TKN case, a pool token is now worth 3 TKN.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.12   Unsupported Tokens", "body": "  Not all ERC20 tokens can act as base tokens for Bancor v3 contracts. In particular, the following tokens are not supported:  Bancor - Bancor v3 -   32  NoteVersion1NoteVersion2NoteVersion1          \f Tokens that return metadata fields like name and symbol encoded as bytes32 instead of string (e.g.  MKR).  PoolTokenFactory.createPoolToken  will  fail  to  create  a  pool  token  for  these tokens.   Tokens  that  take  a  fee  on  transfer  (e.g.  PAXG  and  possibly  USDT).  A  deposit  will  use  the  full  amount to mint pool tokens while the contract has received a lower amount.   Tokens that have a rebasing mechanism (e.g. AAVE's aToken). User's staked balances will not be  updated accordingly.  Additionally, the following tokens could break the protocol in the future:   Tokens with blacklists (e.g. USDT, USDC).   Upgradeable tokens that add one of the mentioned mechanisms in the future.   Pausable tokens (e.g. BNB).  Bancor - Bancor v3 -   33  \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Precision Loss in rewardRate Calculation", "body": "  The  calculation  of  the  rewardRate  causes  a  potentially  harmful  loss  of  precision.  The  default rewardsDuration  denominator  (1  week  reward  duration)  loses  up  to  604800  wei  of  precision  every time notifyRewardAmount() is called, in the following calculation:  CS-MET-001  rewardRate = reward / rewardsDuration;  and  rewardRate = (reward + leftover) / rewardsDuration;  The amount lost due to rounding has been deposited in the contract, but the internal accounting loses track of it, rendering it unclaimable.  If  rewardsToken  is  a  token  with  a  high  value  per  wei,  the  loss  can  be  significant.  For  example,  if rewardsToken  is  USDC,  which  has  6  decimals,  the  loss  can  be  of  up  to  $  0.6048  every  time notifyRewardAmount() is called. If the token is WBTC, which has 8 decimals but much higher value per  wei,  is  computed.  Since notifyRewardAmount()  can  be  called  every  12  seconds  through  VestedRewardsDistribution,  the rounding amount can be lost up to 50400 times per week.  to  $  181  every   the  rewardRate   is  up   time   loss   the   For tokens with a higher number of decimals and a low value per wei, for example DAI or WETH, the loss is less significant. It amounts to a maximum of $ 0.00006 per week for WETH and $ 3e-18 per week for DAI. The maximum weekly loss can be calculated as follows:  weeklyLoss = rewardsDuration * tokenValuePerWei * blocksPerWeek  Risk accepted:  Maker states:  Maker - EndGame Toolkit -   10  DesignCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted         \fRisk accepted. We are aware of the issue with precision loss, however we wanted to avoid making changes to the original code as much as possible. The StakingRewards contract in this context will only ever handle tokens with 18 decimals (DAI, MKR, SubDAO tokens, NewStable \u2013 Dai equivalent, NewGov \u2013 MKR equivalent). If we take MKR as an example, its all-time high price was just short of 6,300 USD. Let\u2019s extrapolate its value imagining it could grow 100x for the duration of the staking rewards program. Using the formula you provided, we would have:  weeklyLoss  = rewardsDuration * tokenValuePerWei * blocksPerWeek             = 604800 * 50400 * (630000 * 10^(-18))             = 0.0192036096  Even in this extreme scenario, weekly losses would amount to less than 0.02 USD, which is acceptable for us.  Maker - EndGame Toolkit -   11  \f6   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Typo in Documentation", "body": "  In  the  NatSpec  for  the  VestedRewardsDistribution  contract  at  line  23  RewardsDistribution  is misspelled.  CS-MET-002  The typo has been corrected.  Maker - EndGame Toolkit -   12  InformationalVersion1  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Ability to Modify name & symbol", "body": "   introduces functionality for the priviledge role to update the token parameter name and symbol. Note that is unusual for ERC20 tokens and must be done with care. Some downstream applications or smart contracts may not be designed to accommodate such changes.  Consider these illustrative examples:   Upon deployment the name of Curve pools is set using the traded token names.   The  representative  token  deployed  by  third-party  bridges  to  other  chains  is  often  based  on  the  original token's name and symbol.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Rewards in StakingRewards Might Take", "body": " Longer to Vest Than Expected  Rewards added to StakingRewards could be expected to be payed out to stakers in rewardsDuration time,  which  is  initially  set  to  7  days.  However,  every  time  notifyRewardAmount()  is  called,  a  new rewardRate  the  next the  vesting  of  rewardDuration.  the  remaining  amount  over   is  computed  prolonging   As a simple example, assume we are distributing 1000 DAI over one week, then the rewardRate will be rewardRate  =  1000  *  10**18  /  rewardDuration.  If  after  3.5  days  have  passed  we  call notifyRewardAmount(), adding a 0 reward, the new rewardRate is computed as  rewardRate = (reward + leftover) / rewardsDuration;  which  will  amount  to  rewardRate  =  500  *  10**18  /  rewardDuration.  Moreover,  the from periodFinish  initialTime  + rewardDuration.  Overall,  the  reward  distribution  will  last  1.5  times  the  expected  duration,  with  the latter rewardDuration period having half the effective rewardRate as expected.  pushed  be  rewardDuration   by  initialTime   rewardDuration/2   rewardDuration,   moving   back   will   +   +   to   it   time   If we take this reasoning to the extreme, notifyRewardAmount() can be called every block, which will the  periodFinish  by  12  seconds,  and  reduce  every  the  reward  rate  by 1 - blockDuration/rewardDuration. This is because the new rewardRate will be the old reward minus the consumed reward.  increase   rewardRatet = (rewardt \u2212 1 \u2212 rewardRatet \u2212 1 * blockDuration)  rewardDuration  rewardt \u2212 1 \u2212 rewardt \u2212 1  RewardDuration * blockDuration rewardDuration  = = rewardt \u2212 1 rewardDuration * (1 \u2212 blockDuration rewardDuration ) = rewardRatet \u2212 1 * (1 \u2212 blockDuration  rewardDuration ) from   Over  by (1-blockDuration/rewardDuration)^n,  which  is  an  exponential  decay  for  the  rewardRate,  rewardRate  will   rewardRate   decrease   block   initial   the   the   n   Maker - EndGame Toolkit -   13  NoteVersion1Version2NoteVersion1      \fcorresponding  to  an  exponential  decay  of  the  remaining  reward.  The  reward  will  therefore  not  be distributed in a finite amount of time. Numerical simulations have showed that after 1 week 63% will have been distributed, after 2 weeks 86%, after 3 weeks 95%, after 4 weeks almost 99%.  In  practice,  anybody  can  trigger  notifyRewardAmount()  at  every  block  by  calling  the  distribute method  of  VestedRewardsDistribution,  the  cost  of  doing  so  in  terms  of  gas  is  likely  to  offset  any advantage that such an attacker can get from delaying in such a way the reward rate.  Calling distribute() every block will however not pass an amount of zero notifyRewardAmount(), but it will pass the reward per block vested in dssVest. In the steady state, when the dssVest has been supplying a constant stream of reward for a long time, even factoring in the exponential decay behavior, the rewardRate in StakingRewards will converge to the same constant rate as in dssVest.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.3   Vesting Plan Must Be Restricted", "body": "  If a vesting plan of DSSVest is restricted, that means only the recipient of the rewards may claim them, no one else can trigger the distribution of the rewards.  For  the  correct  operation  of  VestedRewardsDistribution  it's  important  that  the  plan  is  restricted: VestedRewardsDistribution.distribute()  in amount  =  dssVest.unpaid(vestId);  only,  any  excess  balance  held  at  the  contract  is  not forwarded.  retrieved   forwards   amount   the   Maker - EndGame Toolkit -   14  NoteVersion1    \f", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.1   Flash_callback Can Return Incorrect Values", "body": "  CS-UNM-031  In MarginDex, the flash_callback function returns the actual_outs array, which lets the vault know how many tokens were received, so that it can transfer them back.  For exact_in orders, the return value is calculated as follows:  if swap_type == 0: # exact_in     actual_out: uint256 = self._swap(token_in, token_out, amount_in, amount_out)     actual_outs[s[1]] += actual_out     if actual_outs[s[0]] > 0: #if we have received some token_in from a previous swap         if actual_outs[s[0]] >= amount_in: #if we have enough previous in to cover the trade             actual_outs[s[0]] -= amount_in         else:             actual_outs[s[0]] = 0 #if we don't have enough previous in to cover the trader  In the last line, we set actual_outs[s[0]] = 0 if the previous swap did not give us enough tokens to cover the full trade. However, we may have also transferred some of the same token into the MarginDex from the Vault. Any remainder from the transferred in amount will not be reflected in the return value. As a result, some tokens could be remaining in the MarginDex that should have been transferred back to the Vault. These tokens can be claimed by anyone.  For exact_actual_out orders, the return value is calculated as follows:  if swap_type == 2: # exact_actual_out         remaining_needed: uint256 = amount_out - ERC20(token_out).balanceOf(self)  Unstoppable - Unstoppable Margin Dex -   12  SecurityDesignCorrectnessTrustCriticalHighMediumLowRiskAcceptedCodePartiallyCorrectedCodePartiallyCorrectedCorrectnessLowVersion2RiskAccepted            \f        if remaining_needed > 0:             actual_in: uint256 = self._swap_exact_out(token_in, token_out, remaining_needed, amount_in)             actual_outs[s[1]] += remaining_needed             actual_outs[s[0]] += amount_in-actual_in         else: #no trade             actual_outs[s[0]] += amount_in  In  the  last  line,  any  amount  that  was  transferred  from  the  vault  is  meant  to  be  accounted,  so  that  it  is correctly  transferred  back.  However,  the  amount_in  value  can  also  be  from  a  previous  trade.  In  this case, the amount was already added in the previous trade. As a result, the same tokens will be added to the  actual_outs  twice.  When  the  Vault  tries  to  transferFrom()  this  amount,  the  balance  will  be insufficient  and  the  transaction  will  revert.  However,  the  user  can  try  again  with  a  different swap_sequence and succeed.  Risk accepted:  Unstoppable is aware of the issue and accepts the risk of incorrect return values.  Unstoppable responded:  Non issue for real world swap sequences.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "5.2   Debt Is Rounded in Favor of User", "body": "  The  function  _amount_per_debt_share  rounds  the  amount  per  debt  share  down,  causing _amount_to_debt_shares  to  round  up  and  _debt_shares_to_amount  to  round  down.  This rounding benefits the user in several functions:  CS-UNM-011  1. reduce_position rounds up shares_to_burn.  2. _close_position rounds down position_debt_amount.  3. liquidate rounds down position_debt_amount.  4. _effective_leverage rounds down debt_value.  It is considered best practice to never round in favor of the user and always round in favor of the protocol.  Code partially corrected:  The rounding has been adjusted in favor of the protocol where possible. In change_position, during partial liquidations, debt is still rounded in favor of the user.  Unstoppable responded:  The only remaining rounding issue we see is that during partial closes the rounding is \u201cin favour\u201d of the user but at the expense of other debtors (including the remaining debt of that same user). This plus the fact that rounding occurs at an extra 18 decimals leads us to assume this is not an issue in our case. Any attempt to adjust for this lead to serious issues in the internal accounting, \u201cnegative\u201d debt etc.  Unstoppable - Unstoppable Margin Dex -   13  DesignLowVersion1CodePartiallyCorrected          \f5.3   Reading Unused Values From Storage in MarginDex  The  MarginDex  reads  values  that  are  never  used  from  storage  and  writes  values  that  are  unchanged back to storage. This causes unnecessary gas consumption.  CS-UNM-012  1. User IDs:  The  open  trades  and  limit  orders  IDs  of  each  user  are  stored  in  an  array  of  1024  elements.  In _cleanup_trade()  and  _remove_limit_order(),  the  entire  array  is  copied  from  storage  to memory, an element is removed, and then the modified array is written back to storage. By operating on the array in storage instead of copying it to memory, it would be possible to reduce the (average) number of storage reads by half and write to storage only 2 times.  2. Large Order structs:  Trades and limit orders are stored in large structs (>1.6 kb). The full structs are read from storage in the following functions, even if only a few elements are used.  Trade  1. close_trade  2. partial_close_trade  3. update_tp_sl_orders  4. add_margin  5. remove_margin  6. execute_tp_order  7. execute_sl_order  8. cancel_tp_order  9. cancel_sl_order  LimitOrder  1. cancel_limit_order  Only accessing (and writing back) the elements of the struct that are used would significantly reduce the gas cost of these functions.  Code partially corrected:  The code has been changed in some but not all places to improve gas efficiency.  Unstoppable responded:  In some instances we prefer clean & readable code to minimized gas costs, especially since we're on an L2.  Unstoppable - Unstoppable Margin Dex -   14  DesignLowVersion1CodePartiallyCorrected        \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Bad Debt Can Be Faked for Profit    Users With Approvals Can Be Drained    Large Liquidations Can Fail    Position Can Become Impossible to Close Due to Zero Swaps    Stop-Loss Missing Slippage Protection   -Severity Findings   Bad Debt Check Is Ineffective    Swap Margin Uses Incorrect Fairness Check    TP / SL Can Increase Debt Exposure    Amount Returned From SwapRouter Is Not Validated   Inflation Attack on Newly Added Tokens    MarginDex Admin Is More Trusted Than Required    Stop-Loss Can Unintentionally Increase Leverage   -Severity Findings   Reentrancy Into flash_callback    Bad Debt Check Is Inaccurate    Blacklisted Tokens Can Be Swapped Into    Close_position Slippage May Be Too Strict    Multiple IDs for Each Position    Vault Assumes Chainlink Oracles Have 8 Decimals   Informational Findings   Floating Pragma    Event Logs Value With Unclear Interpretation    Vault Uses Incorrect ERC20 Function Interface    SwapRouter Admin Cannot Be Changed   0  5  7  6  4  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.1   Bad Debt Can Be Faked for Profit", "body": "  Unstoppable - Unstoppable Margin Dex -   15  CS-UNM-023  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion2CodeCorrected         \fIn  Vault,  the  change_position  function  checks  that  the  position.margin_amount  is  zero  before realizing bad debt.  if position.position_amount == 0:     # no position left -> full close     if position.debt_shares > 0:         # bad debt case         assert self.is_whitelisted_liquidator[_caller] or self.bad_debt_liquidations_allowed,         \"only whitelisted liquidators allowed to create bad debt\"         assert position.margin_amount == 0, \"use margin to lower bad_debt\"  However, the position.margin_amount is updated later in the function, after this check was made:  if actual_margin_in > 0:     self._safe_transfer_from(position.margin_token, _caller, self, actual_margin_in)     position.margin_amount += actual_margin_in  A  user  could  liquidate  themselves  and  trade  all  of  their  token  value  into  margin_amount.  This  would pass the \"fairness check\", as the trade would clear at a fair price. Then the user could have their debt deleted  and  accounted  for  as  bad  debt,  as  their  position  margin  is  zero  at  the  time  of  the  check. Afterward,  they  will  receive  the  margin_amount  from  the  trade  back.  This  would  allow  them  to  profit from the bad debt.  However,  this  is  only  possible  if  the  bad_debt_liquidations_allowed  flag  is  set  to  true,  or  if  the user is on the liquidator whitelist. If one of these conditions hold, all funds in the contract would be at risk.    The position.margin_amount is now updated before the check for bad debt. This resolves the issue.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.2   Users With Approvals Can Be Drained", "body": "  CS-UNM-027  In the flash_callback functionality of the Vault, any address can be provided as the _caller, which will be used to swap tokens. In particular, any user's EOA can be used as a \"Swapper\". The provided address will receive some tokens, then transferFrom() will be called to transfer the received tokens back to the Vault.  If a user has an open approval to the Vault, for example, because they are about to make a deposit, then all their approved tokens can be taken by any trader, at a price of zero. This passes the fairness check, as it is a very good price for the trader.  If all users always deposit to the system using a multicall that approves tokens and deposits them in a single  transaction,  and  never  give  more  approval  than  required,  then  they  are  safe.  The  default Unstoppable frontend uses such a multicall flow for deposits. However, users typically expect it to be safe to give approval to a contract they trust.  Sophisticated users, that intentionally implement the P2PSwapper interface, must ensure that they never have open approvals between calls.    A  is_whitelisted_caller  whitelist  has  been  added  to  the  MarginDex.  Now,  addresses  need  to opt-in to the whitelist to be allowed as flash_callback targets. This ensures that normal users cannot  Unstoppable - Unstoppable Margin Dex -   16  SecurityHighVersion2CodeCorrected        \fbe  used  as  swappers,  unless  they  call  the  set_is_whitelisted_caller  function  and  intentionally add themselves to the whitelist.  Contracts that add themselves to the whitelist must still ensure that they never have open approvals to the vault between calls, unless they do not hold any tokens.  If  a  new  MarginDex  is  added  to  the  Vault  in  the  future,  it  should  be  ensured  that  it  also  has  a  similar whitelist mechanism.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.3   Large Liquidations Can Fail", "body": "  Positions in Unstoppable Margin Dex can only be fully liquidated, never partially. Additionally, liquidations are  always  done  with  a  Uniswap  swap,  using  a  min_amount_out  based  on  the  oracle  price  and  the liquidate_slippage set by the admin.  CS-UNM-001  If there is a very large position, that causes more than liquidate_slippage of slippage on Arbitrum Uniswap when attempting to close it in a single swap, this swap will revert. As a consequence, it will be impossible  the liquidate_slippage is increased. Delaying a liquidation is a risk to the system and can cause bad debt.  liquidity  on  Uniswap   the  position  unless   improves  or   liquidate   the   to   If functionality was added to partially liquidate a position, the large position could be liquidated in chunks, where each chunk would have a smaller slippage on Uniswap than liquidating the full position at once. This  would  reduce  the  chances  of  a  liquidation  being  impossible  due  to  the  liquidate_slippage being too small. Note that if the oracle price is higher than the Arbitrum Uniswap price, it still might not be possible to execute even partial liquidations.    In  , liquidators can partially liquidate the position amount, but not the margin amount. When the margin amount is sold, the function Vault.change_position() expects a full liquidation and requires repayment of the entire debt and position. If there is a position with a large margin and debt amount but a small position amount (e.g. 1 wei), the full liquidation may cause more slippage than the fairness check allows, and the liquidation reverts.  In  ,  it  is  allowed  to  trade  from  margin  during  a  partial  liquidation.  This  also  allows  partial liquidations of positions that have a large amount of margin and debt left as long as some position is left.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.4   Position Can Become Impossible to Close", "body": " Due to Zero Swaps  The _swap function in the Vault attempts to perform a swap on an external DEX for all values passed (including zero). The only DEX that is currently supported is Uniswap V3. Uniswap V3 reverts when the specified  amount  is  zero:  https://github.com/Uniswap/v3-core/blob/d8b1c635c275d2a9450bd6a78f3fa24 84fef73eb/contracts/UniswapV3Pool.sol#L603  The vault calls _swap() with amount = 0 when a user's position is closed and one of the following cases applies:  1. The user has reduced their position amount to 0 using a partial close  CS-UNM-002  Unstoppable - Unstoppable Margin Dex -   17  DesignHighVersion1CodeCorrectedVersion2Version3CorrectnessHighVersion1CodeCorrected                \f2. The user removed their full margin amount and marginToken is not the debtToken  3. Trader PnL is 0 and marginToken is not the debtToken  In all these cases, close_position() will revert, and it will be impossible to close the position.  An attacker can abuse this behavior, since it stops them from getting liquidated. For example, an attacker who has a sufficiently high PnL could remove all margin from his position, to avoid liquidation. Note that they  can  always  deposit  some  margin  tokens  back,  to  close  their  position.  This  lets  them  take  all  the potential upside of a trade, while avoiding the downside.  Note that the Vault Admin could make the position closeable again by replacing the SwapRouter with a new one that returns immediately in case the swap amount is 0.  Other decentralized exchanges may revert for other values (e.g. Curve's CryptoSwap Newton Algorithm only converges for values in a certain range).  Code Corrected:  The  vault  no  longer  directly  calls  the  _swap()  function  on  the  SwapRouter.  Instead,  it  calls  the P2PSwapper  interface's  flash_callback()  function.  The  flash_callback()  implementation  in MarginDex handles zero amounts without reverting.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.5   Stop-Loss Missing Slippage Protection", "body": "  The execute_sl_order function takes a caller-provided _min_amount_out argument. However, the function  can  be  called  by  anyone.  This  means  the  _min_amount_out  can  be  set  arbitrarily  low, effectively rendering it useless.  An attacker can profit from this by sandwiching the call. The following calls can be executed atomically in a single transaction:  CS-UNM-003  1. Move the Uniswap Arbitrum market by selling the position asset  2. Call execute_sl_order(), selling position tokens with slippage  3. Buy the position tokens on Uniswap at a discount and bring the market price back to the initial value  The  attack  has  no  capital  requirements,  as  it  can  be  executed  using  a  flashloan.  It  is  profitable  if  the trading fees to move the market are lower than the profit from the sandwich.  The maximum amount of slippage that can be incurred is dependent on the type of Stop-Loss order (full or partial close) and the leverage ratio of the position. For full closes, the maximum slippage allowed by the system for liquidations is the limiting factor. For partial closes, this limit is not in place. However, the position may not get into a liquidatable state after partially closing and withdrawing part of the margin.  Consider the following example of a partial close on a pair where the liquidation threshold is 8x leverage and positionToken/debtToken oracle price is 1:  1. A user has a position of size 1000 with debt 1000 and margin 500 (2x leverage)  2. A Stop-Loss with size 500 reaches its trigger price  3. The user's Stop-Loss is executed by someone who sandwiches them to the maximum extent  4. The execution price of the Stop-Loss is 2/3 (33% slippage), leaving the user with position size 500,  debt (1000 - 500*2/3) = 666.66 and margin 500  5. 250 margin is withdrawn, leaving the user at 7.99x leverage, on the edge of liquidation  Unstoppable - Unstoppable Margin Dex -   18  DesignHighVersion1CodeCorrected        \fThe  user  incurred  a  slippage  loss  of  500/3  =  166.66  tokens.  This  amount  will  be  a  profit  to  the sandwicher,  which  will  then  need  to  deduct  the  costs  of  executing  the  sandwich.  Users  that  start  with lower leverage will incur more slippage than those that are already near the leverage limit. If a user has positive PnL at the stop loss trigger price, they will also lose their PnL amount to slippage.  The _min_amount_out for Stop-Loss execution should be lower-bounded by a value provided by the system or the user.    The  maximum  price  Vault.change_position().  impact  of   trades   is  now  always   limited  by   the   fairness  check   in  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.6   Bad Debt Check Is Ineffective", "body": "  In Vault.close_position() only whitelisted liquidators should be allowed to create bad debt as long as bad_debt_liquidations_allowed is set to False. However, the check is ineffective as it is only enforced when a position is fully closed.  if position.position_amount == 0: # no position left -> full close         if position.debt_shares > 0:             # bad debt case             assert self.is_whitelisted_liquidator[_caller] or self.bad_debt_liquidations_allowed,             \"only whitelisted liquidators allowed to create bad debt\"  CS-UNM-028  A liquidator that is not whitelisted can still partially close a position by selling all but 1 wei of the position amount. This creates a position with unrealized bad debt:  positionValue + marginValue < = debt    A check has been added that ensures that the positionValue + marginValue is greater than the debt after a position is changed by a non-whitelisted liquidator. This means that there cannot be any unrealized bad debt in this case, given that the oracle price used to calculate these values is correct.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.7   Swap Margin Uses Incorrect Fairness Check", "body": "  Function Vault.swap_margin() defines a fairness check to ensure that the user sets an appropriate minimum amount they should receive from the swap (\"amount1\"). However, the implemented check does not enforce a lower bound on the amount received but instead ensures that the amount returned is lower than the amount expected by the user.  assert (self._quote(_token0, _token1, _amount0) * (PERCENTAGE_BASE + self.reasonable_price_impact[_token0]) / PERCENTAGE_BASE) >= _amount1, \"unfair margin swap\"  CS-UNM-029  The code later asserts that the realized amount is greater than the amount1, allowing the user to get a better price than the oracle price:  Unstoppable - Unstoppable Margin Dex -   19  DesignMediumVersion2CodeCorrectedCorrectnessMediumVersion2CodeCorrected                \fassert actual_amount1 >= amount1, \"[MS:cb] too little out\"  However, there is no guarantee that the user will receive at least the oracle price minus some slippage, as intended.  inAmount > = outAmount * (1 + slippage)  As  MarginDex  limits  access  to  this  function  to  the  user  themselves  and  their  delegatee,  (who  is  fully trusted) the impact is limited.    The fairness check has been corrected to ensure that the user receives at least the oracle price minus some slippage.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.8   TP / SL Can Increase Debt Exposure", "body": "    of  the  MarginDex  contract,  the  execute_tp_order  and  execute_sl_order  functions In  allow the caller to set arbitrary values for _debt_change, _margin_change, and _realized_pnl. A malicious actor could choose _debt_change < 0 and _realized_pnl > 0 to create additional debt and offset the debt by moving more margin to the position. This is permissible as long as the final position meets the leverage criteria and the trade is fair.  For instance, consider a trader with an initial position of:  CS-UNM-030   position_amount = 100   margin_amount = 10   debt_amount = 100  leverage = 10  trader margin balance = 5  A malicious executor could execute a take-profit (or stop-loss) order with the following parameters:   reduce_by_amount = position_change = -50   debt_change = -50   margin_change = +100   realized_pnl = +5  The trade can be executed since the fairness condition is fulfilled:  positionChange + debtChange = marginChange  After the trade, the trader has a modified position that has the same leverage as before, but higher debt:   position_amount = 50   margin_amount = 115   debt_amount = 150  leverage = 10  trader margin balance = 0  Unstoppable - Unstoppable Margin Dex -   20  DesignMediumVersion2CodeCorrectedVersion2            \fThe  attacker  profits  from  executing  the  orders,  as  higher  trading  volume  increases  the  extractable slippage.  Further,  users  with  standing  TP/SL  orders  can  be  griefed  by  executing  their  orders  with  a  negative realized_pnl to consume all of their available margin. This stops them from opening a new position, as they are unable to pay the trading fee.    The following checks have been added to the execute_tp_order and execute_sl_order functions:  assert _debt_change >= 0, \"no new debt during tp/sl\" assert _realized_pnl <= 0, \"cannot add more margin during tp/sl\"  For TP/SL orders that do not fully close a position, additional checks are made:  assert not is_full_close, \"was supposed to be full close\"  assert Vault(self.vault).positions(_trade_uid).margin_amount <= position.margin_amount, \"cannot increase margin on partial tp\"  This ensures that no unexpected changes to the position can be made.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.9   Amount Returned From SwapRouter Is Not", "body": " Validated  According to the trust model of the system, the SwapRouter is not fully trusted. As such, the Vault verifies that  it  has  received  the  expected  quantity  of  tokens  from  the  swap  by  comparing  the  token  balance before and after the swap.  CS-UNM-004  token_out_balance_before: uint256 = ERC20(_token_out).balanceOf(self)  amount_out_received: uint256 = SwapRouter(self.swap_router).swap(     _token_in, _token_out, _amount_in, _min_amount_out )  token_out_balance_after: uint256 = ERC20(_token_out).balanceOf(self) assert (     token_out_balance_after >= token_out_balance_before + _min_amount_out )  However,  the  vault  only  verifies  that  the  token  balance  has  increased  by  at  least  min_amount_out, without confirming it has increased by amount_out_received.  The received amount is used to calculate the Trader's profit. If the SwapRouter returns a value that is too large, this extra amount will be credited to the trader, which can then be withdrawn. In the worst case, this could drain all funds in the vault and make it insolvent.    Unstoppable - Unstoppable Margin Dex -   21  CorrectnessMediumVersion1CodeCorrected        \fThe Vault no longer directly calls the SwapRouter. Instead, it calls an untrusted P2PSwapper contract. The  value  returned  by  the  P2PSwapper  is  checked  to  be  at  least  as  large  as  expected.  Afterward,  a safe_transfer_from call is used to transfer this amount of tokens from the P2PSwapper to the Vault. If the P2PSwapper does not have a sufficient balance, the transfer will revert. As a result, an incorrect return value can no longer cause issues.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.10   Inflation Attack on Newly Added Tokens", "body": "  CS-UNM-005  Shared Vaults such as the Unstoppable Vault have a known issue called an \"inflation attack\", where an attacker  increases  the  price  per  share  of  vault  shares  by  a  lot,  such  that  a  small  rounding  error  in  the number of shares other users receive results in a large percentage of the deposit being lost to rounding. This is generally only possible if the attacker is the first depositor to an empty vault.  The Unstoppable Vault mitigates this attack in 2 key ways:  1. It does not count any tokens sent directly to the vault as belonging to LPs, so it is hard to \"donate\"  to the LP.  2. When minting initial shares, 10E18 shares are minted per wei of token deposited. This makes the total number of shares large, even if only 1 wei is deposited. Additionally, withdrawal amounts can only be specified in underlying tokens, not shares.  However, both of these mitigations can be circumvented:  1. Tokens cannot be donated to the LPs directly, but interest from borrowing can accrue and be paid to LPs. In particular, interest from funds lent by one module, such as the base_lp, can be paid to the  other  module,  such  as  the  safety_module_lp  (or  the  other  way  around),  even  if  the safety_module_lp  has  no  shares  or  few  shares.  This  allows  donating  a  lot  of  interest  (by depositing a lot of base_lp and borrowing it all) while keeping the number of safety_module_lp shares small.  2. Once  the  price  per  share  has  been  increased  by  at  least  1E18,  it  will  be  possible  to  withdraw  a  partial amount of the initially minted shares and only leave 1 share left.  Combining these factors, the following attack can be executed on any token that is newly added to the system and has no LPs in one of the modules (here illustrated with the safety_module_lp) yet:  1. Deposit a large amount to the base_lp  2. Borrow 100% of available liquidity from yourself.  3. Deposit 1 wei of token to safety_module_lp. Receive 1E18-1 shares.  4. Partially close an amount of the borrow position such that exactly 1E18-2 tokens are paid as fees to the safety_module_lp. Now the price per share is 1 (initially it was 1/(1E18-1)). This allows us to withdraw a precise number of shares.  5. Withdraw  1E18-2  tokens  from  the  safety_module_lp.  Now  there  is  1  wei  token  and  1  wei  shares left.  6. Wait for a significant amount of interest to accrue. Close the borrow position. If X interest accrued to  the safety_module_lp, the price per share of safety_module_lp will now be X+1.  7. Wait for another user to deposit to the safety_module_lp. When they do, the shares minted will be rounded up, then reduced by 1. This means they will receive up to 1 share less than if there was no  rounding.  Since  1  share  is  worth  X+1  wei  tokens,  up  to  X+1  wei  tokens  will  be  accounted  as belonging to the existing LPs (the attacker) instead of the depositing user.  Note that all future users will suffer from up to X+1 rounding, not just the first one:  Unstoppable - Unstoppable Margin Dex -   22  SecurityMediumVersion1CodeCorrected        \fIn step 6., the attacker pays interest of 1000E18 USDC to the safety_module_lp   As there is only one share, the price per share is now 1000E18 + 1.   A second user deposits 2000E18 USDC in step 7. The rounded-up number of shares they should receive is 2. This number is reduced by 1 to account for rounding. The user only receives 1 share and the price per share now increases to 1500E18. The attacker made a profit of 500E18 USDC, which came from the second user.   A  third  user  deposits  1500E18  USDC.  Their  rounded-up  shares  are  1,  which  is  reduced  by  1,  so they receive 0 shares. The price per share increases to 2250E18. The attacker and the second user both make 750E18 USDC profit, which came from the third user.  The maximum amount that can be donated in step 6. is limited by the following factors: The amount the attacker  deposits,  the safety_module_lp, and the time deposited. The time deposited is likely the largest limiting factor, as the attacker only has time until the first user deposits, after which the attacker will no longer own all the shares in the pool.  the  percentage  of   the  maximum   interest  rate,   that  goes   interest   to   In summary, the mitigations in place for inflation attacks are insufficient, and, given enough capital and time, an attacker can create a pool where all future users lose 100% of their deposit.    The  inflation  attack  was  mitigated  by  adding  a  virtual  offset  to  the  _amount_to_lp_shares  and _lp_shares_to_amount functions.  For details on this approach, see: ERC4626 - defending with a virtual offset.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.11   MarginDex Admin Is More Trusted Than", "body": " Required  CS-UNM-006  The  MarginDex  admin  is  a  partially  trusted  role.  It  should  be  able  to  set  the  MarginDex  instance's is_accepting_new_orders  flag,  which  pauses  new  orders  but  still  allows  existing  positions  to  be closed.  However,  the  admin  can  also  set  the  vault  variable,  which  points  to  the  Vault  on  which  orders  are executed. If the admin sets this variable to a different address, it will be impossible to interact with the Vault,  unless  another  MarginDex  contract  is  added  by  the  Vault  admin.  This  would  cause  a  Denial  of Service, making it impossible to adjust positions or liquidate them.  The  vault  variable  doesn't  need  to  be  updatable,  so  trusting  the  MarginDex  admin  not  to  maliciously unset the Vault is an unnecessary risk.    The  MarginDex  admin  can  no  longer  set  the  vault  variable.  The  vault  variable  is  now  set  in  the constructor and cannot be changed.  Unstoppable - Unstoppable Margin Dex -   23  TrustMediumVersion1CodeCorrected           \f6.12   Stop-Loss Can Unintentionally Increase Leverage  CS-UNM-007  In MarginDex, users can specify a Stop-Loss order that reduces their position at a certain price. If it is a partial close, some of the user's margin will also be withdrawn when the order is triggered.  This is done as follows:  amount_out_received = self._partial_close(trade, sl_order.reduce_by_amount, _min_amount_out) ratio: uint256 = sl_order.reduce_by_amount * PRECISION / position.position_amount remove_margin_amount: uint256 = position.margin_amount * ratio / PRECISION Vault(self.vault).remove_margin(trade.vault_position_uid, remove_margin_amount)  The amount removed from margin is the percentage of margin that corresponds to the percentage of the position that was partially closed. E.g. if the position was reduced by 10%, the margin is also reduced by 10%. This is intended to keep the leverage of the position unchanged.  However,  the  ratio  calculated  here  assumes  that  the  partial  close  reduces  the  debt  by  the  same percentage that the position is reduced. This is only the case if the trade executes exactly at the oracle price which is used to calculate the leverage.  This may not happen for multiple reasons:  1. The oracle price may not reflect the current price  2. There may be trading fees  3. There may be slippage  If  the  execution  price  is  below  the  oracle  price,  the  debt  of  the  position  will  be  reduced  by  less  than ratio. Withdrawing ratio of the margin will thus unintentionally increase the leverage of the position. In  the  extreme  case  where  the  position  already  has  high  leverage,  this  may  cause  the  leverage  to increase above the maximum acceptable leverage. The transaction will revert and it will be impossible to execute  the  partial-close  Stop-Loss,  even  though  it  would  have  been  possible  if  less  margin  was withdrawn.  The same issue also affects Take-Profit orders.  Specification changed:  The  specification  has  been  updated  to  allow  changes  in  leverage  up  to  the  bounds  set  by  the leverage_buffer parameter. This ensures that the leverage does not increase too much:  if Vault(self.vault).positions(_trade_uid).position_amount > 0:     # partial close     leverage_after: uint256 = self._effective_leverage(_trade_uid, 2)     assert (leverage_after >= leverage_before - min(leverage_before,     self.leverage_buffer)) and (leverage_after <= leverage_before + self.leverage_buffer),     invalid sl execution\"  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.13   Reentrancy Into flash_callback", "body": "  CS-UNM-032  Unstoppable - Unstoppable Margin Dex -   24  DesignMediumVersion1Speci\ufb01cationChangedDesignLowVersion2CodeCorrected              \fThe  function  flash_callback  in  the  MarginDex  contract  is  assumed  to  be  called  only  by  the  Vault contract.  However,  there  is  no  restriction  on  calling  it  from  another  contract,  and  no  protection  against the reentrancy.  A  malicious  decentralized  exchange  or  flash_callback  function.  As  the  margin  dex  holds  funds  for  the  duration  of  the  trade,  a  part  of  the funds could be stolen in this situation.  tokens  with  callbacks  could  reenter   The maximum value that can be extracted is capped, as the amount of tokens returned must still fulfill the fairness criteria enforced by the Vault contract.    A reentrancy lock was added to the flash_callback function. It is a separate lock from the one used in other functions of MarginDex.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.14   Bad Debt Check Is Inaccurate", "body": "  CS-UNM-008  In close_position(), there is a check that should ensure a user cannot close a position that would result in bad debt:  margin_value: uint256 = self._quote_token_to_token([...]) assert min_amount_out + margin_value >= self._debt(_position_uid), \"min_amount_out cannot result in bad debt\"  This check is inaccurate, as the margin_value is calculated using the oracle price. The actual price that swapping the margin token to debt token would execute at may be lower due to slippage. For the position token, this is taken into account by using the min_amount_out.  As a result, it may be possible for the user to close a position that results in bad debt.    The close_position function was removed and replaced with the more generic change_position function, which checks a position's health based on the remaining tokens after the swap has taken place. While the oracle price is still used for the remaining tokens, the realized price of the swap is token into account for the swapped tokens.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.15   Blacklisted Tokens Can Be Swapped Into", "body": "  The  Vault  prevents  the  user  from  funding  their  account  with  assets  that  are  not  on  the  whitelist. However,  they  can  call  the  swap_margin  function  to  swap  into  tokens  that  were  removed  from  the whitelist,  given  that  they  still  have  a  route  configured  in  the  SwapRouter.  They  can  then  use  the blacklisted token to top-up an existing margin position via add_margin.  CS-UNM-009    The swap_margin function now enforces a whitelist on the token being swapped into.  Unstoppable - Unstoppable Margin Dex -   25  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.16   Close_position Slippage May Be Too Strict  In Vault, close_position() enforces that the min_amount_out given by the user is at least as large as the system_min_out.  CS-UNM-010  assert min_amount_out >= system_min_out, \"too little min_amount_out\"  This  condition  is  stricter  than  necessary.  As  there  is  a  check  later  that  the  min_amount_out  chosen cannot cause bad debt, a user should be allowed to specify a min_amount_out that is smaller than the one set by the system. A large value set by the system can cause the close to revert. This would be most likely to be a problem when the oracle price is higher than the Arbitrum Uniswap price.    The close_position function was removed and replaced with the more generic change_position function.  Trades  are  now  protected  from  too  much  slippage  by  a  single  \"fairness  check\"  in change_position.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.17   Multiple IDs for Each Position", "body": "  The MarginDex stores two IDs for each position, a position_uid and a vault_position_uid. In the contracts in scope, both IDs are always the same.  CS-UNM-037    The secondary ID was removed, and a single position_uid is now used everywhere.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.18   Vault Assumes Chainlink Oracles Have 8", "body": " Decimals  In  Vault._to_usd_oracle_price,  it  is  assumed  that  Chainlink  USD  price  feeds  have  8  decimals.  This condition is not validated when a new asset and its price feed are whitelisted, so it is possible to add a price feed with a differing number of decimals.  CS-UNM-013  like  Note  https://etherscan.io/address/0xe20CA8D7546932360e37E9D72c1a47334af57706#readContract  AMPL   feeds   some   have   price   USD   that   18   /   decimals  Specification Changed:  Unstoppable clarified that they plan on only utilizing price feeds from the \"verified\" tier with 8 decimals of precision.  Unstoppable - Unstoppable Margin Dex -   26  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                      \f6.19   Event Logs Value With Unclear Interpretation  The  MarginDex  emits  the  LimitOrderPosted  event  for  each  limit  order  placed.  The  event  has  the  field amount_in, which is defined as the sum of margin_amount and debt_amount.  The  value  has  an  unclear  interpretation  when  the  margin  token  is  not  equal  to  the  debt  token,  as balances of two different tokens are summed together.  CS-UNM-017    The event was removed.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.20   Floating Pragma", "body": "  Unstoppable uses a floating pragma vyper ^0.3.10. Contracts should be deployed with the same compiler version and flags that have been used during testing and audit. Locking the pragma helps to ensure this.  CS-UNM-018    Unstoppable has fixed the pragma to vyper version 0.3.10.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.21   SwapRouter Admin Cannot Be Changed", "body": "  The  SwapRouter  admin  role  is  set  once  and  cannot  be  transferred  to  another  address.  The  other contracts contain functionality to change the admin.    The suggest_admin and accept_admin functions have been added to the SwapRouter contract.  CS-UNM-021  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "6.22   Vault Uses Incorrect ERC20 Function", "body": " Interface  The Vault defines the incorrect interface for the ERC20 token. The approve function should return true on success.  Note  that  changing  this  may  break  compatability  with  tokens  that  incorrectly  implement  the  ERC20 standard, such as USDT on Ethereum mainnet.  CS-UNM-025  Unstoppable - Unstoppable Margin Dex -   27  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                        \f  The approve function has been removed from the interface defined in Vault.  Unstoppable - Unstoppable Margin Dex -   28  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.1   Arbitrum Sequencer Could Affect", "body": " Block.Timestamp  The protocol makes use of block.timestamp. On Arbitrum, a malicious sequencer is able to change the block timestamps information to 24 hours earlier then the actual time or 1 hour in the future. See also:  https://docs.arbitrum.io/for-devs/concepts/differences-between-arbitrum-ethereum/block-numbers-and-ti me#block-timestamps-arbitrum-vs-ethereum  If  the  timestamp  value  is  set  to  a  previous  time,  the  Vault  can  accept  stale  Chainlink  prices,  and MarginDex can execute limit orders that have already expired.  CS-UNM-014  Acknowledged:  Unstoppable is aware of this behavior but accepts the risk due to lack of alternative solutions.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.2   Arbitrum-Specific Code", "body": "  Unstoppable  is  targeting  an  initial  launch  to  Arbitrum,  with  plans  to  extend  to  additional  networks. However, certain parts of the code work exclusively on Arbitrum:  1. The  withdrawTo  function,  exclusive  to  Arbitrum's  extended  WETH,  isn't  compatible  with  other  WETH implementations (e.g., Optimism, Mainnet).  2. The addresses for WETH, ARBITRUM_SEQUENCER_UPTIME_FEED, and UNISWAP_ROUTER  are hard-coded to Arbitrum's deployment.  CS-UNM-015  Acknowledged:  Unstoppable responded:  Part of the deployment checklist.  Unstoppable - Unstoppable Margin Dex -   29  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged            \f7.3   Avoiding Liquidation Penalty in Self-Liquidation  In  , a user's position can be liquidated by anyone if it becomes undercollateralized. The user is then  required  to  pay  a  liquidation  penalty  based  on  the  remaining  position  margin  after  liquidation. However, if no margin tokens are left, the liquidation penalty becomes zero:  CS-UNM-033  # full liquidation, penalty from margin if position.margin_token != position.debt_token:     penalty = self._quote(position.debt_token, position.margin_token, penalty) penalty = min(penalty, position.margin_amount)  If a trade returns more debt tokens than required to cover the debt, the excess tokens are credited to the user before any penalty is applied. This means that in a self-liquidation scenario, the user can avoid the liquidation penalty by moving the proceeds from the liquidation into the debt token. Note that the trade must  still  fulfill  the  fairness  criteria  and  the  check  caps  the  debt  change  to  the  minimum  position  debt amount:  amount_in[0] = min(position_debt_amount, convert(_debt_change, uint256))  Acknowledged:  Unstoppable responded:  Very unlikely that a user is willing and capable to outperform MEV liquidators, but he doesn\u2019t simply close his position before it becomes liquidatable and a penalty is even in question. Doesn\u2019t justify the added complexity to cover this case in code.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.4   Blacklisted Tokens Can Be Credited", "body": "  Users are prevented from funding their accounts with assets that are not whitelisted in fund_account and fund_account_eth. But, similar to Blacklisted Tokens Can Be Swapped Into, a user can fund their account  through  other  means:  If  a  user  has  a  debt  position  in  a  token  that  was  removed  from  the whitelist, they can close their position by choosing a route that generates more debt tokens than required to cover their debt. The excess tokens are then credited to the user's margin and can be used to top up existing positions by calling the change_position function with realized_pnl set to a negative value.  CS-UNM-034  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.5   Cannot Mint or Redeem Shares When Price Is", "body": " 0  CS-UNM-016  Unstoppable - Unstoppable Margin Dex -   30  InformationalVersion2AcknowledgedVersion2InformationalVersion2InformationalVersion1Acknowledged              \fThe  price  of  an  LP  share  can  fall  to  zero  when  bad  debt  is  generated.  When  liquidity  is  provided  or removed, the contract divides by the share price and the transaction reverts.  Acknowledged:  Unstoppable answered:  Bad debt would have to be repaid first.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.6   Liquidity Provider Can Withdraw Small", "body": " Amount of Lent Out Assets  According to code comments, Liquidity Providers should not withdraw liquidity that is currently lent out.  The code enforces this by comparing the proposed amount with total liquidity - debt.  However, the contract does not update the debt before making this comparison, so LPs can withdraw a small amount of outstanding interest.  CS-UNM-019  Acknowledged:  Unstoppable responded:  Interest accrued is not the same as lent out liquidity. An LP can withdraw before ``update_debt`` is called, but in exchange \u201cdonates\u201d his interest to the remaining LPs in this case.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.7   No Address 0 Checks", "body": "  The following setter functions do not do a sanity check that the address passed is not zero:  CS-UNM-020  1. Vault.set_is_whitelisted_dex: _dex  2. Vault.set_configuration: swap_router  3. MarginDex.set_vault: _vault  Code partially corrected:  function  Vault.set_configuration  no   The  MarginDex.set_vault  the  Vault.set_is_whitelisted_dex still does not check for address 0.  longer  sets  from   removed   been   has   the  swap   router.  The   codebase.   The   function function  Unstoppable responded:  Due to code size limitations we had to remove low value checks.  Unstoppable - Unstoppable Margin Dex -   31  InformationalVersion1AcknowledgedInformationalVersion1CodePartiallyCorrected            \f7.8   No Grace Period for Sequencer Uptime Feed  The  Vault  retrieves  the  status  code  of  the  Arbitrum  Sequencer  from  a  Chainlink  oracle.  When  the sequencer is down, the Vault does not accept the prices provided by Chainlink and reverts.  The Chainlink documentation recommends to wait an additional grace period after the sequencer is back up to give users time to improve their leverage.  https://docs.chain.link/data-feeds/l2-sequencer-feeds#example-code  Waiting  for  the  grace  period  increases  the  risk  of  price  jumps,  but  could  reduce  the  risk  of  mass liquidations.  CS-UNM-036  Acknowledged:  Unstoppable responded:  The recommendation makes sense for overcollateralized use-cases, in the undercollateralized environment we are working in, we want to react as quickly as possible instead of waiting for users who may or may not react manually.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.9   SwapRouter's Exact Output Swap Does Not", "body": " Handle Non-Standard Tokens  CS-UNM-035  In SwapRouter.swap_exact_out(), the contract grants approval to the Uniswap Router to spend the maximum  amount  of  tokens.  However,  the  router  only  withdraws  the  necessary  tokens  for  the  swap, leaving some approval remaining.  This can be problematic with certain non-standard ERC20 tokens (e.g., USDT on Ethereum) that require the  approval  to  be  reset  to  0  before  a  new  approval  can  be  set.  As  a  result,  the  router  could  become locked after the first swap not consuming the full approval. While resetting the approval to 0 post-swap could resolve this, it would render the router contract incompatible with other ERC20 tokens like BNB (on Ethereum) that explicitly prohibit setting the approval to 0.  To  accommodate  these  non-standard  tokens,  a  safe_approve  wrapper  function  could  be  used  (see: Transfer in SwapRouter does not handle non-standard tokens).  For  https://github.com/d-xo/weird-erc20?tab=readme-ov-file#approval-race-protections  context,   more   refer   the   to   following   link:  Note that we are currently not aware of any such tokens on Arbitrum, although they may exist.  Acknowledged:  Unstoppable responded:  Unstoppable - Unstoppable Margin Dex -   32  InformationalVersion1AcknowledgedInformationalVersion2Acknowledged            \fMarginDEX functionality will be limited for the foreseeable future to a handful of the main tokens, no plans to add or support exotic/non-standard tokens.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}, {"title": "7.10   Transfer in SwapRouter Does Not Handle", "body": " Non-Standard Tokens  The SwapRouter uses the transfer function to transfer tokens.  It  is  considered  best  practice  to  use  safe_transfer_from  for  transfers,  to  check  the  return  value  and handle non-standard ERC20 tokens, such as those that do not return a boolean value on success (such as USDT and BNB on Ethereum mainnet).  https://github.com/d-xo/weird-erc20?tab=readme-ov-file#missing-return-values  CS-UNM-022  Acknowledged:  Unstoppable is aware of this behavior and notes that they have no plans to use non-standard tokens.  ", "labels": ["ChainSecurity"], "html_url": "TODO"}]