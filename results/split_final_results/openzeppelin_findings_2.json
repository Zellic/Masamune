[{"title": "Consider monitoring for any upgrades to the KelpDAO contracts (for rsETH). If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the rsETH contract logic. Additionally, identify all changes to logic pertaining to values like rsEthPrice (from the RSETH_LRT_ORACLE) which Ion also depends on.", "body": "Consider monitoring for any upgrades to the KelpDAO contracts (for rsETH). If an upgrade is detected, scan all execution flows which Ion depends on for any changes in the rsETH contract logic. Additionally, identify all changes to logic pertaining to values like rsEthPrice (from the RSETH_LRT_ORACLE) which Ion also depends on.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#consider-monitoring-for-any-upgrades-to-the-kelpdao-contracts-(for-rseth).-if-an-upgrade-is-detected,-scan-all-execution-flows-which-ion-depends-on-for-any-changes-in-the-rseth-contract-logic.-additionally,-identify-all-changes-to-logic-pertaining-to-values-like-rsethprice-(from-the-rseth_lrt_oracle)-which-ion-also-depends-on.", "labels": ["OpenZeppelin"]}, {"title": "Establish a plan to pause the Ion protocol or change specific parameters, such as the spot address for a given collateral, in the event of an upgrade to any collateral contracts.", "body": "Establish a plan to pause the Ion protocol or change specific parameters, such as the spot address for a given collateral, in the event of an upgrade to any collateral contracts.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#establish-a-plan-to-pause-the-ion-protocol-or-change-specific-parameters,-such-as-the-spot-address-for-a-given-collateral,-in-the-event-of-an-upgrade-to-any-collateral-contracts.", "labels": ["OpenZeppelin"]}, {"title": "Monitor for upgrades to any tokens which are utilized in the Seaport leveraging or deleveraging contracts.", "body": "Monitor for upgrades to any tokens which are utilized in the Seaport leveraging or deleveraging contracts.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#monitor-for-upgrades-to-any-tokens-which-are-utilized-in-the-seaport-leveraging-or-deleveraging-contracts.", "labels": ["OpenZeppelin"]}, {"title": "Monitor for changes to ezETH's TVL and total supply, and identify maximal reasonable error for a predefined max deposit size. Consider the value of this error as compared to current gas prices on Ethereum mainnet to determine whether logic within the EzEthHandler should be updated.", "body": "Monitor for changes to ezETH's TVL and total supply, and identify maximal reasonable error for a predefined max deposit size. Consider the value of this error as compared to current gas prices on Ethereum mainnet to determine whether logic within the EzEthHandler should be updated.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#monitor-for-changes-to-ezeth's-tvl-and-total-supply,-and-identify-maximal-reasonable-error-for-a-predefined-max-deposit-size.-consider-the-value-of-this-error-as-compared-to-current-gas-prices-on-ethereum-mainnet-to-determine-whether-logic-within-the-ezethhandler-should-be-updated.", "labels": ["OpenZeppelin"]}, {"title": "Monitor for significant drops in the TVL of ezETH or rsETH, to identify smart contract bugs within collaterals quickly. Create a plan for pausing either the Ion protocol or modifying parameters for specific markets.", "body": "Monitor for significant drops in the TVL of ezETH or rsETH, to identify smart contract bugs within collaterals quickly. Create a plan for pausing either the Ion protocol or modifying parameters for specific markets.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#monitor-for-significant-drops-in-the-tvl-of-ezeth-or-rseth,-to-identify-smart-contract-bugs-within-collaterals-quickly.-create-a-plan-for-pausing-either-the-ion-protocol-or-modifying-parameters-for-specific-markets.", "labels": ["OpenZeppelin"]}, {"title": "Monitor collateral prices using various sources such as Uniswap, Curve, and Coingecko to identify price disparities for collateral assets. These may signal smart contract bugs or \"black swan\" market conditions. Establish plans for pausing or modifying market parameters based on certain thresholds being reached. For example, \"pause all markets if the price for a collateral asset on Uniswap diverges from the price on Curve by more than 10% for more than 100 blocks\".", "body": "Monitor collateral prices using various sources such as Uniswap, Curve, and Coingecko to identify price disparities for collateral assets. These may signal smart contract bugs or \"black swan\" market conditions. Establish plans for pausing or modifying market parameters based on certain thresholds being reached. For example, \"pause all markets if the price for a collateral asset on Uniswap diverges from the price on Curve by more than 10% for more than 100 blocks\".", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#monitor-collateral-prices-using-various-sources-such-as-uniswap,-curve,-and-coingecko-to-identify-price-disparities-for-collateral-assets.-these-may-signal-smart-contract-bugs-or-\"black-swan\"-market-conditions.-establish-plans-for-pausing-or-modifying-market-parameters-based-on-certain-thresholds-being-reached.-for-example,-\"pause-all-markets-if-the-price-for-a-collateral-asset-on-uniswap-diverges-from-the-price-on-curve-by-more-than-10%-for-more-than-100-blocks\".", "labels": ["OpenZeppelin"]}, {"title": "Monitor all transactions utilizing the Seaport leveraging contracts, specifically checking for token transfer events. Seaport is a complicated system, so special attention should be payed to it. Ensure that tokens are moving as intended. Consider removing the \"SeaportLeverage\" contract from the protocol whitelist if unexpected behavior is detected, to prevent losses for users.", "body": "Monitor all transactions utilizing the Seaport leveraging contracts, specifically checking for token transfer events. Seaport is a complicated system, so special attention should be payed to it. Ensure that tokens are moving as intended. Consider removing the \"SeaportLeverage\" contract from the protocol whitelist if unexpected behavior is detected, to prevent losses for users.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#monitor-all-transactions-utilizing-the-seaport-leveraging-contracts,-specifically-checking-for-token-transfer-events.-seaport-is-a-complicated-system,-so-special-attention-should-be-payed-to-it.-ensure-that-tokens-are-moving-as-intended.-consider-removing-the-\"seaportleverage\"-contract-from-the-protocol-whitelist-if-unexpected-behavior-is-detected,-to-prevent-losses-for-users.", "labels": ["OpenZeppelin"]}, {"title": "Additionally, before performing certain actions, we encourage Ion to validate the following:", "body": "Additionally, before performing certain actions, we encourage Ion to validate the following:", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#additionally,-before-performing-certain-actions,-we-encourage-ion-to-validate-the-following:", "labels": ["OpenZeppelin"]}, {"title": "Before integrating new tokens to the Seaport leveraging contracts, generally ensure that these tokens do not make calls to external contracts, as these could interfere with correct operation of the Seaport leveraging contracts. Pay special attention to \"before transfer\" and \"after transfer\" hooks on tokens.", "body": "Before integrating new tokens to the Seaport leveraging contracts, generally ensure that these tokens do not make calls to external contracts, as these could interfere with correct operation of the Seaport leveraging contracts. Pay special attention to \"before transfer\" and \"after transfer\" hooks on tokens.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#before-integrating-new-tokens-to-the-seaport-leveraging-contracts,-generally-ensure-that-these-tokens-do-not-make-calls-to-external-contracts,-as-these-could-interfere-with-correct-operation-of-the-seaport-leveraging-contracts.-pay-special-attention-to-\"before-transfer\"-and-\"after-transfer\"-hooks-on-tokens.", "labels": ["OpenZeppelin"]}, {"title": "Special considerations for ezETH", "body": "The Ion team specifically requested a review of the math used for ezETH integration within the Ion protocol. The audit team has relayed their findings regarding this asset to Ion outside of this audit report. In summary, the findings were that the minting of ezETH cannot necessarily result in any arbitrary amount specified.  Generally, minting behavior of ezETH is determined by the intermediate value, inflationPercentage, which is used for computing the TVL growth of a deposit into ezETH and the subsequent growth of the supply of ezETH. Since inflationPercentage has a maximal value of 1e18 - 1, there are thus that many different values for the amount of ezETH which can be minted. There are possibly many more potential values for the amount of ETH which can be deposited, and thus the inflationPercentage is the limiting factor in potential values of ezETH minted.  We encourage the Ion team to assess the tradeoff between increased gas costs and potential savings to users when deciding to make computations more accurate. Consider the typical values of deposits into the Ion protocol and utilize these to compute potential error as a general range of values. In addition, extensively document the error considerations to reassure users who may be concerned about inaccuracy in the computations.  High Severity  Full Deleverage Functionality Can Be Permanently Bricked  In the seaportCallback4878572495 function within the SeaportDeleverage contract, there is a requirement that the BASE token balance of the contract is 0 after a full deleverage.  However, this will always revert if a user has independently transferred any amount of BASE tokens into the SeaportDeleverage contract. Since there is no way to transfer the tokens out of the contract, a single transfer will permanently brick the contract.  Consider removing this check, or modifying it to instead check that the token balance of the contract has not changed since the beginning of the execution flow. Alternatively, consider either modifying the logic to transfer all unneeded BASE tokens to the user, or implementing a \"rescue\" function to remove stranded BASE tokens.  Update: Resolved in pull request #3. The sanity check was removed to prevent bricking of the contract.  Low Severity  Incomplete Docstrings  Throughout the codebase there are several parts that have incomplete docstrings. For instance:  The getPrice function in EzEthWstEthSpotOracle.sol the return value is partially documented  The flashswapAndMint function in UniswapFlashswapDirectMintHandlerWithDust.sol the deadline parameter is not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #76.  Floating Pragma  Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled.  codebase there are multiple floating pragma directives. For instance, the files  IGemJoin.sol,  IIonPool.sol,  IUFDMHandler.sol,  IWhitelist.sol have the  solidity ^0.8.4 floating pragma directive.  Consider using a fixed pragma version.  Update: Acknowledged, not resolved. The Ion Protocol team stated:  The floating pragma was kept in order to allow other projects using a different Solidity version to use this repo as a submodule.  Inconsistent Use of ILK_INDEX in Seaport Leveraging Contracts  The SeaportDeleverage contract uses an immutable ILK_INDEX which is set in the constructor of the inherited SeaportBase contract.  assumes an index of 0 in many places in both the  SeaportLeverage.sol uses ILK_INDEX. This inclusion of the  Consider using a consistent Ilk Index across the \"Leverage\" and \"Deleverage\" contracts.  Update: Resolved in pull request #4. The SeaportDeleverage contract was modified to use a hardcoded ILK_INDEX of 0.  Notes & Additional Information  Incremental Update Could be Wrapped in an Unchecked Block  Since Solidity version 0.8.0, any arithmetic operation automatically checks for over- and underflows, which cost gas. Since it is highly unlikely that a positively incrementing variable will overflow within a loop, the increment could be wrapped into an unchecked block.  This applies to the following instances:  On line 157 of RenzoLibrary.sol  On line 249 of RenzoLibrary.sol  To improve gas consumption, consider wrapping the incremental update into an unchecked block to save the gas required to check against overflows.  Update: Resolved in pull request #74. The incremented update was removed in an unrelated refactoring.  Unused Errors  Throughout the codebase, there are unused errors. For instance:  The ZoneHashMustBeZero error in SeaportBase.sol.  The InvalidAmountIn error in RenzoLibrary.sol.  To improve the overall clarity, intentionality, and readability of the codebase, consider either using or removing any currently unused errors.  ", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#special-considerations-for-ezeth", "labels": ["OpenZeppelin"]}, {"title": "The Ion team specifically requested a review of the math used for ezETH integration within the Ion protocol. The audit team has relayed their findings regarding this asset to Ion outside of this audit report. In summary, the findings were that the minting of ezETH cannot necessarily result in any arbitrary amount specified.", "body": "The Ion team specifically requested a review of the math used for ezETH integration within the Ion protocol. The audit team has relayed their findings regarding this asset to Ion outside of this audit report. In summary, the findings were that the minting of ezETH cannot necessarily result in any arbitrary amount specified.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#the-ion-team-specifically-requested-a-review-of-the-math-used-for-ezeth-integration-within-the-ion-protocol.-the-audit-team-has-relayed-their-findings-regarding-this-asset-to-ion-outside-of-this-audit-report.-in-summary,-the-findings-were-that-the-minting-of-ezeth-cannot-necessarily-result-in-any-arbitrary-amount-specified.", "labels": ["OpenZeppelin"]}, {"title": "Generally, minting behavior of ezETH is determined by the intermediate value, inflationPercentage, which is used for computing the TVL growth of a deposit into ezETH and the subsequent growth of the supply of ezETH. Since inflationPercentage has a maximal value of 1e18 - 1, there are thus that many different values for the amount of ezETH which can be minted. There are possibly many more potential values for the amount of ETH which can be deposited, and thus the inflationPercentage is the limiting factor in potential values of ezETH minted.", "body": "Generally, minting behavior of ezETH is determined by the intermediate value, inflationPercentage, which is used for computing the TVL growth of a deposit into ezETH and the subsequent growth of the supply of ezETH. Since inflationPercentage has a maximal value of 1e18 - 1, there are thus that many different values for the amount of ezETH which can be minted. There are possibly many more potential values for the amount of ETH which can be deposited, and thus the inflationPercentage is the limiting factor in potential values of ezETH minted.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#generally,-minting-behavior-of-ezeth-is-determined-by-the-intermediate-value,-inflationpercentage,-which-is-used-for-computing-the-tvl-growth-of-a-deposit-into-ezeth-and-the-subsequent-growth-of-the-supply-of-ezeth.-since-inflationpercentage-has-a-maximal-value-of-1e18---1,-there-are-thus-that-many-different-values-for-the-amount-of-ezeth-which-can-be-minted.-there-are-possibly-many-more-potential-values-for-the-amount-of-eth-which-can-be-deposited,-and-thus-the-inflationpercentage-is-the-limiting-factor-in-potential-values-of-ezeth-minted.", "labels": ["OpenZeppelin"]}, {"title": "We encourage the Ion team to assess the tradeoff between increased gas costs and potential savings to users when deciding to make computations more accurate. Consider the typical values of deposits into the Ion protocol and utilize these to compute potential error as a general range of values. In addition, extensively document the error considerations to reassure users who may be concerned about inaccuracy in the computations.", "body": "We encourage the Ion team to assess the tradeoff between increased gas costs and potential savings to users when deciding to make computations more accurate. Consider the typical values of deposits into the Ion protocol and utilize these to compute potential error as a general range of values. In addition, extensively document the error considerations to reassure users who may be concerned about inaccuracy in the computations.", "html_url": "https://blog.openzeppelin.com/ion-protocol-seaport-ezeth-and-rseth-integration-audit#we-encourage-the-ion-team-to-assess-the-tradeoff-between-increased-gas-costs-and-potential-savings-to-users-when-deciding-to-make-computations-more-accurate.-consider-the-typical-values-of-deposits-into-the-ion-protocol-and-utilize-these-to-compute-potential-error-as-a-general-range-of-values.-in-addition,-extensively-document-the-error-considerations-to-reassure-users-who-may-be-concerned-about-inaccuracy-in-the-computations.", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Implementation of ERC-4626 Base Contract Leading to Asset Management and Usability Issues", "body": "The vault contract's adaptation from the ERC-4626 standard demonstrates critical flaws in asset management and functionality due to incomplete overrides of essential functions. Initially, the primary concern centers around the mint function. When users invoke the function, the contract correctly emits shares. However, it fails to update the _totalAssets variable and the pool's asset holdings. This discrepancy leads to a significant issue: the vault's asset tracking becomes inaccurate, which in turn will result in incorrect calculations when users attempt to redeem their shares.  Similarly, the omission of an override for the withdraw function can lead to transactions reverting when users attempt to execute withdrawals. Although this issue has a minor direct impact compared to the asset management flaw, it contributes to a degraded user experience, potentially deterring user interaction with the contract.  Consider modifying the mint and withdraw functions from the ERC-4626Upgradeable contract within the FortaStakingVault contract to accurately reflect withdrawn and minted assets in the _totalAssets variable.  Update: Resolved in pull request #22.  High Severity", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#incomplete-implementation-of-erc-4626-base-contract-leading-to-asset-management-and-usability-issues", "labels": ["OpenZeppelin"]}, {"title": "Attacker Can Stall Undelegations", "body": "The process of undelegating assets from a subject in the FortaStakingVault contract requires two steps:  initiateUndelegate function, which  deploys a distributor instance, an ERC-20 token. The vault transfers its  initiates the withdrawal of the assets in the  Secondly, once the waiting period passes, users are permitted to call the undelegate function to undelegate all the staked tokens of a specific subject by the vault. However, a problem arises when calculating the amount of FORT tokens to be sent from the distributor back to the vault. Instead of using the amount returned by the withdraw function from the FortaStaking contract, the balance of FORT tokens held by the distributor will be used instead which can be manipulated since anyone can send FORT tokens to the distributor.  If this occurs, the undelegate function will revert when attempting to subtract the assets delegated to the given subject since the amount subtracted will be greater than the one tracked in the _assetsPerSubject variable. This implies that the funds deposited in the distributor will become inaccessible and any subsequent attempts to invoke the undelegate function for that particular subject will fail.  Nonetheless, this is not irreversible as the operator can allocate additional tokens to the subject, thereby increasing the _assetsPerSubject amount to prevent an underflow. However, it may take some time before the operator notices this problem and the attacker could front-run any future delegations to put the undelegation process in a stalled situation again. A step-by-step proof-of-concept for this scenario can be found in this secret gist.  Consider using the amount returned by the withdraw function from the FortaStaking contract instead of the balance of FORT held by the distributor.  Update: Resolved in pull request #24.  Medium Severity", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#attacker-can-stall-undelegations", "labels": ["OpenZeppelin"]}, {"title": "Lack of Event Emissions", "body": "The following functions do not emit relevant events after executing sensitive actions or modifying storage variables:  The updateFeeBasisPoints function should emit a FeeBasisPointsUpdated event. This event should also be emitted in the initialize function.  The updateFeeTreasury function should emit a FeeTreasuryUpdated event. This event should also be emitted in the initialize function.  The delegate function should emit a StakeDelegated event.  The redeem function should emit a StakeRedeemed event.  The deposit function should emit a StakeDeposited event.  The claimRedeem function should emit a StakeClaimed event.  The undelegate function should emit a StakeUndelegated event.  The initiateUndelegate function should emit an UndelegateInitiated event.  Consider emitting events following sensitive changes, including the initial event emission in the constructor where appropriate, and incorporating relevant parameters. This approach will facilitate tracking and alert off-chain clients monitoring the contracts' activity.  Update: Partially resolved in pull request #28. The Nethermind team stated:  Only added the first two suggested and one for redeem. Other functions have plenty of underlying events that can be used for the same, either events of the ERC-4626 or events of FortaStaking, with the exception of redeem which is not calling the ERC-4626 implementation.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#lack-of-event-emissions", "labels": ["OpenZeppelin"]}, {"title": "Unbounded Loops in Redeem Function May Cause DoS", "body": "When multiple delegations exist within the vault, the redeem function's iteration through various subjects and distributors introduces a risk of Denial of Service (DoS) for users. Due to the unbounded nature of these loops, a scenario with numerous delegations and distributors could result in exceeding Polygon's 30 million gas limit upon execution of the redeem function. Although this issue is temporary, it has the potential to significantly degrade user experience.  Consider implementing a limitation on the maximum number of delegations permitted, thereby preventing such undesirable situations.  Update: Acknowledged, not resolved. The Nethermind team stated:  Acknowledged. DoS can only be done by the operator who should know and be cautious about it.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#unbounded-loops-in-redeem-function-may-cause-dos", "labels": ["OpenZeppelin"]}, {"title": "Wrong and Incomplete Docstrings", "body": "Throughout the codebase, there are several parts that have wrong or incomplete docstrings:  The documentation for the undelegate method within the InactiveSharesDistributor contract inaccurately states that vault shares are transferred to the vault. In reality, these shares are burned and it is the FORT tokens that are sent to the vault instead. In addition, the documentation for the claim function misleadingly indicates its use for claiming a portion of the inactive shares owned by individuals, whereas it actually facilitates the claiming of FORT tokens.  The initiateUndelegate, getRedemptionReceiver, and claimRedeem functions in FortaStakingVault.sol do not have their return values documented.  The initiateUndelegate and claim functions in InactiveSharesDistributor.sol do not have their return values documented.  The claim function in RedemptionReceiver.sol does not have its parameters nor return values documented.  The redeem and deposit functions use inheritdoc tags to reference ERC4626Upgradeable docstrings but fail to delineate the modifications from the original implementation.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #26.  Low Severity", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#wrong-and-incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Tokens Trapped in the Vault Might Cause Redemptions to Revert in Low FORT Liquidity Scenarios", "body": "redeem function enables users to redeem their staked FORT tokensor someone else's on their behalf. This function calculates the redeemer's share of the total vault assets and uses this proportion to  transfer active staking tokens and  distributor shares from the vault to the  claimRedeem function when available. Finally, it  transfers the corresponding proportion of available FORT tokens in the vault that have not yet been delegated, utilizing the FORT token's  However, during this final operation, if extra tokens are present in the vaultwhether they were directly sent to the contract by mistake or otherwisethese tokens will be included in the calculation when deducting the assets transferred to the user from the _totalAssets variable. Notably, the _totalAssets variable does not account for tokens directly transferred to the vault. Consequently, this discrepancy may lead to the redeem function reverting due to an underflow, especially when the last few users attempt to redeem tokens from the vault. A step-by-step proof-of-concept for this scenario can be found in this secret gist.  Consider accounting for all mistakenly sent FORT tokens in the vault in the _totalAssets state variable. Otherwise, consider implementing a sweep function that withdraws the token amount difference between _totalAssets and the actual balance reported by the FORT token contract's balanceOf function.  Update: Resolved in pull request #30.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#tokens-trapped-in-the-vault-might-cause-redemptions-to-revert-in-low-fort-liquidity-scenarios", "labels": ["OpenZeppelin"]}, {"title": "Not Checking if There Are Assets in the Vault to Redeem", "body": "redeem function in the  active or  inactive and calculates  the same proportion of FORT tokens present in the vault for immediate withdrawal. However, in the case that all the FORT tokens have been delegated and there are no FORT tokens present in the vault, the  will still transfer 0 tokens.  To avoid unnecessary operations and extra gas costs, consider checking whether there are assets in the vault to be transferred to the user in the redeem function.  Update: Resolved in pull request #32.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#not-checking-if-there-are-assets-in-the-vault-to-redeem", "labels": ["OpenZeppelin"]}, {"title": "Lack of Input Validation", "body": "Throughout the codebase, there are some instances in which the lack of input validation could lead to different undesired scenarios:  The delegate function allows the operator to delegate zero assets to the subject. When a subject has no assets, The subject will be added to the subjects array without the ability to remove it through the undelegate function due to the absence of active shares. Attempting to fix this by delegating assets to the same subject to enable the undelegate functionality would add the subject to the array again.  In the initialize function, there are no checks to validate that the feeTreasury is not the address 0 and that the feeInBasisPoints is lower than the FEE_BASIS_POINTS_DENOMINATOR variable, as it happens in the updateFeeTreasury and updateFeeBasisPoints functions respectively, which is inconsistent.  Consider implementing input validations in functions where parameters must be confined within specific boundaries. Furthermore, ensure that variables used across different functions are checked against the same boundaries to maintain consistency and integrity.  Update: Resolved in pull request #34 at commit 959e20a.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#lack-of-input-validation", "labels": ["OpenZeppelin"]}, {"title": "Missing Return Values in Functions Impair Protocol Integration and Information Flow", "body": "The undelegate function allows anyone to undelegate FORT tokens from the FortaStakingVault contract. However, this function does not return the amount of FORT tokens being withdrawn from the FortaStaking contract (through the undelegate function in the InactiveSharesDistributor contract), making it difficult for users to easily track how many tokens have been withdrawn, either off-chain or within a contract that calls the undelegate function and needs to store it.  A similar situation happens with the delegate function. It allows the operator to stake a given amount of previously deposited FORT tokens for a given subject to the FortaStaking contract through the deposit function. However, although deposit returns how many shares those tokens represent, and delegate has access to it, this value is not returned to the caller.  To avoid hindering off-chain operations and to make the vault more easily integrated with other contracts, consider returning the amount of FORT tokens withdrawn for the former and the amount of shares minted by the FortaStaking contract for the latter.  Update: Resolved in pull request #36.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#missing-return-values-in-functions-impair-protocol-integration-and-information-flow", "labels": ["OpenZeppelin"]}, {"title": "Redundant State Variable", "body": "Throughout the codebase, one variable duplicate another already defined, accessible state variable:  The FortaStakingVault contract defines the private _token state variable to track the underlying asset address. However, since this contract inherits from the ERC4626Upgradeable contract, it already has access to this address through the asset function.  Even though introducing this duplicate variable does not pose any security risk, it is unnecessary, error-prone, and can confuse developers and auditors.  To improve clarity and adhere to best practices in smart contract development, consider removing this variable and using the aforementioned getter function instead.  Update: Resolved in pull request #38.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#redundant-state-variable", "labels": ["OpenZeppelin"]}, {"title": "Inadequate Visibility of State Variables in RedemptionReceiver Contract", "body": "The visibility of the state variables _subjects and _subjectsPending is set to private, posing a significant usability concern within the Forta Vault's claim functionality. This restricted visibility forces users to depend excessively on the Forta Vault user interface to know the remaining number of FORT tokens available for claim. Users might incorrectly conclude that they have claimed all entitled tokens following the execution of the claimReedem function, unaware that additional subjects may still be pending, awaiting the deadline for eligibility.  The claim function iterates through the _subjects array, verifying the timestamp against _subjectsPending and checking if the subject is in a frozen state. When a subject meets all the criteria, its stake is retrieved, it is then removed from the array, and its related entry in _subjectsPending is eliminated. If a subject fails to meet the necessary conditions, it is either because the user must have invoked the function past a certain deadline or because the subject is currently frozen.  Consider providing public access or creating getter functions. This change would let users independently verify their claimable tokens, reducing dependency on the Forta Vault UI and mitigating the risk of misunderstandings regarding their token claims.  Update: Resolved in pull request #40.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#inadequate-visibility-of-state-variables-in-redemptionreceiver-contract", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Code Coverage", "body": "The codebase exhibits insufficient code coverage for branches and functions (currently under 77%). This level of coverage may leave critical portions of the code untested, potentially leading to undetected vulnerabilities.  Consider adding more unit tests to increase the code coverage to above 95%, adhering to best practices for software security and reliability. In addition, integrating code coverage tracking into the repository's Continuous Integration process is advised for ongoing quality assurance.  Update: Acknowledged, will resolve. The Nethermind team stated:  We will improve it after merging all changes associated with other findings, so we can make sure everything is well covered, especially all the branches.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#insufficient-code-coverage", "labels": ["OpenZeppelin"]}, {"title": "Duplicate Utilization of FortaStakingUtils Library", "body": "The project currently replicates the FortaStakingUtils library directly within its codebase instead of leveraging the Forta contracts repository as an external dependency. This approach introduces potential risks of inconsistencies between the version of the FortaStakingUtils used in the project and the latest version available in the Forta contracts repository. Such discrepancies could lead to unforeseen issues and complicate maintenance and updates.  Consider integrating the Forta contracts repository as a dependency. This strategy ensures that the project always utilizes the most current and consistent version of the FortaStakingUtils.  Update: Resolved in pull request #42.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#duplicate-utilization-of-fortastakingutils-library", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Project Information in README.md", "body": "The project's README.md file currently lacks substantial content and provides no specific information about the project itself. It appears to be the default file automatically generated by Foundry, which does not offer valuable insights or guidance for users or contributors.  Consider enriching the README.md with detailed project information, including its purpose, features, installation procedures, usage examples, and contribution guidelines. This enhancement will significantly improve the project's documentation, fostering a better understanding of the system and potentially attracting more contributors or users.  Update: Resolved in pull request #57.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#insufficient-project-information-in-readme.md", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact:  The FortaStakingUtils library.  The FortaStakingVault contract.  The IFortaStaking interface.  The IRewardsDistributor interface.  The InactiveSharesDistributor contract.  The OperatorFeeUtils library.  The RedemptionReceiver contract.  Consider adding a NatSpec comment containing a security contact above the contract definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, not resolved. The Nethermind team stated:  No security contact in Forta staking contracts to replicate. Forta users will surely use Forta socials to get in touch.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Inadequate Function Visibility", "body": "Throughout the codebase, some functions are defined as public but are not being accessed from the contract where they are defined:  In FortaStakingVault.sol:  The claimRewards function The delegate function The initiateUndelegate function The undelegate function  All public functions in the RedemptionReceiver contract  All public functions in the InactiveSharesDistributor contract  When declaring a function as external, its parameters are not copied to memory; instead, they are accessed directly from calldata. Calldata is a read-only, lower-cost area where function arguments are stored. This means that accessing parameters in external functions can consume less gas than accessing parameters in memory.  Consider changing the visibility of the aforementioned functions to external.  Update: Resolved in pull request #44.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#inadequate-function-visibility", "labels": ["OpenZeppelin"]}, {"title": "The Implemented Access Control Presents Potential Risks for the Vault", "body": "The FortaStakingVault uses the AccessControlUpgradeable to incorporate two rules within the vault: the OPERATOR_ROLE, which will be in charge of everything related to the delegations, and the DEFAULT_ADMIN_ROLE, that is in charge of assigning and revoking the latter role.  As the DEFAULT_ADMIN_ROLE is intended to be assigned to only one address, it is not advisable to use the current AccessControlUpgradeable implementation. Using AccessControlUpgradeable might not effectively prevent mistakes such as assigning the admin role to multiple addresses, granting the role to a wrong address, or revoking its own role.  Consider using the AccessControlDefaultAdminRules contract as an alternative to AccessControlUpgradeable. This allows only one account to possess the DEFAULT_ADMIN_ROLE, ensuring better control. It also establishes a two-step process to shift the DEFAULT_ADMIN_ROLE to a different account and includes a configurable delay between the steps. An additional feature allows for the transfer to be canceled before its acceptance. Furthermore, other roles cannot be utilized to manage the DEFAULT_ADMIN_ROLE.  Update: Partially resolved in pull request #46. The current implementation does not specify an initial delay; it defaults to zero. For enhanced readability and explicitness, we recommend using __AccessControlDefaultAdminRules_init_unchained to set the initialDelay and to grant the DEFAULT_ADMIN_ROLE.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#the-implemented-access-control-presents-potential-risks-for-the-vault", "labels": ["OpenZeppelin"]}, {"title": "Multiple Instances of Missing Named Parameters in Mappings", "body": "Since Solidity 0.8.18, developers can utilize named parameters in mappings. This means mappings can take the form of mapping(KeyType KeyName? => ValueType ValueName?). This updated syntax provides a more transparent representation of a mapping's purpose.  Throughout the codebase, there are multiple mappings without named parameters:  The _assetsPerSubject state variable in the FortaStakingVault contract  The _subjectIndex state variable in the FortaStakingVault contract  The _subjectInactiveSharesDistributorIndex state variable in the FortaStakingVault contract  The _subjectDeadline state variable in the FortaStakingVault contract  The _distributorSubject state variable in the FortaStakingVault contract  The _subjectsPending state variable in the RedemptionReceiver contract  The _distributorsPending state variable in the RedemptionReceiver contract  Consider adding named parameters to the mappings to improve the readability and maintainability of the codebase.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#multiple-instances-of-missing-named-parameters-in-mappings", "labels": ["OpenZeppelin"]}, {"title": "Dependency on Polygon Mainnet Fork for Testing", "body": "The project extensively relies on a fork of the Polygon mainnet to validate tests against the current state of contracts intended for integration. While this approach has its merits, the absence of a locally executable testing framework poses significant drawbacks. The dependency on the Polygon mainnet fork requires a constant connection to an RPC endpoint which increases the test execution times and introduces potential points of failure associated with network reliability.  Consider implementing a comprehensive local testing environment. This environment should simulate all external interactions, allowing for both integration tests with the mainnet fork and independent local tests. Adopting this strategy will not only decrease testing durations by eliminating network dependencies but also ensure that testing can proceed uninterrupted by external network issues, thus streamlining the development and debugging processes.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#dependency-on-polygon-mainnet-fork-for-testing", "labels": ["OpenZeppelin"]}, {"title": "Usage of msg.sender and _msgSender", "body": "Throughout the project, msg.sender is used to identify the sender of transactions. However, all OpenZeppelin contracts, from whom the project's contracts inherit, employ _msgSender instead. If the _msgSender function is overridden in the future, for example, to enable other parties to cover the gas costs of transactions, this adaptation will not be accurately represented in instances where msg.sender is used.  Consider either using _msgSender over msg.sender or documenting this distinction clearly to avoid problems. This will help prevent problems if modifications in how the _msgSender function works are introduced in the future.  Update: Resolved in pull request #48.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#usage-of-msg.sender-and-_msgsender", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors were identified in the codebase:  FortaStakingVault.sol:  Line 19: \"stategy\" should be \"strategy\", and \"forta\" should be capitalized as \"Forta\" Line 169: \"Overrided\" should be \"Overridden\". Line 290: \"inmediatly\" should be \"immediately\" Line 291: \"crated\" should be \"created\" Line 389: \"an user\" should be \"a user\"  InactiveSharesDistributor.sol:  Line 13: \"Inactives shares\" should be \"Inactive shares\" Line 15: \"invalidShares\" should be \"inactive shares\" Line 16: \"transferrable\" should be \"transferable\"  RedemptionReceiver.sol:  Line 34: \"Initialiazes\" should be \"Initializes\".  Consider resolving these typographical errors, as well as running an automated spelling/grammar checker on the codebase and correcting any identified errors.  Update: Resolved in pull request #50.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Licensing", "body": "The project uses multiple licenses, MIT and UNLICENSED, which could cause legal or operational issues.  If this is unintentional, standardizing the license across the codebase is recommended to avoid confusion. If intentional, clearly document the rationale for using multiple licenses and ensure compatibility between them.  Update: Resolved in pull request #52.", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#inconsistent-licensing", "labels": ["OpenZeppelin"]}, {"title": "Gas and Code Optimizations", "body": "Several opportunities for gas and code optimizations have been identified across various functions and contracts, which could significantly improve efficiency and reduce execution costs:  For Loop Optimization: Current implementations frequently recalculate array lengths within for loop iterations (e.g., line 86 of the RedemptionReceiver contract and line 315 of the FortaStakingVault contract). Optimizing these loops by caching the array length in a local variable before the loop starts can reduce gas costs and execution times.  Redundant Validation Removal: The _validateIsOperator() function appears to be redundant and could be replaced with onlyRole(OPERATOR_ROLE) for role checking, simplifying the codebase and potentially saving gas.  Immutable State Variables: Several state variables, such as _token and staking, do not change after contract initialization and thus could be declared as immutable and set in the constructor instead of the initialize function. This change could lower gas costs by reducing storage access.  Unnecessary Condition in undelegate: The undelegate function contains a conditional check that is logically unnecessary. If vault shares are greater than zero, it logically follows that vault assets cannot be equal to zero, making the if statement redundant.  Local vs. State Variable Usage: Inconsistencies in using local versus state variables have been noted. In this line, use the local variable assetsReceived both times to avoid the unnecessary SLOAD operation.  Update: Partially resolved in pull request #53 and pull request #36. The third item on the list was acknowledged by the Nethermind team", "html_url": "https://blog.openzeppelin.com/forta-staking-vault-audit#gas-and-code-optimizations", "labels": ["OpenZeppelin"]}, {"title": "BVM_ETH and MNT Deposited in Messengers Can Be Stolen", "body": "L2CrossDomainMessenger contract, the  relayMessage function will perform an arbitrary external call to  will be set to true and, at that point, anyone can  retry the execution of the transaction.  contract when transferring MNT from L2 to L1, the  will transfer MNT to the  depositTransaction through the  relayMessage with the  L2CrossDomainMessenger to an EOA owned by the attacker.  The approval allows the attacker to steal any BVM_ETH sitting in the L2CrossDomainMessenger coming from a failed relayMessage execution and waiting to be retried. The same attack applies to L1 where anyone can become an allowed spender of MNT stored in L1CrossDomainMessenger and steal those too.  function of  contract. Alternatively consider prohibiting setting the  Update: Resolved in pull request #123 at commit e251c1b. No new unit tests have been added.  Medium Severity", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#bvm_eth-and-mnt-deposited-in-messengers-can-be-stolen", "labels": ["OpenZeppelin"]}, {"title": "Cross Domain Messengers Can Fail in Relaying a Message", "body": "L1CrossDomainMessenger contract extends  CrossDomainMessenger and overrides the  relayMessage function. One of the characteristics of the original  has a few operations performed in between. The  docstrings that warn against the overhead gas provided. It  states that 40000 units of gas are added as extra gas cost to account for a worst-case scenario of the  Access to cold storage that accounts for 2600 units of gas.  Call to a non-existent target that accounts for 25000 units of gas.  A positive msg.value in the call that will increase the cost by 9000 units of gas.  Also, note that the second argument of the hasMinGas function is the sum of the following two variables:  RELAY_RESERVED_GAS which is set to 40000 units of gas. This is an estimation of how much gas is needed to continue with the relayMessage execution after the external call. This is unchanged from Optimism code.  RELAY_GAS_CHECK_BUFFER which is set to 5000 units of gas and represents an amount that should be used in between the hasMinGas function and the external call. This is also unchanged from Optimism code.  The hasMinGas function contains the following formula:  Here, _reservedGas is 45000 units of gas of which only 5000 are estimated to be a buffer before the external call. Taking into account all of this, between the gas estimation and the external call, there is a total buffer of 5000 plus the remainder of the 40000, removing the worst case scenario of 36600 units of gas, for a total of 8400 units of gas (and not 5700 as mentioned in the docs). After the external call, another 40000 units of gas are reserve to finish with the normal execution.  The L1CrossDomainMessenger override adds some extra instructions in the code: an approve call to the MNT token contract in case the message being relayed contains a movement of MNT tokens, and a second approve to set the allowance back to 0 which is repeated after the external call. Whether the second approval is needed or not depends on whether there might be circumstances in which given approvals are not consumed by the target of the external call.  Some instances of an  function of the  In light of the above, consider revisiting the values for RELAY_GAS_CHECK_BUFFER and RELAY_RESERVED_GAS, and deciding whether the second approval is needed to avoid having unexpected gas failures due to extra instructions included from the original Optimism code that came with no changes to those default estimation values. Moreover, given the added logic from Optimism code, gas buffers should be adapted to ensure that enough overhead is added so that the transactions do not fail. It is worth noting that calls to relayMessage that can be engineered to fail can prevent the finalization of deposits and withdrawals, opening the doors for DoS attacks.  Update: Resolved in pull request #114 at commit 67f0904 and at commit 92ebaf9.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#cross-domain-messengers-can-fail-in-relaying-a-message", "labels": ["OpenZeppelin"]}, {"title": "Gas Estimation Can Fail in finalizeWithdrawalTransaction", "body": "function of the  revert whenever an external call fails and the  boolean by default to  issue N01.  Consider making the gas estimation behavior consistent with what has been inherited from Optimism and left unchanged in other parts of the codebase. When doing so, consider the mentioned issue about useless boolean variables being used.  Update: Resolved in pull request #105 at commit 6022c06.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#gas-estimation-can-fail-in-finalizewithdrawaltransaction", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Payable Function Definition", "body": "function of the  Consider whether the proposeL2Output has to be payable and document the reason. Alternatively, consider removing the payable attribute.  Update: Resolved in pull request #138 at commit af0d029.  Low Severity", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#unnecessary-payable-function-definition", "labels": ["OpenZeppelin"]}, {"title": "Assets Might Get Stuck in Contracts", "body": "Across the codebase, there are several circumstances in which assets can get locked in the contracts due to external call failures. Two examples are:  When bridging ETH from L2 to L1, the finalizeWithdrawalTransaction function of the OptimismPortal is called. This will attempt to call the L1StandardBridge at the finalizeBridgeETH function which performs an external call to the recipient of the ETH. However, if such a call fails, the success returned boolean will be false and the finalizeWithdrawalTransaction will revert exclusively if the tx.origin is the ESTIMATION_ADDRESS, but it will not revert if the caller is a normal user trying to finalize the bridge back to L1. Moreover, the finalizedWithdrawals mapping will be set to true for this specific withdrawal, preventing any future attempt to replay the transaction and make it work. The result is that ETH will be stuck in the OptimismPortal.  When bridging an ERC-721 token from L2 to L1, the same finalizeWithdrawalTransaction will be called, but this time the L1ERC721Bridge will be called at the finalizeERC721Bridge function. This function will effectively perform a safeTransferFrom from the L1ERC721Bridge to the recipient of the ERC-721 token. The usage of the safeTransferFrom implies also triggering a _checkOnERC721Received hook which will revert if the recipient is a contract that does not implement the correct interface to receive the token. If the call reverts, the same situation as before will happen since the finalizeWithdrawalTransaciton will not revert and the withdrawal will be marked as finalized. The result here is that the ERC-721 token will be stuck in the bridge.  Consider either documenting such behaviours in the docstrings of the contracts or putting remediations in place.  Note that case in which ETH gets stuck in the OptimismPortal is inherited from the Optimism contracts and Optimism have already taken a position in which they delegate the responsibility of this to the user who should understand the risk. Quoting one of their issues:  One of the quirks of the OptimismPortal is that there is no replaying of transactions. If a transaction fails, it will simply fail, and all ETH associated with it will remain in the OptimismPortal contract. Users have been warned of this and understand the risks, so Optimism takes no responsibility for user error.  Update: Acknowledged, not resolved. The Mantle team stated:  Won't fix; we have already implemented transaction replay at the CrossDomainMessenger contract level.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#assets-might-get-stuck-in-contracts", "labels": ["OpenZeppelin"]}, {"title": "Unusual Upgradeability Patterns Are Adopted", "body": "some contracts are meant to be upgradeable and so may have a  variable defined. Upgradeable contracts are meant to be called via proxies, for which reason they usually have an  function that is called through the proxy. This function sets the initial variable values of the proxy storage slots. In order to prevent someone from initializing the implementation contract directly, in some circumstances, the  within the constructor. However, this consumes unnecessary gas and is sub-optimal. All initializable contracts extend the OpenZeppelin  contract which defines an internal  function called  Consider calling the _disableInitializers function instead of calling the initialize function within the constructor.  ERC721Bridge and  L1ERC721Bridge contracts. The former has two immutable variables that do not take any slot and the  set to have a size of 49 slots despite the canonical value being 50, while the latter has one slot occupied by the deposits  mapping. This may be misleading as it might explain the 49 slot size instead of the 50 slot size for the  Consider reviewing the codebase and always using upgradeability standard patterns in which the __gap variable's size reflects the amount of storage slots occupied by the current contextual contract.  Update: Acknowledged, not resolved. The Mantle team stated:  Not fixing. It will not affect the main logic.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#unusual-upgradeability-patterns-are-adopted", "labels": ["OpenZeppelin"]}, {"title": "Wrong Value Emitted in Event", "body": "The TokenRatioUpdated event is emitted in the GasPriceOracle contract everytime the tokenRatio variable is updated to a new value. Its parameters are the previous and the new value being set. However, the event incorrectly emits the new token ratio twice instead of emitting the previous token ratio followed by the new token ratio.  Consider assigning the previousTokenRatio variable to the current token ratio instead of the used input parameter.  Update: Resolved in pull request #138 at commit 572600a.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#wrong-value-emitted-in-event", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "Throughout the codebase, there are several parts that have a incomplete docstring:  In the relayMessage function of the CrossDomainMessenger contract, the _mntValue parameter is not documented.  The OwnershipTransferred event of the CrossDomainOwnable3 contract does not document what the previousOwner, newOwner, and isLocal parameters are.  The TokenRatioUpdated, OwnershipTransferred, and OperatorUpdated events in the GasPriceOracle contract do not document what their parameters are.  In the transferOwnership function of the GasPriceOracle contract, the _owner parameter is not documented.  In the depositMNT function of the L1StandardBridge contract, the _amount parameter is not documented.  In the depositMNTTo function of the L1StandardBridge contract, the _amount parameter is not documented.  In the bridgeETH function of the L2StandardBridge contract, the _value parameter is not documented.  In the l1Token function of theOptimismMintableERC20 contract, not all return values are documented. The same happens in the l2Bridge, remoteToken, and the bridge functions of the same contract.  In the WithdrawalProven event of the OptimismPortal contract, the from and to parameters are not documented.  In the initialize function of the OptimismPortal contract, the _paused parameter is not documented.  In the minimumGasLimit function of the OptimismPortal contract, the _byteCount and the return value are not documented.  In the initialize function of the SystemConfig contract, the _baseFee parameter is not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Acknowledged, not resolved. The Mantle team stated:  Will fix later. it's not a logic issue.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Floating and Multiple Pragma Directives Are Being Used", "body": "Pragma directives should be fixed to clearly identify the Solidity version with which the contracts will be compiled. Throughout the codebase, there are multiple floating pragma directives. The majority of contracts have a fixed version of 0.8.15 but there are some contracts that differ:  The BVM_ETH.sol file has the solidity ^0.8.9 floating pragma directive.  The CrossDomainOwnable.sol file has the solidity ^0.8.0 floating pragma directive.  The CrossDomainOwnable2.sol file has the solidity ^0.8.0 floating pragma directive.  The CrossDomainOwnable3.sol file has the solidity ^0.8.0 floating pragma directive.  The Semver.sol file has the solidity ^0.8.0 floating pragma directive.  Moreover, there are cases in which one contract has a pragma directive which differs from that of its imports:  The CrossDomainOwnable2.sol file has the pragma solidity ^0.8.0; pragma directive and imports L2CrossDomainMessenger.sol which has a different pragma directive.  The CrossDomainOwnable3.sol file has the pragma solidity ^0.8.0; pragma directive and imports L2CrossDomainMessenger.sol which has a different pragma directive.  Consider using a fixed pragma version which is consistent across all contracts.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#floating-and-multiple-pragma-directives-are-being-used", "labels": ["OpenZeppelin"]}, {"title": "Unsafe ABI Encoding", "body": "It is not an uncommon practice to use abi.encodeWithSignature or abi.encodeWithSelector to generate calldata for a low-level call. However, the first option is not typo-safe and the second option is not type-safe. The results in both of these methods being error-prone and thus to be considered unsafe. Within Encoding.sol, there are several occurrences of unsafe ABI encodings:  In line 92.  In line 124.  Consider replacing all the occurrences of unsafe ABI encodings with abi.encodeCall, which checks whether the supplied values actually match the types expected by the called function and also avoids errors caused by typos.  Update: Acknowledged, not resolved. The Mantle team stated:  There is no need to fix this.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#unsafe-abi-encoding", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are several parts that do not have docstrings. For instance:  The mint function of the BVM_ETH contract is not documented.  The variables, events, and modifiers of the GasPriceOracle contract are not documented.  The L1_MNT_ADDRESS variable of the L1CrossDomainMessenger contract is missing documentation. The same variable lacks docstrings in the L1StandardBridge and in the L2StandardBridge contracts.  The bridgeMNTTo function of the L2StandardBridge contract is not documented.  In the depositTransaction function of the OptimismPortal contract it is possible to bridge simultaneously ETH and MNT at the same time. If this is the case the user should not use the normal flow of bridging through L2CrossDomainMessenger and L2StandardBridge since this supports bridging only one asset at time. Consider warning the user about it.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.  Notes & Additional Information  Unnecessary Boolean Values  Throughout the codebase, there are instances of boolean values being defined but not being logically useful:  The success value of the approve call within the _initiateBridgeMNT function of the L1StandardBridge contract. The Mantle token's approve function either reverts or returns true, there is no case in which its result value is false.  The l1mntSuccess variable of the finalizeWithdrawalTransaction function of the OptimismPortal contract is either true or the transfer call reverted. It will never be false.  The ethSuccess variable of the relayMessage function of the L2CrossDomainMessenger contract is either true or the approve function reverted. It will never be false whenever its value is evaluated.  Consider refactoring the code to avoid using unnecessary boolean values. When doing so, care should be taken in maintaining the same flow of execution, especially at places where the current unnecessary booleans are being evaluated.  Update: Resolved in pull request #128 at commit d8efd33.  Misleading Docstrings  Several instances of incorrect or misleading docstrings have been identified throughout the codebase:  BVM_ETH.sol:  Line 12: the comment above the BVM_ETH definition is outdated and can be misleading  LegacyERC20MNT.sol:  Lines 39, 47, 55, 63: \"ETH\" should be \"MNT\"  Burn.sol:  Lines 34, 35: \"ETH\" should be \"MNT\"  The docstrings in lines 19, 21 mention that the gas function \"burns\" a specific amount of gas. However, the amount of gas is not burnt but consumed  Types:  Both mntTxValue and ethTxValue share identical documentation, yet they serve different purposes in UserDepositTransaction.  In WithdrawalTransaction's struct documentation, the docstring for the non-existent field value can be removed. Additionally, both mntValue and ethValue fields are not documented.  Consider updating the misleading instances of docstrings for improved clarity and readability.  Update: Partially resolved in pull request #129 at commit fd4fc03. The outdated comment in BVM_ETH.sol is still present.  Duplicated Getter Function  The RECIPIENT variable of the SequencerFeeVault contract is declared as public. However, it also has a specific getter defined.  Consider removing the duplicate getter and leaving only one instance to retrieve the value of the RECIPIENT variable from.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.  public Functions Can Be Declared as external  Throughout the codebase, there are multiple instances of contracts that define public functions. However, these functions can be defined as external instead.  To save gas and improve code clarity, consider reviewing the codebase and marking all functions that are not called within the code itself as external.  Update: Resolved in pull request #130 at commit c6f2d81.  Code Style Inconsistency  The ERC721Bridge contract has a specific require statement to make sure that the caller is an EOA and not a contract. However, other contracts have a specific modifier called onlyEOA for the same purpose.  Consider using the onlyEOA modifier consistently across the codebase to improve code readability and quality.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.  Typographical Errors  In the codebase, there are a few instances of docstrings containing typos:  In line 32 of the OptimismPortal contract, \"whcih\" should be \"which\".  In line 72 of the OptimismPortal contract, the first docstring line is missing \"If the value\" and thus does not logically connect with the second docstring line.  Consider reviewing the entire codebase and addressing typographical errors in order to improve code quality and readability.  U", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": " Unnecessary Boolean Values", "body": " Unnecessary Boolean Values", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#-unnecessary-boolean-values", "labels": ["OpenZeppelin"]}, {"title": "Misleading Docstrings", "body": "Several instances of incorrect or misleading docstrings have been identified throughout the codebase:  BVM_ETH.sol:  Line 12: the comment above the BVM_ETH definition is outdated and can be misleading  LegacyERC20MNT.sol:  Lines 39, 47, 55, 63: \"ETH\" should be \"MNT\"  Burn.sol:  Lines 34, 35: \"ETH\" should be \"MNT\"  The docstrings in lines 19, 21 mention that the gas function \"burns\" a specific amount of gas. However, the amount of gas is not burnt but consumed  Types:  Both mntTxValue and ethTxValue share identical documentation, yet they serve different purposes in UserDepositTransaction.  In WithdrawalTransaction's struct documentation, the docstring for the non-existent field value can be removed. Additionally, both mntValue and ethValue fields are not documented.  Consider updating the misleading instances of docstrings for improved clarity and readability.  Update: Partially resolved in pull request #129 at commit fd4fc03. The outdated comment in BVM_ETH.sol is still present.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#misleading-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Duplicated Getter Function", "body": "The RECIPIENT variable of the SequencerFeeVault contract is declared as public. However, it also has a specific getter defined.  Consider removing the duplicate getter and leaving only one instance to retrieve the value of the RECIPIENT variable from.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#duplicated-getter-function", "labels": ["OpenZeppelin"]}, {"title": "public Functions Can Be Declared as external", "body": "Throughout the codebase, there are multiple instances of contracts that define public functions. However, these functions can be defined as external instead.  To save gas and improve code clarity, consider reviewing the codebase and marking all functions that are not called within the code itself as external.  Update: Resolved in pull request #130 at commit c6f2d81.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#public-functions-can-be-declared-as-external", "labels": ["OpenZeppelin"]}, {"title": "Code Style Inconsistency", "body": "The ERC721Bridge contract has a specific require statement to make sure that the caller is an EOA and not a contract. However, other contracts have a specific modifier called onlyEOA for the same purpose.  Consider using the onlyEOA modifier consistently across the codebase to improve code readability and quality.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#code-style-inconsistency", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "In the codebase, there are a few instances of docstrings containing typos:  In line 32 of the OptimismPortal contract, \"whcih\" should be \"which\".  In line 72 of the OptimismPortal contract, the first docstring line is missing \"If the value\" and thus does not logically connect with the second docstring line.  Consider reviewing the entire codebase and addressing typographical errors in order to improve code quality and readability.  Update: Resolved in pull request #131 at commit 53fe7ce.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Variables Naming Does Not Follow Solidity Style Guide", "body": "As per the Solidity Style Guide suggestions, private or internal variable identifiers should be prefixed with _. Throughout the codebase, there are multiple instances of variable naming that do not follow these guidelines.  Consider reviewing the codebase and fixing any instances of irregular variable naming, and adopting all the Solidity style guidelines in order to improve the overall code quality and readability.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#variables-naming-does-not-follow-solidity-style-guide", "labels": ["OpenZeppelin"]}, {"title": "Use of Magic Constants", "body": "In L1CrossDomainMessenger, magic constants are being used. In the linked instance, the check can be changed from < 2 to <= MESSAGE_VERSION.  Consider always defining constants with explicit names for better readability and understandability of the codebase.  Update: Resolved in pull request #132 at commit 75e7984. However, the same happens on L2CrossDomainMessenger but it hasn't been fixed there.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#use-of-magic-constants", "labels": ["OpenZeppelin"]}, {"title": "Usage of Single Step Ownership Transfer", "body": "In the CrossDomainOwnable and GasPriceOracle contracts, ownership is transferred in a single step. This might be pose a risk since setting an incorrect address would mean that the ownership of the contracts is permanently lost, with no method of recovery.  Consider using a two-step ownership transfer process such as OpenZeppelin's Ownable2Step.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#usage-of-single-step-ownership-transfer", "labels": ["OpenZeppelin"]}, {"title": "Lack of Indexed Event Parameters", "body": "Throughout the codebase, several events do not have their parameters indexed:  The Withdrawal event of the FeeVault contract  The Paused and Unpaused events of the OptimismPortal contract  Consider indexing event parameters to improve the ability of off-chain services to search and filter for specific events.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#lack-of-indexed-event-parameters", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are many instances of contracts not having a security contact.  Consider adding a NatSpec comment containing a security contact above the contract definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, not resolved. The Mantle team stated:  There is no need to fix this.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Cast", "body": "Within the LegacyERC20MNT contract, the address(_who) cast is unnecessary.  To improve the overall clarity, intent, and readability of the codebase, consider removing unnecessary casts.  Update: Resolved in pull request #133 at commit 9032ff2.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#unnecessary-cast", "labels": ["OpenZeppelin"]}, {"title": "Unused Code", "body": "The hashDepositTransaction function of the Hashing library contract is never used within the codebase. In addition, the following code eventually remains unused as well, since it currently only assists the hashDepositTransaction function:  function encodeDepositTransaction of the Encoding library  function hashDepositSource of the Hashing library  struct UserDepositTransaction of the Types library  To improve the overall clarity, intentionality, and readability of the codebase, consider removing any unused code.  Update: Acknowledged, not resolved. The Mantle team stated:  There is no need to fix this.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#unused-code", "labels": ["OpenZeppelin"]}, {"title": "Addresses of Predeploys Are Not Ordered", "body": "The constant values of addresses in the Predeploys library are not ordered incrementally which is prone to errors when new addresses need to be added.  Consider ordering all addresses incrementally.  Update: Acknowledged, not resolved. The Mantle team stated:  There is no need to fix this.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#addresses-of-predeploys-are-not-ordered", "labels": ["OpenZeppelin"]}, {"title": "Address Is Being Removed Twice", "body": "step3 function is being called to remove deprecated addresses from the  line 293 and then on  line 300.  Consider only removing the deprecated address of BVM_CanonicalTransactionChain once.  Update: Resolved in pull request #135 at commit 4ed9335.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#address-is-being-removed-twice", "labels": ["OpenZeppelin"]}, {"title": "Predeployed Contracts Missing Custom Documentation Tag", "body": "codebase, predeployed contracts listed in the  Predeploys library include the custom tag  ProxyAdmin -  OptimismMintableERC721Factory -  L2ERC721Bridge -  BVM_ETH  To improve code clarity, consider adding the @custom:predeploy tag with the appropriate address to each contract's NatSpec documentation.  Update: Acknowledged, not resolved. The Mantle team stated:  There is no need to fix this.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#predeployed-contracts-missing-custom-documentation-tag", "labels": ["OpenZeppelin"]}, {"title": "Unused Import", "body": "The L1StandardBridge.sol contract imports L1CrossDomainMessenger but does not use it.  Consider removing any unused imports to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #136 at commit 2002a90.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#unused-import", "labels": ["OpenZeppelin"]}, {"title": "Duplicate Event Emission", "body": "The OwnershipTransferred event of the CrossDomainOwnable3 contract is already emitted inside the internal _transferOwnership function.  Consider removing the duplicate event.  Update: Acknowledged, not resolved. The Mantle team stated:  No need to fix.", "html_url": "https://blog.openzeppelin.com/mantle-v2-solidity-contracts-audit#duplicate-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Attacker Can Get Infinite BVM_ETH Tokens to Drain the Protocol", "body": "depositTransaction function of the  pulling the MNT token from the user and  msg.value. However, the transaction values of MNT and ETH are just forwarded from the user input to the  parses it, and includes it in a block to execute it in the client.  enough balance available for the given MNT transfer value. If not, the execution reverts. However, this check is never performed for the ETH transaction value. In fact, the  ETH balance transfer is performed by reading the  applying the difference in value, and setting the new state for these slots.  This means that an attacker with zero ETH balance on L2 can initiate a deposit transaction to transfer 100 ETH to their second controlled address. Then, in the transferBVMETH function, their from balance is calculated as -100 ETH but written to state as +100 ETH, while their second account also gets another +100 ETH, totaling a gain of 200 ETH on L2 without any L1 investment (besides gas). This ETH value could simply be withdrawn to L1 to drain all of the locked ETH.  Consider applying stronger balance and overflow checks when directly manipulating the state of an asset.  Update: Resolved in pull request #42 at commit 0cf00ba.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#attacker-can-get-infinite-bvm_eth-tokens-to-drain-the-protocol", "labels": ["OpenZeppelin"]}, {"title": "Wrong Cost Accounting", "body": "1,  2] where it is checked whether the user's balance covers the transaction costs.  However, as the cost does not include the transaction value, a transaction the user could not afford by value would still be added to the pool as valid. Then, when the transaction is processed during state_transition.go to buy gas, the balance check is performed again, this time with the Value, which causes the transaction to revert without charging the user. This leads to a DoS attack vector, where an attacker can spam the network with lucrative transactions that would be prioritized by the node, but never get executed at no cost while also preventing other transactions from being added to the transaction pool, effectively causing the blockchain to stop working.  Consider adding the transaction Value to the transaction cost. Also, consider whether the code redundancy of cost calculation can be better managed with one or two methods.  Update: Resolved in pull request #41 at commit 44c9a41.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#wrong-cost-accounting", "labels": ["OpenZeppelin"]}, {"title": "Potential Insufficient Balance for Sponsorship", "body": "The purpose of the validateMetaTxList function of core/txpool/txpool.go is to check if the sponsor has enough balance to cover the gas fees of the transactions that it is sponsoring. This is used by the validateTx function, the promoteExecutables function, and the demoteUnexecutables function, in order to determine which transactions are valid.  The validateMetaTxList function iterates over all the transactions in a list, and checks if the sponsor has enough to fund each transaction individually. However, there can be scenarios in which a sponsor has enough balance to fund each transaction individually, but not all of the transactions combined. The node then views all of these transactions as valid and keeps them in its txpool. It is not until the node builds a block and begins to process these transactions that it realizes that some of these transactions may fail. As such, a malicious attacker could perform a DoS attack on a node by submitting many sponsored transactions to sponsor as much as its balance, and while the node views all of the transactions as valid and thus stores them in its txpool, only one of them can actually be valid. This could stall the node from processing other users' transactions, effectively causing the L2 to stop functioning.  Consider updating the validateMetaTxList function to check if the balance of the sponsor can pay for the sponsorCostSum, which is the total of the sponsored amounts.  Update: Resolved in pull request #43 at commit 2619376.  Low Severity", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#potential-insufficient-balance-for-sponsorship", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Error Message", "body": "In the validateTx function of light/txpool.go, if the sponsor does not contain sufficient funds in order to pay for the sponsorAmount, the error returned is core.ErrInsufficientFunds. However, for clarity and consistency with txpool/txpool.go, consider returning the types.ErrSponsorBalanceNotEnough error instead.  Update: Resolved in pull request #50 at commit 65ab3a1.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#incorrect-error-message", "labels": ["OpenZeppelin"]}, {"title": "Use of Non-Granular Value for tokenRatio", "body": "The value of tokenRatio is stored in the GasPriceOracle.sol contract on L2 as a uint256. This tokenRatio is intended to take on the quotient value of ETH price divided by MNT price, and it is used to calculate the gas on L2. Currently, when this value is updated, all decimals are truncated. Given the current market price of ETH and MNT, the truncation would only result in a slight error in the gas calculation. However, if the value of MNT grows relative to the price of ETH, the error will continue to grow.  Therefore, consider scaling up the tokenRatio value and, upon using this value in op-geth, scale it back down to its proper scale at that point in order to improve precision.  Update: Acknowledged, will resolve.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#use-of-non-granular-value-for-tokenratio", "labels": ["OpenZeppelin"]}, {"title": "The Light txpool Implementation Does Not Account for L1 Costs", "body": "The light client implementation of txpool validates added transactions just as the core implementation does. This includes checking whether the user and the meta transaction sponsor have enough balance to cover the costs.  However, the user balance is only checked against the L2 cost [1, 2] without the L1 fee, even though it is necessary to account for the rollup transaction cost to L1. This implies that the underestimated cost could lead to the transaction reverting due to insufficient funds once it is sent to a full node.  Despite the light node not being in use yet, consider correcting the validation to account for the L1 costs in order to be prepared for when the network goes decentralized with light nodes.  Update: Acknowledged, will resolve. The Mantle team stated:  The light node is not yet in use, we will fix it later.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#the-light-txpool-implementation-does-not-account-for-l1-costs", "labels": ["OpenZeppelin"]}, {"title": "Fragilely Shared Pointer", "body": "with this assignment, the variables share the same memory. Luckily, the  However, if in future revisions this code were to be changed to balanceCheck.SetUint64(), no new memory would be allocated for this value, implying an overwrite of mgval with it. In this code context, this means that the transaction value is additionally considered as gas cost, leading to a double spending of the value or additional spending for the transaction sponsor.  Consider avoiding a shared pointer altogether by always allocating a new value through new(big.Int).SetUint64(). While this is not an issue in the given function, it is better to minimize the risk before it escalates in the future if not treated carefully.  Update: Resolved in pull request #52 at commit 75b60cb.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#fragilely-shared-pointer", "labels": ["OpenZeppelin"]}, {"title": "Misleading Documentation", "body": "Throughout the codebase, there are instances of misleading documentation:  In line 80 of transaction.go, the comment currently says \"This is implemented by DynamicFeeTx, LegacyTx and AccessListTx\", but should be updated to include the BlobTx and DepositTx types.  In line 377 of transaction.go, the comment currently says \"gas * gasPrice + value\", but should say \"(gas * gasPrice) + (blobGas * blobGasPrice) + value\" instead.  In line 655 of state_transition.go, the comment currently says \"Return ETH for remaining gas\", but should say \"MNT\" instead.  Furthermore, there is misleading documentation in the developer documentation as well:  The \"BASEFEE Adjustment Mechanism\" section \"Application of EIP-1559 in Mantle v2\" is outdated. With the Mantle BaseFee upgrade, the BaseFee is set by a config contract (or remains as the last BaseFee).  Consider fixing the reported documentation instances to improve the overall readability of the codebase.  Update: Partially resolved in pull request #41 at commit 44c9a41 and pull request #52 at commit 2527a58. While the comments on line 377 in transaction.go and line 655 in state_transition.go have been resolved, the comment on line 80 in transaction.go as well as the developer documentation remain unchanged.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#misleading-documentation", "labels": ["OpenZeppelin"]}, {"title": "Code Redundancy", "body": "Code redundancy can lead to code bloat and an increased error surface when updating the code in the future. Throughout the codebase, there are several instances of code redundancy:  The newPUSH0InstructionSet function contains the same code as the newShanghaiInstructionSet function.  This section of code in the DoEstimateGas function which is to estimate the gas cap for a meta transaction is redundant given the calculateGasWithAllowance function.  In line 87 of meta_transaction.go, the len(MetaTxPrefix) is the same as the existing constant MetaTxPrefixLength.  In lines 73 to 76 of rollup_l1_cost.go, the contract state is fetched directly instead of using the DeriveL1GasInfo function.  In worker.go, the way the header.BaseFee can be overwritten twice is redundant.  Consider removing any instances of code redundancy or explicitly documenting why they are necessary.  Update: Acknowledged, will resolve.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#code-redundancy", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Module Name", "body": "The Mantle codebase is currently using github.com/ethereum/go-ethereum as its module name, as seen in the go.mod file. The usage of this name, which is from a GitHub repo that it does not own, prevents others from importing Mantle's code and makes it more challenging for testing.  Consider using Mantle's own path for its module name.  Update: Acknowledged, will resolve. The Mantle team stated:  No issue. In mantle-v2, we will replace github.com/ethereum/go-ethereum v1.11.6 => github.com/mantlenetworkio/op-geth... and so on.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#incorrect-module-name", "labels": ["OpenZeppelin"]}, {"title": "Struct Field and Tag Mismatch", "body": "tagged and  referred to as \"input\". In the  go-ethereum reference implementation, this field is called  To prevent confusion about the parameters and to close the gap between this and the go-ethereum repository, consider renaming the Data field to Input.  Update: Acknowledged, will resolve. The Mantle team stated:  Will not fix now, we will upgrade to the latest go-ethereum later.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#struct-field-and-tag-mismatch", "labels": ["OpenZeppelin"]}, {"title": "Block Number Expiry Potentially Confusing", "body": "The validity of a meta transaction can be limited by the block number. When this block number is exceeded, the transaction will not be accepted as valid. However, from a user experience perspective, it is less intuitive for a sponsor to set a block number as opposed to a timestamp.  To enhance the user experience, consider changing the unit from block number to block timestamp.  Update: Acknowledged, not resolved. The Mantle team stated:  The blockheight and blocktime of the mantle-v2 blocks correspond one-to-one, and this is only for user experience. If we modify it, it will introduce significant modifications. Will not fix.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#block-number-expiry-potentially-confusing", "labels": ["OpenZeppelin"]}, {"title": "Unused Variables", "body": "As the codebase grows and matures, unused variables can cause code bloat, naming collisions, and confusion when reading the code. Throughout the codebase, there are instances of unused variables:  The OptimismL1FeeRecipient variable is not used since the L1 fee is already included in the fee that goes towards the OptimismBaseFeeRecipient.  The OverrideMantleBaseFee variable is unused and from the comment it should be removed after the fork.  The OverrideShanghai variable is unused and from the comment it should be removed after the fork.  Consider removing these unused variables to improve code clarity.  Update: Acknowledged, will resolve.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#unused-variables", "labels": ["OpenZeppelin"]}, {"title": "Inexplicit Struct Declaration", "body": "It is considered best practice to create a struct using the keys explicitly when instantiating it. This helps improve the readability and maintainability of the codebase. Struct usage with inexplicit declarations reduces code readability and is more error-prone. One instance of an inexplicit struct declaration is EthAPIBackend in backend.go.  Consider using the key-value syntax for explicitness.  Update: Resolved in pull request #55 at commit 79bab65.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#inexplicit-struct-declaration", "labels": ["OpenZeppelin"]}, {"title": "Unclear Calldata Byte Counting", "body": "gas estimation (without balance check) run mode, it counts the zero and non-zero bytes of the RLP-encoded transaction to approximate the  L1 fee cost. For these specific run modes, a  heuristic value of 80 is added to the number of  DataGas function to apply the different gas cost per each zero and non-zero byte. However, before the Regolith update, a magic value of 68 is added to the  Consider using a const value at the top of the file along with some context information instead of magic numbers. This will ensure the maintenance of the value as the protocol progresses. Moreover, consider renaming the Ones field of the RollupGasData struct to NonZero in order to better reflect its meaning.  Update: Acknowledged, will resolve.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#unclear-calldata-byte-counting", "labels": ["OpenZeppelin"]}, {"title": "Todo Comments in the Code", "body": "During development, having well-described TODO comments will make the process of tracking and solving them easier. Without such information, these comments might age and important information for the security of the system might be forgotten by the time it is released to production. These comments should be tracked in the project's issue backlog and resolved before the system deployment.  Consider removing all instances of TODO comments and instead tracking them in the issues backlog. Alternatively, consider linking each inline TODO comment to the corresponding issues backlog entry.  Update: Acknowledged, will resolve.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#todo-comments-in-the-code", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Double Check of SponsorPercent", "body": "Meta transactions are transactions where the another party other than the tx.origin can agree to sponsor the gas fees or a percentage of them on behalf of the user. The percent that a sponsor can sponsor up to should have an upper bound of 100%. In meta_transaction.go, this upper bound is checked in lines 100 to 102 in the DecodeMetaTxParams function.  In the DecodeAndVerifyMetaTxParams function, this DecodeMetaTxParams function is called and then subsequently the upper bound of 100% is checked once again. Consider removing this second check as it has already been performed.  Update: Resolved in pull request #57 at commit ff8f850.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#unnecessary-double-check-of-sponsorpercent", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Naming of File", "body": "deposit_tx.go file implements the  tx_access_list.go,  tx_blob.go,  tx_dynamic_fee.go, and  tx_legacy.go files.  Consider renaming the deposit_tx.go file to tx_deposit.go for consistency.  Update: Acknowledged, not resolved. The Mantle team stated:  No issues. This file is related to the depositTx data struct.", "html_url": "https://blog.openzeppelin.com/mantle-op-geth-audit#inconsistent-naming-of-file", "labels": ["OpenZeppelin"]}, {"title": "Data With Id 1 Cannot Be Retrieved From Mantle DA", "body": "RetrievalFramesFromDa function of  OP-Node implements the logic for retrieving frames from Mantle DA. It requires a  it is equal to or smaller than 0. As the  dataStoreId decreased by 1, attempting to retrieve data from Mantle DA with a  Consider removing the check from the RetrievalFramesFromDa function to permit the processing of a dataStoreId with a value of 0. In addition, since the dataStoreId is of type uint32 and so cannot be smaller than 0, the check becomes unnecessary.  Update: Resolved in pull request #117.  Low Severity", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#data-with-id-1-cannot-be-retrieved-from-mantle-da", "labels": ["OpenZeppelin"]}, {"title": "RequestL2Range Does Not Return Error if Channel Is Full", "body": "The RequestL2Range function queues a range of L2 blocks and returns early if the channel is full. However, it does not return an error in this case which means that the partial data will be processed.  Consider returning an error in case the channel is full in order to make callers aware.  Update: Acknowledged, not resolved. The Mantle team stated:  Not a valid issue.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#requestl2range-does-not-return-error-if-channel-is-full", "labels": ["OpenZeppelin"]}, {"title": "Witness Data Reader Skips the Last Line if There Is No New Line", "body": "ReadWitnessData function of OP-Chain-Ops utilizes  NewReader to iterate through the file and retrieve all entries. To read each line, the function employs  ReadString, which reads until a new line is encountered. However, this approach poses an issue  if the last line of the file lacks a new line character (as is the case for text file  causing an early break from the loop failing to read the last line.  Consider redesigning the function logic in such a way the last line will be read correctly even if it does not end with a new line.  Update: Acknowledged, not resolved. The Mantle team stated:  Acknowledged, only used for upgrading, will not fix it.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#witness-data-reader-skips-the-last-line-if-there-is-no-new-line", "labels": ["OpenZeppelin"]}, {"title": "Missing Type Conversion", "body": "NewWithdrawal function of OP-Chains-Ops returns a  Data field, which is of type  data of type  Consider converting the data parameter to the hexutil.Bytes type.  Update: Not resolved. The Mantle team stated:  Not a valid issue.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#missing-type-conversion", "labels": ["OpenZeppelin"]}, {"title": "Tests Panic and Fail", "body": "The proposed changes are not thoroughly covered by the test suite. In addition, there are multiple tests that fail, making it difficult to confirm the correctness of the implementation. The following components require additional testing:  op-node  op-batcher  op-chain-ops  Consider reviewing the test suite for the above mentioned components to improve code quality.  Update: Not resolved.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#tests-panic-and-fail", "labels": ["OpenZeppelin"]}, {"title": "Lack of Input Validation", "body": "The BaseFee parameter of type big.Int is checked for not being nil. However, a big.Int can be a negative number which does not make sense for BaseFee given that it should always be positive.  Consider checking the BaseFee parameter both for not being nil and being a positive number just like other big.Int parameters (e.g., chain ids are validated to be greater than 0 and not equal to 0).  Update: Acknowledged, will resolve.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#lack-of-input-validation", "labels": ["OpenZeppelin"]}, {"title": "The Mantle DA Status Is Not Cleared on OP-Batcher Start", "body": "Upon starting the OP-Batcher, the state is cleaned but the Mantle DA status is not.  Consider calling the clearMantleDAStatus function to clear the Mantle DA status.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#the-mantle-da-status-is-not-cleared-on-op-batcher-start", "labels": ["OpenZeppelin"]}, {"title": "Sleep Is Used to Wait for Channel Readiness", "body": "The sleep is used to wait 0.1 ms for sequencerCh and stepReqCh to be ready. While this might mitigate the issue in the testing environment, it might behave differently in the production environment where load might be different and thus the sleep time might not provide the desired effect.  Consider refactoring the code to avoid using sleep and instead using more reliable mechanisms to sync the channels.  Update: Not resolved. The Mantle team stated:  Not a valid issue.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#sleep-is-used-to-wait-for-channel-readiness", "labels": ["OpenZeppelin"]}, {"title": "Missing Connection Timeout for Contacting Mantle DA", "body": "The implemented connection to Mantle DA is missing a defined timeout option. This might lead to issues when servers accept connections but fail to respond to calls. There are the following occurrences of connections to Mantle DA:  Connection to Mantle DA in getFramesByDataStoreId of OP-Node  Connection to Mantle DA Indexer in getFramesFromIndexerByDataStoreId of OP-Node  Connection to Mantle DA Disperser in callEncode of OP-Batcher  Consider adding a timeout mechanism to the above listed connections.  Update: Acknowledged, will resolve.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#missing-connection-timeout-for-contacting-mantle-da", "labels": ["OpenZeppelin"]}, {"title": "Unencrypted Connection to Mantle DA", "body": "The implemented connection to Mantle DA is unencrypted. In a production environment, it is generally recommended to encrypt the connection. There are the following occurrences of unencrypted connections to Mantle DA:  Connection to Mantle DA in getFramesByDataStoreId of OP-Node  Connection to Mantle DA Indexer in getFramesFromIndexerByDataStoreId of OP-Node  Connection to Mantle DA Disperser in callEncode of OP-Batcher  Consider using encrypted connection instead.  Update: Acknowledged, will resolve.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#unencrypted-connection-to-mantle-da", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "Throughout the codebase, several typographical errors were found:  The constant name TxConfirmDataSubmiited should be TxConfirmDataSubmitted.  The comment openend should be opened.  This comment should be L1_MANTLE_TOKEN not L1_MANTLE_TOEKN.  Consider addressing the above typographical errors.  Update: Resolved in pull request #124.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Code Clarity", "body": "Throughout the codebase, several instances of redundant and unclear code were identified:  The NewMantleDataStore function defined in datastore.go always returns error as nil. Thus, it is not necessary to return it and check it later.  The NewMantleDataStoreConfig function returns a config and an error. However, the error is always nil which makes returning an error unnecessary.  The MockDataStoreConfig variable is not used anywhere and should be removed.  The marshalDepositVersion1 function is not used anywhere and can be removed.  The data from reply is retrieved twice in the getFramesByDataStoreId function. Consider calling GetData once and then use it in log.Debug and the return statement.  The data from reply is retrieved twice in the getFramesFromIndexerByDataStoreId function. Consider calling GetData once and then use it in log.Debug and the return statement.  The two if statements check for the BaseFee not being equal to 0. Consider moving the second if statement inside the first if statement block and removing the unnecessary check.  The ds.cfg.MantleDaSwitch if statement could be easier to read if it used an if statement with only true and false branches where the true branch contained code for handling MantleDA and the else branch contained code for Ethereum calldata.  One of the significant updates to the codebase was addition of the MNT value which changed the protocol to handle MNTValue and ETHValue. The correct encoding starts with the MNTValue parameter followed by ETHValue parameter. However, in multiple places, the structures are initilaized in the reverse order. While this does not cause an issue since the parameter names are used, it does hinder readability. Consider changing the order of the MNTValue and ETHValue parameters in the Decode and WithdrawalTransaction functions.  Update: Resolved in pull request #125.", "html_url": "https://blog.openzeppelin.com/mantle-node-batcher-proposer-and-tooling-incremental-audit#code-clarity", "labels": ["OpenZeppelin"]}, {"title": "Batch Commitments Can Make Use of Arbitrary Library", "body": "commitBatch function of the  _version parameter is used to define whether the version of the batch to commit is 0 or 1, as any other values will cause the  _version is 0, the  _version is 1, the function will use the  However, the sequencer can arbitrarily define the _version value. This means a version 0 batch commitment can be forced to follow a version 1 commitment path and vice versa. For instance, if a version 1 batch was committed, but the _version parameter is set to 0, the commitBatch function will gracefully pass without throwing any error.  Note that this scenario has a low likelihood since, at the time of this audit, the commitBatch function is guarded by the OnlySequencer modifier, which allows access only to the Scroll relayer EOAs. However, the severity of this issue could increase if additional parties are granted the sequencer role in the future.  Consider validating the _version parameter to match the version of the committed batch.  Update: Acknowledged, will resolve. The Scroll team added PR 1264 at commit c03cdad explaining the rationale of addressing this potential risk in the future:  We initially excluded the KZG commitment by assuming lack of presence of malicious Sequencer entities that collude with malicious Provers in the current threat model. Upon considering such a scenario (which is ruled out at present, but could eventually be possible in a decentralized setting), and as per cryptographic hygiene, we decided to include the KZG commitment (in the form of the blob's versioned hash, i.e. a hash of the commitment) while computing the Fiat-Shamir challenge. Since the blob's versioned hash is accepted as private witness to our circuits, we also include it in the preimage of the batch's public input hash (the public instance to our circuits).  Low Severity", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#batch-commitments-can-make-use-of-arbitrary-library", "labels": ["OpenZeppelin"]}, {"title": "Unchecked Blob-Proof Parameter", "body": "In the finalizeBatchWithProof4844 function of the ScrollChain contract, the _blobDataProof parameter should have a fixed length of 160 bytes, according to the function's documentation.  However, this length is not being checked, opening the possibility of injecting arbitrary bytes. While the likelihood of this scenario is low, it could introduce an unforeseen vulnerability if the client executing the finalizeBatchWithProof4844 function contains a bug in its implementation of the point evaluation precompile.  Consider reverting when the length of _blobDataProof does not match its specifications.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged, not resolved. The length is already checked by ErrorCallPointEvaluationPrecompileFailed. In the case of a wrong precompile implementation, such a vulnerability in L1 clients is not in the scope of this audit, since they would lead to major issues (erroneous hard fork) on L1, so they wouldn't just affect Scroll.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#unchecked-blob-proof-parameter", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "Throughout the codebase, there are several instances of incomplete docstrings.  The lastFinalizedBatchIndex, committedBatches, finalizedStateRoots, withdrawRoots, and isBatchFinalized functions in IScrollChain.sol explain what they return in the @notice tag. However, this should be specified under the @return tag.  In the legacyVerifiersLength function in MultipleVersionRollupVerifier.sol, the _version parameter and the return value are not documented.  In the getVerifier function in MultipleVersionRollupVerifier.sol, the return value is not documented.  In the updateVerifier function in MultipleVersionRollupVerifier.sol, the _version parameter is not documented.  In the importGenesisBatch function in ScrollChain.sol, the _batchHeader and _stateRoot parameters are not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of a contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #1256 at commit 5425ce7.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are several parts that do not have docstrings.  The IRollupVerifier interface in IRollupVerifier.sol  The IScrollChain interface in IScrollChain.sol  The MultipleVersionRollupVerifier contract in MultipleVersionRollupVerifier.sol  Note that, for example, the ScrollChain contract can inherit the docstrings from the IScrollChain interface using the @inheritdoc tag .  Consider thoroughly documenting all contracts, interfaces, events, and functions that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #1256 at commit 5425ce7.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Unused Named Return Variables", "body": "Named return variables are a way to declare variables that are meant to be used within a function body for the purpose of being returned as the function's output. They are an alternative to explicit in-line return statements.  Within ChunkCodecV1.sol, there are unused named return variables. For instance:  The _numBlocks return variable in the getNumBlocks function  The _numTransactions return variable in the getNumTransactions function  The _numL1Messages return variable in the getNumL1Messages function  Consider either using or removing any unused named return variables.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged, not resolved. This is not a priority. The naming convention is kept the same between versions for more readability in further code review.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#unused-named-return-variables", "labels": ["OpenZeppelin"]}, {"title": "State Variable Visibility Not Explicitly Declared", "body": "Throughout the codebase, there are state variables that lack an explicitly declared visibility:  The scrollChain state variable in MultipleVersionRollupVerifier.sol  The POINT_EVALUATION_PRECOMPILE_ADDR state variable in ScrollChain.sol  The BLS_MODULUS state variable in ScrollChain.sol  For clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #1256 at commit 5425ce7.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Unused Function With Internal Visibility", "body": "In both BatchHeaderV0Codec and BatchHeaderV1Codec libraries, the internal getSkippedBitmap function [1] [2] is not being used.  Consider removing any currently unused functions to improve the codebase's overall clarity, intentionality, and readability.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not fixed. This is not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#unused-function-with-internal-visibility", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact. For instance:  The BatchHeaderV0Codec library  The BatchHeaderV1Codec library  The ChunkCodecV0 library  The ChunkCodecV1 library  The IRollupVerifier interface  The IScrollChain interface  The MultipleVersionRollupVerifier contract  The ScrollChain contract  Consider adding a NatSpec comment containing a security contact on top of the contracts definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not fixed. This is not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Lack of Indexed Event Parameter", "body": "Consider indexing the version and startBatchIndex parameters in the UpdateVerifier event of the MultipleVersionRollupVerifier contract to enhance the ability of off-chain services to search and filter by version and batch interval.  Update: Acknowledged, not resolved. The Scroll team stated:  Acknowledged. Not fixed. This is not a priority.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#lack-of-indexed-event-parameter", "labels": ["OpenZeppelin"]}, {"title": "Misleading Comments", "body": "The following misleading and inconsistent comments have been identified in the codebase:  In line 49 of ChunkCodecV1.sol, \"should contain\" should be \"should be equal\".  In line 61 of MultipleVersionRollupVerifier.sol, \"lastest\" should be \"latest\" or \"last\".  Consider revising the comments to improve consistency and more accurately reflect the implemented logic.  Update: Partially resolved in pull request #1256 at commit 5425ce7. The fix did not address the first bullet point.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#misleading-comments", "labels": ["OpenZeppelin"]}, {"title": "Client Reported", "body": "Client Reported", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Calculation of Non-Skipped L1 Messages", "body": "In the _commitChunkV1 function, the _totalTransactionsInChunk is designated to hold the number of actual transactions in one chunk. To calculate the final value of _totalTransactionsInChunk, the number of non-skipped L1 messages is added to the number of L2 transactions.  To calculate the number of non-skipped L1 messages, on line 880, the value of the subtraction of startPtr from dataPtr is added to the result. The values of startPtr and dataPtr are computed as follows:  First, startPtr is set to dataPtr.  Then, the L1 message hashes are loaded to set the new value of dataPtr. Within the _loadL1MessageHashes function, the pointer value is increased by 32 bytes for every non-skipped L1 message.  However, the subtraction on line 880 is not taking into account the 32 bytes per message, resulting in a larger number of _totalTransactionsInChunk. This can cause the commit function to either fail for exceeding maxNumTxInChunk or return a wrong data hash if _totalTransactionsInChunk is still smaller than maxNumTxInChunk.  Update: Resolved in pull request #1232 at commit cbb65d7.", "html_url": "https://blog.openzeppelin.com/scroll-eip-4844-support-audit#incorrect-calculation-of-non-skipped-l1-messages", "labels": ["OpenZeppelin"]}, {"title": "Ability to Generate Valid Exclusion Proofs of Keys Which Are Present in the Trie", "body": "The MerkleDB allows for the creation of inclusion and exclusion proofs. An inclusion proof verifies the presence of a particular key-value pair in the trie under a specified root, whereas an exclusion proof confirms the absence of a particular key-value pair from the trie under the same root. Both proofs are constructed in a similar manner utilizing the Proof struct. For exclusion proofs, this structure's Key field is assigned the key intended to be demonstrated as absent from the trie, and the Value field is left blank. The Path represents a sequence of nodes leading from the trie's root to (the parent of) the position where the node would have been located if it were part of the trie.  During verification of the exclusion proof, the verifier constructs an empty trie and populates it with all the nodes in the Path. If the root ID of this constructed trie matches the expected root ID, the verifier can be sure that all the nodes in the Path are correct, confirming the absence of the specified key-value pair from the trie.  However, a malicious prover could forge a valid exclusion proof for a key-value pair that actually exists in the trie. This is done by removing the Value from the proof and reducing the length of the proof path by not including the parent of the node where the key-value pair would have been located. Given that the ID represents the hash of a node, and each node keeps the IDs of its children, the proof path does not actually have to reach this node as long as one of its parents is included in the proof path. Because of this, the trie created by the verifier will be identical to the upper half of the original trie and yield an identical root ID, and mistakenly pass the verification process.  Consider reviewing the proof verification mechanism to prevent the acceptance of falsified exclusion proofs for existing key-value pairs.  Update: Resolved in pull request #2789.  Low Severity", "html_url": "https://blog.openzeppelin.com/merkledb-audit#ability-to-generate-valid-exclusion-proofs-of-keys-which-are-present-in-the-trie", "labels": ["OpenZeppelin"]}, {"title": "RecordKeyChange Ignores ErrorNotFound", "body": "view.go gets called with the boolean parameter  error gets ignored.  would be registered in the v.changes.nodes mapping. This would be inconsistent as it should not be possible that there is no  Consider not ignoring the return error database.ErrNotFound and having the function return an error.  Update: Resolved in pull request #2743.", "html_url": "https://blog.openzeppelin.com/merkledb-audit#recordkeychange-ignores-errornotfound", "labels": ["OpenZeppelin"]}, {"title": "If There Is No Existing Child, the Function addPathInfo Will Use the Previous compressedKey", "body": "In the addPathInfo function, the verifier adds each node in the proof path to a new trie. For each node, the children are added if they are smaller than the lower bound or greater than the upper bound of the keys which are proven. While adding the children, the function will fetch the corresponding compressedKey before creating the child entry.  is declared outside the for loop, if there is no existing child in the constructing trie, the function  Consider if setting the compressedKey is absolutely necessary in the addPathInfo function. If it is, then ensure that it has the correct value for each child.  Update: Resolved in pull request #2777.", "html_url": "https://blog.openzeppelin.com/merkledb-audit#if-there-is-no-existing-child,-the-function-addpathinfo-will-use-the-previous-compressedkey", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Parameter Value for the recordKeyChange Function When Deleting a Node", "body": "The recordKeyChange function has a hadValue boolean parameter that is passed when calling the function getEditableNode. This is necessary to select which underlying database (valueNodeDB or intermediateNodeDB) should be used when looking up the node in the underlying database.  set to maybe.Nothing and then  recordNodeDeleted is called which calls  Consider reviewing how the hadValue parameter is being set instead of always using after.hasValue() to ensure that it is properly identifying whether a node did have a previous value.  Update: Resolved in pull request #2779.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/merkledb-audit#incorrect-parameter-value-for-the-recordkeychange-function-when-deleting-a-node", "labels": ["OpenZeppelin"]}, {"title": "Possible Optimization on Trie Building When Verifying a Proof", "body": "When a proof is verified, the function addPathInfo iterates from the last element len(proofPath) - 1 in the proof path and then proceeds backwards to the first element. This reverse order indicates that the trie is built by processing nodes starting from the leaves and moving upwards towards the root in a bottom-to-top approach. However, it is possible that building the trie from a top-to-bottom approach would be more efficient, as it would minimize the number of times that a node has to be created and then deleted to be replaced with a split.  Consider evaluating whether a top-to-bottom approach when processing the nodes in addPathInfo would be more efficient.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/merkledb-audit#possible-optimization-on-trie-building-when-verifying-a-proof", "labels": ["OpenZeppelin"]}, {"title": "ViewNodeCacheMiss Is Never Used", "body": "The ViewNodeCacheHit function is called when a node is successfully retrieved from the cache. However, the ViewNodeCacheMiss function is never used.  Consider calling the ViewNodeCacheMiss function when a node fails to be retrieved from the cache.  Update: Resolved in pull request #2781 and pull request #2844.", "html_url": "https://blog.openzeppelin.com/merkledb-audit#viewnodecachemiss-is-never-used", "labels": ["OpenZeppelin"]}, {"title": "Code Style Inconsistencies", "body": "Throughout the codebase, there are several places where code has an inconsistent style:  In the assignment of provenKey, the lastNode variable could be reused.  The range instruction could iterate over both the key-value pairs instead of only the key. This way, childEntry should not be declared separately.  Consider reviewing the entire codebase to improve consistency and refactor the code where possible.  Update: Resolved in pull request #2783.", "html_url": "https://blog.openzeppelin.com/merkledb-audit#code-style-inconsistencies", "labels": ["OpenZeppelin"]}, {"title": "Misleading Comments", "body": "The following misleading and inconsistent comments have been identified in the codebase:  According to this comment, visitPathToKey should return the nodes along the path. Instead, the visitNode function is called on each node along the path and visitPathToKey either returns err or nil.  The comment in getValue refers to a local \"copy of the key\", but it should refer to a \"copy of the value at the key\".  According to this comment, compressNodePath is merging nodes without a value and a single child recursively. However, it is only merging one single node with its parent.  The documentation of getProof mentions a non-existent bytesPath variable.  This comment in verifyProofPath says \"should store a value\". However, it should be \"should not store a value\".  Consider revising the comments to improve consistency and more accurately reflect the implemented logic.  Update: Resolved in pull request #2780.", "html_url": "https://blog.openzeppelin.com/merkledb-audit#misleading-comments", "labels": ["OpenZeppelin"]}, {"title": "Variable Shadowing", "body": "Through the codebase, there are multiple instances of variable shadowing where a variable takes the name of an existing function:  The newView variable in NewView is shadowing the newView function.  The newView variable in newView is shadowing the newView function.  The newView variable in newViewWithChanges is shadowing the newView function.  While it does not affect the code as the shadowing only happens in the scope of the function, nonetheless, consider following the best practices and using a different variable name.  Update: Resolved in pull request #2784.", "html_url": "https://blog.openzeppelin.com/merkledb-audit#variable-shadowing", "labels": ["OpenZeppelin"]}, {"title": "Potential Denial of Service Due to Limited Cache for Validator Signatures", "body": "Relayers request validators to sign valid warp messages. Afterwards, they aggregate the BLS signatures from all signers, and submit a transaction to the destination chain with the aggregated signatures encoded in the AccessList as a predicate.  Validators store unsigned warp messages in persistent storage. In addition, two limited-size caches are used to store signatures and unsigned warp messages, which are both cleared upon a system restart. Signatures are only cached due to the fact that the validator BLS keys may change during a restart, which would result in a different signature for the same message and thus render the signatures in the cache invalid.  Given that generating signed messages is computationally expensive for the validators, it is possible for a malicious relayer to exploit the cache limitation. This can be done by requesting signatures for a large number of warp messages, thereby exceeding the cache size. The malicious validator can keep cycling the large number so that validators keep having to compute the signature for a message and can't simply return the response from the cache.  This can consume the network's resources and potentially degrade the performance or availability of the network.  Consider setting up network monitoring and expanding the current DoS protection measures to prevent this scenario.  Update: Acknowledged, not resolved.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/ava-warp-messaging-audit#potential-denial-of-service-due-to-limited-cache-for-validator-signatures", "labels": ["OpenZeppelin"]}, {"title": "Inefficient Struct Memory Layouts", "body": "Several structs within the codebase are not optimally organized, leading to wasted memory due to padding and alignment. This results in higher-than-necessary memory usage, which can affect performance and resource utilization:  signatureAggregationJob: 104 pointer bytes, could be 40  AggregateSignatureResult: 24 pointer bytes, could be 8  Aggregator: 64 pointer bytes, could be 32  signatureJob: 56 pointer bytes, could be 32  AddressedPayload: 104 pointer bytes, could be 32  BlockHashPayload: 40 pointer bytes, could be 8  WarpMessage: 18: 112 pointer bytes, could be 8  SendWarpMessageInput: 64 pointer bytes, could be 8  Consider reordering struct fields to place the largest data types at the beginning and group fields of similar sizes together. The alignment can be verified with the fieldalignment tool. This will help minimize padding and optimize memory usage.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/ava-warp-messaging-audit#inefficient-struct-memory-layouts", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Assignment of Empty Signature", "body": "When a relayer asks a node for the signature of a specific unsigned warp message, the OnSignatureRequest function is called. This function will retrieve a BLS signature for a requested message ID. The function will ask the backend for a signature by calling the GetSignature function. In case this function returns an error, the signature is set to an empty byte array of 96 bytes. However, this assignment is unnecessary as the GetSignature function of the backend already sets the signature to an empty byte array of 96 bytes in case the unsigned warp message is not found or the backend fails to sign it.  Consider removing the assignment of the empty byte array in the OnSignatureRequest function of the signatureRequestHandler struct.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/ava-warp-messaging-audit#unnecessary-assignment-of-empty-signature", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Error", "body": "The StateRootHashInvalid error message does not match the error that it is describing.  For instance, it is possible for both parameters to be empty. Even if the _submissionData.parentStateRootHash is non-empty, it would be more natural to treat it as the expected value. However, in practice, this is actually checking the validity of the submitted dataParentHash parameter.  Consider updating the error accordingly.  Update: Acknowledged, not resolved. The Linea team stated:  This is going to be removed with the next gas optimization.", "html_url": "https://blog.openzeppelin.com/linea-blob-submission-audit#incorrect-error", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "Throughout the codebase, the event parameters are not documented.  Consider thoroughly documenting all events and their parameters. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #39. The Linea team stated:  All events now have better NatSpec. Note that in two of the files, the order has been shuffled to be: Structs, Events, Errors, and then Functions to be consistent with the rest of the codebase.", "html_url": "https://blog.openzeppelin.com/linea-blob-submission-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Polynomial Encoding", "body": "The submitData function interprets the compressed data as polynomial coefficients. On the other hand, the submitBlobData function uses EIP-4844 blobs which implicitly interpret the data as polynomial evaluations. The Linea team have indicated that the circuit includes an Eip4844Enabled flag to handle this difference.  However, this flag is not included in the shnarf, which is used to derive the public input, due to which the prover can select the opposite value. By itself, this would cause the circuit to derive an incorrect polynomial from the provided data. However, if the prover modified the provided L2 transaction data so the correct polynomial was derived, it would successfully pass the proof-of-equivalence check with incorrect transactions.  In practice, these transactions will likely be malformed and will not have valid signatures. Whether the proof will succeed depends on the details of the circuit. If the proof does succeed, the prover can use this mechanism to discard valid transactions that were correctly published.  In either case, in the interest of simplicity and reducing the attack surface, consider including the Eip4844Enabled flag in the shnarf and modifying the circuit to retrieve it from the public input.  Update: Acknowledged, will resolve. The Linea team stated:  Acknowledged: Currently being resolved outside of the contract with the circuit, prover, and other components that will be enforced in decentralized scenarios.", "html_url": "https://blog.openzeppelin.com/linea-blob-submission-audit#inconsistent-polynomial-encoding", "labels": ["OpenZeppelin"]}, {"title": "Missing or Misleading Documentation", "body": "The following code instances are misleading or would benefit from additional documentation:  The systemMigrationBlock state variable in the L1MessageService contract could be documented or renamed to explain that it is now deprecated.  The _currentDataHash parameter is incorrectly described as an aggregated proof.  The finalization data hashes list is described as optional but it must be non-empty  Consider updating these instances to improve the clarity of the codebase.  Update: Resolved in pull request #36. The Linea team stated:  The _currentDataHash has been corrected, the systemMigrationBlock has had comments added around future use, and dataHashes has been marked as required.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/linea-blob-submission-audit#missing-or-misleading-documentation", "labels": ["OpenZeppelin"]}, {"title": "Unused Errors and Events", "body": "Following the deprecation of V1, the following issues and events are now unused and could be removed:  The SystemMigrationBlockInitialized event in IL1MessageService.sol.  The BlockFinalized event and BlockTimestampError error in IZkEvmV2.sol.  The ServiceHasMigratedToRollingHashes error and ServiceVersionMigrated event in IL2MessageManager.sol.  Consider removing these instances to improve the clarity of the codebase.  Update: Partially resolved in pull request #38. The Linea team stated:  Errors were removed along with the initialized event. The two other events (BlockFinalized) and (ServiceVersionMigrated) were left with comments regarding their usage. They were left primarily for existing consumer usage for past events.", "html_url": "https://blog.openzeppelin.com/linea-blob-submission-audit#unused-errors-and-events", "labels": ["OpenZeppelin"]}, {"title": "Non-Standard Storage Gaps", "body": "When using the proxy pattern for upgrades, it is a common practice to include storage gaps in parent contracts to reserve space for potential future variables. The size is typically chosen so that all contracts have the same number of variables (usually 50). In this way, the expected layout can be deduced without knowing the full contract history. However, the codebase uses inconsistent sizes given that all of them declare a gap storage of 50 positions, regardless of how many variables were declared in the contracts. In addition, the code under review does not reduce the LineaRollup contract's gap size despite introducing a new variable. This does not cause inconsistencies because the LineaRollup contract is the last one in the inheritance chain, making the gap unnecessary.  Consider documenting the existing gap sizes in deployed parent contracts to avoid confusion when updating them. Furthermore, consider removing the unnecessary gap in the LineaRollup contract, which can be reintroduced if future upgrades inherit from this contract. Alternatively, consider reducing the gap size so the whole contract uses 50 storage slots.  Update: Resolved in pull request #37. The Linea team stated:  We removed the gap in LineaRollup.sol and documented the specific numbers of the gaps at each location. Some additional gap comments were made for previous ones that we could not alter.", "html_url": "https://blog.openzeppelin.com/linea-blob-submission-audit#non-standard-storage-gaps", "labels": ["OpenZeppelin"]}, {"title": "Incorrect SHA256 Implementation", "body": "We identified the following invalid behaviors in the preprocess function of the SHA256L implementation.  Incorrect Implementation  The preprocessing step involves padding the input to ensure that, along with the final 8-byte length field, it occupies an integer number of 64-byte blocks. However, when an extra block is needed, only 56 extra zero bytes (rather than 64) are added, resulting in the incorrect hash output. This will occur whenever the length of the input (in bytes) is higher than 55 modulo 64. In the current codebase, neither use case triggers this error.  Unsafe Memory Assumptions  The function implicitly assumes the input was the last value allocated, but this is not necessarily true. As a result, the input padding will overwrite any memory that is saved after the input. The return values are also placed [number padding bytes] after the current free memory pointer, which is an arbitrary position if the free memory pointer did not start at the padding location.  Imprecise Return Values  The output array has an entry for every 4-byte value in the input, but its length is set to 32 regardless of the input size. Its first record is set to 16 * rounds, and then immediately overwritten by the loop. The function also allocates an extra word for the returned array.  Inefficient Algorithm  The k value is the size of the whole input including the padding, but it is also used as the amount of zeroes to add. The function only needs to pad to the nearest 64-byte block but it could end up padding for several blocks.  Consider updating the algorithm accordingly. In addition, consider using the Solidity sha256 function for networks that support it.  Update: Partially resolved in pull request #1. The Particle team stated:  Indeed, according to the current implementation, if the user enters more than 55 bytes, there will be an erroneous result. However, we do not believe that it will happen in our scenario. As such, we have only fixed the following high-severity sub-issues:  Incorrect Implementation  Imprecise Return Values  However, we are not addressing following sub-issues for now:1. Unsafe Memory Assumptions2. Inefficient Algorithm  These are primarily optimization issues so we are not in a hurry to solve them at the moment. May be we will fix them someday in the future or switch to the native SHA256 implementation by the layer 2.  Low Severity", "html_url": "https://blog.openzeppelin.com/particle-network-btc-smart-account-audit#incorrect-sha256-implementation", "labels": ["OpenZeppelin"]}, {"title": "Misleading Comments", "body": "We identified the following misleading comments:  The reinitializer modifier in CustomSlotInitializable has a comment stating that setting the version number to 255 will prevent any future reinitialization. However, as a 64-bit number, it can still be reinitialized up to \"version\" 264 - 1.  The _validateSignature function in LightAccount has a comment describing an \"Ethereum Signed Message\" envelope, but it is actually a \"Bitcoin Signed Message\" envelope.  Consider updating these comments accordingly.  Update: Acknowledged, will resolve. The Particle team stated:  This issue is not urgent and will be resolved in the future.", "html_url": "https://blog.openzeppelin.com/particle-network-btc-smart-account-audit#misleading-comments", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "Throughout the codebase, there are multiple components that do not have docstrings:  The receive function in LightAccount.sol  The accountImplementation immutable in LightAccountFactory.sol  The round function in SHA256L.sol  Moreover, the Initialized event does not document the version parameter, while the _transferOwnership function and the hash function do not document their parameters and return values.  Consider thoroughly documenting all events and functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Acknowledged, will resolve. The Particle team stated:  This issue is not urgent and will be resolved in the future.", "html_url": "https://blog.openzeppelin.com/particle-network-btc-smart-account-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Lack of Tests", "body": "Consider introducing a testing suite, particularly for a complex system like a smart account. It should cover functional tests of the main use cases as well as security tests for operations that should be rejected.  Update: Acknowledged, will resolve. The Particle team stated:  This issue is not urgent and will be resolved in the future.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/particle-network-btc-smart-account-audit#lack-of-tests", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Furthermore, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact:  The CustomSlotInitializable abstract contract  The LightAccount contract  The LightAccountFactory contract  The SHA256L library  Consider adding a NatSpec comment containing a security contact above the contract definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, will resolve. The Particle team stated:  This issue is not urgent and will be resolved in the future.", "html_url": "https://blog.openzeppelin.com/particle-network-btc-smart-account-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Code Simplifications", "body": "the getMessageHash function instead of  reimplementing the same logic. Moreover, it appears to use an unnecessary layer of indirection. The  encodeMessageData function function creates an EIP-712 encoding of an arbitrary message wrapped in a  For simplicity, consider defining the LightAccountMessage struct as directly containing the bytes32 digest.  Update: Acknowledged, will resolve. The Particle team stated:  This issue is not urgent and will be resolved in the future.", "html_url": "https://blog.openzeppelin.com/particle-network-btc-smart-account-audit#code-simplifications", "labels": ["OpenZeppelin"]}, {"title": "Missing Namespaced Storage NatSpec Tag", "body": "ERC-7201 specifies that namespaced storage structs be annotated with the NatSpec tag @custom:storage-location <FORMULA_ID>:<NAMESPACE_ID>, where <FORMULA_ID> identifies a formula used to compute the storage location where the namespace is rooted, based on the namespace id. There are multiple namespaced storage structs that do not have these tags:  LightAccount.LightAccountStorage  CustomSlotInitializable.CustomSlotInitializableStorage  However, it is clear from the code that they follow ERC-7201's formula for computing storage locations.  For improved code clarity and for tooling integration, consider adding ERC-7201 annotations to these storage structs.  Update: Acknowledged, will resolve. The Particle team stated:  This issue is not urgent and will be resolved in the future.", "html_url": "https://blog.openzeppelin.com/particle-network-btc-smart-account-audit#missing-namespaced-storage-natspec-tag", "labels": ["OpenZeppelin"]}, {"title": "Malicious User Can Increase the Gas Cost of Verification", "body": "The ZkTrieVerifier library verifies proofs that come from the Scroll L2 node which uses a sparse binary Trie as the data structure. For the verification process, the proofs have the necessary node hashes to reconstruct the root hash based on the queried leaf. The walkTree method used for going through all the levels of the Trie uses the bits of the key provided to define where the path should continue (left or right). However, a malicious user can influence how many levels the proof must go through by predicting addresses (or storage slots) that would branch the Trie until a certain depth.  Even though artificially increasing the proof's depth of a certain account or storage will not cause a DoS scenario, since the depth can still reach the maximum depth size in the worst-case scenario, artificially increasing the proof's depth will increase the number of iterations the walkTree method has to perform in order to reach the respective leaf. If protocols that use this verifier limit the gas used on-chain to perform such a verification (to a reasonable value), then a malicious user might be able to increase it for a particular transaction by reaching a similar hashed key to a certain depth in the Trie.  As such, consider letting users and developers know about this possible attack vector so as to not limit the gas used in such scenarios. Otherwise, the verification might fail.  Update: Resolved in pull request #1135 at commit 265800f.  Low Severity", "html_url": "https://blog.openzeppelin.com/scroll-zktrieverifier-audit#malicious-user-can-increase-the-gas-cost-of-verification", "labels": ["OpenZeppelin"]}, {"title": "Node Type Check Uses Underflow to Define Range", "body": "In the walkTree function of the ZkTrieVerifier library, a requirement checks whether the nodeType is within the expected range. However, the operation is done by subtracting 6 units from the nodeType and then checking if the resulting value is less than 4. In the expected range of 6 to 9, this operation does not present an issue, but for node types below 6, the requirement relies on an underflow that would make the result greater than 4, reverting the validation.  To follow the best practices for reducing error-proneness, lowering the attack surface, and improving the readability of the code, consider splitting the requirement into two different operations to validate the respective nodeType range.  Update: Acknowledged, not resolved. The Scroll team stated:  No node types are below 6, so the current code works as expected.", "html_url": "https://blog.openzeppelin.com/scroll-zktrieverifier-audit#node-type-check-uses-underflow-to-define-range", "labels": ["OpenZeppelin"]}, {"title": "Use of Implicit Default rootHash and expectedHash", "body": "for loop over the nodes and implicitly returns the default value of 0 for the  verifyStorageProof function to continue with the validation. However, using the default value without any explicit assignment, especially when handling assembly code and memory pointers, might result in undesired outcomes.  As such, to reduce the attack surface, consider explicitly handling the scenario in which the walkTree function does not have a proof to go through.  Update: Acknowledged, not resolved. The Scroll team stated:  We are sure that the default value of rootHash and expectedHash is zero, so no assignment is needed.", "html_url": "https://blog.openzeppelin.com/scroll-zktrieverifier-audit#use-of-implicit-default-roothash-and-expectedhash", "labels": ["OpenZeppelin"]}, {"title": "Unbounded walkTree Due to Underflow", "body": "walkTree function calculates the  nodes as the length passed with the proofs, minus one. However, if a user sets the length as if there are no proofs, the  Although this issue does not cause a problem by itself, as it will probably revert due to checks during the walkTree function, it can still be used as a tool to craft a malicious proof with the intention of triggering another issue.  In favor of reducing the attack surface, consider checking the lengths against the passed proofs.  Update: Acknowledged, not resolved. The Scroll team stated:  If a user sets the length as if there are no proofs, the function will revert. So, it will not be a problem.", "html_url": "https://blog.openzeppelin.com/scroll-zktrieverifier-audit#unbounded-walktree-due-to-underflow", "labels": ["OpenZeppelin"]}, {"title": "Trie Depth Is Not Explicitly Capped", "body": "By using the Poseidon Hash, the node uses a maximum depth of 248 levels. However, the ZkTrieVerifier library does not impose a limit on the first byte that represents the length added to the proofs, making it possible to pass proofs with a length that exceeds the limit and continue with the operation. Even though it is challenging to craft a proof that would allow a user to pass the validations performed when constructing the leaf hash, not asserting the length exposes some un-mitigated attack surface which could be targeted by a malicious user in a different attack.  Consider asserting that the maximum depth is not exceeded by the crafted proof.  Update: Resolved in pull request #1137 at commit daaf600.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/scroll-zktrieverifier-audit#trie-depth-is-not-explicitly-capped", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Naming Convention", "body": "The ZkTrieVerifier library uses two naming conventions for the functions' names. In particular, functions associated with the hashing operation (poseidon_hash and the hash_uint256 functions) are written in snake case, whereas other functions such as the walkTree function are written in camel case.  Consider using a consistent naming style throughout the codebase.  Update: Resolved in pull request #1138 at commit db8f65d.", "html_url": "https://blog.openzeppelin.com/scroll-zktrieverifier-audit#inconsistent-naming-convention", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Integer Base in Inline Assembly", "body": "The ZkTrieVerifier library makes use of inline assembly for multiple features. When performing these calculations, the decimal and hexadecimal integer bases are used interchangeably. For instance, 1 and 0x1 are used to move the memory pointer.  Consider sticking to one integer base for memory pointer movements and any other operations to improve the readability of the codebase and prevent calculation errors.  Update: Partially resolved in pull request #1139 at commit d280b6c. There are still cases, such as the addition in line 99, that are not consistent with the rest of the code. The Scroll team stated:  depth is not pointer, so we use 1 instead of 0x01.", "html_url": "https://blog.openzeppelin.com/scroll-zktrieverifier-audit#inconsistent-integer-base-in-inline-assembly", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Function Visibility", "body": "The verifyZkTrieProof function of the ScrollChainCommitmentVerifier contract is not called internally by this contract.  Consider setting this function's visibility to external instead of public in order to reduce the attack surface.  Update: Resolved in pull request #1140 at commit bb781f1. The verifyStateCommitment function now uses the verifyZkTrieProof function from the ScrollChainCommitmentVerifier contract instead of calling the library directly.", "html_url": "https://blog.openzeppelin.com/scroll-zktrieverifier-audit#incorrect-function-visibility", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Check in UniswapFlashswapDirectMintHandler", "body": "The check against maxResultingDebt in the UniswapFlashswapDirectMintHandler contract is incorrect and may mislead users. The intent for this handler is to help leverage positions within the wstETH / weETH market. The maxResultingDebt parameter is intended to limit the borrowed amount for the user, measured in terms of the \"base asset\".  Here, the base asset should be wstETH. However, the check compares this value to an amount of wETH. Since wETH units are worth slightly less than wstETH, this will have the effect of causing reverts more often for users as the threshold for \"max resulting debt\" will be lower than they are anticipating. This will result in a poor user experience overall, as well as potential errors in calculations from trying to convert to a reasonable wstETH value.  Consider either changing the docstrings or name of the variable to make it clear that this value represents wETH. Alternatively, consider converting the amountWethToFlashloan value to an equivalent value of wstETH before the check.  Update: Resolved in pull request #52.", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#incorrect-check-in-uniswapflashswapdirectminthandler", "labels": ["OpenZeppelin"]}, {"title": "UniswapFlashswapDirectMintHandler Unusable When Not Leveraging", "body": "clause that is unreachable. This is due to the fact that the  getEthAmountInForLstAmountOut function in the  1 or greater. Intuitively, for an amount \"out\" of 0, the amount \"in\" should also be 0. However, due to  the addition of 1, this is not possible. The  amountLrt is 0, and when this is the case, we will get an  Not only does this mean that an unnecessary flash-borrow will occur, but the transaction execution will fail as well. During the flashswap callback, the contract will attempt to mint the collateral asset using the value 1. This will eventually revert inside the eETH liquidity pool contract since the division in _sharesForDepositAmount returns 0. This prevents the contract from functioning under normal circumstances if a user were to use flashswapAndMint for depositing collateral and borrowing. Note that this is technically not a given and is dependent on the number of shares being less than the total pooled ETH in the eETH contract.  Consider adding an early-escape check within getEthAmountInForLstAmountOut, which returns 0 when lrtAmount is 0.  Update: Resolved in pull request #53.  Low Severity", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#uniswapflashswapdirectminthandler-unusable-when-not-leveraging", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are several parts that do not have docstrings:  Lines 4-9 in IRedstone.sol  Lines 72-80 in IonHandlerBase.sol  Lines 6-116 in ProviderInterfaces.sol  Lines 47-48 in UniswapFlashswapDirectMintHandler.sol  Line 49 in UniswapFlashswapHandler.sol  Lines 15-39 in WeEthHandler.sol  Lines 69-81 in YieldOracle.sol.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Partially resolved in pull request #54. the following instances remain unresolved:  Lines 72-80 in IonHandlerBase.sol  Lines 6-116 in ProviderInterfaces.sol  Lines 47-48 in UniswapFlashswapDirectMintHandler.sol  Line 49 in UniswapFlashswapHandler.sol  Lines 69-81 in YieldOracle.sol  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Unused Return Variable", "body": "Named return variables are a way to declare variables that are meant to be used within a function's body for the purpose of being returned as the function's output. They are an alternative to explicit in-line return statements.  The amountIn return value for the _initiateFlashSwap function in the UniswapFlashswapDirectMintHandler contract is being set but not used in the rest of the function or in the _flashswapAndMint function it returns to.  Consider either using or removing any unused named return variables.  Update: Resolved in pull request #52.", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#unused-return-variable", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "Consider correcting the following typographical errors to improve the readability of the codebase:  At line 216 of UniswapFlashswapDirectMintHandler.sol, \"the a\" should be \"the\".  At lines 222 and 223 of UniswapFlashswapDirectMintHandler.sol, \"eth\" should be \"mint asset\".  At lines 43 and 44 of WeEthWstEthReserveOracle.sol, \"rate between ETH and weETH\" should be \"rate between wstETH and weETH\".  Update: Resolved in pull request #54.", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Unused Variables", "body": "Throughout the codebase, there are multiple unused variables:  The flashloanInitiated state variable in the UniswapFlashswapDirectMintHandler contract.  The PROTOCOL_FEED state variable in the WeEthWstEthReserveOracle contract.  The addresses variable in the _flashswapAndMint function of the UniswapFlashswapDirectMintHandler contract is declared and initialized, but otherwise unused  To improve the overall clarity, intentionality, and readability of the codebase, consider removing any unused variables.  Update: Resolved in pull request #54.", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#unused-variables", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact:  The IRedstonePriceFeed contract  The IReserveFeed contract  The IStEth interface  The IWstEth interface  The IStaderStakePoolsManager interface  The IStaderConfig interface  The IStaderOracle interface  The IETHx interface  The ISwEth interface  The IWeEth interface  The IEEth interface  The IEtherFiLiquidityPool interface  The WeEthHandler contract  Consider adding a NatSpec comment containing a security contact above the contract definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Partially resolved in pull request #54. The instances pertaining to the interfaces are not fixed.", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Client Reported", "body": "Client Reported", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Liquidation Contract Incompatible With IonPool When ilkIndex Less Than Three", "body": "implicitly expected to have lengths of at least three. However, the lengths of these arrays are  compared to the ilkCount returned from the input instance of the  assign the MAX_DISCOUNT_ state variables with an out-of-bounds error for the array.  Consider refactoring the constructor to accept any non-zero number of ilk indices.  Update: Resolved in pull request #59 at commit 8c4f615.", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#liquidation-contract-incompatible-with-ionpool-when-ilkindex-less-than-three", "labels": ["OpenZeppelin"]}, {"title": "Reserve Factor Incorrect Decimals Validation", "body": "Within the InterestRate contract, the reserveFactor uses 4 decimal places of precision. However, the constructor for the contract incorrectly validates that the input has 27 (RAY) decimals of precision.  Consider updating the validation in the constructor to check for 4 decimals of precision.  Update: Resolved in pull request #58.", "html_url": "https://blog.openzeppelin.com/ion-protocol-weeth-integration-audit#reserve-factor-incorrect-decimals-validation", "labels": ["OpenZeppelin"]}, {"title": "Operations Can Throttle Paymasters [core]", "body": "Note: this error was present in the previous audit commit but was not identified by the auditors at the time.  The simulateValidation function of EntryPointSimulations combines the validity conditions of the account and the paymaster to determine when the operation is considered valid by both parties. However, the aggregator parameter is semantically overloaded, to represent either a signature success flag or an aggregator address, and this is not completely handled in the combination.  Specifically, the combined aggregator is either the value chosen by the account, or if that is zero, the value chosen by the paymaster. This leads to two possible mistakes:  an account's \"signature success\" flag (0) would be overwritten by a paymaster's non-zero aggregator parameter.  a paymaster's \"signature failed\" flag (1) would be ignored in the presence of an account's non-zero aggregator.  The first condition would be identified by the rest of the security architecture and likely has minimal consequences. However, the second condition would cause bundlers to include unauthorized operations in a bundle and then blame the paymaster for the failure. This would cause paymasters to be unfairly throttled.  Consider updating the simulation to require paymasters to only return 0 or 1 as the aggregator parameter, and to ensure that the \"signature failed\" flag (1) always takes precedence.  Update: Resolved in pull request #406. The Ethereum Foundation team stated:  Remove the simulateValidation code to intersect the paymaster and account time-ranges (and signature validation). This calculation should be done off-chain by the bundler. The simulation functions now return the \"raw\" validationData, as returned by the account and paymaster (separately).", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#operations-can-throttle-paymasters-[core]", "labels": ["OpenZeppelin"]}, {"title": "Ineffective Unused Gas Penalty [core]", "body": "Operations specify several gas limits for each part of the lifecycle. The callGasLimit and paymasterPostOpGasLimit can be collectively denoted the \"execution gas limit\". This is because these values are related to the operation's execution and the amount of gas consumed in this phase cannot be reliably estimated during simulation.  Once an operation is executed, any unused execution gas is partially confiscated, and given to the bundler. This discourages operations that specify a much larger execution gas limit than they need, which consumes excess space in the bundle and prevents other valid operations from being included.  However, the paymasterPostOpGasLimit is not penalized when the context is empty. Although this corresponds to a situation where the postOp function is not called, the gas limit is still reserved, so it still consumes space in the bundle.  Consider always including the paymasterPostOpGasLimit in the penalty calculation.  Update: Resolved in pull request #407.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#ineffective-unused-gas-penalty-[core]", "labels": ["OpenZeppelin"]}, {"title": "Unattributable Paymaster Fault [core]", "body": "Note: this error was present in the previous audit commit but was not identified by the auditors at the time.  The paymaster's validatePaymasterUserOp function is executed inside a try-catch block to trap any errors. However, this does not catch errors that occur when decoding the return values. This means that a malicious paymaster could provide an incompatible return buffer (e.g., by making it too short) in order to trigger a revert in the main call frame.  Importantly, this bypasses the FailedOpWithRevert error. This means that if a paymaster passes the operation simulations and triggers this error inside a bundle simulation, the bundler cannot use the revert message to immediately identify the malicious paymaster, and will spend excessive computation to construct a valid bundle.  Fortunately, as the Ethereum Foundation pointed out to us, bundlers are now expected to use debug_traceCall, and could identify the failing operation from the trace.  Consider using a low-level call and explicitly checking the size of the return data. Moreover, consider using this pattern generally with the other try-catch blocks that require return values to be decoded.  Update: Resolved in pull request #429. The Ethereum Foundation team stated:  The paymaster (and account) can use assembly code to create a response that is un-parseable by solidity, and thus cause a revert that can't be caught by solidity's try/catch and thus can't be mapped to a FailedOp revert reason. Instead of performing low-level call using abi.encodeCall, and later decoding the response manually using assembly code, we require the bundler to use the traceCall of the bundle (which is already mandatory), and find the root cause of the revert, as the last called entity just prior to this revert.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#unattributable-paymaster-fault-[core]", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Price Precision [samples]", "body": "The TokenPaymaster appears to be in the middle of transitioning between two choices for precision.  The PRICE_DENOMINATOR constant defines a scaling factor of 26 decimals. The priceMarkup should have the same precision but is described as having 6 decimals.  The same scaling factor is used in the OracleHelper contract. As such, the priceUpdateThreshold should have the same precision, but it is instead forced to have 6 decimals.  In the second case, the threshold effectively rounds to zero and an update will be triggered on every change. Consider using 26 decimals of precision throughout the contract.  Update: Resolved in pull request #428.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#inconsistent-price-precision-[samples]", "labels": ["OpenZeppelin"]}, {"title": "ERC Recommendations [core]", "body": "Procedural Update  The validateUserOpSignature function allows the aggregator to replace the operation signature. If this happens, the bundler should re-run validateUserOp with this new signature to ensure that it succeeds and returns the same aggregator. Otherwise, the operation might fail unexpectedly in the bundle.  Update Specification  There are places where the specification references outdated features of the system and thus should be updated:  References to UserOperation should be replaced with PackedUserOperation. This includes updating the field descriptions and all the affected interfaces.  The references to ValidationResultWithAggregator (1, 2) should be removed.  The specification should mention the new IAccountExecute interface and how it can be used.  Technical Corrections  The specification requires the EntryPoint to fail if the account does not exist and the initCode is empty. It actually just skips validation when the initCode is empty (although it would revert later when attempting to interact with the empty address). While failing explicitly would typically be recommended, this check has been moved to the simulation. For completeness, this should be explained in the ERC.  The specification incorrectly claims that the postOpReverted mode implies that the user operation succeeded.  The specification claims that the paymaster's addStake function must be called by the paymaster. However, it is called by the paymaster's owner address.  The specification requires the EntryPoint to validate the aggregate signature after performing the individual account validations. It is actually performed beforehand.  Additional Context  The specification mentions some examples of how to attribute AAx errors. It would benefit from a complete table explaining all the error code prefixes.  Update: Resolved in pull request #412.  Low Severity", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#erc-recommendations-[core]", "labels": ["OpenZeppelin"]}, {"title": "Temporarily Unusable ETH [samples]", "body": "The TokenPaymaster includes a mechanism to receive ETH donations. However, they cannot be used or withdrawn until they are deposited to the EntryPoint. Therefore, the ETH remains unusable until the deposit balance falls low enough and user operation triggers the refill mechanism.  Since the ETH will eventually become a deposit with the EntryPoint, consider removing this function and instead requiring donations to use the existing deposit mechanism.  Update: Resolved in pull request #420, pull request #433. The Ethereum Foundation team stated:  TokenPaymaster receives eth, but that's not for \"donations\" but part of its business logic: when converting tokens, it converts them to WETH and then to ETH, which is sent through this \"receive\" function. Then the paymaster uses these funds to replenish its deposit in the EntryPoint. We did add a method so that it would be able to withdraw any Eth that got accumulated there.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#temporarily-unusable-eth-[samples]", "labels": ["OpenZeppelin"]}, {"title": "Imprecise Refresh Requirement [samples]", "body": "The OracleHelper contract is configured for a price feed that updates every day but still accepts prices that are two days old. On a well-functioning feed, the price should never be more than one day old.  Consider using this more restrictive requirement (with a possible small buffer).  Update: Resolved in pull request #424.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#imprecise-refresh-requirement-[samples]", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Oracle Configuration [samples]", "body": "In the OracleHelper contract, when the tokenOracle price is already based in the native asset, the nativeOracle is unused. However, it must still be configured to a valid contract with a decimals function.  Consider requiring it to be the zero address in this case.  Update: Resolved in pull request #423.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#inconsistent-oracle-configuration-[samples]", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Generalization [samples]", "body": "native asset and a  bridging asset, but also explicitly mentions  Ether and dollars. This is not purely descriptive. It also assumes that the Chainlink price  is updated every 24 hours, even though different Chainlink oracles can have  wildly different heartbeats, ranging from 1 hour to 48 hours.  Consider choosing a specific configuration, or making all parameters and comments generic.  Update: Resolved in pull request #425.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#incomplete-generalization-[samples]", "labels": ["OpenZeppelin"]}, {"title": "Misleading Comments [core and samples]", "body": "The following misleading comments were identified:  This comment is incorrect now that deposits occupy 256 bits.  This comment still refers to a second postOp call.  The simulation functions both claim (1, 2) to always revert, but that is no longer accurate.  The paymaster validation comment incorrectly implies that it can return a non-zero authorizer address.  This comment still references the obsolete ValidationResultWithAggregation.  The BasePaymaster _postOp comment still references the obsolete second call.  The paymasterAndData parameter is incorrectly described as a paymaster address followed by a token address.  The requiredPreFund parameter in the TokenPaymaster contract is described as the amount of tokens, but it is the amount of ETH.  Consider updating them accordingly.  Update: Resolved in pull request #413, pull request #440.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#misleading-comments-[core-and-samples]", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings [core and samples]", "body": "Throughout the codebase, there are several parts that have incomplete docstrings:  In the updateCachedPrice function in OracleHelper.sol:  The force parameter is not documented. The return value is not documented.  In the _postOp function in BasePaymaster.sol, the actualGasCost parameter is not documented.  In the getUserOpPublicKey function in BLSSignatureAggregator.sol, the userOp parameter is not documented.  In the addStake function in BLSSignatureAggregator.sol, the delay parameter is not documented.  In the validateUserOp function in BaseAccount.sol, the return value is not documented.  In the innerHandleOp function in EntryPoint.sol, the return value is not documented.  In the _getValidationData function in EntryPoint.sol, the return values are not documented.  In the getUserOpHash function in IEntryPoint.sol, the return value is not documented.  In the delegateAndRevert function in IEntryPoint.sol, the target and data parameters are not documented.  In the simulateValidation function in IEntryPointSimulations.sol, the return value is not documented.  In the simulateHandleOp function in IEntryPointSimulations.sol, the return value is not documented.  In the executeBatch function in SimpleAccount.sol, the dest, value, and func parameters are not documented.  In the initialize function in SimpleAccount.sol, the anOwner parameter is not documented.  In the balanceOf function in StakeManager.sol, the return value is not documented.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #414.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#incomplete-docstrings-[core-and-samples]", "labels": ["OpenZeppelin"]}, {"title": "Different Pragma Directives Are Used [core and samples]", "body": "Pragma directives should be fixed and the same across file imports in order to clearly identify the Solidity version in which the contracts will be compiled.  Throughout the codebase, there are multiple different pragma directives:  The BLSAccount.sol file has the pragma directive pragma solidity ^0.8.12; and imports the following files with different pragma directives:  SimpleAccount.sol IBLSAccount.sol  The BLSSignatureAggregator.sol file has the pragma directive pragma solidity >=0.8.4 <0.9.0; and imports the following files with different pragma directives:  IBLSAccount.sol BLSHelper.sol  The EntryPoint.sol file has the pragma directive pragma solidity ^0.8.23; and imports the following files with different pragma directives:  StakeManager.sol SenderCreator.sol Helpers.sol NonceManager.sol UserOperationLib.sol  The EntryPointSimulations.sol file has the pragma directive pragma solidity ^0.8.12; and imports the file EntryPoint.sol which has a different pragma directive.  The OracleHelper.sol file has the pragma directive pragma solidity ^0.8.12; and imports the IOracle.sol file which has a different pragma directive.  The SimpleAccountFactory.sol file has the pragma directive pragma solidity ^0.8.12; and imports the SimpleAccount.sol file which has a different pragma directive.  Consider using the same fixed pragma version in all files.  Update: Resolved in pull request #415.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#different-pragma-directives-are-used-[core-and-samples]", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Event [samples]", "body": "The UserOperationSponsored event includes the market price but does not include the markup price which is what the user actually paid.  Consider including the markup price in the event as well for completeness.  Update: Resolved in pull request #431.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#incomplete-event-[samples]", "labels": ["OpenZeppelin"]}, {"title": "Code simplifications [samples]", "body": "The following code simplifications were identified:  In the OracleHelper contract, the previousPrice variable is redundant because the _cachedPrice and price already represent the old and new values. There is no need to update the _cachedPrice value because price can directly be assigned to storage. Consider removing the redundant value.  The UniswapHelper contract accepts _tokenDecimalPower instead of calculating it from the token.decimals() value. Presumably, this is intended to support ERC-20 contracts that do not implement the metadata extension. However, it is initialized in the TokenPaymaster using the decimals function, which suggests that logic could be moved to UniswapHelper. Although, in this case, tokenDecimalPower is unused and could instead be removed entirely.  Update: Resolved in pull request #422.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#code-simplifications-[samples]", "labels": ["OpenZeppelin"]}, {"title": "Unused Functions With internal or private Visibility [core and samples]", "body": "Throughout the codebase, there are unused functions:  The getGasPrice function in TokenPaymaster.sol  The swapToWeth function in UniswapHelper.sol  To improve the overall clarity, intentionality, and readability of the codebase, consider using or removing any currently unused functions.  Update: Resolved in pull request #426.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#unused-functions-with-internal-or-private-visibility-[core-and-samples]", "labels": ["OpenZeppelin"]}, {"title": "Multiple Contracts With the Same Name [samples]", "body": "There are two incompatible instances (1, 2) of the IOracle interface.  Consider renaming the contracts to avoid unexpected behavior and improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #427.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#multiple-contracts-with-the-same-name-[samples]", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact [core and samples]", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for the maintainers of those libraries to establish contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact.  Consider adding a NatSpec comment containing a security contact above the contract definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #432.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#lack-of-security-contact-[core-and-samples]", "labels": ["OpenZeppelin"]}, {"title": "Using uint Instead of uint256 [core and samples]", "body": "The following instances of using uint were identified:  The INNER_GAS_OVERHEAD constant in EntryPoint.sol  The g and x variables in EntryPointSimulations.sol  The actualUserOpFeePerGas variable in TokenPaymaster.sol  In favor of explicitness, consider replacing all instances of uint with uint256.  Update: Resolved in pull request #417.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#using-uint-instead-of-uint256-[core-and-samples]", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestions [core and samples]", "body": "To favor explicitness and readability, listed below are suggestions for better naming:  postOp should be \"postOpGasLimit\".  paymasterAndDataLength should just be \"dataLength\".  Update: Resolved in pull request #418.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#naming-suggestions-[core-and-samples]", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors [core]", "body": "Consider addressing the following typographical errors:  \"with\" should be \"which\"  Update: Resolved in pull request #419.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#typographical-errors-[core]", "labels": ["OpenZeppelin"]}, {"title": "Unused or Indirect Imports [core and samples]", "body": "Throughout the codebase, there are multiple imports that are unused or only indirectly refer to the value imported:  Import import \"./Helpers.sol\"; in BaseAccount.sol  Import import \"./Helpers.sol\"; in BasePaymaster.sol  Import import \"../interfaces/IEntryPoint.sol\"; in NonceManager.sol  Import import \"../core/UserOperationLib.sol\"; in TokenPaymaster.sol  Import import \"@uniswap/v3-periphery/contracts/interfaces/ISwapRouter.sol\"; in OracleHelper.sol  Consider removing unused and indirect imports to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #419.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#unused-or-indirect-imports-[core-and-samples]", "labels": ["OpenZeppelin"]}, {"title": "Client Reported", "body": "Client Reported", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "simulateHandleOp does not set _senderCreator address", "body": "The simulateValidation function computes and sets the _senderCreator variable, which is required when the account is deployed in a user operation. However, the simulateHandleOp function does not perform the same initialization.  Update: Resolved in pull request #411, by moving the initialization to the simulationOnlyValidations function.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#simulatehandleop-does-not-set-_sendercreator-address", "labels": ["OpenZeppelin"]}, {"title": "Unverified TokenPaymaster gas limit", "body": "The TokenPaymaster estimates the gas cost of its postOp operation but does not validate that the user operation provides enough gas. If insufficient postOp gas is provided, the user would still pay the gas costs, but the operation would revert.  Update: Resolved in pull request #434 at commit 900a6a8.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#unverified-tokenpaymaster-gas-limit", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Prefund", "body": "Note: This error was present in the previous audit commit but was not identified by the auditors at the time. It was reported to the Ethereum Foundation by OKX.  In addition to the enforceable gas limits, user operations are charged preVerificationGas to compensate bundlers for off-chain work and transaction overhead. Since preVerificationGas cannot be measured by the EntryPoint contract, it is directly added to the measured amount that will be charged from the user or paymaster.  However, this means that when confirming that the pre-funded charge covers the measured usage, the cost of preVerificationGas is implicitly included on both sides of the inequality, and is therefore irrelevant. The guard condition actually checks whether the measured gas, including transaction overhead, exceeds the enforceable limits (which do not cover overhead). If all of the enforceable limits are completely consumed, the overhead might be sufficient to trigger the revert, which would cause the entire transaction to revert at the bundler's expense.  To mitigate this risk, bundlers could ensure that at least one of the enforceable gas limits is not completely consumed during simulation so that there is enough buffer to cover the overhead. In practice, they should choose the user's verification gas limit to guarantee that the simulated buffer amount is reproduced on-chain.  Update: Resolved in pull request #441, pull request #449.", "html_url": "https://blog.openzeppelin.com/erc-4337-account-abstraction-incremental-audit#insufficient-prefund", "labels": ["OpenZeppelin"]}, {"title": "Deadline Buffer for Fills Is Not Always Respected", "body": "A newly added feature to the system is that the fill requests are subject to a deadline after which any fill attempt reverts. The essence of this feature is to limit the maximum necessary lookback for dataworkers and relayer instances.  For backwards compatibility reasons, the _deposit function will be present for a long time after the system upgrade introducing the new V3 interface takes place. However, note that the _deposit function sets each fill's deadline to an infinitely large number. As a consequence, even after the system's upgrade, new deposits will remain active practically forever, thereby breaking the assumption of the limited maximum necessary lookback.  Consider setting the default fill deadline equal to the standard deadline buffer in order to enable limited lookbacks.  Update: Resolved in pull request #14 at commit 71383bc. The Risk Labs team stated:  We decided not to implement the suggested fix because the existing integrators that use deposit() are likely not prepared to receive expired deposit refunds on the origin chain. Instead, we will enshrine MAX_UINT_256 as a magic number in the Across UMIP that is only possible to be set via the soon-to-be deprecated deposit() function.  This means that deposits sent from this function can never expire, and therefore the dataworker does not need to maintain a longer lookback to look out for these. Moreover, these deposits can always be slow-filled because outputToken is hardcoded to 0x0 by deposit(), meaning that these deposits will never lock funds.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#deadline-buffer-for-fills-is-not-always-respected", "labels": ["OpenZeppelin"]}, {"title": "Refund Leaf Execution Fails if One of the Addresses Is Blacklisted", "body": "If an address is blacklisted in the USDC token then both to and from transfers revert for this address. During refund leaf execution, tokens are pushed to the recipients. If one of the recipients is a blacklisted address, the whole execution fails and the blacklisted address as well as other addresses included in the leaf are not refunded. While such issues are inherent to the push pattern as opposed to the pull pattern, in this case, these issues and those similar to them can be remedied off-chain.  Consider adding a fallback option to the off-chain process that can separate problematic addresses to their own refund leaf so that they do not affect legitimate addresses.  Update: Acknowledged, will resolve. The Risk Labs team stated:  We will address this in the upcoming UMIP changes for Across V3. Relayer refund leaves that refund any user on the l2Token's blacklist should not be created.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#refund-leaf-execution-fails-if-one-of-the-addresses-is-blacklisted", "labels": ["OpenZeppelin"]}, {"title": "Permit2OrderLib Is Not Fully Compliant With EIP-712", "body": "In the Permit2OrderLib contract, the witnessTypeString argument when calling the external permit2WitnessTransferFrom function does not fully follow the EIP-712 specification.  Specifically:  Some of the entries have a different type in the struct's declaration than what is included in the typestring. Namely, these entries are: fillPeriod, validationContract, and validationData.  Some entries are included in the witness but are not included in the typestring. Namely, order.challengerCollateral.token and order.challengerCollateral.amount.  Consider fixing all the inconsistencies described above in order to fully comply with the EIP-712 specification.  Update: Resolved in pull request #15 at commit 446aae6.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#permit2orderlib-is-not-fully-compliant-with-eip-712", "labels": ["OpenZeppelin"]}, {"title": "Polygon_SpokePool-Specific Lock Can Be Bypassed", "body": "The Polygon_SpokePool contract has locks that prevent filling deposits with a message hook if a leaf is claimed within the same transaction. This is intended to prevent a situation in which the attacker executes a refund leaf and gets the control flow.  This lock, however, can be bypassed by executing the multicall function within which a relayer refund leaf is executed and a deposit is filled. The fill does not contain a message hook but during a native token transfer or a malicious outputToken transfer, it still gives the control flow to the attacker which defeats the purpose of the lock.  Consider adding a contract-wide lock to the executeV3RelayerRefundLeaf and executeRelayerRefundLeaf functions of Polygon_SpokePool so that each of these functions can only be executed if it is the only one in a transaction.  Update: Resolved in pull request #24 at commit d910641 and in pull request #29 at commit 8d6682b. The executeV3RelayerRefundLeaf function has been completely removed. Additionally, it is now prohibited to call executeRelayerRefundLeaf combined with other public function calls within a multicall transaction.  Low Severity", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#polygon_spokepool-specific-lock-can-be-bypassed", "labels": ["OpenZeppelin"]}, {"title": "Unchecked Return Value", "body": "In the SwapAndBridge contract, the _swapAndBridge function attempts to pull the caller's tokens but does not check the return value of the transferFrom call.  Consider using the safeTransferFrom function of the SafeERC20 library in order to assert the call's success.  Update: Resolved in pull request #16 at commit 3a105a2.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#unchecked-return-value", "labels": ["OpenZeppelin"]}, {"title": "Fillers Might Lose Their Collateral", "body": "The Permit2Depositor contract is meant to be used by third-party fillers and requires collateral from their side which is returned during the refund process. Because of this, they are also set as the exclusive relayer for the deposit. This way, they are protected from someone else filling the deposit and claiming the collateral.  However, liquidity providers can bypass the exclusivity restriction and have an incentive to do so by slow-filling the deposit thus leaving the collateral in the protocol. They can achieve this by requesting and executing a slow fill before the exclusivity deadline. This, of course, requires the filler to not to fill for at least the root bundle dispute period because slow fills can happen only after the root bundle dispute period has passed.  Consider either restricting the caller of the requested slow fill function to the depositor for the duration of the exclusivity period or guiding the third-party integrations to set the deposit lifespan to be less than the challenge period. The former approach gives more flexibility in terms of deposit lifespan but forces users to do on-chain calls if they want a slow fill for a deposit with an exclusive relayer. This might not be desirable given that the Permit2Depositor contract provides a gasless bridging experience to the user. The latter approach provides a better gasless experience but requires the third-party integration to be mindful of this issue.  Update: Resolved in pull request #17 at commit cc6b3cc. The Risk Labs team stated:  We ultimately decided to not only restrict when a slow fill request can be sent during the exclusivity window, but to block it altogether. We think that there is no reason for a depositor to request a slow fill when there is an exclusivity window set since they would have already made an off-chain agreement with an exclusive relayer to fill their deposit. If they had not, then they would set a 0-length exclusivity window. This implementation is the simplest to reason about without affecting projected UX.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#fillers-might-lose-their-collateral", "labels": ["OpenZeppelin"]}, {"title": "Lack of Input Validation", "body": "There are some instances of input parameters within the SpokePool contract that are not sufficiently validated:  fillDeadline can be set in the past. In such a case, it is not possible to fill the deposit request.  exclusiveRelayer and exclusivityDeadline may not be consistent with each other. For example, it is possible that exclusiveRelayer is set to the 0x0 address while exclusivityDeadline is a non-zero value. This would create some confusion when filling the deposit request.  In the payable depositV3 function, msg.value should always be zero in case the inputToken is not the wrappedNativeToken.  Consider sufficiently validating all of the instances as described above.  Update: Resolved in pull request #18 at commit e1f2492. The Risk Labs team stated:  The new rule for exclusiveRelayer and exclusivityDeadline is that either both must be 0 or both must be non-zero and exclusivityDeadline >= currentTime.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#lack-of-input-validation", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Access Controls", "body": "claimMessage function of the Linea message service. The function sets the  sender for the duration of the call. This might be problematic if the HubPool ever sends a cross-chain message to an attacker-controlled contract on Linea. This is because in this case, the attacker-controlled contract can make calls to  access controls because the  Consider checking both that sender is the HubPool and that the immediate caller is the Linea message service.  Update: Resolved in pull request #19 at commit e6bb797.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#insufficient-access-controls", "labels": ["OpenZeppelin"]}, {"title": "Low Level Call to External Exchange Contract With Arbitrary Calldata", "body": "SwapAndBridge contract enables swapping an amount of tokens via a decentralized exchange service of preference and then bridge the swapped amount via Across. Both swap and bridging actions take place within a single transaction. To execute the swap, the  low level call to the designated exchange contract. For this call, the  calldata parameters are arbitrarily given by the user. The only  restriction is that the called function selector must be different than an ERC-20 token's  Instead of blacklisting the suspicious calldata parameters, consider whitelisting the allowed ones. More specifically, consider whitelisting the specific swap function selectors of the external exchange in each SwapAndBridge contract.  Update: Resolved in pull request #20 at commit 2c68c2e.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#low-level-call-to-external-exchange-contract-with-arbitrary-calldata", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent And Misleading Events Emitted When Bridging To HubPool", "body": "A relayer refund leaf contains information about the refund amounts of a specific L2 token that need to be transferred to the relayers. In addition, it may also contain information about a non-zero amount of the L2 token that needs to be bridged back to the HubPool contract. Each L2 SpokePool contract implements the _bridgeTokensToHubPool function to handle the chain-specific operations for bridging to L1.  There is an inconsistency in the events emitted by the several L2 SpokePools upon bridging to HubPool. More specifically, the base SpokePool contract emits the TokensBridged event upon all relevant actions. Apart from this event, most of the L2 SpokePools emit one more event which typically contains 3 parts of information: the address of the L2 token, the receiver address (i.e., HubPool address), and the amount bridged.  However, the following inconsistencies and errors have been identified:  Instead of emitting the L2 token address, Arbitrum_SpokePool emits the L1 token address. The L1 address is also hardcoded as the 0x0 address.  Ethereum SpokePool and PolygonZkEVM_SpokePool emit no event.  Polygon_SpokePool mistakenly emits address(this) as the HubPool address.  Consider addressing any faulty or inconsistent event information as listed above. Since most of the information contained in the more specific events is already covered by the event emitted by the base SpokePool contract, consider emitting a more specific event only when complementary information needs to be logged.  Update: Resolved in pull request #21 at commit d1aa772. The Risk Labs team stated:  We decided to remove all these chain-specific bridge events as they add no additional value to the TokensBridged event emitted in the parent contract and they are not currently used in any off-chain infrastructure.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#inconsistent-and-misleading-events-emitted-when-bridging-to-hubpool", "labels": ["OpenZeppelin"]}, {"title": "Wrong Constructor Argument Passed", "body": "constructing the  SwapAndBridgeBase's constructor due to a typographical error. Specifically, instead of passing the  does not validate  Consider fixing the typographical error to avoid faulty deployments.  Update: Resolved in pull request #22 at commit 0a960f1.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#wrong-constructor-argument-passed", "labels": ["OpenZeppelin"]}, {"title": "Different Pragma Directives Are Used", "body": "Having fixed and the same pragma directives across file imports helps clearly identify the Solidity version with which the contracts will be compiled. However, the Permit2Depositor.sol file has the pragma directive pragma solidity ^0.8.0; and imports the Permit2OrderLib.sol file which has a different pragma directive.  Consider using the same fixed pragma version where possible.  Update: Resolved in pull request #23 at commit 5571b12. The Risk Labs team stated:  Changed pragma call in the following contracts: IPermit2, Permit2Order, Permit2OrderLib, and AddressLibUpgradeable.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#different-pragma-directives-are-used", "labels": ["OpenZeppelin"]}, {"title": "Todo Comments in the Code", "body": "During development, having well-described TODO/Fixme comments will make the process of tracking and solving them easier. Without this information, these comments might age and important information for the security of the system might be forgotten by the time it is released to production. These comments should be tracked in the project's issue backlog and resolved before the system is deployed. There is a TODO comment at line 1221 in SpokePool.sol.  Consider removing all instances of TODO/Fixme comments and instead tracking them in the issues backlog. Alternatively, consider linking each inline TODO/Fixme to the corresponding issues backlog entry.  Update: Acknowledged, will resolve. The Risk Labs team stated:  We decided to leave in the TODO comments to remind ourselves to fix them in the future.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#todo-comments-in-the-code", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Use of Named Returns", "body": "Contract Arbitrum_Adapter contract has inconsistent usage of named returns in its functions. More specifically, only the _contractHasSufficientEthBalance function names its return variable.  To improve the readability of the contract, consider using the same return style in all of its functions.  Update: Resolved in pull request #23 at commit 5571b12.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#inconsistent-use-of-named-returns", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Event Emission", "body": "directly sets the  internal setters. As a consequence, the associated events will not be emitted. Similarly, the  immediately sets the  setter functions.  Consider calling the setter functions instead of directly setting the variables so that the associated events are emitted in a consistent manner.  Update: Resolved in pull request #23 at commit 5571b12. The Risk Labs team stated:  We refactored Scroll_SpokePool and Polygon_SpokePool to use the internal setter functions in the initializer.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#inconsistent-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Use of Magic Constants", "body": "Arbitrum_SpokePool,  OVM_SpokePool, and  Polygon_SpokePool contracts use the magic constant  CCTP domain id for the Ethereum Mainnet. In addition, hardcoded  0 and  address(0) values are used in the  Consider using a constant variable for each value of special meaning for better readability and clarity.  Update: Resolved in pull request #23 at commit 5571b12. The Risk Labs team stated:  We added the CCTP domain ID's as constants in CircleCCTPAdapter.sol. Magic values in Arbitrum_SpokePool, Polygon_SpokePool, andOVM_SpokePool have been replaced.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#use-of-magic-constants", "labels": ["OpenZeppelin"]}, {"title": "Incorrect or Misleading Docstrings", "body": "Several instances of incorrect or misleading docstrings have been identified throughout the codebase:  In SpokePool.sol:  At line 683, \"plus\" should be \"less\".  At line 528, \"_deposit()\" should be \"deposit()\".  At line 565, \"_deposit()\" should be \"depositFor\".  In Permit2Depositor.sol, at line 13, \"AcrossV2\" should be \"AcrossV3\".  In Permit2Order.sol, at line 59, \"signature\" could be more specifically described as \"Permit2 signature\".  Consider updating the misleading instances of docstrings for improved clarity and readability.  Update: Resolved in pull request #23 at commit 5571b12.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#incorrect-or-misleading-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Unused Modifier", "body": "The onlyFromCrossDomainAccount modifier of the CrossDomainEnabled contract is never used within the entire codebase.  Consider removing the unused modifier for clarity and readability.  Update: Resolved in pull request #23 at commit 5571b12.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#unused-modifier", "labels": ["OpenZeppelin"]}, {"title": "SwapAndBridge Contract Could Be Abstract", "body": "The SwapAndBridgeBase contract could be marked abstract since it only contains internal functions and is not intended to be directly deployed as a standalone contract.  Consider marking the SwapAndBridge contract abstract for clarity.  Update: Resolved in pull request #23 at commit 5571b12.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#swapandbridge-contract-could-be-abstract", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestion", "body": "The Polygon_SpokePool contract disallows relayer refunds and fills with a message hook to take place within a single transaction. This is achieved by setting and checking the lock variables. In essence, the _setFunctionLock function is responsible for locking a designated lock variable, while the _revertIfFunctionCalledAtomically function checks whether the lock variable is locked, and if so, reverts the execution.  Despite these two functions performing symmetric checks, their names do not represent this fact. As such, to improve the contract's overall clarity and readability, consider renaming _revertIfFunctionCalledAtomically to a more intuitive name (e.g., _revertIfFunctionLockSet).  Update: Resolved in pull request #24 at commit d910641. The Risk Labs team stated:  These hooks were completely removed by the fix for the M04 issue.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#naming-suggestion", "labels": ["OpenZeppelin"]}, {"title": "Constants Not Using UPPER_CASE Format", "body": "Throughout the codebase, there are constants that do not use the UPPER_CASE format.  According to the Solidity Style Guide, constants should be named with all capital letters with underscores separating words. For better readability, consider following this convention.  Update: Resolved in pull request #23 at commit 5571b12. The Risk Labs team stated:  We renamed variables in: BondToken, Ovm_SpokePool, PolygonTokenBridger, PolygonZkEVM_SpokePool, Arbitrum_Adapter, Base_Adapter, Boba_Adapter, Linea_Adapter, Optimism_Adapter, PolygonZkEVM_Adapter, Polygon_Adapter, Scroll_Adapter, and Permit2Depositor.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#constants-not-using-upper_case-format", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for the maintainers of those libraries to contact the appropriate person about the problem and provide mitigation instructions. Throughout the codebase, there are contracts that do not have a security contact.  Consider adding a NatSpec comment containing a security contact above the contract definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #23 at commit 5571b12. The Risk Labs team stated:  Security contact information has been added to SpokePool.sol", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Variables Could Be constant", "body": "If a variable is only ever assigned a value when it is declared, then it could be declared as constant. Throughout the codebase, there are several variables that could be constant:  The l2GasLimit variable in Base_Adapter.sol  The l2GasLimit variable in Optimism_Adapter.sol  The dai variable in Optimism_Adapter.sol  The daiOptimismBridge variable in Optimism_Adapter.sol  The snx variable in Optimism_Adapter.sol  The snxOptimismBridge variable in Optimism_Adapter.sol  To better convey the intended use of variables and to potentially save gas, consider adding the constant keyword to variables that are only set when they are declared.  Update: Resolved in pull request #23 at commit 5571b12.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#variables-could-be-constant", "labels": ["OpenZeppelin"]}, {"title": "Unused Event", "body": "In SpokePool.sol, the RefundRequested event is unused.  To improve the overall clarity, intentionality, and readability of the codebase, consider removing the unused event.  Update: Resolved in pull request #23 at commit 5571b12. The Risk Labs team stated:  The event has been removed.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#unused-event", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Casts", "body": "Throughout the codebase, there are multiple unnecessary casts:  The uint32(l2GasLimit) cast in the Base_Adapter contract  The IMessageService(l2MessageService) cast in the Linea_SpokePool contract  The IMessageService(l2MessageService) cast in the Linea_SpokePool contract  The IMessageService(l2MessageService) cast in the Linea_SpokePool contract  The uint32(l2GasLimit) cast in the Optimism_Adapter contract  The IPermit2(address(permit2)) cast in the Permit2OrderLib contract.  To improve the overall clarity, intent, and readability of the codebase, consider removing unnecessary casts.  Update: Resolved in pull request #23 at commit 5571b12 and in pull request #30 at commit 2d90d5b.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#unnecessary-casts", "labels": ["OpenZeppelin"]}, {"title": "Code Duplication", "body": "The IMessageService, ITokenBridge, and IUSDCBridge interfaces are defined in both the Linea_Adapter and the Linea_SpokePool contracts.  Consider including these interfaces in a separate file and importing them wherever needed in order to avoid duplicating the code which can be error-prone.  Update: Resolved in pull request #23 at commit 5571b12. The Risk Labs team stated:  They have been moved to the LineaInterfaces.sol contract.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#code-duplication", "labels": ["OpenZeppelin"]}, {"title": "Permit2Depositor Restricts Exclusive Relayer To msg.sender", "body": "permit2Deposit function of the  entire fill period is set exclusive. The exclusive relayer  is always the caller of  If the Permit2 functionality gets supported on zkSync Era, the current version of Permit2Depositor would not function properly because of the different address derivation algorithm. Moreover, fillers may have different addresses on different chains so they might need more flexibility in specifying the exclusive relayer.  Consider adding the filler's address on the destination chain within the order's argument for flexibility but also to avoid faulty implementations on future upgrades that involve zkSync Era.  Update: Resolved in pull request #23 at commit 5571b12. The Risk Labs team stated:  The address destinationChainFillerAddress parameter has been added to permit2Deposit.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#permit2depositor-restricts-exclusive-relayer-to-msg.sender", "labels": ["OpenZeppelin"]}, {"title": "Recommendations", "body": "Recommendations", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#recommendations", "labels": ["OpenZeppelin"]}, {"title": "Codebase Can Benefit From Additional Testing", "body": "We recommend adding more unit and integration tests for the new components. In particular, tests for the Permit2Depositor and SwapAndBrdige contracts were not found. Tests can aid in communicating the intended behaviour and making the codebase more robust.", "html_url": "https://blog.openzeppelin.com/across-v3-incremental-audit#codebase-can-benefit-from-additional-testing", "labels": ["OpenZeppelin"]}, {"title": "Complex Design of Submission and Finalization Flows Causes Risks", "body": "The current design of the submission data and finalization data flows exhibits significant structural and logical complexities.  Causes  The flow varies based on the combination and nature of the data submitted. For instance, whether submission data and finalization data are submitted separately or together, the finalization data dataHashes array length, and the submission compressedData length.  Data is duplicated between the submission data and the finalization data, resulting in the need for a lot of consistency checks.  Data hashes are used as cardinality. Utilizing data hashes as the main key for various data structures poses several challenges:  Complex validation and difficulty in tracking parent/child relationships. Unconventional and error-prone approach. Ambiguity about the order and nature of the data which, for example, results in the absence of support for resubmission. Potential for non-uniqueness. Difficulty in reviewing.  Impact  The combination of these causes results in a complex and brittle system. Even with thorough reviews and bug fixes, this increases the chances of new bugs being introduced in future code changes.  In the current report, a high number of issues has the above design choices either as a direct cause, or as a significant contributing factor:  M-01:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#complex-design-of-submission-and-finalization-flows-causes-risks", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Validation of Loaded Data Allows Out-of-Order Submission, Preventing Finalization", "body": "M-06: Incorrectly Submitted Data Prevents Finalization  M-07: Non-Unique compressedData Can Prevent Submission  M-08: Insufficient Validation of Block Numbers During Submission and Finalization  L-01: Loaded Shnarf Is Not Checked to Be Non-Empty  L-02: Submission Data Can Be Overwritten in Certain Circumstances  L-10: False Sense of Security Due to Validation of Unused Data Fields  L-12: Data Chain Integrity Can Be Broken  L-13: Intermediary Blocks Are Not Validated  Due to the high number of complex and severe issues found, the current design can result in two kinds of high severity scenarios:  High likelihood of a future medium impact issue.  Medium likelihood of a future high impact issue. This possibility is further exacerbated by the eventual gradual removal of the heavy usage of access control and \"training wheels\" which currently make the likelihood of most issues low.  Recommendation  To address these issues, a restructuring and simplification of the data structures and transaction flow is recommended:  Data Structure  Utilize L2 batch indices (or block numbers) as the primary key (cardinality) for all data structures to ensure clarity and consistency.  Process Flow  Segregate the data storage writes (in submitData) from the storage reads and validation checks (in finalize) into separate concerns. This should also help remove most of the data duplication between submission data and finalization data. Allow submission to be reversible and idempotent (for non-finalized batches/blocks), serving strictly as a gas cost-splitting measure. In practice, this would mean that the information required to compute the shnarf would be stored (e.g., as a hash) at submission, and the shnarf would be computed during finalization. Restrict finalization to not accept submission data, thereby separating concerns and reducing complexity. Alternatively, ensure that finalize, if called with the submission data, submits the data as the first step, exactly as if submitData were called separately. Perform all checks in the finalize step. Since the storage write costs were already paid in submit, finalize will incur mostly storage read costs, and so should read all necessary data and perform all checks. Crucially, implement only one, unavoidable codepath which checks for all required invariants, and in which the conditional flow does not depend on the contents of the data such as array sizes.  Update: Partially resolved at commit 99039eb. The submission and finalization flows are now separate, and there is largely a single main flow with some temporary branches to allow an upgrade from an unproven previous state starting from empty data. However, data structures' cardinality remains unchanged, allowing multiple submission chains to co-exist and requiring a large amount of consistency checks.  Medium Severity    Data loaded from storage during the initialization in _submitData lacks sufficient validation, enabling out-of-order data submission (i.e., submitting later data before earlier data). Since previously submitted data cannot be resubmitted, this out-of-order submission irrevocably corrupts the stored data, preventing subsequent finalization. Specifically, submissionData.dataParentHash is used to load data that initializes the shnarf value.  If submission occurs out of order, either mistakenly or maliciously, the shnarf is initialized incorrectly from an empty value, leading to an incorrect shnarf being written for the submitted data hash. This differs from the correct data that would result from in-order submission, where the initial shnarf would not be empty. The corrupted shnarf then becomes unprovable, preventing finalization.  Consider:  Implementing robust validation to ensure that the data loaded from storage is not empty.  Exploring additional mechanisms to enforce in-order submission, such as tracking the expected parent hash's submitted block numbers.  Permitting the correction of incorrectly submitted data by allowing for the resubmission of unfinalized data.  Update: Resolved at commit 99039eb. The Linea team stated:  We have implemented additional functionality to validate that various fields are not empty as suggested. These include shnarfs as well as compressed data and finalRootHashes. We have also included the start and end blocks we expect in the data, which will reduce the risk of error. The design choice we have taken is to allow resubmission only in the case of submitting different compressed data for blocks that have not been finalized already.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#insufficient-validation-of-loaded-data-allows-out-of-order-submission,-preventing-finalization", "labels": ["OpenZeppelin"]}, {"title": "Incorrectly Submitted Tree Depth Prevents Claiming and May Increase the Odds of Forged Messages", "body": "The tree depth submitted in l2MerkleTreesDepth is not validated or sufficiently constrained. Specifically, it is not included in the public input to the proof, so it can be any arbitrary value. This creates several issues:  If submitted incorrectly, finalization will succeed. However, it would prevent any messages belonging to the affected message trees from being claimed on L1, since no proof can be provided for the incorrect depth stored. This would allow the operator to censor users even though their cross-chain messages were properly included in the L2 state.  A tree depth exceeding the provable depth can be submitted since l2MerkleTreesDepth is of size uint256, but the proof's leafIndex is a uint32 which would correspond to a maximum depth of 32. Even if the leafIndex variable were changed to be of type uint256, the maximum depth would still only be 256 and not type(uint256).max as allowed now.  A maliciously submitted tree depth that is too small allows proving intermediate nodes. While finding collisions with intermediate nodes is not significantly easier than with the leaves, this should not be allowed. In addition, if the submitted depth is too large, this adds an infinite number of \"phantom leaves\" that do not belong to the actual tree. Finding a proof for these would start from a non-existent \"phantom extension\" of the tree, hashing the phantom leaf and the supplied proof to try to find a collision with an existing leaf. While not significantly easier than finding second preimages for true leaves, proving phantom leaves should not be possible.  Consider including the depth of the trees in the proof, as well as validating it to be below the maximum possible depth.  Update: Resolved at commit 99039eb. The Linea team stated:  As part of the public input, we have now included the Tree Depth. It is now the responsibility of the circuit and prover to enforce the accuracy of this.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#incorrectly-submitted-tree-depth-prevents-claiming-and-may-increase-the-odds-of-forged-messages", "labels": ["OpenZeppelin"]}, {"title": "Censorable Claiming of L2 \u2192 L1 Messages Due to Required Operator Cooperation with Users", "body": "l2MessagingBlocksOffsets is used during finalization of the LineaRollup to emit L2MessagingBlockAnchored events on L1. These are used to build the proofs required to claim L2\u2192L1 messages. However, the data passed in l2MessagingBlocksOffsets is not verified or proven, and so can be arbitrary. Moreover, even if correct data is provided and extracted from these fields, the offsets emitted are not by themselves sufficient to allow reconstructing the proof needed for claiming.  The offsets allow for narrowing the L2 blocks down to only the ones that contain messages. However, the user must rely on the L2 node operator to provide additional information, mainly all the other messages in the blocks that are grouped in the range of finalized blocks along with the block containing their message. The user then must construct the trees for the range by grouping the messages according to the tree depths emitted. Only after reconstructing all the groupings, and subsequently the tree, in full, can they construct the proof for their message. Consequently, if the operator only provided partial information to the L2 network (e.g., an event or block's body is missing), claiming specific messages would not be possible.  While partial transaction data is made available on L1 in the form of compressed calldata, using just the compressed data to reconstruct the events may not be possible. This is because parts of the flow are not currently open-source and verifiably runnable by users. For example, the calldata is transformed in an opaque way to the users by the execution and proving flows. There is, to the best of our knowledge, no public documentation or codebase related to what the L1-posted data exactly contains, and how to rebuild the full L2 state from it to reach the same state as the circuit. As such, lacking verifiable knowledge of the execution being proven and software to reverse engineer the data into state, the user cannot reconstruct all the events in range.  Importantly, while it is theoretically possible to rebuild this state, if working software to reconstruct it is not public, in practice, the state is not trustlessly available from the perspective of an average user. We do note, however, that steps have been taken in this direction, such as open-sourcing the decompression algorithm. Thus, because active cooperation of the operator of the L2 network is required to allow claiming messages on L1, if this cooperation is incomplete or is intentionally used for censorship, some messages may not be claimable.  Consider the following recommendations:  Rethink the message-passing mechanism to reduce the dependence of users on L2 data provided by the operator. For example, the requirement to have perfect knowledge of all L2 events in a range may need simplification.  Validate the l2MessagingBlocksOffsets as part of the finalization proof to prevent malicious or incorrect values from being used.  Provide software that users can run to independently reconstruct the L2 state and log history from L1 data without relying on L2 network data that is not verifiably publicly available.  Update: Acknowledged, will resolve. The Linea team stated:  It is possible to construct the required data range by inferring block ranges from finalization events and the L2 Block number of the sent message. So, it is not critical at this point. We will either be providing the offsets in the circuit and public input in upcoming releases, or alternatively an SDK (software as suggested) that will simplify this process for users/partners etc.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#censorable-claiming-of-l2-\u2192-l1-messages-due-to-required-operator-cooperation-with-users", "labels": ["OpenZeppelin"]}, {"title": "V1 addL1L2MessageHashes Allows L1 \u2192 L2 Messages to Be Censored and May Prevent Finalization", "body": "Due to the V1 method for processing L1 messages (addL1L2MessageHashes) still existing on L2 and being callable by the operator after the upgrade, two issues arise:  The rolling hash mechanism can be circumvented and messages can be added while skipping (censoring) others by calling addL1L2MessageHashes. Finalization on L1 can continue without updating the rolling hash (by maintaining the previous one) and the added messages can be claimed on L2 to allow for the continued operation of the uncensored protocols or users.  If this V1 method is called mistakenly or maliciously by the operator with a message that was included in the rolling hash on L1 already, finalization on L1 will no longer be possible. This is because a message status can be set to \"received\" only once, and so will be skipped and not included in the rolling hash.  Consider the following recommendations:  Prevent addL1L2MessageHashes from being callable on L2 if lastAnchoredL1MessageNumber is not 0. This would mitigate the risk of finalization issues caused by accidental or malicious use of the V1 method.  Alternatively, ensure that the rolling hash is advanced on L1 by some minimal amount of messages if any unreceived messages exist on L1. This would help ensure that message passing continues without operator censorship or delay.  Update: Resolved at commit 99039eb. The Linea team stated:  We have now added an additional check to prevent anchoring with the old method once migration has occurred. This will also negate many of the issues mentioned in M-05.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#v1-addl1l2messagehashes-allows-l1-\u2192-l2-messages-to-be-censored-and-may-prevent-finalization", "labels": ["OpenZeppelin"]}, {"title": "Message Setter Can Anchor Arbitrary Messages on L2", "body": "Message Setter Can Anchor Arbitrary Messages on L2", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#message-setter-can-anchor-arbitrary-messages-on-l2", "labels": ["OpenZeppelin"]}, {"title": "Incorrectly Submitted Data Prevents Finalization", "body": "M-07:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#incorrectly-submitted-data-prevents-finalization", "labels": ["OpenZeppelin"]}, {"title": "Non-Unique compressedData Can Prevent Submission", "body": "M-08:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#non-unique-compresseddata-can-prevent-submission", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Validation of Block Numbers During Submission and Finalization", "body": "L-01: Loaded Shnarf Is Not Checked to Be Non-Empty  L-02: Submission Data Can Be Overwritten in Certain Circumstances  L-10: False Sense of Security Due to Validation of Unused Data Fields  L-12: Data Chain Integrity Can Be Broken  L-13: Intermediary Blocks Are Not Validated  Due to the high number of complex and severe issues found, the current design can result in two kinds of high severity scenarios:  High likelihood of a future medium impact issue.  Medium likelihood of a future high impact issue. This possibility is further exacerbated by the eventual gradual removal of the heavy usage of access control and \"training wheels\" which currently make the likelihood of most issues low.  Recommendation  To address these issues, a restructuring and simplification of the data structures and transaction flow is recommended:  Data Structure  Utilize L2 batch indices (or block numbers) as the primary key (cardinality) for all data structures to ensure clarity and consistency.  Process Flow  Segregate the data storage writes (in submitData) from the storage reads and validation checks (in finalize) into separate concerns. This should also help remove most of the data duplication between submission data and finalization data. Allow submission to be reversible and idempotent (for non-finalized batches/blocks), serving strictly as a gas cost-splitting measure. In practice, this would mean that the information required to compute the shnarf would be stored (e.g., as a hash) at submission, and the shnarf would be computed during finalization. Restrict finalization to not accept submission data, thereby separating concerns and reducing complexity. Alternatively, ensure that finalize, if called with the submission data, submits the data as the first step, exactly as if submitData were called separately. Perform all checks in the finalize step. Since the storage write costs were already paid in submit, finalize will incur mostly storage read costs, and so should read all necessary data and perform all checks. Crucially, implement only one, unavoidable codepath which checks for all required invariants, and in which the conditional flow does not depend on the contents of the data such as array sizes.  Update: Partially resolved at commit 99039eb. The submission and finalization flows are now separate, and there is largely a single main flow with some temporary branches to allow an upgrade from an unproven previous state starting from empty data. However, data structures' cardinality remains unchanged, allowing multiple submission chains to co-exist and requiring a large amount of consistency checks.  Medium Severity  Insufficient Validation of Loaded Data Allows Out-of-Order Submission, Preventing Finalization  Data loaded from storage during the initialization in _submitData lacks sufficient validation, enabling out-of-order data submission (i.e., submitting later data before earlier data). Since previously submitted data cannot be resubmitted, this out-of-order submission irrevocably corrupts the stored data, preventing subsequent finalization. Specifically, submissionData.dataParentHash is used to load data that initializes the shnarf value.  If submission occurs out of order, either mistakenly or maliciously, the shnarf is initialized incorrectly from an empty value, leading to an incorrect shnarf being written for the submitted data hash. This differs from the correct data that would result from in-order submission, where the initial shnarf would not be empty. The corrupted shnarf then becomes unprovable, preventing finalization.  Consider:  Implementing robust validation to ensure that the data loaded from storage is not empty.  Exploring additional mechanisms to enforce in-order submission, such as tracking the expected parent hash's submitted block numbers.  Permitting the correction of incorrectly submitted data by allowing for the resubmission of unfinalized data.  Update: Resolved at commit 99039eb. The Linea team stated:  We have implemented additional functionality to validate that various fields are not empty as suggested. These include shnarfs as well as compressed data and finalRootHashes. We have also included the start and end blocks we expect in the data, which will reduce the risk of error. The design choice we have taken is to allow resubmission only in the case of submitting different compressed data for blocks that have not been finalized already.  Incorrectly Submitted Tree Depth Prevents Claiming and May Increase the Odds of Forged Messages  The tree depth submitted in l2MerkleTreesDepth is not validated or sufficiently constrained. Specifically, it is not included in the public input to the proof, so it can be any arbitrary value. This creates several issues:  If submitted incorrectly, finalization will succeed. However, it would prevent any messages belonging to the affected message trees from being claimed on L1, since no proof can be provided for the incorrect depth stored. This would allow the o", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#insufficient-validation-of-block-numbers-during-submission-and-finalization", "labels": ["OpenZeppelin"]}, {"title": "Relayer Claiming a Message to a Contract Destination Does Not Refund the User", "body": "A relayer claiming a message on L2 to a contract destination does not refund the user, resulting in the fee always being fully taken by the relayer. During submission, when specifying the fee on L1, the fee will always either be overestimated or underestimated due to unknown gas conditions on L2 during claiming. Consequently, if underpaid, it will be uneconomical to relay, or if overpaid, it will unnecessarily leak value from users.  In contrast, for EOAs, the refund mechanism mitigates this issue by refunding overpayments, thus allowing sustained operation by the subsidized relayers. The absence of similar functionality for contract destinations limits the usefulness and reliability of cross-chain applications built on this messaging system, raising their maintenance costs since cross-chain applications will need to run and subsidize their own relay bots or force users to overpay for the gas fees. Since anything other than bridging ETH to an EOA requires calling contracts, this approach significantly impairs cross-chain functionality. Specifically, in times of rising gas prices, a backlog of unrelayed transactions will accumulate, causing unreliable user experiences for cross-chain applications relying on this mechanism.  In practice, the impact of this will likely be complexity and additional costs for cross-chain protocols, which will probably be passed on to their users as higher costs and risks. Alternatively, users will be directly forced to overpay for gas fees for cross-chain messaging. Both scenarios result in a low impact but highly likely value leakage from users.  Consider redesigning the gas metering system for cross-chain messages so that a refund mechanism for contract destinations is viable. For example, the cross-chain payload may specify maxFeePerGas, gasLimit, and refundRecipient instead of a total amount and unlimited gas. Such a mechanism can limit overpayment by users by refunding any oversupplied fees to the refund recipient while providing a predictable incentive for relayers.  Update: Acknowledged, not resolved. The Linea team stated:  We are considering options for this already and there are no changes for this audit.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#relayer-claiming-a-message-to-a-contract-destination-does-not-refund-the-user", "labels": ["OpenZeppelin"]}, {"title": "Third-Party Message Claiming for EOAs Is Uneconomical", "body": "Third-Party Message Claiming for EOAs Is Uneconomical", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#third-party-message-claiming-for-eoas-is-uneconomical", "labels": ["OpenZeppelin"]}, {"title": "Loaded Shnarf Is Not Checked to Be Non-Empty", "body": "L-02:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#loaded-shnarf-is-not-checked-to-be-non-empty", "labels": ["OpenZeppelin"]}, {"title": "Submission Data Can Be Overwritten in Certain Circumstances", "body": "L-10: False Sense of Security Due to Validation of Unused Data Fields  L-12: Data Chain Integrity Can Be Broken  L-13: Intermediary Blocks Are Not Validated  Due to the high number of complex and severe issues found, the current design can result in two kinds of high severity scenarios:  High likelihood of a future medium impact issue.  Medium likelihood of a future high impact issue. This possibility is further exacerbated by the eventual gradual removal of the heavy usage of access control and \"training wheels\" which currently make the likelihood of most issues low.  Recommendation  To address these issues, a restructuring and simplification of the data structures and transaction flow is recommended:  Data Structure  Utilize L2 batch indices (or block numbers) as the primary key (cardinality) for all data structures to ensure clarity and consistency.  Process Flow  Segregate the data storage writes (in submitData) from the storage reads and validation checks (in finalize) into separate concerns. This should also help remove most of the data duplication between submission data and finalization data. Allow submission to be reversible and idempotent (for non-finalized batches/blocks), serving strictly as a gas cost-splitting measure. In practice, this would mean that the information required to compute the shnarf would be stored (e.g., as a hash) at submission, and the shnarf would be computed during finalization. Restrict finalization to not accept submission data, thereby separating concerns and reducing complexity. Alternatively, ensure that finalize, if called with the submission data, submits the data as the first step, exactly as if submitData were called separately. Perform all checks in the finalize step. Since the storage write costs were already paid in submit, finalize will incur mostly storage read costs, and so should read all necessary data and perform all checks. Crucially, implement only one, unavoidable codepath which checks for all required invariants, and in which the conditional flow does not depend on the contents of the data such as array sizes.  Update: Partially resolved at commit 99039eb. The submission and finalization flows are now separate, and there is largely a single main flow with some temporary branches to allow an upgrade from an unproven previous state starting from empty data. However, data structures' cardinality remains unchanged, allowing multiple submission chains to co-exist and requiring a large amount of consistency checks.  Medium Severity  Insufficient Validation of Loaded Data Allows Out-of-Order Submission, Preventing Finalization  Data loaded from storage during the initialization in _submitData lacks sufficient validation, enabling out-of-order data submission (i.e., submitting later data before earlier data). Since previously submitted data cannot be resubmitted, this out-of-order submission irrevocably corrupts the stored data, preventing subsequent finalization. Specifically, submissionData.dataParentHash is used to load data that initializes the shnarf value.  If submission occurs out of order, either mistakenly or maliciously, the shnarf is initialized incorrectly from an empty value, leading to an incorrect shnarf being written for the submitted data hash. This differs from the correct data that would result from in-order submission, where the initial shnarf would not be empty. The corrupted shnarf then becomes unprovable, preventing finalization.  Consider:  Implementing robust validation to ensure that the data loaded from storage is not empty.  Exploring additional mechanisms to enforce in-order submission, such as tracking the expected parent hash's submitted block numbers.  Permitting the correction of incorrectly submitted data by allowing for the resubmission of unfinalized data.  Update: Resolved at commit 99039eb. The Linea team stated:  We have implemented additional functionality to validate that various fields are not empty as suggested. These include shnarfs as well as compressed data and finalRootHashes. We have also included the start and end blocks we expect in the data, which will reduce the risk of error. The design choice we have taken is to allow resubmission only in the case of submitting different compressed data for blocks that have not been finalized already.  Incorrectly Submitted Tree Depth Prevents Claiming and May Increase the Odds of Forged Messages  The tree depth submitted in l2MerkleTreesDepth is not validated or sufficiently constrained. Specifically, it is not included in the public input to the proof, so it can be any arbitrary value. This creates several issues:  If submitted incorrectly, finalization will succeed. However, it would prevent any messages belonging to the affected message trees from being claimed on L1, since no proof can be provided for the incorrect depth stored. This would allow the operator to censor users even though their cross-chain messages were properly included in the L2 state.  A tree depth ex", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#submission-data-can-be-overwritten-in-certain-circumstances", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Validations in Polynomial Openings", "body": "Similarly to what will be implemented for EIP-4844, submitted data is represented by a polynomial and opened at a random point to validate that it matches with the data given as witness to the circuit. This point is computed in practice as a hash derived from the submitted data and a commitment to the witness (represented as a SNARK-friendly hash of the witness data, snarkHash) following the Fiat-Shamir heuristic.  However, we found that the following validations are missing:  compressedDataComputedX is not checked to be an element of the scalar field.  There is no explicit validation on the size of the submitted data and thus the degree of the polynomial (which will be limited to 4096 in EIP-4844). While there is an implicit constraint through the block size limit, we would recommend either adding an explicit check or documenting this decision.  We do not, at the time of this report, have access to the circuit. Thus, we cannot confirm nor deny that the lack of these validations could cause concrete issues. However, we do recommend adding them for good practice.  Consider adding the mentioned validations/documentation.  Update: Resolved at commit 99039eb. Documentation has been added for both of the mentioned points.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#insufficient-validations-in-polynomial-openings", "labels": ["OpenZeppelin"]}, {"title": "Message Anchoring on L2 Is Not Pausable", "body": "Messages can be anchored on L2 by addresses having the L1_L2_MESSAGE_SETTER_ROLE role. This is done by calling the addL1L2MessageHashes or the anchorL1L2MessageHashes function. However, these functions are not currently pausable. Making them pausable could prove helpful in the future (e.g., if a message setter address is compromised).  Consider making these functions pausable (e.g., under GENERAL_PAUSE_TYPE).  Update: Resolved at commit 99039eb. The mentioned functions were made pausable for the general pause type.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#message-anchoring-on-l2-is-not-pausable", "labels": ["OpenZeppelin"]}, {"title": "sendMessage Reentrancy on L2 Could Result in Unordered MessageSent Events", "body": "The sendMessage function can be called on L2 to send a cross-chain message to L1. When doing so, coinbaseFee is collected from the value sent and transferred to the block.coinbase through a low-level call.  However, this makes it possible for block.coinbase to reenter sendMessage before the MessageSent event is emitted. This could result in events being emitted in decreasing order of message numbers, with the message number from the subcall getting emitted before the message number from the main function call. With the block.coinbase on L2 being the sequencer currently run by Linea, the likelihood of this issue is low. However, the impact is unknown as it depends on how the coordinator and the circuit process these events and the associated messages.  Consider emitting the MessageSent event before transferring the coinbaseFee to block.coinbase.  Update: Resolved at commit 99039eb.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#sendmessage-reentrancy-on-l2-could-result-in-unordered-messagesent-events", "labels": ["OpenZeppelin"]}, {"title": "Unproven Upgrade State Transition May Reduce Trust in State Validity", "body": "The planned transition from the V1 to the V2 finalization flow is set to utilize finalizeCompressedBlocksWithoutProof. This approach has been chosen because the prover does not support establishing the initial conditions required for the V2 flow.  However, employing finalizeCompressedBlocksWithoutProof permits arbitrary state changes, including potentially undetectable ones that could be exploited in the future. For example, an account's ETH or token balance could be set to a high number, eventually allowing the L1 bridge to be drained. While having the finalizeCompressedBlocksWithoutProof function is a reasonable risk mitigation mechanism in case of an emergency, using it diminishes users' trust in the integrity of the updated L2 state.  Consider substantiating that the state transition conducted during finalizeCompressedBlocksWithoutProof is a valid state transition. This verification could, for example, be demonstrated off-chain by providing a V1 or V2 proof for the same state transition that can be run on a mainnet fork.  Update: Acknowledged, will resolve. The Linea team stated:  The fact that the validation of the parent state root was done only when finalizing with a proof was intentional and is consistent with the previous version. We will look to update documentation and transparency around these executions if they occur.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#unproven-upgrade-state-transition-may-reduce-trust-in-state-validity", "labels": ["OpenZeppelin"]}, {"title": "Sequencer Censorship Issues", "body": "The design of the system exposes multiple points at which the sequencer can apply censorship. While the documentation mentions building towards \"enabling Censorship Resistant Withdrawals\", the current implementation of the contracts and the sequencer has broader censorship implications than withdrawals (L2\u2192L1 transactions):  L1\u2192L2 Messages  While L1 messages sent via sendMessage after the migration have to be anchored on L2 for the rollup to finalize and continue processing messages, the L1 contract only validates anchoring and does not ensure that they have been claimed. Consequently, if the sequencer chooses to censor the mandatory L2 claimMessage transaction for a message, it may never be included, trapping the users' funds inside the L1 contract.  Opaque Censorship Due to Uneconomical Content  Gas costs incurred by L2s for including user transactions typically differ in their pricing structure from those of similar L1 transactions. For instance, L1 calldata is significantly more expensive than L2 execution costs, often dominating transaction inclusion costs. This discrepancy usually necessitates a distinct gas pricing model for users compared to the L1 gas pricing model, whereby L1 calldata costs are explicitly calculated and borne directly by the users.  However, Linea's gas pricing model mimics L1 gas pricing and scales the average gas price by a factor of ~15x, without accounting for factors such as L1 calldata costs. Consequently, users posting large calldata transactions, which are relatively more expensive to include, end up paying much less than their actual share of the costs. This shortfall is partially covered by other users, who subsidize calldata-heavy users through higher payments for execution, and partially by the operators if an aggregate shortfall is realized. Moreover, proving costs are also mispriced, with some opcodes/operations being significantly more expensive to prove than others.  Crucially, due to these limitations, the Linea's sequencer's undocumented role involves censoring uneconomical transactions. It is tasked with selectively excluding transactions that are economically unviable, deviating from the transparent gas pricing model presented to its users.  This is in contrast to a typical sequencer's role of ordering transactions and including all the correctly submitted ones. Certain design choices allow a documented possibility of censorship, such as the sequencer's ability to censor both L1\u2192L2 and L2\u2192L1 transactions (without the ability to enforce a transaction inclusion from L1). However, such censorship would be detected and considered malicious. In contrast, censorship related to gas pricing is undocumented and likely to occur in practice if needed (e.g., if prompted by a calldata-heavy surge, such as the numerous instances of inscriptions-related outages and surges). Relying on censorship as a design decision contradicts the system's intention to be an L2 inheriting the safety and liveness of L1, as censorship represents a liveness failure.  Consider, in the short term, documenting the expected censorship functionality and its implementation in the sequencer so that expected censorship can be distinguished by third-party observers from malicious censorship. In the long term, consider incorporating transaction inclusion rules into the protocol or revising the gas pricing model.  Update: Acknowledged, will resolve. The Linea team stated:  The gas pricing model is being revised and a pricing API will be available in the near term. We will add additional documentation explaining how transactions are processed to sustain a working system.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#sequencer-censorship-issues", "labels": ["OpenZeppelin"]}, {"title": "Code Quality and Readability Suggestions", "body": "Consider implementing the following recommendations to improve the quality and readability of the codebase:  Avoid using unchecked blocks in L2 code as the gas savings are negligible but overflows can be catastrophic. In the current audit, an overflow issue stemmed from an unchecked gas optimization on L2. Also, starting from Solidity 0.8.22 (thus specifically for L1 contracts), there's no need to use unchecked increments in loops. Consider removing all L2 unchecked blocks, removing all unchecked loop increments blocks for L1 contracts, and documenting the reasoning for the impossibility of overflows/underflows for any remaining unchecked blocks.  Rename pauseTypeStatuses to __DEPRECATED_pauseTypeStatuses.  OFFSET_CONTAINS_MESSAGE is unused and can be removed.  Rename l2MerkleRoot to l2MerkleRootDepths for clarity.  Rename _shouldProve to withProof (or vice versa) for consistency.  Rename l1RollingHash to l2RollingHash.  Make the L2MessageServiceV1 contract abstract for consistency with L1MessageServiceV1.  The import of IMessageService in L1MessageService.sol is unnecessary and can be removed.  The LineaRollup contract should call __ReentrancyGuard_init() during initialization for completeness.  The functions initialize of L2MessageServiceV1, initialize of LineaRollup, and initializeSystemMigrationBlock have public visibility and can be made external for clarity of the intended external-only usage.  Refactor the condition flow in distributeFees for improved readability. The full fee is always paid to feeReceiver unless three conditions are true: calldata is empty, to is an EOA, and the calculated result is not higher than the total fee. Early returns can replace nested if blocks for improved code clarity:  modifier  distributeFees  ...  uint256  startingGas  gasleft  ();  _sendFees  (...);  // use internal method to avoid inlining  function  _sendFees  (...)  internal  if  (fee  ==  return  uint  deliveryFee  _calcDeliveryFee  (...);  if  (fee  deliveryFee  // send refund  // send deliveryFee  function  _calcDeliveryFee  (...)  internal  returns  uint  if  (_calldata  .length  !=  return  fee  uint  codeSize  assembly  codeSize  :=  extcodesize  (_to  if  (codeSize  !=  return  fee  uint  deliveryFee  ...  // calculation  return  deliveryFee  fee  fee  deliveryFee  Update: Partially resolved at commit 99039eb. Most of the mentioned points have been addressed, regarding the others the Linea team stated:  1. The distributeFees will form part of a later rethink/refactor. 2. The __DEPRECATED_pauseTypeStatuses is not compatible with the OpenZeppelin upgrade plugin/library and we have opted for a @dev comment instead to indicate deprecation. 3. The one unchecked loop where we do a i += 2 does not automatically get optimized as per the Solidity docs because we are doing more than just a simple increment in their view. 4. The l1Rollinghash naming remains as it indicates it is L1 related.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#code-quality-and-readability-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Validation of Parent State Root Hashes When Finalizing Without Proof", "body": "Insufficient Validation of Parent State Root Hashes When Finalizing Without Proof", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#insufficient-validation-of-parent-state-root-hashes-when-finalizing-without-proof", "labels": ["OpenZeppelin"]}, {"title": "False Sense of Security Due to Validation of Unused Data Fields", "body": "L-12: Data Chain Integrity Can Be Broken  L-13: Intermediary Blocks Are Not Validated  Due to the high number of complex and severe issues found, the current design can result in two kinds of high severity scenarios:  High likelihood of a future medium impact issue.  Medium likelihood of a future high impact issue. This possibility is further exacerbated by the eventual gradual removal of the heavy usage of access control and \"training wheels\" which currently make the likelihood of most issues low.  Recommendation  To address these issues, a restructuring and simplification of the data structures and transaction flow is recommended:  Data Structure  Utilize L2 batch indices (or block numbers) as the primary key (cardinality) for all data structures to ensure clarity and consistency.  Process Flow  Segregate the data storage writes (in submitData) from the storage reads and validation checks (in finalize) into separate concerns. This should also help remove most of the data duplication between submission data and finalization data. Allow submission to be reversible and idempotent (for non-finalized batches/blocks), serving strictly as a gas cost-splitting measure. In practice, this would mean that the information required to compute the shnarf would be stored (e.g., as a hash) at submission, and the shnarf would be computed during finalization. Restrict finalization to not accept submission data, thereby separating concerns and reducing complexity. Alternatively, ensure that finalize, if called with the submission data, submits the data as the first step, exactly as if submitData were called separately. Perform all checks in the finalize step. Since the storage write costs were already paid in submit, finalize will incur mostly storage read costs, and so should read all necessary data and perform all checks. Crucially, implement only one, unavoidable codepath which checks for all required invariants, and in which the conditional flow does not depend on the contents of the data such as array sizes.  Update: Partially resolved at commit 99039eb. The submission and finalization flows are now separate, and there is largely a single main flow with some temporary branches to allow an upgrade from an unproven previous state starting from empty data. However, data structures' cardinality remains unchanged, allowing multiple submission chains to co-exist and requiring a large amount of consistency checks.  Medium Severity  Insufficient Validation of Loaded Data Allows Out-of-Order Submission, Preventing Finalization  Data loaded from storage during the initialization in _submitData lacks sufficient validation, enabling out-of-order data submission (i.e., submitting later data before earlier data). Since previously submitted data cannot be resubmitted, this out-of-order submission irrevocably corrupts the stored data, preventing subsequent finalization. Specifically, submissionData.dataParentHash is used to load data that initializes the shnarf value.  If submission occurs out of order, either mistakenly or maliciously, the shnarf is initialized incorrectly from an empty value, leading to an incorrect shnarf being written for the submitted data hash. This differs from the correct data that would result from in-order submission, where the initial shnarf would not be empty. The corrupted shnarf then becomes unprovable, preventing finalization.  Consider:  Implementing robust validation to ensure that the data loaded from storage is not empty.  Exploring additional mechanisms to enforce in-order submission, such as tracking the expected parent hash's submitted block numbers.  Permitting the correction of incorrectly submitted data by allowing for the resubmission of unfinalized data.  Update: Resolved at commit 99039eb. The Linea team stated:  We have implemented additional functionality to validate that various fields are not empty as suggested. These include shnarfs as well as compressed data and finalRootHashes. We have also included the start and end blocks we expect in the data, which will reduce the risk of error. The design choice we have taken is to allow resubmission only in the case of submitting different compressed data for blocks that have not been finalized already.  Incorrectly Submitted Tree Depth Prevents Claiming and May Increase the Odds of Forged Messages  The tree depth submitted in l2MerkleTreesDepth is not validated or sufficiently constrained. Specifically, it is not included in the public input to the proof, so it can be any arbitrary value. This creates several issues:  If submitted incorrectly, finalization will succeed. However, it would prevent any messages belonging to the affected message trees from being claimed on L1, since no proof can be provided for the incorrect depth stored. This would allow the operator to censor users even though their cross-chain messages were properly included in the L2 state.  A tree depth exceeding the provable depth can be submitted since l2MerkleTreesDepth is", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#false-sense-of-security-due-to-validation-of-unused-data-fields", "labels": ["OpenZeppelin"]}, {"title": "Reliance on Application-Level Logic in Chain State Transition Proof", "body": "Reliance on Application-Level Logic in Chain State Transition Proof", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#reliance-on-application-level-logic-in-chain-state-transition-proof", "labels": ["OpenZeppelin"]}, {"title": "Data Chain Integrity Can Be Broken", "body": "L-13:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#data-chain-integrity-can-be-broken", "labels": ["OpenZeppelin"]}, {"title": "Intermediary Blocks Are Not Validated", "body": "Due to the high number of complex and severe issues found, the current design can result in two kinds of high severity scenarios:  High likelihood of a future medium impact issue.  Medium likelihood of a future high impact issue. This possibility is further exacerbated by the eventual gradual removal of the heavy usage of access control and \"training wheels\" which currently make the likelihood of most issues low.  Recommendation  To address these issues, a restructuring and simplification of the data structures and transaction flow is recommended:  Data Structure  Utilize L2 batch indices (or block numbers) as the primary key (cardinality) for all data structures to ensure clarity and consistency.  Process Flow  Segregate the data storage writes (in submitData) from the storage reads and validation checks (in finalize) into separate concerns. This should also help remove most of the data duplication between submission data and finalization data. Allow submission to be reversible and idempotent (for non-finalized batches/blocks), serving strictly as a gas cost-splitting measure. In practice, this would mean that the information required to compute the shnarf would be stored (e.g., as a hash) at submission, and the shnarf would be computed during finalization. Restrict finalization to not accept submission data, thereby separating concerns and reducing complexity. Alternatively, ensure that finalize, if called with the submission data, submits the data as the first step, exactly as if submitData were called separately. Perform all checks in the finalize step. Since the storage write costs were already paid in submit, finalize will incur mostly storage read costs, and so should read all necessary data and perform all checks. Crucially, implement only one, unavoidable codepath which checks for all required invariants, and in which the conditional flow does not depend on the contents of the data such as array sizes.  Update: Partially resolved at commit 99039eb. The submission and finalization flows are now separate, and there is largely a single main flow with some temporary branches to allow an upgrade from an unproven previous state starting from empty data. However, data structures' cardinality remains unchanged, allowing multiple submission chains to co-exist and requiring a large amount of consistency checks.  Medium Severity  Insufficient Validation of Loaded Data Allows Out-of-Order Submission, Preventing Finalization  Data loaded from storage during the initialization in _submitData lacks sufficient validation, enabling out-of-order data submission (i.e., submitting later data before earlier data). Since previously submitted data cannot be resubmitted, this out-of-order submission irrevocably corrupts the stored data, preventing subsequent finalization. Specifically, submissionData.dataParentHash is used to load data that initializes the shnarf value.  If submission occurs out of order, either mistakenly or maliciously, the shnarf is initialized incorrectly from an empty value, leading to an incorrect shnarf being written for the submitted data hash. This differs from the correct data that would result from in-order submission, where the initial shnarf would not be empty. The corrupted shnarf then becomes unprovable, preventing finalization.  Consider:  Implementing robust validation to ensure that the data loaded from storage is not empty.  Exploring additional mechanisms to enforce in-order submission, such as tracking the expected parent hash's submitted block numbers.  Permitting the correction of incorrectly submitted data by allowing for the resubmission of unfinalized data.  Update: Resolved at commit 99039eb. The Linea team stated:  We have implemented additional functionality to validate that various fields are not empty as suggested. These include shnarfs as well as compressed data and finalRootHashes. We have also included the start and end blocks we expect in the data, which will reduce the risk of error. The design choice we have taken is to allow resubmission only in the case of submitting different compressed data for blocks that have not been finalized already.  Incorrectly Submitted Tree Depth Prevents Claiming and May Increase the Odds of Forged Messages  The tree depth submitted in l2MerkleTreesDepth is not validated or sufficiently constrained. Specifically, it is not included in the public input to the proof, so it can be any arbitrary value. This creates several issues:  If submitted incorrectly, finalization will succeed. However, it would prevent any messages belonging to the affected message trees from being claimed on L1, since no proof can be provided for the incorrect depth stored. This would allow the operator to censor users even though their cross-chain messages were properly included in the L2 state.  A tree depth exceeding the provable depth can be submitted since l2MerkleTreesDepth is of size uint256, but the proof's leafIndex is a uint32 which would correspond to a max", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#intermediary-blocks-are-not-validated", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors were identified in the codebase:  The NatSpec around _addL2MerkleRoots should be plural as there are several Merkle roots taken as arguments  \"has\" should be \"have\"  \"achoring\" should be \"anchoring\"  \"Thrown current Data was already submitted\" should be \"Thrown when the current data was already submitted\"  \"concatonation\" should be \"concatenation\"  \"compatability\" should be \"compatibility\"  \"Add a cross-chain L1->L2 message hashes in storage\" [1] [2] should be \"Add cross-chain L1\u2192L2 message hashes in storage\"  To improve the overall readability of the codebase, consider correcting the identified errors.  Update: Resolved at commit 99039eb.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Pause Types Should be Cast to uint8", "body": "The PauseManager contract allows pausing a contract with different pause types. These pause types are stored in a uint256 variable treated as a bitmap. The bitmap is fetched and updated by using the bit shift operator.  overflow. Thus, passing a  Update: Resolved at commit 99039eb.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#pause-types-should-be-cast-to-uint8", "labels": ["OpenZeppelin"]}, {"title": "Refund Failure Using send in distributeFees Is Not Addressed", "body": "L2 and  L1, the  Consider either using transfer, which will revert on failure, or documenting the intent to allow failures.  Update: Acknowledged, not resolved. The Linea team stated:  This is intentional. The reason is that the refund is set up as an incentive and by forcing the transaction to fail once the relayer/postman has already paid for all the previous opcodes would be a waste of funds. We are looking into reworking the whole mechanism in a future audit along with refactoring the modifier.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#refund-failure-using-send-in-distributefees-is-not-addressed", "labels": ["OpenZeppelin"]}, {"title": "Arbitrary Calls Can Exploit Accidental Token Approvals", "body": "Both L1 and L2 contracts can be made to execute arbitrary calls when claiming a message. As a result, any tokens sent to these contracts, or any token approvals granted to them, can be easily exploited. Despite the fact that users should not grant approvals or send tokens to these contracts, there have been instances where users mistakenly sent significant amounts, such as 10K USDT to the L1 contract, which was subsequently taken.  Consider implementing a monitoring system for substantial transfers or approvals granted to these contracts. If such transactions are detected, promptly rescue these assets.  Update: Resolved. The Linea team stated:  Acknowledged. We have account monitoring and also offer the ability to contact our support to recover funds.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#arbitrary-calls-can-exploit-accidental-token-approvals", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary receive and fallback Methods", "body": "Multiple receive and fallback methods are defined in the contracts. In child contracts, these methods revert with an EthSendingDisabled error to prevent any ETH from being received. However, the practice of defining base methods that pass and overriding them with methods that revert is confusing, error-prone, and results in unnecessary deployment gas costs. Instead, removing all instances of these methods from the hierarchy would be equally effective in preventing the contract from receiving ETH or executing a fallback.  Consider removing all receive and fallback methods from the contracts.  Update: Resolved at commit 99039eb. The receive and fallback functions were removed.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#unnecessary-receive-and-fallback-methods", "labels": ["OpenZeppelin"]}, {"title": "claimMessage* Functions Susceptible to Relayer Griefing", "body": "The call to the destination in claimMessage* functions (example) can conditionally revert or consume an arbitrary amount of gas. Relayers rely on off-chain simulation to estimate the required gas and decide if the fee justifies the transaction, thereby exposing themselves to potential griefing attacks.  In a griefing attack, a large fee could be passed to entice relayers to complete the transaction. The off-chain simulation might suggest non-reversion, but the on-chain transaction could revert due to conditional factors or running out of gas. To bypass off-chain simulation, a destination contract could be designed to consume excessive gas or revert only when called on-chain (e.g., by inspecting gasleft(), tx.gasprice, block.coinbase, block.gaslimit, or other state variables that are often set differently during off-chain simulations). The attacker, having control over the destination contract, could then complete the transaction themselves to recover the fee. This vulnerability may limit the third-party relaying mechanism to only EOAs or trusted contracts.  Consider documenting this vulnerability and advising relayer software developers to simulate transactions with the exact transaction and global values that will be used on-chain.  Update: Acknowledged, not resolved. The Linea team stated:  We are investigating and will produce content based on the investigations.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#claimmessage*-functions-susceptible-to-relayer-griefing", "labels": ["OpenZeppelin"]}, {"title": "Compiler EVM Version for L2 Contracts Is paris Instead of london", "body": "Compiler configuration in hardhat.config specifies the EVM version for L1 contracts' 0.8.22 compiler as london, but does not specify it for L2 contracts' 0.8.19. As a result, L2 contracts will be compiled for EVM version paris which is the default version for solc 0.8.18 and 0.8.19. Hardhat by default uses the default solc version. This is inconsistent with Linea's provided documentation of being on the London EVM version for L2.  Consider specifying the EVM version explicitly for all used compiler versions.  Update: Resolved at commit 99039eb. The london version of the EVM was set in the Hardhat config. The Linea team stated:  Note that the changes in the paris version do not affect the behavior of the contracts on L2 that we have seen.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#compiler-evm-version-for-l2-contracts-is-paris-instead-of-london", "labels": ["OpenZeppelin"]}, {"title": "Testing Coverage Issues", "body": "It appears that no fork tests are used in the audited repository. Fork tests are of crucial importance in a system such as this owing to the usage of proxies, the need for a migration, and possible compiler configuration compatibility issues.  Some unit test coverage is also missing:  Usage of nonReentrant on claimMessageWithProof and claimMessage appears to not be tested.  RLP.sol only has 86% branch coverage with several untested execution branches.  Consider maintaining full unit test branch coverage, as well as running fork tests for the migration and automatically running them for any code change.  Update: Partially resolved at commit 99039eb. Reentrancy tests on the claimMessage and claimMessageWithProof functions are present but were overlooked during our review. The Linea team stated:  1. The RLP code will be removed in the upcoming versions and audits as it will no longer be used post migration. In addition, the branches not covered are not used in our code.2. We have tested the old versions and new with explicit bytecode and upgrade tests in the repository tests as well as simulations on Tenderly. 3. There are reentrancy tests that may have been overlooked when reviewing.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#testing-coverage-issues", "labels": ["OpenZeppelin"]}, {"title": "Gas Optimizations", "body": "The following opportunities for gas optimizations were found:  claimMessage* functions should only copy returndata if it is needed for the revert case. Otherwise, they pay for returdatacopy (and memory expansion costs) for data that will not be used. An assembly call should be used instead (since a Solidity low level call always copies the full returndata), and returndatasize should be checked in the reverting condition to determine if copying is needed.  In distributeFees modifiers, most of the code should be refactored into an internal method called from the modifier to prevent bytecode bloat due to inlining.  PauseManager: whenTypePaused and _requireTypePausedcan be removed since they are not used by the inheriting contracts.  GENERAL_PAUSE_TYPE is always checked with any other specific pause, so it could instead be moved into the internal pause checking logic. This would enable loading the bitmap only once from storage and reduce the contract size (by removing a modifier). The whenTypeNotPaused modifier would have to be renamed (e.g., to whenTypeOrGeneralNotPaused) to keep the clarity of the current implementation.  An L2MessagingBlockAnchored event is emitted for each bit of each offset, thus potentially emitting many tens of expensive events (each one having an overhead of 750 gas). A very large saving is possible by just emitting the array of offsets.  Upon a RollingHashUpdated event emission, the lastAnchoredL1MessageNumber storage variable is read and included in the event. Consider replacing it with currentL1MessageNumber to read from memory and save gas.  Consider updating these to save gas during the operation/deployment of the protocol.  Update: Partially resolved at commit 99039eb. All the mentioned instances have been updated except for the first, second, and fifth points. The Linea team stated:  The offsets are by design and there is an explicit need for the individual blocks to emit index block numbered events. The claim and distributeFees form part of future work.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#gas-optimizations", "labels": ["OpenZeppelin"]}, {"title": "Missing or Misleading Documentation", "body": "The following instances were found where the documentation could be made clearer:  The claimMessage function is documented as being \"called automatically by the Postman, dApp, or end user\". Consider removing the word \"automatically\".  The NatSpec around the SubmissionData struct would benefit from additional details, notably regarding what snarkHash is and what is contained in the compressedData.  The NatSpec around the SubmissionData struct incorrectly states that \"compressedData is a hash of the transaction data\".  l1RollingHashMessageNumber is incorrectly documented as being \"the calculated block number on L2\". Consider explicitly stating that it is a message number and not a block number.  The NatSpec around _l2MessagingBlocksOffsets should explain that it is a sequence of uint16 representing the L2 blocks numbers which contain L2\u2192L1 messages as offsets from the current block.  Consider updating the above instances to improve the clarity of the codebase.  Update: Resolved at commit 99039eb.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#missing-or-misleading-documentation", "labels": ["OpenZeppelin"]}, {"title": "Multiple Instances of Missing Named Parameters in Mappings", "body": "Since Solidity 0.8.18, developers can utilize named parameters in mappings. This means that mappings can take the form of mapping(KeyType KeyName? => ValueType ValueName?). This updated syntax provides a more transparent representation of a mapping's purpose.  Throughout the codebase, there are multiple mappings which could benefit from having named parameters:  The rollingHashes and l2MerkleRoots state variables in the L1MessageManager contract  The outboxL1L2MessageStatus and inboxL2L1MessageStatus state variables in the L1MessageManagerV1 contract  The l1RollingHashes state variable in the L2MessageManager contract  The inboxL1L2MessageStatus state variable in the L2MessageManagerV1 contract  The dataFinalStateRootHashes, dataShnarfHashes, and dataParents state variables in the LineaRollup contract  The stateRootHashes and verifiers state variables in the ZkEvmV2 contract  Consider adding named parameters to these mappings to improve the readability and maintainability of the codebase.  Update: Resolved at commit 99039eb.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#multiple-instances-of-missing-named-parameters-in-mappings", "labels": ["OpenZeppelin"]}, {"title": "Lack of Event Emission", "body": "Throughout the codebase, some functions could benefit from an added event emission:  The __SystemMigrationBlock_init function could emit an event to indicate the block at which it was migrated.  The setMinimumFee function could emit an event to indicate that the fee was changed.  __RateLimiter_init could emit an event to indicate the initial values set for periodInSeconds, limitInWei, and currentPeriodEnd.  Consider emitting events whenever there are state changes to help off-chain services accurately follow the state of the contracts.  Update: Resolved at commit 99039eb. The mentioned events have been added.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#lack-of-event-emission", "labels": ["OpenZeppelin"]}, {"title": "Client Reported", "body": "Client Reported", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Submission and Finalization Fails for the First Batch of Data Submitted After Migration to the Updated Contract", "body": "When submitting the initial batch of compressed block data after the contract update, submission and finalization will fail.  Recommendation  Set the correct initial value for dataFinalStateRootHashes for the initial batch of the compressed block data.  Update: Resolved at commit 99039eb. Some exceptions were added to allow the parent of a submitted data to be empty, in which case finalization will not check the final state root of this empty parent.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#submission-and-finalization-fails-for-the-first-batch-of-data-submitted-after-migration-to-the-updated-contract", "labels": ["OpenZeppelin"]}, {"title": "Prover Can Censor L2 \u2192 L1 Messages", "body": "In L2\u2192L1 messaging, messages are grouped and added to a Merkle tree by the prover. During finalization, the operator (coordinator) submits the Merkle root to L1 and the user SDK rebuilds the tree to which the message is added and generates a Merkle proof to claim against the root finalized on L1.  However, the prover can skip messages when building the tree. Consequently, the user cannot claim the skipped message, which might result in frozen funds. Currently, the prover is a single entity owned by Linea. Hence, this would require malice or negligence on Lineas part.  Recommendation  Decentralize the prover so that messages can be included by different provers.  Update: Acknowledged, will resolve. The Linea team stated:  This will be enforced in the circuit and will be the same circuit that all decentralized parties use.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#prover-can-censor-l2-\u2192-l1-messages", "labels": ["OpenZeppelin"]}, {"title": "Malicious Operator Might Finalize Data From a Forked Linea Chain", "body": "A malicious operator (prover) can add and finalize block data from a forked Linea chain. Thus, transactions on the forked chain can be finalized, causing a loss of funds from the L1.  For example, a malicious operator forks the canonical chain after which the attacker sends the forked chain ETH to L1 with sendMessage from the forked L2. The operator then submits the block data to L1 and finalizes it with finalizeCompressedBlocksWithProof, using the finalization data and proof from the forked chain. (Note that the malicious prover sets the forked chain's chainId in its circuit as a constant). The L1 contract (LineaRollup) does not know whether the data and the proof are from the canonical L2 or the forked one. The finalization succeeds and the attacker can claim the bridged forked chain ETH and steal funds from L1.  As there is currently only one operator and it is owned by the Linea team, this kind of attack is unlikely to happen. However, when the operator and the coordinator are decentralized, the likelihood of this attack increases.  Recommendation  Add chainId in the FinalizationData as a public input of the verifier function _verifyProof. This is so that the proof from the forked Linea chain will not pass the verification because the chainId will not match.  Update: Acknowledged, will resolve. The Linea team stated:  This will be enforced in the circuit and will be the same circuit that all decentralized parties use. ChainId is hardcoded in the circuit.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#malicious-operator-might-finalize-data-from-a-forked-linea-chain", "labels": ["OpenZeppelin"]}, {"title": "The Compressed Block Data Is Not Verified Against Data in the Prover During Data Submission", "body": "When the sequencer submits the batched block data with the submitData function, it is expected to check that the submitted commitment of the compressed block data keccak(_submissionData.compressedData) and the commitment of the block data used in the prover (snarkHash) commit to the same data. This is done by proof of equivalence.  The only difference is that if the two commitments do not commit to the same block data (meaning the data submitted doesnt match the data used in the prover), submitData would fail. Whereas in the current implementation, it would fail in the proof verification during the finalization. As a result, if the data submitted does not match the data in the prover in the finalization, the operator has to submit the correct data again in order to finalize it. Linea has stated that they will verify it in the data submission once EIP-4844 is implemented.  Recommendation  Add the compressed block data verification in the submitData function.  Update: Acknowledged, will resolve. The Linea team stated:  The values will be verified in the proof/verifier and will be addressed with the 4844 changes.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-compressed-block-data-is-not-verified-against-data-in-the-prover-during-data-submission", "labels": ["OpenZeppelin"]}, {"title": "Empty Compressed Data Allowed in Data Submission", "body": "Empty Compressed Data Allowed in Data Submission", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#empty-compressed-data-allowed-in-data-submission", "labels": ["OpenZeppelin"]}, {"title": "Recommendations", "body": "Conclusion  Summary  L2  From 2023-12-11  To 2024-01-19  Solidity + Yul  41 (20\u202fresolved, 7\u202fpartially\u202fresolved)  0 (0\u202fresolved)  1 (0\u202fresolved, 1\u202fpartially\u202fresolved)  10 (5\u202fresolved, 1\u202fpartially\u202fresolved)  13 (5\u202fresolved, 3\u202fpartially\u202fresolved)  12 (8\u202fresolved, 2\u202fpartially\u202fresolved)  5 (2\u202fresolved)  Scope  We audited the Consensys/linea-contracts-audit repository at commit bb6eb72. All the resolutions mentioned in this report are contained at commit 99039eb, making it the final version reviewed during this audit.  In scope were the following files:  System Overview  Linea is a Zero-Knowledge (ZK) rollup and an Ethereum Layer Two (L2). It executes L2 transactions, publishes the associated data, and then proves the correctness of the state transition on Ethereum. This correctness is ensured by verifying validity proofs. These are proofs that a ZK circuit reproducing the Ethereum Virtual Machine (EVM) executed the transactions successfully and reached the proposed state. Importantly, validity proofs are succinct, meaning that they are cheaper to verify than re-executing L2 transactions. This allows the execution of transactions to be cheaper, providing users with lower transaction fees on Linea than on L1.  The audited codebase represents the second version (V2) of the Linea rollup contracts which differs from the first version (V1) in a few aspects:  The data submission and verification logic were reworked in anticipation of EIP-4844.  An L1\u2192L2 rolling hash mechanism is validated when finalizing on L1. This is to ensure that no L1\u2192L2 messages were maliciously forged or censored by the coordinator on L2.  Cross-chain L2\u2192L1 messages are now batched and anchored on L1 as the roots of sparse Merkle trees instead of anchoring all the message hashes separately.  Similar to V1, the contracts on both layers are constrained by a RateLimiter contract, which limits the amount of ETH that can be sent from L2 and claimed from messages on L1. The codebase is composed of two main contracts to which the Linea contract implementations will be upgraded as part of the version upgrade.  Layer 1  The LineaRollup contract will be upgraded on L1 and is responsible for three main tasks.  The first is to ensure the availability of the data associated with L2 transactions on Ethereum. To do so, a Linea operator batches L2 transaction data, compresses it, and stores it in calldata on Ethereum by calling the submitData function. The availability of this data is important for rollup users to ensure that the L2 state can be rebuilt without relying on anything else other than the data posted to Ethereum. In the future, this data will be posted to Ethereum as blobs (see EIP-4844).  The second responsibility of the LineaRollup contract is to query a PLONK verifier to verify proofs, and thus the validity of state transitions. This ensures that the data submitted to Ethereum matches signed L2 transactions, that these transactions resulted in the proposed state transition, and that the transition is valid. This verification is done by the operator calling the finalizeCompressedBlocksWithProof function which finalizes the state transition and stores the new state root.  The third main responsibility of the contract is to send and receive cross-chain messages to and from L2. L1\u2192L2 messages are sent by the users calling the sendMessage function which emits a MessageSent event. This event is then detected by the coordinator and relayed to L2. Messages sent after the V2 migration will be added to a rolling hash that is reproduced on L2. These rolling hashes are verified to be consistent across the two layers during finalization. During finalization, L2\u2192L1 messages are anchored on L1 in the form of the root of a sparse Merkle tree. Users can then call claimMessageWithProof with a Merkle proof against this root to execute their transaction on L1.  Layer 2  The L2MessageService contract will be deployed on L2, and is responsible for sending and receiving messages to and from L1. Similar to the contract on L1, users can call the sendMessage function on L2 to have the coordinator relay the cross-chain message and anchor it on L1. In addition, L1\u2192L2 messages are anchored on L2 by the coordinator calling the anchorL1L2MessageHashes function, making the message claimable by users and adding it to the L2 rolling hash.  Privileged Roles  There are multiple privileged roles in the system:  OPERATOR_ROLE: Operators can call submitData and finalizeCompressedBlocksWithProof on LineaRollup to submit data, as well as finalize a rollup state transition (and thus anchor L2\u2192L1 messages).  DEFAULT_ADMIN_ROLE: Addresses with this role can grant any other role to another address, as well as call finalizeCompressedBlocksWithoutProof to finalize a state transition without having to provide a valid proof. This function is only intended to be used in case of an emergency and during the V1 to V2 migration. This role has been granted to the Linea security council.  VERIFIER_SET", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#recommendations", "labels": ["OpenZeppelin"]}, {"title": "General Recommendations", "body": "General Recommendations", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#general-recommendations", "labels": ["OpenZeppelin"]}, {"title": "Summary", "body": "Summary", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#summary", "labels": ["OpenZeppelin"]}, {"title": "L2", "body": "\u2192 L1 Messages Due to Required Operator Cooperation with Users V1 addL1MessageHashes Allows L1 \u2192  Messages to Be Censored and May Prevent Finalization Message Setter Can Anchor Arbitrary Messages on  Incorrectly Submitted Data Prevents Finalization Non-Unique compressedData Can Prevent Submission Insufficient Validation of Block Numbers During Submission and Finalization Relayer Claiming a Message to a Contract Destination Does Not Refund the User Third-Party Message Claiming for EOAs Is Uneconomical  Low Severity  Loaded Shnarf Is Not Checked to Be Non-Empty Submission Data Can Be Overwritten in Certain Circumstances Insufficient Validations in Polynomial Openings Message Anchoring on  Is Not Pausable sendMessage Reentrancy on  Could Result in Unordered MessageSent Events Unproven Upgrade State Transition May Reduce Trust in State Validity Sequencer Censorship Issues Code Quality and Readability Suggestions Insufficient Validation of Parent State Root Hashes When Finalizing Without Proof False Sense of Security Due to Validation of Unused Data Fields Reliance on Application-Level Logic in Chain State Transition Proof Data Chain Integrity Can Be Broken Intermediary Blocks Are Not Validated  Notes & Additional Information  Typographical Errors Pause Types Should be Cast to uint8 Refund Failure Using send in distributeFees Is Not Addressed Arbitrary Calls Can Exploit Accidental Token Approvals Unnecessary receive and fallback Methods claimMessage* Functions Susceptible to Relayer Griefing Compiler EVM Version for  Contracts Is paris Instead of london Testing Coverage Issues Gas Optimizations Missing or Misleading Documentation Multiple Instances of Missing Named Parameters in Mappings Lack of Event Emission  Client Reported  Submission and Finalization Fails for the First Batch of Data Submitted After Migration to the Updated Contract Prover Can Censor  \u2192 L1 Messages Malicious Operator Might Finalize Data From a Forked Linea Chain The Compressed Block Data Is Not Verified Against Data in the Prover During Data Submission Empty Compressed Data Allowed in Data Submission  Recommendations  General Recommendations  Conclusion  Summary    From 2023-12-11  To 2024-01-19  Solidity + Yul  41 (20\u202fresolved, 7\u202fpartially\u202fresolved)  0 (0\u202fresolved)  1 (0\u202fresolved, 1\u202fpartially\u202fresolved)  10 (5\u202fresolved, 1\u202fpartially\u202fresolved)  13 (5\u202fresolved, 3\u202fpartially\u202fresolved)  12 (8\u202fresolved, 2\u202fpartially\u202fresolved)  5 (2\u202fresolved)  Scope  We audited the Consensys/linea-contracts-audit repository at commit bb6eb72. All the resolutions mentioned in this report are contained at commit 99039eb, making it the final version reviewed during this audit.  In scope were the following files:  System Overview  Linea is a Zero-Knowledge (ZK) rollup and an Ethereum Layer Two (). It executes  transactions, publishes the associated data, and then proves the correctness of the state transition on Ethereum. This correctness is ensured by verifying validity proofs. These are proofs that a ZK circuit reproducing the Ethereum Virtual Machine (EVM) executed the transactions successfully and reached the proposed state. Importantly, validity proofs are succinct, meaning that they are cheaper to verify than re-executing  transactions. This allows the execution of transactions to be cheaper, providing users with lower transaction fees on Linea than on L1.  The audited codebase represents the second version (V2) of the Linea rollup contracts which differs from the first version (V1) in a few aspects:  The data submission and verification logic were reworked in anticipation of EIP-4844.  An L1\u2192 rolling hash mechanism is validated when finalizing on L1. This is to ensure that no L1\u2192 messages were maliciously forged or censored by the coordinator on .  Cross-chain \u2192L1 messages are now batched and anchored on L1 as the roots of sparse Merkle trees instead of anchoring all the message hashes separately.  Similar to V1, the contracts on both layers are constrained by a RateLimiter contract, which limits the amount of ETH that can be sent from  and claimed from messages on L1. The codebase is composed of two main contracts to which the Linea contract implementations will be upgraded as part of the version upgrade.  Layer 1  The LineaRollup contract will be upgraded on L1 and is responsible for three main tasks.  The first is to ensure the availability of the data associated with  transactions on Ethereum. To do so, a Linea operator batches  transaction data, compresses it, and stores it in calldata on Ethereum by calling the submitData function. The availability of this data is important for rollup users to ensure that the  state can be rebuilt without relying on anything else other than the data posted to Ethereum. In the future, this data will be posted to Ethereum as blobs (see EIP-4844).  The second responsibility of the LineaRollup contract is to query a PLONK verifier to verify proofs, and thus the validity of state transitions. This ensures that the data submitted ", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#l2", "labels": ["OpenZeppelin"]}, {"title": "From 2023-12-11", "body": "From 2023-12-11", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#from-2023-12-11", "labels": ["OpenZeppelin"]}, {"title": "To 2024-01-19", "body": "To 2024-01-19", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#to-2024-01-19", "labels": ["OpenZeppelin"]}, {"title": "Solidity + Yul", "body": "Solidity + Yul", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#solidity-+-yul", "labels": ["OpenZeppelin"]}, {"title": "41 (20\u202fresolved, 7\u202fpartially\u202fresolved)", "body": "41 (20\u202fresolved, 7\u202fpartially\u202fresolved)", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#41-(20\u202fresolved,-7\u202fpartially\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "0 (0\u202fresolved)", "body": "0 (0\u202fresolved)", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#0-(0\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "1 (0\u202fresolved, 1\u202fpartially\u202fresolved)", "body": "1 (0\u202fresolved, 1\u202fpartially\u202fresolved)", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#1-(0\u202fresolved,-1\u202fpartially\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "10 (5\u202fresolved, 1\u202fpartially\u202fresolved)", "body": "10 (5\u202fresolved, 1\u202fpartially\u202fresolved)", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#10-(5\u202fresolved,-1\u202fpartially\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "13 (5\u202fresolved, 3\u202fpartially\u202fresolved)", "body": "13 (5\u202fresolved, 3\u202fpartially\u202fresolved)", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#13-(5\u202fresolved,-3\u202fpartially\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "12 (8\u202fresolved, 2\u202fpartially\u202fresolved)", "body": "12 (8\u202fresolved, 2\u202fpartially\u202fresolved)", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#12-(8\u202fresolved,-2\u202fpartially\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "5 (2\u202fresolved)", "body": "5 (2\u202fresolved)", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#5-(2\u202fresolved)", "labels": ["OpenZeppelin"]}, {"title": "Scope", "body": "We audited the Consensys/linea-contracts-audit repository at commit bb6eb72. All the resolutions mentioned in this report are contained at commit 99039eb, making it the final version reviewed during this audit.  In scope were the following files:  System Overview  Linea is a Zero-Knowledge (ZK) rollup and an Ethereum Layer Two (L2). It executes L2 transactions, publishes the associated data, and then proves the correctness of the state transition on Ethereum. This correctness is ensured by verifying validity proofs. These are proofs that a ZK circuit reproducing the Ethereum Virtual Machine (EVM) executed the transactions successfully and reached the proposed state. Importantly, validity proofs are succinct, meaning that they are cheaper to verify than re-executing L2 transactions. This allows the execution of transactions to be cheaper, providing users with lower transaction fees on Linea than on L1.  The audited codebase represents the second version (V2) of the Linea rollup contracts which differs from the first version (V1) in a few aspects:  The data submission and verification logic were reworked in anticipation of EIP-4844.  An L1\u2192L2 rolling hash mechanism is validated when finalizing on L1. This is to ensure that no L1\u2192L2 messages were maliciously forged or censored by the coordinator on L2.  Cross-chain L2\u2192L1 messages are now batched and anchored on L1 as the roots of sparse Merkle trees instead of anchoring all the message hashes separately.  Similar to V1, the contracts on both layers are constrained by a RateLimiter contract, which limits the amount of ETH that can be sent from L2 and claimed from messages on L1. The codebase is composed of two main contracts to which the Linea contract implementations will be upgraded as part of the version upgrade.  Layer 1  The LineaRollup contract will be upgraded on L1 and is responsible for three main tasks.  The first is to ensure the availability of the data associated with L2 transactions on Ethereum. To do so, a Linea operator batches L2 transaction data, compresses it, and stores it in calldata on Ethereum by calling the submitData function. The availability of this data is important for rollup users to ensure that the L2 state can be rebuilt without relying on anything else other than the data posted to Ethereum. In the future, this data will be posted to Ethereum as blobs (see EIP-4844).  The second responsibility of the LineaRollup contract is to query a PLONK verifier to verify proofs, and thus the validity of state transitions. This ensures that the data submitted to Ethereum matches signed L2 transactions, that these transactions resulted in the proposed state transition, and that the transition is valid. This verification is done by the operator calling the finalizeCompressedBlocksWithProof function which finalizes the state transition and stores the new state root.  The third main responsibility of the contract is to send and receive cross-chain messages to and from L2. L1\u2192L2 messages are sent by the users calling the sendMessage function which emits a MessageSent event. This event is then detected by the coordinator and relayed to L2. Messages sent after the V2 migration will be added to a rolling hash that is reproduced on L2. These rolling hashes are verified to be consistent across the two layers during finalization. During finalization, L2\u2192L1 messages are anchored on L1 in the form of the root of a sparse Merkle tree. Users can then call claimMessageWithProof with a Merkle proof against this root to execute their transaction on L1.  Layer 2  The L2MessageService contract will be deployed on L2, and is responsible for sending and receiving messages to and from L1. Similar to the contract on L1, users can call the sendMessage function on L2 to have the coordinator relay the cross-chain message and anchor it on L1. In addition, L1\u2192L2 messages are anchored on L2 by the coordinator calling the anchorL1L2MessageHashes function, making the message claimable by users and adding it to the L2 rolling hash.  Privileged Roles  There are multiple privileged roles in the system:  OPERATOR_ROLE: Operators can call submitData and finalizeCompressedBlocksWithProof on LineaRollup to submit data, as well as finalize a rollup state transition (and thus anchor L2\u2192L1 messages).  DEFAULT_ADMIN_ROLE: Addresses with this role can grant any other role to another address, as well as call finalizeCompressedBlocksWithoutProof to finalize a state transition without having to provide a valid proof. This function is only intended to be used in case of an emergency and during the V1 to V2 migration. This role has been granted to the Linea security council.  VERIFIER_SETTER_ROLE: This role can call setVerifierAddress to set a new address which can verify validity proofs. This role is part of the V2 changes and will be granted to the Timelock address as part of the migration.  RATE_LIMIT_SETTER_ROLE: The rate limit setter can call the resetRateLimitAmount and resetAmountUs", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#scope", "labels": ["OpenZeppelin"]}, {"title": "We audited the Consensys/linea-contracts-audit repository at commit bb6eb72. All the resolutions mentioned in this report are contained at commit 99039eb, making it the final version reviewed during this audit.", "body": "We audited the Consensys/linea-contracts-audit repository at commit bb6eb72. All the resolutions mentioned in this report are contained at commit 99039eb, making it the final version reviewed during this audit.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#we-audited-the-consensys/linea-contracts-audit-repository-at-commit-bb6eb72.-all-the-resolutions-mentioned-in-this-report-are-contained-at-commit-99039eb,-making-it-the-final-version-reviewed-during-this-audit.", "labels": ["OpenZeppelin"]}, {"title": "In scope were the following files:", "body": "In scope were the following files:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#in-scope-were-the-following-files:", "labels": ["OpenZeppelin"]}, {"title": "System Overview", "body": "Linea is a Zero-Knowledge (ZK) rollup and an Ethereum Layer Two (L2). It executes L2 transactions, publishes the associated data, and then proves the correctness of the state transition on Ethereum. This correctness is ensured by verifying validity proofs. These are proofs that a ZK circuit reproducing the Ethereum Virtual Machine (EVM) executed the transactions successfully and reached the proposed state. Importantly, validity proofs are succinct, meaning that they are cheaper to verify than re-executing L2 transactions. This allows the execution of transactions to be cheaper, providing users with lower transaction fees on Linea than on L1.  The audited codebase represents the second version (V2) of the Linea rollup contracts which differs from the first version (V1) in a few aspects:  The data submission and verification logic were reworked in anticipation of EIP-4844.  An L1\u2192L2 rolling hash mechanism is validated when finalizing on L1. This is to ensure that no L1\u2192L2 messages were maliciously forged or censored by the coordinator on L2.  Cross-chain L2\u2192L1 messages are now batched and anchored on L1 as the roots of sparse Merkle trees instead of anchoring all the message hashes separately.  Similar to V1, the contracts on both layers are constrained by a RateLimiter contract, which limits the amount of ETH that can be sent from L2 and claimed from messages on L1. The codebase is composed of two main contracts to which the Linea contract implementations will be upgraded as part of the version upgrade.  Layer 1  The LineaRollup contract will be upgraded on L1 and is responsible for three main tasks.  The first is to ensure the availability of the data associated with L2 transactions on Ethereum. To do so, a Linea operator batches L2 transaction data, compresses it, and stores it in calldata on Ethereum by calling the submitData function. The availability of this data is important for rollup users to ensure that the L2 state can be rebuilt without relying on anything else other than the data posted to Ethereum. In the future, this data will be posted to Ethereum as blobs (see EIP-4844).  The second responsibility of the LineaRollup contract is to query a PLONK verifier to verify proofs, and thus the validity of state transitions. This ensures that the data submitted to Ethereum matches signed L2 transactions, that these transactions resulted in the proposed state transition, and that the transition is valid. This verification is done by the operator calling the finalizeCompressedBlocksWithProof function which finalizes the state transition and stores the new state root.  The third main responsibility of the contract is to send and receive cross-chain messages to and from L2. L1\u2192L2 messages are sent by the users calling the sendMessage function which emits a MessageSent event. This event is then detected by the coordinator and relayed to L2. Messages sent after the V2 migration will be added to a rolling hash that is reproduced on L2. These rolling hashes are verified to be consistent across the two layers during finalization. During finalization, L2\u2192L1 messages are anchored on L1 in the form of the root of a sparse Merkle tree. Users can then call claimMessageWithProof with a Merkle proof against this root to execute their transaction on L1.  Layer 2  The L2MessageService contract will be deployed on L2, and is responsible for sending and receiving messages to and from L1. Similar to the contract on L1, users can call the sendMessage function on L2 to have the coordinator relay the cross-chain message and anchor it on L1. In addition, L1\u2192L2 messages are anchored on L2 by the coordinator calling the anchorL1L2MessageHashes function, making the message claimable by users and adding it to the L2 rolling hash.  Privileged Roles  There are multiple privileged roles in the system:  OPERATOR_ROLE: Operators can call submitData and finalizeCompressedBlocksWithProof on LineaRollup to submit data, as well as finalize a rollup state transition (and thus anchor L2\u2192L1 messages).  DEFAULT_ADMIN_ROLE: Addresses with this role can grant any other role to another address, as well as call finalizeCompressedBlocksWithoutProof to finalize a state transition without having to provide a valid proof. This function is only intended to be used in case of an emergency and during the V1 to V2 migration. This role has been granted to the Linea security council.  VERIFIER_SETTER_ROLE: This role can call setVerifierAddress to set a new address which can verify validity proofs. This role is part of the V2 changes and will be granted to the Timelock address as part of the migration.  RATE_LIMIT_SETTER_ROLE: The rate limit setter can call the resetRateLimitAmount and resetAmountUsedInPeriod functions on the two contracts to change the rate limit or reset the amount in the internal accounting.  PAUSE_MANAGER_ROLE: The pause manager can prevent different sets of functions from being called by pausing the contracts with four different pause ty", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#system-overview", "labels": ["OpenZeppelin"]}, {"title": "Linea is a Zero-Knowledge (ZK) rollup and an Ethereum Layer Two (L2). It executes L2 transactions, publishes the associated data, and then proves the correctness of the state transition on Ethereum. This correctness is ensured by verifying validity proofs. These are proofs that a ZK circuit reproducing the Ethereum Virtual Machine (EVM) executed the transactions successfully and reached the proposed state. Importantly, validity proofs are succinct, meaning that they are cheaper to verify than re-executing L2 transactions. This allows the execution of transactions to be cheaper, providing users with lower transaction fees on Linea than on L1.", "body": "Linea is a Zero-Knowledge (ZK) rollup and an Ethereum Layer Two (L2). It executes L2 transactions, publishes the associated data, and then proves the correctness of the state transition on Ethereum. This correctness is ensured by verifying validity proofs. These are proofs that a ZK circuit reproducing the Ethereum Virtual Machine (EVM) executed the transactions successfully and reached the proposed state. Importantly, validity proofs are succinct, meaning that they are cheaper to verify than re-executing L2 transactions. This allows the execution of transactions to be cheaper, providing users with lower transaction fees on Linea than on L1.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#linea-is-a-zero-knowledge-(zk)-rollup-and-an-ethereum-layer-two-(l2).-it-executes-l2-transactions,-publishes-the-associated-data,-and-then-proves-the-correctness-of-the-state-transition-on-ethereum.-this-correctness-is-ensured-by-verifying-validity-proofs.-these-are-proofs-that-a-zk-circuit-reproducing-the-ethereum-virtual-machine-(evm)-executed-the-transactions-successfully-and-reached-the-proposed-state.-importantly,-validity-proofs-are-succinct,-meaning-that-they-are-cheaper-to-verify-than-re-executing-l2-transactions.-this-allows-the-execution-of-transactions-to-be-cheaper,-providing-users-with-lower-transaction-fees-on-linea-than-on-l1.", "labels": ["OpenZeppelin"]}, {"title": "The audited codebase represents the second version (V2) of the Linea rollup contracts which differs from the first version (V1) in a few aspects:", "body": "The audited codebase represents the second version (V2) of the Linea rollup contracts which differs from the first version (V1) in a few aspects:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-audited-codebase-represents-the-second-version-(v2)-of-the-linea-rollup-contracts-which-differs-from-the-first-version-(v1)-in-a-few-aspects:", "labels": ["OpenZeppelin"]}, {"title": "The data submission and verification logic were reworked in anticipation of EIP-4844.", "body": "The data submission and verification logic were reworked in anticipation of EIP-4844.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-data-submission-and-verification-logic-were-reworked-in-anticipation-of-eip-4844.", "labels": ["OpenZeppelin"]}, {"title": "An L1\u2192L2 rolling hash mechanism is validated when finalizing on L1. This is to ensure that no L1\u2192L2 messages were maliciously forged or censored by the coordinator on L2.", "body": "An L1\u2192L2 rolling hash mechanism is validated when finalizing on L1. This is to ensure that no L1\u2192L2 messages were maliciously forged or censored by the coordinator on L2.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#an-l1\u2192l2-rolling-hash-mechanism-is-validated-when-finalizing-on-l1.-this-is-to-ensure-that-no-l1\u2192l2-messages-were-maliciously-forged-or-censored-by-the-coordinator-on-l2.", "labels": ["OpenZeppelin"]}, {"title": "Cross-chain L2\u2192L1 messages are now batched and anchored on L1 as the roots of sparse Merkle trees instead of anchoring all the message hashes separately.", "body": "Cross-chain L2\u2192L1 messages are now batched and anchored on L1 as the roots of sparse Merkle trees instead of anchoring all the message hashes separately.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#cross-chain-l2\u2192l1-messages-are-now-batched-and-anchored-on-l1-as-the-roots-of-sparse-merkle-trees-instead-of-anchoring-all-the-message-hashes-separately.", "labels": ["OpenZeppelin"]}, {"title": "Similar to V1, the contracts on both layers are constrained by a RateLimiter contract, which limits the amount of ETH that can be sent from L2 and claimed from messages on L1. The codebase is composed of two main contracts to which the Linea contract implementations will be upgraded as part of the version upgrade.", "body": "Similar to V1, the contracts on both layers are constrained by a RateLimiter contract, which limits the amount of ETH that can be sent from L2 and claimed from messages on L1. The codebase is composed of two main contracts to which the Linea contract implementations will be upgraded as part of the version upgrade.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#similar-to-v1,-the-contracts-on-both-layers-are-constrained-by-a-ratelimiter-contract,-which-limits-the-amount-of-eth-that-can-be-sent-from-l2-and-claimed-from-messages-on-l1.-the-codebase-is-composed-of-two-main-contracts-to-which-the-linea-contract-implementations-will-be-upgraded-as-part-of-the-version-upgrade.", "labels": ["OpenZeppelin"]}, {"title": "Layer 1", "body": "The LineaRollup contract will be upgraded on L1 and is responsible for three main tasks.  The first is to ensure the availability of the data associated with L2 transactions on Ethereum. To do so, a Linea operator batches L2 transaction data, compresses it, and stores it in calldata on Ethereum by calling the submitData function. The availability of this data is important for rollup users to ensure that the L2 state can be rebuilt without relying on anything else other than the data posted to Ethereum. In the future, this data will be posted to Ethereum as blobs (see EIP-4844).  The second responsibility of the LineaRollup contract is to query a PLONK verifier to verify proofs, and thus the validity of state transitions. This ensures that the data submitted to Ethereum matches signed L2 transactions, that these transactions resulted in the proposed state transition, and that the transition is valid. This verification is done by the operator calling the finalizeCompressedBlocksWithProof function which finalizes the state transition and stores the new state root.  The third main responsibility of the contract is to send and receive cross-chain messages to and from L2. L1\u2192L2 messages are sent by the users calling the sendMessage function which emits a MessageSent event. This event is then detected by the coordinator and relayed to L2. Messages sent after the V2 migration will be added to a rolling hash that is reproduced on L2. These rolling hashes are verified to be consistent across the two layers during finalization. During finalization, L2\u2192L1 messages are anchored on L1 in the form of the root of a sparse Merkle tree. Users can then call claimMessageWithProof with a Merkle proof against this root to execute their transaction on L1.  Layer 2  The L2MessageService contract will be deployed on L2, and is responsible for sending and receiving messages to and from L1. Similar to the contract on L1, users can call the sendMessage function on L2 to have the coordinator relay the cross-chain message and anchor it on L1. In addition, L1\u2192L2 messages are anchored on L2 by the coordinator calling the anchorL1L2MessageHashes function, making the message claimable by users and adding it to the L2 rolling hash.  Privileged Roles  There are multiple privileged roles in the system:  OPERATOR_ROLE: Operators can call submitData and finalizeCompressedBlocksWithProof on LineaRollup to submit data, as well as finalize a rollup state transition (and thus anchor L2\u2192L1 messages).  DEFAULT_ADMIN_ROLE: Addresses with this role can grant any other role to another address, as well as call finalizeCompressedBlocksWithoutProof to finalize a state transition without having to provide a valid proof. This function is only intended to be used in case of an emergency and during the V1 to V2 migration. This role has been granted to the Linea security council.  VERIFIER_SETTER_ROLE: This role can call setVerifierAddress to set a new address which can verify validity proofs. This role is part of the V2 changes and will be granted to the Timelock address as part of the migration.  RATE_LIMIT_SETTER_ROLE: The rate limit setter can call the resetRateLimitAmount and resetAmountUsedInPeriod functions on the two contracts to change the rate limit or reset the amount in the internal accounting.  PAUSE_MANAGER_ROLE: The pause manager can prevent different sets of functions from being called by pausing the contracts with four different pause types.  L1_L2_MESSAGE_SETTER_ROLE: This role is given to the coordinator who can call the addL1L2MessageHashes and anchorL1L2MessageHashes functions to anchor L1\u2192L2 messages for V1/V2 respectively.  MINIMUM_FEE_SETTER_ROLE: The fee setter can set the fee collected by the Linea node operator (block.coinbase) on L2\u2192L1 messages by calling setMinimumFee.  Security Model and Trust Assumptions  There are several trust assumptions for users of the audited codebase:  All of the addresses with the roles mentioned above can impact users in different ways, and if compromised, could freeze or steal users' funds depending on the roles granted to them.  As Linea is a ZK rollup without an open-source circuit, users trust that the circuit faithfully reproduces the EVM execution environment and is implemented in a way that does not allow a malicious prover to supply inputs that may prove an invalid state transition.  As underlined in one of the issues below, there is currently no software available to rebuild the L2 state from L1-posted data. Users thus trust the Linea operator to send them the data they need to build inclusion proofs or to resume the operation of the chain if the operator and L2 data become unavailable.  Similar to most rollups today, the sequencer can censor L2 transactions.  There is currently no way for users to force the inclusion of a cross-chain transaction in neither the L1\u2192L2 nor the L2\u2192L1 direction. This is because Linea's messaging system is purely ticket-based. While messages can be proven to be claimab", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#layer-1", "labels": ["OpenZeppelin"]}, {"title": "The LineaRollup contract will be upgraded on L1 and is responsible for three main tasks.", "body": "The LineaRollup contract will be upgraded on L1 and is responsible for three main tasks.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-linearollup-contract-will-be-upgraded-on-l1-and-is-responsible-for-three-main-tasks.", "labels": ["OpenZeppelin"]}, {"title": "The first is to ensure the availability of the data associated with L2 transactions on Ethereum. To do so, a Linea operator batches L2 transaction data, compresses it, and stores it in calldata on Ethereum by calling the submitData function. The availability of this data is important for rollup users to ensure that the L2 state can be rebuilt without relying on anything else other than the data posted to Ethereum. In the future, this data will be posted to Ethereum as blobs (see EIP-4844).", "body": "The first is to ensure the availability of the data associated with L2 transactions on Ethereum. To do so, a Linea operator batches L2 transaction data, compresses it, and stores it in calldata on Ethereum by calling the submitData function. The availability of this data is important for rollup users to ensure that the L2 state can be rebuilt without relying on anything else other than the data posted to Ethereum. In the future, this data will be posted to Ethereum as blobs (see EIP-4844).", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-first-is-to-ensure-the-availability-of-the-data-associated-with-l2-transactions-on-ethereum.-to-do-so,-a-linea-operator-batches-l2-transaction-data,-compresses-it,-and-stores-it-in-calldata-on-ethereum-by-calling-the-submitdata-function.-the-availability-of-this-data-is-important-for-rollup-users-to-ensure-that-the-l2-state-can-be-rebuilt-without-relying-on-anything-else-other-than-the-data-posted-to-ethereum.-in-the-future,-this-data-will-be-posted-to-ethereum-as-blobs-(see-eip-4844).", "labels": ["OpenZeppelin"]}, {"title": "The second responsibility of the LineaRollup contract is to query a PLONK verifier to verify proofs, and thus the validity of state transitions. This ensures that the data submitted to Ethereum matches signed L2 transactions, that these transactions resulted in the proposed state transition, and that the transition is valid. This verification is done by the operator calling the finalizeCompressedBlocksWithProof function which finalizes the state transition and stores the new state root.", "body": "The second responsibility of the LineaRollup contract is to query a PLONK verifier to verify proofs, and thus the validity of state transitions. This ensures that the data submitted to Ethereum matches signed L2 transactions, that these transactions resulted in the proposed state transition, and that the transition is valid. This verification is done by the operator calling the finalizeCompressedBlocksWithProof function which finalizes the state transition and stores the new state root.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-second-responsibility-of-the-linearollup-contract-is-to-query-a-plonk-verifier-to-verify-proofs,-and-thus-the-validity-of-state-transitions.-this-ensures-that-the-data-submitted-to-ethereum-matches-signed-l2-transactions,-that-these-transactions-resulted-in-the-proposed-state-transition,-and-that-the-transition-is-valid.-this-verification-is-done-by-the-operator-calling-the-finalizecompressedblockswithproof-function-which-finalizes-the-state-transition-and-stores-the-new-state-root.", "labels": ["OpenZeppelin"]}, {"title": "The third main responsibility of the contract is to send and receive cross-chain messages to and from L2. L1\u2192L2 messages are sent by the users calling the sendMessage function which emits a MessageSent event. This event is then detected by the coordinator and relayed to L2. Messages sent after the V2 migration will be added to a rolling hash that is reproduced on L2. These rolling hashes are verified to be consistent across the two layers during finalization. During finalization, L2\u2192L1 messages are anchored on L1 in the form of the root of a sparse Merkle tree. Users can then call claimMessageWithProof with a Merkle proof against this root to execute their transaction on L1.", "body": "The third main responsibility of the contract is to send and receive cross-chain messages to and from L2. L1\u2192L2 messages are sent by the users calling the sendMessage function which emits a MessageSent event. This event is then detected by the coordinator and relayed to L2. Messages sent after the V2 migration will be added to a rolling hash that is reproduced on L2. These rolling hashes are verified to be consistent across the two layers during finalization. During finalization, L2\u2192L1 messages are anchored on L1 in the form of the root of a sparse Merkle tree. Users can then call claimMessageWithProof with a Merkle proof against this root to execute their transaction on L1.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-third-main-responsibility-of-the-contract-is-to-send-and-receive-cross-chain-messages-to-and-from-l2.-l1\u2192l2-messages-are-sent-by-the-users-calling-the-sendmessage-function-which-emits-a-messagesent-event.-this-event-is-then-detected-by-the-coordinator-and-relayed-to-l2.-messages-sent-after-the-v2-migration-will-be-added-to-a-rolling-hash-that-is-reproduced-on-l2.-these-rolling-hashes-are-verified-to-be-consistent-across-the-two-layers-during-finalization.-during-finalization,-l2\u2192l1-messages-are-anchored-on-l1-in-the-form-of-the-root-of-a-sparse-merkle-tree.-users-can-then-call-claimmessagewithproof-with-a-merkle-proof-against-this-root-to-execute-their-transaction-on-l1.", "labels": ["OpenZeppelin"]}, {"title": "Layer 2", "body": "The L2MessageService contract will be deployed on L2, and is responsible for sending and receiving messages to and from L1. Similar to the contract on L1, users can call the sendMessage function on L2 to have the coordinator relay the cross-chain message and anchor it on L1. In addition, L1\u2192L2 messages are anchored on L2 by the coordinator calling the anchorL1L2MessageHashes function, making the message claimable by users and adding it to the L2 rolling hash.  Privileged Roles  There are multiple privileged roles in the system:  OPERATOR_ROLE: Operators can call submitData and finalizeCompressedBlocksWithProof on LineaRollup to submit data, as well as finalize a rollup state transition (and thus anchor L2\u2192L1 messages).  DEFAULT_ADMIN_ROLE: Addresses with this role can grant any other role to another address, as well as call finalizeCompressedBlocksWithoutProof to finalize a state transition without having to provide a valid proof. This function is only intended to be used in case of an emergency and during the V1 to V2 migration. This role has been granted to the Linea security council.  VERIFIER_SETTER_ROLE: This role can call setVerifierAddress to set a new address which can verify validity proofs. This role is part of the V2 changes and will be granted to the Timelock address as part of the migration.  RATE_LIMIT_SETTER_ROLE: The rate limit setter can call the resetRateLimitAmount and resetAmountUsedInPeriod functions on the two contracts to change the rate limit or reset the amount in the internal accounting.  PAUSE_MANAGER_ROLE: The pause manager can prevent different sets of functions from being called by pausing the contracts with four different pause types.  L1_L2_MESSAGE_SETTER_ROLE: This role is given to the coordinator who can call the addL1L2MessageHashes and anchorL1L2MessageHashes functions to anchor L1\u2192L2 messages for V1/V2 respectively.  MINIMUM_FEE_SETTER_ROLE: The fee setter can set the fee collected by the Linea node operator (block.coinbase) on L2\u2192L1 messages by calling setMinimumFee.  Security Model and Trust Assumptions  There are several trust assumptions for users of the audited codebase:  All of the addresses with the roles mentioned above can impact users in different ways, and if compromised, could freeze or steal users' funds depending on the roles granted to them.  As Linea is a ZK rollup without an open-source circuit, users trust that the circuit faithfully reproduces the EVM execution environment and is implemented in a way that does not allow a malicious prover to supply inputs that may prove an invalid state transition.  As underlined in one of the issues below, there is currently no software available to rebuild the L2 state from L1-posted data. Users thus trust the Linea operator to send them the data they need to build inclusion proofs or to resume the operation of the chain if the operator and L2 data become unavailable.  Similar to most rollups today, the sequencer can censor L2 transactions.  There is currently no way for users to force the inclusion of a cross-chain transaction in neither the L1\u2192L2 nor the L2\u2192L1 direction. This is because Linea's messaging system is purely ticket-based. While messages can be proven to be claimable when finalizing, the L2 sequencer can still censor claiming and L2\u2192L1 transactions.  As mentioned in one of the issues, the sequencer is assumed to filter uneconomical transactions due to the gas pricing model used by Linea. Users thus have to account for this when submitting, for example, calldata-heavy transactions.  The above assumptions are inherent to the current structure of the audited system. During our audit, we made the assumption that the L1 contracts would be compiled using Solidity 0.8.22, with the EVM version London. Similarly, the L2 contracts should be compiled using Solidity 0.8.19 on London. Following communication with the Linea team, it is also assumed in the following report that the migration to V2 will happen in four transactions executed in the following order:  An L1 transaction calling upgradeAndCall on the proxy, targeting the initializeSystemMigrationBlock function.  An L1 transaction granting the VERIFIER_SETTER_ROLE to the Timelock address.  An L2 transaction upgrading the proxy implementation.  Later, an L1 transaction from the security council calling finalizeCompressedBlocksWithoutProof to migrate the verification to V2 after reaching the target L1 migration block and after anchoring the first V2 message on L2.  Client-Reported Issues:  Some issues were reported to us by Linea as part of another audit. They have been included as-is at the end of this report under the Client-Reported section. As those issues are included as-is, they may include findings that overlap with some of our findings, are out of scope, or are not valid.  High Severity  Complex Design of Submission and Finalization Flows Causes Risks  The current design of the submission data and finalization data flows exhibits significant structural ", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#layer-2", "labels": ["OpenZeppelin"]}, {"title": "The L2MessageService contract will be deployed on L2, and is responsible for sending and receiving messages to and from L1. Similar to the contract on L1, users can call the sendMessage function on L2 to have the coordinator relay the cross-chain message and anchor it on L1. In addition, L1\u2192L2 messages are anchored on L2 by the coordinator calling the anchorL1L2MessageHashes function, making the message claimable by users and adding it to the L2 rolling hash.", "body": "The L2MessageService contract will be deployed on L2, and is responsible for sending and receiving messages to and from L1. Similar to the contract on L1, users can call the sendMessage function on L2 to have the coordinator relay the cross-chain message and anchor it on L1. In addition, L1\u2192L2 messages are anchored on L2 by the coordinator calling the anchorL1L2MessageHashes function, making the message claimable by users and adding it to the L2 rolling hash.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-l2messageservice-contract-will-be-deployed-on-l2,-and-is-responsible-for-sending-and-receiving-messages-to-and-from-l1.-similar-to-the-contract-on-l1,-users-can-call-the-sendmessage-function-on-l2-to-have-the-coordinator-relay-the-cross-chain-message-and-anchor-it-on-l1.-in-addition,-l1\u2192l2-messages-are-anchored-on-l2-by-the-coordinator-calling-the-anchorl1l2messagehashes-function,-making-the-message-claimable-by-users-and-adding-it-to-the-l2-rolling-hash.", "labels": ["OpenZeppelin"]}, {"title": "Privileged Roles", "body": "There are multiple privileged roles in the system:  OPERATOR_ROLE: Operators can call submitData and finalizeCompressedBlocksWithProof on LineaRollup to submit data, as well as finalize a rollup state transition (and thus anchor L2\u2192L1 messages).  DEFAULT_ADMIN_ROLE: Addresses with this role can grant any other role to another address, as well as call finalizeCompressedBlocksWithoutProof to finalize a state transition without having to provide a valid proof. This function is only intended to be used in case of an emergency and during the V1 to V2 migration. This role has been granted to the Linea security council.  VERIFIER_SETTER_ROLE: This role can call setVerifierAddress to set a new address which can verify validity proofs. This role is part of the V2 changes and will be granted to the Timelock address as part of the migration.  RATE_LIMIT_SETTER_ROLE: The rate limit setter can call the resetRateLimitAmount and resetAmountUsedInPeriod functions on the two contracts to change the rate limit or reset the amount in the internal accounting.  PAUSE_MANAGER_ROLE: The pause manager can prevent different sets of functions from being called by pausing the contracts with four different pause types.  L1_L2_MESSAGE_SETTER_ROLE: This role is given to the coordinator who can call the addL1L2MessageHashes and anchorL1L2MessageHashes functions to anchor L1\u2192L2 messages for V1/V2 respectively.  MINIMUM_FEE_SETTER_ROLE: The fee setter can set the fee collected by the Linea node operator (block.coinbase) on L2\u2192L1 messages by calling setMinimumFee.  Security Model and Trust Assumptions  There are several trust assumptions for users of the audited codebase:  All of the addresses with the roles mentioned above can impact users in different ways, and if compromised, could freeze or steal users' funds depending on the roles granted to them.  As Linea is a ZK rollup without an open-source circuit, users trust that the circuit faithfully reproduces the EVM execution environment and is implemented in a way that does not allow a malicious prover to supply inputs that may prove an invalid state transition.  As underlined in one of the issues below, there is currently no software available to rebuild the L2 state from L1-posted data. Users thus trust the Linea operator to send them the data they need to build inclusion proofs or to resume the operation of the chain if the operator and L2 data become unavailable.  Similar to most rollups today, the sequencer can censor L2 transactions.  There is currently no way for users to force the inclusion of a cross-chain transaction in neither the L1\u2192L2 nor the L2\u2192L1 direction. This is because Linea's messaging system is purely ticket-based. While messages can be proven to be claimable when finalizing, the L2 sequencer can still censor claiming and L2\u2192L1 transactions.  As mentioned in one of the issues, the sequencer is assumed to filter uneconomical transactions due to the gas pricing model used by Linea. Users thus have to account for this when submitting, for example, calldata-heavy transactions.  The above assumptions are inherent to the current structure of the audited system. During our audit, we made the assumption that the L1 contracts would be compiled using Solidity 0.8.22, with the EVM version London. Similarly, the L2 contracts should be compiled using Solidity 0.8.19 on London. Following communication with the Linea team, it is also assumed in the following report that the migration to V2 will happen in four transactions executed in the following order:  An L1 transaction calling upgradeAndCall on the proxy, targeting the initializeSystemMigrationBlock function.  An L1 transaction granting the VERIFIER_SETTER_ROLE to the Timelock address.  An L2 transaction upgrading the proxy implementation.  Later, an L1 transaction from the security council calling finalizeCompressedBlocksWithoutProof to migrate the verification to V2 after reaching the target L1 migration block and after anchoring the first V2 message on L2.  Client-Reported Issues:  Some issues were reported to us by Linea as part of another audit. They have been included as-is at the end of this report under the Client-Reported section. As those issues are included as-is, they may include findings that overlap with some of our findings, are out of scope, or are not valid.  High Severity  Complex Design of Submission and Finalization Flows Causes Risks  The current design of the submission data and finalization data flows exhibits significant structural and logical complexities.  Causes  The flow varies based on the combination and nature of the data submitted. For instance, whether submission data and finalization data are submitted separately or together, the finalization data dataHashes array length, and the submission compressedData length.  Data is duplicated between the submission data and the finalization data, resulting in the need for a lot of consistency checks.  Data hashes are used as cardinality. Utilizing data has", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#privileged-roles", "labels": ["OpenZeppelin"]}, {"title": "There are multiple privileged roles in the system:", "body": "There are multiple privileged roles in the system:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#there-are-multiple-privileged-roles-in-the-system:", "labels": ["OpenZeppelin"]}, {"title": "OPERATOR_ROLE: Operators can call submitData and finalizeCompressedBlocksWithProof on LineaRollup to submit data, as well as finalize a rollup state transition (and thus anchor L2\u2192L1 messages).", "body": "OPERATOR_ROLE: Operators can call submitData and finalizeCompressedBlocksWithProof on LineaRollup to submit data, as well as finalize a rollup state transition (and thus anchor L2\u2192L1 messages).", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#operator_role:-operators-can-call-submitdata-and-finalizecompressedblockswithproof-on-linearollup-to-submit-data,-as-well-as-finalize-a-rollup-state-transition-(and-thus-anchor-l2\u2192l1-messages).", "labels": ["OpenZeppelin"]}, {"title": "DEFAULT_ADMIN_ROLE: Addresses with this role can grant any other role to another address, as well as call finalizeCompressedBlocksWithoutProof to finalize a state transition without having to provide a valid proof. This function is only intended to be used in case of an emergency and during the V1 to V2 migration. This role has been granted to the Linea security council.", "body": "DEFAULT_ADMIN_ROLE: Addresses with this role can grant any other role to another address, as well as call finalizeCompressedBlocksWithoutProof to finalize a state transition without having to provide a valid proof. This function is only intended to be used in case of an emergency and during the V1 to V2 migration. This role has been granted to the Linea security council.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#default_admin_role:-addresses-with-this-role-can-grant-any-other-role-to-another-address,-as-well-as-call-finalizecompressedblockswithoutproof-to-finalize-a-state-transition-without-having-to-provide-a-valid-proof.-this-function-is-only-intended-to-be-used-in-case-of-an-emergency-and-during-the-v1-to-v2-migration.-this-role-has-been-granted-to-the-linea-security-council.", "labels": ["OpenZeppelin"]}, {"title": "VERIFIER_SETTER_ROLE: This role can call setVerifierAddress to set a new address which can verify validity proofs. This role is part of the V2 changes and will be granted to the Timelock address as part of the migration.", "body": "VERIFIER_SETTER_ROLE: This role can call setVerifierAddress to set a new address which can verify validity proofs. This role is part of the V2 changes and will be granted to the Timelock address as part of the migration.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#verifier_setter_role:-this-role-can-call-setverifieraddress-to-set-a-new-address-which-can-verify-validity-proofs.-this-role-is-part-of-the-v2-changes-and-will-be-granted-to-the-timelock-address-as-part-of-the-migration.", "labels": ["OpenZeppelin"]}, {"title": "RATE_LIMIT_SETTER_ROLE: The rate limit setter can call the resetRateLimitAmount and resetAmountUsedInPeriod functions on the two contracts to change the rate limit or reset the amount in the internal accounting.", "body": "RATE_LIMIT_SETTER_ROLE: The rate limit setter can call the resetRateLimitAmount and resetAmountUsedInPeriod functions on the two contracts to change the rate limit or reset the amount in the internal accounting.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#rate_limit_setter_role:-the-rate-limit-setter-can-call-the-resetratelimitamount-and-resetamountusedinperiod-functions-on-the-two-contracts-to-change-the-rate-limit-or-reset-the-amount-in-the-internal-accounting.", "labels": ["OpenZeppelin"]}, {"title": "PAUSE_MANAGER_ROLE: The pause manager can prevent different sets of functions from being called by pausing the contracts with four different pause types.", "body": "PAUSE_MANAGER_ROLE: The pause manager can prevent different sets of functions from being called by pausing the contracts with four different pause types.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#pause_manager_role:-the-pause-manager-can-prevent-different-sets-of-functions-from-being-called-by-pausing-the-contracts-with-four-different-pause-types.", "labels": ["OpenZeppelin"]}, {"title": "L1_L2_MESSAGE_SETTER_ROLE: This role is given to the coordinator who can call the addL1L2MessageHashes and anchorL1L2MessageHashes functions to anchor L1\u2192L2 messages for V1/V2 respectively.", "body": "L1_L2_MESSAGE_SETTER_ROLE: This role is given to the coordinator who can call the addL1L2MessageHashes and anchorL1L2MessageHashes functions to anchor L1\u2192L2 messages for V1/V2 respectively.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#l1_l2_message_setter_role:-this-role-is-given-to-the-coordinator-who-can-call-the-addl1l2messagehashes-and-anchorl1l2messagehashes-functions-to-anchor-l1\u2192l2-messages-for-v1/v2-respectively.", "labels": ["OpenZeppelin"]}, {"title": "MINIMUM_FEE_SETTER_ROLE: The fee setter can set the fee collected by the Linea node operator (block.coinbase) on L2\u2192L1 messages by calling setMinimumFee.", "body": "MINIMUM_FEE_SETTER_ROLE: The fee setter can set the fee collected by the Linea node operator (block.coinbase) on L2\u2192L1 messages by calling setMinimumFee.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#minimum_fee_setter_role:-the-fee-setter-can-set-the-fee-collected-by-the-linea-node-operator-(block.coinbase)-on-l2\u2192l1-messages-by-calling-setminimumfee.", "labels": ["OpenZeppelin"]}, {"title": "Security Model and Trust Assumptions", "body": "There are several trust assumptions for users of the audited codebase:  All of the addresses with the roles mentioned above can impact users in different ways, and if compromised, could freeze or steal users' funds depending on the roles granted to them.  As Linea is a ZK rollup without an open-source circuit, users trust that the circuit faithfully reproduces the EVM execution environment and is implemented in a way that does not allow a malicious prover to supply inputs that may prove an invalid state transition.  As underlined in one of the issues below, there is currently no software available to rebuild the L2 state from L1-posted data. Users thus trust the Linea operator to send them the data they need to build inclusion proofs or to resume the operation of the chain if the operator and L2 data become unavailable.  Similar to most rollups today, the sequencer can censor L2 transactions.  There is currently no way for users to force the inclusion of a cross-chain transaction in neither the L1\u2192L2 nor the L2\u2192L1 direction. This is because Linea's messaging system is purely ticket-based. While messages can be proven to be claimable when finalizing, the L2 sequencer can still censor claiming and L2\u2192L1 transactions.  As mentioned in one of the issues, the sequencer is assumed to filter uneconomical transactions due to the gas pricing model used by Linea. Users thus have to account for this when submitting, for example, calldata-heavy transactions.  The above assumptions are inherent to the current structure of the audited system. During our audit, we made the assumption that the L1 contracts would be compiled using Solidity 0.8.22, with the EVM version London. Similarly, the L2 contracts should be compiled using Solidity 0.8.19 on London. Following communication with the Linea team, it is also assumed in the following report that the migration to V2 will happen in four transactions executed in the following order:  An L1 transaction calling upgradeAndCall on the proxy, targeting the initializeSystemMigrationBlock function.  An L1 transaction granting the VERIFIER_SETTER_ROLE to the Timelock address.  An L2 transaction upgrading the proxy implementation.  Later, an L1 transaction from the security council calling finalizeCompressedBlocksWithoutProof to migrate the verification to V2 after reaching the target L1 migration block and after anchoring the first V2 message on L2.  Client-Reported Issues:  Some issues were reported to us by Linea as part of another audit. They have been included as-is at the end of this report under the Client-Reported section. As those issues are included as-is, they may include findings that overlap with some of our findings, are out of scope, or are not valid.  High Severity  Complex Design of Submission and Finalization Flows Causes Risks  The current design of the submission data and finalization data flows exhibits significant structural and logical complexities.  Causes  The flow varies based on the combination and nature of the data submitted. For instance, whether submission data and finalization data are submitted separately or together, the finalization data dataHashes array length, and the submission compressedData length.  Data is duplicated between the submission data and the finalization data, resulting in the need for a lot of consistency checks.  Data hashes are used as cardinality. Utilizing data hashes as the main key for various data structures poses several challenges:  Complex validation and difficulty in tracking parent/child relationships. Unconventional and error-prone approach. Ambiguity about the order and nature of the data which, for example, results in the absence of support for resubmission. Potential for non-uniqueness. Difficulty in reviewing.  Impact  The combination of these causes results in a complex and brittle system. Even with thorough reviews and bug fixes, this increases the chances of new bugs being introduced in future code changes.  In the current report, a high number of issues has the above design choices either as a direct cause, or as a significant contributing factor:  M-01: Insufficient Validation of Loaded Data Allows Out-of-Order Submission, Preventing Finalization  M-06: Incorrectly Submitted Data Prevents Finalization  M-07: Non-Unique compressedData Can Prevent Submission  M-08: Insufficient Validation of Block Numbers During Submission and Finalization  L-01: Loaded Shnarf Is Not Checked to Be Non-Empty  L-02: Submission Data Can Be Overwritten in Certain Circumstances  L-10: False Sense of Security Due to Validation of Unused Data Fields  L-12: Data Chain Integrity Can Be Broken  L-13: Intermediary Blocks Are Not Validated  Due to the high number of complex and severe issues found, the current design can result in two kinds of high severity scenarios:  High likelihood of a future medium impact issue.  Medium likelihood of a future high impact issue. This possibility is further exacerbated by the eventual gradual removal of th", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#security-model-and-trust-assumptions", "labels": ["OpenZeppelin"]}, {"title": "There are several trust assumptions for users of the audited codebase:", "body": "There are several trust assumptions for users of the audited codebase:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#there-are-several-trust-assumptions-for-users-of-the-audited-codebase:", "labels": ["OpenZeppelin"]}, {"title": "All of the addresses with the roles mentioned above can impact users in different ways, and if compromised, could freeze or steal users' funds depending on the roles granted to them.", "body": "All of the addresses with the roles mentioned above can impact users in different ways, and if compromised, could freeze or steal users' funds depending on the roles granted to them.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#all-of-the-addresses-with-the-roles-mentioned-above-can-impact-users-in-different-ways,-and-if-compromised,-could-freeze-or-steal-users'-funds-depending-on-the-roles-granted-to-them.", "labels": ["OpenZeppelin"]}, {"title": "As Linea is a ZK rollup without an open-source circuit, users trust that the circuit faithfully reproduces the EVM execution environment and is implemented in a way that does not allow a malicious prover to supply inputs that may prove an invalid state transition.", "body": "As Linea is a ZK rollup without an open-source circuit, users trust that the circuit faithfully reproduces the EVM execution environment and is implemented in a way that does not allow a malicious prover to supply inputs that may prove an invalid state transition.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#as-linea-is-a-zk-rollup-without-an-open-source-circuit,-users-trust-that-the-circuit-faithfully-reproduces-the-evm-execution-environment-and-is-implemented-in-a-way-that-does-not-allow-a-malicious-prover-to-supply-inputs-that-may-prove-an-invalid-state-transition.", "labels": ["OpenZeppelin"]}, {"title": "As underlined in one of the issues below, there is currently no software available to rebuild the L2 state from L1-posted data. Users thus trust the Linea operator to send them the data they need to build inclusion proofs or to resume the operation of the chain if the operator and L2 data become unavailable.", "body": "As underlined in one of the issues below, there is currently no software available to rebuild the L2 state from L1-posted data. Users thus trust the Linea operator to send them the data they need to build inclusion proofs or to resume the operation of the chain if the operator and L2 data become unavailable.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#as-underlined-in-one-of-the-issues-below,-there-is-currently-no-software-available-to-rebuild-the-l2-state-from-l1-posted-data.-users-thus-trust-the-linea-operator-to-send-them-the-data-they-need-to-build-inclusion-proofs-or-to-resume-the-operation-of-the-chain-if-the-operator-and-l2-data-become-unavailable.", "labels": ["OpenZeppelin"]}, {"title": "Similar to most rollups today, the sequencer can censor L2 transactions.", "body": "Similar to most rollups today, the sequencer can censor L2 transactions.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#similar-to-most-rollups-today,-the-sequencer-can-censor-l2-transactions.", "labels": ["OpenZeppelin"]}, {"title": "There is currently no way for users to force the inclusion of a cross-chain transaction in neither the L1\u2192L2 nor the L2\u2192L1 direction. This is because Linea's messaging system is purely ticket-based. While messages can be proven to be claimable when finalizing, the L2 sequencer can still censor claiming and L2\u2192L1 transactions.", "body": "There is currently no way for users to force the inclusion of a cross-chain transaction in neither the L1\u2192L2 nor the L2\u2192L1 direction. This is because Linea's messaging system is purely ticket-based. While messages can be proven to be claimable when finalizing, the L2 sequencer can still censor claiming and L2\u2192L1 transactions.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#there-is-currently-no-way-for-users-to-force-the-inclusion-of-a-cross-chain-transaction-in-neither-the-l1\u2192l2-nor-the-l2\u2192l1-direction.-this-is-because-linea's-messaging-system-is-purely-ticket-based.-while-messages-can-be-proven-to-be-claimable-when-finalizing,-the-l2-sequencer-can-still-censor-claiming-and-l2\u2192l1-transactions.", "labels": ["OpenZeppelin"]}, {"title": "As mentioned in one of the issues, the sequencer is assumed to filter uneconomical transactions due to the gas pricing model used by Linea. Users thus have to account for this when submitting, for example, calldata-heavy transactions.", "body": "As mentioned in one of the issues, the sequencer is assumed to filter uneconomical transactions due to the gas pricing model used by Linea. Users thus have to account for this when submitting, for example, calldata-heavy transactions.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#as-mentioned-in-one-of-the-issues,-the-sequencer-is-assumed-to-filter-uneconomical-transactions-due-to-the-gas-pricing-model-used-by-linea.-users-thus-have-to-account-for-this-when-submitting,-for-example,-calldata-heavy-transactions.", "labels": ["OpenZeppelin"]}, {"title": "The above assumptions are inherent to the current structure of the audited system. During our audit, we made the assumption that the L1 contracts would be compiled using Solidity 0.8.22, with the EVM version London. Similarly, the L2 contracts should be compiled using Solidity 0.8.19 on London. Following communication with the Linea team, it is also assumed in the following report that the migration to V2 will happen in four transactions executed in the following order:", "body": "The above assumptions are inherent to the current structure of the audited system. During our audit, we made the assumption that the L1 contracts would be compiled using Solidity 0.8.22, with the EVM version London. Similarly, the L2 contracts should be compiled using Solidity 0.8.19 on London. Following communication with the Linea team, it is also assumed in the following report that the migration to V2 will happen in four transactions executed in the following order:", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#the-above-assumptions-are-inherent-to-the-current-structure-of-the-audited-system.-during-our-audit,-we-made-the-assumption-that-the-l1-contracts-would-be-compiled-using-solidity-0.8.22,-with-the-evm-version-london.-similarly,-the-l2-contracts-should-be-compiled-using-solidity-0.8.19-on-london.-following-communication-with-the-linea-team,-it-is-also-assumed-in-the-following-report-that-the-migration-to-v2-will-happen-in-four-transactions-executed-in-the-following-order:", "labels": ["OpenZeppelin"]}, {"title": "An L1 transaction calling upgradeAndCall on the proxy, targeting the initializeSystemMigrationBlock function.", "body": "An L1 transaction calling upgradeAndCall on the proxy, targeting the initializeSystemMigrationBlock function.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#an-l1-transaction-calling-upgradeandcall-on-the-proxy,-targeting-the-initializesystemmigrationblock-function.", "labels": ["OpenZeppelin"]}, {"title": "An L1 transaction granting the VERIFIER_SETTER_ROLE to the Timelock address.", "body": "An L1 transaction granting the VERIFIER_SETTER_ROLE to the Timelock address.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#an-l1-transaction-granting-the-verifier_setter_role-to-the-timelock-address.", "labels": ["OpenZeppelin"]}, {"title": "An L2 transaction upgrading the proxy implementation.", "body": "An L2 transaction upgrading the proxy implementation.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#an-l2-transaction-upgrading-the-proxy-implementation.", "labels": ["OpenZeppelin"]}, {"title": "Later, an L1 transaction from the security council calling finalizeCompressedBlocksWithoutProof to migrate the verification to V2 after reaching the target L1 migration block and after anchoring the first V2 message on L2.", "body": "Later, an L1 transaction from the security council calling finalizeCompressedBlocksWithoutProof to migrate the verification to V2 after reaching the target L1 migration block and after anchoring the first V2 message on L2.", "html_url": "https://blog.openzeppelin.com/linea-v2-audit#later,-an-l1-transaction-from-the-security-council-calling-finalizecompressedblockswithoutproof-to-migrate-the-verification-to-v2-after-reaching-the-target-l1-migration-block-and-after-anchoring-the-first-v2-message-on-l2.", "labels": ["OpenZeppelin"]}, {"title": "Sudden Price Change Can Enable MEV Exploit", "body": "Oval contract, if the  unlockLatestValue function has been called  within the lockWindow, the  internalLatestData function will return the most recent price from the  BaseController contract, the  setLockWindow function is used to change the value returned from  lockWindow. Suppose the  Both cases can create an opportunity for users aiming to exploit MEV to sandwich the setLockWindow calls, taking advantage of sudden price changes.  Consider restricting the change in the setLockWindow function so that the return value from the internalLatestData function remains the same after setting the new value of the lock-window.  Update: Partially resolved in pull request #63 at commit a90bef5. The Risk Labs team stated:  Implemented the recommended fix in restricting the setLockWindow function so that the return value from the internalLatestData function remains the same after setting the new value of the lock-window.  When changing the value of lockWindow_, after unlocking the latest value, if setLockWindow is called during the current lockWindow_ but is called outside the newLockWindow period, the second call to internalLatestData might return the most recent value that is at least lockWindow_ old, which could be different than the first call to internalLatestData causing the transaction to fail. The same issue is true if setLockWindow is called outside the current lockWindow_ period but is called during the newLockWindow period.  However, suppose on the Ethereum mainnet, if the lockWindow_ is being reduced from 60 seconds to a value ranging from 0 to 11 seconds, which is less than the 12 seconds block time (ATTOW), a malicious user might prevent the setLockWindow call from being included in the same block as the unlockLatestValue. If the setLockWindow transaction is added to a following block but called within 60 seconds of the unlockLatestValue call, the transaction might fail from being executed if the underlying source oracle is updated.  Although the proposed fix restricts from setting a newLockWindow if a change in the internalLatestData occurs, consider always ensuring that setLockWindow will be called during a valid period after unlocking the latest value.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#sudden-price-change-can-enable-mev-exploit", "labels": ["OpenZeppelin"]}, {"title": "Use of Deprecated Function From Chainlink API", "body": "IAggregatorV3Source interface inherits from the  IAggregatorV3 interface which implements Chainlink's deprecated functions  latestAnswer and  latestTimestamp. Moreover, the  latestRound function.  Additionally, the UniswapAnchoredViewSourceAdapter contract in getLatestSourceData is using Chainlink's deprecated latestTimestamp function.  The usage of Chainlink's deprecated functions in ChainlinkDestinationAdapter contracts is justified to respect the interface of the protocols that already implement the deprecated Chainlink interface and to ease the switch to the newly developed Oval-based contract without introducing breaking changes to the destination protocol. However, the ChainlinkSourceAdapter contracts should follow the up-to-date interface from the Chainlink docs.  Consider replacing Chainlink's deprecated functions with the appropriate up-to-date counterparts. Moreover, consider not importing the IAggregatorV3 interface into the IAggregatorV3Source interface to avoid future mistakes and separate both codebases for source and destination adapters.  Update: Resolved in pull request #93 at commit 35d5f7c.  Low Severity", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#use-of-deprecated-function-from-chainlink-api", "labels": ["OpenZeppelin"]}, {"title": "Misleading Comments", "body": "Throughout the codebase the following instances of incorrect documentation have been identified:  The comment on lines 35 and 36 in DecimalLib contains the following errors:  The maximum value of uint256 is 2^256 - 1 not 2^265. 2^256 is approximately equal to 1.2e77, but not equal.  The _tryLatestRoundDataAt function comment suggests that the function is trying to get the latest data as of the requested timestamp. If it is not available, the function will return the earliest data. However, the _searchRoundDataAt function comment states that the function might return newer data than the requested timestamp. Both aforementioned comments appear to contradict each other.  Consider resolving these instances of incorrect documentation to improve the clarity and readability of the codebase.  Update: Resolved in pull request #66 at commit 623ca26, and in pull request #89 at commit 17ffd3b.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#misleading-comments", "labels": ["OpenZeppelin"]}, {"title": "Possible Revert While Converting", "body": "DecimalLib library, both  1 and  2 take an input number  If iDecimals < oDecimals and answer * 10^(oDecimals - iDecimals) > type(uint256).max, the convertingDecimals functions will revert.  Despite the low likelihood of this occurrence, consider including a code comment explaining this case as a precautionary measure.  Update: Resolved in pull request #64 at commit ecbdcd0.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#possible-revert-while-converting", "labels": ["OpenZeppelin"]}, {"title": "Conversion Can Lead to Loss of Precision", "body": "DecimalLib library, both  1 and  2 take an input number  Suppose a protocol allows users to buy a token for a certain price which is returned by the oracle. Suppose that this protocol expects an output decimals number smaller than the input decimals. When downscaling the answer (i.e., when iDecimals > oDecimals), the conversion can lead to a loss of precision. In the worst case, if the answer is small enough, the conversion can return zero, allowing users to buy the token for a value of zero.  Consider adding a warning comment to highlight this issue for clients integrating this oracle.  Update: Resolved in pull request #61 at commit 9670e08.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#conversion-can-lead-to-loss-of-precision", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Double Conversion", "body": "The source adapter contracts interact with the incoming oracle interface that is ingested by the Oval system. The destination adapter contracts represent the standardized output interface that the Oval system exposes. In other words, the ChainlinkSourceAdapter is responsible for fetching the data from Chainlink, and the ChainlinkDestinationAdapter will return this data to the protocols implementing the Oval system. The data returned by ChainlinkDestinationAdapter should return the output decimals to match the decimals expected by the protocol. Optionally, if the source oracle's answer is based on a different decimals number than expected, the answer is converted using the DecimalLib library.  However, within the source and destination contracts of Chainlink, the data is converted twice. Once when fetched by the source adapter and another time when returned by the destination adapter.  tryLatestDataAt in the  ChainlinkSourceAdapter, the  answer returned is converted from the  ChainlinkDestinationAdapter contract, when calling either  latestAnswer,  latestTimestamp, or  latestRoundData, the answer returned from the  Moreover, when converting from a higher to lower decimal output and then from lower to higher again, the data returned will be altered and will not match the original answer.  Consider handling the conversion in a single contract to avoid conversion duplication and data loss.  Update: Acknowledged, not resolved. The Risk Labs team stated:  We decided to not do anything in response to this issue. Specifically, we want all internal units within the OEVShare contracts to operate at 18 decimals to keep logic consistent and decimal independent within the OEVShare contracts. It also enables us to have different input and output decimals, by mixing and matching sources and destination adapters. Regarding loss of precision and the risk therein: this would only be the case if the input decimals are greater than 18 decimals. None of the feeds we want to use OEVshare on are more than 18 so there is no risk in this regard.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#unnecessary-double-conversion", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are several parts that do not have docstrings:  Line 21 in UniswapAnchoredViewDestinationAdapter.sol  Line 12 in BaseDestinationAdapter.sol  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Acknowledged, not resolved. The Risk Labs team stated:  No changes were made on this as these are public state variables. We historically do not document them with NatSpec.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Missing Error Message in revert Statement", "body": "Within the getTokenConfigByCToken function of UniswapAnchoredViewDestinationAdapter.sol, there is a revert statement on line 55 that lacks an error message.  Consider including specific, informative error messages in revert statements to improve the overall clarity of the codebase and avoid potential confusion when the contract reverts.  Update: Resolved in pull request #67 at commit 2628f26.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#missing-error-message-in-revert-statement", "labels": ["OpenZeppelin"]}, {"title": "Functions Are Updating the State Without Event Emissions", "body": "Throughout the codebase, instances of functions that are updating the state without an event emission were found. The contracts which could benefit from the addition of event emissions include:  The constructor function in ChainlinkDestinationAdapter.sol.  The constructor function in ImmutableController.sol.  The constructor function in ImmutableController.sol.  The constructor function in ImmutableController.sol.  The constructor function in ChainlinkSourceAdapter.sol.  The constructor function in ChainlinkSourceAdapter.sol.  The snapshotData function in SnapshotSource.sol.  The constructor function in UniswapAnchoredViewSourceAdapter.sol.  The constructor function in UniswapAnchoredViewSourceAdapter.sol.  The constructor function in UniswapAnchoredViewSourceAdapter.sol.  The syncAggregatorSource function in UniswapAnchoredViewSourceAdapter.sol.  The unlockLatestValue function in OevShare.sol.  The setOevOracle function in UniswapAnchoredViewDestinationAdapter.sol.  The setOevOracle function in UniswapAnchoredViewDestinationAdapter.sol.  The constructor function in UniswapAnchoredViewDestinationAdapter.sol.  The setLockWindow function in BaseController.sol.  The setMaxTraversal function in BaseController.sol.  The setUpdater function in BaseController.sol.  Consider emitting events whenever there are state changes to make the platform more verbose and improve its on-chain readability.  Update: Resolved in pull request #77 at commit b199370. The Risk Labs team stated:  Implemented the recommended fix in emitting events whenever there are state changes.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#functions-are-updating-the-state-without-event-emissions", "labels": ["OpenZeppelin"]}, {"title": "Variable Cast Is Unnecessary", "body": "Throughout the codebase there are multiple functions that have variables that were unnecessary cast. For instance:  The cToken variable in the syncAggregatorSource function in the UniswapAnchoredViewSourceAdapter contract.  The cToken variable in the getLatestSourceData function in the UniswapAnchoredViewSourceAdapter contract.  To avoid clarify the intent and improve the readability of the codebase, consider removing these unnecessary casts.  Update: Resolved in pull request #69 at commit 7beb464.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#variable-cast-is-unnecessary", "labels": ["OpenZeppelin"]}, {"title": "State Variables Have Been Shadowed", "body": "Throughout the codebase, there are multiple state variables that have been shadowed. For instance:  The lastUnlockTime state variable in the Oval contract is shadowed on line 36 in BaseController and line 35 in ImmutableController.  To improve the overall clarity, intent, and readability of the codebase, consider renaming variables that shadow any state variables.  Update: Resolved in pull request #70 at commit f43507b.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#state-variables-have-been-shadowed", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease the clarity of the code, and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity files or when inheritance chains are long.  Throughout the codebase, global imports are being used:  DiamondRootOval.sol  Oval.sol  BaseDestinationAdapter.sol  DecimalLib.sol  SnapshotSource.sol  ChainlinkDestinationAdapter.sol  ChainlinkSourceAdapter.sol  UniswapAnchoredViewDestinationAdapter.sol  UniswapAnchoredViewSourceAdapter.sol  BaseController.sol  ImmutableController.sol  Following the principle that clearer code is better code, consider using named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #78 at commit 3b9c6d9.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact, such as an email or ENS, within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the creators of those libraries to make contact, inform the code owners about the problem, and provide mitigation instructions.  Every contract in the codebase omits the security-contract tag.  Consider adding a NatSpec comment on top of the contract definition with a security contact. Using the @custom:security-contact convention is recommended as it has been adopted by the Openzeppelin Wizard and the ethereum-lists.  Update: Partially resolved in pull request #81 at commit 96db8e3. The Risk Labs team only added the security tag to the OevShare contract.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Unused Named Return Variables", "body": "Named return variables are a way to declare variables that are meant to be used within a function's body for the purpose of being returned as the function's output. They are an alternative to explicit in-line return statements.  Throughout the codebase, there are multiple instances of unused named return variables. For instance:  The roundId return variable in the latestRoundData function in ChainlinkDestinationAdapter.sol.  The answer return variable in the latestRoundData function in ChainlinkDestinationAdapter.sol.  The startedAt return variable in the latestRoundData function in ChainlinkDestinationAdapter.sol.  The answeredInRound return variable in the latestRoundData function in ChainlinkDestinationAdapter.sol.  The answer return variable in the internalLatestData function in Oval.sol.  The timestamp return variable in the internalLatestData function in Oval.sol.  Consider either using or removing any unused named return variables.  Update: Resolved in pull request #73 at commit 2063f8e.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#unused-named-return-variables", "labels": ["OpenZeppelin"]}, {"title": "Lack of SPDX License Identifiers", "body": "Throughout the codebase, there are files that lack SPDX license identifiers. For instance:  DiamondRootOval.sol  BaseDestinationAdapter.sol  DecimalLib.sol  SnapshotSource.sol  UniswapAnchoredViewDestinationAdapter.sol  To avoid legal issues regarding copyright and follow best practices, consider adding SPDX license identifiers to files as suggested by the Solidity documentation.  Update: Resolved in pull request #74 at commit b5f63e6.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#lack-of-spdx-license-identifiers", "labels": ["OpenZeppelin"]}, {"title": "State Variable Visibility Not Explicitly Declared", "body": "Within ChainlinkSourceAdapter.sol, the state variable PHASE_MASK lacks an explicitly declared visibility.  For clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #79 at commit 3a1141b.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "Throughout the codebase there are multiple instances of typographical errors:  \"dont\" should be \"don't\".  \"is this is\" should be \"is\".  Please note that this list is not an exhaustive list and more cases may be found. Consider fixing these and any other typographical errirs to improve the readability of the documentation.  Update: Resolved in pull request #75 at commit 1efe162.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Unused State Variable", "body": "Throughout the codebase, there are multiple unused state variables. For instance:  The decimals state variable in the BaseDestinationAdapter contract  While these are all abstract contracts, it may be best to define the decimals variables in the actual implementation.  To improve the overall clarity, intentionality, and readability of the codebase, consider standardizing and moving the decimals definitions to their respective implementation contracts.  Update: Resolved in pull request #80 at commit 950e0c0.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#unused-state-variable", "labels": ["OpenZeppelin"]}, {"title": "Constants Not Using UPPER_CASE Format", "body": "Throughout the codebase, there are constants not using UPPER_CASE format. For instance:  The lockWindow_ constant declared on line 15 in ImmutableController.sol  The maxTraversal_ constant declared on line 16 in ImmutableController.sol  The chainlinkSource constant declared on line 14 in ChainlinkSourceAdapter.sol  The sourceDecimals constant declared on line 15 in ChainlinkSourceAdapter.sol  The uniswapAnchoredViewSource constant declared on line 16 in UniswapAnchoredViewSourceAdapter.sol  The cToken constant declared on line 17 in UniswapAnchoredViewSourceAdapter.sol  The sourceDecimals constant declared on line 18 in UniswapAnchoredViewSourceAdapter.sol  The decimals constant declared on line 12 in BaseDestinationAdapter.sol  According to the Solidity Style Guide, constants should be named with all capital letters with underscores separating words. For better readability, consider following this convention.  Update: Resolved in pull request #76 at 7a9b631.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#constants-not-using-upper_case-format", "labels": ["OpenZeppelin"]}, {"title": "Client-Reported", "body": "Client-Reported", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Medium: ChainlinkSourceAdapter Does Not Correctly Validate Historical Data in _tryLatestRoundDataAt", "body": "When validating the data returned from _searchRoundDataAt in the ChainlinkSourceAdapter._tryLatestRoundDataAt function, the implementation checks updatedAt for uninitialized historical data.  Update: Resolved in pull request #54 at commit b2807eb.", "html_url": "https://blog.openzeppelin.com/uma-oval-audit#medium:-chainlinksourceadapter-does-not-correctly-validate-historical-data-in-_trylatestrounddataat", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Testing", "body": "The codebase has several potential gaps in testing which may pose a risk to the robustness and security of the system. The following list is a collection of identified issues and proposed recommendations aimed at improving the overall quality of the testing suite:  Overall, the testing coverage of the code under review is notably low. This can lead to various consequences such as maintainability problems, functionality issues, and security concerns. Consider thoroughly testing the codebase to enhance system maintainability and fortify security measures.  Consider adding more tests to ensure a complete coverage of all possible branches. For example, renderFieldLayout.ts is one of the few audited files with corresponding tests. However, the conditions on lines 17, 18, and 22 are not covered by the test suite.  Consider adding tests to check if the values in constants.ts are equivalent to the values in constants.sol, similar to the test in storeEvents.test.ts and storeEventsAbi.test.ts.  In both storeEvents.test.ts and storeEventsAbi.test.ts, only the helloStoreEvent event is being tested. Consider adding more tests to cover all the existing events.  The tests in storeEvents.test.ts and storeEventsAbi.test.ts are functionally equivalent but have been implemented with slight code variations. Consider merging logically identical tests into a single test in order to increase the maintainability of the test suite.  Update: Partially resolved in pull request #2176. The Lattice Labs team stated:  We have addressed the specific examples listed above and added some tests for various low-level helpers. For the higher-level stuff (rendering functions, etc.), we rely on the codegen output generated throughout the codebase (packages, examples, templates, etc.) and check into git to test/review the output we expect.  We will plan to expand test coverage for specific edge cases as we find things that break or do not output what we expect. We are also planning a much deeper refactor of codegen. Before this, we may add a test suite that generates tables, etc. for a specific set of MUD config, and then use that to compare the refactor output to keep things compatible.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#insufficient-testing", "labels": ["OpenZeppelin"]}, {"title": "Static Arrays Are Extendable", "body": "treated as dynamic for storage purposes and  are cast to and from dynamic arrays as required. However, this means the corresponding dynamic field methods (  are rendered. Since  empty array is returned (and the remaining values are ignored). On the other hand, if the array is too long, it  is truncated to the expected size.  Consider skipping the push and pop functions for static arrays. In addition, consider implementing a simpler length function that directly returns the known length. Lastly, in the interests of predictability, when converting dynamic arrays to static ones, consider reverting whenever the lengths are inconsistent.  Update: Resolved in pull request #2175.  Low Severity", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#static-arrays-are-extendable", "labels": ["OpenZeppelin"]}, {"title": "Encapsulation Recommendation", "body": "There are several examples throughout the codebase where rendering functions make strong assumptions about how and when they are called. For example, the renderDecodeDynamicFieldPartial function assumes that the _blob, _start and _end variables exist, and that SliceLib will be available. While the example is intended to illustrate the claim, this pattern is a broad feature of the entire codebase, which is error-prone and makes local reasoning difficult.  The rest of this report includes suggestions for specific trivial simplifications, but we also believe that the codebase could benefit from a more structured approach. Our core recommendation is to make extensive use of TypeScript objects instead of strings to accumulate and synthesize business logic. The final rendering should focus entirely on describing the object in Solidity syntax.  For example, there could be a SolidityFunction object that individually tracks comments, input arguments, return values, local variables, visibility, etc. The arguments would also be objects that track type, location and name. Possible advantages include:  The body of the function could reference specific named parameters or local variables. If the variable did not exist, it would raise an error.  Functions could only invoke other functions if they exist in the higher SolidityContract object.  Instead of using configurable callbacks to create similar functions, the object could simply be copied and modified to add new parameters or return values.  The objects could use partial (or Pick) types to clearly indicate partially complete structures.  Consider restructuring the rendering code to focus on manipulating TypeScript objects instead of strings.  Update: Acknowledged, not resolved. The Lattice Labs team stated:  We are going to punt on this because we believe that an object-oriented approach may be meaningful for a standalone library designed for generating arbitrary solidity code. On the other hand, MUD codegen has a very narrow purpose and most of its functions are not meant for external use. Overly generalising it will complicate its development and maintenance with little benefit to the MUD codebase.  A SolidityFunction object could be a full AST which requires unparsing it (using slang, which is in alpha, or writing our own unparser). This removes any context assumptions but adds a lot of code. This also does not create typescript compile-time typechecks. An object with some structured properties (like arguments, name, comment, etc.) and an unstructured body. The body has to allow many possible operations besides assignment.  This slightly isolates context assumptions, but at the cost of replacing simple strings with complicated objects, and additional helpers that work on said objects. A SolidityContract object would only be meaningful for renderTable, which is redundant - it would verify imports and variables which are mostly static and verified by the Solidity compiler.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#encapsulation-recommendation", "labels": ["OpenZeppelin"]}, {"title": "Missing Function Comments", "body": "Most of the functions in the codebase do not have explanatory comments. Also, note that the extractUserTypes function is missing a @param statement for the fromPath parameter.  To improve the readability of the codebase, consider documenting all functions and their parameters.  Update: Resolved in pull request #2185. The Lattice Labs team stated:  We pulled out some return values into TS interfaces to make it easier to document params and added comment headers to the rest of the functions.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#missing-function-comments", "labels": ["OpenZeppelin"]}, {"title": "Missing Import of Events, Structs, and Enums from Contract to ABI", "body": "The renderSystemInterface function automatically generates an interface from the corresponding contract. The function takes the imports, the contract name, functions, function prefix, and errors into account. However, it does not include events, structs, and enums. It is worth noting that since the interface is generated from the System file, the System cannot inherit its own interface. Thus, the duplicate definition does not lead to a conflict. One advantage of generating all the interfaces is that the IWorld interface will fail to compile if there are conflicting function signatures or errors across the different systems. This feature can be extended to the other structures as well.  Consider also including the events, structs, and enums to ensure the generation of a complete interface.  Update: Partially resolved in pull request #2194. The Lattice Labs team stated:  We played around with this but decided against these changes:  It does not make sense for us to copy over structs/enums into system interfaces because they end up being treated as different types in Solidity. It's best to define+import them from a common place outside of systems.  We do not want to encourage defining events in systems because they create side effects with potentially unexpected results depending on the context in which the system was called (call vs delegatecall). We did make a small adjustment to only include errors in interfaces when they are actually used (rather than including them if they are found in the file).", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#missing-import-of-events,-structs,-and-enums-from-contract-to-abi", "labels": ["OpenZeppelin"]}, {"title": "Restricting Solidity Version", "body": "In renderedSolidityHeader, the Solidity version has been hardcoded to >= 0.8.21. This was chosen to match the manually created part of the codebase. However, this can cause restrictions when developing contracts on other EVM-compatible chains that often do not support certain opcodes (e.g., the PUSH0 opcode that was introduced in Solidity version 0.8.20).  Consider making the Solidity version a configurable parameter to increase the possible applicability of the codebase.  Update: Acknowledged, not resolved. The Lattice Labs team stated:  We are going to punt on this because we want to make use of some recent Solidity features and many of our contracts, libraries, etc. are meant to be used together as a whole (i.e., a framework) rather than in isolation.  While it might be better to set each Solidity file to its minimum viable Solidity version, this is not something we have seen users ask for and probably does not make sense for us to maintain.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#restricting-solidity-version", "labels": ["OpenZeppelin"]}, {"title": "TypeScript Inconsistency", "body": "The codebase makes extensive use of TypeScript types to validate consistency and improve code clarity. Here are some instances that could benefit from more consistent types:  renderCommonData and fieldPortionData could return a named type instead of an arbitrary object.  The argument type for renderCommonData and renderTypeHelpers could Pick from RenderTableOptions.  renderTightCoderDecode and renderTightCoderEncode could Pick from RenderType.  Update: Partially resolved in pull request #2121 and pull request #2185. The Lattice Labs team stated:  RenderTableOptions is a store package concept and importing that into the common package for reuse would create a circular dependency and the codegen utils in the common package have no real knowledge of tables. Going to punt on this change.  Also going to punt on notes for renderCommonData and fieldPortionData as they are more stylistic suggestions and do not seem entirely necessary. Will save any cleanup of this for a larger refactor of the codegen utils.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#typescript-inconsistency", "labels": ["OpenZeppelin"]}, {"title": "Missing Explicit Function Visibility", "body": "The generated functions in renderWrapperStaticArray and renderUnwrapperStaticArray are implicitly using the default public visibility.  To clarify the intent and favor readability, consider explicitly declaring the visibility of the aforementioned functions.  Update: Resolved. This is not an issue. The Lattice Labs team stated:  This issue seems to be incorrect. These particular renderers are only ever used to render free functions which cannot have visibility (and they are not meant to be used outside of the table file). Perhaps an alternative issue could be to either render private library functions instead of free functions, or to make the use of these TypeScript renderers less ambiguous.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#missing-explicit-function-visibility", "labels": ["OpenZeppelin"]}, {"title": "Code Cleanup", "body": "We identified the following examples of code that can be simplified for better readability:  In record.ts, the if statements on lines 210 to 227 and 279 to 291 contain repeated code in both branches. This code can be moved outside the conditional structure.  In formatAndWrite.ts, lines 9 to 12 and lines 22 to 25 can be refactored into a single function.  This name parameter could reuse the corresponding constant.  Using an Immediately Invoked Function Expression to set staticResourceData seems unnecessary.  The regular expression conformity checks present in these functions could use test (on the regex itself) instead of match. This is because the matched result is not used.  This expression unnecessarily wraps a string inside another string.  Object.assign modifies the target object. Hence, assigning the result to itself is unnecessary.  renderTableIndex could use the tableIdName in staticResourceData instead of recomputing it.  Update: Partially resolved in pull request #2110. The Lattice Labs team stated:  Punting on record.ts file changes as we think it is clearer to repeat the code snippets instead of trying to reduce repeated code (and it is unclear how to not repeat without increasing complexity).  Punting on DRY-ing formatAndWrite.ts as it feels unnecessary here and would require a later refactor if we want to introduce any Solidity-specific or TS-specific code paths.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#code-cleanup", "labels": ["OpenZeppelin"]}, {"title": "Imprecise Error Message", "body": "In the encodeFieldLayout function, both error messages on lines 17 and 18 render the same message without differentiating whether the dynamic fields or total fields caused the error.  Consider changing both error messages to show the exact reason for failure.  Update: Resolved in pull request #2114. The Lattice Labs team stated:  We found the same imprecise errors in Solidity so we improved those too.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#imprecise-error-message", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestions", "body": "Throughout the codebase, some functions and variables can benefit from being renamed:  The length function should be renamed to getLength.  The renderEncodedLengths function should be renamed to renderEncodeLengths.  The _internal parameter does not describe its behavior and should be renamed to _useExplicitFieldLayout or something similar.  The renderWorld function should be renamed to renderWorldInterface.  Update: Resolved in pull request #2115. The Lattice Labs team stated:  Going to punt on the length -> getLength suggestion because it would conflict with our pattern of get{FieldName}. For each array field, a corresponding length method is added (in addition to get, set, etc.).", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#naming-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Bloated Codebase", "body": "Listed below are instances where files are generated upon configuration changes or the addition of system contracts but not removed when they become unused:  When adding a new system contract, the contract's interface is extracted and written to the worldgenBaseDirectory. If the system contract is removed or the worldgenBaseDirectory changes, the interface remains.  When adding tables to the configuration or when outputBaseDirectory changes, table files are generated and written to the outputBaseDirectory. In this case, only when a table is removed and outputBaseDirectory remains the same, the corresponding generated table file is also removed.  When changing the codegenIndexFilename or outputBaseDirectory a new table index file is written without removing the old one.  When changing the userTypesFilename or outputBaseDirectory, a new types file is written without removing the old one.  Consider clearing obsolete files so that the configuration and systems directory always match the current codebase.  Update: Acknowledged, not resolved. The Lattice Labs team stated:  We do not keep any sort of manifest to determine what files have been generated between usages of tablegen or worldgen (either run independently as regular functions or via dev-contracts, or other commands). Therefore, in the context of these functions, we have no \"previous output directory\" or \"previous index filename\" to know what files to clear.  We work around this by:  Defaulting to putting codegen files into a consistent directory (i.e., codegen) so they can be removed with one command.  Having each template include a clean script in the package.json file for manual cleanup of this directory. We would like to move towards combining codegen functions/commands into a single util and consolidate some of this behavior and may wait for deeper changes (like a file manifest) until that time.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#bloated-codebase", "labels": ["OpenZeppelin"]}, {"title": "Unused Variables", "body": "methodNameSuffix is defined and used in an object to convert a RenderType into a RenderField. However, it does not exist on either type and is otherwise unused.  Similarly, the following values are never used:  The UserTypeInfo type  The _tableId and _keyArgs return values from renderCommonData  The name parameter of StaticResourceData  The worldContractName parameter of zWorldConfig  The _untypedStore parameter to the renderWithStore callback  Consider removing any unused variables from the codebase.  Update: Resolved in pull request #2103. The Lattice Labs team stated:  StaticResourceData's name is used by renderTableId. worldContractName was in use but was an oversight when rewriting our deploy pipeline. We intend to add this back in and this is outside the scope of codegen anyway.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#unused-variables", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors were identified in the codebase:  dyanmic should be \"dynamic\".  registed should be \"register\".  system should be \"world\".  Consider fixing the aforementioned typographical errors in order to improve the readability of the codebase.  Update: Resolved in pull request #2101.", "html_url": "https://blog.openzeppelin.com/mud-code-generation-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Namespace Access Can Be Backdoored", "body": "The WorldRegistrationSystem contract takes care of registering namespaces, among other things. A namespace sets the context for a user to deploy systems and register tables. Ownership of or access to this namespace allows for the performance of critical operations such as setting Store values or transferring balance. Access to a namespace also gives access to all resource-specific systems or tables.  However, there is a problem when it comes to the arbitrary options of registering namespaces. For instance, consider the following attack. It assumes that the victim initially registers something for a new namespace (so the namespace does not yet exist):  The user attempts to register a system or a table, which would implicitly register the namespace.  The attacker front-runs the victim to:  Register the namespace directly themselves Grant access to an account they control Transfer ownership of the namespace to the victim  The victim proceeds with (1). The call succeeds because while the namespace already exists, the victim is the legitimate owner.  The attacker has full control over anything that requires access such as balance transfer or Store writes.  Consider making the design more self-contained by removing the automatic namespace registration from the aforementioned functions. Instead, make it mandatory for a user to register the namespace beforehand such that a front-run would make the user's call fail due to the existence check.  Update: Resolved in pull request #2007.", "html_url": "https://blog.openzeppelin.com/mud-audit#namespace-access-can-be-backdoored", "labels": ["OpenZeppelin"]}, {"title": "Core System Can Be Disabled", "body": "The CoreSystem contract is registered in the ROOT_NAMESPACE in the World contract. This means that it is called using delegatecall.  register a system for the  access control check. This is not an attack in itself because the contract storage of the  delegatecall to the attacker-controlled core system, which could execute the  Consider removing the namespace registration branch so that the CoreSystem will not execute a delegatecall. Alternatively (or in addition), consider protecting all CoreSystem functions with an onlyProxy modifier.  Update: Resolved in pull request #2111, pull request #2007, and pull request #2180.  Medium Severity", "html_url": "https://blog.openzeppelin.com/mud-audit#core-system-can-be-disabled", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Hook Parameter", "body": "Any storage hook that implements the onBeforeSpliceDynamicData function should receive the state of the record before the update. However, it will receive the updated encoded lengths instead, which may cause the hook to respond incorrectly.  Consider passing the original encoded lengths.  Update: Resolved in pull request #2020.", "html_url": "https://blog.openzeppelin.com/mud-audit#incorrect-hook-parameter", "labels": ["OpenZeppelin"]}, {"title": "requireInterface Is Incorrectly Specified", "body": "The requireInterface function is incorrectly specified in two ways.  Firstly, it uses a try-catch block to revert with a meaningful error if the contract does not implement the expected interface. However, this will only catch errors that occur in the context of the target contract. If the target contract has no code, or returns a value that cannot be decoded as a boolean, the error will occur in the caller's context and will revert outside the try-catch block.  Secondly, it discards some requirements of the EIP specification. To be compliant, it should confirm that the supportsInterface function returns false for the invalid interface 0xffffffff, and that it does not consume more than 30000 gas. This ensures that unrelated contracts that happen to have a fallback function that returns at least 32 bytes will not mistakenly pass the validation.  Consider using the OpenZeppelin ERC165Checker contract, or correcting these deviations.  Update: Resolved in pull request #2016.", "html_url": "https://blog.openzeppelin.com/mud-audit#requireinterface-is-incorrectly-specified", "labels": ["OpenZeppelin"]}, {"title": "Sliced Bytes Are Cut Off", "body": "slice4 function intends to return a  Consider correcting the output variable type to bytes4.  Update: Resolved in pull request #2031.", "html_url": "https://blog.openzeppelin.com/mud-audit#sliced-bytes-are-cut-off", "labels": ["OpenZeppelin"]}, {"title": "Memory Corruption on Load From Storage", "body": "In the Storage library, the load function can load data from a storage location into a memory pointer location. The loaded data can further be specified by an offset in the storage and a length to enable loading data that spans over multiple slots.  However, there is an edge case in the parameter input set that causes memory corruption. This is when data is loaded from an offset position, but the length is less than the remainder of the slot:  The problem occurs because the bitmask is based on the word remainder instead of accounting for the length. This leads to extra bytes being written into memory (e.g., bytes 20 to 31 in the example above).  There are no significant consequences in the current version of the codebase. This is because all memory loads either use a zero offset or invoke the three-parameter version which reserves sufficient space to cover and ignore the unwanted bytes. Nevertheless, the library is intended to support external codebases and the inconsistency may lead to arbitrarily severe memory corruption.  Consider respecting the length when constructing the bitmask as seen in the store function.  Update: Resolved in pull request #1978.", "html_url": "https://blog.openzeppelin.com/mud-audit#memory-corruption-on-load-from-storage", "labels": ["OpenZeppelin"]}, {"title": "registerFunctionSelector Can Be Front-Run and DoS'ed", "body": "registerFunctionSelector function is used to register system function selectors for the  call and  callFrom functions that allow the user to specify the system to address through a function parameter.  The problem is that function selectors are only four bytes, so collisions (technically, second-preimages) can be realistically generated. This is particularly true if the worldFunctionSelector is known ahead of time (e.g., in the context of DAO voting). If a worldFunctionSelector is already taken, subsequent registrations will revert. This allows a malicious actor to brute-force a worldFunctionSelector that is identical to that of the victim and front-run the transaction. Hence, the legitimate victim transaction would fail.  Further, the worldFunctionSignature is constructed by concatenating the namespace, name, and system function signature with underscores. If the function name contains underscores itself, a selector collision can be trivially constructed. For example, the worldFunctionSignature of MyNS_MySystem_do_things() can be broken down into:  victim  MyNS  MySystem  do_things()  attacker  MyNS_MySystem  do  things()  The impact of this attack is Denial of Service with the intention of griefing. The victim would have to re-write their code, redeploy it, and try to register it again. Alternatively, they will be unable to use this selector mapping feature.  Another collision that may occur is between registered worldFunctionSignatures and any of the external/public functions in the World contract. Since the external/public function is prioritized over the fallback function, the intended system call could lead to two problems:  The call reverts due to a parameter decoding mismatch or access control check.  The call succeeds and performs an unexpected action.  Consider changing the world function selector delimiter from an underscore to a character that is invalid for function names (e.g., a colon). Also, consider registering the World's functions so that they can't be registered for the fallback function mechanism. However, the front-running issue will persist without a larger redesign. Hence, consider reducing the attack surface and code complexity by removing this feature entirely, or possibly restricting it to the root namespace and enforcing the usage of the call and callFrom functions that address systems specifically.  Update: Resolved in pull request #2160, pull request #2169, and pull request #2182. The Lattice Labs team stated:  The fixes address the potential conflicts between function selectors of different namespaces. It does not address the possibility of front-running namespace/function selector registration which we've decided to punt on for now and later address with an optional module. This module will allow \"committing\" to a hashed namespace and then \"revealing/registering\" the namespace in a second step. Since C-01 is fixed, this is not a security issue anymore but just a potential griefing vector.  We have also decided to punt on addressing the possibility of brute-force calculating a conflicting function selector - since the value space is only 4 bytes it seems impossible to prevent this - but the feature is too useful to remove it altogether. The only issue this could lead to is a griefing attack if a function selector is known long enough before it is registered. This seems like a relatively small issue compared to the value custom function selectors provide in the vast majority of situations.", "html_url": "https://blog.openzeppelin.com/mud-audit#registerfunctionselector-can-be-front-run-and-dos'ed", "labels": ["OpenZeppelin"]}, {"title": "Misleading Documentation", "body": "Throughout the codebase, there are multiple instances of misleading documentation:  In the loadField function of the Storage library, the documentation suggests that the bytes beyond the length parameter are zero. However, considering a storage slot as [ aa..aa bb..bb cc..cc ] and bb..bb being the desired field, then despite its respective length, the result would return cc..cc as part of the bytes response. As such, the documentation is misleading and can cause consecutive memory corruption. Consider cleaning up the memory space by applying a bitmask or updating the documentation.  In the zero function of the Storage library, the length parameter's documentation suggests it should be specified in words. However, in the code, the value is expected to be in bytes. This can lead to a shortcoming in overwrites to zero and therefore in preserving old data, which can lead to additional security issues. Furthermore, the length is rounded up to the nearest 32 bytes multiple which is not clear either. Consider clarifying the length documentation.  The comments in the Storage.load function refer to the masking as \"middle part\" and \"surrounding parts\" whereas it is actually the left and right parts.  The code comments for all the pack functions of the PackedCounterLib library read \"Packs a single value into a PackedCounter\", but most of them pack multiple values.  The documentation of the leftPaddingBits parameter in the TightCoder.encode function is ambiguous. It says, \"The number of bits to pad on the left for each element\", but the code actually shifts the values by that count to the left. For instance, this means when encoding a uint120 value, the leftPaddingBits count would be 136 as seen in the EncodeArray library.  Consider correcting the documentation to align with the code's behavior. This will help improve the clarity and readability of the codebase.  Update: Resolved in pull request #2100.  Low Severity", "html_url": "https://blog.openzeppelin.com/mud-audit#misleading-documentation", "labels": ["OpenZeppelin"]}, {"title": "Missing Table Registration", "body": "This issue was independently identified and fixed by the Lattice team during the audit.  The Core module registers the tables it uses, but it excludes the FunctionSignatures table. This prevents the indexers from decoding the FunctionSignatures events. Consider registering this table as well.  Update: Resolved in pull request #1841 at commit f96d8b3.", "html_url": "https://blog.openzeppelin.com/mud-audit#missing-table-registration", "labels": ["OpenZeppelin"]}, {"title": "Off-Chain Indexers Can Lose Track of On-Chain State", "body": "The StoreCore contract allows for the manipulation of static and dynamic data in the tables. This includes setting a record of table elements, splicing static and dynamic data, and deleting a record. Hooks before and after the respective action enable reactivity to these storage changes. Whenever one of these functions is called, an event is emitted to notify off-chain indexers about the latest storage changes. It is expected that the indexers can recreate the on-chain storage from these events.  A problem can arise due to the order of events and calls within any of the aforementioned functions which can cause an indexer to perceive a different state outcome than what happened on-chain. The flow for those functions is generally the following:  Emit an event.  Call the \"before\" hooks.  Do the storage change.  Call the \"after\" hooks.  However, a malicious or mistaken namespace owner can set up a hook that can reenter any of those functions to change the flow (simplified) to the following:  Emit event A.  Reenter through the \"before\" hook.  Emit event B. Do storage change B.  Do storage change A.  As such, although event B was emitted last, storage change A is in fact true. For instance, this could cause major confusion when the same record is first deleted and then created which would be perceived in a reversed order off-chain.  Consider placing the event emissions together with the actual state change to prevent this type of confusion for off-chain indexers.  Update: Resolved in pull request #2017.", "html_url": "https://blog.openzeppelin.com/mud-audit#off-chain-indexers-can-lose-track-of-on-chain-state", "labels": ["OpenZeppelin"]}, {"title": "Namespace Balance Transfer Value Can Be Lost", "body": "The BalanceTransferSystem is used to send a namespace's accounted ETH value to either another namespace or to an address. However, balances can be sent to a non-existent namespace. This could occur due to human error and would likely lead to a loss of funds. Although the non-existent namespace could be registered afterwards, any other user could front-run this registration to get control over the funds.  Consider checking whether the recipient namespace exists before proceeding with the transaction.  Update: Resolved in pull request #2095.", "html_url": "https://blog.openzeppelin.com/mud-audit#namespace-balance-transfer-value-can-be-lost", "labels": ["OpenZeppelin"]}, {"title": "Delegation Can Be Misconfigured", "body": "The WorldRegistrationSystem allows users to register a delegation. This will enable the delegatee to make a call on behalf of the delegator, provided it meets the delegator's criteria.  When setting up delegation control with a system, it is possible to register an invalid delegation control without it being immediately noticeable. This would be the case when initCallData is not required (has length zero), which causes the registration function to skip the interface conformance check of the delegation control system. An attacker can take advantage of this mistake, if the delegation is not account-specific, by registering this non-existent system ID to thereby gain control over the system.  Consider performing the interface checks on the delegation control system in all cases, whether or not initCallData is required. It should be noted that this would prevent clearing the delegation (i.e., resetting the delegationControlId to zero). Thus, consider introducing a new function to unregister delegations.  Update: Resolved in pull request #2096.", "html_url": "https://blog.openzeppelin.com/mud-audit#delegation-can-be-misconfigured", "labels": ["OpenZeppelin"]}, {"title": "Deployment Edge Case", "body": "The World contract's initialize function sets up the CoreSystem functionality. To make it only callable once, it checks if there is no existing \"core\" module installed.  core module is installed under the name that the module responds with. If it responds with a different name,  delegate call. As the  creator role, this attack vector is active despite potentially revoking any root namespace ownership. Also, it allows  overwriting any other record in the table of installed modules.  It is worth noting that the initial validation reads a record from the InstalledModules table before it is registered, and the subsequent update assumes the core module registered the table. This still works whether or not the core module actually registers the InstalledModules table because both operations directly access the contract storage location where the relevant table record would be stored. Nevertheless, it undermines the expected table abstraction.  Consider explicitly installing the core module under the CORE_MODULE_NAME to ensure the initialize function is single-use. Alternatively, to avoid accessing an unregistered table, consider introducing a new initialization flag.  Update: Resolved in pull request #2170. There is a new CoreModuleAddress table to save the address.", "html_url": "https://blog.openzeppelin.com/mud-audit#deployment-edge-case", "labels": ["OpenZeppelin"]}, {"title": "Incorrect ERC-165 Interface", "body": "The following interface IDs include the ERC165_INTERFACE_ID constant:  STORE_HOOK_INTERFACE_ID  MODULE_INTERFACE_ID  SYSTEM_HOOK_INTERFACE_ID  WORLD_CONTEXT_CONSUMER_INTERFACE_ID  This is inconsistent with the EIP (as can be seen by the Simpson example). Consider excluding the ERC165_INTERFACE_ID constant from the custom interface IDs.  Update: Resolved in pull request #2014.", "html_url": "https://blog.openzeppelin.com/mud-audit#incorrect-erc-165-interface", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Table Validation", "body": "There are several consistency checks when registering a new table, but they are incomplete. In particular:  The field layout validation does not confirm whether the total static field length is the sum of all the individual static field lengths, or that the unused length fields (if the maximum number of fields is not reached) are all zero.  The schema validations for the key and value schemas do not confirm whether the total static field length is consistent with the static schema types.  The field layout and value schema are not confirmed to be consistent with each other, except for having the same total number of fields. This means that the number of static fields is not necessarily the same, and the length of a static field in the field layout does not necessarily match the type of the static field in the value schema.  Inconsistent table specifications may interfere with saving, retrieving and interpreting the database records. Consider including these additional validations.  Update: Resolved in pull request #2046.", "html_url": "https://blog.openzeppelin.com/mud-audit#incomplete-table-validation", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Module Access Control", "body": "The ModuleInstallationSystem allows anyone to install any module. Since this makes an external call to the module, it does not provide any additional functionality. Instead, it is simply a convenient way to execute several related operations atomically. However, it can overwrite any record in the InstalledModules table, which doesn't have any subsequent effects in the current codebase.  Consider whether the InstalledModules table should use the module address (along with the arguments hash) instead of the module name as the record key. This is so that it identifies the action that was taken more directly and is more resistant to being overwritten. Alternatively, consider whether the InstalledModules table should be removed entirely.  Update: Resolved in pull request #2168.", "html_url": "https://blog.openzeppelin.com/mud-audit#incomplete-module-access-control", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Resource ID Validations", "body": "Resource IDs in the World are expected to encode three components (the type, namespace and name) that are used to ensure consistency between different table records. However, there are several instances of incomplete consistency checks:  It is possible to call transferOwnership on any resource ID, provided the caller owns the corresponding namespace. This includes a table, system, an unknown resource ID, or an incorrectly specified resource ID.  It is possible to call transferBalanceToNamespace with a toNamespaceId that has a non-zero \"name\" component. This will effectively transfer the funds to a new account in the destination namespace, which needs to be spent individually (i.e., it cannot be consumed by systems within the namespace unless they are explicitly designed to handle it).  It is possible to call registerFunctionSelector with any resource ID, provided the caller owns the corresponding namespace. In practice, if it does not correspond to a valid system, it will be unusable.  It is possible to grantAccess to an incorrectly specified resource ID, or a resource that does not exist.  It is possible to call registerNamespace or registerNamespaceDelegation with a namespaceId that has a non-zero \"name\" component.  It is possible to call registerSystemHook with any resource ID, provided the caller owns the corresponding namespace.  It is possible to call registerStoreHook with a non-existent tableId, provided the caller owns the corresponding namespace.  In the interest of predictability and limiting the attack surface, consider validating all three components of user-provided resource IDs and validating the existence of a resource wherever relevant throughout the codebase.  Update: Resolved in pull request #2142 and pull request #2195.", "html_url": "https://blog.openzeppelin.com/mud-audit#incomplete-resource-id-validations", "labels": ["OpenZeppelin"]}, {"title": "Inexplicit Revert", "body": "In the getDynamicFieldSlice function of the StoreCore library, a bytes range specified by start and end can be read from a dynamic field.  While the range is checked to be within the field's length, the order of start and end is not checked. If start were to be greater than end, the subtraction for the length would underflow and the transaction would revert implicitly without providing any contextual information.  Consider adding a range check to fail more explicitly.  Update: Resolved in pull request #2034.", "html_url": "https://blog.openzeppelin.com/mud-audit#inexplicit-revert", "labels": ["OpenZeppelin"]}, {"title": "World Resource ID ROOT String Has Unexpected Length", "body": "The WorldResourceIdInstance library has helper functions to get information from an encoded World resource ID such as type, namespace and name. These fields can also be returned as a string using the toString function.  However, while the resource namespace is expected to occupy 14 bytes, the ROOT_NAMESPACE_STRING is actually a bytes16 value. The string output could, therefore, have an unexpected length.  Consider changing the constant's type from bytes16 to bytes14.  Update: Resolved in pull request #1976.", "html_url": "https://blog.openzeppelin.com/mud-audit#world-resource-id-root-string-has-unexpected-length", "labels": ["OpenZeppelin"]}, {"title": "Override Removes Supported Interface", "body": "The Module contract overrides the supportsInterface function and no longer supports the WORLD_CONTEXT_CONSUMER_INTERFACE_ID. This is inconsistent with the equivalent DelegationControl override, which retains support for the WORLD_CONTEXT_CONSUMER_INTERFACE_ID.  Consider ensuring ERC-165 support for all implemented interfaces.  Update: Resolved in pull request #2032.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/mud-audit#override-removes-supported-interface", "labels": ["OpenZeppelin"]}, {"title": "Encapsulate Functionality Recommendation", "body": "Several functions in the codebase have side effects or handle multiple use cases:  The AccessManagementSystem does not provide a mechanism to renounce the ownership of a namespace, so users will need to transfer ownership to an uncontrolled address (like the zero address). However, this will create an unnecessary record in the ResourceAccess table.  The registerTable function might register a namespace as well.  The registerSystem function might register a namespace or delete a system. In fact, this is the only way to delete a system using the World functionality.  The registerSystem function also accepts an existing system and system ID pair, which will delete the system records only to recreate them again, possibly changing the publicAccess flag in the process.  Individual delegations must be removed by overwriting them using the regular registration function, which still leaves a stray record in the UserDelegationControl table.  Namespace delegations cannot be set to zero so they must be removed by creating a new delegation control that rejects all calls.  The stray records could potentially be addressed by directly updating the tables, but this is fragile and undermines the abstractions provided by the World contract. Similarly, functions with side effects or multiple use cases can be fragile, and the most significant issues in this report are a result of imprecise handling at the boundaries of different functionality.  To reduce the attack surface and increase predictability, consider limiting each function to a single use case with a linear code path where possible.  Update: Resolved in pull request #2157.", "html_url": "https://blog.openzeppelin.com/mud-audit#encapsulate-functionality-recommendation", "labels": ["OpenZeppelin"]}, {"title": "Unintuitive Order of Function Arguments", "body": "The Storage library contains functions to store and load data according to the storage pointer, offset, length, and memory pointer. However, both functions take these arguments in different orders which can be non-intuitive for a developer.  Consider aligning the order of function parameters when the set of arguments overlaps.  Update: Resolved in pull request #2033.", "html_url": "https://blog.openzeppelin.com/mud-audit#unintuitive-order-of-function-arguments", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestions", "body": "Throughout the codebase, there are code element names that are ambiguous:  The _staticFields parameter of the encode function could be called _staticFieldLengths.  The requireNoCallback modifier could be called prohibitDirectCallback.  The byteCode parameter in the deploy function could be called creationCode as referred to in the documentation.  The tableWithHooks parameter of the filterListByAddress function could be called elementWithHooks to account for the possibility that it refers to a system.  Update: Resolved in pull request #2091.", "html_url": "https://blog.openzeppelin.com/mud-audit#naming-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Unused Functions and Variables", "body": "Throughout the codebase there are multiple instances of unused functions and variables:  In the Bytes library, the functions toBytes32, equals, setBytes1, setBytes2, setBytes4, setBytes5, setBytes7, as well as some of the slice functions  The NAME_BITS, TYPE_MASK, RESOURCE_MODULE and MASK_PTR constants  Consider removing this code to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #2090.", "html_url": "https://blog.openzeppelin.com/mud-audit#unused-functions-and-variables", "labels": ["OpenZeppelin"]}, {"title": "Unused Imports", "body": "Throughout the codebase, the following imports are unused and could be removed:  Import STORE_VERSION of StoreRead.sol  Import SliceLib of TightCoder.sol  Import FunctionSelectors of SystemCall.sol  Import IStore, Schema, System, ROOT_NAMESPACE, ROOT_NAME, revertWithBytes, NamespaceOwner, IDelegationControl, Systems, and SystemHooks of World.sol  Import ROOT_NAMESPACE, IBaseWorld, ResourceId, WorldResourceIdLib, WorldResourceIdInstance, RESOURCE_SYSTEM, AccessManagementSystem, BalanceTransferSystem, BatchCallSystem, ModuleInstallationSystem, and StoreRegistrationSystem of CoreModule.sol  Import IModule, WorldResourceIdLib, and InstalledModules of AccessManagementSystem.sol  Import WorldResourceIdLib of BalanceTransferSystem.sol  Import AccessControl and ResourceAccess of ModuleInstallationSystem.sol  Import ROOT_NAMESPACE, WorldContextProviderLib, NamespaceOwner, ResourceAccess, SystemHooks, SystemRegistry, and FunctionSelectors of StoreRegistrationSystem.sol  Import IDelegationControl of WorldRegistrationSystem.sol  Import DecodeSlice of Slice.sol  Consider removing unused imports to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #2028.", "html_url": "https://blog.openzeppelin.com/mud-audit#unused-imports", "labels": ["OpenZeppelin"]}, {"title": "Duplicate Imports", "body": "There is a duplicate import of the WorldContextProviderLib library in the SystemCall.sol file.  Consider removing duplicate imports to improve the readability of the codebase.  Update: Resolved in pull request #2024.", "html_url": "https://blog.openzeppelin.com/mud-audit#duplicate-imports", "labels": ["OpenZeppelin"]}, {"title": "Visibility Not Explicitly Declared", "body": "There are some instances of missing explicitly declared visibility:  The coreSystem state variable  The _toBool function  The requireInterface function  Consider always explicitly declaring the visibility of variables and functions, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #2029.", "html_url": "https://blog.openzeppelin.com/mud-audit#visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Code Simplification Suggestions", "body": "Throughout the codebase, there are multiple instances where the code could be simplified:  The schema type validation loop in the Schema library can be simplified. Consider looping over the _numStaticFields schema types first to ensure they all have a non-zero static byte length. Then, loop over the _numDynamicFields schema types to ensure they have a zero static byte length. This way, it is not necessary to count the fields (and validate the count later) or branch inside the loop.  The Memory.copy function is redundant to the identity precompile. Consider replacing the function's logic with a call to the precompile for simplicity and efficiency.  The leftMask function is constructed by first creating a right mask (of size 32 - byteLength) and then inverting it. However, the actual usage involves using both left and right masks [1, 2, 3, 4, 5]. Hence, the left mask is inverted back to a right mask. Consider returning a right mask in the first place.  In contrast to, for instance, FieldLayout, PackedCounter and Schema, the ResourceId does not have a using statement in the ResourceId.sol file. Instead, it is duplicated several times throughout the codebase.  There is an inconsistency for the integer base in assembly blocks. While most of the codebase uses hexadecimal numbers, there are instances [1, 2, 3, 4, 5] where decimal numbers are used.  The Slice library uses pointer(self) first and self.pointer() later.  For EIP-165 support, the codebase maintains constants [1, 2, 3, 4, 5, 6, 7] that reflect the supported interface IDs which are checked against in the supportsInterface functions. Instead, consider making use of the interface ID provided by the interface type like type(Interface).interfaceId.  The FieldLayout.numFields function could make use of the numStaticFields and numDynamicFields functions instead of reimplementing them.  In the Slice.sol and Schema.sol files, there is an inconsistency when it comes to the leading underscores for stack variables.  There is an inconsistency of relying on default initialization to zero [1, 2] versus explicitly initializing to zero [1].  In the StoreCore.getFieldLayout function, instead of getting the field layout through Storage.loadField, consider using Tables._getFieldLayout, similar to how it is done for the key schema and value schema.  In WorldContextConsumer._world, the call to StoreSwitch could invoke WorldContextConsumerLib._world for consistency with the rest of the contract.  The coreModule state variable of the WorldFactory is set in the constructor and never changed. Consider making it immutable.  The WorldRegistrationSystem.registerSystem function accepts a WorldContextConsumer type argument, whereas it should accept a System type argument.  The slice functions in the Bytes library can be simplified by declaring the output variable as a named return to save on the extra declaration and return in the function body.  The validation condition in the getSubslice function could be replaced with start > end || end > data.length.  The extcodesize opcode is not necessary to check whether the Create2.deploy call was successful since the address will also be zero in that case.  Consider applying the code changes as outlined above to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #2140. The Lattice Labs team stated:  We chose not to implement three suggestions due to gas use and readability concerns.", "html_url": "https://blog.openzeppelin.com/mud-audit#code-simplification-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Magic Number", "body": "BYTES_TO_BITS constant, but then fails to use it in several places [  1,  2,  3,  4,  5]. Consider using the constant wherever it applies.  Update: Resolved in pull request #2015.", "html_url": "https://blog.openzeppelin.com/mud-audit#magic-number", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors were identified in the codebase:  \"Since the they're max 32 bytes\" has an extra \"the\"  \"@param e The length of the fourth dynamic field's data\" should say \"[...] fifth dynamic field's data\"  The constant DYNMAIC_DATA_SLOT should be called DYNAMIC_DATA_SLOT  \"A namespace can includes tables and systems\" should say \"include\"  \"Require the balance balance to be greater or equal to the amount to transfer\" says \"balance\" twice  Consider fixing all instances of typographical errors throughout the codebase.  Update: Resolved in pull request #2023.", "html_url": "https://blog.openzeppelin.com/mud-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Use of Generic Function", "body": "There are multiple cases [1, 2, 3] where the full record in the Systems table is retrieved but only the system address is retained. Consider using the more specialized _getSystem function instead.  Update: Resolved in pull request #2022.", "html_url": "https://blog.openzeppelin.com/mud-audit#unnecessary-use-of-generic-function", "labels": ["OpenZeppelin"]}, {"title": "Client-Reported", "body": "Client-Reported", "html_url": "https://blog.openzeppelin.com/mud-audit#client-reported", "labels": ["OpenZeppelin"]}, {"title": "Store Namespace Unregistered", "body": "are both registered with the creator as the owner. However, the  Tables,  StoreHooks and  ResourceIds), which essentially gives them control over the entire  Update: Resolved in pull request #1712 at commit c14d140.", "html_url": "https://blog.openzeppelin.com/mud-audit#store-namespace-unregistered", "labels": ["OpenZeppelin"]}, {"title": "Missing Slippage Protection for Locking Liquidity", "body": "When a UniswapV3 position is locked that is not full-range, the liquidity position is removed and redeposited in the _convertPositionToFullRange function. In this situation, the liquidity between the tickUpper and tickLower decreases while the liquidity in any tick outside of that range increases. These changes in the liquidity distribution of the UniswapV3 pool can be sandwiched for a profit by manipulating the AMM with a large buy order of one token and then selling that token back into the new liquidity distribution.  The sandwiching attack requires manipulating the pool tick such that it is outside the victim's tick range (tickLower to tickUpper) when they lock their liquidity. However, when the liquidity is removed, the liquidity position is comprised entirely of one token and none of the other token. When this liquidity gets redeposited in the mint call, since there is an amount of 0 for one of the tokens, the contract will attempt to mint 0 liquidity and revert.  The attacker can still make the victim deposit the full amount of liquidity by transferring a small amount of the missing token directly to the contract before the lock call. At this point, since the AMM is already manipulated to an extreme tick, only a small transfer is required to complete the liquidity deposit. The cost of the direct transfer ends up being negligible compared to the attacker's profit.  Consider adding slippage parameters to the lock function. These slippage parameters can either be determined by input parameters or hard coded to require the pool's price tick to be within a locker's position's tick range.  Update: Resolved in pull request #1 at commit 56a8037.  High Severity", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#missing-slippage-protection-for-locking-liquidity", "labels": ["OpenZeppelin"]}, {"title": "Collector Role Is Not Relinquished During Lock Transferral", "body": "Owners of a lock can set collector addresses through the setCollectAddress and setAdditionalCollector functions. However, these addresses are not reset when the lock is transferred. This means that the previous owner can still call collect on a lock that they previously owned and collect the market fees.  Consider resetting the previous collector and additionalCollector addresses or forcing the new owner to set them whenever a lock is transferred.  Update: Resolved in pull request #1 at commit c1e2718.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#collector-role-is-not-relinquished-during-lock-transferral", "labels": ["OpenZeppelin"]}, {"title": "Users Can Lock Non-Full-Range Positions", "body": "The protocol is meant to only lock full-range UniswapV3 positions.  The logic in the lock function can be described as:  If the NFT represents a full range position, collect the fees and lock it in. If it is not a full range, then convert the position before locking it  logic block does not match this precisely. A  Consider changing the proposition check to ensure that only full ranges get locked.  Update: Resolved in pull request #1 at commit 56a8037. The UNCX team removed this design requirement from the lock function and implemented this fix in a new FullConvertor contract.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#users-can-lock-non-full-range-positions", "labels": ["OpenZeppelin"]}, {"title": "Arbitrary Position Managers", "body": "The UNCX_ProofOfReservesV2_UniV3 contract is meant to work with any \"UniswapV3-like\" protocol. It does this by allowing users to specify their own position manager contract. This gives complete execution control to an arbitrary contract that could be tailored specifically to attack the UNCX_ProofOfReservesV2_UniV3 contract.  Consider a contract that simply refuses to cooperate. It wraps all of its methods around a well-behaved NFT position manager contract (e.g., UniswapV3's). However, if it sees a call to collect from the UNCX contract, it simply does nothing and does not pass the call on to the actual NFT position manager. In this manner, the contract can bypass the lock creation fee, the collect fee, and can supply the wrong maxTick to pass the non-full-range positions from the correct manager to the UNCX locker contract. It can even refuse to safeTransferFrom the NFT to the UNCX contract, rendering the lock contract completely ineffective.  Consider implementing a whitelist system for the position manager contracts with the contract owner having the power to add (but not remove) permitted position managers.  Update: Resolved in pull request #1 at commit ea8b60a.  Medium Severity", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#arbitrary-position-managers", "labels": ["OpenZeppelin"]}, {"title": "Anybody Can Remove Tokens Accidentally Sent to the Contract", "body": "The adminRefundEth and adminRefundERC20 functions can be used by the owner to withdraw tokens which are accidentally sent to the contract. However, anybody can withdraw tokens in the contract by calling lock on a non-full-range NFT position where one pool token corresponds to the token which is stuck in the contract.  lock function, the call to  _convertPositionToFullRange will send the entire  Consider implementing such logic whereby only the tokens which come from the liquidity position during the liquidity removal are redeposited during _convertPositionToFullRange instead of the entire token balance of the contract.  Update: Resolved in pull request #3 at commit c750641.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#anybody-can-remove-tokens-accidentally-sent-to-the-contract", "labels": ["OpenZeppelin"]}, {"title": "Gas Siphoning Attack Vector", "body": "In the codebase, there is an auto-collector role (AUTO_COLLECT_ACCOUNT) that can call collect on behalf of the lock owners to collect their underlying market position fees. However, the tokens being transferred and the position manager being called by the contract are arbitrary and provided by users.  A malicious user can supply the address of a smart contract tailored to take advantage of the free gas. Such attacks have been seen in the past with FTX's withdrawal mechanism or dYdX's metatransaction mechanism. Mitigations could include a whitelist for tokens and an auto-collect blacklist for locks, but both of these would stop the protocol from providing its core service.  Consider monitoring the AUTO_COLLECT_ACCOUNT's gas consumption in order to stop it from calling collect on problematic positions.  Update: Acknowledged, not resolved. The UNCX team stated:  The auto-collector bot is called manually at the moment and only for certain clients. We will make sure tokens fit our spec before adding them to the bot.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#gas-siphoning-attack-vector", "labels": ["OpenZeppelin"]}, {"title": "Collect Fee Can Be Avoided", "body": "When users withdraw from the protocol (transfer back their NFT after the time lock has expired), there is a \"collect fee\" that is assessed from the user. However, users can sidestep this fee by simply calling decreaseLiquidity instead which transfers the full amount to the caller (the lock owner).  Consider reworking the logic for how the collect fee is collected.  Update: Resolved in pull request #3 at commit 8355982.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#collect-fee-can-be-avoided", "labels": ["OpenZeppelin"]}, {"title": "LP Fee Can Be Avoided", "body": "The LP fee is meant to take a portion of the tokens-to-be-locked when users call the lock function. However, this can easily be sidestepped by locking a position with minimal tokens and then later calling increaseLiquidity which does not collect the LP fee. This fee can also be sidestepped by calling increaseLiquidity directly on the UniswapV3 NonFungiblePositionManager.  Consider changing the logic for how the LP fee is assessed and collected.  Update: Acknowledged, not resolved. The UNCX team stated:  Since this is possible via the NonFungiblePositionManager itself and is outside of our contracts, this is ok.  Low Severity", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#lp-fee-can-be-avoided", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are numerous parts that do not have docstrings.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API, including interface functions. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Inadequate Error Messages in require Statements", "body": "In UNCX_ProofOfReservesV2_UniV3.sol, there are multiple require statements that either lack any error message or have error messages that are not descriptive:  The require statements on lines 108 and 144 are missing error messages.  The require statements on lines 148, 276, 345, along with many others have one-word error messages.  Consider including specific, informative error messages in require statements to improve the overall code clarity and facilitate troubleshooting whenever a requirement is not satisfied. If saving on gas is a priority, consider adding informative custom errors instead of require statements.  Update: Partially resolved in pull request #3 at commit 124b495. The UNCX team stated:  Partially fixed. Only added error messages where there were none before.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#inadequate-error-messages-in-require-statements", "labels": ["OpenZeppelin"]}, {"title": "transfer and send Calls Are No Longer Considered Best Practice", "body": "the upcoming TSTORE opcode will open new reentrancy attack vectors with the use of these calls. Currently,  lines 130 and  544 of  UNCX_ProofOfReservesV2_UniV3.sol.  Instead of using transfer or send, consider using address.call{value: amount}(\"\") or the sendValue function of the OpenZeppelin Address library to transfer ETH.  Update: Resolved in pull request #3 at commit 8225e36.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#transfer-and-send-calls-are-no-longer-considered-best-practice", "labels": ["OpenZeppelin"]}, {"title": "Incorrect Interface Implementation", "body": "UNCX_ProofOfReservesV2_UniV3 contract does not implement the  EIP-721 specification. Instead of  Consider implementing the function exactly as prescribed in EIP-721.  Update: Resolved in pull request #3 at commit e55dcf3.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#incorrect-interface-implementation", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Docstrings", "body": "In UNCX_ProofOfReservesV2_UniV3.sol, there are several sections that have an incomplete docstring.  Consider thoroughly documenting all functions/events (and their parameters or return values) that are part of any contract's public API. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Acknowledged, not resolved.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Capwords Style", "body": "Throughout the codebase, there are multiple components that do not follow the Solidity Style Guide. For example, events such as onMigrate and onRemoveFee should be capitalized at the start. In addition, the contract name should read UNCXProofOfReservesV2UniV3 instead of UNCX_ProofOfReservesV2_UniV3.  To improve the project's overall legibility, consider adhering to the Solidity Style Guide by naming the contracts, structs, enums, events, and errors using the CapWords style.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#inconsistent-capwords-style", "labels": ["OpenZeppelin"]}, {"title": "Unused Named Return Variables", "body": "Named return variables are a way to declare variables that are meant to be used within a function's body for the purpose of being returned as the function's output. They are an alternative to explicit in-line return statements. In UNCX_ProofOfReservesV2_UniV3's getAmountsForLiquidity function, amount0 and amount1 are unused.  Consider removing any unused named return variables.  Update: Resolved in pull request #3 at commit d619a27.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#unused-named-return-variables", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease the clarity of the code and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity files or when inheritance chains are long. In the UNCX_ProofOfReservesV2_UniV3 contract, global imports are being used.  Following the principle that clearer code is better code, consider using named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #3 at commit ef64ac6.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they discover a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for the maintainers of these libraries to contact the appropriate person about the problem and provide mitigation instructions.  Consider adding a NatSpec comment containing a security contact above the scoped contracts. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Use of Named Returns", "body": "To improve the readability of the contract, use the same return style in all of it is functions. Some of UNCX_ProofOfReservesV2_UniV3's functions explicitly return while others have implicit return values.  Consider using a consistent style for all functions.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#inconsistent-use-of-named-returns", "labels": ["OpenZeppelin"]}, {"title": "State Variable Visibility Not Explicitly Declared", "body": "In UNCX_ProofOfReservesV2_UniV3.sol, the state variable USER_LOCKS lacks an explicitly declared visibility.  For clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #3 at commit ee4384a.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Multiple Instances of Missing Named Parameters in Mappings", "body": "Since Solidity 0.8.18, developers can utilize named parameters in mappings. This means mappings can take the form of mapping(KeyType KeyName? => ValueType ValueName?). This updated syntax provides a more transparent representation of a mapping's purpose.  In UNCX_ProofOfReservesV2_UniV3.sol, there are multiple mappings without named parameters:  The FEES state variable  The LOCKS state variable  The USER_LOCKS state variable  Consider adding named parameters to the mappings to improve the readability and maintainability of the codebase.  Update: Resolved in pull request #3 at commit dc059e3.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#multiple-instances-of-missing-named-parameters-in-mappings", "labels": ["OpenZeppelin"]}, {"title": "Lack of Indexed Event Parameters", "body": "No events in IUNCX_ProofOfReservesV2_UniV3.sol have indexed parameters.  Consider indexing the event parameters to improve the ability of off-chain services to search and filter for specific events.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#lack-of-indexed-event-parameters", "labels": ["OpenZeppelin"]}, {"title": "State Variables Can Be Named More Accurately", "body": "In cryptography, a nonce is an arbitrary number that can be used just once in a cryptographic communication. In the UNCX_ProofOfReservesV2_UniV3 contract, the variable NONCE is the current lock id that will be assigned to new locks. Furthermore, fee structures have names which are hashed and those hashes are stored for quick lookup and recall. The hash of these names is sometimes called nameHash and other times feeHash.  To improve the readability and maintainability of the codebase, consider naming variables accurately and consistently.  Update: Acknowledged, not resolved.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#state-variables-can-be-named-more-accurately", "labels": ["OpenZeppelin"]}, {"title": "Variables Can Be Marked immutable", "body": "If a variable is only ever assigned a value from within the constructor of a contract, then it could be declared as immutable. COUNTRY_LIST is such a variable.  To better convey the intended use of variables and to potentially save gas, consider adding the immutable keyword to variables that are only set in the constructor.  Update: Resolved in pull request #3 at commit 4c1e716.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#variables-can-be-marked-immutable", "labels": ["OpenZeppelin"]}, {"title": "Variables Can Be Marked constant", "body": "If a variable is only ever assigned a value when it is declared, then it could be declared as constant. The ETERNAL_LOCK is such a variable.  To better convey the intended use of variables and to potentially save gas, consider adding the constant keyword to variables that are only set when they are declared.  Update: Resolved in pull request #3 at commit 6f86778.", "html_url": "https://blog.openzeppelin.com/uncx-uniswapv3-liquidity-locker-audit#variables-can-be-marked-constant", "labels": ["OpenZeppelin"]}, {"title": "ETH Deposits Can Get Stuck if They Are Not Successfully Bridged", "body": "Pull request #1011 introduced the change of redirecting the calls to deposit ETH from the L1GatewayRouter contract to the L1ScrollMessenger contract without going through the L1ETHGateway contract. This was done with the intention of reducing the gas cost associated with such an action.  However, this causes a problem. Namely, in situations in which a message could not be correctly sent through the bridge, the dropping and asset-return mechanism implemented in the L1ScrollMessenger contract will get stuck and the assets will not be able to be paid back. This is due to the lack of the onDropMessage hook implementation in the L1GatewayRouter contract, which serves as a handler to repay the respective origin of the message.  depositETH function from the  who calls and passes the message to the  message would come from the  caller. This is relevant as the  _xDomainCalldata data that will be used to keep track of the message (with its hash) but will also be used in case the message needs  to be dropped.  In such a dropping scenario, as the address that sent the message to the L1ScrollMessenger contract is the one that will be called to execute the onDropMessage hook, if such hook is not implemented, the dropping mechanism will fail and the original user will not get their ETH back. This is the same as how it used to happen when routing the call through the L1ETHGateway contract. As this does not depend on the data added to the depositETH call, those funds will get stuck in case they are not bridged successfully.  To showcase this, one can get inspired by the following gist; however, caution should be made when fixing this issue, since the gist's proposed scenario in which the issue resolves is merely an example and it is not meant to represent a fully valid resolution.  Consider implementing the onDropMessage hook in the L1GatewayRouter contract to handle the back payment when dropping messages.  Update: Resolved in pull request #1093 at commit 888c3d2. The respective contracts have been rolled back to a previous state in which the bypass previously done over the respective ETH gateways is no longer there, and in which the gateway routers have to go through the ETH gateways when depositing/withdrawing ETH.  Low Severity", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#eth-deposits-can-get-stuck-if-they-are-not-successfully-bridged", "labels": ["OpenZeppelin"]}, {"title": "Implementation Keeps Functionalities for Deprecated Variables", "body": "At line 82 of L1GatewayRouter.sol, it is explained that the ethGateway parameter is no longer in use. However, the logic that makes use of/changes this variable, such as the check in the initialize function and the setETHGateway function, is maintained.  If a variable is no longer in use, consider removing the logic that uses it.  Update: Resolved in pull request #1094 at commit 223538d.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#implementation-keeps-functionalities-for-deprecated-variables", "labels": ["OpenZeppelin"]}, {"title": "Solidity Version Is Not Fixed and Its Use Is Inconsistent", "body": "In the codebase, there are some contracts whose pragma statement does not use a fixed version, whereas others are correctly using a fixed one.  Consider reviewing all the contracts and always using the same fixed Solidity pragma version in all of them. This will help improve consistency and avoid compiling contracts with unexpected compiler versions.  Update: Acknowledged, not resolved. The Scroll team stated:  We prefer to leave base contracts and interfaces using ^0.8.0 such that the third party can inherit it more easily.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#solidity-version-is-not-fixed-and-its-use-is-inconsistent", "labels": ["OpenZeppelin"]}, {"title": "Different Frameworks Are Used Concurrently in the Protocol", "body": "When it comes to checking the correct execution of unit tests, coverage, and scripts, the project offers integrations with both Hardhat and Foundry. However, we identified some issues that are worth analyzing:  The coverage does not work if run through Hardhat. This is because the instrumentation step fails with the following error:  Error in plugin solidity-coverage: Error: Could not instrument: L2/predeploys/L1BlockContainer.sol. (Please verify solc can compile this file without errors.) extraneous input ',' expecting {'from', '{', '}', '(', 'error', 'for', 'function', 'address', 'calldata', 'if', 'assembly', 'return', 'revert', 'byte', 'let', '=:', 'switch', 'callback', DecimalNumber, HexNumber, HexLiteralFragment, 'break', 'continue', 'leave', 'payable', 'constructor', 'receive', Identifier, StringLiteralFragment} (251:23)  Even though the coverage with Foundry executes well, it shows an empty coverage for all the contracts inside the src/libraries/verifier sub-directory.  There is no script defined in the package.json to run the Foundry coverage. Consider adding one as done for the tests and for Hardhat's coverage.  Scripts exist for both Foundry and Hardhat, but it seems that those used in the latter are outdated and deprecated. This is error-prone and a concern since production environment variables can be used in the wrong scripts and thereby run unneeded/erroneous transactions. As such, consider whether is worth maintaining both frameworks, unifying the testing and coverage. In addition, consider having a unique way of running production scripts to avoid unexpected executions.  Update: Acknowledged, will resolve. In pull request #1095 at commit 26fa7a1 a specific script has been defined to run coverage with Foundry. Verifiers contracts are being skipped by the coverage in the .solcover.js file. The Scroll team stated:  We also noted this issue. That's why we added it to skipFiles in .solcover.js.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#different-frameworks-are-used-concurrently-in-the-protocol", "labels": ["OpenZeppelin"]}, {"title": "Renaming Opportunities", "body": "The INTRINSIC_GAS_NONZERO_BYTE factor that multiplies the length of the message-to-be-sent in order to calculate the amount of gas needed for the L2 execution, has a name that originates from a previous version that differentiated between zero and non-zero bytes. However, now, there is no such distinction and its name suggests that the whole message does not have a zero byte.  Consider changing its name to something more appropriate that does not refer to old code's behavior.  Update: Resolved in pull request #1096 at commit 71d8c78.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#renaming-opportunities", "labels": ["OpenZeppelin"]}, {"title": "Mismatch Between Interface and Implementation", "body": "Throughout the codebase, there are some instances in which the interface differs from the actual implementation:  The parameter _calldata from the L1MessageQueue.calculateIntrinsicGasFee function is defined as memory in the interface but as calldata in the implementation.  The L2GasPriceOracle.intrinsicParams getter from the implementation is not reflected in the interface.  The IL1MessageQueueWithGasPriceOracle interface does not reflect the existence of the l2BaseFee and whitelistChecker getters from the implementation.  The gasOracle public variable of the L1MessageQueue contract is not defined in the corresponding interface. The same happens for all the immutable and public variables except for pendingQueueIndex which has a specific getter defined in the interface.  The parameter _calldata from the IL1GatewayRouter.setERC20Gateway function is defined as memory in the interface but as calldata in the implementation.  Consider reviewing the entire codebase and making all the interfaces consistent with their implementations.  Update: Partially resolved in pull request #1097 at commit 747f354. Only the memory input in the IL1MessageQueue interface and the inconsistency between the IL1MessageQueueWithGasPriceOracle interface and its implementation has been resolved. However, in the latter ones, the variables have been marked as override. The Scroll team stated:  Two are fixed. The others are intended to not be public in the interface or will be fixed at a later time.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#mismatch-between-interface-and-implementation", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Use of the __gap Variable", "body": "Throughout the codebase, there are contracts that make use of the __gap variable whereas others do not. As the majority of the contracts are upgradeable, consider consistently defining a __gap variable for each one of such upgradeable contracts, with the corresponding size being according to the defined storage slots. Furthermore, consider adding comments mentioning the slots that were already used to keep track of the deprecated slots when upgrading the contracts.  Moreover, the L2ScrollMessenger contract uses a variable called __used to reflect the slots that were used prior to changing them into immutable parameters or into parameters are no longer in use. However, the rest of the codebase has adopted the approach of replacing those slots with deprecated private variables.  In order to be consistent and prevent possible mistakes when upgrading future versions of the contract, consider keeping the same style of deprecating previously used slots while also addressing the lack of the __gap variable in most of the contracts.  Update: Acknowledged, not resolved. The Scroll team stated:  We are comfortable with the current implementation, no change is needed.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#inconsistent-use-of-the-__gap-variable", "labels": ["OpenZeppelin"]}, {"title": "Code Style Inconsistencies", "body": "Throughout the codebase, there are places at which the code style adopted is not consistent across all the contracts:  In some instances, the onlyInitializing modifier is used, but in others it is not.  A few events are defined in the interface, whereas in other cases they are defined in the implementation contract.  The L2GasPriceOracle.IntrinsicParams struct should be defined in the interface instead of in the implementation to be consistent with the rest of the codebase.  The ErrorZeroAddress error defined in L1GatewayRouter should be defined in the IL1GatewayRouter interface as well to be consistent with the other implementations like the IScrollChain interface. The same applies to the L2GatewayRouter contract.  Consider fixing such inconsistencies to improve the overall readability and clarity of the codebase.  Update: Acknowledged, not resolved. The Scroll team stated:  We are comfortable with the current implementation, no change is needed.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#code-style-inconsistencies", "labels": ["OpenZeppelin"]}, {"title": "Potential Gas Improvements", "body": "Throughout the codebase, there are some instances in which the code can be refactored to be more gas-efficient:  Many getters are duplicated due to there being public variable declarations along with specific getter definitions as well. Consider using only one of the two and checking the code for other such instances.  Some functions might be defined as external instead of public. Consider reviewing the entire codebase for other similar occurrences like the one in the L2ETHGateway contract.  The use of require statements instead of custom errors has been proven to consume more gas. Even though there are attempts at porting the existing require statements to custom errors, several cases still remain that have not been so ported. Consider porting these across the entire codebase.  Consider whether it is worth refactoring the code to accommodate such changes so that less gas is consumed.  Update: Acknowledged, not resolved. The Scroll team stated:  We are comfortable with the current implementation, no change is needed.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#potential-gas-improvements", "labels": ["OpenZeppelin"]}, {"title": "Missing or Inconsistent Documentation", "body": "Throughout the codebase, there are inconsistencies in the documentation. Particularly when checking the NatSpec docstrings from the other analogous set of contracts:  At lines 47 and 57 of the L1ERC721Gateway contract, \"in L1\" is missing at the end. The same happens at lines 47 and 54 of the L1ERC1155Gateway contract, at lines 47, 48, 63 and 64 of the L1CustomERC20Gatewaycontract, and at lines 57, 58, 81 and 82 of the L1USDCGateway contract.  The L1WETHGateway contract misses the same statement present in the L2WETHGateway contract about parameters not being used.  The L2ETHGateway contract is missing documentation in the _withdraw function analogous to the one in L1ETHGateway._deposit but with the respective parameters.  The L2GatewayRouter is missing the \"@dev This variable is no longer used\" comment in the ethGateway variable definition.  In the IL2GasPriceOracle interface, the two added getter functions do not have any documentation besides a single \"@notice\" comment.  Consider fixing the reported examples to improve the overall readability of the codebase.  Update: Partially resolved in pull request #1098 at commit a8addd8. The comment on the L2GatewayRouter contract has not been added to the variable definition.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#missing-or-inconsistent-documentation", "labels": ["OpenZeppelin"]}, {"title": "Deprecated Variables Are Still Being Assigned Values", "body": "__l2TokenImplementation and the __l2TokenFactory variables have been deprecated as  suggested by the docstrings. However, they are still being assigned values. This not only consumes more gas but is also inconsistent with other places across the codebase, such as the  ScrollGatewayBase contract where variables are being directly omitted. The same happens in the  L2StandardERC20Gateway contract with the  Consider removing such assignments to save gas. In addition, consider improving the consistency of the codebase by not assigning values to deprecated variables.  Update: Resolved in pull request #1099 at commit fbb7862.", "html_url": "https://blog.openzeppelin.com/scroll-bridge-gas-optimizations-audit#deprecated-variables-are-still-being-assigned-values", "labels": ["OpenZeppelin"]}, {"title": "Bootloader Uses Incorrect Value for System Contract Upgrade Log Key", "body": "SystemLogKey enum is employed by the L2 system contracts to distinguish between logs. As per its definition, the value assigned to  EXPECTED_SYSTEM_CONTRACT_UPGRADE_TX_HASH_KEY is  bootloader.yul file, the  protocolUpgradeTxHashKey function associated with  Consider changing the return value of the protocolUpgradeTxHashKey function to the correct value matching EXPECTED_SYSTEM_CONTRACT_UPGRADE_TX_HASH_KEY, which is 9.  Update: Resolved in pull request #178 at commit 88d22b5.  Low Severity", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#bootloader-uses-incorrect-value-for-system-contract-upgrade-log-key", "labels": ["OpenZeppelin"]}, {"title": "require Statement With Multiple Conditions", "body": "In Executor.sol, there is a require statement that checks multiple conditions to be satisfied.  To simplify the codebase and show the most helpful error messages for failing require statements, consider having a single require statement per condition.  Update: Resolved in pull request #179 at commit cf63da3.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#require-statement-with-multiple-conditions", "labels": ["OpenZeppelin"]}, {"title": "Missing Tests", "body": "The proposed changes to the system contracts lack tests that could confirm the correctness of the implementation. For instance, the chunkAndPublishPubdata function of the PubdataChunkPublisher contract requires additional testing.  Consider adding tests to enhance the quality and health of the codebase.  Update: Partially resolved in pull request #188 at commit 43e3ecd. The Matter Labs team stated:  We added tests for failure scenarios with relevant revert checks. For success cases, we couldn't check whether the correct system log was published within the test, but have verified it manually.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#missing-tests", "labels": ["OpenZeppelin"]}, {"title": "Misleading Documentation", "body": "Documentation is misleading at some places in the codebase. For instance, the NatSpec comment describing MAX_MEM_SIZE suggests that the memory page consists of 24000000  / 32 VM words. However, the value returned is 30000000.  Consider rephrasing misleading comments to match the intention of the code.  Update: Resolved in pull request #180, at commit 84fbcfd.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#misleading-documentation", "labels": ["OpenZeppelin"]}, {"title": "Todo Comments in the Code", "body": "During development, having well-described TODO/Fixme comments will make the process of tracking and solving them easier. Without this information, these comments might age and important information for the security of the system might be forgotten by the time the system is released to production. These comments should be tracked in the project's issue backlog and resolved before the system deploys.  Multiplies instances of TODO/Fixme comments were found in the codebase:  The TODO comment at line 44 of Executor.sol  The TODO comment at line 23 of PubdataChunkPublisher.sol  Consider removing all instances of TODO/Fixme comments and instead tracking them in the issues backlog. Alternatively, consider linking each inline TODO/Fixme comment to the corresponding issues backlog entry.  Update: Resolved in pull request #181, at commit d23d5c3.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#todo-comments-in-the-code", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. In addition, if the contract incorporates third-party libraries and a bug surfaces in those, it becomes easier for the maintainers of those libraries to contact the appropriate person about the problem and provide mitigation instructions. The IPubdataChunkPublisher interface does not appear to have a security contact.  Consider adding a NatSpec comment containing a security contact above the contract definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #182 at commit 54e982e.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Uninitialized Local Variable", "body": "The local variable blobVersionedHash in Executor.sol is declared and subsequently initialized with the return value of _getBlobVersionedHash function later in the code.  To enhance the overall clarity, intent, and readability of the codebase, consider declaring and initializing the blobVersionedHash variable in a single line.  Update: Resolved in pull request #183 at commit 0edd4ed.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#uninitialized-local-variable", "labels": ["OpenZeppelin"]}, {"title": "Addresses Are Not Ordered Correctly", "body": "The constant values of the addresses in the L2ContractAddresses contract are not ordered incrementally which is error-prone.  Consider ordering all addresses incrementally.  Update: Resolved in pull request #184 at commit 4da7ca8.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#addresses-are-not-ordered-correctly", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors were identified throughout the codebase:  Instead of using \"4844\" [1] [2] [3] [4] [6] [7] [8], consider using \"EIP-4844\".  Instead of \"EIP 4844\", consider using \"EIP-4844\".  \"failer\" should be \"failure\"  \"doesnt\" should be \"doesn't\"  \"isnt\" should be \"isn't\"  \"arent\" should be \"aren't\"  \"blobHah\" should be \"blobHash\"  Consider fixing the above errors for improved clarity and readability.  Update: Resolved in pull request #185 at commit e9479f2.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Unused Code", "body": "In the Executor contract, the check on line 189 implies that the number of _newBatchesData is equal to 1. This check makes the following parts of the code irrelevant in subsequent executions:  The check on line 192 is obsolete because _newBatchesData.length is equal to 1 (i.e., greater than 0).  Both for-loops on lines 216 and 248 can be refactored. If the length of the _newBatchesData array is known to be 1, there is no value in iterating over it.  Moreover, consider restructuring the commitBatches function to only accept data from a single new batch instead of a CommitBatchInfo array. Furthermore, consider assessing further interdependent functions within the Executor contract to accommodate this modification.  Update: Partially resolved in pull request #186 at commit 2aeb40a. The Matter Labs team stated:  We chose to remove the require on length being greater than 0 as the only change. Supporting 1 batch per commitment is a temporary change so leaving the code minimizes unnecessary work.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#unused-code", "labels": ["OpenZeppelin"]}, {"title": "Chunks Are Published Before Data Is Validated", "body": "The publishPubdataAndClearState function of L1Messenger contract calls the pubdata chunk publisher contract in order to chunk and publish data. The issue lies in the fact that the call occurs before the check that ensures that the calldata does not contain extra data.  Consider swapping the checks to ensure that the data is in the correct format before calling the pubdata chunk publisher contract.  Update: Resolved in pull request #187 at commit c53456f.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#chunks-are-published-before-data-is-validated", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are several parts that have an incomplete docstring:  The IPubdataChunkPublisher interface is missing docstrings.  The BlockCommit event in IExecutor.sol is missing docstrings for the batchNumber, batchHash, and commitment parameters.  The BlocksVerification event in IExecutor.sol is missing docstrings for the previousLastVerifiedBatch and currentLastVerifiedBatch parameters.  The BlockExecution event in IExecutor.sol is missing docstrings for batchNumber, batchHash, and commitment parameters.  The BlocksRevert event in IExecutor.sol is missing documentation for the totalBatchesCommitted, totalBatchesVerified, and totalBatchesExecuted parameters.  The sendL2ToL1Log function in L1Messenger.sol is missing docstrings for the _isService, _key and _value parameters.  The sendToL1 function in L1Messenger.sol is missing docstrings for the _message parameter.  The requestBytecodeL1Publication function in L1Messenger.sol is missing docstrings for the _bytecodeHash parameter.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #189 at commit f244ede.", "html_url": "https://blog.openzeppelin.com/eip-4844-support-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Overwriting ERC-20 Metadata Can Cause Unexpected Behaviors", "body": "reinitializeToken function that allows the Beacon owner to overwrite the  setting a new name in the  To mitigate these risks, consider removing the option of overwriting the decimals value in the reinitializeToken function. Moreover, consider issuing clear warnings regarding any changes in the token's name in order to ensure that users are fully aware of the potential invalidation of their previously signed permits.  Update: Resolved in pull request #139 at commit a6ceba0. The decimals overwrite was removed from the function.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#overwriting-erc-20-metadata-can-cause-unexpected-behaviors", "labels": ["OpenZeppelin"]}, {"title": "Critical and High Vulnerabilities in Yarn Module Dependencies", "body": "The project's current dependencies include versions of yarn modules that are known to have critical and high vulnerabilities. The following dependencies are not imported directly but are nonetheless included as part of other project dependencies:  In the era-contracts repository:  lodash (4.17.20)  json5 (0.5.1)  get-func-name (2.0.0)  underscore (1.9.1)  minimatch (3.0.4)  crypto-js (3.3.0)  browserify-sign (4.0.0)  http-cache-semantics (4.0.0)  flat (4.1.0)  node-fetch (1.7.3)  async (2.6.3)  In the era-system-contracts repository:  get-func-name (2.0.0)  To mitigate the risks associated with these vulnerabilities, consider upgrading these modules to versions that have resolved those issues. This may involve updating the primary dependencies that include these modules. If the vulnerable modules are part of unmaintained projects, consider seeking alternative modules that offer similar functionality without the security risks. In cases where immediate replacement or upgrading is not feasible, it is crucial to document these issues clearly and address the potential risks in the project's documentation and security protocols. This proactive approach ensures awareness and readiness to handle any security challenges that might arise from these vulnerabilities.  Update: Partially resolved in pull request #98 at commit ada1bac, and in pull request #153 at commit e9246e3. The Matter Labs team stated:  We upgraded most of the listed dependencies, except for flat and minimatch. These dependencies belong to the Hardhat gas reporter which is still in use in our repo today. Since the main product of the repo is smart contracts, the corresponding JavaScript vulnerabilities cannot be exploited.  Furthermore, it was recommended to set up Dependabot to monitor vulnerable dependencies and keep them up to date more automatically.  Low Severity", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#critical-and-high-vulnerabilities-in-yarn-module-dependencies", "labels": ["OpenZeppelin"]}, {"title": "minDelay Set to Zero Undermines Security Council Purpose", "body": "The Governance contract is a timelock that allows scheduling operations that make critical changes to the protocol. These scheduled operations can be executed after waiting for a minDelay period in seconds. During construction or through a scheduled operation, this minDelay can be set to zero (or a low value).  This option of a zero minDelay has the following implications:  A compromised owner can perform malicious actions immediately.  Hence, the role of the security council to skip the delay is obsolete.  Users do not have enough time to withdraw their funds.  To mitigate these risks, consider defining a constant minimum limit for minDelay (e.g., by facilitating the UPGRADE_NOTICE_PERIOD constant), thereby allowing adequate time for stakeholders to respond to any proposed modifications.  Update: Acknowledged, not resolved. While the team intends to have a non-zero minDelay after the initial stage, a minimal minDelay has not been hard coded. The Matter Labs team stated:  At the initial stage of the protocol, the minDelay is 0. It is part of the initial training wheels of the protocol to allow for swift reaction in case of a needed emergency upgrade. While the alternative to achieve the same effect is to leverage the security council (basically set the security council to be the same entity as the owner of the Governance), having it as zero is more explicit and easier to maintain.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#mindelay-set-to-zero-undermines-security-council-purpose", "labels": ["OpenZeppelin"]}, {"title": "Undisclosed Functionality Mismatch in L1 and L2 Token Functions Post-Bridging", "body": "When bridging tokens from L1 to L2, by default, the L2StandardERC20 contract will be deployed initially. However, this default implementation can introduce a gap in functionalities when compared to their L1 counterparts, such as rebase methods or voting capabilities. This discrepancy can cause confusion for users or developers trying to interact with these tokens like they would on L1.  To enhance transparency, consider adding a disclaimer to the existing note in the documentation as well as to the ERC-20 bridge contracts documentation [1, 2]. In addition, the user interface of the bridge, which is controlled by Matter Labs, should inform users of the potential limitations in token functionality post-bridging.  Update: Resolved in pull request #140 at commit 5cbf05b, and in pull request #845 at commit 82232bc.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#undisclosed-functionality-mismatch-in-l1-and-l2-token-functions-post-bridging", "labels": ["OpenZeppelin"]}, {"title": "Inaccurate Attribution in LibMap.sol", "body": "In the LibMap.sol contract, specifically at line 5, the authorship is attributed to Solady. However, upon examination, it is clear that the code is not directly sourced from Solady but rather draws inspiration from their work. This misattribution could lead to confusion regarding the origins and the licensing of the code.  To maintain clarity and proper intellectual property acknowledgment, consider revising the comment to accurately reflect the nature of Solady's influence, perhaps indicating that the implementation is inspired by Solady's work rather than directly copied from there.  Update: Resolved in pull request #141 at commit 9712419.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#inaccurate-attribution-in-libmap.sol", "labels": ["OpenZeppelin"]}, {"title": "Documentation Mismatch", "body": "Throughout the codebase, there are several documentation mismatches:  In the Governance.sol contract, specifically within the cancel method, the documentation indicates that both the owner and the securityCouncil have the ability to cancel. However, the implementation restricts this action solely to the owner through the onlyOwner modifier. This means in the event of the owner account getting compromised, the securityCouncil cannot intervene.  In the L2ContractHelper contract, the IL2Messenger interface is described for sending arbitrary-length messages from L2 to L1. It describes the four parameters senderAddress, isService, key, and value of the underlying operation, but then refers to isService as marker. Consider sticking to one word for consistency.  In LibMap.sol, the _index parameter of the set function is inaccurately described. The documentation states \"The index of the uint32 value to retrieve\", whereas it is used for setting the value.  The documentation of the verifierParams element of the ProposedUpgrade struct says that \"If either of its fields is 0, the params will not be updated\". However, in the _setVerifierParams function, the action of setting new parameters is only skipped when all parameters are zero. Consider correcting the documentation to match the implementation.  Update: Resolved in pull request #142 at commit a320b9b.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#documentation-mismatch", "labels": ["OpenZeppelin"]}, {"title": "Upgrade Validation and Execution Is Not Strict", "body": "The BaseZkSyncUpgrade contract is an abstract contract used to perform standardized upgrades on the rollup. To ensure stricter execution and validation in this process, consider the following suggestions.  upgrade function using the values passed in through the  In addition, the _setVerifier function is used to set the verifier contract that will be used on L1 to verify the ZK proofs of the L2 rollup. As the documentation explains, batches that have been committed but not verified with the old verifier cannot be verified afterwards.  To prevent this mistake on a smart contract level, consider checking that the number of batches verified matches the number of the batches committed in the storage.  Update: Resolved in pull request #158 at commit b34ca08. The Matter Labs team stated:  We decided to not check that all the batches are verified, due to the following reasons:  Firstly, it is not the only thing that needs to be checked. For instance, we need to ensure that all the batches with the old version have been committed prior to executing the upgrade. This cannot be done on-chain.  The following scenario is possible:  We may start an upgrade (that fixes some theoretical issue with the verifier, i.e., the system does not change its logic but there is an edge case whereby a batch may become unprovable and we are trying to fix it). Let's assume that we introduced a delay in upgrades (i.e., they are not instant). During the waiting period, the issue has been triggered. Meaning, we cannot achieve the \"all committed blocks must be verified\" requirement without the upgrade itself. Now, in order to turn off the \"all committed blocks must be verified\" requirement, we will have to restart the waiting period (or do an emergency upgrade) to use the upgrade implementation that does not enforce it.  While the benefits are clear, it introduces edge cases that are rather easier to avoid by just always double-checking the requirements off-chain before triggering the upgrade.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#upgrade-validation-and-execution-is-not-strict", "labels": ["OpenZeppelin"]}, {"title": "Misleading Contract Name", "body": "The Governance contract, while descriptive of its operational role, can cause confusion given its name. The term \"Governance\" could be perceived as encompassing all governance aspects, such as voting, proposal submissions, and community decision-making. However, as the documentation suggests, the purpose of this contract is to act as a timelock for operations that change critical properties and functionalities of the protocol.  For clarity, consider naming the contract in a way that relates to its implementation (e.g., \"TimelockedGovernor\" or \"UpgradeScheduler\").  Update: Acknowledged, not resolved. The Matter Labs team stated:  The current name was used because this contract is intended to serve as the governor of the main DiamondProxy. While it is true that switching to a name that better represents the functionality of the contract could be considered, the Governance contract has already been deployed. To avoid the risk-prone process of migrating the governance, and the discrepancies between the open-source repository and the deployed code, it is better to avoid renaming the contract at this point.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#misleading-contract-name", "labels": ["OpenZeppelin"]}, {"title": "Multiple Instances of Missing Named Parameters in Mappings", "body": "Since Solidity 0.8.18, developers can utilize named parameters in mappings. This means mappings can take the form of mapping(KeyType keyName => ValueType valueName). This updated syntax provides a more transparent representation of a mapping's purpose.  Throughout the codebase, there are multiple mappings without named parameters:  The selectorToFacet and facetToSelectors state variable in the Diamond library  The map state variable in the LibMap contract  The data state variable in the PriorityQueue contract  The immutableDataStorage state variable in the ImmutableSimulator contract  The balance state variable in the L2EthToken contract  The rawNonces and nonceValues state variables in the NonceHolder contract  The batchHash state variable in the SystemContext contract  The timestamps state variable in the Governance contract  The isWithdrawalFinalized, depositAmount, and totalDepositedAmountPerUser state variables in the L1ERC20Bridge contract  The isWithdrawalFinalized state variable in the L1WethBridge contract  The l1TokenAddress state variable in the L2ERC20Bridge contract  Consider adding named parameters to the mappings in order to improve the readability and maintainability of the codebase.  Update: Resolved in pull request #143 at commit 647a798, and in pull request #96 at commit 8b19ffc.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#multiple-instances-of-missing-named-parameters-in-mappings", "labels": ["OpenZeppelin"]}, {"title": "Incomplete Documentation of Differences Between WETH9 and L2Weth Contracts", "body": "The documentation for the L2Weth contract outlines its differences from the WETH9 contract. However, this list is not exhaustive. Key functionalities like the added depositTo and withdrawTo methods, along with the bridge functions, are missing.  To enhance clarity and accuracy, consider expanding the list of differences to include these additional features or rephrasing the documentation to indicate that the listed differences are not exhaustive.  Update: Resolved in pull request #144 at commit 0f5d29d. The depositTo and withdrawTo functions were added to the documentation as WETH9 differences. The bridge-related differences were not specifically mentioned, but these functions are not callable by users.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#incomplete-documentation-of-differences-between-weth9-and-l2weth-contracts", "labels": ["OpenZeppelin"]}, {"title": "Unnecessary Cast", "body": "At line 328 of L1ERC20Bridge, the l2TokenBeacon variable is already an address type, but is unnecessarily cast explicitly as an address.  To improve the overall clarity, intent, and readability of the codebase, consider removing unnecessary casts.  Update: Resolved in pull request #145 at commit 7759538.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#unnecessary-cast", "labels": ["OpenZeppelin"]}, {"title": "State Variable Visibility Not Explicitly Declared", "body": "Throughout both codebases, there are state variables that lack an explicitly declared visibility.  In the era-contracts repository:  The state variables DIAMOND_INIT_SUCCESS_RETURN_VALUE and DIAMOND_STORAGE_POSITION in Diamond.sol  The state variable CREATE2_PREFIX in L2ContractHelper.sol  The state variable availableGetters in L2StandardERC20.sol  In the era-system-contracts repository:  the state variables DEPLOY_NONCE_MULTIPLIER and MAXIMAL_MIN_NONCE_INCREMENT in NonceHolder.sol  For clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #97 at commit 20a8fb7, and in pull request #146 at commit 93c019d.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice is quite beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Even interfaces and libraries, which may not be deployed in and of themselves, may be used by another protocol, which would need a security contact when coming across a vulnerability in the integration.  Throughout both codebases, the following libraries and interfaces do not have a security contact.  In the era-contracts repository:  The IGovernance interface  The IL1Bridge interface  The LibMap library  In the era-system-contracts repository:  The IComplexUpgrader interface  The ICompressor interface  The IKnownCodesStorage interface  The IL1Messenger interface  The ISystemContext interface  The ISystemContextDeprecated interface  The ISystemContract abstract contract  Consider placing a NatSpec comment containing a security contact above the contract, library, or interface definitions. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #149 at commit c6ed3fa, and in pull request #99 at commit f4a906e.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Lack of Indexed Event Parameters", "body": "Throughout the codebase, two events do not have their parameters indexed:  The ChangeSecurityCouncil event in IGovernance.sol  The NewValidator event in ValidatorTimelock.sol  Consider indexing event parameters to improve the ability of off-chain services to search and filter for specific events.  Update: Acknowledged, not resolved. The Matter Labs team stated:  Using Indexed parameters could indeed be preferred. However, at this point, it is better not to add them due to the following considerations:  These contracts are not upgradable. To upgrade ValidatorTimelock, we need to deploy a new one, introducing additional risks during the process of migrations as the commitment times between batches will not be migrated. The migration of governance is even more risk-prone and time-consuming.  These changes might be breaking for those who already track these events.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#lack-of-indexed-event-parameters", "labels": ["OpenZeppelin"]}, {"title": "Unused Constants", "body": "The following constants were identified as being unused:  L2_BYTECODE_COMPRESSOR_SYSTEM_CONTRACT_ADDR  INITIAL_STORAGE_CHANGE_SERIALIZE_SIZE  REPEATED_STORAGE_CHANGE_SERIALIZE_SIZE  UPGRADE_NOTICE_PERIOD  MAX_PUBDATA_PER_BATCH  PRIORITY_TX_MAX_PUBDATA  Consider clarifying whether these constants are necessary. Otherwise, consider removing them.  Update: Resolved in pull request #154 at commit 23a7381.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#unused-constants", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease the code clarity, and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity files or when inheritance chains are long.  Throughout the codebases, global imports are being used. For instance:  All imports in BootloaderUtilities.sol  1 import in ImmutableSimulator.sol  3 imports in MsgValueSimulator.sol  2 imports in NonceHolder.sol  5 imports in BaseZkSyncUpgrade.sol  All imports in DefaultUpgrade.sol  All imports in Diamond.sol  All imports in Merkle.sol  All imports in Storage.sol  All imports in ValidatorTimelock.sol  All imports in L1ERC20Bridge.sol  11 imports in L1WethBridge.sol  7 imports in L2ERC20Bridge.sol  All imports in L2StandardERC20.sol  All imports in L2Weth.sol  5 imports in L2WethBridge.sol  Following the principle that clearer code is better code, consider using named import syntax import {A, B, C} from \"X\"; to explicitly declare which contracts are being imported.  Update: Resolved in pull request #100 at commit 9926470, and in pull request #155 at commit df43911.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "Literal Number With Many Digits", "body": "In the SystemContext contract, the block difficulty is defined as 2500000000000000. Literal numbers with many digits are hard to parse and harm the readability of the code.  Consider using the scientific notation instead.  Update: Resolved in pull request #101 at commit 0666f02.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#literal-number-with-many-digits", "labels": ["OpenZeppelin"]}, {"title": "Unused Import", "body": "The import of SystemContractHelper is not used throughout the KnownCodesStorage contract.  Consider removing this import to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #102 at commit 8152d5c.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#unused-import", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors were identified throughout the codebases:  \"Propage\" should be \"Propagate\"  \"where\" should be \"when\"  The following revert strings should say \"is allowed\":  \"Only security council allowed to call this function\" \"Only governance contract itself allowed to call this function\"  The following comments should say \"[...] the L2 bridge [...]\":  \"[...] the L1 -> L2 transaction for deploying L2 bridge implementation\" \"[...] the L1 -> L2 transaction for deploying L2 bridge proxy\" \"No factory deps are needed for L2 bridge proxy, [...]\"  \"Structure used to represent zkSync transaction\" should be \"a zkSync transaction\" or \"zkSync transactions\"  The list of parameters in an L2 to L1 message is missing a comma  \"The struct that describes for the users will be charged for pubdata for L1->L2 transactions\" should be \"The struct that describes whether users [...]\"  \"occured\" should be \"occurred\"  Update: Resolved in pull request #156 at commit 3d7cc8e, and in pull request #103 at commit 508f6e8.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Missing and Incomplete Docstrings", "body": "Throughout the codebases, some parts are missing docstrings while some docstrings are incomplete:  The fallback function of the MsgValueSimulator contract does not have any docstrings.  The isNonceUsed function of the NonceHolder contract does not have any docstrings.  In the upgrade function of the BaseZkSyncUpgrade contract, the _proposedUpgrade parameter is not documented.  The initialize function of the L2ERC20Bridge contracts does not have any docstrings.  The reinitializeToken function of the L2StandardERC20 contract does not use proper NatSpec comments and none of its parameters are documented.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #157 at commit efab770, and in pull request #104 at commit 16bfe51.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#missing-and-incomplete-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Function Is Updating the State Without Event Emissions", "body": "constructor of the  NewExecutionDelay and  NewValidator, are not emitted at this point. While these state variables can optionally be changed later, and such changes are communicated through the events, the absence of initial values means that the complete history is not accurately reflected in the emitted events.  Consider emitting events in the constructor in order to enable off-chain indexers to track the complete history for these particular values.  Update: Acknowledged, not resolved. The Matter Labs team stated:  The addition of these events is preferred. However, to upgrade ValidatorTimelock, we need to deploy a new one, introducing additional risks during the process of migrations as the commitment times between batches will not be migrated. So, to avoid additional risks with redeployment, or discrepancies between the open-source repo and the deployed code, it is better not to introduce these events at this point.", "html_url": "https://blog.openzeppelin.com/december-diff-and-governance-audit#function-is-updating-the-state-without-event-emissions", "labels": ["OpenZeppelin"]}, {"title": "Issues Discovered in v1.4.1-integration Diff Audit", "body": "518bfff, and in the  ef0eb0c. Consequently, all issues identified in the  Consider merging all fixes from the v1.4.1-integration branch audit into the sb-short-term-fee-model branch of the era-contracts and era-system-contracts repositories.  Update: Resolved in pull request #160 at commit 4e1dfc7 and pull request #105 at commit d85d7d0.", "html_url": "https://blog.openzeppelin.com/short-term-fee-model-changes-audit#issues-discovered-in-v1.4.1-integration-diff-audit", "labels": ["OpenZeppelin"]}, {"title": "Outdated Version of OpenZeppelin Contracts Library Used", "body": "The short-term fee model upgrade involves updating the OpenZeppelin Contracts library from version 4.8.0 to 4.9.2. However, the latest version of the OpenZeppelin Contracts library is 4.9.5 which addresses several security issues.  While these security issues do not directly impact the current implementation of the contracts in scope, consider updating the library to the newest version.  Update: Resolved in pull request #128 at commit bf5905d.", "html_url": "https://blog.openzeppelin.com/short-term-fee-model-changes-audit#outdated-version-of-openzeppelin-contracts-library-used", "labels": ["OpenZeppelin"]}, {"title": "Missing Input Validation", "body": "changeFeeParams function, callable by the Governor, modifies the  parameters for deriving the gas price in L1-to-L2 transactions. To prevent potential system failure due to misconfiguration, it is recommended to  validate whether the provided value for  Consider validating the input values for maxPubDataPerBatch and priorityTxMaxPubdata to prevent misconfigurations.  Update: Resolved in pull request #129 at commit d59b22d.", "html_url": "https://blog.openzeppelin.com/short-term-fee-model-changes-audit#missing-input-validation", "labels": ["OpenZeppelin"]}, {"title": "Missing Tests", "body": "The proposed changes to the short-term fee model lack tests that could confirm the correctness of the implementation. The following areas require additional testing:  The changeFeeParams function of the Admin contract  The new short-term fee model changes added to the bootloader  Consider adding tests to enhance the quality and safety of the codebase.  Update: Resolved in pull request #95 at commit 80b1869, pull request #131 at commit 85a1b12.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/short-term-fee-model-changes-audit#missing-tests", "labels": ["OpenZeppelin"]}, {"title": "Base Fee Calculated Outside of Proved Batch", "body": "The logic of calling getFeeParams function and calculating the baseFee is implemented outside of the proved batch section. This leads to a scenario whereby the baseFee is calculated for the playground batch as well.  Consider moving the initialization of baseFee and the calling of getFeeParams to the proved batch section.  Update: Resolved in pull request #93 at commit 2546b0a.", "html_url": "https://blog.openzeppelin.com/short-term-fee-model-changes-audit#base-fee-calculated-outside-of-proved-batch", "labels": ["OpenZeppelin"]}, {"title": "Unused Code", "body": "Throughout the codebase, there are multiple instances of unused code:  The getBatchOverheadEth function of bootloader  The result of calculating txGasLimit  Consider removing all unused code to improve the readability and clarity of the codebase.  Update: Resolved in pull request #94 at commit fc9ba75.", "html_url": "https://blog.openzeppelin.com/short-term-fee-model-changes-audit#unused-code", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestions", "body": "In the Mailbox contract, the parameter _gasPricePerPubdata of the _deriveL2GasPrice function has a misleading name. Despite its current name, it does not represent a price in wei but rather a gas value per pubdata byte. The given name is rather unintuitive and makes the code harder to read.  Consider renaming the _gasPricePerPubdata parameter for improved readability.  Update: Resolved in pull request #130 at commit 9e45fb4.", "html_url": "https://blog.openzeppelin.com/short-term-fee-model-changes-audit#naming-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Throughout the codebase, there are several parts that do not have docstrings:  The Admin.sol, Executor.sol, Getters.sol, and Mailbox.sol contracts are missing docstrings for the getName constant.  The IAdmin.sol, IExecutor.sol, IGetters.sol, ILegacyGetters.sol, IMailbox.sol, IVerifier.sol, and IZkSync.sol interfaces are missing docstrings for multiple function declarations.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #127 at commit d4bd820.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "The getFirstUnprocessedPriorityTx Function Does Not Revert When There Are No Unprocessed Transactions", "body": "The getFirstUnprocessedPriorityTx function of the Getters contract is expected to return the first unprocessed priority transaction. In case there are no unprocessed priority transactions, the function should revert, as indicated in the NatSpec comment comment. The issue is that the function uses the PriorityQueue library, which simply returns the head of the queue and does not revert when there are no unprocessed priority transactions.  Consider reverting when there are no unprocessed priority transactions.  Update: Resolved in pull request #137 at commit ff8a9cd. The Matter Labs team stated:  We decide to keep the current behavior for the simplicity of the function. However, it does make sense to update the comment.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#the-getfirstunprocessedprioritytx-function-does-not-revert-when-there-are-no-unprocessed-transactions", "labels": ["OpenZeppelin"]}, {"title": "The Refund Recipient Might Be Aliased to an Unexpected Address", "body": "The Mailbox contract implements the requestL2Transaction function that allows communication from L1 to L2. It allows to specify a _refundRecipient address on L2 that will receive the refund after the transaction's completion. The function handles the following scenarios:  if _refundRecipient is a contract on L1, the refund will be sent to the aliased _refundRecipient.  If _refundRecipient is set to address(0) and the sender has not deployed bytecode on L1, the refund will be sent to the msg.sender address.  If _refundRecipient is set to address(0) and the sender has deployed bytecode on L1, the refund will be sent to the aliased msg.sender address.  checks if refundRecipient is a contract by comparing its code size with  applying L1 to L2 alias only in case it is a contract. In addition, at the beginning of the function,  msg.sender address is aliased in case it is a contract. This means that in case the sender is a smart contract and  Consider fixing the code so that the address aliasing is applied exactly once when needed. Even if the aliased addresses are not currently immediately used for claiming refunds, the current implementation returns unexpected results and could lead to serious bugs in future upgrades.  Update: Acknowledged, not resolved. We concluded that the problematic scenario is probabilistically impossible, so the issue is dismissed. The Matter Labs team stated:  In case the sender is a smart contract and the recipient is address(0), then we apply the alias to the sender. Additionally, in case the the refundRecipient is address(0), then the refund recipient would become equal to the aliased sender. Note that we will never get into the next if since the aliased sender can not contain any code because of collision resistance.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/november-diff-audit#the-refund-recipient-might-be-aliased-to-an-unexpected-address", "labels": ["OpenZeppelin"]}, {"title": "Todo Comments in the Code", "body": "During development, having well-described TODO/Fixme comments will make the process of tracking and solving them easier. Without such information, these comments might age and important information for the security of the system might be forgotten by the time it is released to production. These comments should be tracked in the project's issue backlog and resolved before the system deployment.  The identified instance of TODO/Fixme comments:  The TODO comment on line 151 in TransactionValidator.sol.  Consider removing all instances of TODO/Fixme comments and instead tracking them in the issues backlog. Alternatively, consider linking each inline TODO/Fixme comment to the corresponding issues backlog entry.  Update: Acknowledged, will resolve. The Matter Labs team stated:  This comment will be resolved in the future release.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#todo-comments-in-the-code", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Use of Named Returns", "body": "Throughout the codebase, there are multiple contracts that have inconsistent usage of named returns in their functions:  In ExecutorFacet contract of Executor.sol  In GettersFacet contract of Getters.sol  In MailboxFacet contract of Mailbox.sol  In IGetters interface of IGetters.sol  In IMailbox interface of IMailbox  To improve the readability and consistency of a contract, use the same return style in all of its functions. As such, consider naming the return variables of all functions.  Update: Acknowledged, not resolved. The Matter Labs team stated:  Especially for smaller functions, always using named returned variables will unnecessarily increase the amount of code so it is better to keep things as they are for readability.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#inconsistent-use-of-named-returns", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease the clarity of the code, and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity files or when inheritance chains are long.  Throughout the codebase, global imports are being used:  Lines 5-6 and line 8 in Admin.sol.  Lines 5-6 in Base.sol  Lines 5-10 in Getters.sol.  Line 5 in IAdmin.sol  Line 5 and line 7 in IGetters.sol  Line 5 in ILegacyGetters.sol  Line 6 in IMailbox.sol  Lines 5-8 in IZkSync.sol  Lines 5-8 in TransactionValidator.sol  Following the principle that clearer code is better code, consider using named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #126 at commit 5ae779e. The Matter Labs team stated:  This PR additionally creates some new implicit imports in other files, but those will be fixed in subsequent PRs (i.e. those files are in scope of other audits).", "html_url": "https://blog.openzeppelin.com/november-diff-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "Unused Function With Internal Visibility", "body": "The _maxU256 internal function of Executor.sol contract is not used.  To improve the overall clarity, intentionality, and readability of the codebase, consider using or removing any currently unused functions.  Update: Resolved in pull request #125 at commit 7e24b66.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#unused-function-with-internal-visibility", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "The following typographical errors were identified in the codebase:  The comment in TransactionValidator.sol should be dependencies not dependenies.  The comment in TransactionValidator.sol should be auxiliary not auxilary.  The comment in TransactionValidator.sol should be dependencies not dependenies.  The comment in Executor.sol should be noticeable not noticable.  The comment in Bootloader.yul should be maintenance not maintainance.  The comment in Bootloader.yul should be Scratch not Scatch  The comment in Bootloader.yul should be accommodate not accomodate  The comment in Bootloader.yul should be trigger not triger  The comment in Bootloader.yul should be Transferring not Transfering  The comment in Bootloader.yul should be exhausted not exhaused  The comment in ILegacyGetters.sol should be kept not keot.  The comment in Getters.sol should be blockchain not batchchain.  Consider fixing the aforementioned typographical errors to improve the readability and clarity of the codebase.  Update: Resolved in pull request #120 at commit fdd9006 and pull request #91 at commit cf955cc.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "The isFacetFreezable function Returns Value for Non-Existent Facets", "body": "The isFacetFreezable function of the Getters contract returns a boolean value (true or false) depending on whether the given facet is freezable or not. However, the current implementation logic defaults to returning false even for non-existent facets.  Instead of returning false, consider reverting in case the facet does not exist.  Update: Acknowledged, not resolved. The Matter Labs team stated:  The current interface subjectively looks easier to use and maintain. Besides, the function is generally rarely used. If someone is not sure whether a facet is a valid one, they could also request the facetFunctionSelectors() function.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#the-isfacetfreezable-function-returns-value-for-non-existent-facets", "labels": ["OpenZeppelin"]}, {"title": "Lack of Consistency in Error Messages", "body": "The Base contract, inherited by the facets, implements modifiers to handle access control for specific functions. The error messages in the require statements use codes, but for the onlyGovernorOrAdmin modifier, the full error message is used.  For the sake of clarity and consistency, consider using the error code for validation in the onlyGovernorOrAdmin modifier.  Update: Resolved in pull request #121 at commit 4051533.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#lack-of-consistency-in-error-messages", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact (such as an email or ENS name) within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in them, it becomes easier for the maintainers of those libraries to make contact with the appropriate person about the problem and provide mitigation instructions.  Throughout the codebase, there are contracts that do not have a security contact:  The IAdmin contract  The IExecutor contract  The IGetters contract  The ILegacyGetters contract  The IMailbox contract  The IVerifier contract  The IZkSync contract  Consider adding a NatSpec comment containing a security contact above the contract definition. Using the @custom:security-contact convention is recommended as it has been adopted by the OpenZeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #122 at commit c969649.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Unused Imports", "body": "The following unused imports were identified throughout the codebase:  In Executor.sol, the constants MAX_INITIAL_STORAGE_CHANGES_COMMITMENT_BYTES and MAX_REPEATED_STORAGE_CHANGES_COMMITMENT_BYTES imported from Config.sol are unused.  In Executor.sol, the constant L2_KNOWN_CODE_STORAGE_SYSTEM_CONTRACT_ADDR imported from L2ContractAddresses.sol is unused.  Consider removing unused imports to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #123 at commit 3f2f947.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#unused-imports", "labels": ["OpenZeppelin"]}, {"title": "Incorrect or Misleading Docstrings", "body": "The following instances of incorrect or misleading docstrings were identified throughout the codebase:  In the publishPubdataAndClearState function of the L1Messenger contract, the docstring explaining the expected encoding of the state diffs in the _totalL2ToL1PubdataAndStateDiffs parameter is partially incorrect. The docstring describes the encoding as:  whereas, in fact, it is:  At Line 81 of Mailbox.sol, key is documented as being the hash of L1ToL2Transaction whereas it is the hash of the L2 transaction.  Consider fixing all instances of incorrect or misleading documentation to enhance the overall clarity and readability of the codebase.  Update: Partially resolved in pull request #92 at commit 66481dd. The Matter Labs team stated:  The first issue is acknowledged, but the second one is disagreed with, since this function is intended to be used specifically for L1->L2 transaction and not just any L2 transaction.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#incorrect-or-misleading-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Use of override Keyword", "body": "Throughout the codebase, several functions have the override keyword in their signature as they are being implemented from an interface. However, in the most current versions of the Solidity compiler, the override keyword is not necessary for interface implementation.  Specifically:  The commitBatches function of the Executor contract  The proveL1ToL2TransactionStatus and finalizeEthWithdrawal functions of the Mailbox contract  Consider removing the redundant override keywords to simplify and be consistent with the rest of the codebase.  Update: Resolved in pull request #124 at commit 03c579f.", "html_url": "https://blog.openzeppelin.com/november-diff-audit#inconsistent-use-of-override-keyword", "labels": ["OpenZeppelin"]}, {"title": "Precompile Keccak256 Contract Is Missing Constructor Code", "body": "The Keccak256 contract defined in the Keccak256.yul file is missing the constructor definition, whereas all other precompile contracts have it.  Consider adding constructor code to the Keccak256 contract to improve its readability and clarity.  Update: Resolved in pull request #57 at commit bd52d32.", "html_url": "https://blog.openzeppelin.com/zksync-keccak256-upgrade-audit#precompile-keccak256-contract-is-missing-constructor-code", "labels": ["OpenZeppelin"]}, {"title": "Missing Tests", "body": "The upgrade to the new version of keccak256 lacks several tests that could significantly enhance the quality of the codebase. Consider adding the following tests to ensure the correctness of the upgrade process:  A test for the upgrade process using the new version of keccak256. The current upgrade process does not test transitioning from one keccak256 version to another. Instead, it acquires the current keccak256 version, changes it to a reverting contract, and then changes it back to the current version.  A keccak256 unit test to verify the correctness of generated hashes. Consider implementing fuzz testing for this purpose.  Update: Resolved in pull request #58 at commit a4dc0d9.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/zksync-keccak256-upgrade-audit#missing-tests", "labels": ["OpenZeppelin"]}, {"title": "Missing Comments", "body": "The comment on lines 233 and 234 suggests that the forceDeployKeccak256 function is temporarily needed to upgrade the Keccak256 precompiled contract, and is to be removed in the future.  In the future, if forceDeployKeccak256 is removed, its interdependent counterpart upgradeKeccakIfNeeded function should also be removed. However, the documentation for the upgradeKeccakIfNeeded function does not mention that this is temporarily needed and should be removed when the upgrade process is no longer needed.  Consider adding a comment to the upgradeKeccakIfNeeded function, pointing out that it should be removed once the upgrade process is complete. Furthermore, ensure that the documentation for both mentioned functions includes a note specifying that their interdependent counterpart function should also be removed.  Update: Resolved in pull request #60 at commit 40d31d5.", "html_url": "https://blog.openzeppelin.com/zksync-keccak256-upgrade-audit#missing-comments", "labels": ["OpenZeppelin"]}, {"title": "Magic Numbers Documentation", "body": "The Keccak256.yul contract defines two magic hardcoded numbers, but there is a lack of proper documentation regarding how they were derived.  BLOCK_SIZE function returns a value of 136, which is expected to be the size of the processing  The KECCAK_ROUND_GAS_COST function returns a value of 40, which is expected to be the gas cost of processing one keccak256 round. Yet there is no explanation of how this value is computed.  Consider including explanations in the comments as to how the values $136$ and $40$ were derived.  Update: Resolved in pull request #61 at commit a90e2c0.", "html_url": "https://blog.openzeppelin.com/zksync-keccak256-upgrade-audit#magic-numbers-documentation", "labels": ["OpenZeppelin"]}, {"title": "Function Order of Contract Addresses", "body": "The ordering of functions that return contract addresses in bootloader.yul is not currently done based on the address value. This lack of proper ordering may lead to errors and issues when new contract addresses need to be added.  Consider reordering these functions according to the address they return for better organization and reliability.  Update: Resolved in pull request #62 at commit d6c93ed.", "html_url": "https://blog.openzeppelin.com/zksync-keccak256-upgrade-audit#function-order-of-contract-addresses", "labels": ["OpenZeppelin"]}, {"title": "Gas Is Not Charged for Hashing Empty Data", "body": "The proposed implementation of the keccak256 precompile calculates the amount of gas to be charged for hashing. This calculation is based on the number of keccak256 rounds required to process the given data, multiplied by the hardcoded cost of gas for a single round. The number of rounds is determined by performing a ceiling division on the data length with BLOCK_SIZE as the denominator.  This approach results in an issue: if empty data is hashed, the calculation yields a numRounds value of 0. While this is technically accurate because no rounds of hashing are executed, there is still some processing involved in returning the keccak256 hash for empty input data.  Consider charging gas for cases where empty data is being hashed.  Update: Resolved in pull request #63 at commit 4f1b6c6.", "html_url": "https://blog.openzeppelin.com/zksync-keccak256-upgrade-audit#gas-is-not-charged-for-hashing-empty-data", "labels": ["OpenZeppelin"]}, {"title": "Lack of Data Availability of Bytecode", "body": "For rollups, it is crucial to have data availability on the L1 chain. In a ZK-rollup, the validity proof ensures that the L2 sequencer cannot create invalid transactions. However, if the sequencer were to go down or become malicious, having only the proof itself would be insufficient for another node to reconstruct the state on L2. In addition, data availability of bytecode is essential to ensure that not only the state on L2 is able to be reconstructed, but also that the deployed contracts will maintain integrity should the L2 sequencer go down. Furthermore, in the current design with a centralized sequencer, this plays an even more important role as there is a single point of failure.  In the design of the protocol, transactions on L2 can originate from L1 or L2. If a message starts from L1, it is not necessary to resend the bytecode back down to L1, as the bytecode is already available on that layer. However, if a transaction starts on L2 and deploys a new contract, the bytecode must be sent to L1 to ensure data availability.  processL2Tx function. Stepping into this function eventually leads to a call to  publishCompressedBytecode in Compressor. After verifying that the original bytecode and the compressed version of the bytecode match, the function  markBytecodeAsPublished is called in KnownCodesStorage. This makes a call to  requestBytecodeL1Publication will be skipped and the bytecode will not be sent to L1.  For transactions that originate on L2, consider making the bytecode available on L1 to ensure data availability.  Update: Resolved in pull request #332 at commit 801b2a2. The raw compressed data is now sent to L1 in the publishCompressedBytecode function.  Medium Severity", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#lack-of-data-availability-of-bytecode", "labels": ["OpenZeppelin"]}, {"title": "Gas Charged Twice for Sending Message to L1", "body": "sendToL1 function of the  L1Messenger contract deployed on L2 facilitates the direct transmission of messages to L1. To execute this operation successfully and publish data, it requires the user to provide gas. However, the  calculated amount of gas is charged twice. Initially, gas is consumed through the  SystemContractHelper library, utilizing the  burnGas function, and subsequently, another gas charge occurs through a direct  call to the precompile at address 0.  Consider eliminating the direct call to the precompile address and charging gas only once by using the burnGas function provided in the SystemContractHelper library.  Update: Resolved in pull request #331 at commit b351f13. The redundant precompile call was removed and the gas is charged once through the burnGas function of the SystemContractHelper library.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#gas-charged-twice-for-sending-message-to-l1", "labels": ["OpenZeppelin"]}, {"title": "Naming Error", "body": "Within the bootloader.yul code, two instances referencing non-existent variables and functions were identified. Compiling the code will lead to a compilation error, as the referred variable and function names lack definitions:  The unknown variable SHOULD_SET_NEW_BLOCK is used for the switch statement. The correct name of the variable is SHOULD_SET_NEW_BATCH, which is defined in the statement above the switch block.  The unknown function MAX_PUBDATA_PER_BLOCK is called. The correct name of the defined function is MAX_PUBDATA_PER_BATCH.  Consider implementing these changes in the aforementioned instances to ensure that the correct variables and functions are referenced.  Update: Resolved in pull request #330 at commit 0027afa.  Low Severity", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#naming-error", "labels": ["OpenZeppelin"]}, {"title": "Missing Error Messages in require Statements", "body": "The unsafePrecompileCall and precompileCall functions of the SystemContractHelper contract use require statements that lack descriptive error messages. This can make debugging difficult if the affected functions revert.  These are the dentified instances:  The require statement on line 151 of SystemContractHelper.sol  The require statement on line 167 of SystemContractHelper.sol  Consider including specific, informative error messages in require statements to improve the overall clarity of the codebase and facilitate troubleshooting whenever a requirement is not satisfied.  Update: Resolved in pull request #333 at commit 2deaa57. The functions that utilized require statements without error messages have been deleted.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#missing-error-messages-in-require-statements", "labels": ["OpenZeppelin"]}, {"title": "Use of Magic Numbers", "body": "Magic numbers are used throughout the codebase. This practice is generally discouraged in software development as it can lead to issues when refactoring code, particularly if the magic value is used in more than one location. These are some examples where magic values are used in the codebase:  In line 93 of Compressor.sol, the right-hand side uses the magic numbers 4 and 64. Consider replacing 4 with compInitialStateDiffPtr and 64 with a constant that represents the size of the initial write, such as SIZE_OF_INITIAL_WRITE.  In line 114 of Compressor.sol, the same magic values of 4 and 64 are used.  Consider updating these magic numbers with a constant that represents their value and storing that constant in the Constants.sol file so that any updates only need to take place in one location in the codebase.  Update: Resolved in pull request #334 at commit f681c23.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#use-of-magic-numbers", "labels": ["OpenZeppelin"]}, {"title": "Misleading Comment", "body": "In line 484 of Executor.sol, it says \"Returns if the bit at index {_index} is 1\". It should instead say \"Returns true if the bit at index {_index} is 1\".  Consider resolving this instance of misleading documentation to improve the clarity and readability of the codebase.  Update: Resolved in pull request #219 at commit 59fd7f2.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#misleading-comment", "labels": ["OpenZeppelin"]}, {"title": "Improper Hash Value for Unused Leaves in Merkle Tree", "body": "The leaves of the Merkle tree that are not used by the L2 logs are set to the default value L2_L1_LOGS_TREE_DEFAULT_LEAF_HASH, which is equal to the hash of the all-zero byte string keccak256(new bytes(L2_TO_L1_LOG_SERIALIZE_SIZE)). It is best practice not to set a default hash to a value where the preimage is known. While a malicious bootloader cannot prepare an array of logs each having a hash equal to L2_L1_LOGS_TREE_DEFAULT_LEAF_HASH (i.e., the preimage of each hash is the all-zero byte string) and have it emitted due to other safeguards in the system contracts, it is still discouraged to use this value, as future upgrades to the codebase could potentially impact these safeguards.  Instead of L2_L1_LOGS_TREE_DEFAULT_LEAF_HASH, consider using L2_L1_LOGS_TREE_DEFAULT_LEAF_HASH - 1 for the value of the unused leaves. This value would most likely have an unknown preimage, which would further protect against a malicious operator should the codebase be changed.  Update: Resolved in pull request #341 at commit c405437.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#improper-hash-value-for-unused-leaves-in-merkle-tree", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "The use of non-explicit imports in the codebase can decrease the clarity of the code and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity files or when inheritance chains are long. The following instances were identified:  In zksync-2-contracts:  Line 5 to Line 9 of DiamondInit.sol  Line 5 of DiamondProxy.sol  Line 5 to Line 12 of Executor.sol  Line 5 to Line 15 and Line 17 to Line 18 of Mailbox.sol  Line 5 of IExecutor.sol  In system-contracts:  Line 5 of ComplexUpgrader.sol  Line 5 to Line 9 of Compressor.sol  Line 5 to Line 15 of Constants.sol  Line 6, Line 9 to Line 10 and Line 12 in ContractDeployer.sol  Line 5 to Line 8 of KnownCodesStorage.sol  Line 5 to Line 8 of L1Messenger.sol  Line 7 of SystemContractHelper.sol  Following the principle that clearer code is better code, consider using named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #220 at commit 3db8f16 and pull request #335 at commit b2d76b7.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "State Variable Visibility Not Explicitly Declared", "body": "Throughout the protocol, the visibility of state variables is explicitly declared, but within the L2EthToken.sol contract, the state variable balance is missing such a declaration.  For clarity, consider always explicitly declaring the visibility of variables, even when the default visibility matches the intended visibility.  Update: Resolved in pull request #336 at commit 032c88a.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#state-variable-visibility-not-explicitly-declared", "labels": ["OpenZeppelin"]}, {"title": "Using uint Instead of uint256", "body": "Throughout the protocol, the type uint256 is used, with the exception of the L1Messenger.sol contract where uint is used instead.  To improve the codebase's quality and in favor of explicitness, consider replacing all instances of int/uint with int256/uint256.  Update: Resolved in pull request #337 at commit 0b29a6a.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#using-uint-instead-of-uint256", "labels": ["OpenZeppelin"]}, {"title": "Naming Suggestions", "body": "To favor explicitness and readability, the following locations in the contracts may benefit from better naming:  The enum SystemLogKey in IExecutor.sol and in Constants.sol has a value named EXPECTED_SYSTEM_CONTRACT_UPGRADE_TX_HASH. Consider renaming this to EXPECTED_SYSTEM_CONTRACT_UPGRADE_TX_HASH_KEY to be consistent with the other values in the enum.  The enum SystemLogKey in Constants.sol has a value PREV_BATCH_HASH_KEY. Consider renaming this to PREV_BLOCK_HASH_KEY to be more aligned with its intention and to be consistent with the value in IExecutor.sol  The function _setBit in Executor.sol takes in a parameter named _num, which represents a bitmap. Consider renaming this to _bitMap to provide more clarity on the purpose of this parameter.  The function publishPubdataAndClearState has a local variable named compressedRepeatedStateDiffs. Consider renaming this to compressedStateDiffs, as this variable stores both the repeated and initial state diffs.  Consider implementing these naming modifications to improve the consistency and readability of the codebase.  Update: Resolved in pull request #221 at commit f9f39bc and pull request #338 at commit 07647f8.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#naming-suggestions", "labels": ["OpenZeppelin"]}, {"title": "Lack of Security Contact", "body": "Providing a specific security contact, such as an email or ENS, within a smart contract significantly simplifies the process for individuals to communicate if they identify a vulnerability in the code. This practice proves beneficial as it permits the code owners to dictate the communication channel for vulnerability disclosure, eliminating the risk of miscommunication or failure to report due to a lack of knowledge on how to do so. Additionally, if the contract incorporates third-party libraries and a bug surfaces in these, it becomes easier for the creators of those libraries to make contact, inform the code owners about the problem, and provide mitigation instructions.  Consider adding a NatSpec comment on top of the contracts' definition with a security contact. Using the @custom:security-contact convention is recommended as it has been adopted by the Openzeppelin Wizard and the ethereum-lists.  Update: Resolved in pull request #223 at commit 2fc13dd and pull request #342 at commit a60dbae.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#lack-of-security-contact", "labels": ["OpenZeppelin"]}, {"title": "Inconsistency Between Decimal and Hex Representation", "body": "bootloader.yul, there are instances where the  line 846,  line 869 and  line 1094. Some examples of the hexadecimal representation (  line 561,  line 673 and  line 688.  Consider using a single representation throughout the implementation for consistency and readability.  Update: Resolved in pull request #339 at commit 7b97e4d.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#inconsistency-between-decimal-and-hex-representation", "labels": ["OpenZeppelin"]}, {"title": "Unused Imports", "body": "Throughout the protocol, there are imports that are unused and could be removed.  In zksync-2-contracts:  Import L2ContractHelper of Executor.sol  Import L2_KNOWN_CODE_STORAGE_SYSTEM_CONTRACT_ADDR of Executor.sol  Import L2_BYTECODE_COMPRESSOR_SYSTEM_CONTRACT_ADDR of Executor.sol  In system-contracts:  Import BOOTLOADER_FORMAL_ADDRESS of KnownCodesStorage.sol  Import SystemContractHelper of L2EthToken.sol  Import MSG_VALUE_SYSTEM_CONTRACT of SystemContractHelper  Consider removing unused imports to improve the overall clarity and readability of the codebase.  Update: Resolved in pull request #222 at commit 061de34 and pull request #340 at commit 4e51af8.", "html_url": "https://blog.openzeppelin.com/zksync-l1messenger-upgrade-audit#unused-imports", "labels": ["OpenZeppelin"]}, {"title": "Constant Block Difficulty Breaks EVM Equivalence", "body": "The SystemContext system contract is used to maintain context information that can be accessed from contract code. One of these values is the block difficulty, which is hard-coded to 25 * 1015.  This breaks EVM equivalence where block.difficulty is defined as the previous RANDAO value of the consensus layer as per the EIP-4399 specification. This can result in unexpected contract misbehavior which utilizes block difficulty as a weak source of randomness. For instance, in a na\u00efve casino dApp this could lead to one-sided odds and hence a loss of funds.  Note that since Solidity version 0.8.18, block.difficulty is considered deprecated in favor of block.prevrandao.  Consider conforming to the EIP-4399 properties of block.difficulty / block.prevrandao to match the EVM's behavior.  Update: Acknowledged, not resolved. The Matter Labs team stated:  Due to the difficulty of the implementation of the fix, it was postponed to one of the future milestones. Note that the discrepancy is common among L2s and has been documented on the Differences from Ethereum page.  Low Severity", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#constant-block-difficulty-breaks-evm-equivalence", "labels": ["OpenZeppelin"]}, {"title": "Misleading Documentation", "body": "Some of the comments communicate incorrect or misleading information. For instance:  In the bootloader, the TX_OPERATOR_L2_BLOCK_INFO_SLOTS constant description says \"Note, that an additional slot is required for the fictive block at the end of the block\" while it should say \"[...] fictive block at the end of the batch\".  The reasoning for the fictive block to exist on lines 638-639 can be more detailed.  The comment on lines 1923-1924 is wrong considering the respective code is commented-out.  The condition in SystemContext on line 294 mismatches the message string and comment: The condition checks \"greater than or equal to\" while the message string and comment say \"greater than\".  The publicBatchDataToL1 function debug logs state that block data is published to L1, although it is referring to batch data.  The comment and variables of the getBatchNumberAndTimestamp function refer to block data, although batch is meant.  The docstrings on lines 297-304 mention block in several places, but it should be batch.  Consider changing the comments to reflect the intention of the code.  Update: Resolved in pull request #304 at commit 3d9a4fa.", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#misleading-documentation", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "Within the scope, there are two instances where docstrings are missing:  The _previousBlockTimestamp parameter is not documented for the _verifyBlockTimestamp function.  The _baseFee parameter is not documented for the setNewBatch function.  Consider thoroughly documenting all functions (and their parameters) that are part of any contract's public API. Functions implementing sensitive functionality, even if not public, should be clearly documented as well. When writing docstrings, consider following the Ethereum Natural Specification Format (NatSpec).  Update: Resolved in pull request #305 at commit 19c5200 and pull request #197 at commit dc82a21.", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Missing Error Message in require Statement", "body": "Within SystemContext.sol, there is a require statement on line 17 that lacks an error message.  Consider including specific, informative error messages in require statements to improve overall code clarity and facilitate troubleshooting whenever a requirement is not satisfied.  Update: Resolved in pull request #306 at commit d44a675.", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#missing-error-message-in-require-statement", "labels": ["OpenZeppelin"]}, {"title": "Misleading Variable Naming", "body": "Throughout the codebase, variable naming related to \"batch\" and \"block\" terminology is mixed together. For instance:  In SystemContext on lines 103-107  In Executor on line 84  In Bootloader on line 141, line 166, line 409, line 3334, and line 3414  Consider consolidating terminology in all instances where \"block\" refers to \"batch\".  Update: Resolved in pull request #307 at commit daa4020 and pull request #198 at commit c4efbe7.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#misleading-variable-naming", "labels": ["OpenZeppelin"]}, {"title": "Non-Explicit Imports Are Used", "body": "Within Executor.sol, global imports are being used. The use of non-explicit imports in the codebase can decrease the clarity of the code and may create naming conflicts between locally defined and imported variables. This is particularly relevant when multiple contracts exist within the same Solidity files or when inheritance chains are long.  Following the principle that clearer code is better code, consider using named import syntax (import {A, B, C} from \"X\") to explicitly declare which contracts are being imported.  Update: Resolved in pull request #199 at commit 154ce74.", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#non-explicit-imports-are-used", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "Throughout the scope, the following typographical errors were found:  \"Transfering\" should be \"Transferring\"  \"For the support of coinbase, we will the bootloader formal address for now\" should be \"[...] we will use [...]\".  \"Just like the blockhash in the EVM, it returns bytes32(0), when when queried about hashes that are older than 256 blocks ago.\" should have one less \"when\".  \"timestampts\" should be \"timestamps\".  Consider fixing the above errors to improve the clarity and readability of the codebase.  Update: Resolved in pull request #308 at commit e0f6798 and pull request #200 at commit 7f7b6c6.", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Gas Optimizations", "body": "In the Executor facet, the following instances of gas optimization were identified:  A bitwise \"right-shift\" operation (>>) is cheaper than a division with a power of two.  A bitwise \"and\" operation (&) is cheaper than a modulo with a power of two.  Consider changing to these bitwise operations to save gas.  Update: Resolved in pull request #201 at commit bbaa2f0.", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#gas-optimizations", "labels": ["OpenZeppelin"]}, {"title": "Recommendations", "body": "Recommendations", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#recommendations", "labels": ["OpenZeppelin"]}, {"title": "Usage of Block Number and Difficulty", "body": "The NUMBER or 0x43 opcode returns the current block number on Ethereum and zkSync Era. While on Ethereum blocks are produced every 12 seconds, on zkSync Era L2 blocks are produced every 1-2 seconds. However, on zkSync Era the operator controls the frequency of L2 blocks and, hence, can manipulate the block timestamp and block number. Thus, smart contracts that rely on the block number for calculations (e.g., interest rate) are exposed to unexpected behavior considering the Ethereum difference and influence through the operator.  Another peculiarity is related to the PREVRANDAO, DIFFICULTY, or 0x44 opcode which is set to a constant value on zkSync Era but on Ethereum, it gives a pseudo-random value. This might influence applications that rely on this opcode to behave unexpectedly.  Consider adding compile-time warnings or errors when the NUMBER and PREVRANDAO opcodes are used and thoroughly outlining their peculiarities in the documentation to help smart contract developers understand the differences and avoid making false assumptions.", "html_url": "https://blog.openzeppelin.com/zksync-l2-block-refactor-audit#usage-of-block-number-and-difficulty", "labels": ["OpenZeppelin"]}, {"title": "Not Setting L2 Upgrade Block Number Prevents Future Upgrades", "body": "The L2 block at which the L2 update occurs is not properly recorded in l2SystemContractsUpgradeBlockNumber. Consequently, when it is validated during subsequent upgrades, it fails, causing the upgrade to revert. Moreover, this code section, intended to handle blocks that have been previously reverted, becomes unreachable. Lastly, since l2SystemContractsUpgradeTxHash is never reset, the optimized code path for the case when there is no active upgrade also becomes unreachable after any upgrade.  _setL2SystemContractUpgrade. This process will ensure that only one upgrade is active at a time and that these values are reset when an upgrade is finalized.  We also recommend enforcing proper test coverage. For this case, consider adding tests that exercise all possible control flow branches (e.g., if statements, and require checks), and validate relevant views and events. Specifically, add scenarios involving multiple subsequent upgrades, their finalization scenarios including possible reverted blocks, and variation in the upgraded functionality (e.g., with or without an L2 update, with or without a verifier update, etc.). Generally, consider enabling the generation of test coverage reports and implementing a policy to flag pull requests with a branch test coverage of less than 95%.  Medium Severity", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#not-setting-l2-upgrade-block-number-prevents-future-upgrades", "labels": ["OpenZeppelin"]}, {"title": "Insufficient Validation of L2 Upgrade Transaction", "body": "While standard L1->L2 transactions undergo comprehensive validation logic (1, 2) in the Mailbox facet, L2 upgrade transactions  though similarly executed  are subject to minimal validation during the upgrade process. Although such transactions are assumed to be vetted off-chain by governor owners, the absence of thorough on-chain validation is error-prone and could have severe consequences on L2. Furthermore, remediation complexity is exacerbated as upgrade transactions cannot be overridden - they must be finalized.  Potential issues include minting of L2 ETH not provided in the L1 transaction, which could result in mismatched L1 and L2 ETH balances and potential L2 ETH devaluation. Another potential issue is the submission of a transaction that would be unprovable on L1 or unexecutable on L2.  Existing checks on standard L1-to-L2 transactions include:  Sender assignment to msg.sender, with aliasing if it's a contract.  Ensuring l2Value does not exceed msg.value or provided transaction gas costs.  Confirmation that valueToMint matches msg.value.  Setting the refund recipient.  Verifying expected gas costs to be within acceptable thresholds, ensuring the ability to prove and process.  Consider adding validation checks to confine upgrade transactions within a narrowly defined set of intended actions. Specifically, consider limiting the addresses the upgrade can impersonate (e.g., only the forced deployer system contract), prohibiting ETH minting or value transfers, and enforcing sensible gas limits and costs.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#insufficient-validation-of-l2-upgrade-transaction", "labels": ["OpenZeppelin"]}, {"title": "L2 Upgrade Timing Will Precede L1 Upgrade", "body": "The L2 upgrade is enforced on L1 during the block commitment phase in the first committed block when the transaction is set. However, due to block commitment delays, the L2 upgrade can have a retroactive effect preceding the L1 upgrade, as recorded by the block timestamps.  One of the primary objectives of the upgrade mechanism is to enforce delayed upgrades, as validated for the L1 part of the upgrade. Therefore, it's reasonable to expect the L2 upgrade not to be implemented earlier than the scheduled upgradeTimestamp.  Moreover, a malicious operator has the ability to postpone new block postings on L1 within the permitted commit delays. This capacity enables the operator to retroactively apply an L2 upgrade considerably earlier than the L1 upgrade and provides them with the power to select the L2 transactions to include before and after the L2 upgrade.  Enforcing a strict lack of \"back-dating\" may be complex due to the need to avoid committing to blocks created with a previous bootloader or account code if these parameters were changed. However, enforcing a minimal tolerance of, for instance, several minutes, should balance complexity with safety.  Consider enforcing that the L2 upgrade block should have an L2 timestamp not preceding the planned upgradeTimestamp by more than a few minutes. Choosing the block based on the L2 timestamp will not only address the timing issue but will also simplify block selection in cases where an operator has reverted any blocks.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#l2-upgrade-timing-will-precede-l1-upgrade", "labels": ["OpenZeppelin"]}, {"title": "Reverted L2 Upgrade Block Forces Recommitment of Preceding Blocks with Incorrect Values", "body": "An L2 upgrade block that has been reverted may prompt the recommitment of the blocks preceding the upgrade. Given that the block height is enforced based on the previously recorded l2SystemContractsUpgradeBlockNumber (prior to being reverted), a problem arises if the L1 upgrade updates either the l2BootloaderBytecodeHash or l2DefaultAccountBytecodeHash. In this case, the blocks preceding the L2 upgrade will be recommitted with the updated values (from contract storage), effectively placing the L2 upgrade before the block in which the L2 upgrade transaction is included.  This situation implies that the L2 upgrade won't be atomic, with the bootloader or default account code being updated an arbitrary number of blocks before the L2 upgrade transaction. Furthermore, this could result in an unprovable or inconsistent state if the upgrade transaction is the one that updates the default account contract code.  Consider avoiding the \"replay\" of the upgrade at the previously recorded block height, and instead ensure that the l2SystemContractsUpgradeBlockNumber is reset if that block is reverted during revertBlocks. Also, ensure that l2SystemContractsUpgradeBlockNumber is always zero at the start of _commitBlocksWithSystemContractsUpgrade to prevent concurrent upgrades or inconsistent upgrade states.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#reverted-l2-upgrade-block-forces-recommitment-of-preceding-blocks-with-incorrect-values", "labels": ["OpenZeppelin"]}, {"title": "Inadequate Test Coverage", "body": "There are significant gaps in the testing for the current changes. As generating a coverage report is not currently supported, the process of finding these coverage gaps has been manual and potentially error-prone. Consequently, the following list of gaps may not be exhaustive.  Within the scope of L1 contracts:  Some require statements (e.g., 1, 2, 3, 4) are not tested.  Some view functions and the corresponding state variables (e.g., 1, 2) are not tested.  Some scenarios, such as reverting blocks and sequential upgrades, are not tested.  Some events, including most of the upgrade events are not tested.  Within the scope of system-contracts, there are very few tests in the repository and no test files updated for this code change.  Within the scope of L2 contracts, there are no tests (and no test updates).  Consider implementing automated measurement of test coverage to ensure 95%-100% branch coverage for all repositories. Crucially, consider ensuring that all code changes that are in the scope of an audit have full branch coverage.  Low Severity", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#inadequate-test-coverage", "labels": ["OpenZeppelin"]}, {"title": "Lack of Handling for Unrecognized L2 Logs Senders", "body": "Logs within the L2 system are processed based on their sender's address in the Executor. However, a potential issue arises if an unrecognized sender requires action or should be rejected. There is also a future risk that the code may need to be updated for new sender scenarios, but without a final else block, the necessary action may be overlooked.  Consider including an else block that automatically reverts transactions to ensure comprehensive handling both now and in future scenarios. If you anticipate adding more senders that should default to a no action (no-op), consider including in the explicit else block detailed comments explaining the expected behavior.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#lack-of-handling-for-unrecognized-l2-logs-senders", "labels": ["OpenZeppelin"]}, {"title": "ComplexUpgrader Does Not Revert on delegatecall to an EOA", "body": "If the delegatecall target is not a contract, the delegatecall will not revert due to the default account possessing a non-reverting, empty fallback function. The upgrade transaction would not have the intended effect, but it will still appear to have been successfully executed.  Consider reverting whenever the code size of the target is zero. This is consistent with the existing diamond behavior on layer 1 and standard practice in the ecosystem.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#complexupgrader-does-not-revert-on-delegatecall-to-an-eoa", "labels": ["OpenZeppelin"]}, {"title": "Missing Docstrings", "body": "There are several functions that do not have docstrings. Here is a non-exhaustive list:  The upgrade function of ComplexUpgrader  The create2 function of L2ContractHelper  The getL2SystemContractsUpgradeTxHash and getL2SystemContractsUpgradeBlockNumber functions of the Getters contract  Consider thoroughly documenting all functions as well as their parameters.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#missing-docstrings", "labels": ["OpenZeppelin"]}, {"title": "Inconsistent Verifier", "body": "If the verifier is upgraded, it will immediately be used to prove all committed blocks, including ones that were committed before the upgrade. This could lead to an inconsistency where the blocks cannot be proven. To minimize disruption, the verifier should only be changed when all committed blocks are finalized.  Consider enforcing this property at upgrade time. Additionally, consider documenting this requirement in the function comments and any relevant upgrade infrastructure.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#inconsistent-verifier", "labels": ["OpenZeppelin"]}, {"title": "Missing or Misleading Documentation", "body": "There are several instances of missing or misleading documentation:  The customUpgradeCalldata comment uses the wrong parameter name.  The executeUpgradeTx comment references a non-existent parameter, which is also referenced by the l2ProtocolUpgradeTx comment.  The AppStorage comment only mentions one of three deprecated parameters.  The NewVerifierParams comment incorrectly references the verifier address.  The _setL2SystemContractUpgrade function is missing its @return parameter.  Consider updating the parameters accordingly.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#missing-or-misleading-documentation", "labels": ["OpenZeppelin"]}, {"title": "Missing Post-update Hook", "body": "The DefaultUpgrade contract contains a hook that can be used to perform arbitrary operations during the upgrade. However, it is executed after setting the protocol and before all other updates. This limits its ability to perform any post-update configuration, which is the typical use case. Consider executing the function after the rest of the updates, or introducing a new post-update hook.  Notes & Additional Information", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#missing-post-update-hook", "labels": ["OpenZeppelin"]}, {"title": "Typographical Errors", "body": "Consider addressing the following typographical errors:  \"mosst\" \u2192 \"most\"  \"the only difference are\" \u2192 \"the only differences are\"  \"a mapping from facet address to its selector\" \u2192 \"a mapping from facet address to its selectors\"", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#typographical-errors", "labels": ["OpenZeppelin"]}, {"title": "Duplicate Import", "body": "There is a duplicated import of Storage in the IGetters.sol contract.  Consider removing it and updating the explicit import to include all necessary structures.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#duplicate-import", "labels": ["OpenZeppelin"]}, {"title": "Multiple Contracts With Same Name", "body": "There are two different contracts that have the same name, yet different responsibilities:  The DefaultUpgrader which serves as a template for L1 Diamond upgrades.  The DefaultUpgrader which implements force deployment of L2 system contracts.  Consider renaming them to avoid unexpected behavior and improve the overall clarity and readability of the codebase.", "html_url": "https://blog.openzeppelin.com/zksync-upgrade-system-audit#multiple-contracts-with-same-name", "labels": ["OpenZeppelin"]}]