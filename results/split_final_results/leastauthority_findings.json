[{"title": "Issue A: Missing Grouping for an Operation With Lower Precedence", "body": "  Location  src/utils/baseTXBurnedAmount.ts#L8  Synopsis  The - operator has a higher priority than the ?? operator. Consequently, agg[assetId] will be set to NaN when outAmount[assetId] is undefined.  Impact  Users may calculate the burned amount using the baseTxBurnedAmount function. If an asset is burnt completely in a transaction, an output amount would not be generated for the asset. In this case, the user receives NaN instead of the exact burned amount, which can lead to unexpected results.  Remediation  We recommend grouping operations with lower precedence, as follows:  agg[assetId] = amt - (outAmount[assetId] ?? 0n);  Status  The Ava Labs team has deleted src/utils/baseTXBurnedAmount.ts, as it is currently not being used.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/least-authority-ava-labs-avalanchejs-v2-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Clarify Generation of Poseidon ARC Round Constants", "body": "   Location   poseidon.c#L17-L1298   /pasta_params.sage   Synopsis   The way in which the Poseidon hash round constants were generated is currently unclear. As such, we  must assume that the numbers may have been chosen in a way such that they have properties that open  up a security vulnerability that is only exploitable by the party generating the numbers. A  script  to generate  the parameters was found, however, it returns different numbers from those used in the code. Instead,  nothing-up-my-sleeve numbers should be used.    Security Audit Report | Mina Ledger Application | O(1) Labs 5 February 2021 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.          Impact   It may be possible for the Mina team to find hash collisions or second preimages in a reasonable amount  of time. Since the hashes are used in a signature scheme, breaking the hash function may allow forging  signatures.    Preconditions   In order for the attack to be possible, the numbers must have been chosen in a particular way. There is no  evidence that this is the case, but there is also no evidence that it is not.   Feasibility   The attacker would need significant knowledge of the Poseidon hash function and the mathematics  behind it. The amount of computational complexity required for the attack is unclear to our team.   Technical Details   Poseidon is a SNARK-friendly hash function. It executes in multiple rounds and in each round it performs  computations based on a set of constants. These should be close to random. However, it should also be  verifiable that these numbers have not been chosen to undermine the security of the algorithm. This is  usually done by generating the numbers using hashes or pseudorandom functions, based on short strings  that describe the use, and do not provide room for the party generating the constants to introduce bias.   While we did find a script in another repository of Mina, we have not been able to verify that the numbers  match.    Remediation   If the numbers are already generated in a verifiable manner, this should be clearly documented and made  easy to verify that the numbers are those present in the code.   Should the numbers not be generated in a verifiable manner, a nothing-up-my-sleeve generation scheme  should be used to make the generation verifiable. For example, the designers of Poseidon chose a  scheme based on the  Grain cipher . The description of their algorithm can be found in appendix F of the  Poseidon paper .    Status   Following further discussion with the Mina team, we determined this to be a non-issue. Our team was able  to verify that the numbers used are generated such that they can be verified to be random. Previously, we  compared the actual ARC values with the generated MDS matrix values. With further clarification from the  Mina team, we compared ARC constants to the generated ARC constants and were able to successfully  conduct the verification.    However, we recommend that the Mina team simplify the verification process (See  Suggestion 5 ). During  our review, we found that the existing script prints poorly formatted Rust code, which is not accepted by  rustfmt. We had to employ a semi-manual process that included writing custom code to make comparing  the values to those in  src/poseidon.c  feasible. The process for verifying that the parameters were  generated honestly should be streamlined by adding a script will simplify the verification process. This  will make it easier for reviewers, developers, and contributors to verify the system is working as expected.   Verification   Resolved.   Security Audit Report | Mina Ledger Application | O(1) Labs 5 February 2021 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.      ", "html_url": "https://leastauthority.com//static/publications/LeastAuthority_O1_Labs_Mina_Ledger_Application_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Pre-committing a Document Can Block Counterparty State", "body": "  Updates   Location   https://github.com/centrifuge/centrifuge-chain/blob/master/runtime/src/anchor/mod.rs#L125   Synopsis   Anyone that has access to an  anchor_id   preimage ID (   d next\u2212img     ) can block committing an update  of  that document by any counterparties involved in that document for up to  pre_commit_expiration_duration_blocks() . As pre-commits fall off from the eviction process,  the attacker could resubmit and continue to block state updates.   Impact   This would allow anyone with the document data for the anchor to  pre_commit  and block updating that  document as a result. If this occurs, a document will not be able to complete an update that it would like  to  commit .    Feasibility   An attacker would be required to obtain a document and have knowledge of the    d next\u2212img     field. This  knowledge is intended to be kept to only the set of participants in the document. If the attacker is unable  to uncover this preimage, then they will not be able to  pre_commit  to prevent state updates that are of  concern to the owners of the document. However, if a counterparty finds a document disastifing to them  at any point, they may choose to lock the anchor and continue to relock it after the pre-commit eviction  time passes.    Technical Details   If an attacker is able to obtain a document in full, they could propose a  pre_commit  with the information  of   . This would likely be a counterparty of the document but could be due to an accidental leak   d next\u2212img     of the updates randomness. They could create a  pre_commit  for a specific  anchor_id  or  signing  root,  and if any legitimate participants of the document wish to then update the anchor, they would find  themselves blocked by the attackers pre-commits. Pre-commits last 800 (6 second) blocks and do not  require state rent but do require a transaction fee.   Mitigation   It may be possible for legitimate owners to fork the document by adding some extra salt to a leaf such  that they exclude a participant from a new document update. This is stated as a mitigation in the   Protocol  Limitations documentation . The documentation also notes that owners of the anchored document should  be trusted business partners in the initial implementation to reduce the likelihood of this attack.     Status   The Centrifuge team has stated that they consider this to be a protocol limitation. In the protocol  documentation, they note an assumption that counterparties are trusted and centralized business  partners and, as a result, these parties are not expected to behave in malicious ways. In the event one of  these parties acts maliciously and blocks a document update the document will be abandoned and a new  version created.    If counterparties are decentralized, we consider this to be a security issue that will negatively impact  participants of document updates and we strongly recommend that investigation into fraud proofs or  validity proofs be conducted in order to help prevent malicious actions.    Security Audit Report | Centrifuge Chain | Centrifuge 3 April 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.            Verification   Unresolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Chain_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Fees Must Be Continually Updated to Avoid DoS Issues", "body": "   Location   https://github.com/centrifuge/centrifuge-chain/blob/master/runtime/src/anchor/mod.rs#L121-L123   https://github.com/centrifuge/centrifuge-chain/blob/master/runtime/src/anchor/mod.rs#L153-L157   https://github.com/centrifuge/centrifuge-chain/blob/master/runtime/src/anchor/mod.rs#L253-L255   Synopsis   Anyone may iterate over random document data and flood a node with transactions to store pre-commit  data, anchor data, or other computational or disk heavy transactions. To combat this, Centrifuge  implements the   transaction weights  functionality provided by Substrate. In addition, Centrifuge has  developed a specific state rent fee and eviction times that are an additional protection against state bloat  from anchor data being committed with little cost.    All fees will be based on a variable amount of tokens that transaction initiators are required to pay to  block proposers. This token will have a fluctuating conversion rate to fiat value that must be balanced  enough to equal a fiat cost imposed on the proposers that prevents spamming of transactions. Given that  the conversion rate could likely be volatile, particularly in the early blocks of the chain, this cost may not  be adequately priced at all times and the amount of token required to cover this cost based on fees will be  required  to fluctuate in some way. In Ethereum, these fees are decided by the miner and how much work  the miner is willing to take based on their assessment of the current value of the native token.   Impact   State storage and transactional computation  will be forced on nodes. If this is done recursively at little  cost as the value of the token used to calculate fees fluctuates, it could cause state storage to bloat and  create potential DoS issues by overwhelming full nodes.    Feasibility   There are preventative measures to ensure that data is not stored for indefinite time periods and all  transactions are weighted or incur some fee. This is only feasible if the fee is not priced correctly based  on the value of the token that the fee is paid in.   Mitigation   As the value of the chains currency fluctuates, we recommend continuing to investigate the economic  burden placed on custom functions to ensure that the cost of these functions prevents unwanted spam.   Status   The Centrifuge team intends to use a centralized form of governance to adjust fees as the value of the  native token fluctuates in the early stages of the chain. They are continuing to investigate other methods  of pricing the native token such as oracles.   Verification   Partially Resolved.   Security Audit Report | Centrifuge Chain | Centrifuge 3 April 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.      ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Chain_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Document Consensus Is Not Enforced", "body": "   Location   https://github.com/centrifuge/centrifuge-chain/blob/master/runtime/src/anchor/mod.rs#L177   Synopsis   The commit function does not check that the document root contains valid signatures of counterparties  in the  signature root .   Impact   Any participant in a documents state update can commit an update without signatures from  counterparties. The whitepaper,   [VPSW17] , mentions that this is intended behavior for this early version.    Remediation   Documentation that explains that a future use will be made of the proof hash supplied to the commit  function and that this is intended to be a feature can be found in the   Protocol Limitations documentation  that was provided to us by the Centrifuge team.   Status   The Centrifuge team considers unenforced document consensus to be a protocol limitation at this time.  Any participant of a document may commit an update without the consent of other participants. This  would not be a security issue if document updating is a centralized process that does not require  consensus, however, if a decentralized update process is desired in the future then checking signatures  and acting on the consensus of the document will be required.   Verification   Unresolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Chain_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Block Proposers May DoS Anchors", "body": "    Location    https://github.com/centrifuge/centrifuge-chain/blob/master/runtime/src/anchor/mod.rs#L125    Synopsis    If anchor pre-commits are supplied to nodes via a blockchain transaction, it could be possible that a block  proposer could witness a pre-commit transaction and create their own pre-commit for an anchor if they  know the  anchor_id  of the next document update. This would block the user wanting to make a state  update to a document.   Impact   Those anchored documents that a proposer decides to block will be unavailable until the pre-commit  times out and another proposer correctly includes these transactions. Alternatively the document owners  would need to recompute a new pre-commit root and have a non-malicious proposer include it.   Feasibility   The value gained from a proposer committing this action is not clear. A block proposer may not be able to  identify valuable targets to censor and an incentive to do so would not come from the chains currency,  but rather only potentially from the value of harassing the document owners. This would likely only   Security Audit Report | Centrifuge Chain | Centrifuge 3 April 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.        happen in the case that a block proposer wants to damage the network without a direct reward, however  there is no cost to a proposer for committing this action.   Mitigation    Begin research into a slashing condition at the consensus layer that will deter miners from committing  this random behavior.     Status   The Centrifuge team has stated in their response that because there is no clear reward to performing this  attack, that an attack will not take place as a result. Given that incentives to attack a blockchain are not  always clear and there may be reasons that attackers would commit to attacks without an immediate or  monetary reward, we believe that this should still be considered a security issue. We encourage continued  monitoring for this attack, regardless of unknown incentives, and further investigation into slashing  conditions to prevent (or minimize) any unknown reward a block proposer may receive for performing this  attack.   Verification   Unresolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Chain_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Update and Replace Vulnerable Dependencies", "body": "  Location  mpc-uniqueness-check/Cargo.toml  mpc-uniqueness-check/Cargo.lock  Synopsis  We found four issues in the dependencies of the mpc-uniqueness-check.  Security Audit Report | MPC Protocol for Uniqueness Check | Worldcoin 4 April 2024 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  We found the following dependency vulnerabilities in the mpc-uniqueness-check codebase using Rusts cargo audit:   RUSTSEC-2024-0020: stack buffer overow for dependency whoami;  RUSTSEC-2023-0071: potential key recovery through timing side channels for dependency rsa;  RUSTSEC-2024-0021: memory corruption for dependency eyre; and  RUSTSEC-2024-0019: return of invalid tokens for named pipes (Windows-specic) for  dependency mio.  In addition, running cargo audit revealed two warnings:   RUSTSEC-2021-0141: dotnev is unmaintained and should not be used in production code; and  iana-time-zone V0.1.59: iana-time-zone version 0.1.59 has been yanked.  Remediation  We recommend following a process that emphasizes secure dependency usage to avoid introducing vulnerabilities to the mpc-uniqueness-check, which includes:   Manually reviewing and assessing currently used dependencies;  Upgrading dependencies with known vulnerabilities to patched versions with xes;  Replacing unmaintained dependencies with more secure alternatives, if possible (more  specically, alternatives that are used, tested, and audited and that work as intended);  Pinning dependencies to specic versions, including pinning build-level dependencies in the  respective le to a specic version;   Only upgrading dependencies upon careful internal review for potential backward compatibility  issues and vulnerabilities; and   Incorporating an automated dependency security check into the CI workow, such as  cargo_audit, gosec, or nancy.  Status  The Worldcoin team has updated the dependencies, included patched versions with xes, and added cargo audit to the CI. The rsa crate affected by RUSTSEC-2023-0071 has not been upgraded since it is only used by sqlx-mysql within sqlx. Since this codebase uses postgres, the code is not affected. However, our team noted a new warning currently appears \u2014 RUSTSEC-2024-0320 \u2014 which states that the yaml-rust crate used by the config le is unmaintained. The Worldcoin team responded that they will upgrade it in the next release.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/least-authority-worldcoin-mpc-protocol-for-uniqueness-check-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Module Ordering During Application Instantiation", "body": "   Location   https://github.com/LeastAuthority/bandchain/blob/master/chain/app/app.go#L221-L225   Synopsis   The comments in the code base suggest that the oracle module must execute before the staking in order  for violators of the oracle protocol to be penalized. The order that appears in the code is such that the  staking module runs before the oracle in the  SetOrderEndBlockers  function.    Impact  If the staking module is performed before the oracle, then actions such as penalizing validators stake  based on validations done in the oracle module would not be possible.   Mitigation   The Band Protocol team responded to this issue noting that the comment is outdated. The oracle module  in the current version will not be providing information to the staking module.   Remediation   Correct the comment before the module registry function to avoid confusion.   Status   The outdated comment has been removed and an additional comment has been added for further  clarification of the Cosmos SDK module ordering in  SetOrderBeginBlockers .    // NOTE: Oracle module must occur before distr as it takes some fee to   distribute to active oracle validators.   -  // NOTE: During begin block slashing happens after   distr.BeginBlocker so that there is nothing left    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Band_Protocol_Cosmos_SDK_Oracle_Module_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Man In The Middle Can Fake Colocation", "body": "   Location   https://github.com/LeastAuthority/go-libp2p-pubsub/blob/master/score.go#L244-L249   Synopsis   The score function has an aggressive colocation penalty for running multiple peers from the same IP  address, with the peers being the recipient of the penalty. This can be used by a man-in-the-middle  attacker to decrease the score of other peers.   Impact   The attacker can reduce the peer score of one node at one of its peers. This can lead to them being  ignored or pruned.   Security Audit Report | Gossipsub v1.1 | Protocol Labs 3 June 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.        Preconditions   The attacker needs to convince a peer to connect to its IP address, expecting the peer ID of a target peer.   Feasibility   The attack is straightforward with unsigned peer records.   Technical Details   First, the attacker broadcasts a fake peer record with the target's ID and the attacker's IP. When a victim  connects to the attacker, the attacker proxies them to the target. The target and the victim will both  believe the other has the attacker's IP address. If more than one victim is proxied to the same target, the  target will start to negatively score the victims. This may cause their score to fall low enough that the  target refuses to mesh with them or to ignore their gossip. The target will penalize all victims that connect  through the attacker, considering them sybils. If a victim falls for the same trick twice by the same  attacker, the same penalty is applied to both targets.   Remediation   A more reliable way of associating IDs with IP addresses is required. Since libp2p is already in the  process of switching to signed peer records, an attacker will be unable to create a signed peer record that  claims an ID they do not control.   Status   The Gossipsub team has clarified that the network should be set up using signed peer records in the  Gossipsub v1.1 specification . Furthermore, signed peer records are now the default and need to be  explicitly disabled in order to make the protocol susceptible.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-ProtocolLabs-Gossipsubv1.1-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Love Bombing Attack", "body": "   Location   https://github.com/LeastAuthority/go-libp2p-pubsub/blob/master/score.go#L188-L208  https://github.com/LeastAuthority/libp2p-specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md#ov erview-of-new-parameters   Synopsis   The most significant positive factor in the score function is  first message deliveries , following  recommendations in the Gossipsub 1.1 design specification for relative parameter weights , s ince time in  mesh is capped to a small value and message delivery failure is only negative.   Sybil attackers influence a victim to mesh with the sybils by behaving in a calculated way to make their  score increase. This may cause the peer to unmesh from honest peers and produce a higher proportion of  sybils in the network. As a result,   the mesh gets an overall higher percentage of sybil members, which,  for example,  could result in delaying the network.   Impact   A single peer could be influenced to unmesh from honest peers. If a peer that is delivering many  messages leaves the honest mesh, one possible impact is that it could cause the network to be delayed.  If that delay hits critical thresholds such as block time, that delay is equally harmful as dropping  messages.   Security Audit Report | Gossipsub v1.1 | Protocol Labs 3 June 2020 by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.        Preconditions   The attacker needs a faster route from the publishers to the victim in addition to enough unique IP  addresses such that the sybils can replace the mesh of the victim, without hitting the colocation penalty.   Feasibility   It would be straightforward to apply to a single peer, however, it would be more challenging but likely  possible to pull off at a larger scale.   Technical Details   Due to the random structure of a gossip network, most peers are not connected directly to the publishers.  Although peers may possibly be connected to some publishers, they are not connected to all of them.  This lack of direct connection is essential to the scalability of the network since the publisher would  otherwise require a significant amount of resources. However, an attacker could connect directly to  publishers and then to a victim, likely having a shorter path and therefore getting the messages before the  victim. By delivering the messages to the victim before the honest peers do, the victim will give them a  higher score than the other peers and eventually unmesh the honest peers and only mesh with the sybils.    Remediation   This attack is possible because the attackers are able to create incoming connections at will and a  Gossipsub peer treats these connections as equivalent to the outgoing connections that they control. If  peers had a quota to always maintain  some  outgoing mesh connections, then the attackers would not be  able to fully take over the peer's mesh, unless the peer willingly connects to them (which is somewhat  more difficult for the attackers to ensure).   Status   Minimum quotas for outgoing connections chosen by the node have been established, and when pruning  peers due to oversubscription, they remain connected to at least that quota of outgoing peers. As a result,  it is now no longer possible for attackers to influence all a peer's connections, since that peer will always  maintain at least some connections which are not controlled by the attacker.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-ProtocolLabs-Gossipsubv1.1-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Graft Sniping", "body": "   Location   Specification:  https://github.com/LeastAuthority/libp2p-specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md#op portunistic-grafting   Code:  handleGraft()  -  https://github.com/LeastAuthority/go-libp2p-pubsub/blob/master/gossipsub.go#L477   Synopsis   A Gossipsub peer accepts all graft requests and will not prune them until the next heartbeat, even if the  graft puts the peer over the mesh limits. As a result, an attacker can request a graft and immediately send  fresh messages which increases their score. If they increase their score enough, it is possible that honest  peers will be unmeshed in a subsequent heartbeat.   Security Audit Report | Gossipsub v1.1 | Protocol Labs 3 June 2020 by Least Authority TFA GmbH   9   This audit makes no statements or warranties and is for discussion purposes only.        Impact   This would allow for a more efficient way to carry out the love bombing attack (see  Issue B ).   Preconditions   The same preconditions apply as  Issue B , which are further aided if the attacker knows when the victim's  heartbeat takes place.   Feasibility   This attack can be performed from a cheap Virtual Private Server (VPS). To increase the chances, the VPS  should be deployed in a datacenter as close to the victim as possible, which does not increase the cost or  difficulty of the attack.   Technical Details   Similar to  Issue B , sybils prearrange many connections to publishers. Connecting to a Gossipsub peer  takes some time given that there are several layers of protocol handshakes to get through, at least one  roundtrip each for multistream, secure channel, and transport upgrader. As a result, attackers would also  need to prearrange a connection to each victim. Once they are ready and think they can rapidly deliver  messages (faster than the peer is getting them otherwise), they send a graft request, rapidly followed by  as many messages as possible. If they manage to deliver the first message, it is possible that their score  becomes more than that of honest peers. If the peer is now over the mesh limits ( D_high ), then the peer  should prune the lower scoring peers.   Remediation   This attack depends on the ability of a peer to request a graft and immediately be grafted. The  remediation is simple and requires rejecting new grafts immediately if the peer is already at the high  threshold.   Status   If a node already has  D_high  active mesh connections, incoming grafts are rejected, and a prune  response is sent without delay. Outgoing grafts are still permitted, which allows recovery from eclipse  events even when connected to many peers.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-ProtocolLabs-Gossipsubv1.1-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Potential Vulnerabilities if Insecure Peer Discovery is Used", "body": "   Location   Peer Discovery:  https://github.com/LeastAuthority/go-libp2p-pubsub/blob/master/discovery.go   Distributed Hash Table (DHT) Peer Discovery:  https://github.com/libp2p/go-libp2p-discovery/blob/e6ceacdf48dba72efae705a384a2f9f1b217db77/rout ing.go#L59   Synopsis   Gossipsub goes to some length to harden the protocol against attacks but recovery from an attack  assumes that it is possible for honest peers to reliably connect to new random honest peers, via a peer  discovery service. If that discovery service is attacked, the defense could potentially fail.  The broader  libp2p/IPFS ecosystem is highly modular, but some available peer discovery methods are too insecure to  provide the assurances required by Gossipsub.    Security Audit Report | Gossipsub v1.1 | Protocol Labs 3 June 2020 by Least Authority TFA GmbH   10   This audit makes no statements or warranties and is for discussion purposes only.        Impact   Depending on how severely the discovery service is attacked and how much the Gossipsub instance relies  on it, it could severely impact the Gossipsub mesh's ability to recover from an attack.   Preconditions   A Gossipsub instance must depend on a vulnerable peer discovery service, such as DHT.   Feasibility   It would be easier to perform an attack on the peer discovery service than on Gossipsub directly. For the  DHT discovery service, it would be fairly easy.   Technical Details   It is somewhat difficult to secure a DHT since they are open by design and assume that peers will interact  helpfully with random strangers. The existing literature contains a number of attacks on them, such as the  Eclipse attack [ SNDW06 ].   In the Eclipse attack, attackers create fake nodes with keys nearby the target. When honest peers request  that target, they are likely to get a response from an attacker. Thus, the attackers can censor a node or  provide false information.   The libp2p Kademlia (DHT) implementation could be potentially be vulnerable to Eclipse attacks. Bucket  assignment is based simply on peer ID, a value the attacker controls, so it is easy and feasible to generate  new peers to Eclipse a given topic. In addition, DHT peers will recommend other peers that have  responded to a RPC request, which is a somewhat lower bar than Gossipsub (since there is no peer score  function). Therefore, it is probably easier to attack the DHT than to attack Gossipsub. However, under the  assumption that a DHT is used for peer discovery, an attack on Gossipsub could begin with attacking the  DHT.   Mitigation   Node operators can configure explicit peering arrangements instead of using the DHT.   Remediation   It would be very difficult to prevent this entirely. The libp2p DHT could be hardened by any of the  following:    The discovery service could use other less vulnerable services;    Peers could detect if a given discovery service becomes unreliable (low rate of successful   connections or a high rate of connecting to bad peers); and     Rebalance to other services or alert the operator.    Our team recommends additional research into hardening the DHT and other discovery services.   It has also been suggested to use bootstrappers and peer exchange. New peers would connect to a  bootstrapper and, when they are unmeshed, they become recommended peers to mesh with. It seems  possible that this could be vulnerable to attacks (such as love bombing the bootstrappers), but it has not  yet been as well studied or researched as the attacks on DHTs.   Status   The  Gossipsub v1.1 specification  now includes a recommendation that network operators may use peer  exchange via bootstrapping instead of a peer discovery service. The Least Authority team has requested   Security Audit Report | Gossipsub v1.1 | Protocol Labs 3 June 2020 by Least Authority TFA GmbH   11   This audit makes no statements or warranties and is for discussion purposes only.      that it be more explicitly stated by emphasizing that Gossipsub is vulnerable if the peer discovery can be  attacked.   Verification   Partially Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-ProtocolLabs-Gossipsubv1.1-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Length Field in CSafeHash256/512::Write Can Overow", "body": "  Location  crypto-suites/crypto-hash/safe_hash256.cpp#L33  crypto-suites/crypto-hash/safe_hash512.cpp#L33  Synopsis  The length elds that provide injectivity in CSafeHash can overow, resulting in the same hash being produced for different sequences of writes.  Impact  This attack may lead to forged proofs, possibly undermining the security of the MPC-ECDSA signature protocol.  Preconditions  The attacker needs to be able to trick the prover to include a very long value in one of the hashes.  Feasibility  It is unlikely that this attack can be performed successfully outside of a lab setting.  Technical Details  CSafeHash256 and CSafeHash512 wrap hash functions and add a 32-bit length to each write. This is a common method for injectively encoding sequences of values that may have variable length. Injectivity means that any two sequences produce different encodings. In the edge case where a very large value (>4GiB) is supplied, the length eld wraps around, allowing injectivity to break. Breaking injectivity allows hash collisions to be produced without the hash function itself being attacked.  Security Audit Report | Crypto Suites & Multiparty ECDSA (incremental changes) + Encapsulation Layer | Safeheron 5 February 2024 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend checking that the length of each write ts in 32-bits.  Status  The Safeheron team has expanded the length representation to 64-bit length, which makes it practically infeasible to overow the length eld.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/safeheron_crypto_suites__multiparty_ecdsa_updated_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Sanity Check Assertions Are Compiled Away in Release Mode", "body": "  Location  Examples (non-exhaustive):  crypto-suites/crypto-bn/bn.cpp#L125  crypto-suites/crypto-bn/rand.cpp#L143  crypto-suites/crypto-sss/vsss.cpp#L25  Synopsis  The C++ assertion macro is implemented for assumption checks throughout the codebase.  Impact  This might lead to unexpected behavior.  Technical Details  In C++, the assert macro is used for debugging purposes only, and its behavior depends on the presence of the NDEBUG macro. If NDEBUG is dened, the assert macro is compiled away. Developers often utilize the assert macro for optimization purposes by eliminating the negative impact assertion checks can have on performance.  In some instances in the codebase, however, the Safeheron team utilizes the assert macro to perform assumption checks on parameters in low-level algebraic and cryptographic primitives. These checks are hence missing if the NDEBUG macro is present, which is standard behavior in release builds.  Remediation  We recommend that the Safeheron team either build a custom assert macro expressing the same logic, or check the relevant assumption via exception handling.  Status  The Safeheron team has implemented a custom assert functionality and replaced the C++ assert macro with it.  Verication  Resolved.  Security Audit Report | Crypto Suites & Multiparty ECDSA (incremental changes) + Encapsulation Layer | Safeheron 5 February 2024 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/safeheron_crypto_suites__multiparty_ecdsa_updated_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Incorrect Cofactor Handling in PubKeyRecovery", "body": "  Location  crypto-suites/crypto-curve/ecdsa.cpp  Synopsis  In Safeherons implementation of the ECDSA PubKeyRecovery algorithm, a parameter j is used in order to decide which of the four possible public keys from the key recovery process should be considered as valid. However, the implementation uses j incorrectly.  Impact  The two cases j=2 and j=3 might compute public keys that are invalid for the signature.  Preconditions  A private key would need to have an associated public key pk=(x,y), such that x is larger than the modulus of the curves scalar eld.  Feasibility  The attack is straightforward since public keys are distributed uniformly. Hence, by utilizing a brute-force try and error generation of secret keys, it would be feasible to generate an associated public key that satises the precondition.  Technical Details  For parameter 2 <= j <= 3, the Safeheron team computes the x coordinate of the curve point R as x = r + curv->n * j. However, the algorithm requires x = r + curv->n. Since 2*curve->n > curve->p, the value curve->n*j exceeds the curves base eld modulus, which would result in unexpected consequences.  Mitigation  We recommend computing the x coordinate of R as x = r + curve->n in case j=2 or j=3.  Remediation  As Safeherons implementation of the ECDSA key recovery algorithm can only handle curves with a cofactor of 1, and utilizes j inconsistently, we recommend implementing algorithm 4.1.6, as explained in [Brown09].  Status  The Safeheron team has replaced the parameter j with a more descriptive name and updated their elliptic curve representation to include the cofactor. They also updated the recovery algorithm to work as intended for elliptic curves with a cofactor of 1.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/safeheron_crypto_suites__multiparty_ecdsa_updated_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Missing Checks in ECDSA Signature Verication", "body": "  Location  crypto-suites/crypto-curve/ecdsa.cpp#L122  Security Audit Report | Crypto Suites & Multiparty ECDSA (incremental changes) + Encapsulation Layer | Safeheron 5 February 2024 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  In addition to computing the verication equation, an ECDSA verier must also compute some sanity checks on the input values. While the Safeheron team checks that the coordinates of the public key are reduced and that they satisfy the curves dening equation, other sanity checks are missing.  Impact  In the absence of such sanity checks, an attacker can forge signatures.  Technical Details  Our team identied the following missing checks on the veriers input:   a check verifying that the signers public key is not the point at innity;  a check verifying that the public key is in the large prime order subgroup (note that this is not  needed for secp256k1, P256 or STARK); and   a check verifying that the signature values are reduced (i.e., verifying that r<curve->n and  s<curve->n).  Remediation  We recommend implementing the missing checks.  Status  The Safeheron team has implemented the missing checks.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/safeheron_crypto_suites__multiparty_ecdsa_updated_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue E: Missing Check in Feldmans Secret Sharing Allows for Threshold", "body": " Escalation [Known Issue]  Location  /src/crypto-suites/crypto-sss/vsss.cpp#L32  Synopsis  During the audit, an external security service provider reported a vulnerability to the Safeheron team. This vulnerability occurs because a test is missing where an honest participant checks that the degree of each random polynomial in Feldmans veriable secret sharing scheme does not exceed the agreed on threshold t of the protocol.  Impact  If a malicious participant generates a commitment to a Feldman random polynomial of degree T > t for an agreed on threshold t, and the degree is not checked by all other honest participants, it effectively transforms the t out of n protocol into a T out of n protocol. As a result, no set of t participants will be able to generate a valid signature. In case the attacker choses T>n, it is not possible to generate a valid signature at all.  Feasibility  The attack is straightforward since it is trivial to generate random polynomials of arbitrary degrees.  Security Audit Report | Crypto Suites & Multiparty ECDSA (incremental changes) + Encapsulation Layer | Safeheron 5 February 2024 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  The VerifyShare function in Safeherons implementation of Feldmans veried secret sharing scheme needs to implement a check on the number of coecient commitments for the shared random polynomial of each participant.  Status  The Safeheron team has implemented the recommended check.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/safeheron_crypto_suites__multiparty_ecdsa_updated_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Locked Mutex on Return From Functions", "body": "  Location  state/snapshot/snapshot.go#L600-L603  trie/database.go#L700-L707  Synopsis  The referenced function does not unlock the mutex when returning.  Impact  Incorrect implementation of concurrent access to shared objects can lead to undened behavior or be exploited for a denial of service attack.  Mitigation  We recommend unlocking the mutex using a defer statement, if possible. Otherwise, we recommend verifying that all mutexes are unlocked along all control-ow paths.  Status  The Ava Labs team has mitigated the issue by unlocking the mutexes.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/ava_labs_subnet_evm_final_audit_report/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Tickers Leak", "body": "  Location  plugin/evm/gossiper.go#L240-L244  Synopsis  The function awaitEthTxGossipA creates three tickers but does not stop them when it nishes. As a result, the allocated resources leak.  Impact  The allocated resources for tickers will leak. This could be exploited for a denial of service attack.  Mitigation  We recommend using the Stop function to stop a ticker.  Status  The Ava Labs team has mitigated the issue as suggested.  Verication  Resolved.  Security Audit Report | Subnet EVM | Ava Labs 03 April 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/ava_labs_subnet_evm_final_audit_report/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Out of Range Index Causes a Potential Panic", "body": "  Location  internal/ethapi/api.go#L1717  Synopsis  A panic can be triggered in the GetTransactionReceipt function. If the value of the index variable is equal, for example, to (1<<64)-1 (max uint for 64-bit system) or (1<<32)-1 (max uint for 32-bit system) then that index is cast to the int type, its value changes to -1, and the execution will not be canceled on the if statement. After that, a panic will be triggered upon accessing a slice element with a negative index.  Impact  Triggering a panic can be exploited for a denial of service attack.  Mitigation  We recommend checking that the result of casting to int type is a positive number.  Status  The Ava Labs team has added the check as suggested.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/ava_labs_subnet_evm_final_audit_report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Uni-Stark Verier Trusts the Prover on the Validity of Proof", "body": " Parameters  Location  uni-stark/src/verifier.rs  Synopsis  The verier does not check the validity of certain proof parameters (degree_bits and the number of the FRI commitments) but, instead, trusts the prover to provide the correct data.  Impact  A malicious prover could send an incorrect value to degree_bits or manipulate the number of the FRI commitments, which could lead to undened behavior. For example, by pushing arbitrary data to the  Security Audit Report | Plonky3 | Polygon 31 July 2024 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   vector of FRI commitments, the prover can potentially trick the verier into using an incorrect generator for the domain.  Technical Details  At the moment, the prover sends a proof consisting of commitments, opened values, an opening proof, and the parameter degree_bits. A check on the valid shape is performed for the opened values. However, a check is missing on the validity of degree_bits and the number of the FRI commitments contained in the opening proof. These should be veried against the AIR itself.  Remediation  We recommend implementing checks on the relevant proof parameters in the verier by comparing them against values derived from the associated AIR.  Status  The Polygon team has acknowledged the nding and argued convincingly that it is not a security issue because degree_bits is the denitive source of truth, and it cannot be maliciously altered in any successful attack. If the length of a Merkle proof does not align with degree_bits (considering any adjustments, such as blowup), the Merkle proof will fail, and any adaptation of associated Merkle trees to the wrong degree_bits is not a viable concern.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/polygon-plonky3-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Fiat-Shamir Initialization Is Incomplete", "body": "  Location  uni-stark/src/prover.rs  uni-stark/src/verifier.rs  keccak-air/examples  Synopsis  The initialization of the Fiat-Shamir challenger for the univariate STARK implementation does not adhere to the principles of Fiat-Shamir, which require the challenger to absorb all information the verier has access to at any given step in the computation.  Impact  Not absorbing parameters such as the public inputs, the FRI conguration, or the degree of the polynomial allows a malicious prover to tamper with this data. Depending on the use case of this STARK implementation, this can lead to security-related consequences (see, for example, [DMW+23]).  Technical Details  In the current implementation, the prover and the verier initialize the challenger with an empty vector. The principles of Fiat-Shamir recommend absorbing all the information the verier has access to. Based on this, we identied that the following items are missing:   A global domain separator to ensure that proofs of different domains are incompatible;  A conguration for FRI, including the log_blowup, num_queries, proof_of_work_bits, and  a representation of the Mixed-Matrix Commitment Scheme (MMCS);   A representation of the underlying Fields and Field Extensions;  Security Audit Report | Plonky3 | Polygon 31 July 2024 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.    All pre-decided generators;  A representation of the AIR in use;  A representation of the Polynomial Commitment Scheme (PCS);  The public values used;  The potential maximal degree of all constraints; and  The number of atomic constraints \u2014 that is, the number of elements in the enum  SymbolicExpression.  Remediation  We recommend properly initializing the challenger by including all of the items listed above.  Status  The Polygon team has added the public values and the trace degree. For the other data, the team stated that a domain separator should be sucient.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/polygon-plonky3-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Fiat-Shamir in FRI Is Incomplete", "body": "  Location  fri/src/prover.rs#L27  Synopsis  The Fiat-Shamir challenger does not currently absorb the value final_poly, which is the result of the commit phase in the FRI protocol.  Impact  While our team did not reason about a specic attack, incorrect Fiat-Shamir implementations have been shown to have security-relevant consequences (see, for example, [DMW+23]).  Technical Details  During FRI, the prover divides and folds a polynomial in order to reduce its degree and to prove proximity to a low-degree polynomial. After each folding round, the prover absorbs the commitment hash on the polynomial of that round. The value final_poly is the result of the commit phase in the FRI protocol and is currently not absorbed into the challenger.  Since the challenger is used to sample the query indices after the commit phase, and the verier sees the value final_poly, following the principles of Fiat-Shamir, the prover has to absorb final_poly into the challenger before squeezing the query indices.  Remediation  We recommend absorbing the value final_poly into the challenger before squeezing the query indices.  Status  The Polygon team has implemented the remediation as recommended (PR #393).  Verication  Resolved.  Security Audit Report | Plonky3 | Polygon 31 July 2024 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/polygon-plonky3-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Missing Checks on the Validity of Inputs", "body": "  Location  field/src/field.rs#L304  commit/src/domain.rs#L91  matrix/src/bitrev.rs#L28  interpolation/src/lib.rs#L46  Synopsis  Our team identied a number of missing checks on the validity of inputs.  Impact  A missing check on relevant input data can lead to crashes or undened behavior in the code.  Technical Details  We identied the following missing checks:   In the le commit/src/domain.rs, the function split_domains panics if log_n is smaller than log_chunks. It should be checked that this is not the case. In addition, the code fails if num_chunks is not a power of two.   In the same le, in the function selectors_on_coset, it is implicitly assumed that the inverses  of denoms for the single_point_selector exist. This should be checked with assert_neq!(coset.shift, Val::one()).   In the le matrix/src/bitrev.rs, the function new panics if inner.height is not a power of two due to the function log2_strict_usize. This occurs in several other locations, including in the folder matrix and in other les (more specically, searching the function in the codebase yields 76 results in 24 different les).   In interpolation/src/lib.rs, the function interpolate_coset panics if the point  passed as an input is one of the roots of unity \u2014 that is, equals subgroup_i. In this case, the inverse does not exist. It should be veried that this is not the case.   In the le field/src/field, the function monomial crashes for exponents larger than the  extension degree D. It should be checked that the exponent is smaller than the extension degree D.  Remediation  We recommend implementing the relevant checks listed above. Additionally, and as noted in Suggestion 1, we recommend returning error messages instead of panics for these checks.  Furthermore, we recommend making the code more robust and typesafe, whenever possible. Our team recognizes that for most functions in the codebase, it is a precondition that certain input data be powers of two (such as the height of matrices). One possible mitigation is passing in log2 of a number instead of the number. In addition, it could be stated as a precondition in the respective modules.  Status  The Polygon team has introduced changes to clarify assumptions about valid inputs (PR #387). The team also noted that they could not identify any instances where these panics could realistically be triggered; however, they have added a warning in the README, in case such instances are present but were undetected. The Polygon team additionally stated that if one conservatively assumes a malicious prover  Security Audit Report | Plonky3 | Polygon 31 July 2024 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   could trigger a panic, there are reasonable ways for users to make their applications resilient (for example, by implementing auto-restarts).  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/polygon-plonky3-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue E: The FRI-Verier Is Vulnerable to Multiple Buffer-Overow", "body": " Conditions  Location  fri/src/verifier.rs  Synopsis  The verier currently lacks robustness against out-of-boundary attacks, such as buffer, slice, or array overows, and does not perform several critical checks on the shape of the prover's data.  Impact  A malicious prover could potentially push irrelevant data to the end of certain vectors in the proof, which could lead to unpredictable behavior or cause the code to crash. Crashes could open an attack vector for denial of service (DoS) types of attacks. For example, a longer than expected commit_phase_commits vector would imply an unexpected generator.  Technical Details  We identied the following missing boundary checks, which should:   Verify the length of commit_phase_commits (computed by the verier) against a number (see  Issue A);   Ensure that the commit_phase_openings length equals log_max_height;  Conrm the correct length of reduced_openings; and  Check the data type of reduced openings in the verify_challenges function.  Remediation  We recommend implementing the proper checks.  Status  The Polygon team has made modications to clarify assumptions about boundary conditions (PR #387). The team also noted that they could not identify any realistic scenarios where these crashes could be triggered; however, they have included a warning in the README in case such instances are present but were undetected. In addition, safe Rusts bound check currently prevents buffer overows, and, hence, the only prevalent risk is that the code panics. The Polygon team additionally stated that assuming a malicious prover might be able to trigger a panic, users can adopt reasonable measures to enhance the resilience of their applications (for example, by implementing auto-restarts).  Verication  Partially Resolved.  Security Audit Report | Plonky3 | Polygon 31 July 2024 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/polygon-plonky3-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue F: Rust Assert Checks Could Potentially Crash the Verier", "body": " Strategically  Location  fri/src/verifier.rs  Synopsis  In the verier, multiple checks are implemented as Rusts assert!() macros, thus resulting in the code crashing instead of recovering.  Impact  A malicious prover could intentionally crash the code to open an attack vector for performing DoS attacks.  Remediation  We recommend implementing proper error handling, such that the verier returns an INVALID_PROOF error instead of crashing.  Status  The Polygon team has implemented updates to clarify assumptions regarding Rust assertion checks (PR #387). The team also noted that they could not identify any realistic situations where these checks could panic; however, they have added a warning in the README,in case such instances are present but were undetected. The Polygon team additionally stated that, assuming a malicious prover could potentially trigger a panic, users can take sensible precautions to make their applications more robust (for example, by setting up auto-restarts).  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/polygon-plonky3-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Block Propagation Restrictions Are Too Loose", "body": "   Synopsis   Block propagation messages do not check for a range in the past, which could allow valid, yet old  messages to be withheld and sent out later.    Impact   This type of attack could cause unnecessary processing by nodes, and in large enough volume, would  slow down the entire network, possibly causing transaction processing to stall entirely. Additionally, the  caches that track attestation aggregation messages would grow unbounded.    Preconditions   Any node participating in the gossip network can mount this attack.   Feasibility   An attacker can inexpensively start several malicious nodes for increasing the harm to the stability of the  network. Although conducting this attack would be inexpensive and repeatable, it is moderately feasible  due to the requirement of having some technical knowledge in order to carry it out successfully.   Technical Details   There is no lower bound on the slot for block propagation, allowing a node to use older block proposal  messages.   Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.        Remediation   Introduction of a lower bound on the slot for block propagation would stop forwarding of old, but valid,  messages and make an attack with this method far less effective.    Status   The specification was updated to include the requirement that received blocks need to be newer than the  latest finalized block before forwarding them to other nodes in the network.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Ethereum-2.0-Specifications-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Attester and Proposer Slashing Message Propagation Attack", "body": "   Location   Global topics   Validations   Synopsis   Attester slashing and proposer slashing messages can be propagated with minimal punishment if they  look valid. This allows nodes to spam these messages and create unnecessary traffic in the network,  creating a DoS attack vector.    Impact   This type of attack would slow down or potentially halt network processing for the duration it was carried  out.    Preconditions   First, a node must create a valid attester or proposer slashing message by signing. Once complete,  however, they can create an unlimited amount of similar, valid-looking messages. Second, the attacker  must have access to bandwidth capable of transmitting the volume of messages necessary to create a  noticeable slow-down of the network. The node must also be able to join the network as a validator,  meaning their 32 ETH stake must be deposited and activated before they can send these types of  messages.    Feasibility   This attack is possible by an individual with experience in the language the client is written in and is able  to work with the protocol. The requirements in computing resources are ordinary and satisfied by most  modern laptops. However,  the bandwidth required to carry this out is more substantial. With the  increased availability of fiber lines, home internet connections could possibly transmit the data required  for this attack. Between the required bandwidth, computing power, and skills necessary to carry this  attack out, this attack is moderately feasible, now and more feasible in the near future.   Technical Details   Before a slashing message is propagated by a node in the network, a node must validate that it is  legitimate. However, these validations currently only check that a signature is present and valid. A node  could create a number of valid looking messages and publish them. When other nodes receive these  messages, they will check the signature but nothing else, deem them valid, and forward them to the rest  of their subnet. Given the right volume, this could stall the block proposal and finalization processes.   Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.        For a specific example, a node could create a slashable message (e.g. a double signed message) and  then propagate it. This would result in them being slashed. Once slashed, however, they can send an  unlimited amount of similar messages without punishment, since slashing is a binary state (i.e. a node is  either slashed or is not slashed).   Remediation   Since slashing is a binary state,  proposer_slashing  can be limited to one message per validator and  ignore any other duplicates that are received. Otherwise, a validator that was going to be slashed or was  already slashed could create infinite valid `proposer_slashing` messages.    voluntary_exit  messages can be treated similarly and can accept one valid  voluntary_exit  message per validator, since it is a one-time operation. If another  voluntary_exit  message is received  for a validator, it can be forwarded if it has a more recent epoch than the one that is known. Otherwise,  duplicates can be safely ignored.    The  attester_slashing  messages are a little more difficult to declare the rules for because the  slashable attestations included in the message contain many different validators. We recommend  updating the specification so that a node only forwards  attester_slashing  messages that contain  new validators not yet seen in another  attester_slashing  message.   We recommend that stronger validations be included in the specification for clients around message  forwarding for these three message types in particular.   Status   The specification was updated and applies the recommended remediation. Specifically, any  voluntary_exit  and  proposer_slashing  message is only forwarded once, ignoring duplicates.  Additionally,  attester_slashing  messages that do not contain new information are also not  propagated. Details on the specifics of their approach can be found in  PR #1617 .   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Ethereum-2.0-Specifications-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Distributed Denial of Service (DDoS) Attacks Against Block", "body": "  Proposer   Location   compute_shuffled_index, compute_proposer_index, compute_committee   Design decision rationale   Synopsis   The network specification makes it simple for any validator to figure out the IP addresses of any other  validator quickly. In addition, specification of committees and proposers imply that all proposers are  public knowledge for any slot in an epoch at the beginning of that epoch. An attacker might use this  knowledge to strategically execute DDoS attacks against the proposer of a slot to stall the chain, or to  keep slots empty.   Impact   A validator that is made incapable of reasonably fast network access may be unable to propagate  attestations and proposed blocks in a timely manner. This would lead to targeted censorship of  attestations and blocks, resulting in penalties for the victim.   Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.        Furthermore, the attack is inexpensive enough to perform it over a long range of time on a series of block  proposers. This means that it is a possibility that no new blocks are getting gossipped, which threatens  the liveness of the chain. Once a sustained attack prevents finalization for several epochs, the validators  will lose deposits due to the inactivity penalty.   Feasibility   Any attacker who is able to perform DDoS attacks can mount this attack. The cost depends on the node  under attack - a home staker node with a residential internet connection is significantly less expensive to  bring down than a node in a data center with a symmetric 10GBit/s uplink.   Technical Details   Committees are computed by  RANDAO  at the beginning of each epoch and the first member (relative to  index order) of each committee is the block proposer. An attacker could then precompute IP addresses of  the validator set and keep that list updated on the fly, while that set changes over time. After the  RANDAO  is revealed, they then select all proposer addresses and DDoS them in the usual manner, when their slot is  up for execution.   Remediation   This attack can be remediated by using a proposer election system where only the elected proposer  knows that they are elected, but is able prove this to others. This way, the attacker does not know which  validator node to target before the elected validator proposes their block. Such schemes are called Single  Secret Leader Election (SSLE), as described and constructed in  [BEHG20] .    Status   The team has acknowledged the issue and is working both on implementing a short term workaround and  developing a long-term solution.    The long term solution will likely be using Single Secret Leader Election (SSLE) for electing block  proposers, based on our recommendation. Since SSLE research is still premature and implementing SSLE  is non-trivial, the Ethereum Foundation team decided to introduce this change during a later phase.   In the interim, the Ethereum Foundation team suggests that validator operators run multiple nodes, such  that one node participates in network communication on behalf of the validator, and another node is used  to propagate the blocks proposed by the validator. The decoupling of node identity and validator identity  allows for operators to switch between nodes in order to publish their blocks.   Unfortunately, operating multiple nodes comes with a financial cost that can be prohibitive for hobbyists  and home stakers. For these cases, the Ethereum Foundation team suggests introducing a  community-run semi-trusted node that accepts proposed blocks and forwards them to the network.   At present, the Ethereum Foundation team has stated that they are working on formulating processes and  recommendations that implement this pattern.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Ethereum-2.0-Specifications-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Block Proposer Eclipse Attack", "body": "   Location   https://github.com/libp2p/go-libp2p-pubsub/blob/master/gossipsub.go#L472   Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.        compute_shuffled_index, compute_proposer_index, compute_committee   Synopsis   An attacker creates a large volume of nodes and uses them to connect to the block proposer. The large  number of connections triggers the victim node to prune, as described in gossipsub. When the node  pruning occurs, some legitimate nodes might be purged. This increases the likelihood of connections with  the attackers malicious nodes. After a number of repetitions, the target node only has connections to the  attackers node, eclipsing them from the rest of the network.    Impact   A node that has a majority of attacker nodes as peers in their topic mesh may be unable to propagate  attestations and proposed blocks to the main network. This would lead to targeted censorship of  attestations and blocks, resulting in penalties for the victim.   Furthermore, the attack is inexpensive enough to perform it over a long range of time on a series of block  proposers. This makes it possible that no new blocks are getting gossipped, which threatens the liveness  of the chain. Once a sustained attack prevents finalization for several epochs, the validators will lose  deposits due to the inactivity penalty.   Preconditions   An attacker is able to control enough identities that they have a high probability of becoming the majority  of the targets mesh peers.    Feasibility   This attack can be carried out by any actor with access to a reasonably modern computer and a decent  internet connection.    Technical Details   Given a  D_High  of 12 and a node selecting peers on the mesh to join as a target, not at random. For each  GRAFT  message let P equal the probability of adding to the target mesh while maintaining a previously  connected attack node. Assuming a target is at  D_High  with 12 connected peers, getting the first attack  node already in the list with zero previous nodes is P=1. The probability of not removing the first, or any  subsequent, attack nodes will be  P=11/12 , followed by  P=10/12,P=9/12  and so on until the final  attempt to completely fill the target mesh with attack nodes being P=1/12. Summing the expected values  of becoming an additional peer, an attacker expects to be all 12 peers in 37.2385  GRAFT  messages.  These probabilities assume that trials are independent and that the probability of success does not  change between trials (i.e. that no other peers attempt to  GRAFT  to the target while the attack is taking  place). In practice, it can be expected that more attempts to completely fill the targets mesh would be  needed.   Mitigation   An effort could be made to make a variant of gossipsub less susceptible to eclipse attacks and clients  could deviate from regular gossipsub behavior and try to detect and counteract this attack. For example,  instead of randomly pruning peers, use a conservative approach and keep old connections or connections  that provide low latency pubsub (i.e. connections that send  IHAVE  first for many messages). There are  likely other suitable metrics to heuristically determine the value of a connection.   Remediation   Instead of making the pubsub mechanism less susceptible to eclipse attacks, we recommend making the  beacon chain rely on a protocol that is eclipse-resistant. See  Issue C .   Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   9   This audit makes no statements or warranties and is for discussion purposes only.      Status   See the status explanation in  Issue C .   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Ethereum-2.0-Specifications-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Misaligned Gossip Incentives", "body": "    Synopsis   Rational, or non-altruistic Beacon Nodes (BN) in the gossip network are only incentivised to relay  information to other BNs if it provides their messages with a higher probability of being seen by the  network. Where it is expected that relaying this information increases their profitability (i.e. increase the  likelihood that their block proposal and attestation messages are propagated). If another BN requests  blocks, or asks to relay a message, then it would be a cost burden of some degree on the bandwidth of  the rational BN.    Impact   This could lead to a tragedy of the commons where BNs are incentivized into using the gossip network  only in their favor. This would require altruistic nodes to take on more network traffic and increase gossip  latency. However, this may not be of any immediate concern and more research is needed to fully  understand this concern.    Preconditions   This is only likely if the network is providing a stressful load to a rational BN and there is a clear price to  behaving altruistically that many will not take on.   Feasibility   There are many examples of altruistic actions and we are unsure of the cost that will be placed on these  nodes at this time. It is likely that altruistic nodes will take on rational node costs.    Technical Details   We define altruistism as a BN performing an action initiated by another BN on the network without  compensation (i.e if BN A forwards attestations from BN B, then A expects that B will forward their  attestations messages). Another example is provided in  Issue G  where control messages meant to keep  nodes in sync are abused to always request more information than is produced. The common resource is  a healthy network that can deliver messages that all nodes require as a whole, and a tragedy being a  situation where nodes behave in a self interested way that damages the network.    A rational node we define as one that would attempt to minimize short term costs or maximize profit (i.e.  saving bandwidth costs by not gossiping messages that a node has no interest in, or selectively reducing  the chance of others to maintain validator good standing such that the attackers profits are increased).    Remediation   Methods to deal with rational actors in gossip networks are known, for example under models like  Byzantine, Altruistic, Rational (BAR) tolerant  Gossip described in  [LCWNRAD06]  and first introduced in  [AACDMP05] . Similar strategies might succeed here, too. These strategies come with tradeoffs and it is  not clear what the best approach for Eth2.0 traffic will be at this time.    Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   10   This audit makes no statements or warranties and is for discussion purposes only.          Status   This is an area of ongoing research as the network unfolds and activity is monitored and analyzed.   Proof of Work (PoW) networks have a limited amount of gossip communication, primarily due to block  and transaction propagation. Traditionally in PoW systems, there are tendencies towards more  centralized solutions that are deployed to ensure timely block delivery and healthy propagation in general.  Ethereum is working hard to avoid these strategies if possible by taking into consideration distributed  reputation and scoring systems. PoS networks will require slightly more complicated messaging which  could make this challenging.     Verification   Unresolved.   (Invalid)  Issue F: Bias in Weighted Random Sampling in Election of Block  Proposers   Location   compute_proposer_index    Synopsis   The probability for an active validator to be elected block proposer should be their deposit, divided by the  deposit of all active validators. Measurements have shown that this is not the case.   Impact   Based on an initial review, it seems like the measured bias in favour of validators with a higher effective  balance further incentivizes not provoking to get slashed. However, it is possible that there are edge  cases where this unexpected behavior produces results that are not in the interest of the network.   Technical Details   The following test setup describes an extreme, but possible case in which the proposer selection function  should behave as expected. Sets of validators of different sizes are prepared. In each of these sets, all  validators have an effective balance of 16 ETH, except one, that has an expected balance of 32 ETH. Then  run the  compute_proposer_index  function over these validators. Each test is performed 32 times and  the average each of the resulting values approximates typical behaviour. The expected outcome is that in  all cases, all 16 ETH validators get elected roughly the same amount of time, and the 32 ETH validator  gets elected roughly twice as often.   However, test results show that this is not the behavior of the function. In order to learn about the  statistical properties of the function, a large number of samples is required. Since the python executable  specification is not very fast, the tests were performed using zrnt.   Two irregularities are identified with this test. The first validator in the set consistently gets elected more  often than the rest. The extent of this advantage varies, depending on the number of validators and the  ratio of the own stake and that of the rest of the network. Second, as the validator set grows larger, the  validator with more stake is elected disproportionately more often than the others.   A possible cause of these issues is the  compute_proposer_index  function, which performs a variant  of the rejection sampling method. Instead of sampling a new validator that is tested in every round, it  performs a random permutation once and then iterates over that.   Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   11   This audit makes no statements or warranties and is for discussion purposes only.        The fact that the first validator gets elected more than the others suggests that there is an issue in the  permutation function, as the first validator in the shuffled list will have a much higher chance of getting  elected. The shuffle function described in the specification appears to match the description in  [HMR12] .    Remediation   We advise performing tests to verify whether the shuffle really behaves randomly.   We do not have a concrete explanation for why validators with large deposits get elected more often as  the validator set grows. We did identify two possible sources of error, though.   First, the rejection sampling variant used in the specification iterates over a random permutation instead  of sampling fresh on every iteration. This discrepancy is measurable with very small sets of validators, but  unlikely to have an impact with many validators. The probability for a validator to get tested for rejection  twice within one function invocation is 0 for the permutation (ignoring the case where all validators have  been rejected), but 1/n^2 for re-sampling with n validators. While we did measure small irregularities for  very small validator sets (up to 16 validators), the data we measured especially shows deviations from the  expected result for large validator sets. This suggests that there is another issue.   The other possible source of error we identified is that the resolution of the rejection test is not high  enough. In each rejection test round, only a single byte is used to sample. The probability of the validator  to be sampled has over 32 bits of resolution. Reading four bytes from the result of the hash function  instead of one should reduce sampling error.   The tests we performed are in the  dist_test  branch of our fork of the  zrnt  repository, as well as PR #9  in our fork of the  eth2.0-specs  repository.   We consider the issue resolved when the provided tests indicate that proposer election rates are in fact  proportional to the effective balance of the validators.   Status   Invalid Issue. We initially ran the tests with the  zrnt  testnet presets. These configured the shuffle  algorithm to only perform 10 instead of 90 rounds, which resulted in statistically significant biases in the  election of block proposers.   Rerunning the test with the mainnet presets did not show these biases. Therefore, the issue does not  apply with the mainnet parameter selection of Ethereum 2.0.   Verification   Not Applicable.    Issue G: Gossipsub Control Message DoS   Location   Libp2p spec control messages    Libp2p gossipsub implementation   Synopsis   The Ethereum 2.0 P2P networking specification relies on libp2p gossipsub. Gossipsub uses an optimistic  push to handle gossiping messages with what are called Control Messages. The control messages in  questions are  IHAVE ,  IWANT , and  GRAFT  that could cause network traffic overhead on a target node.    Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   12   This audit makes no statements or warranties and is for discussion purposes only.        Impact   This overhead could come at sensitive times when the node needs bandwidth to communicate and sync  with other nodes., which may result in reduced rewards (because their attestation is only added to later  blocks) or penalties (if the attack is strong enough to interrupt the service of the validator).   Preconditions   There must be no limits placed on the optimistic pushing of messages, and the message cache of the  target needs to be large enough to be required to send enough data that it hinders the targets connection.   Feasibility   This would only require a single peer and internet connection to cause traffic overhead in the target,  therefore the costs are inexpensive on the attacker side. However, we havent fully investigated the  disparity in relative resource consumption. There is also a tight bound in libp2p on the window of the  cache. A node will request messages that are not in the seen cache, meaning the attacker needs to  generate valid messages not in this cache. The cache is said to hold two minutes of message ID data. A  node will also only respond with data held within the  GossipHistoryGossip  slot length, which is  defaulted to three slots and assumed to be a minimal amount of message history stored, making this a  moderate to low feasibility attack at current understanding.   Technical Details   An example of optimistic pushing that forces network traffic overhead on a target is a sender  S  initiates a  message to a receiver  R  with the control message  IHAVE .  R  then ignores if they have already seen those  ID s and responds to  S  with  IWANT(IHAVE.ids.length()) . The  S  client will then process every  IWANT  ID  in the control message and begin sending all messages in their cache that match the provided IDs.    IHAVE  control messages will trigger a peer to search to see if they have seen this list of message  ID s,  within a default value of two minutes, from the sender of the  IHAVE  message. The attacking client could  be modified here to ignore if the messages have been seen and load an  IWANT  control message with all  of the  IHAVE   ID s where  ID s are in the targets range of [0.. CacheWindow.length ]. The attacker only  needs to send a list of message IDs and the target will reply with up to 1MB message bodies depending  on the message for each ID, potentially inundating the target machine. Alternatively it may be possible to  originate an  IWANT(suspected_ids_target_has)  control message without seeing what the peer  already has and target a peer that isnt actively gossiping with the attacker. If the target node has been  filled with a large cache of messages from the following attack, this may cause a large amount of  messages to be sent.   IWANT  control messages could be forged by an attacker to contain messages  ID s for invalid messages  by first sending to the target an  IHAVE  message for a topic the target is listening to with many invalid  message  ID s. This would cause the target to download and verify the invalid messages sent by the  attacker. If message validation is a slow process, this could consume resources on the targets node. Also  a node may attempt to store old valid messages and wait for the  SEEN cache  timed message cache to  lapse after two minutes and attempt to retransmit old messages that are no longer in the  SEEN cache ,  causing the target to load their  mcache  with a large amount of old messages. If there is no bound  checking on future valid messages, these may also get stored in the  mcache .   Repeated  GRAFT  messages from an attacker to a target may also cause some unwanted network activity  on the target by forcing a  PRUNE  message response. This should cost the attacker as much as the target.   Mitigation   Regulate the amount of messages a peer is willing to store in the  mcache  and respond with in  IWANT  control messages.   Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   13   This audit makes no statements or warranties and is for discussion purposes only.      Remediation   Implementing something more sophisticated than simple regulation like tit-for-tat may be possible. Using  the same or similar research linked to in the Remediation section of  Issue D  could help alleviate this  traffic overhead in an even more sophisticated way. If  S  only responds to  R  with an equivalent amount of  messages that  S  has not already seen from  R , then it makes it harder for  R  to endlessly request data. The  tradeoff for implementing such a strategy is that lagging nodes or new nodes will have a harder time  syncing with the network.   Verification could require simulating game theory strategies for how nodes serve each other data. When it  is not possible or in the best interest of an attacker to perform this attack, it is considered resolved.    Status   According to the Ethereum Foundation team, the following mitigation strategies are in progress:    Protocol Labs libp2p team is working on hardening gossipsub; and   The Ethereum Foundation is working on publishing the details on the protections that will be put   in place, such as peer scoring and blacklisting.   Verification   Unresolved.   Suggestions   Suggestion 1: Improve Specification for ENR and P2P Systems   Synopsis   We found the documentation around the P2P and ENR systems of Ethereum 2.0 to be insufficient.  Specifically, we were unable to conclude how the P2P system incorporates the ENR system. We  recommend a more thorough and detailed document around how the ENR system should work with the  P2P interface and the gossipsub system.   Status   The Ethereum Foundation team states that they are currently working on a bidirectional conversion  function between multiaddr and ENR fields to allow for a canonical construction of a multiaddr from a  discovered ENR, which they intend to submit to the Ethereum 2.0 specifications repository as a PR for  review and integration into the specification.   Verification   Unresolved.   Suggestion 2: Consider Implementing a BAR-Resilient Gossip Protocol   Location   The  specification states  that  gossipsub  will be the protocol used for communication between nodes.   Synopsis   We recommend implementing a BAR-resilient gossip protocol as a way to provide additional guarantees  around node failure and throughput for the network given different conditions of partitions and possible  bad actors.    Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   14   This audit makes no statements or warranties and is for discussion purposes only.          Status   The Ethereum Foundation team has made note of the ongoing efforts with Protocol Labs, the maintainers  of libp2p / gossipsub, to investigate BAR-resilient peer-sampling techniques to harden the protocol. They  also raised questions on how to best achieve Sybil attack resistance in the context of blockchain  networks, as it is suggested in the paper on BAR Gossip,  [LCWNRAD06] , that each participant is limited to  a single identity. In addition, the Ethereum Foundation also made known that a design goal of theirs has  been to avoid the use of validator pubkeys to enhance the P2P layer, in order to avoid coupling validator  identity with node identity and therefore allowing for flexibility for additional potential and sophisticated  validation/network setup designs ( Issue C ).   To note, the abstract principle of BAR-resilient gossip often goes beyond peer-sampling techniques and  also ensures that freeriding off the gossip platform is not possible. At present and to the best of our  knowledge, there is no proof of whether or not such BAR-resilience is possible in an entirely  permissionless system.   Our team proposed looking into BAR-resilient gossiping in order to help prevent greedy participants  freeriding on the gossip system. However, we do not consider Byzantine participants a significant issue,  given that they can only send too few or too many messages. In general, gossip networks do well with  handling participants that forward too few messages, for example when a few nodes completely fail. As a  result, we believe that this does not require further action. Sending too many messages is equivalent to  attempting to overwhelm the recipient with network traffic. While this problem may be resolved on the  gossip layer, it is not on the network layer. Thus, a publicly dialable participant can always be subject to a  DDoS attack.     Since the Ethereum P2P layer only forwards valuable messages, this type of attack does not pose an  application-layer threat. The attacks a Sybil node could launch on the gossip layer are not significantly  more powerful than network layer DDoS attacks (e.g. simple UDP floods). As a result, we consider Sybil  attacks tolerable and mitigating against them to be a lower-priority target.   Verification   Unresolved.   Suggestion 3: Peer Review of Consensus Papers and Proofs    Synopsis   Consensus systems are notoriously difficult to audit. Peer review processes are the de facto standard to  ensure quality research. Since consensus is at the heart of Ethereum 2.0, we recommend a peer review of  the theorems and proofs in the ongoing research on the consensus protocol, described in  [BHKPQRSWZ19] , once finalized.   Status   The Ethereum Foundations team notes that the ongoing research paper combining Casper FFG and  LMD-GHOST,  [BHKPQRSWZ19] , is under final review and near completion. They have stated their intent to  publish the first draft on  arXiv , with the intention of soliciting a community review, before seeking to  publish and submit the paper for peer review in a journal and conference.    Additionally, the Ethereum Foundation team has stated that they are working with Runtime Verification to  formally model the  Beacon Chain Phase 0 Specification in K  and are currently working on formally proving  that the Phase 0 specification correctly implements the theorems and proofs outlined in  [BHKPQRSWZ19] . They have stated their intent to also publish and submit this work to a conference and  journal for peer review.     Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   15   This audit makes no statements or warranties and is for discussion purposes only.        Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Ethereum-2.0-Specifications-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Gossipsub Control Message DoS", "body": "   Location   Libp2p spec control messages    Libp2p gossipsub implementation   Synopsis   The Ethereum 2.0 P2P networking specification relies on libp2p gossipsub. Gossipsub uses an optimistic  push to handle gossiping messages with what are called Control Messages. The control messages in  questions are  IHAVE ,  IWANT , and  GRAFT  that could cause network traffic overhead on a target node.    Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   12   This audit makes no statements or warranties and is for discussion purposes only.        Impact   This overhead could come at sensitive times when the node needs bandwidth to communicate and sync  with other nodes., which may result in reduced rewards (because their attestation is only added to later  blocks) or penalties (if the attack is strong enough to interrupt the service of the validator).   Preconditions   There must be no limits placed on the optimistic pushing of messages, and the message cache of the  target needs to be large enough to be required to send enough data that it hinders the targets connection.   Feasibility   This would only require a single peer and internet connection to cause traffic overhead in the target,  therefore the costs are inexpensive on the attacker side. However, we havent fully investigated the  disparity in relative resource consumption. There is also a tight bound in libp2p on the window of the  cache. A node will request messages that are not in the seen cache, meaning the attacker needs to  generate valid messages not in this cache. The cache is said to hold two minutes of message ID data. A  node will also only respond with data held within the  GossipHistoryGossip  slot length, which is  defaulted to three slots and assumed to be a minimal amount of message history stored, making this a  moderate to low feasibility attack at current understanding.   Technical Details   An example of optimistic pushing that forces network traffic overhead on a target is a sender  S  initiates a  message to a receiver  R  with the control message  IHAVE .  R  then ignores if they have already seen those  ID s and responds to  S  with  IWANT(IHAVE.ids.length()) . The  S  client will then process every  IWANT  ID  in the control message and begin sending all messages in their cache that match the provided IDs.    IHAVE  control messages will trigger a peer to search to see if they have seen this list of message  ID s,  within a default value of two minutes, from the sender of the  IHAVE  message. The attacking client could  be modified here to ignore if the messages have been seen and load an  IWANT  control message with all  of the  IHAVE   ID s where  ID s are in the targets range of [0.. CacheWindow.length ]. The attacker only  needs to send a list of message IDs and the target will reply with up to 1MB message bodies depending  on the message for each ID, potentially inundating the target machine. Alternatively it may be possible to  originate an  IWANT(suspected_ids_target_has)  control message without seeing what the peer  already has and target a peer that isnt actively gossiping with the attacker. If the target node has been  filled with a large cache of messages from the following attack, this may cause a large amount of  messages to be sent.   IWANT  control messages could be forged by an attacker to contain messages  ID s for invalid messages  by first sending to the target an  IHAVE  message for a topic the target is listening to with many invalid  message  ID s. This would cause the target to download and verify the invalid messages sent by the  attacker. If message validation is a slow process, this could consume resources on the targets node. Also  a node may attempt to store old valid messages and wait for the  SEEN cache  timed message cache to  lapse after two minutes and attempt to retransmit old messages that are no longer in the  SEEN cache ,  causing the target to load their  mcache  with a large amount of old messages. If there is no bound  checking on future valid messages, these may also get stored in the  mcache .   Repeated  GRAFT  messages from an attacker to a target may also cause some unwanted network activity  on the target by forcing a  PRUNE  message response. This should cost the attacker as much as the target.   Mitigation   Regulate the amount of messages a peer is willing to store in the  mcache  and respond with in  IWANT  control messages.   Security Audit Report | Ethereum 2.0 Specifications | Ethereum Foundation 6 March 2020 by Least Authority TFA GmbH   13   This audit makes no statements or warranties and is for discussion purposes only.      Remediation   Implementing something more sophisticated than simple regulation like tit-for-tat may be possible. Using  the same or similar research linked to in the Remediation section of  Issue D  could help alleviate this  traffic overhead in an even more sophisticated way. If  S  only responds to  R  with an equivalent amount of  messages that  S  has not already seen from  R , then it makes it harder for  R  to endlessly request data. The  tradeoff for implementing such a strategy is that lagging nodes or new nodes will have a harder time  syncing with the network.   Verification could require simulating game theory strategies for how nodes serve each other data. When it  is not possible or in the best interest of an attacker to perform this attack, it is considered resolved.    Status   According to the Ethereum Foundation team, the following mitigation strategies are in progress:    Protocol Labs libp2p team is working on hardening gossipsub; and   The Ethereum Foundation is working on publishing the details on the protections that will be put   in place, such as peer scoring and blacklisting.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Ethereum-2.0-Specifications-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Weak Scrypt Due to Low Parameters", "body": "  Location  pkg/config/config.go#L19-L22  Synopsis  The scrypt function is a memory hard function designed to securely derive keys from passwords. The caller can specify parameters, such as iterations and required memory. However, the parameters chosen by the client are too low.  Impact  Setting low scrypt parameters more easily facilitates an attackers ability to successfully guess a low-entropy password. This would enable an attacker to unlock a users wallet, which can result in the loss of user funds.  Preconditions  A low-entropy password (which is common) and physical access to the encrypted wallet of the target.  Feasibility  This attack requires signicant computational resources but is technically feasible. This attack is economically feasible if the prots gained from compromising the wallet surpass the costs of the computational resources.  Technical Details  An established standard for scrypt parameters does not exist and the scrypt parameters in Venus are implemented as suggested in an article on scrypt parameters, written in 2017. The Venus implementation makes use of the scrypt parameter recommendations for interactive logins but uses scrypt for computing le encryption keys. These lower interactive login parameter settings produce much higher performance than what is required for unlocking a wallet, resulting in a much lower cost of computing hashes and decreasing the time needed to bruteforce the password.  Remediation  We recommend using a minimum of scrypt parameter N = 1 << 21.  Status  The Venus team has updated the scrypt N parameter to 1 << 21. The lower value 1 << 15 is still used in tests, in order to maintain short test execution times.  Verication  Resolved.  Security Audit Report | Venus | Filecoin Foundation 29 June 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Filecoin_Foundation_Venus_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Node Initialization Loads a Validator for Namespace v", "body": " Accepting Every Message  Location  submodule/network/network_submodule.go#L133  Synopsis  The network submodule uses a DHT validator that allows all records in the v namespace. While the purpose of namespace is unclear, it does constitute a validation bypass.  Impact  Messages in the v namespace are not being adequately validated, which allows unvalidated messages to enter the system. This may interfere with the correct processing of valid messages.  Technical Details  Networked applications should rst check incoming messages for validity. The function that does this is called a validator. In this instance, a validator that allows all messages is explicitly loaded, leading to a bypass of validation.  Remediation  We recommend removing the blankValidator from the DHT initialization.  Status  The Venus team has removed the validator from the initialization.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Filecoin_Foundation_Venus_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Locking a Wallet Requires a Password", "body": "  Location  pkg/wallet/dsbackend.go#L241-L250  Synopsis  The wallet requires the input of the password in order to lock and encrypt the data, slowing the users response to real-world threats, and increasing risk of unauthorized access. When needed, placing a wallet in a locked state must always be easy and quick, enabling a user to secure their assets. Furthermore, a locked wallet would require that a password is entered before new transactions can be made.  Increased diculty in locking the wallet inhibits the user from being able to quickly respond to real-world threats to the security of their digital assets. An attack could be as simple as pushing the user away from the computer and using the unlocked wallet.  Impact  An attacker is able to access an unlocked and unencrypted wallet, which could lead to the loss of user funds.  Preconditions  An attacker must separate the unlocked device from the user before the user is able to lock the device.  Security Audit Report | Venus | Filecoin Foundation 29 June 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend removing the requirement for a password in order to lock the wallet.  Status  The Venus team has changed the implementation so that it no longer requires entering the password for locking the wallet.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Filecoin_Foundation_Venus_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Keys Lack Adequate Protection", "body": "  Location  pkg/wallet/dsbackend.go  Synopsis  Upon locking, the wallet does not delete the Keccak hash of the password from memory, which facilitates ecient password checking. When attempting to unlock the wallet, the password is Keccak-hashed and compared against the stored hash. This operation is very ecient, which is not desirable. Optimally, checking a password should take a long time, in order to make brute-force and dictionary attacks dicult.  The fact that the wallet still contains the Keccak hash in locked states means that an attacker with access to a memory dump of a locked wallet is able to derive the wallet encryption key. If an attacker also has access to the encrypted wallet, this allows them to decrypt the wallet and obtain the secret key.  Additionally, secret keys are never cleared from the memory and may be moved by Gos memory management system or swapped to disk by the operating system, further reducing the security of the secret keys.  Impact  An attacker may get hold of the secret keys of a wallet.  Preconditions  The attacker needs access to the encrypted wallet, in addition to the API or memory of a locked wallet that has been previously unlocked and then locked.  Feasibility  The feasibility varies with the specic setting, but it is to be expected that the attack is possible, yet expensive if the preconditions are fullled. The economic feasibility would be determined by the expected reward of an attack, which may vary.  Technical Details  In Venus, the wallet encryption key is derived from the Keccak hash of the passowrd. Locking the wallet only removes the encryption key, but not the Keccak hash, leaving a critical value in memory. Computing the scrypt hash of a Keccak hash of a password is not a common practice, which we suspect is implemented to speed up the password checking process. This could be counterproductive because slower password checking mechanisms are a good protection against brute force and dictionary attacks.  Security Audit Report | Venus | Filecoin Foundation 29 June 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Keys are also never overwritten with zeros, and no other effort is made to secure secrets stored in memory (e.g. to prevent Gos memory management from copying memory segments arbitrarily). These may also be written to disk for swap and virtual memory, making the secret values even more accessible.  Given that all of these security issues can not be completely remediated, we recommend implementing both the mitigation and the remediation, as detailed below.  Mitigation  We recommend using memguard to protect keys in memory against Gos memory management and the operating systems swap, as well as protect against memory dumps. Memguard provides its own memory management, encrypts the memory contents, and sets a non-swap ag.  To mitigate against secrets written to swap, we recommend advising users to disable or encrypt swap on the machines that they use for Venus.  Remediation  We recommend that the implementation does not compute an intermediate hash and only computes the scrypt hash of the password. When locking, we recommend overwriting the value and all decrypted secrets with zeros.  Status  The Venus team has implemented a change such that all secrets that are kept in memory throughout the run of the program are stored in memguard protected memory. These measures cover the more feasible and likely scenarios of data leakage. However, secret data that is only kept temporarily is often still stored in memory that is managed by the Go runtime, allowing the opportunity for data leakage. While there are some instances where moving secret data from memguard managed memory to runtime managed memory can be avoided, we acknowledge that it is often not possible to use memguard managed memory when interfacing with external code. In this particular instance, the Venus team has no inuence on how allocations are performed externally.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Filecoin_Foundation_Venus_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Incorrect Logic for Comparing Sync Targets Parent Weight and", "body": " Missing Parent Check in IsNeibor Function  Location  chainsync/types/target_tracker.go#L32  Synopsis  When adding a new sync target in the target queue, the new target is compared with its neighbor target of the same parent weight. If the neighbor target is idle, it is replaced by the new target. The function IsNeibor incorrectly checks the equality of the weights of the parents of the two targets, instead of checking that the two targets have the same parents.  Impact  The sync target is merged (replaced) with a new target of the same height, but of a different parent weight or different parents, resulting in an inconsistent chain weight among different clients, potentially delaying or preventing the clients converging into the chain of highest weight or the chain with highest weight among different forks.  Security Audit Report | Venus | Filecoin Foundation 29 June 2021 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  A new sync target of the same height from existing targets is found with different parent weight or different parents, and the current targets syncing state is idle.  Feasibility  This is feasible when syncing,the target tipset is in an idle (waiting) state and a new target tipset of the same height is found but with different parents or different parent weight.  Technical Details  In function IsNeibor,  weightIn := target.Head.ParentWeight()  targetWeight := target.Head.ParentWeight()  if !targetWeight.Equals(weightIn) {  return false  } Weightln and targetWeight is always equal, no check for the two targets having the same parents.  Remediation  We recommend replacing targetWeight := target.Head.ParentWeight() with targetWeight := t.Head.ParentWeight(). Furthermore, we recommend adding parents check for the two target tipsets.  Status  The Venus team has changed the assignment of targetWeight in accordance with the recommendation. The change is based on code which includes the check for equal parents.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Filecoin_Foundation_Venus_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Program Panics if Length of Returned Messages is Less Than", "body": " Length of Tipset Segments Requested  Location  chainsync/syncer/syncer.go#L543-L548  chainsync/exchange/client.go#L165  Synopsis  In syncing with target tipsets, the client must fetch messages (fetchSegMessage) for a segment of tipsets from a peer client. The returned message length could be less than the number of requested tipsets. When processing the returned message for each tipset in a loop over requested tipsets, the program will panic.  Impact  The program will panic and exit unexpectedly.  Security Audit Report | Venus | Filecoin Foundation 29 June 2021 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  The length of the returned message is less than the number of requested tipsets in GetChainMessages when the syncing peer client is down or the network is down.  Feasibility  This is feasible and likely when preconditions are met (i.e. the syncing peer client is down or disconnected due to network problems).  Technical Details  In fetchSegMessage:  messages, err := syncer.exchangeClient.GetChainMessages(ctx, leftChain)  ...  for index, tip := range leftChain {  fts, err := zipTipSetAndMessages(bs, tip, messages[index].Bls,  messages[index].Secpk, messages[index].BlsIncludes, messages[index].SecpkIncludes)  ...  }  Message length might be less than the length of leftChain, in which case the loop over leftChain the program would panic upon reaching the out of range messages index.  Remediation  We recommend checking the length of the return message against the length of the requested tipsets (leftChain) before processing the messages of each tipset (zipTipSetAndMessages). If the length of the return message is less than the length of the requested tipset, process the partially returned messages from requested tipsets and put the unfetched tipset back in the tipset to be requested (leftChain) and refetch it from another peer.  Status  The Venus team has added a condition which returns an error if the length of the messages and tipset are not equal. We recommend implementing a change, which would add the unfetched tipset back to the queue to refetch from another peer, in order to fully resolve the issue.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Filecoin_Foundation_Venus_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Target Queue Size Exceeds the Preset Maximum Size", "body": "  Location  chainsync/types/target_tracker.go#L124  Synopsis  When adding a target tipset to the target queue, an extra target will be added to the queue when queue size already reaches the preset max size (bucket size).  Security Audit Report | Venus | Filecoin Foundation 29 June 2021 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   Impact  This would result in minimal impact to the functioning of the program, but it would cause confusion and inconsistency in the code.  Technical Details  In add():  if len(tq.q) <= tq.bucketSize {  tq.q = append(tq.q, t)  }  When len(tq.q)== tq.bucketSize, a new target will still be added to the queue.  Remediation  We recommend replacing .len(tq.q) <= tq.bucketSize with len(tq.q) < tq.bucketSize.  Status  The Venus team has resolved the off-by-one error.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Filecoin_Foundation_Venus_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: The BN254 Curve Provides Insufficient Security", "body": "   Location   /CMakeLists.txt#L47-L53   Synopsis   Loopring uses a variant of the BN254 curve. In 2016, advances in number theory led to a lower security  estimate of that curve. Specifically, its security is now considered to be around 96 bits. This is  significantly lower than the 112 bits required by NIST for new products.     Impact   Use of the BN254 curve undermines the security of the zk-SNARK scheme, such that the feasibility of  computing valid, forged proofs cannot be ruled out. Such proofs would pass validation, yet violate the  constraints imposed by the circuit. For example, a valid, forged proof could increase or reduce the  balance of accounts arbitrarily.    Preconditions   In Loopring, only proofs published by the operator are considered. As a result, an attacker needs access  to the operators keys, either through being the operator or through having gained access to them by  different means.   Feasibility   The exact feasibility is difficult to estimate. However, the potential gains from a successful attack are  high, which suggests that an attacker would have incentive to invest significant resources.   Technical Details   Attacks based on the Tower Number Field Sieve (TNFS) and the derivative exTNDS and SexTNFS have led  to a reduced estimate of the security level of BN254. The several scholars and practitioners working on  this issue do not entirely agree on the new estimate, but opinions range from 96 bits to 110 bits [ KB15 ,  MSS16 ,  BD17 ,  Perrin16 ]. Regardless of where on this spectrum the real value falls, it is still too low. Even  for applications that only need to remain secure until 2030, NIST requires a security level of at least 112  bits [ B20 , Table 4], which BN254 does not achieve.   Mitigation   This attack can be detected, however, it would require that one or more parties permanently check for  forged proofs.    Remediation   We recommend using the curve BLS12-381. According to the draft RFC on pairing-friendly curves [ Sakemi  et al. 20 ], it has a security level of ~128 bits, which is above the 112 bits considered sufficient by NIST  until 2030.    The Berlin hard fork, which is planned to take place in January 2021, will bring precompiled contracts  support for operations on this curve. This will make using the curve viable. Given the potentially high   Security Audit Report | Loopring 3.6 Design + Implementation: Circuit | Loopring 16 March 2021 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.          incentive for launching such an attack, running a new trusted setup computation to generate a required  common reference string for BLS12-381 should be strongly considered. As a result, we recommend this  approach as an appropriate long-term solution for Loopring.    Status   The Berlin hard fork upgrade will no longer contain EIP-2537, as originally planned at the time we  delivered the  Initial Audit Report . As a result, 384 bit arithmetic in the EVM (i.e. EVM-384) is currently  unavailable. Given this change, there is currently no efficient method for secure pairing based  cryptography that is able to achieve at least 112 bits of security as required by NIST for new products.  Thus, a long-term remediation is not currently possible and we recommend that the Loopring team  continue to monitor developments with EIP-2537.    Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Loopring_3.6_Design_Implementation_Circuit_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Stealth Addresses Provide Only 64-Bit of Security by Default", "body": "  Location  src/classes/RandomNumber.ts#L37  Synopsis  In the Umbra Protocol, as implemented by umbra-js, stealth addresses are derived from spending keys by scalar multiplication with random numbers. However, these numbers only contain 128 bits of randomness by default, in addition to 128 bits that can be used for short messages but are zeroes by default. In elliptic curve cryptography, 128 bits of randomness translates to 64 bits of security, which is insucient.  Impact  Stealth addresses may be brute force derivable from spending keys and vice versa.  Preconditions  The attack assumes that the sender does not ll up the upper 16 bytes of the random number with cryptographically strong randomness on their own. In addition, the attacker needs access to the stealth address public key, which is given if the target account has signed a transaction (e.g. a withdrawal).  Feasibility  The attack only requires to run a standard brute force discrete log algorithm, such as the Pollard-Rho method, which is feasible for short secret values. For similar problems in secp256k1, practical attacks already exist, with readily available code. As a result, we estimate that it is not dicult to adapt the code to the context of the Umbra Protocol.  Technical Details  In the Umbra Protocol, spending keys as well as stealth addresses are points on the elliptic curve secp256k1, where secret keys have a size of 256 bits. If a spending key address key  is computed as the secp256k1 scalar multiplication of a random number  is given, any associated stealth \ud835\udc5f , supposed to  \ud835\udc5d\ud835\udc58  \ud835\udc5d\ud835\udc58 \ud835\udc60  be from the secp256k1 scalar eld, with the spending key, specically,    =  [\ud835\udc5f] \ud835\udc5d\ud835\udc58 \ud835\udc5d\ud835\udc58 \ud835\udc60  For an attacker, associating any stealth address public key to a given spending key is as dicult as nding a discrete log relation between the two curve points. For cryptographically strong 256-bit random numbers r, this should provide roughly 128-bit security, assuming that the fastest algorithms, such as the Pollard-Rho method, have runtimes in the order of 2^(len(r)/2). The random number is then encrypted and published on-chain.  However, the Umbra Protocol only uses the lower 16 bytes of the random number, overwriting the upper 16 bytes with zeros by default, which then only gives roughly 64 bits of security. The purpose is to give the sender 16 bytes of space to transmit encrypted short messages, along with the actual randomness to the public key owners.  NIST 800-131A [BR19] presents the security level to target, which for all classes of protocols does not consider anything below 112-bit security and corresponding elliptic curve key lengths of 224 bits to be suciently secure.  Security Audit Report | Umbra-js | ScopeLift 25 May 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation  If a message or memo eld is required and a security level below 128 bits is acceptable, we recommend choosing the bit lengths of the memo eld f_memo and random data f_rand, such that the sum is 256 bits. This results in a security level of at least len(f_rand)/2.  From these bit lengths, a uniformly random scalar eld element (i.e. a number less than group order n) must be computed. To do so, we recommend using a hash function or an extractor like HKDF-Extract (which is just a way of using HMAC) to extract a 256-bit value sk_stealth from the SMS and random value. If sk_stealth >= n, pick a new random number and try again. This should be repeated until an appropriate value is found. Submit the encryption of f_memo and f_rand as usual and the receiver can try to decrypt, extract the value, and check if the stealth address matches. If it does not match, or if the announcement extracts to a value >= n, they can then deduce that they are not the recipient.  In addition, we recommend updating the Umbra documentation to reect the changes to the protocol, as well as the reasoning behind the chosen lengths and security parameters.  Remediation  We recommend using the full 256 bits from the curves scalar eld as the random number.  In addition, we recommend updating the Umbra documentation to reect the changes to the protocol, as well as the reasoning behind the chosen lengths and security parameters.  Status  The ScopeLift team has updated the code to use the entire 256 bits of randomness for the random number. Additionally, the update removes support for memos or messages, leading to full 128-bit security.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_ScopeLift_Umbra-js_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Group Membership of Public Keys Not Checked", "body": "  Location  src/classes/KeyPair.ts#L59  Synopsis  In umbra-js, parties may read public keys from untrusted sources. These public keys are binary representations of points that are supposedly on the elliptic curve. However, not all binary strings are representations of valid curve points.  Impact  Publishing results of computations on invalid curve points may leak sensitive data that contains or allows inference or linking of key material. This issue specically impacts the handling of uncompressed curve points, since compressed curve points are implicitly checked for validity during decompression. In addition, not checking for public key validity puts the privacy of the recipient of a transaction at risk.  Preconditions  The public key must enter the system in uncompressed form and not be validated. The attacker must pick a point in a compatible, yet weak curve.  Security Audit Report | Umbra-js | ScopeLift 25 May 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  The attack requires some computational resources, but not enough to make the attack infeasible.  Technical Details  Elliptic curve public keys are points and often are described using the two ane coordinates x and y. However, only the points that satisfy the respective curve equation are valid public keys. Public keys entering the system need to be validated. For compressed points this happens implicitly, because the y coordinate is not transmitted in full and is found by solving the curve equation, which means the equation is trivially satised or the decompression fails. For uncompressed points, however, validity needs to be checked explicitly.  Failure to check public key validity could make the protocol vulnerable to invalid curve attacks described in [ABM+03], which further lead to small subgroup attacks and the possibility of weak shared secrets being used, allowing an attacker to compute encryption keys or stealth addresses.  Remediation  We recommend consistent checking of whether uncompressed public keys fulll the curve equation by adding a check to the respective part in the constructor of the KeyPair class.  Status  The ScopeLift team updated the umbra-js library to check if the elliptic curve equation is satised when working with uncompressed keys.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_ScopeLift_Umbra-js_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: noble-secp256k1 Contains Bias in Private Key Generation", "body": "  Location  noble-secp256k1/  Synopsis  Umbra-js utilizes noble-secp256k1 version 1.2.0 which contains a slight bias in the private key generation.  Impact  The bias slightly increased the probability of generating insecure encryption and stealth keys, which would have led to linkability of stealth addresses to real addresses.  Remediation  We recommend updating noble-secp256k1 to the latest version.  Status  The ScopeLift team updated noble-secp256k1 to version 1.2.5, as recommended.  Verication  Resolved.  Security Audit Report | Umbra-js | ScopeLift 25 May 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_ScopeLift_Umbra-js_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Incorrect Implementation of deleteBeneciary", "body": "  Location  contracts/TokenVesting.sol#L395-L403  Synopsis  In the deleteBeneficary function, there is no check to test if _beneficiary is not a zero address. There is also no check to verify if the beneciary being deleted actually exists. In both cases, the function loops through the entire vestingSchedulesNames array needlessly. Additionally, if the _beneficiary does exist, the function loops through the vestingScheduleNames array rather than those related to the particular beneciary only.  In the zero address case, a new zero address beneciary is added to the mapping of beneciaries for every vestingScheduleName, if it is the rst time calling with a zero address. Otherwise, it is an unnecessary update of a previously added zero address.  For the non-existing address case, a new beneciary is added to the mapping of beneciaries for every vestingScheduleName with that address if it is the rst time calling with a non-existing address. Otherwise, it is an unnecessary update of a previously added non-existing address.  Additionally, when there is no beneciary for any vestingSchedulesNames[i], it redundantly performs operations, and another beneciary may be added for vestingSchedulesNames[i].  Impact  In the rst two cases, an incorrect event is emitted at the end of the function because it did not actually delete anything but rather added to the mapping. In every case, it results in the further consumption, and eventual loss, of gas. Additionally, the incorrect event results in misinterpretation of the state of the contract for external entities (whoever is watching for that event).  Security Audit Report | Data Lake Smart Contracts | Data Lake 5 December 2022 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  This issue is possible if the _beneficiary is a zero address or if there is no beneciary with such an address. It is also possible if the beneciary has no allocation in a VestingSchedule, which has vestingSchedulename = vestingSchedulesNames[i].  Mitigation  We recommend implementing a check that the _beneficiary is not a zero address. Additionally, as suggested by the Data Lake team during the audit, we recommend nding the list of active vesting schedule names, checking the length of the list, and reverting if the length of the list is not greater than zero.  Moreover, we recommend only looping through those vestingScheduleNames,which are related to the particular beneciary using active vesting schedule names to avoid redundancy. The implementation could be as follows:  require(_beneficiary != address(0x0));  string[] memory scheduleNames = getBeneficiaryActiveScheduleNames(_beneficiary);  uint32 activeSchedulesLength = scheduleNames.length;  require(activeSchedulesLength > 0);  for (uint32 i = 0; i < activeSchedulesLength; i++) {  uint256 unreleasedAmount =  getBeneficiaryUnreleasedAmount(_beneficiary, vestingSchedulesNames[i]);  beneficiaries[_beneficiary][scheduleNames[i]].allocatedAmount -=  unreleasedAmount;  vestingSchedules[scheduleNames[i]].allocatedAmount -=  unreleasedAmount;  }  Status  The recommended check has been implemented in the deleteBeneficary function.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Data%20Lake%20Token_Vesting_Smart%20Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Incorrect Implementation of addVestingScheduleAllocation and", "body": " removeVestingScheduleAllocation  Location  contracts/TokenVesting.sol#L290-L294  contracts/TokenVesting.sol#L301-L305  Security Audit Report | Data Lake Smart Contracts | Data Lake 5 December 2022 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The above-referenced functions are missing necessary checks and adjustments or execute incorrect adjustments:  1. The addVestingScheduleAllocation function does not check if the contract has enough  unused balance to dedicate to the particular vesting schedule: require(getUnusedAmount() >= _amount). As a result, the amount of balance dedicated to all vesting schedules could exceed the smart contracts balance, rendering the smart contract unable to pay for all vesting schedules;  2. The removeVestingScheduleAllocation function does not check if the schedule has  enough unallocated tokens to deduct from: require(getScheduleUnallocatedAmount(_name) >= _amount). If the amount deducted is more than a particular vesting schedules unallocated amount, the smart contract would lose track of the vestingSchedulesTotalAmount, assuming the amount allocated to beneciaries is less than what it actually is, which may result in it being unable to pay for all vesting schedules;  3. Both functions do not check if a VestingSchedule function with the particular _name  argument exists. In the case of addVestingScheduleAllocation, the operation would pass and a new VestingSchedule would be added to the vestingSchedules mapping, with vestingSchedule.totalAmount = _amount. In the case of removeVestingScheduleAllocation, it would revert due to an unpredicted underow: vestingSchedules[_name].allocatedAmount -= _amount  4. Both functions incorrectly adjust vestingSchedules[_name].allocatedAmount instead of  vestingSchedules[_name].totalAmount. This might lead to the track of the actual vestingSchedule.allocated amount being lost, resulting in incorrect calculations in the functions getScheduleLockedAmount and getScheduleUnallocatedAmount. Consequently, the claimTokens function could behave unexpectedly; and  5. Both functions are missing the necessary adjustments of vestingSchedulesTotalAmount by  the amount increased or decreased: vestingSchedulesTotalAmount += _amount;  vestingSchedulesTotalAmount -= _amount;  In both increase and decrease cases, the vestingSchedulesTotalAmount would indicate an incorrect state of the amount reserved for all vesting schedules, resulting in the getUnusedAmount function incorrectly calculating the remaining balance to be allocated for vesting schedules.  Mitigation  We recommend implementing these functions as follows:  addVestingScheduleAllocation:  function addVestingScheduleAllocation(uint256 _amount, string calldata _name) external onlyOwner {  require(!paused, 'TokenVesting: Contract is paused!');  require(_amount != 0, 'TokenVesting: amount must be bigger than  zero');  //This line checks if the vesting schedule is valid (exists)  Security Audit Report | Data Lake Smart Contracts | Data Lake 5 December 2022 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   require(isVestingScheduleValid(_name), \"Vesting schedule is not  valid\");  //Add this check to ensure the contract has enough unused balance  require(getUnusedAmount() >= _amount, \"_amount cannot be greater the  unused balance\");  //Add the following line and remove the previous line to adjust  vestingSchedule's totalAmount instead of allocatedAmount.  vestingSchedules[_name].totalAmount += _amount;  //Add this line to perform necessary adjustment of  vestingSchedulesTotalAmount  vestingSchedulesTotalAmount += _amount;  }  RemoveVestingScheduleAllocation:  function removeVestingScheduleAllocation(uint256 _amount, string calldata _name) external onlyOwner {  require(!paused, 'TokenVesting: Contract is paused!');  require(_amount != 0, 'TokenVesting: amount must be bigger than  zero');  //This line checks if the vesting schedule is valid (exists)  require(isVestingScheduleValid(_name), \"Vesting schedule is not  valid\");  //Add this check to ensure the schedule has enough amount of  unallocated tokens to deduct from  require(getScheduleUnallocatedAmount(_name) >= _amount, 'TokenVesting:  amount cannot be greater than vesting schedule unallocated amount');  //Add the following line and remove the previous line to adjust  vestingSchedule's totalAmount instead of allocatedAmount.  vestingSchedules[_name].totalAmount -= _amount;  //Add this line to perform necessary adjustment of  vestingSchedulesTotalAmount  Security Audit Report | Data Lake Smart Contracts | Data Lake 5 December 2022 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   vestingSchedulesTotalAmount -= _amount;  }  Status  The referenced functions have been reimplemented according to the recommendation.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Data%20Lake%20Token_Vesting_Smart%20Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: BlackList Manager Can Blacklist TokenVesting Smart Contract", "body": "  Location  contracts/access/BlacklistManager.sol#L68-L74  Synopsis  In the addToBlacklist function, there is no check to verify if the address being blacklisted is not the TokenVesting smart contract.  Impact  If this happens for any reason, the TokenVesting smart contract would not be able to send $LAKE tokens until it is removed from the blacklist.  Mitigation  We recommend adding a check in the addToBlackList function to identify that the blacklisted address is not the TokenVesting smart contract address.  Status  A check has been implemented to the addToBlacklist function.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Data%20Lake%20Token_Vesting_Smart%20Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: claimTokens Does Not Deduct the vestingSchedulesTotalAmount", "body": " by the Amount Claimed (Known Issue)  Location  contracts/TokenVesting.sol#L482-L507  Synopsis  The Data Lake developer team raised this issue during the audit and noted that the allocated tokens, which had been claimed, were not deducted from the vestingSchedulesTotalAmount.  Impact  If the allocated tokens, which were claimed, were not deducted from the vestingSchedulesTotalAmount, this could prevent the creation of new vesting schedules and/or allocations.  Security Audit Report | Data Lake Smart Contracts | Data Lake 5 December 2022 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  The Data Lake team resolved this issue by deducting the vestingSchedulesTotalAmount by the amount claimed.  Status  The Data Lake smart contracts team resolved the issue.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Data%20Lake%20Token_Vesting_Smart%20Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Centralized Ownership of Smart Contracts", "body": "  Location  Example (non-exhaustive):  contracts/TokenVesting.sol#L831-L835  Synopsis  The smart contracts in scope, which include the functions for changing the owner, are heavily dependent on the owner.  Impact  If the owner is set incorrectly, the functionality that depends on it will break and negatively impact the protocol, rendering it almost unusable.  Mitigation  We recommend that a two-step process be used whereby in the rst step, a new owner is proposed, and in the second step, the previous owner remains in charge until the newly appointed owner claims the owner rule.  Status  The recommended mitigation has been implemented.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Data%20Lake%20Token_Vesting_Smart%20Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Unchecked Return Value from the ERC-20 Token Transfer", "body": "  Location  contracts/tokenvesting#L141  Synopsis  The return value from the token transfer should be checked to verify that the transaction has been executed successfully.  Impact  This issue could result in the ERC-20 Token transfer failing silently, thereby affecting the token accounting process.  Security Audit Report | Data Lake Smart Contracts | Data Lake 5 December 2022 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation  We recommend the use of SafeTransfer from the OpenZepplin library.  Status  The use of the recommended library has been implemented.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Data%20Lake%20Token_Vesting_Smart%20Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Missing Zero Check for terms in createVestingSchedule Function", "body": "  Location  contracts/TokenVesting.sol#L188-L219  Synopsis  In the createVestingSchedule function, there is no check to verify if the terms argument being passed is not zero. Consequently, a vestingSchedule with zero terms could be added.  Impact  This would result in incorrect calculations in every function which uses vestingSchedule.terms. The following are two prominent cases:  First, the isVestingScheduleFinished function would immediately return true after the vestingSchedule.cliff time has passed without taking the vestingSchedule.duration into account.  Second, the getPassedVestings function will always revert due to a division by zero.  Preconditions  The passed terms argument to the createVestingSchedule function is zero.  Mitigation  We recommend adding a zero check for terms in the createVestingSchedule function.  Status  A zero check has been implemented in the createVestingSchedule function as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Data%20Lake%20Token_Vesting_Smart%20Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Insufcient Argument Validation in Encryption Functions", "body": "  Location  storage/utils/crypto.ts  Synopsis  The function takes a boolean ag derive, a key, and a value. The key may be a string or a Uint8Array. If derive is set or the key does not have a length of 32, the scrypt password hashing function is used to derive a strong key.  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   It can be assumed that the caller only expects the function to derive a key when derive is set. This means that the function is too liberal in its inputs: If the caller mistakenly assumes that they pass a 32-byte Uint8Array, but accidentally pass, for example, an uninitialized array, and set derive to false, the function will use an encryption key derived from an empty array.  Impact  This Issue could result in keys being stolen, or the loss of funds.  Preconditions  An attacker would need access to encrypted data, for example, by stealing the browser prole.  Feasibility  Our team did not nd a way to exploit the attack, given how the function is used in the rest of the codebase.  Remediation  The Issue occurs as a result of:  1. Being liberal in the inputs in the face of conicting inputs; and 2. One function, which is controlled by a Boolean ag argument, being used to perform two separate  tasks.  The rst can be resolved by returning an error when derive == false and key.length != 32. However, this approach results in code that is disorganized and dicult to read. Instead, we recommend splitting the function into two parts: One function encryptWithKey that takes a Uint8Array, which is checked to have a length of 32, and another function encryptWithPassword that takes a string, which is used to derive a key and then calls encryptWithKey. The caller can then call the appropriate function depending on the context.  Status  The Ava Labs team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/151223_ava-labs_avalanche-browserextension-and_sdk-3rd-review_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Insufcient Key Derivation Strength", "body": "  Location  storage/utils/crypto.ts  Synopsis  The browser extension uses the scrypt password hashing function with parameters N = 1<<15, r = 8, p = 1. This matches the recommendations for interactive logins, but since the situation requires le encryption, this is insucient.  Impact  This Issue could result in keys being stolen, or the loss of funds.  Preconditions  An attacker would need access to encrypted data, for example, by stealing the browser prole.  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  This type of exploit requires signicant but realistic computation power.  Remediation  We recommend either increasing N to 1<<20 or using Argon2id with parameters t=3, p=4, m=64MiB, and 16-byte salt, as recommended in section 4 of RFC 9106.  Status  The Ava Labs team has resolved this Issue by implementing a parallelism factor parameter of 1, which does not affect security.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/151223_ava-labs_avalanche-browserextension-and_sdk-3rd-review_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Mnemonic Sampling May Fail", "body": "  Location  Onboarding/CreateWallet/ConfirmMnemonic.tsx#L34  Onboarding/CreateWallet/ConfirmMnemonic.tsx#L52  Synopsis  The code written for randomly sampling mnemonics may yield an array index out of range error.  Impact  This Issue could result in users being unable to complete the onboarding process.  Technical Details  The function Math.random generates a random decimal number between 0 (inclusive) and 1 (exclusive), as per the MDN documentation:  Math.ceil(Math.random() * wordCount - 1);  Consequently, the aforementioned function can potentially produce an invalid index when Math.random returns zero or a value very close to zero. This is because subtracting 1 from a small decimal number can result in a -1, and Math.ceil will round this up to -1, thus leading to an incorrect array index.  Remediation  We recommend using Math.floor to round the randomly generated number as follows:  Math.floor(Math.random() * wordCount);  In this corrected code, Math.random() * wordCount produces a oating-point number in the range [0, wordCount). Then, Math.floor rounds this number down to the nearest whole number, resulting in an integer in the range [0, wordCount - 1], which is the correct range of valid indices for an array of length wordCount.  Status  The Ava Labs team has resolved this Issue by implementing the remediation as recommended.  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/151223_ava-labs_avalanche-browserextension-and_sdk-3rd-review_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Insecure Calls to window.open", "body": "  Location  Examples (non-exhaustive):  pages/Wallet/WalletRecentTxs.tsx#L352  components/common/CameraAccessPromptDialog.tsx#L55  settings/pages/Legal.tsx#L46  pages/Bridge/BridgeTransactionStatus.tsx#L267  Synopsis  The code uses the window.open method in multiple places to link and redirect users to external pages without explicitly setting the noopener attribute. The noopener attribute, when used with the window.open method, serves as a security feature to prevent newly opened windows or tabs from accessing the window.opener object of the parent window. This feature is crucial in safeguarding against potential security vulnerabilities, particularly cross-site scripting (XSS) attacks.  Impact  If an attacker manages to exploit this omission, they can gain access to the window.opener object of the parent window from a child window or tab. This access allows malicious scripts running in the child window to manipulate or interact with the parent window, potentially leading to unauthorized actions, data theft, or other security breaches.  Preconditions  This Issue can be exploited if:  1. A new window or tab is opened using the window.open method, establishing a parent-child  relationship between them;  2. The noopener attribute is not included as part of the window.open method when opening the  new window or tab;  3. The attacker has the ability to execute malicious scripts within the child window or tab; and 4. Either the use case has an explicit noopener attribute explicitly set or users use browser  versions that do not implement this spec change.  Remediation  We recommend reviewing the existing usages of the window.open method across the codebase and always using the noopener attribute explicitly when utilizing the window.open method to open new windows or tabs by including the noopener attribute as an argument. This attribute prevents the child window or tab from accessing the window.opener object of the parent window.  Status  The Ava Labs team has resolved this Issue by adding the noreferrer ag, which is even more restrictive than noopener, to all instances of window.open.  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/151223_ava-labs_avalanche-browserextension-and_sdk-3rd-review_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue E: Recovery Phrase Is Stored in Clipboard", "body": "  Location  Onboarding/CreateWallet/CopyPhrase.tsx  Synopsis  The mnemonic phrase used to derive the Avalanche browser extension wallet keys is accessible to all applications that have access to Clipboard. Clipboard is a global object that is accessible across application security boundaries. Applications watching Clipboard will be able to see the mnemonic when the user copies it to Clipboard.  Impact  This Issue could result in the loss of funds or a complete wallet takeover.  Preconditions  An attacker would need to infect the victims PC with a Clipboard hijacker malware or any other malicious Clipboard monitoring process. This can also occur if a user installs a malicious browser extension with the required permissions, or in the event that the browser was previously compromised and an extension was installed without the user's knowledge.  Technical Details  The mnemonic phrase may be copied to Clipboard upon nishing the registration process. The Clipboard is considered a public medium, which can be accessed by almost any program or process running on the users device, without any prior permission or notication.  Remediation  We recommend preventing the mnemonic phrase from being saved to Clipboard. Instead, we recommend requiring users to write down the mnemonic phrase in a place off of the lesystem of their device and continuing to require the user to conrm the mnemonic phrase, which helps to conrm that the user has actually written it down.  Note that this Issue was reported in our previous review, and the Ava Labs team decided not to address it, stating that they want to continue providing a copy button for a smoother user experience. Hence, we are reporting it again.  Status  The Ava Labs team decided to not resolve this Issue, as they found it would have a negative impact on user experience.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/151223_ava-labs_avalanche-browserextension-and_sdk-3rd-review_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue F: No User Controls Over Wallets Session Management", "body": "  Location  services/lock/LockService.ts#L81  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   services/lock/models.ts#L7  Synopsis  The Avalanche browser extension wallet implements an auto-locking mechanism, which is hard coded to a 12-hour interval. As a result, the wallet remains unlocked for an extended period of time unless a user manually activates the locking mechanism or closes the browser running the extension. Users have no control over auto-locking intervals. A user who leaves their wallet-hosting device unattended or gets infected with a Remote Access Trojan (RAT) is vulnerable to losing funds. An unlocked wallet gives an attacker an additional advantage, particularly because signing a transaction or removing the wallet account does not require password authentication if the wallet is unlocked. This is considered an insecure practice, as users have a propensity to forget locking their wallets.  Impact  Once a user has logged into their wallet by providing a password, the password is stored in Chromes session storage with a key named SESSION_AUTH_DATA_KEY.  For example, the plaintext value of the password can be extracted through Chromes Developer Tools as follows:  chrome.storage.session.get(\"SESSION_AUTH_DATA_KEY\", result=> console.log(result))  Persisting the wallet access sessions unnecessarily for an extended period of time increases the attack window in which an attacker can take advantage of the system.  Remediation  We recommend that the Ava Labs team implement a user-controllable auto-lock feature and activate it by default for all users. Additionally, we recommend adding a warning of possible hazards to users who try to disable it. Furthermore, we recommend that users be required to authenticate their identity by inputting the password to sign transactions and remove a wallet account.  Note that this Issue was reported in our previous review, and the Ava Labs team decided not to address it, stating that implementing the auto-lock feature can have implications for user experience with regards to dApp connections. Hence, we are reporting it again.  Status  The Ava Labs team decided to not resolve this Issue, as they found it would have a negative impact on user experience.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/151223_ava-labs_avalanche-browserextension-and_sdk-3rd-review_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue G: Low Entropy Passwords Are Allowed Upon New Wallet Creation", "body": "  Location  pages/Onboarding/CreatePassword.tsx#L51  Synopsis  In the current implementation, the user password strength checking mechanism is only utilized for password changes and not during the initial onboarding process. As a result, a user can select an insuciently secure password during the initial onboarding to the Avalanche browser extension wallet.  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Impact  Weak passwords leave the wallet susceptible to dictionary attacks. An attacker who is able to guess the user password can take complete control of the wallet.  Preconditions  The attacker would need to have access to either the encrypted mnemonic or the extension.  Remediation  The strength check that is currently performed when the user changes their password should also be performed during the initial onboarding to the Avalanche browser extension wallet. We recommend using the dropbox/zxcvbn library for a password composition policy intended to prevent the use of passwords obtained from previous breaches, common passwords, and passwords containing repetitive or sequential characters, as recommended by the NIST guidelines noted in [GFN+17]. Finally, we recommend requiring that all passwords meet zxcvbns strength rating of 4.  Note that this Issue was reported in our previous review, and the Ava Labs team decided not to address it, as they considered it to be a low threat vector. Hence, we are reporting it again.  Status  The Ava Labs team has implemented the zxcvbn library as recommended; however, users are required to choose a password strength of at least 2, which is below the [safely unguessable] standard of 3 .  Verication  Partially Resolved.  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   About Least Authority  We believe that people have a fundamental right to privacy and that the use of secure solutions enables people to more freely use the Internet and other connected technologies. We provide security consulting services to help others make their solutions more resistant to unauthorized access to data and unintended manipulation of the system. We support teams from the design phase through the production launch and after.  The Least Authority team has skills for reviewing code in multiple Languages, such as C, C++, Python, Haskell, Rust, Node.js, Solidity, Go, JavaScript, ZoKrates, and circom, for common security vulnerabilities and specic attack vectors. The team has reviewed implementations of cryptographic protocols and distributed system architecture in cryptocurrency, blockchains, payments, smart contracts, zero-knowledge protocols, and consensus protocols. Additionally, the team can utilize various tools to scan code and networks and build custom tools as necessary.  Least Authority was formed in 2011 to create and further empower freedom-compatible technologies. We moved the company to Berlin in 2016 and continue to expand our efforts. We are an international team that believes we can have a signicant impact on the world by being transparent and open about the work we do.  For more information about our security consulting, please visit https://leastauthority.com/security-consulting/.  Our Methodology  We like to work with a transparent process and make our reviews a collaborative effort. The goals of our security audits are to improve the quality of systems we review and aim for sucient remediation to help protect users. The following is the methodology we use in our security audit process.  Manual Code Review  In manually reviewing all of the code, we look for any potential issues with code logic, error handling, protocol and header parsing, cryptographic errors, and random number generators. We also watch for areas where more defensive programming could reduce the risk of future mistakes and speed up future audits. Although our primary focus is on the in-scope code, we examine dependency code and behavior when it is relevant to a particular line of investigation.  Vulnerability Analysis Our audit techniques include manual code analysis, user interface interaction, and whitebox penetration testing. We look at the project's website to get a high level understanding of what functionality the software under review provides. We then meet with the developers to gain an appreciation of their vision of the software. We install and use the relevant software, exploring the user interactions and roles. As we do this, we brainstorm threat models and attack surfaces. We read design documentation, review other audit results, search for similar projects, examine source code dependencies, skim open issue tickets, and generally investigate details other than the implementation. We hypothesize what vulnerabilities may be present and possibly resulting in Issue entries, then for each, we follow the following Issue Investigation and Remediation process.  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Documenting Results We follow a conservative and transparent process for analyzing potential security vulnerabilities and seeing them through successful remediation. Whenever a potential issue is discovered, we immediately create an Issue entry for it in this document, even before having veried the feasibility and impact of the issue. This process is conservative because we document our suspicions early even if they are later shown to not represent exploitable vulnerabilities. We generally follow a process of rst documenting the suspicion with unresolved questions, then conrming the issue through code analysis, live experimentation, or automated tests. Code analysis is the most tentative, and we strive to provide test code, log captures, or screenshots demonstrating our conrmation. After this, we analyze the feasibility of an attack in a live system.  Suggested Solutions We search for immediate and comprehensive mitigations that live deployments can take, and nally, we suggest the requirements for remediation engineering for future releases. The mitigation and remediation recommendations should be scrutinized by the developers and deployment engineers, and successful mitigation and remediation is an ongoing collaborative process after we deliver our Initial Audit Report, and before we perform a verication review.  Before our report, including any details about our ndings and the solutions are shared, we like to work with your team to nd reasonable outcomes that can be addressed as soon as possible without an overly negative impact on pre-existing plans. Although the handling of issues must be done on a case-by-case basis, we always like to agree on a timeline for a resolution that balances the impact on the users and the needs of your project team.  Resolutions & Publishing Once the ndings are comprehensively addressed, we complete a verication review to assess that the issues and suggestions are suciently addressed. When this analysis is completed, we update the report and provide a Final Audit Report that can be published in whole. If there are critical unaddressed issues, we suggest the report not be published and the users and other stakeholders be alerted of the impact. We encourage that all ndings be dealt with and the Final Audit Report be shared publicly for the transparency of efforts and the advancement of security learnings within the industry.  Security Audit Report | Avalanche Browser Extension + SDK (3rd Review) | Ava Labs 15 December 2023 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.  ", "html_url": "https://leastauthority.com/151223_ava-labs_avalanche-browserextension-and_sdk-3rd-review_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: The Governance Mechanism is Underspecied", "body": "  Location  https://docs.youves.com/governance/Governance-Mechanism  Synopsis  Governance decisions regarding the tuning and maintenance of the system are made via a multisignature contract in which four of seven keyholders are required to make important changes. One of the keys is held by ubinetic and the remaining six by independent parties. However, the documentation doesnt specify who these parties are. A governance token (YOU) has been well-dened but the means by which it will be used for voting has not.  Impact  The current Youves platform provides a foundation for a solid governance system but until the system is implemented the platform cannot truly be characterized as decentralized. Users of the system are incentivized to engage with the platform over long periods of time by locking up collateral, saving  Security Audit Report | Synthetic Asset Platform Smart Contracts | Tezos Foundation 21 September 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   synthetic asset tokens, and staking governance tokens. Through non-transparent governance decisions these incentives could change to the disadvantage of the users.  Mitigation  We recommend adding a warning to the Risks section of the documentation that the governance features are incomplete and that decision making power is not transparent.  Remediation  We suggest implementing formal processes and structures for voting using the governance tokens. Additionally, we encourage the ubinetic team to consider best practices as adopted by MakerDAO such as correlating voting power with stake, run governance polls, and provide a governance portal. Finally, we recommend implementing timelocks for important decisions so that questionable decisions can be reversed and/or invested users can have an opportunity to exit their positions before being impacted by them.  Status  The ubinetic team has provided additional clarication about the keyholding parties and their aliations, as well as potential risks in the governance mechanism. This helps create a better understanding of the systems operation in contrast to other stablecoin systems.  However, the aspects of governance utilizing the YOU token have not yet been implemented. As a result, that component of the system cannot be assessed at this time.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Tezos-Foundation-Synthetic-Asset-Platform-Smart-Contracts-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Grieng Attack Possible from Use of Single Price Oracle", "body": "  Location  orchestrator/coingecko/coingecko.go  Synopsis  The Peggo Orchestrator sends transactions from Cosmos to Ethereum in batches. Before sending a batch, each relayer rst determines if the batch will be protable based on the expected cost of the transactions and the included fees in the batch. The batch cost is estimated by using pricing data from the CoinGecko oracle. The over-reliance on one oracle introduces a SPOF, which could compromise the Peggo Orchestrator by accident or through a grieng attack.  Impact  If the single price oracle malfunctioned or was attacked, it is possible that batches of transactions may not be relayed because they are deemed unprotable, disrupting the functionality of the bridge. It is also possible that unprotable batches may be relayed, draining value from the system (a grieng attack).  Preconditions  The CoinGecko oracle (or the communication channel to it) is compromised.  Feasibility  There is precedent for a price oracle malfunctioning and resulting in a signicant impact (see the Synthetix oracle incident).  Remediation  We recommend sampling prices from several oracles, discarding any outliers, and using the average of the remaining prices.  Status  The Umee team has generalized the oracle code to sample multiple feeds.  Verication  Resolved.  ", "html_url": "https://www.leastauthority.com/static/publications/LeastAuthority_Umee_Peggo_Orchestrator_Updated_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Cosmos Account Private Key is Passed as Command Line", "body": " Argument  Location  cmd/peggo/flags.go#L76  Synopsis  The Peggo Orchestrator command line interface takes the following argument:  --cosmos-pk string   Specify a Cosmos account private key of the  orchestrator in    Passing secrets on the command line is not a recommended practice as it is vulnerable to snooping.  Security Audit Report | Peggo Orchestrator | Umee 19 May 2022 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Impact  An attacker in control of the Cosmos private key could move the tokens on the Cosmos blockchain to other accounts, draining the bridge of its funds.  Preconditions An attack requires access to a Peggo Orchestrator validator's machine as an unprivileged user.  Feasibility  Given access to a Peggo validators machine, it would be relatively straightforward to execute the attack.  Technical Details  An attacker with access to the validators machine could use a tool such as pspy to steal the private key from the command line argument.  Remediation  We recommend that the Cosmos private key be retrieved from the system keyring rather than being input as a command line argument.  Status  The Umee team updated the code to now accept the private key through an environment variable instead of an argument on the command line.  Verication  Resolved.  Specic ", "html_url": "https://www.leastauthority.com/static/publications/LeastAuthority_Umee_Peggo_Orchestrator_Updated_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Stark Verier Trusts the Prover on the Validity of degree_bits", "body": "  Location  starky/src/proof.rs#L45  starky/src/verifier.rs#L110  starky/src/verifier.rs#L223  Synopsis  The verier does not check the validity of the parameter degree_bits but, instead, trusts the prover to provide correct data.  Impact  A malicious prover could extend the Merkle proof openings and hence trick the verier into using an incorrect value for degree_bits, which could lead to undened behavior.  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  This Issue occurs when the verier calls the function recover_degree_bits to obtain the degree bits value. This function computes the value from the length of the Merkle proof openings provided by the prover as well as data from the STARK config le.  Remediation  We recommend implementing a check on the parameter degree_bits in the verier by comparing it against a value derived from the associated constraint system.  Status  The Polygon team has acknowledged the nding and has convinced us that it is not a security issue, because degree_bits is the denitive source of truth, and cannot be maliciously altered in any successful attack. If the length of a Merkle proof does not align with degree_bits (considering any adjustments like blowup), the Merkle proof will fail and any adaptation of associated Merkle trees to the wrong degree_bits is not a viable concern.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Fiat-Shamir Initialization in Starky Crate Is Incomplete", "body": "  Location  starky/src/prover.rs#L73  Synopsis  The initialization of the Fiat-Shamir challenger for the STARK implementation in the Starky crate does not adhere to the principles of Fiat-Shamir, which require the challenger to absorb all information the verier has access to at any given step in the computation.  Impact  Not absorbing parameters, such as the public inputs or the FRI conguration, allows a malicious prover to tamper with this data. Depending on the use case of this STARK implementation, this can lead to security-related consequences (see, for example, [DMW+23]).  Technical Details  In the current implementation, the prover and the verier initialize the challenger with the hash of the trace commitment. The principles of Fiat-Shamir recommend absorbing all the information the verier has access to. Based on this, we identied that the following items are missing:   A global domain separator to ensure that proofs of different domains are incompatible;  A conguration for FRI, including the rate_bits, num_query_rounds or  proof_of_work_bits;   A representation of the underlying Fields and Field Extensions;  All pre-decided generators;  A representation of the AIR in use;  A representation of the Polynomial Commitment Scheme (PCS);  The public values used; and  The potential maximal degree of all constraints;  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend properly initializing the challenger by including all of the items listed above.  Status  The Polygon team has added the public values. The team does not consider any data beyond the trace commitment and the public values to be relevant.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Fiat-Shamir Initialization in zkEVM Is Incomplete", "body": "  Location  evm_arithmetization/src/prover.rs#L106  Synopsis  The initialization of the Fiat-Shamir challenger for the STARK implementation in the zkEVM does not adhere to the principles of Fiat-Shamir, which require the challenger to absorb all information the verier has access to at any given step in the computation.  Impact  Not absorbing parameters, such as the FRI conguration, allows a malicious prover to tamper with this data. Depending on the use case of this STARK implementation, this can lead to security-related consequences (see, for example, [DMW+23]).  Technical Details  In the current implementation, the prover and the verier initialize the challenger with the hash of the trace commitment and the public values. This is an improvement in comparison to Issue B. However, it is still missing crucial information, such as the FRI config data as well as other critical items, as listed in the Technical Details of Issue B.  Remediation  We recommend properly initializing the challenger by including all of the items listed above in the Technical Details of Issue B.  Status  The Polygon team stated that public values are part of the initialization. The team does not consider any data beyond the trace commitment and the public values to be relevant.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Missing Check in ECREC", "body": "  Location  curve/secp256k1/ecrecover.asm#L140  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  ECREC precompile, as dened in [Wood24], utilizes ECDSARECOVER. ECDSARECOVER requires a range check of the value of s, as described in Equation 304. This check is missing from the implementation.  Impact  This is a correctness Issue. According to EIP-2, this missing check opens a transaction malleability concern; however, this is not a serious security aw, especially since Ethereum uses addresses and not transaction hashes as the input to an ether value transfer or other transaction.  Our team did not identify any security concerns directly stemming from this Issue.  Technical Details  According to Equation 304 in [Wood24], a signature is invalid if it does not follow this range check 0 < \ud835\udc60 < \ud835\udc60\ud835\udc52\ud835\udc50\ud835\udc5d256\ud835\udc581\ud835\udc5b / 2  + 1 0 < \ud835\udc60 < \ud835\udc60\ud835\udc52\ud835\udc50\ud835\udc5d256\ud835\udc581\ud835\udc5b omission permits two values of s per signature.  . However, the implementation only checks for  . This  Remediation  We suggest implementing the missing check. Additionally, we recommend adding a regression test targeting this case.  Status  The Polygon team has xed this issue.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue E: BLOCKHASH Incorrect for Max Block Height", "body": "  Location  asm/memory/metadata.asm#L294-L297  Synopsis  The BLOCKHASH instruction is expected to work on any allowed block height, but it will return an error if invoked at block height 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff.  Impact  The BLOCKHASH instruction cannot be considered fully equivalent to the specication. This misalignment between the expected and actual behavior will disrupt, at the specic block height, smart contracts that utilize BLOCKHASH.  Preconditions  The Block height would have to be 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff (256-bits with value 1).  Feasibility  The block height that triggers this behavior is a large number. Assuming that the current block generation pace does not accelerate dramatically, this is unlikely to be a problem in practice.  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  When cur_block_number is 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff (256-bits with value 1), the BLOCKHASH implementation (code line) returns an error (zero value). The reasoning behind this behavior is to protect the following check from an overow. Before this check is performed, cur_block_number is increased by one, which results in a value wrap-around when cur_block_number is at its max value. The intended check is block_number >= cur_block_number, but the check is transformed to its equivalent block_number + 1 > cur_block_number. Due to this, there is a need for an increment by one and, subsequently, the need for the overow check.  Remediation  We recommend implementing the check without incrementing by one and removing the overow check.  Status  The Polygon team acknowledged the nding but decided not to resolve this Issue since it is unlikely to be a problem in practice.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue F: Some Privileged Instructions Not Restricted to Kernel Mode", "body": "  Location  src/cpu/decode.rs#L78  src/cpu/decode.rs#L226  Synopsis  According to the zkEVM specication section 5.3 Privileged instructions, the operations ADDFP254, MULFP254, SUBFP254, and SUBMOD are privileged, and, as such, they must be executed only while in Kernel mode. This restriction is missing from the implementation.  Impact  Although our team did not identify a specic attack vector, we note that this Issue can result in unintended behavior that could be exploited by a malicious actor.  Feasibility  This type of exploit requires an understanding of EVM opcode-level programming.  Remediation  We suggest implementing necessary checks for the affected instructions, similarly to the rest of the privileged instructions. Additionally, we recommend refactoring the code to replace special case handling for each group of instructions and utilizing, instead, a conguration/data structure. The conguration would store information about the instructions privileges, while the functional part would generate the required constraints based on the conguration. This approach can help to alleviate risks for similar omissions in the future.  Status  The Polygon team has implemented the remediation as recommended.  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue G: Type Confusion in Access List Bounds Check", "body": "  Location  kernel/asm/core/access_lists.asm#L75  kernel/asm/core/access_lists.asm#L217  Synopsis  The misinterpretation of a global variable in the Kernel bookkeeping code makes an associated bounds check largely ineffective. This allows a malicious prover to supply false data and gain invalid write access to Kernel memory across context boundaries.  Impact  The corruption of internal Kernel data structures as well as cross-context user memory can have unpredictable (i.e., potentially catastrophic) consequences.  Preconditions  An attacker would have to accurately predict memory access patterns by the EVM emulation and understand the data structures involved. Some restrictions would have to be maintained on the particular values used.  Feasibility  This Issue is similar to common heap memory vulnerabilities. An attacker familiar with basic techniques can likely exploit it. The exact impact depends on effort invested and whether the remaining restrictions apply or can be overcome.  Technical Details  Whenever an EVM instruction such as BALANCE accesses an Ethereum contract, that contracts address is entered into a list of accessed addresses. In the zkEVM, this list is implemented as an ordered (singly) linked list that is stored in a dedicated segment of a given contexts memory space. This segment is treated as an array of list nodes, each node consisting of a value (list element) and a pointer to the next node. When a new element is to be entered into the list, the appropriate place for insertion is determined, a new list node is constructed (extending the array), and the next pointer of its designated predecessor node is updated. Upon the eventual removal of a list element, its predecessor and successor are determined, the predecessors next pointer is updated, and the removed node is marked as deleted by storing an invalid value in its next pointer eld.  Since searching the linked list for a given element (or its future place) is a relatively costly operation, the zkEVM avoids this overhead by leveraging the PROVER_INPUT instruction. This special (privileged) instruction serves as an oracle for operations that are costly to compute but inexpensive to verify, o\ufb04oading the costly computation to the prover, while the VM code only has to verify that the result is correct (i.e., that the prover was honest).  Part of the validity checks on a (purported) list location is to verify that its address falls within the allocated array of list nodes within the access list segment. PROVER_INPUT yields a pointer that is then validated with the macro get_valid_addr_ptr. This macro converts the pointer into an offset by subtracting the segment base address and then compares this offset to the global variable GLOBAL_METADATA_ACCESSED_ADDRESSES_LEN. However, despite its name, the variable does not  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   contain a length/size. It contains a pointer to (one past) the end of the allocated array \u2013 that is, a bound on the pointer rather than on the offset. This is evident from the initialization code in the function init_access_lists, where an address (pointer) is placed on the stack, incremented twice while storing an initial (dummy) node, and then saved to GLOBAL_METADATA_ACCESSED_ADDRESSES_LEN.  Since the base address, and thus GLOBAL_METADATA_ACCESSED_ADDRESSES_LEN, includes the (nonzero) context number in its higher-order portion, the erroneous check will pass (correctly) for valid pointers, but also for those that place the purported list node far outside the bounds of the correct segment, or outside the bounds of the correct context.  This will allow an attacker (on insert) to cause the address of a newly-allocated list node to be written into an almost arbitrary memory location, corrupting control ow. On removal, the value to be written is taken from the data structure at the attacker-controlled location, allowing even more control.  An analogous vulnerability exists with respect to the list of accessed storage keys and the variable GLOBAL_METADATA_ACCESSED_STORAGE_KEYS_LEN.  Remediation  We recommend correcting the logic of the macros get_valid_addr_ptr and get_valid_storage_ptr as well as changing the name of the global variables to properly reect their type.  Status  The Polygon team has independently discovered this issue and implemented the remediation as recommended, though retaining the original variable names.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue H: Incomplete Bounds Check in CALLDATACOPY Instruction", "body": "  Location  kernel/asm/memory/syscalls.asm#L78  Synopsis  Lax bounds checks in the implementation of CALLDATACOPY and (to a lesser extent RETURNDATACOPY), theoretically give an attacker access to Kernel data structures. Only gas cost considerations likely avoid practical exploitability.  Impact  Writing (even zero values) into unintended parts of Kernel memory could have unpredictable consequences. Unintended read access represents a violation of the EVM specication, but does not reveal new information to an attacker.  Feasibility  Given the gas costs involved in storing or copying large amounts of data, this Issue is unlikely to be practically exploitable.  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  The wcopy macro that is used to implement the CALLDATACOPY and RETURNDATACOPY instructions checks that its destination address is reasonable \u2014 that is, below the limit considered practically reachable given gas costs. It does not account for the size of the data in this check.  The EVM specication [Wood24] requires CALLDATACOPY to store a value of zero for any index that falls outside the bounds of the source area. The wcopy macro branches to a code path that copies all zeroes in the case where the source (base) offset is strictly greater than the size of the available data. We note that a base offset equal to the available size is already sucient for the entire source range to be out of bounds and would thus justify the all zeroes code path. However, zero values also have to be written for any part of the source range that falls out of bounds. Since unused memory is initialized to zero, the correct value is written if a source address that is technically out of bounds is still a valid address within the associated segment of Kernel memory. The latter is only assured by the present code under the assumption that the calldata memory segment can never be full enough, nor the size argument to CALLDATACOPY large enough, to reach across the boundary into the next segment.  A more thorough implementation would properly identify any parts of the source that are in bounds versus those that are not and copy the former while explicitly writing zero values for the latter. Notably, the macro codecopy_after_checks that is used for the CODECOPY instruction already does just that.  The RETURNDATACOPY instruction, while also using wcopy, follows different semantics in that it is required to fail if any source address is out of bounds, and the implementation correctly includes this check.  Remediation  We recommend adapting or reusing the existing solution in codecopy_after_checks.  Status  The Polygon team has implemented an alternative remediation that causes a controlled fault in the critical case where the data window to be copied overlaps both the available data and the end of the internal calldata memory segment. We note that this still deviates from the EVM specication which requires any access outside the available data to succeed and yield zero.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue I: Integer Overow in CODECOPY and EXTCODECOPY Instructions", "body": "  Location  kernel/asm/memory/syscalls.asm#L233  Synopsis  An unchecked addition operation theoretically gives an attacker unintended read access to Kernel memory.  Impact  Unintended read access represents a violation of the EVM specication but does not reveal new information to an attacker.  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  Given the gas costs involved in storing or copying large amounts of data, this Issue is unlikely to be practically exploitable.  Technical Details  The macro codecopy_after_checks that is used to implement the CODECOPY and EXTCODECOPY instructions (in a similar manner to the wcopy macro discussed in Issue H) calculates the upper bound of its source buffer as offset + size without checking for integer overow. Passing a large size argument could yield a very small result, making the code consider the entire source area to be within bounds. This would lead to reading out-of-bounds data.  Remediation  We recommend leveraging the existing add_or_fault macro to explicitly check for overow on the rst addition of offset and size.  Status  The Polygon team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue J: Integer Overow When Creating New Contexts", "body": "  Location  kernel/asm/core/util.asm#L14  Synopsis  The global context ID counter is incremented without checking for overow. This would theoretically allow an attacker to compromise existing contexts, including the privileged Kernel context.  Impact  Obtaining a previously-assigned context ID has an unpredictable impact on the control ow of other (user) contexts. Obtaining the privileged ID of the Kernel context (0) would compromise a central security assumption of the system.  Feasibility  Given that the counter in question starts at zero, has a width of 192-bits, and can only be incremented in steps of one, we consider this Issue unexploitable in practice.  Technical Details  The macro next_context_id is used when a new context is created (for example, during a CALL instruction) to assign the corresponding number to the new context. This context ID becomes part of the internal memory addresses used by the Kernel. Specically, it forms the most signicant 192 bits of the 256-bit address (with the lower 64 bits divided between segment and virtual address). Context IDs are never reused, so the Kernel simply keeps a counter of (effectively) 192 bits, and creating a new context increments this counter (GLOBAL_METADATA_LARGEST_CONTEXT) to the next value.  The increment operation uses the add_const macro and does not check for integer overow. Thus, theoretically, the counter could wrap around, leading to the reuse of context IDs, starting with zero (the privileged Kernel context).  Security Audit Report | Starky and zkEVM Kernel | Polygon 22 August 2024 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   We note that GLOBAL_METADATA_LARGEST_CONTEXT is only modied by next_context_id.  Remediation  We recommend using the add_or_fault macro in next_context_id to explicitly check for overow.  Status  The Polygon team has implemented the remediation as recommended. They also noted that the context counter is in fact required to stay within 32 bits for the arithmetic circuit and have applied the check with that limit.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/polygon-starky-zkevm-kernel-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: requestvalidation: Piece Requests Access Disk Before Checking", "body": "  Validity of Request    Location   https://github.com/LeastAuthority/go-fil-markets/pull/1     Synopsis   An attacker can generate and send a valid  Piece  request to a target  StorageMiner , specifically, any  RetrievalMarket  provider that triggers an unnecessary disk access before being validated. This disk  access can be exploited to consume a nodes resources.   Impact   We consider this a high impact issue, which has the potential to flood any node in the system with valid  requests that would immediately return at no expense to the attacker, with the exception of the initial  storage cost for the  Piece .    Preconditions   The  StorageMiner  must store a  Piece  for the attacker and the attacker must format a request for a  Piece  in such a way that it is valid except for the  UnsealPrice ,  PaymentIntervalIncrease ,  PaymentInterval , or  PricePerByte . This still causes the disk to be accessed but the payment terms  to be rejected.   Feasibility   This attack can be carried out by a single actor with a Filecoin node and a fair amount of knowledge of the  Filecoin specification and implementations.   Technical Details   The attacker stores a  Piece  with a given  StorageMiner . As soon as the  Piece  is stored, the attacker  can begin crafting a request that would be out of the range of the  StorageMiner s accepted payment  parameters (in this instance, the configurable parameters are  deal.PricePerByte ,  deal.PaymentInterval ,  deal.PaymentIntervalIncrease , or  deal.UnsealPrice ) and start  flooding the victim with requests for that  Piece . When the  RetrievalMarket  provider goes to handle  the retrieval request, they check that they have the  Piece  in storage, which then triggers a disk read and  loads the  Piece .  The   RetrievalMarket  provider then validates the price parameters, which returns an  error and stops the request. This is significant because it means it will not cost the attacker anything to  send requests, as  vouchers  are not processed if the request is denied for being out of bounds, however,  they are able to incur unnecessary and non-trivial disk usage to check. An attacker can flood a victim  StorageMiner  with these requests and cause delays in their disk reads, slow down request handling for  other users, and potentially stall them out of mining.   Security Audit Report | Lotus Implementation + Subcomponents | Protocol Labs 19 December 2020 by Least Authority TFA GmbH   10   This audit makes no statements or warranties and is for discussion purposes only.        Remediation   We propose validating the request before the disk access so that the attacker cannot force the disk  access without being required to pay.   Status   The Protocol Labs team  implemented the suggested remediation  of checking the validity of the payment  parameters prior to checking the disk for the  Piece .   Verification   Resolved.   ", "html_url": "https://leastauthority.com//static/publications/LeastAuthority_Protocol_Labs_Lotus_Implementation_Subcomponents_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: message: FromNet Inputs Produce an Index Out of Range Error", "body": "    Location   https://github.com/LeastAuthority/go-graphsync/issues/2   https://github.com/LeastAuthority/go-graphsync/blob/master/message/pb/message.pb.go   Synopsis   We discovered crashing inputs while fuzzing the  FromNet  function in g o-graphsync.   Impact   We consider this a low impact issue. An attacker could send this payload to a victim node and crash the  thread handling the request. However, once the thread is crashed, the attacker has no more control or  input into the system and the connection is terminated.    Preconditions   The attacker must be capable of making  go-graphsync  requests with custom payloads. They must also  have a way to generate this input or knowledge of this crashing input.   Feasibility   This attack can be carried out by a single actor with a  go-graphsync  capable node and a fair amount of  knowledge of the Filecoin protocol and implementations.    Technical Details   During fuzz testing, we discovered crashing inputs to the  FromNet  and  ToNet  functions in  go-graphsync . An attacker would craft a  go-graphsync  request with this payload as the metadata  extension:        \"$\\x1a \\x8000\\x1a\\x16002\\xf4\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\" +  \"00000000000000000\"   During processing this input, the thread panics and produced the following output:   ` panic: runtime error: index out of range [-9223372036854775802]`   Mitigation   A proper remediation is beyond the scope, since it is an issue in the gogo-protobuf code generator. As a  mitigation, we recommend changing the generated code to ignore unknown fields in all messages and   Security Audit Report | Lotus Implementation + Subcomponents | Protocol Labs 19 December 2020 by Least Authority TFA GmbH   11   This audit makes no statements or warranties and is for discussion purposes only.        submessages. To do this, return early in the  default  cases in all  switch  statements on variables of  type  fieldNum . In our tests, this eliminates this class of crashes.   Status   The Protocol Labs team is  now using Googles protobuf generator  instead of the gogo-protobuf code  generator. In addition, they have added a regression test for the crashing input discovered during the  audit, in order to protect against any potential issues in future releases.   Verification   Resolved.   ", "html_url": "https://leastauthority.com//static/publications/LeastAuthority_Protocol_Labs_Lotus_Implementation_Subcomponents_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: dagcbor: Input to Unmarshal Function Causes Panic", "body": "   Location   https://github.com/LeastAuthority/go-ipld-prime/issues/4   Synopsis   While fuzz testing the  DecodeMetadata  function in  go-graphsync , we discovered an input that  crashes the  goroutine  processing it.   Impact   We consider this a low to moderate impact issue. This crashing input could be sent to nodes to eat up  processing time and force resource usage. However, the damage is limited since the connection is  dropped once the node crashes the  goroutine .   Preconditions   The  lotus node  must be running a vulnerable version of  go-graphsync .   Feasibility   This attack requires the attacker to run a  go-graphsync  node and a familiarity with the protocols, as  well as knowledge of the crashing input or a way to generate it themselves.    Technical Details   An attacker sends a  go-graphsync  request to a target  go-graphsync  node with a specific payload  containing the raw input of    \"\\xbf\\u007f\\xff\\x8c\\xbf\\u007f\\xff\\x8c\\xbf\\u007f\\xff\\x8c\\xbf\\u007f\\xff\\x8c\\xbf\\ u007f\\xff\\xbb\" + \"00000000   When the node receives the request, they will attempt to decode the extension metadata and, in doing so,  run across this input which will crash the  DecodeMetadata  function and the entirety of the  goroutine  handling that request.    Remediation   This bug can be fixed with a simple length check for the token in the  dagcbor   unmarshal  function.    Status   The Protocol Labs team  implemented a gas budgeting system  in the  Unmarshal  function that limits the  amount of memory that can be consumed while processing a message. This prohibits the  Unmarshal   Security Audit Report | Lotus Implementation + Subcomponents | Protocol Labs 19 December 2020 by Least Authority TFA GmbH   12   This audit makes no statements or warranties and is for discussion purposes only.        function from crashing the  goroutine  that is processing the message by early returning if it meets the  allocated memory budget.   Verification   Resolved.   ", "html_url": "https://leastauthority.com//static/publications/LeastAuthority_Protocol_Labs_Lotus_Implementation_Subcomponents_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: dagcbor: Parsing Adversarially Chosen Data Causes", "body": "  Out-of-Bounds Slice Read   Location   https://github.com/LeastAuthority/go-ipld-prime/issues/7   Synopsis   We discovered an input to the  dagcbor   unmarshal  function that produces an index out of bounds  panic.   Impact   We consider this a low to moderate impact issue. This crashing input may be sent to nodes to consume  processing time and force resource usage. However, the damage is limited since the  goroutine  handling the request recovers from the panic.    Preconditions   The target node must be using a vulnerable dependency version of  go-ipld-prime  and running a  go-graphsync  or equivalent network-capable node. The attacker must be connected to the target and  have an active  go-graphsync  session. This is the case for any data transfer connection that two peers  have.   Technical Details   The first element of  tk.Bytes  is accessed without checking whether the slice is empty. This results in  an out of bounds panic.   Remediation   Before accessing an element of a slice, make sure that the slice is long enough.   Status   The Protocol Labs team  added a simple length check  that prevents the out of bounds access attempt  and, as a result, the panic.   Verification   Resolved.   ", "html_url": "https://leastauthority.com//static/publications/LeastAuthority_Protocol_Labs_Lotus_Implementation_Subcomponents_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: dagcbor: Parsing Adversarially Chosen Data Crashes Node Due to", "body": "  Memory Exhaustion   Location   https://github.com/LeastAuthority/go-ipld-prime/issues/6   https://github.com/LeastAuthority/go-ipld-prime/tree/master/node/basic   Security Audit Report | Lotus Implementation + Subcomponents | Protocol Labs 19 December 2020 by Least Authority TFA GmbH   13   This audit makes no statements or warranties and is for discussion purposes only.          https://github.com/LeastAuthority/go-ipld-prime/tree/master/codec/dagcbor   Synopsis   During fuzz testing we discovered inputs that cause an out of memory error when decoded using  dagcbor .    Impact   The triggering of the issue unrecoverably crashes the  lotus node  due to running out of memory. This  may leave the persistent database in a corrupted state, so simply restarting it may not be possible.   Preconditions   The attacker needs to be in an active  go-graphsync  exchange network with the node under attack.   Feasibility   Since  go-graphsync  is a core part of Filecoin and it is used to transfer data between miners and clients,  it is relatively easy for a client to crash a miner.   Technical Details   The central issue is that the  go-ipld-prime  performs no sanity checks of the encoded data and  imposes no boundaries on allocated resources. Specifically, the encoding of arrays in CBOR may include  an element count. The attacker can create a CBOR-object that contains an array with a very high element  count and the  refmt  library will attempt to allocate the corresponding memory.   Remediation   We suggest enforcing a limit of memory that the CBOR parser is allowed to allocate. The limit may be  hardcoded or specified by the calling function. We suggest a default limit of 64MiB, following the example  of the JavaScript package  ipld-dag-cbor . In general, we recommend treating the CBOR data as untrusted  user input.   Status   The Protocol Labs team  implemented a gas budgeting system  in the  Unmarshal  function that limits the  amount of memory that can be consumed while processing a message. This prohibits the  Unmarshal  function from crashing the  goroutine  that is processing the message by early returning if it meets the  allocated memory budget.   Verification   Resolved.   ", "html_url": "https://leastauthority.com//static/publications/LeastAuthority_Protocol_Labs_Lotus_Implementation_Subcomponents_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: dagjson.Encoder: Lack of Float Support in refmt Causes a Crash", "body": "   Location   https://github.com/LeastAuthority/go-ipld-prime/issues/5   https://github.com/polydawn/refmt/blob/3d65705ee9f12dc0dfcc0dc6cf9666e97b93f339/json/jsonEnco der.go#L211   Synopsis   During fuzz testing we discovered inputs, which can be decoded but then crash the encoder when  re-encoding. It appears that in this particular case, it is of a number that gets parsed as a float which is  not supported by  refmt s encoder.   Security Audit Report | Lotus Implementation + Subcomponents | Protocol Labs 19 December 2020 by Least Authority TFA GmbH   14   This audit makes no statements or warranties and is for discussion purposes only.        Impact   This issue has the potential to crash a  lotus node  unless it is recovered from by an out of scope  system unknown to our team.   Preconditions   The attacker needs to be in an active  go-graphsync  exchange network with the node under attack.   Feasibility   Since  go-graphsync  is a core part of Filecoin and it is used to transfer data between miners and clients,  it is relatively easy for a client to crash a miner.   Technical Details   Go-ipld-prime  depends on the  refmt  module for object serialization.  Refmt s JSON encoder currently  has limited support for JSON primitives, which results in a panic when it encounters an unsupported input  type. If a node attempts to re-encode this input (which it can decode without error), it will crash.   Remediation   Adding a recovery statement where  refmt  is being used would allow the program to regain control after  experiencing a panicking call to the encoder.   Status   The Protocol Labs team  implemented float support to the underlying  refmt  library  that was panicking  when it attempted to encode the input, thus resolving this issue.   Verification   Resolved.   ", "html_url": "https://leastauthority.com//static/publications/LeastAuthority_Protocol_Labs_Lotus_Implementation_Subcomponents_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Permission Requests Can Be Circumvented", "body": "   Location   https://github.com/LeastAuthority/metamask-json-rpc-capabilities-middleware/blob/master/index.ts#L5 58-L585   Synopsis   The capabilities middleware grants permission based on the resolution of a promise returned from a  user-defined function. This leaves the security of the permission system up to the Promise  implementation.   Impact   Critical. An attacker could silently subvert the permissions system and gain full access to users wallets.   Preconditions   Attacker is able to overwrite the Promise implementation, by compromising a dependency.   Feasibility   Unknown. The attackers ability to compromise a dependency depends on how frequently and thoroughly  the dependencies are reviewed and audited, the security practices of maintainers of the dependencies,  the security of the package registry, build pipelines, and many other areas of concern. Due to the surface  area of dependency poisoning attacks, we are not able to say definitively what the feasibility of such an  attack is, given that much of this area is outside of the scope of this audit.   Technical Details   The JSON RPC capabilities middleware package provides access to a particular set of methods by  requesting permission from the end user. In the context of this package, that permission request is an   Final Security Audit Report | MetaMask Permissions System + CapNode 27 November 2019  |  Least Authority TFA GmbH   4   This audit makes no statements or warranties and is for discussion purposes only.        unspecified, user-designated, promise-returning function. The package that uses this (the extension itself)  supplies this function, which displays a dialog in the user interface and, based on the end users input,  either resolves or rejects the Promise.   In the middleware, it is decided whether or not to provide access to these methods based on the  Promises ending status. If resolved with the appropriate permission data, then the user is given access,  otherwise access is denied. In our attack, we act as a rogue dependency to overwrite the global Promise  implementation used such that all Promises always resolve with the permission data for which we desire  access. In doing so, regardless of how the user interacts with the permission dialog, the middleware will  always act as though the permissions were granted.   This is particularly problematic because this may be completely invisible to the end user. The user will  deny the permission request and believe that the denial was successful, while in truth, the attacker may  then make use of whichever wallet functions were exposed. This attack was validated by modifying a  Promise polyfill to suit our attack and using it to overwrite the global Promise, then authoring a test within  the existing test suite.    diff --git a/test/requestPermissions.js b/test/requestPermissions.js  index cab1a02..39e9db7 100644  --- a/test/requestPermissions.js  +++ b/test/requestPermissions.js  @@ -6,6 +6,7 @@ const rpcErrors = require('eth-json-rpc-errors')   const USER_REJECTION_CODE =  require('../dist/src/errors').USER_REJECTED_ERROR.code   const INVALID_REQUEST_CODE = rpcErrors.ERROR_CODES.jsonRpc.invalidRequest   +   test('requestPermissions with user rejection creates no permissions', async  (t) => {     const expected = []   @@ -182,3 +183,51 @@ async function sendRpcMethodWithResponse(ctrl, domain,  req) {       }     })   }  +  +test('modifying the promise prototype can grant self permissions',  function(t) {  +  OldPromise = Promise;  +  Promise = require('./bad-promise')  +  +  const expected = {  +    parentCapability: 'restricted',  +    invoker: 'all.your.base'  +  };  +  +  const ctrl = new CapabilitiesController({  +    requestUserApproval: () => {  +      return new Promise(function(resolve, reject) {  +        reject(new Error('User rejected permissions'));  +      });  +    },  +    restrictedMethods: {  +      restricted: (req, res, next, end) => {  +        res.result = 'Wahoo!';  +        end();   Final Security Audit Report | MetaMask Permissions System + CapNode 27 November 2019  |  Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.            +      }  +    }  +  })  +  +  const domain = { origin: 'all.your.base' }  +  let req = {  +    method: 'requestPermissions',  +    params: [  +        {restricted: {}}  +    ]  +  }  +  let res = {}  +  +  ctrl.providerMiddlewareFunction(domain, req, res, next, end)  +  +  function next() {  +    t.ok(false, 'next should not be called')  +    t.end()  +  }  +  +  function end() {  +    const perms = ctrl.getPermissionsForDomain(domain.origin)[0];  +    t.ok(equal(perms.parentCapability, expected.parentCapability), 'has  correct parentCapability');  +    t.ok(equal(perms.invoker, expected.invoker), 'has correct invoker');  +    Promise = OldPromise;  +    t.end()  +  }  +});   The Promise polyfill used can be reviewed at:  https://gist.github.com/emeryrose/c0195b091d7910d14cf0762073674b16#file-bad-promise-js-L439-L44 1    Mitigation   While Promises are used extensively throughout the code and a complete evaluation of how this type of  attack might impact all of those areas was not feasible within the timeframe, we do know that the impact  on the  requestUserPermissions  function is that an attacker can completely circumvent the  permission dialog. An effective mitigation for this specific area of concern would be to simply trade the  use of a Promise returning function for a standard node-style callback.   Remediation   The longer term remediation for this entire class of issues is a complete and verified implementation of  SESify/LavaMoat. We acknowledge that this project is currently in development and that this particular  issue is part of an entire class of issues for which the MetaMask team is already actively pursuing a  solution.   Status   The global Promise implementation is frozen upon boot in the extension background and interface, before  any other dependencies are imported.   https://github.com/MetaMask/metamask-extension/pull/7309 .   Final Security Audit Report | MetaMask Permissions System + CapNode 27 November 2019  |  Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.          Verification   Resolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Permissions-Capnode-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Subset Check In Reverse Order", "body": "   Location   https://github.com/MetaMask/json-rpc-capabilities-middleware/blob/master/src/caveats.ts#L24    Synopsis   The design of permission caveats are intended to restrict options to a fixed list given in the caveat,  however, the arguments to  isSubset  were the wrong way around. As a result, as long as the options  given in the caveat are provided, other unlisted options may also be used.   Impact   The impact depends on what the specific permissioned API does and what options it uses. If option A  was left out of the caveat that grants option B, a call enabling options A and B would pass.   Preconditions   An API that has some features that are restricted but are enabled by an option, possibly to reveal private  data, or excede a spend limit.   Feasibility   Unknown. Depends upon the implementation. See  Preconditions .   Technical Details   The arguments to  isSubset  were in reverse order, meaning it was checking if the caveat options are a  superset not a subset. This was not caught by the test cases because they only tested with equal inputs  (and an equal set is also a subset).   The error is that the  isSubset  module had arguments in an unexpected order. Instead of reading left to  right,  isSubset(A,B)  meaning is A subset of B, it was in reverse order. While the metamask code had  the correct intentions, it was assumed that the arguments applied from left to right.   Remediation   Correct the order of the options to  isSubset . Test cases that checked against inputs that were actually  subsets or supersets would have also caught this problem.   Status   The MetaMask team clarified that the subset check was in the correct order, but the  naming/documentation of the caveats was confusing. The subset check remains unchanged, however  the documentation has been clarified.    Verification   Invalid.   Final Security Audit Report | MetaMask Permissions System + CapNode 27 November 2019  |  Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.        ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Permissions-Capnode-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Method IDs Have Half Expected Entropy", "body": "   Location   https://github.com/LeastAuthority/metamask-capnode/blob/243c0bca0dc664f2626f73719f865d110d99 a402/index.ts#L22    Synopsis   The constant  K_BYTES_ENTROPY  = 20 suggests that message IDs with enough entropy to be  unguessable were selected. This is then passed to a module that interprets this as a character length,  returning a 20 character long string that has only 10 bytes of entropy.   Impact   The entropy is reduced from a level that would be cryptographically unguessable to one that would  potentially be guessable. It would require a significant amount of time to do so but is no longer in the  bounds that would make the entropy unguessable.   Preconditions   To brute force a message ID, it would be necessary to have an oracle of some form (a part of the system  that behaves in a way that yes and no answers can be required of it). As it stands, sends messages  with random IDs would suffice, usually returning an error, but if you get one right it would return a valid  response.   Feasibility   Low. This attack would be pretty difficult to pull off in practice and would use a lot of local computing  resources, which the user might notice.   Technical Details   Send protocol messages directly with random values for the method ID.   Remediation   Use the amount of entropy originally intended, which is 40 characters in   or 27 characters in base64.    Status   The entropy parameter has been doubled.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Permissions-Capnode-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Lack of Method Registry Access Control", "body": "    Location   https://github.com/LeastAuthority/metamask-capnode/blob/master/src/method-registry/index.ts   Synopsis    An attacker knowing the method ID can call a registered method they should not be able to access.    Impact   Critical. Other extensions and web applications may be able to move user funds without consent.   Final Security Audit Report | MetaMask Permissions System + CapNode 27 November 2019  |  Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.          Preconditions   The attacker must know the method ID. Since the entropy of the method ID is low ( Issue C ) its  conceivable that it could be guessed. The method ID could also be obtained by exploiting a vulnerability in  another remote, or the remote could leak it intentionally.   Feasibility   The feasibility depends greatly upon the implementation. We do know that even a modestly sized botnet  could brute force the 10-byte key used within a reasonable amount of time, especially if it is evident that  user funds could be compromised.    Technical Details   An incoming message is passed to  processMessage  which then checks the message type and forwards  the message to the appropriate handler, along with a reference to an  emitMessage  function that allows  the handler to respond to the caller. For an invocation (calling a remote function), the arguments are  deserialized (which includes regenerating functions from any method IDs given in the serialized form) and  these are passed to the function. The return value is then sent back to the calling remote (if it was a  Promise, it would wait until it is resolved). If a function was at some point passed to a call, its method ID  gets registered, along with a reference to a function that send messages to the remote, which passed that  function. If the  messageid  chosen by the first remote becomes known to another remote, they may now  call it, and the CapNode instance will act as a proxy between the two remotes.   This also affects other interactions around method IDs. For example, peers can dealloc methods they do  not own but know the method ID (except for index methods).   Mitigation   Resolving  Issue C  would prevent the possibility of guessing the method ID. Tracking which remote owns a  function and checking that the calling remote is acceptable, would probably be a small change to the  current code.   Remediation   To fully prevent the problem, have separate registries for each remote and for each set of local methods  exposed to a particular remote. That way, its always clear what context a registered method is to be used  in, then it doesnt matter if two remotes share the same method id. This means they can even be  incrementing integers.   Status   The usage of the method registry code has been updated to ensure that instances of the registry are on a  per-connection basis. The MetaMask team has also indicated that this will be the first of a series of  improvements that should prevent shared instance usage between connections.   Verification   Partially Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Permissions-Capnode-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Method Registry Uses Reverse Index of Functions by their Source", "body": "  String   Location   https://github.com/danfinlay/capnode/blob/243c0bca0dc664f2626f73719f865d110d99a402/src/metho d-registry/index.ts#L24   Final Security Audit Report | MetaMask Permissions System + CapNode 27 November 2019  |  Least Authority TFA GmbH   9   This audit makes no statements or warranties and is for discussion purposes only.        Synopsis   Javascript Maps index functions by their source. However, due to closure references, functions can have  the same source but display different behaviour. This will result in bugs.   Impact   This is an ordinary correctness bug. Since it does work as intended if only one or two functions are  registered, it could be considered a security bug, but it is also likely to break on many non malicious  applications.   Preconditions   More than one function that happens to have the same string value is registered. Due to closure scope, if  using functional programming techniques (functions that return functions), it is likely that functions with  the same source have different behavior. If two of these are registered, the second one will steal the first  ones method ID.   Feasibility   Likely to happen accidentally in a medium to large application.   Technical Details   Javascript Maps store a key:value array that accept Javascript objects or primitives as keys. However, if a  function is used as the key, the source string of that function is used. That means if you have two  functions that are not equal,  fn1 !== fn2,  but have the same source,  fn1.toString() ===  fn2.toString(),  the second function will steal the method ID of the first function when it is registered.   Remediation   Remove the reverse function map, allowing the same function to be registered twice and giving it more  than one method ID.   Alternatively, instead of maintaining a reverse index of functions, iterate over the registry and check each  one with === when checking if a function already exists. This will check functions by reference, which will  behave as expected.   Status   This issue was reported based on the incorrect assumption that JavaScript maps were indexed by their  source string, however this is not the case - they are indexed by their ID. This was an oversight in our  understanding of how JavaScript maps are implemented.    Verification   Invalid.   Suggestion 1:  Redundant Check if Variable is Undefined   Location   https://github.com/LeastAuthority/metamask-json-rpc-capabilities-middleware/blob/master/index.ts#L 457   Synopsis   When domain settings do not already exist, a new key value pair is created and then a check is done to  verify domain is not undefined.   Final Security Audit Report | MetaMask Permissions System + CapNode 27 November 2019  |  Least Authority TFA GmbH   10   This audit makes no statements or warranties and is for discussion purposes only.        Mitigation   Delete the redundant check.   Status   The check has been replaced with a more useful validation.   Verification   Resolved.    Suggestion 2: Redundant Check if IOriginMetadata.id is Empty When  Always Set   Location   https://github.com/LeastAuthority/metamask-json-rpc-capabilities-middleware/blob/master/index.ts#L 567   Synopsis   There is a check if  metadata.id  is empty. If it is not set, the  metadata.id  is created with a new  uuid() . The updated metadata is set on the  permissionsRequest . As a result, there is a redundant  check if  permissionsRequest.metadata.id  is empty.    Mitigation   Delete the redundant check.   Status   The extraneous check has been removed.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Permissions-Capnode-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: SHA Checksum Bypass", "body": "  Location  packages/snaps-utils/src/snaps.ts#L201  Synopsis  The SHA checksum of a Snap can be bypassed by inserting __proto__ objects into the Manifest. This will change the Manifest without changing the Shasum Hash.  Impact  Items in __proto__ can end up inside the application, even when the Snap is not resigned. While we were able to identify malicious __proto__ objects inside the initialPermissions object during Snap install, we found no way to exploit this.  Remediation  We recommend that __proto__ objects be included as part of the hashing pre-image, or ensuring that all __proto__ objects are removed from the Manifest before being processed (See Suggestion 2).  Status  The MetaMask team addressed this Issue by adding a sanitizing function in the out-of-scope library @metamask/utils and using it whenever JSON has to be parsed for generating the Manifest le. This strips any __proto__ objects from the JSON.  Security Audit Report | MetaMask Snaps | Consensys Software Inc. 8 September 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/metamask_snaps_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Snap Execution Exceeds Timeout", "body": "  Synopsis  Repeated frivolous RPCs using await promises in a Snap can manipulate the requestQueue so that the Snap execution timeout is overridden, and the Snap executes indenitely.  Impact  This Issue could result in the unintended behavior of the Snap.  Technical Details  Consider the following proof of concept that illustrates an attack:  let now = Date.now();  while(true) {  let state = await snap.request({  method: 'snap_manageState',  params: { operation: 'get'}  })  console.log(state);  console.log('Doing other stuff here');  let duration = Date.now();  console.log(`${duration - now} time passed`);  }  The aforementioned code requires the Snap to have both RPC and manageState permissions, but does not require the long-running endowment.  With the above code, we observed execution times from 15 to 45 minutes. However, this only occurs when the await keyword is used. When the code is changed so that the snap.request call resolves into a promise using .then, the Snap execution times out after approximately 60 seconds.  Remediation  Our team did not nd a viable solution during the time of this audit to mitigate this Issue suciently. We recommend that this be subject to further investigation in the future.  Status  The MetaMask team stated that they were unable to prevent a Snap from executing an arbitrary function indenitely. Hence, after evaluation, the team decided to defer the Issue, as each Snap is suciently sandboxed, such that this does not pose a major risk to the platform.  Security Audit Report | MetaMask Snaps | Consensys Software Inc. 8 September 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Unresolved.  ", "html_url": "https://leastauthority.com/metamask_snaps_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Missing Check on is_system_off", "body": "  Location  das-contracts/contracts/proposal-cell-type/src/entry.rs#L26-L42  das-contracts/contracts/balance-cell-type/src/entry/mod.rs#L12-L90  das-contracts/contracts/device-key-list-cell-type/entry.rs#L13-L33  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The function is_system_off permits checking in the type scripts of each cell whether the d.id system has been shut down, for example, for security reasons. This function call is missing in the three cells proposal-cell-type, balance-cell-type, and device-key-list-cell-type, thus making them vulnerable during an attack.  Impact  If the system is under attack, certain parts of the system cannot be protected. As an example, the proposal-cell-type script can be used by an attacker to tamper with the sign up process. It is used without any other script in the transactions Propose, ExtendProposal, and RecycleProposal. An attacker can potentially manage to propose false accounts, for example, to circumvent the uniqueness check. In this case, d.id would be unable to pause the usage of this type script.  Preconditions  The system would need to be shut down for security reasons; that is, when an attack is detected.  Feasibility  Low.  Remediation  We recommend adding the function call to the type scripts listed above.  Status  The d.id team has added the checks.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Missing Check on the Approval Field in the Witness of the", "body": " Account Cell  Location  das-contracts/contracts/proposal-cell-type/src/entry.rs#L796  das-contracts/contracts/proposal-cell-type/src/entry.rs#L592  Synopsis  In verify_proposal_execution_result, the type script proposal-cell-type veries whether the Account and PreAccount cells have been converted according to the data in the Proposal cell. A check is missing here on the eld approval in the witness of the new Account cell.  Impact  An attacker can trick a user to sign up with a non-empty approval eld. This can be potentially used to insert an approved transfer to the attacker's address. However, the attacker would still need to pass the signature verication. A second potential scenario is that the user can block any further usage of the approval eld for the user by inserting specic data (such as a timestamp far in the future) for the eld input_protected_until.  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  The attacker would need to be able to tamper with the approval eld of the attacked account.  Feasibility  Low.  Technical Details  The witness eld approval stores authorization-related data. At the moment, the only authorized action that is implemented is a transfer, which allows the transfer of an account to another user. During sign up, it is necessary to check that this eld is empty in the type script proposal-cell-type.  Remediation  We recommend adding the check.  Status  The d.id team has added the check by implementing the function verify_witness_initial_approval.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Missing Check on Action Field in the Approval", "body": "  Location  das-contracts/contracts/account-cell-type/src/approval.rs#L15  Synopsis  In the function transfer_approval_create, there is no check verifying that the action eld equals transfer.  Impact  Passing in a different type leads to undened behavior in the code. Since only one approval type exists currently, the impact is low. However, if new types of approvals are introduced, the missing check could lead to severe consequences (depending on the type of approvals being introduced).  Technical Details  The approval struct is used for storing information on authorization. The eld action within this struct stores the specic authorization type. The only implemented type so far is account transfers, with the primary use case being third-party platforms.  Remediation  We recommend adding the check.  Status  The d.id team has added the check, which veries that the action eld equals transfer, prior to calling the transfer_approval_create function.  Verication  Resolved.  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Missing Check on status_ag in verify_cell_initial_properties", "body": "  Location  das-contracts/libs/das-core/src/verifiers/sub_account_cell.rs#L22  das-contracts/contracts/account-cell-type/src/entry.rs#L840  Synopsis  When the type script account-cell-type runs the action EnableSubAccount, the initialization of the SubAccount cell is veried by the function verify_cell_initial_properties. However, this function does not check whether the status_flag equals zero.  Impact  A malicious attacker can trick a user to set the status_flag to the value one when the user enables the SubAccount cells. This activates the rules stored in the elds price_rules_hash and preserved_rules_hash. Since the code veries whether the rule is initially set to zero, the impact of the attack is low. The attacker would need to modify these rules in a second attempt to successfully exploit the user. Nevertheless, refraining from checking the eld leads to unintended behavior since the rest of the code assumes an initial value of zero. In addition, if the status_flag is set to a value different than zero or one, it could lead to unexpected system states or consequences.  Technical Details  The status_flag implements the rules stored in the elds price_rules_hash and preserved_rules_hash. These allow the user to specify custom pricing rules for the SubAccount cell.  Remediation  We recommend adding the check.  Status  The d.id team has added checks to the verify_cell_initial_properties function.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue E: Rounding Error Leads To Imprecise Capacity Calculation", "body": "  Location  das-contracts/libs/das-core/src/util.rs#L716  das-contracts/libs/das-core/src/util.rs#L727  Link to Rust playground: https://play.rust-lang.org  Synopsis  The functions calc_yearly_capacity and calc_duration_from_paid perform division before multiplication for u64 types. Consequently, this results in imprecisions in the calculations, which could lead to nancial losses for d.id.  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Impact  The imprecision in calc_yearly_capacity could potentially lead to less income for the d.id team since customers benet from the current calculation \u2013 at least in the numerical examples our team reviewed (see the Rust playground for more details). For this function, our numerical analysis identied a deviation of up to 99%. We did not identify a problem with the imprecision found in calc_duration_from_paid.  Preconditions  The prices would need to be in a range where division differs signicantly between the two approaches, and yearly_price would have to be larger than quote.  Technical Details  For demonstration purposes, we implemented this rust playground and varied the yearly price. Below, we describe the extreme case that we were able to detect. Note that we did not perform a thorough investigation of the complete input space of yearly_capacity and quote. The example is rather used to demonstrate that the deviation is non-negligible and needs to be addressed.  The function calc_yearly_capacity behaves differently depending on the relation between yearly_price and quote. If yearly_price is less than quote, then yearly_price is rst multiplied by 100000000 and then divided by quote. This is necessary to prevent the rounding behavior from yielding a value of zero for the yearly capacity. To avoid this, the function uses the if-loop specied below:  Python  pub fn calc_yearly_capacity(yearly_price: u64, quote: u64, discount: u32) -> u64  {  }  let total u64;  if yearly_price < quote {  total = yearly_price * 100_000_000 / quote;  } else {  total = yearly_price / quote * 100_000_000;  }  ...  However, the else-case is still imprecise for the case where yearly_price is greater than or equal to quote, as in this case, the code performs division before multiplication. To illustrate, consider the following values:  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Python  yearly_price= 199;  quote = 100;  // based on total = yearly_price / quote * 100_000_000;  total_1 = 100000000;  // based on total = yearly_price * 100_000_000 / quote;  total_2 = 199000000;  The deviation between the two cases reaches 99% in this extreme case.  Mitigation  The recommended remediation below might be not practicable since overows can occur and hence lead to an unfavorable user experience. In this case, we recommend monitoring the situation closely. Note that the size of the deviation, and hence the resulting loss of income, highly depend on the exact numbers used in the calculations.Therefore, it is possible that the actual losses might be lower than expected.  Remediation  We recommend performing multiplication before division, especially for calc_yearly_capacity. This recommendation is a standard for other smart-contract-based blockchains like Ethereum (see here), where rounding errors are among the top 10 classical bugs. In addition, if possible, we recommend implementing softoat implementation into the binary, as described in the RFC of the CKB VM.  Status  The d.id team has resolved the Issue by using the primitive-types crate to handle u256.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue F: Incorrect Validation of Length in Base64", "body": "  Location  das-lock/c/base64url.h#L231-L234  Synopsis  A check for undersized or oversized inputs is incorrectly structured, using logical conjunction (Boolean AND) instead of logical disjunction (Boolean OR). Since an input cannot, at the same time, be both oversized and undersized, the check does not capture either condition.  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Impact  An attacker can pass oversized data that can result in buffer overows and the overwriting of arbitrary memory.  Feasibility  Straightforward.  Technical Details  C/C++  if (*len < 1 && *len > 256) {  debug_print(\"decode_base64url_to_string: invalid input, length out of range\");  return ERROR_ARGUMENTS_LEN;  }  Remediation We recommend using logical disjunction (i.e., Boolean OR) by changing && to || instead.  Status  The d.id team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue G: Potential Buffer Overow in Base64", "body": "  Location  das-lock/c/base64url.h#L235C1-L236C46  Synopsis  A potential buffer overow might occur when converting Base64URL encoded strings to Base64 encoded strings as a result of the additional padding characters present in Base64.  Feasibility  Straightforward.  Technical Details  Base64URL encoded string does not contain padding characters, which are included in Base64 encoded strings. As a result, when converting from Base64URL to Base64, the resulting string may be longer than the input.  The code allocates a 256 byte buffer in which the converted string is stored. It checks whether the length of the input string is, at most, 256 bytes (see Issue F) and then attempts the conversion.  If the conversion requires the insertion of padding bytes (1 or 2) it might be possible to overow the buffer.  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend expanding the buffer in which the conversion is performed to allow for the insertion of up to two padding characters from the conversion.  Status  The d.id team has remediated this Issue following a discussion with our team.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue H: Improper Input Validation", "body": "  Location  das-lock/c/webauthn_sign.c#L52-L62  Synopsis  The \u2018challenge string retrieved from the JSON data passed to the function is assumed to have a xed length of 86 characters in a comment, but no validation of the length is performed.  The challenge string is subsequently decoded and assumed to have a length of precisely 64 bytes, but it is possible for the input to be much longer, resulting in out-of-bounds writes.  Impact  This Issue could result in buffer overowing and out-of-bounds writes, affecting the stack.  Technical Details  If the JSON document contains the following example challenge string, the code will overow the buffer:  RnJvbSAuYml0OiBUaGlzIGlzIGEgc2ltcGxlIHN0cmluZyBlbmNvZGVkIHdpdGggYmFzZTY0dXJsLi BCbGFoIGJsYWggYmxhaC4  This is the Base64URL encoding of the string From .bit: This is a simple string encoded with base64url. Blah blah blah. However, any string would lead to the same outcome. By having the expected common prex present, the function may appear to succeed, but, depending on the stack layout, it may corrupt the state of the program in unpredictable ways.  Remediation  We recommend converting the comment to an actual check to ensure that the challenge has the correct xed length, and generating an error otherwise. Additionally, we recommend increasing the size of the buffer into which the challenge is decoded to ensure that it cannot be overowed.  Status  The d.id team has implemented the remediation as recommended. The team additionally noted that there are already protocol-level safeguards in place to prevent this Issue from being exploited.  Verication  Resolved.  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue I: Signature and Public Key Duplication in Multi-Sign Verication", "body": "  Location  das-lock/c/ckb_multi_sign.c#L52  Synopsis  The code checks signatures against an array of public keys. No checking is performed to ensure that a public key is not listed multiple times. As a result, it is possible to construct scenarios where an attacker can reuse a single signature.  Impact  An attacker may be able to bypass threshold checking by reusing a single valid signature.  Preconditions  The lock_bytes buffer would have to be under the control of the attacker.  Technical Details  The code determines the number of public keys present (storing them in the pubkeys_cnt variable) and the required threshold (storing it in the threshold variable) and then iterates by checking the signature and comparing it against a list of public keys.  The code does not include any checks to ensure that the signature at index i is not duplicated, or that the public key used in the signature has not already been used. As long as the signature is valid, it will set used_signatures[i] to one.  If a threshold is specied, an attacker can either duplicate a single signature or, if in possession of one private key, generate threshold valid signatures with the same key and place them in the rst threshold slots to meet the simple check.  Remediation  We recommend checking that all listed signatures and their corresponding public keys are unique. If possible, we recommend imposing a canonical format (e.g., one where public keys are listed in ascending order).  Status  The d.id team stated they investigated this Issue and conrmed that this risk does exist. Our team agrees and thus considers this resolved.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue J: Use of Uninitialized Memory When Hashing", "body": "  Location  das-lock/c/doge_sign.c#L23  Security Audit Report | .bit Contracts | d.id 10 April 2024 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The code collates several inputs to form a message, which it then hashes. One of the inputs is encoded using a variable-length encoding (either 1 or 2 bytes). For messages between 256 and 65536 bytes, one byte is not explicitly initialized and may have unpredictable values, causing non-deterministic behavior.  Feasibility  Straightforward.  Technical Details  The message _vi_len species the number of bytes needed to encode the length of the message, which will then be set to either one or two.  The code leverages the compilers variable length array support to allocate a properly-sized buffer. The C standard imposes no requirements on the contents of such allocated buffers. While it is possible that a given compiler zero-initializes variable length arrays, this behavior is, at best, compiler-dependent.  For messages greater than 255 bytes (and less than 65536 bytes) the 28th byte of the buffer (i.e., total_message[27]) will be left uninitialized.  As a result, the magic_hash function may return unpredictable values for messages greater than 255 bytes.  Remediation  We recommend properly initializing the contents of the buffer to some known value using memset. The value zero might be appropriate, depending on existing behavior.  Note that it appears that the variably-encoded length is never written to the buffer. It might be possible to simply adjust the size of the total_message array to not include message_vi_len. Care should be taken to ensure that this is not a breaking change and that the resulting buffer is still appropriately sized to hold the data written to it.  Status  The d.id team has implemented the remediation as recommended. However, our team noted that the code is still complex and dicult to understand and therefore presents a risk that the d.id team should further address.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/d-id_-bits_contracts_final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Weak Key Derivation Algorithm Used", "body": "  Location  snap/src/encryption/index.ts#L84  Synopsis  In the GetAESBase64Key function, the password is used as input for keydata in the crypto.subtel.importKey function, which can result in weak key generation.  Impact  In the GetAESBase64Key function, crypto.subtel.importKey(format, keyData, algorithm, extractable, keyUsage) uses HKDF as an algorithm for key derivation. However, since HKDF is not designed for low entropy input, the derived master key will not be secure enough.  Remediation  We recommend using PBKDF2, instead of HKDF, as it is specically designed for deriving keys from passwords.  Status  The Generative Labs team has implemented the remediation as recommended.  Verication  Resolved.  Security Audit Report | MetaMask Snap | Generative Labs 30 August 2023 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/generative_labs_web3mq_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Unnecessary Usage of Non-Standard Libraries", "body": "  Location  snap/src/utils.ts#L31  snap/src/utils.ts#L270  Synopsis  While the libraries used do not appear to be insecure, there are standard libraries available that should be used instead.  Impact The use of non-standard libraries to handle sensitive functionalities introduces the potential for implementation errors and increases the possibility of a supply chain attack that may result in serious vulnerabilities.  Remediation  We recommend the use of standardized, trusted, and audited alternatives, such as SubtleCrypto.  Additionally, for the cases where the implementation uses SHA3-224, although it is not implemented in any of the WebAPI libraries to the best of our knowledge, SHA256 can be utilized instead, and the output hash can be trimmed with negligible impact on performance.  Status  The Generative Labs team responded that the npm package @noble/ed25519 is both recommended and user-friendly. While our team agrees with this statement, this Issue was identied in order to suggest alternatives for the usage of libraries, such as js-sha224 and js-sha3. Our team continues to recommend the usage of SHA256 instead of SHA3-224.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/generative_labs_web3mq_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Initialization Vector Used Does Not Meet Recommended Best", "body": " Practices  Location  src/register/index.ts#L257  Synopsis  A key is a piece of information used in ciphering data and must remain secret, while an Initialization Vector (IV) is used to ensure that the same plaintext encrypted with the same key results in different ciphertexts, thus providing semantic security. In addition, in specic cases, the IV can be public and retaining uniqueness can be sucient, according to [Dworkin07]. However, the current implementation uses parts of the derived secret key as an IV. Mixing the roles of the aforementioned two inputs can jeopardize the strength of the symmetric encryption algorithm used.  Impact  The purpose of an IV is to add randomness to the encryption process. If IVs are not unique, the security of the encryption is weakened. Attackers might be able to predict or manipulate the ciphertext, leading to potential data leakage.  Security Audit Report | MetaMask Snap | Generative Labs 30 August 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend using a pseudorandom number generator (PRNG) to generate an IV instead of reusing parts of the secret key.  Status  The Generative Labs team stated that decoding and encoding require consistent IV parameters, so the user's password is used as the original parameter for SHA256. However, our team found that the IV is still being derived from the password using SHA256 and is then converted to a Base64 string. While this approach is better than using a plaintext password as an IV, it is still not ideal. As noted in the synopsis of this Issue, it is generally recommended to use a randomly generated IV for each encryption operation, and to ensure that there is no overlap between the secret key and the IV (which can be public or safely stored in plaintext format).  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/generative_labs_web3mq_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Vulnerable and Unused Dependencies Detected in the Codebase", "body": "  Synopsis  Analyzing the code using npm audit and depcheck shows that the dependencies used have 10 known vulnerabilities (1 Critical, 9 Moderate). According to npx depcheck, the following unused dependencies and devDependencies were identied:  Unused dependencies:   @metamask/snaps-ui  @protobuf-ts/plugin  buffer  web3  Unused devDependencies:   @lavamoat/allow-scripts  @metamask/auto-changelog  prettier-plugin-packagejson  Impact  Using unmaintained and outdated dependencies and devDependencies may lead to critical security vulnerabilities in the codebase.  Remediation  We recommend proper management and maintenance of dependencies and devDependencies, as detailed below:   Manually auditing and updating dependencies, in order to avoid known issues in unmaintained and outdated dependencies and conducting extensive testing to conrm there are no backward compatibility issues introduced by upgrading dependencies;   Including the automated dependency auditing into the CI workow or enabling Dependabot on GitHub, which automatically noties developers about published security advisories relevant to the codebase;   Acting on published advisories and updating dependencies accordingly when xes are released;  and  Security Audit Report | MetaMask Snap | Generative Labs 30 August 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.    Pinning specic dependency versions to mitigate any potential supply chain attacks or the  possibility of newer versions of dependencies breaking the code.  Status  The Generative Labs team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/generative_labs_web3mq_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: A Compromised Machine Might Read or Generate False Secret", "body": " Randomness  Location  Example of how to generate the randomness: https://github.com/AleoHQ/aleo-setup/blob/313a938e0549f36007c69a4a6cd0955988beee94/phase1-cli /scripts/phase1_chunked.sh  Actual use of randomness: https://github.com/AleoHQ/aleo-setup/blob/313a938e0549f36007c69a4a6cd0955988beee94/phase1-cli /src/contribute.rs  Security Audit Report | Trusted Setup: Phase 1 | Aleo 30 July 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  During previous CRS-MPC ceremonies, such as the Zcash Sprout ceremony in 2016, considerable efforts were made by the Electric Coin Company team to secure the underlying hardware used to compute any contribution and reduce the likelihood that it could be compromised. However, if decentralized private computations become widespread, circuit specic CRS-MPCs like those required in Groth16 might become more common and occur frequently, particularly as circuits increase in size. As a result, it cannot be assumed that all ceremony participants will be able to put forth such considerable effort to ensure the integrity of the hardware and software will remain the same as it did for previous ceremonies.  Given this knowledge, we suggest in threat modeling, to assume that the machines involved in ceremonies may be compromised in some way. As a result, the Aleo codebase would benet from taking additional precautions to protect the random seed and the private key against a compromised system, the latter of which might be able to read or generate false secret randomness.  Impact  The overall impact is low, since the entire CRS-MPC is secure as long as at least one private key among all contributions remains a secret. However, in the unlikely event that an attacker is able to accumulate the secret randomness of all participants, it can compute false proofs in any system that is based on the derived CRS.  Preconditions  In order to read the seed or the private key, an attacker must compromise the executing machine in such a way that they are able to read or write from or to the process memory (e.g. RAM/SWAP). A second precondition would be a random number generator attack, in which the systems randomness generator is compromised in order to generate fake randomness.  Technical Details  In function key_generation in le /phase1/src/key_generation.rs, the private key (usually called the toxic waste or the secret eld elements) is deterministically derived from a seed that has to be provided as a parameter during program start. The seed and private_key then exist during the execution time of the function contribute in the le /phase1-cli/src/contribute.rs. However, depending on the circuit size, that function might run for an extended period, giving an attacker enough time to complete their attack. After termination, the associated memory is deallocated but not actively overwritten. Furthermore, no precautions have been taken to prohibit the compiler from allocating various copies of that secret in different parts of the memory, including less volatile parts (e.g. a swap partition).  Remediation  As long as any contribution is executed in a single chunk, there is no reason for the seed randomness to be generated outside of the function contribute. In this scenario, Rust's crate secret can be used as protected-access memory for the seed. This guarantees that the memory is both freed and overwritten after termination.  Unfortunately, if the contribution is provided across more than one chunk, the previously mentioned approach will not suciently address the issue since the secret randomness needs to be shared across different computations. As a result, we recommend a pre-contribution phase that generates the randomness inside Rusts crate secret and encrypts it using strong symmetric encryption and a user dened password, the latter of which is, for example, stored in an OS keyring or memorized by the user. The encrypted toxic waste can then be stored safely and used in the various chunk computations. In each computation, it is decrypted and then handled as we suggested under the single chunk computations.  Security Audit Report | Trusted Setup: Phase 1 | Aleo 30 July 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Aleo team has responded that, since one non-compromised participant is sucient for security, they do not plan to resolve this issue. Given that the impact of this issue is indeed minimal since an attacker needs to compromise all ceremony participants to gain knowledge over the hidden entropy used, we consider the decision to leave the issue unresolved at the time of verication to be acceptable.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Aleo_Trusted_Setup_Phase_1_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Hashing to G2 Exposes a Discrete Log Relation to the Generator", "body": "  Location  Function hash_to_g2 in le: https://github.com/AleoHQ/aleo-setup/blob/313a938e0549f36007c69a4a6cd0955988beee94/setup-util s/src/helpers.rs  Synopsis  As described in BGM17, CRS-MPCs require access to an oracle, whose outputs are uniform and independent elements of the group G2. This implies that no discrete logarithm relation between different oracle queries should be known to any user of the system. However, we found that the approach taken by the Aleo development team trivially exposes a discrete logarithm relation between any output and the generator.  Impact  Having knowledge of discrete logarithm relations between any output and the generator imply discrete logarithm relations between any two outputs, which in turn violates the assumptions of BGM17 on the independence of outputs. As a consequence, the security proof no longer holds true.  Feasibility  This is very feasible as the discrete logarithm relation is easy to compute.  Technical Details  Function hash_to_g2 calls function sample from le algebra-core/src/curves/models/short_weierstrass_jacobian.rs, which computes the hash to curve as follows:  Let g_2 be a generator of G2 and x be the byte string that needs to be hashed to G2. Then the curve hash is computed as,  H_G2(x) := g_2^Hash(x),  where Hash(.) is a cryptographically secure hash function that hashes to the base eld. The discrete log relation between H_G2(x) and g_2 is then trivially seen as Hash(x).  Remediation  A secure approach would be to hash separately to the x and the y coordinates and check if the result is actually a point in the required large order prime group. If it is not in the prime order subgroup, changing the initial byte string is necessary. Depending on the approach, proper cofactor clearing may also be necessary.  Security Audit Report | Trusted Setup: Phase 1 | Aleo 30 July 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Aleo team rewrote the hash_to_G2 function and implemented a try-and-increment approach for hashing into G1 of the twist in the usual way. This was done by rst hashing into the base eld, trying to nd a curve point, and then doing a cofactor multiplication to project into G1 of the twist. Since the twist isomorphism identies G1 of the twist with G2 of the original curve over the extension eld F_{q^k} with k being the embedding degree, this implements a way to hash into G2. We analyzed the implementation and were not able to identify any new issues. Thus, we consider the original issue to be resolved.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Aleo_Trusted_Setup_Phase_1_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: RUSTSEC-2016-0005 Rust-Crypto is Unmaintained", "body": "  Location  https://github.com/AleoHQ/aleo-setup/blob/313a938e0549f36007c69a4a6cd0955988beee94/setup-util s/Cargo.toml  https://rustsec.org/advisories/RUSTSEC-2016-0005.html  Synopsis  The Aleo codebase uses the Rust-Crypto crate in version 0.2. However, according to the Rust advisory database, RUSTSEC-2016-0005, that particular crate has not seen a release or GitHub commit since 2016 and its author is unresponsive.  Impact  While vulnerabilities have not been identied in this crate to date, the Rust advisory database recommends to change that dependency to an actively maintained crate.  Remediation  We recommend switching to a maintained cryptography library as advised in RUSTSEC-2016-0005.  Status  The Aleo team has stated that the Rust-Crypto crate in version 0.2 is only used for SHA2 hashing in Beacon code and is therefore unnecessary to remediate for security, from their perspective. We veried that the Rust-Crypto crate in version 0.2 is only used in this specic setting which then, as an example, generates randomness for the beacon in Phase 1. Even if the crate is only used in one place in the code, we nevertheless recommend switching to a maintained cryptography library in the future.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Aleo_Trusted_Setup_Phase_1_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Balance Recording Forces Check-Effects Anti-Pattern", "body": "  Location  contracts/LoanCore.sol#L125  Security Audit Report | Pawn Smart Contracts | Pawn Finance 27 August 2021 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The method chosen to record the balances held by the LoanCore.sol smart contract is to check the smart contracts balance after a transfer has occurred, forcing the smart contract to update the state of a balance after a call to the ERC-20 token smart contract has been made. This results in a possibility for a corrupt ERC-20 token to be used to re-enter the loan creation process. As good practice, the check-effects-interactions pattern should be used at all times.  Impact  Using a corrupt ERC-20 token to re-enter the loan creation process allows many invalid loans to be stored on the smart contract originating from the same loan terms agreement. However, the impact of this is likely negligible and would only cost the attacker.  Feasibility  Given that we could not determine an incentive for this attack, we consider this attack to be unlikely.  Remediation  We recommend using the loan state data, data.terms.principal, to update and record the balances. This will allow the LoanCore.sol smart contract to prevent an ERC-20 transfer from re-entering on line 110, since the received amount would now be updated.  Status  The Pawn Finance team refactored the code in LoanCore.sol to follow a stronger checks-effects-interactions pattern by moving the token transfer until after the token balance is updated (now on Line 119).  Upon review of the pull request where the above changes were made, the Pawn Finance team noted an issue with Fee on Transfer tokens and other tokens with nonstandard handling of transfers, causing the potential to miscalculate their internal balance. The Pawn Finance team decided to replace the previous way of updating balances, by pushing them into a mapping, with the use of transferFrom and safeTransfer patterns. We examined these changes and found no issues.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Pawn_Finance_Pawn_Smart_Contracts_Updated_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Minimized Replay Attack", "body": "  Location  contracts/OriginationController.sol#L33  Synopsis  In order to initialize a loan, there is an off-chain agreement that is made between lender and borrower, in which the loan terms are set. This loan terms agreement is then used to create a loan. This agreement is signed by either the borrower or the lender off-chain. It is required that the counterparty of the agreement then broadcast the transaction on-chain, effectively signing the agreement themselves. There is no nonce in the agreement signed, meaning that if multiple iterations of the agreement are signed by one party, the other may broadcast an older version of the agreement.  Security Audit Report | Pawn Smart Contracts | Pawn Finance 27 August 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Impact  If a loan terms agreement is iterated off-chain, an older agreement might be used by a counterparty causing a loan to be started that a counterparty did not intend to be started, resulting in one of the parties carrying suboptimal loan terms.  Feasibility  The feasibility of this attack could not be assessed from the scope of this audit. The case of multiple iterations of loan terms agreements may be limited in possibility.  Mitigation  The Pawn Finance team has responded to this issue noting that this case should not be possible due to application code. However, we assert that application code can be bypassed on-chain, and a bug or incorrect usage of the protocol may result in an issue. The Pawn Finance team also responded that there is no conceivable incentive to perform a replay attack unless a mistake is made during the iteration of a loan terms agreement. Our team is not able to conrm this assertion.  The decentralized approach to solving this issue involves using a nonce on agreements and requiring a delay in the start of a loan for a counterparty to challenge an old loan agreement being used. This is not a trivial design and we do not suggest that this be implemented.  We recommend that the application warn users when they sign a loan terms agreement that this action is irreversible and that no further iterations of the agreement should be made. If a loan agreement must be updated off-chain, it should be known that there is no guarantee that the older signed agreement will not be used to start a loan. This extends to any point in the future.  Status  The Pawn Finance team responded that they intend to address this issue in the future. As a result, this issue remains unresolved at the time of verication.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Pawn_Finance_Pawn_Smart_Contracts_Updated_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Loan Term Countdown Can Begin Before Loan is Funded [Known", "body": " Issue]  Location  contracts/OriginationController.sol#L33  Synopsis  The Pawn Finance team identied an issue where, in OriginationController.sol, intializeLoan uses an absolute due date to initialize a loan when calling createLoan and startLoan from LoanCore.sol. However, upon loan creation, the repayment term will begin counting down towards an absolute due date without taking into account whether or not a loan has been funded.  Impact  In a worst-case scenario where a lender has negotiated a short repayment term, a borrower could default on a loan without having received the intended funds.  Security Audit Report | Pawn Smart Contracts | Pawn Finance 27 August 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  A loan requires a repayment term to be originated, which can be represented using a due date. In contracts/OriginationController.sol#L64-L65:  uint256 loanId = ILoanCore(loanCore).createLoan(loanTerms);  ILoanCore(loanCore).startLoan(lender, borrower, loanId);  The call data loanTerms passes an absolute dueDate to createLoan, which is then passed to startLoan. However, this due date is negotiated off-chain before the loan actually starts. It can be any date, so long as it is anytime later than the block.timestamp and thus not expired. In a scenario where a loan is originated on-chain unexpectedly later than the off-chain negotiation of terms, a borrower would have a reduced time frame to repay a loan.  Mitigation  Pawn Finance proposed a mitigation of using a due date that is relative to the block.timestamp the startLoan transaction was mined, which gives the borrower a repayment period that is consistent with the expectations of the loan terms negotiated off-chain.  Status  The Pawn Finance team have implemented a change using block.timestamp + terms.relDueDate to represent the dueDate, when calculating if the repayment period has passed and a loan has defaulted.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Pawn_Finance_Pawn_Smart_Contracts_Updated_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: The BN254 Curve Provides Insufcient Security", "body": "  Location  circuits/script/powers_of_tau_phase_1.sh  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  Zkopru uses a variant of the BN254 curve, also called BN128. In 2016, advances in number theory led to a lower security estimate of that curve. Specically, its security is now considered to be around 96 bits. This is signicantly lower than the 112 bits currently required by NIST for new products.  Impact  Use of the BN254 curve reduces the security of the zk-SNARK scheme, such that the feasibility of computing valid, forged proofs cannot be ruled out. Such proofs would pass validation, yet violate the constraints imposed by the circuit. For example, a valid, forged proof could spend UTXOs arbitrarily.  Feasibility  Although the exact feasibility is dicult to estimate, the potential gains from a successful attack are high. This suggests that an attacker would have incentive to invest signicant resources resulting in an increased risk that the feasibility is reasonable.  Technical Details  Attacks based on the Tower Number Field Sieve (TNFS) and the derivative exTNDS and SexTNFS have led to a reduced estimate of the security level of BN254. Consensus on the new estimate has not been reached by scholars and practitioners working on this issue, however, opinions range from 96 bits to 110 bits [KB15, MSS16, BD17, P16]. Regardless of where on this spectrum the real value falls, it is still too low. Even for applications that only need to remain secure until 2030, NIST requires a security level of at least 112 bits [B20, Table 4], which BN254 does not achieve.  Remediation  We recommend using the curve BLS12-381. According to the draft RFC on pairing-friendly curves [SLK+20], it has a security level of ~128 bits, which is above the 112 bits considered sucient by NIST until 2030.  Status  The Berlin hard fork upgrade will no longer contain EIP-2537 and, as a result, 384 bit arithmetic in the EVM (i.e. EVM-384) is currently unavailable. Given this change, there is currently no ecient method for secure pairing based cryptography that is able to achieve at least 112 bits of security, as required by NIST for new products. Thus, a long-term remediation is not currently possible and we recommend that the Zkopru team continue to monitor developments with EIP-2537.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Write a Proper Accompanying zk-SNARK Statement", "body": "  Location  zkopru-network/protocol-specification/  Synopsis  zk-SNARKS are short and computationally sound proofs for the existence of witnesses to given statements, able to hide parts of the witness from any verier. In order to correctly perform a security audit on a zk-SNARK implementation, it is therefore fundamental to start with a clear and formal denition of the associated zk-SNARK statement.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Impact  A well written SNARK statement improves the security of the SNARK by making it easier to reason abstractly about the security properties of the zk-SNARK itself. Statements that are not well designed carry the risk of unintended solutions, which will enable a malicious prover to nd valid proofs for unintended system behavior. Since zero-knowledge is involved, those proofs, that are valid but malicious, would be potentially very dicult to detect. In addition, statements are the foundation for writing security proofs for zk-SNARK properties.  Additionally, when lacking a statement, there is no foundation to compare the implementation against. It is insucient to have the statement implicit in the code, as this would force a circular approach for reviewers, consisting of comparing the code against a statement that is implicit in the code.  Remediation  We recommend that the Zkopru team write an extensive and rigorous statement denition, adhering to the best practices of SNARK development as outlined for example in [BGT18], section Correctness and Trust / Considerations, [H18], or [H19]. In addition, we suggest instituting regular documentation reviews to ensure the documentation remains up to date and consistent with the implementation. The statement should contain a list of all assumptions made by the system. In addition, a clear description of how the common reference string was or will be computed should be given, and reference all data known related to the trusted setup accordingly.  The statement documentation created by the Zkopru team during the course of this audit is helpful, and we identied no deviations in comparison to the actual functionality of the gadgets apart from Issue C and Issue E.  Status  The Zkopru team developed a specication for the protocol, which included a zk-SNARK statement. This aided their efforts in identifying and resolving new critical vulnerabilities.  Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Previously Correct Ownership Proof Disabled via Code Changes", "body": "  Location  circuits/lib/ownership_proof.circom#L10  Synopsis  Zkopru is supposed to check the ownership of any UTXO, by enforcing a valid EdDSA check on the BabyJubJub curve. To do so, it utilizes Circoms EdDSAPoseidonVerifier() gadget, which has an input variable that is used to enable or disable EdDSA signature checks during proof generation. In Zkopru, the intended mode is to always enable the signature check, but in the commit we audited, we found this variable to be set in such a way that signature checks were always disabled.  On inspection of the commit history, we discovered that previous commits correctly enabled the signature check as expected. The vulnerability was introduced in a commit, most likely due to a need for large code refactoring, since Circom and snarkjs both underwent prior major changes.  Impact  Severe. Without enabled signature checks, the ownership proof will always be valid, regardless of the correctness of the signature. A malicious proofer might use this vulnerability to forge valid zk-SNARK  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   proofs. As the signature is private data and hence not revealed to the public, this kind of behaviour would be potentially very dicult to detect.  Feasibility  Forging an ownership proof with the signature check disabled is a trivial effort. Whether this can be used to transfer value from UTXOs that are not owned by the attacker is not easy to estimate, as this depends on the ability of the attacker to provide all the other private data required to generate a valid proof.  Technical Details  In the gadget OwnershipProof(), the EdDSAPoseidonVerifier() subgadgets input signal eddsa.enabled is dened as the constant 0, whereas it should be dened as 1. We note that the correct setting is used in commits preceding the commit under investigation for this audit.  Remediation  Set eddsa.enabled to 1 so that the ownership proof works as intended. In addition, extend test coverage, to ensure that no future code update can re-introduce this vulnerability.  Status  The Zkopru team changed eddsa.enabled to 1 and added an ownership test catching the issue upon reintroduction.  Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Dene the Desired zk-SNARK Properties and Write Proper Proofs", "body": "  Location  zkopru-network/protocol-specification/  Synopsis  In SNARK statement design, attention should be given to the accuracy of the specications, as well as the mathematical and proong aspects of system design. In doing so, a comprehensive list of security assumptions should be clearly specied that can then be compared against the coded implementation.  Zkopru uses the zk-SNARK Groth16 to provide a range proof while hiding the account balance. The Groth16 SNARK hinges on certain cryptographic assumptions about elliptic curve pairings and requires a trusted setup. The common reference string (CRS) is usually constructed through a secure multi-party computation (MPC). In our audit, we found that the documentation did not explicitly mention the cryptographic assumptions. Details about the construction of the CRS were also missing.  Technical Details  During our review, we rst audited the zk-SNARK implementation for coding errors and then compared it to the statement that the Zkopru team provided to us upon request (see the section System Design). However, we identied four problems with the statement provided:  1. The assumptions that the system relies on are not explicit. 2. The properties that the SNARK is intended to guarantee are not explicit. 3. There are no proper proofs for the guaranteed properties. 4. There is not any reference to the common reference string that is used in the system and there is  not a description about how that CRS was computed, or why it can be trusted.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   In the Zkopru transaction documentation, the following is stated:  Zkopru achieves privacy using the commitment-nullier scheme. It means that a zk transaction spends a UTXO while not revealing which note has been used.  However, from a security point of view, this is too vague. For example, exactly what is guaranteed to stay private and under what assumptions is unclear. Additionally, it is unknown to which commitment-nullier scheme the documentation refers to and there is not a proof for the claimed properties.  Mitigation  If writing a proper proof is untenable at this point in the Zkopru project, we recommend that at least the statement description is expanded by providing a clear list of assumptions, referencing the common reference string trusted setup phase and making the claimed guarantees as explicit as possible. At minimum, some high level reasoning should be given about why it is impossible to unreveal any spent UTXO.  Remediation  In [BCG+14], the authors dened their version of what they called a decentralized anonymous payment scheme [DAP scheme], and then proved its critical properties like ledger indistinguishability, transaction non-malleability and balance invariance (Section 3.4, [BCG+14]).  We recommend to rst make the Zkopru adaptation of a DAP scheme explicit, then derive an analog to theorem 4.1 in [BCG+14] and prove equivalent properties, which could be called something like contract state indistinguishability, transaction non-malleability and multi-asset-balance invariance. In contrast to [BCG+14], more than one asset type is involved, so a proper denition of something we could call a multi-asset commitment-nullier scheme is needed.  Status  The Zkopru team developed a specication for the protocol, which includes a zk-SNARK statement. However, a formal specication of the SNARK properties and security proofs is still missing. The trusted setup has been completed on the Zkopru website and they have noted that a verication script will soon be published.  Verication  Partially Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Circuit Does Not Check the ERC-20 Sum Correctly (Known Issue)", "body": "  Location  circuits/lib/zk_transaction.circom#L255  Synopsis  The current circuit only checks the sum of ERC-20 tokens for the token addresses included in the input notes, but not for others, which could enable a malicious actor to drain funds.  Impact  Severe. An attack could result in token loss, with the attacker potentially draining funds. Moreover, an attack of this type would be potentially undetectable, since tokens would only be seen on the smart contract side. The amount of tokens that can be potentially stolen is limited to the tokens that are rolled up.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  Some amount of tokens need to be rolled up in order to be stolen.  Technical Details  The following is an input that works as intended:  inputs: [ { token: DAI, amount: 10 }, {token: WETH, amount: 1}],  outputs: inputs: [ { token: DAI, amount: 5 }, { token: DAI, amount: 5 }, {token: WETH,amount: 1}],  However, this also returns true in the following, unintended case:  inputs: [ { token: DAI, amount: 10 }, {token: WETH, amount: 1}],  outputs: inputs: [ { token: DAI, amount: 5 }, { token: DAI, amount: 5 }, {token: WETH, amount: 1}, { token: USDC, amount: 1000000 }],  Remediation  Modify the circuit to enforce that outputs do not contain ERC-20 addresses that are not part of any spend note.  Status  This issue was found and resolved by the Zkopru team in writing the zk-SNARK statement during the audit.  Verication  Resolved.  Suggestion 1: Increase Code Comments  Location  Some examples, although not an exhaustive list: packages/circuits/lib  contracts/consensus/BurnAuction.sol  Synopsis  Circuits  Code comments within the codebase are critical for developers and reviewers, as they help to dene and explain the purpose of each gadget and provide a description of the intended functionality. Furthermore, code comments can highlight other key information, such as which areas are vulnerable to potential failure, which is critical in making sure the system is implemented correctly. A comprehensive description of the intended functionality of each gadget is missing. The lack of sucient code comments hinders the readability and auditability of the code. For example, in if_else_then.circom, a helpful comment would say the following:  The gadget IfTHenElse(n) is satised if and only if: ( (For all n: obj1[n] == obj2[n]) AND out == if_v ) OR (There is a n: obj1[n] =!= obj2[n] AND out == else_v) )  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   Smart Contracts  Additionally, the smart contracts lack sucient comments. For example, the lack of sucient comments on the Burn Auction contract made the consensus mechanism particularly time-consuming to examine and understand in detail. Thorough and clear code comments make the system easier to use and review.  Mitigation  Circuits  We recommend the Zkopru team expand code comment coverage so that each gadget is accompanied by a code comment describing what it is intended to prove.  Smart Contracts  Additionally, expand smart contract code comments to include comments describing the intended behavior.  Status  The Zkopru team has added descriptive code comments to the circuits and smart contracts.  Verication  Resolved.  Smart Contracts  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Front Running of Challenge Transactions", "body": "  Location  zkopru/controllers/Challengeable.sol#L48  Synopsis  Ethereum uses gas auction to order transactions in the mempool: the transaction with the higher gas price or gas limit gets into the mempool rst and will be included in the block. A front runner bot which scans the mempool of Ethereum may front run the challenge transaction with higher gas price and gas limit and, as a result, gets the slash rewards.  Impact A front runner can steal the slash rewards from original validators, which is \u2154 of the proposer staked (32 ETH) in the burn auction, and weakens the incentivization of performing the validation work.  Preconditions  Anyone can front run a transaction using a higher gas price/limit as long as the prot it gains is higher than gas cost.  Feasibility  A front runner bot that constantly scans the mempool looking for protable transactions can front run the challenge transaction. These kinds of bots are known to exist and have carried out attacks of this type in the past.  Technical Details  The challenger sends a challenge transaction to the Zkopru.sol contract, then it redirects the call to the fallback function of Challengeable.sol, which redirects it to the validators contract for validation. If  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  16  This audit makes no statements or warranties and is for discussion purposes only.   the challenge is successful, it will trigger the slash function, the bad block proposer will be slashed and the challenger will be rewarded. The front runner who front runs the challenge transaction will get the reward instead of the real challenger.  Mitigation  There is no known mitigation, for such front running attacks, at this point. Since front running attacks are the natural consequence of the Ethereum mempool, the possibility of such attacks is a known disadvantage of optimistic rollups. We recommend that the Zkopru team monitor the progress of front running research for future potential mitigation strategies. In the interim, we also suggest that the validators be warned of this possible attack.  Remediation  There is no known effective protection against front running. Sending the transaction to a trustworthy miner which includes it in the block without broadcasting it to the network would block the attack, however, this is not practically implementable since mining is currently too costly to make this worthwhile.  Status  The Zkopru team has acknowledged and responded to the front running concern on slashing rewards. At present, they have chosen to keep the system as simple as possible. Our team considers this to be a reasonable choice, particularly given the nature of this issue and that introducing complexity at this stage may introduce additional harm. In addition, we note that this could reduce the incentives for validation. Nonetheless, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Front Running of Fees in Withdraw Transactions", "body": "  Location zkopru/controllers/UserInteractable.sol#L256  Synopsis  An attacker can front run the withdraw transaction and steal the caller fee.  Impact  If the fee is being front run, the withdraw caller would lose the incentive to withdraw for other users.  Preconditions  When a withdraw caller calls withdraw() for another user and there is a caller fee in the withdrawal note, a front runner can front run the fee in the transaction. When user A does not have sucient ETH to pay the transaction fee to withdraw, user B can call withdraw for user A. In this case, user A would attach a fee for the withdrawal caller (user B).  Feasibility  The incentive of a prot is dicult to estimate, and would depend on how high the fees are in comparison to the gas costs.  Technical Details  When the attacker front runs the withdraw transaction, the fee will be transferred to the message sender (the front runner) as the front runner is not the note owner.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  17  This audit makes no statements or warranties and is for discussion purposes only.   (bool success, ) = msg.sender.call{ value: fee }(\"\");  Remediation  Although there is no known effective protection against front running in general, this issue can be remediated by removing the use of msg.sender, and explicitly using signed state as the receiver of the fee payment.  Status  The Zkopru team has acknowledged and responded to the front running concern on withdrawal fees and, at present, have chosen to keep the system as simple as possible. Our team considers this to be a reasonable choice, particularly given the nature of this issue and that introducing complexity at this stage may introduce additional harm. Nonetheless, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue H: Reentrancy Attacks", "body": "  Location  zkopru/controllers/UserInteractable.sol#L269  zkopru/controllers/Coordinatable.sol#L183  Synopsis  An attacker can commit a reentrancy attack using the withdraw() function to drain all the Ether funds from the contract. We also found the reward withdraw function will transfer before decrementing the award state and may also be reentered.  Impact  The attacker could drain all the Ether funds from the contract.  Preconditions  The attacker can make a contract as the destination address of to.call( value: eth) and call back into the withdraw function in its fallback function, which would withdraw all the funds in the contract.  Feasibility  Highly feasible, as its easy to carry out and highly protable since the only costs for the attacker are gas costs.  Technical Details  The withdrawn state update (set to true) is done after the fund transfer call, the attacker can call the withdraw() function repeatedly to withdraw all funds before the withdrawn state is updated.  Remediation  Use the check effects interaction pattern. Update the state right after the state check:  require(!Storage.chain.withdrawn[withdrawalHash], \"Already withdrawn\");  Storage.chain.withdrawn[withdrawalHash] = true;  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  18  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Zkporu team has moved the state that marks the withdrawal boolean to before the transfer function, correcting the possible reentrancy attack.  Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue I: Fix Reentrancy Code Patterns", "body": "  Location  zkopru/controllers/Coordinatable.sol#L184  zkopru/controllers/Coordinatable.sol#L59  Synopsis  There are a few other locations where the contract state is only updated after calling external functions, which make the system susceptible to reentrancy attacks in which an attacker repeatedly calls certain functions to extract prot.  Impact  The different invocations of the function may change contract data in destructive ways, which could expose other vulnerabilities.  Preconditions  A call to an external function before nishing internal work, e.g. state change, in the contract.  Feasibility  Highly feasible as long as an attacker can gain prots from the external calls (e.g., withdrawing funds repeatedly).  Technical Details  The attacker can call the involved functions repeatedly, before the rst invocation of the function is nished. This may cause the different invocations of the function to interact in destructive ways. For example:  payable(proposerAddr).transfer(amount);  proposer.reward -= amount;  The attacker can use an external contract as the proposer address to call back the involved function which repeatedly transfers funds, before the reward is deducted. Only here the attack is not exploitable as the transfer function is only forwarded with a limited amount of gas (2300 wei), the call back is not possible with this amount of gas.  Remediation  Call external functions before nishing internal work (e.g. state updates ), update the state right after state check.  require(proposer.reward >= amount, \"You can't withdraw more than you have\");  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  19  This audit makes no statements or warranties and is for discussion purposes only.   proposer.reward -= amount;  payable(proposerAddr).transfer(amount);  Status  The Zkopru team has issued a commit that contains a list of smart contracts and functions where the correct check effects interaction pattern has been applied, eliminating the possibility for reentrance attacks on these functions.  Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue J: No Nullier Uniqueness Check", "body": "  Location  middlewares/default/block-generator.ts#L44  Synopsis  The Zkopru SNARK implements a commitment nullier scheme that requires each revealed nullier to be unique, in order to prevent double spending. It is therefore the burden of any verier to not only check the correctness of the Groth16 proof [G16], but also the uniqueness of any revealed nullier. Since the proposer includes the transactions to generate blocks, each spent UTXO should therefore have its unique nullier checked.  Impact  The block proposer will get slashed if there is a redundant nullier, causing a double spend issue when someone challenges the transaction. An attacker who submits a double spend transaction can challenge the block which includes the invalid transaction later to claim the slash reward.  Preconditions  The block producer/coordinator does not check the uniqueness of the spending note.  Feasibility  Highly feasible, as there is very high prot from this attack. An attacker can double spend if no one challenges the invalidate transaction or get a slash reward by challenging the bad block, since they know its invalid.  Remediation  Add a transaction nullier uniqueness check when the proposer generates blocks.  Status  The Zkopru team has responded noting that this is not an issue as they have client code that will ensure that the identier is unique in a dry run.  Verication  Resolved.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  20  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue K: No Withdrawal Note Validity Check (Out of Scope)", "body": "  Location  coordinator/src/api.ts#L111  zkopru/controllers/UserInteractable.sol#L92  Synopsis  There is no withdrawal note validity check when the prepayer receives an instant withdraw request. If the withdrawal note is invalid and the block which includes it is slashed later by a validator challenge, the bad block will not be nalized and the withdrawal note becomes non-withdrawable. This would result in the prepayer who bought this note taking the loss.  Impact  The prepayer will lose the funds they prepaid to the user who requests instant withdrawal with an invalid withdrawal note, which could be caught by a challenger before it is nalized, as they cannot withdraw.  Preconditions  This attack is possible if the withdrawal note is not valid, the prepayer does not verify it and pays the instant withdrawal. In this case, the note is transferred to the prepayer, the block which includes the invalid withdrawal note gets challenged later and cannot be nalized, and the prepayer cannot withdraw the prepaid withdrawal note they bought.  Feasibility  This is feasible as an attacker can forge an invalid withdrawal note and request instant withdrawal from a prepayer as long as the prepayer doesnt check the validity of the withdrawal note.  Remediation  When receiving an instant withdraw request, we recommend that the coordinator or prepayer should add a validity check for the withdrawal note that it is correctly included in the block.  Status  The Zkopru team has introduced verication checks in the API that may resolve this issue. However, we recommend that this out of scope code be further reviewed and evaluated, as it has not been thoroughly reviewed by our team.  Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue L: SNARK Validation Missed in On-chain/Off-chain Validation (Out of", "body": " Scope)  Location  src/validator/validator.ts#L398  Synopsis  When the validator validates a transaction, it runs a couple of validations on-chain/off-chain. One of the validations is SNARK validation, which validates the SNARK proof in the transaction and it is missed in the called validations.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  21  This audit makes no statements or warranties and is for discussion purposes only.   Impact  Invalid transactions can pass the validation, and an attacker can generate a transaction which outputs an invalid note of arbitrage amount, then withdraw it to L1, draining all the funds in the contract.  Feasibility  Highly feasible, as an attacker can gain huge prot just by making an invalid transaction.  Technical Details  The validateTx() function of the validator, returns an array of on-chain/off-chain validator functions in the array fnCalls, validateSNARKCalls (which validates SNARK proofs) is missed.  Remediation  Add the missed validateSNARKCalls in the array (fnCalls).  Status  This issue was reported to the Zkopru team and xed during the audit and prior to the delivery of the Initial Audit Report.  Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue M: No Caller Fee When Withdrawing Only Non-ETH Assets (ERC-20", "body": " Token and NFTs) (Known Issue)  Location  zkopru/controllers/UserInteractable.sol#L246  Synopsis  When withdrawing L2 assets to L1 for other users, the withdraw caller can get a caller fee as a reward. When there are only ERC-20 tokens and NFTs (and no ETH assets) in the withdrawal, the caller will not get a caller fee.  Impact  Withdraw caller will not get the caller fee.  Preconditions  The withdraw note only contains ERC-20 tokens and NFTs and the withdrawal fee is not zero.  Technical Details  In the withdraw function, when eth is not 0, the contract transfers the fee to the caller (whether the caller is the owner or not). When eth=0, there is no fee transfer logic, only the ERC-20 tokens and NFTs are transferred to the owner.  Remediation  Add fee transfer to the caller when eth=0.  Status  The addition of the fee logic has been moved out of the conditional statement, thus resolving this issue.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  22  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue N: Front Running of Burn Auction Bids", "body": "  Location  contracts/consensus/BurnAuction.sol  Synopsis  Staked coordinators may claim block proposal rights by winning a \"burn auction\". They make bids that must increase by 10% each accepted bid, until a time limit. But a front runner can submit the same bid with a slightly higher gas price to get their transaction moved to the start of the next block and considered the rst bid, and thus winning that price.  Impact  A front runner can win burn auctions and force honest bidders to increase bids, possibly making coordinating Zkopru unprotable for honest participants.  Preconditions  An honest coordinator is making a burn auction bid to gain block submission rights and then make a prot from transaction fees.  Technical Details  For coordinating to be protable, the amount spent in burn auctions must be less than the average amount gained in fees. This means that the burn auction is a competition about who can most accurately model the distribution of fees. The requirement that a bid be 10% more than the previous bid actually makes coordinating quite protable. Assuming accurate expected fees are known, then it is possible to make a bid slightly below the average fee, such that the next bid will be above it. For example, if 109 in fees is expected, and then 100 is bid, the next bid would be 110, which would lose 1 unit. Since fees are public information, it's expected that all coordinators know the averages. However, a front runner can submit the same bid, but at a slightly higher gas price, this forces the honest coordinator to make a bid at least 10% more, which may be unprotable.  Mitigation  Bids should be submitted with very high gas prices as close to the end of the block as possible, to reduce the chance that a front runner will have time to get their transaction in.  Remediation  Bids could be made with a commit-and-reveal pattern, or use a different consensus mechanism that is not threatened by front running, such as having all coordinators take turns.  Status  The 10% increment step has been removed, making the protable bid less obvious for front runners. However, since front running may still occur, we consider the issues partially resolved. We recommend implementing a different auction or consensus mechanism not threatened by front running to fully resolve the issue.  Verication  Partially Resolved.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  23  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue O: Old ERC-20 Token Interfaces May Lead to Stuck Tokens or Be", "body": " Blocked from Use  Location  zkopru/controllers/UserInteractable.sol#L263-L266  zkopru/controllers/UserInteractable.sol#L135  Synopsis  All instances of ERC-20 token transfer and transferFrom calls do not have a wrapper to anticipate the event that a token interface does not adhere to the standard of reverting in the case of failure. A missing return value bug may arise, leading to older tokens becoming locked on the contract when Zkopru needs to interact with them to withdraw. The Zkopru contract uses IERC20.sol, and if it interacts with a token that does not match IERC20 return values, there is a potential for the tokens to be locked in the contract.  To combat this possibility, the registration of a token in Zkopru must return a successful transfer trial. This can add a small amount of extra gas consumption and will block any older tokens that have a bad standard interface.  Impact  Tokens may become locked in the Zkopru contract and will be destroyed if this is not prevented in a standard way. Ensuring that tokens must transfer before registering them should reduce the possibility of this incident happening but will block bad interface tokens.  Preconditions  A token that does not conform to the standard that Zkopru expects is deposited and is unable to be withdrawn after. This token must get registered by passing the transfer checks so this may just result in the token being blocked from use in Zkopru.  Feasibility  Some tokens that are in use still adhere to a standard that does not return a value. A list of them is provided in the documentation on the missing return value bug.  Remediation  We recommend using a standard safe transfer wrapper, such as the one used by Uniswap or provided by OpenZeppelin, which will anticipate these interfaces with no return value and allow them to still be used.  Status  The safe transfer wrapper has been added to the Coordinatable.sol controller, thus eliminating the possibility of bad tokens being stuck.  Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue P: Operator Has Total Authority Over State Verication", "body": "  Location  contracts/zkopru/Zkopru.sol#L31  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  24  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  In the current implementation, the Zkopru contracts allow for the centrally owned operator to replace the SNARK circuit or the associated common reference string at any time. This SNARK circuit is used to verify shielded transactions. If this verication circuit is replaced with a malicious one, it will allow state updates that are malicious.  Impact  Severe. If the operator of the SNARK circuit becomes malicious or compromised, they are able to control all state updates. This can lead to the users losing all funds in the system.  Feasibility  In the early stages of the Layer 2 chain, it is against the self interest of the owner to commit fraud. However, this is a single point of failure that could become compromised through other attack methods.  Mitigation  While the SNARK circuits are still being nalized, it is favorable to be able to switch a broken circuit out quickly. Once the SNARK circuits have been nalized, the update function should be immediately switched to one controlled by a multisig contract.  Remediation  A democratic and transparent approach to the update of the consensus rules would be an ideal alternative to the currently centralized design. One way to do this would be to place a proposed circuit update on-chain where it could be voted on by the users of the system, or by those qualied to ensure that the new circuit is correct. SNARK circuits are complicated protocols and not easily reviewed by most people, so votes should be only placed on circuits that have been thoroughly audited by reliable and ethical sources.  Status  The setup phase of the smart contracts now renounces ownership on the OpenZepplen ownership smart contract.  Verication  Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue Q: Deposit Does Not Check For Registered Token", "body": "  Location  zkopru/controllers/UserInteractable.sol#L146  Synopsis  There is a registration process for tokens where they must be able to transfer tokens. This is a precaution for tokens that want to use Zkopru but do not adhere to the ERC-20 standard interface. The deposit function here should check that the tokens entering the Layer 2 chain have been registered and conform to ERC-20 standards.  Impact  Tokens deposited with an incorrect standard may become stuck on the contract.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  25  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  This is possible if tokens do not adhere to standards and this has happened in other systems.  Remediation  Add a requirement that the token being deposited, is in the registered tokens storage.  require(Storage.chain.registeredERC20s[token]  != address(0));  Status  The tokens entering now use the safe transfer wrapper to ensure that there is no return value bug and that the transfer interface exists on the tokens. However, the x now introduces redundant code, which should be removed:  zkopru/controllers/UserInteractable.sol#L185-L186  zkopru/controllers/UserInteractable.sol#L192-L193  As _checkNoteFields already performs the check.  Verication  Partially Resolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue R: Coordinator's URL/IP Address is Exposed in Auction Process,", "body": " Which Can Be Exploited For a DDoS Attack  Location  contracts/consensus/BurnAuction.sol#L108  coordinator/src/auction-monitor.ts#L207  Synopsis  In a burn auction, coordinators are required to set the URL when they join the auction. This URL/IP information is open to all coordinators. This enables a possible Distributed Denial of Service attack, in which a malicious coordinator can prevent the legitimate block proposer from proposing blocks and snatch the block proposing right without winning the burn auction.  Impact  A malicious coordinator can gain the block proposing right without being the winner in the burn auction or an attacker can prevent coordinators from proposing blocks to disrupt the system.  Preconditions  Assuming there are not many coordinators at the beginning of the system launch, an attacker can launch a DDoS attack against all coordinators during the block proposing round.  Feasibility  Highly likely, as winning the block proposal rights can be very competitive. The feasibility increases when there are fewer coordinators in an auction.  Technical Details  The coordinator is required to set their URL/IP with the auction smart contract when they join an auction. The smart contract will emit an event UrlUpdate once the coordinator sets the URL, and all coordinators  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  26  This audit makes no statements or warranties and is for discussion purposes only.   who join the auction will have access to the coordinator URL/IP by subscribing to the UrlUpdate event. A malicious coordinator can use this information to launch a DDoS attack against the winning coordinator during the block proposing round (10 minutes at 15 sec/block), thus preventing them from proposing blocks. After half of the round passes then any other coordinator can propose, but an attacker could launch a DDoS attack against the other coordinators, especially when there are not many of them. As a result, the malicious coordinator gains the proposal rights without winning the auction.  Mitigation  Implement an incentive mechanism that can attract enough coordinators to participate in the system, and have multiple coordinators propose the block during the block proposing round to ensure that, if one block proposer is attacked, another coordinator can still proceed with proposing the block. After half of the round has passed, any other coordinator can propose a block (since it is harder for the attacker to attack all other proposers). Additionally, we recommend that the Zkopru team investigate possible DDoS protections for coordinators to implement.  Remediation  Remove the URL/IP information requirements for coordinators to join the auction, using some anonymous routing protocol (Tor, I2P, Raven e.g.) to protect coordinator network metadata privacy (IP and its link to on-chain ID) from deanonymization attacks.  Status  The Zkopru team has responded stating that a browser wallet will be deployed on a subdomain of zkopru.network and the coordinators will only accept HTTP requests from the whitelisted domains. However, DDos attacks can still send non HTTP requests/data (e.g. SYN) to ood the coordinators bandwidth. As a result, we consider this issue to be partially resolved.  Verication  Partially Resolved.  Suggestion 2: Increase Test Coverage  Location  packages/circuits/tests  test/validators/tx-validator.soltest.js#L93-L97  test-cases/test/validators  Synopsis  Circuits  The zk-SNARK circuits include some test coverage, which demonstrate the intended use for the circuits. However, additional tests to account for potential edge cases would help to further protect against malicious actions and unexpected behavior  Smart Contracts  The smart contracts include test coverage that is limited to success cases (when the slash condition is false), and does not incorporate failures and errors. Furthermore, each validator should have corresponding tests (e.g. withdrawtreeValidator, NullifierTreeValidator, DepositValidator and UtxoTreeValidator), which are currently insucient.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  27  This audit makes no statements or warranties and is for discussion purposes only.   Increasing test coverage with specic attention to fail cases will help identify simple errors and prevent functionality from breaking when new code changes are introduced. In addition, tests help to detect and prevent unintended behavior and edge cases, which may result in the potential vulnerabilities.  Mitigation  Circuits  We recommend increasing test coverage to account for potential edge cases and unexpected behavior.  Smart Contracts  We recommend increasing test coverage for fail cases (e.g. slashable condition) and for all validator contracts.  Status  The Zkopru team has responded that they have provided additional tests and are currently onboarding new developers so they expect test coverage to increase in the near term. At the time of this verication, test coverage continues to be insucient.  Verication  Unresolved.  Suggestion 3: Expand System Documentation  Location  https://docs.zkopru.network/v/burrito  Synopsis  The project documentation provides an overview of the Zkopru system and the intended functionality for the smart contracts. However, the smart contracts interact with many off-chain components of the circuit system (e.g. coordinator, validator, SNARK verier, wallet client, fullnode, etc.) and these interactions are not comprehensively documented.  Furthermore, build and test documentation is missing and would provide a clear description of the setup process, which would avoid the potential for mistakes.  Insucient documentation of this nature leads to diculty understanding, reviewing, and using the system effectively.  Mitigation  We recommend creating detailed documentation of how the entire system interacts, which would provide a deeper appreciation and understanding of Zkopru. In addition, we recommend providing build and test documentation, which would prevent the potential for issues to arise during the initial setup phase.  Status  The Zkopru team has responded that the documentation would be updated before their launch to mainnet. At the time of this verication, this suggestion remains unresolved.  Verication  Unresolved.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  28  This audit makes no statements or warranties and is for discussion purposes only.   Suggestion 4: Remove Duplicate Code  Location  Example 1: zkopru/controllers/Challengeable.sol#L69  zkopru/controllers/Challengeable.sol#L66  Example 2: zkopru/libraries/MerkleTree.sol#L265  zkopru/libraries/MerkleTree.sol#L289  Synopsis  Example 1 demonstrates an instance of code duplication, where two identical lines of code exist in the system. Example 2 demonstrates an instance of two lines of code that are different but perform an identical function.  Code duplication should be avoided, as it increases storage costs and can lead to misunderstandings when making changes to and reviewing code.  Mitigation  We recommend performing a code review to identify and remove all duplicated lines of code.  Status  The Zkopru team has removed the duplicate code.  Verication  Resolved.  Suggestion 5: Update Compiler Version  Location  zkopru/controllers/Challengeable.sol  Synopsis  The compiler version is set to version 0.6.12, which does not incorporate newer compiler xes and updates.  Mitigation  We recommend updating the compiler version to 0.7.0\u20130.7.4. While more recent versions exist, we advise against their use as they may contain a higher probability of unknown issues.  Status  The compiler has been updated to v0.7.4. Since the time of the original report, there has been more time for compiler versions to settle. We recommend going as high as 0.8.0 if desired to achieve the new features such as EVM safe math and to regularly update the compiler to up to date, stable versions.  Verication  Resolved.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  29  This audit makes no statements or warranties and is for discussion purposes only.   Suggestion 6: Add Address Input Sanitization  Location  zkopru/controllers/Coordinatable.sol#L41  Synopsis  There are two ways to enter stake to the coordinator contract. If calling register(), the address will be hardcoded to be msg.sender and there will be no issue. However, if stake() is called directly, the address input is never examined for format correctness.  Mitigation  We recommend adding a check to the address coordinator input for at least NULL address with require(coordinator != address(0));.  Status  The Zkopru team has issued an update and a check for the zero address supplied for the coordinator is now present.  Verication  Resolved.  Suggestion 7: Address TODO Comments  Location  zkopru/controllers/UserInteractable.sol#L166  zkopru/controllers/Coordinatable.sol#L192  zkopru/libraries/Types.sol#L370  contracts/consensus/BurnAuction.sol#L170  Synopsis  The TODOs listed in the code may impact the security of the system. In the event that they are not planned to be implemented, a comment associated with each TODO explaining the rationale would benet from security review.  Mitigation  Complete TODOs or add documentation as to why they are unnecessary.  Status  The Zkopru team has responded that most of the TODO comments were outdated and have removed them where necessary.  Verication  Resolved.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  30  This audit makes no statements or warranties and is for discussion purposes only.   Suggestion 8: Audit Off-Chain Components  Location  packages/coordinator  packages/core  packages/account  packages/transaction  packages/zk-wizard  Synopsis  Off-chain components (coordinator, wallet client, validator, SNARK verier, synchronizer, transaction builder) were out of scope for this audit. To check the security of the system as a whole, these would require a security audit.  Mitigation  We recommend that audits of the off-chain components, including the coordinator, wallet client, validator, SNARK verier, transaction builder and synchronizer, are undertaken to check for potential vulnerabilities and to ensure that the interaction of the components function as intended.  Status  The Zkopru team has responded that, given that Zkopru is an optimistic rollup protocol, everything should be guaranteed on-chain. Off-chain components are only the implementation and they do not have any plans to have them audited.  Verication  Unresolved.  About Least Authority  We believe that people have a fundamental right to privacy and that the use of secure solutions enables people to more freely use the Internet and other connected technologies. We provide security consulting services to help others make their solutions more resistant to unauthorized access to data and unintended manipulation of the system. We support teams from the design phase through the production launch and after.  The Least Authority team has skills for reviewing code in C, C++, Python, Haskell, Rust, Node.js, Solidity, Go, and JavaScript for common security vulnerabilities and specic attack vectors. The team has reviewed implementations of cryptographic protocols and distributed system architecture, including in cryptocurrency, blockchains, payments, and smart contracts. Additionally, the team can utilize various tools to scan code and networks and build custom tools as necessary.  Least Authority was formed in 2011 to create and further empower freedom-compatible technologies. We moved the company to Berlin in 2016 and continue to expand our efforts. Although we are a small team, we believe that we can have a signicant impact on the world by being transparent and open about the work we do.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  31  This audit makes no statements or warranties and is for discussion purposes only.   For more information about our security consulting, please visit https://leastauthority.com/security-consulting/.  Our Methodology  We like to work with a transparent process and make our reviews a collaborative effort. The goals of our security audits are to improve the quality of systems we review and aim for sucient remediation to help protect users. The following is the methodology we use in our security audit process.  Manual Code Review  In manually reviewing all of the code, we look for any potential issues with code logic, error handling, protocol and header parsing, cryptographic errors, and random number generators. We also watch for areas where more defensive programming could reduce the risk of future mistakes and speed up future audits. Although our primary focus is on the in-scope code, we examine dependency code and behavior when it is relevant to a particular line of investigation.  Vulnerability Analysis Our audit techniques included manual code analysis, user interface interaction, and whitebox penetration testing. We look at the project's web site to get a high level understanding of what functionality the software under review provides. We then meet with the developers to gain an appreciation of their vision of the software. We install and use the relevant software, exploring the user interactions and roles. While we do this, we brainstorm threat models and attack surfaces. We read design documentation, review other audit results, search for similar projects, examine source code dependencies, skim open issue tickets, and generally investigate details other than the implementation. We hypothesize what vulnerabilities may be present, creating Issue entries, and for each we follow the following Issue Investigation and Remediation process.  Documenting Results We follow a conservative, transparent process for analyzing potential security vulnerabilities and seeing them through successful remediation. Whenever a potential issue is discovered, we immediately create an Issue entry for it in this document, even though we have not yet veried the feasibility and impact of the issue. This process is conservative because we document our suspicions early even if they are later shown to not represent exploitable vulnerabilities. We generally follow a process of rst documenting the suspicion with unresolved questions, then conrming the issue through code analysis, live experimentation, or automated tests. Code analysis is the most tentative, and we strive to provide test code, log captures, or screenshots demonstrating our conrmation. After this we analyze the feasibility of an attack in a live system.  Suggested Solutions We search for immediate mitigations that live deployments can take, and nally we suggest the requirements for remediation engineering for future releases. The mitigation and remediation recommendations should be scrutinized by the developers and deployment engineers, and successful mitigation and remediation is an ongoing collaborative process after we deliver our report, and before the details are made public.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  32  This audit makes no statements or warranties and is for discussion purposes only.   Responsible Disclosure Before our report or any details about our ndings and suggested solutions are made public, we like to work with your team to nd reasonable outcomes that can be addressed as soon as possible without an overly negative impact on pre-existing plans. Although the handling of issues must be done on a case-by-case basis, we always like to agree on a timeline for resolution that balances the impact on the users and the needs of your project team. We take this agreed timeline into account before publishing any reports to avoid the necessity for full disclosure.  Security Audit Report | Zkopru zk-SNARK Circuits + Smart Contracts | Ethereum Foundation 22 June 2021 by Least Authority TFA GmbH  33  This audit makes no statements or warranties and is for discussion purposes only.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_Zkopru_zk-SNARK_Circuits_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Operator Has Total Authority Over State Verication", "body": "  Location  /packages/loopring_v3/contracts/core/impl/BlockVerier.sol#L27  Synopsis  In the current implementation, the Loopring contracts allow for the centrally owned operator to replace the SNARK circuit at any time. This SNARK circuit is used to verify incoming blocks generated off-chain that will subsequently update the stored merkle root that controls the account state of all users and all components of the system. If this verication circuit is changed for something malicious, it will allow state updates that are malicious.  Impact  Severe. If the operator of the SNARK circuit becomes malicious or compromised, they are able to control all state updates. This can lead to the users losing all funds in the system.  Feasibility  In the early stages of the exchange, it is against the self interest of the Loopring organization to commit fraud. However, this is a single point of failure that could become compromised through other attack methods.  Mitigation  In advance of delivering this audit report, the Loopring team responded that they are dedicated to resolving this issue. While the SNARK circuits are still being nalized, it is favorable to be able to switch a  Security Audit Report | Loopring 3.6 Design + Implementation: Smart Contracts | Loopring 16 March 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   broken circuit out quickly. Once the SNARK circuits have been nalized, the update function should be immediately switched to one controlled by a multisig contract.  Remediation  As discussed with the Loopring team, a democratic and transparent approach to the update of the consensus rules would be an ideal alternative to the currently centralized design. One way to do this would be to place a proposed circuit update on-chain where it could be voted on by the users of the system, or by those qualied to ensure that the new circuit is correct. SNARK circuits are complicated protocols and not easily reviewed by most people. Votes should be only placed on circuits that have been thoroughly audited by reliable and ethical sources.  Status  The Loopring team has informed us that they intend to launch with a multisig contract, per the suggested mitigation, in addition to delays for ownership transfer and circuit upgrade of seven days that will also allow users time to exit if they suspect that a governance action is malicious. A full remediation is currently dicult since an agreed upon democratic and transparent approach to the update of the consensus rules has not been established, however, we recommend that the Loopring team continue to investigate, research, and implement long term strategies that promote decentralization.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Loopring_3.6_Design_Implementation_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Potential Limbo Exit \u2013 Withdrawal Fee Grieng", "body": "  Location  /packages/loopring_v3/contracts/core/impl/libexchange/ExchangeWithdrawals.sol#L61  Synopsis  A limbo exit is a result of a single source of truth creating off-chain state updates and a data availability problem, as was rst theorized during Plasma scalability discussions. A form of it is present in Loopring as well: operators have the ability to process state but not reveal this processed state to anyone. If a user submits a transaction off-chain but does not see that their transaction is being processed, they will initiate a forced withdrawal on-chain. At a later point, the operator can reveal the block that includes the transaction that invalidates the withdrawal and block the process of forced withdrawal. These forced withdrawals require fees to be processed, and if the withdrawal is invalidated by the revealed block, the user will be griefed a small amount for the fees.  Impact  The impact of this is low because fees are not very high, and the operator is not incentivized to hurt their own business by committing these types of infractions.  Preconditions  The operator includes a transaction for a trade or a transfer of funds, but does reveal or commit the block that includes this transaction to the mainnet.  Feasibility  This is easily feasible but the incentive to do so is not aligned.  Security Audit Report | Loopring 3.6 Design + Implementation: Smart Contracts | Loopring 16 March 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation  This issue results from the fact that data availability is in the control of layer-2 operators and, to the best of our knowledge,  reasonable protocol level solutions for addressing this issue are currently unavailable. However, out-of-band channels such as social media will ensure that there is a reputation loss for the Loopring organization if this is attempted beyond an accidental incident. We simply suggest that this issue be made public to encourage transparent reporting of incidents that may arise.  Status  The Loopring team has incorporated additional documentation on the issue of withdrawal fee grieng, along with providing a mitigation strategy, in accordance with our suggested mitigation.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Loopring_3.6_Design_Implementation_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Missing Check for the Distributor Address Can Lead to the Loss of", "body": " Access Control for the Respective Token  Location  contracts/interchain-token-service/InterchainTokenService.sol#L612  Synopsis  In the function _processDeployStandardizedTokenAndManagerPayload, the distributor address is obtained, in bytes, through the function distributorBytes, after which it is converted to address. There is no check verifying that it is not address(0). Only the distributorBytes length is checked, which is not sucient because the following address can be passed:  address(0) {\"0x0000000000000000000000000000000000000000\"}  Impact  If the function distributorBytes is an address(0), then access control for that token can be lost.  Preconditions  This Issue is possible if the value of distributorBytes is:  0x0000000000000000000000000000000000000000.  Security Audit Report | Smart Contracts | Axelar Network 19 October 2023 by Least Authority TFA GmbH  4  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  Low.  Remediation  We recommend adding an address(0) check after obtaining the distributor address from the function distributerBytes.  Status  The Axelar Network team has added a check to verify that the distributor address is not address(0).  Verication  Resolved  ", "html_url": "https://leastauthority.com/axelar_network_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: ETH Can Be Locked in the Contract Indenitely", "body": "  Location  contracts/utils/StandardizedTokenDeployer.sol#L45-L54  contracts/utils/TokenManagerDeployer.sol#L33  Synopsis  These functions are dened as payable. However, it is not possible to withdraw the ETH in the contracts.  Impact  This Issue could result in ETH being locked in the contract for an indenite amount of time.  Preconditions  The Issue is likely if these payable functions are called with Eth(msg.value > 0).  Mitigation  We recommend updating the functions to nonpayable.  Status  The Axelar Network Network team acknowledged the Issue but stated that deployers are payable because they are delegated by payable methods.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/axelar_network_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Updates Between Non-Zero Allowances Can Result in Exploits", "body": "  Location  contracts/token-implementations/ERC20.sol#L61  Synopsis  The process by which a user updates from one non-zero allowance to another can be susceptible to exploits. When user A approves the transfer of N tokens to user B, and user A updates the allowance to M using the approve function, user B can deploy the approve transaction in the mempool and take M+N  Security Audit Report | Smart Contracts | Axelar Network 19 October 2023 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   tokens by transferring N tokens just before the second approval with a higher gas price, and transferring M tokens after the second approval.  Impact  In this case, this Issue could result in user B stealing user As M tokens.  Remediation  We recommend that the Axelar Network team prevent updates between non-zero allowances. The user planning to update the approval from one non-zero allowance to another must rst set the allowance to zero. As a result, the user can detect if the allowance was used by the approved user before the new approval. For example:  function approve(address spender, uint256 amount) external virtual override  returns (bool) {  require(!((amount!= 0) && (allowance[msg.sender][_spender] != 0)));  _approve(msg.sender, spender, amount);  return true;  }  Status  The Axelar Network team stated that checking the ERC20 approval amount would result in a tradeoff, as it would increase the gas cost of approvals by more than 5k gas each. Hence, the team decided not to address this suggestion, noting that users can set the allowance to zero in between if they choose to. .  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/axelar_network_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Deanonymization Attack Targeting Sender Node of Proximity", "body": " Order 0 and Light Node  Synopsis  In Swarm, sender anonymity, or more precisely, the ambiguity of a node, is based on Forwarding Kademlia routing, thus a node can be a forwarder or an originator of a chunk or message. However, there are two exceptions:  1.  If the chunk or PSS message is sent from a node with Proximity Order (PO) 0, the node must be an originator of the chunk/message.  2. Light node can only be the originator as light node can not forward chunk/message.  Security Audit Report | Bee + Bee Clef | Swarm Association 26 November 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Impact  Nodes with PO 0 or a light node would be an easy target for a deanonymization attack, which could result in leaks of network meta data (e.g. IP, location) through Kademlia DHT. This network metadata could enable other attacks including DoS attacks and censorship attacks. However, this deanonymization attack would not reveal the contents of the chunk/message.  Preconditions  A chunk/PSS message is sent by a node of PO 0 or a light node to the attacker node.  Feasibility  The feasibility of this attack depends on the number of attacker nodes. For every attacker node, there is a 50% percent chance of being the PO 0 node. The probability of a successful attack is linear in the number of attacker nodes.  Mitigation  The following are potential approaches to mitigate this issue:   Use a proxy node to hide the sender node. The limitation of this approach is that if the proxy node  is attacked, the sender node will be deanonymized or taken down.   A Bee node owner can use network layer anonymization tools such as Onion routing, mixnet, or  others to connect to the Swarm network.   The planned spoof-resistant overlay addressing to mitigate neighborhood mining will also reduce  the feasibility of an attacker generating a large number of malicious nodes.   A more comprehensive mitigation to this class of deanonymization attacks is to attract as many  nodes to the network as possible, thus reducing the chance of sybil attacks leading to deanonymization attacks.  We recommend that the Swarm team continue to improve the incentive mechanism, including Swap and postage lottery, in order to attract more users to the network and increase overall security. In addition, we suggest advising users of the risk of this attack and the mitigation approaches.  Status  The Swarm team has responded that they have not yet identied an effective solution to resolve this issue. We recommend that the Swarm team continue to explore effective mitigation strategies to improve the incentive mechanism.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Swarm_Association_Bee_and_Bee_Clef_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Deanonymization Attack Based on Eclipse Attack", "body": "  Synopsis  In the case that a victim node is eclipsed in a neighborhood and if the victim node is the sender/retriever/receiver of a chunk or message, it will be deanonymized by the attacker.  Impact  Once a node is deanonymized, the node becomes vulnerable to other attacks such as DoS attacks, censorship attacks, and others.  Security Audit Report | Bee + Bee Clef | Swarm Association 26 November 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  The attacker nodes occupy the neighborhood of the victim node in an eclipse attack by mining addresses in the neighborhood and capturing the chunks sent to or from the victim node.  Feasibility  The probability of capturing a neighborhood is low, as there is an upper bound of neighborhood depth. Although currently not implemented, spooess address features that may be introduced in the future could make mining addresses in a specic neighborhood prohibitively dicult and expensive.  Technical Details  Attacker nodes occupy the neighborhood; any chunk/message sent to or from the victim node will be captured by the attacker, thus capturing the sender overlay address and other network meta data such as IP address and location. This data leak could result in other kinds of attacks such as DoS, censorship attacks, and others.  Remediation  We recommend taking steps to make address mining costly as a mitigation for eclipse attacks. We note that spooess addresses are proposed for implementation. This step would make address mining costly, although Ethereum miners can still mine addresses by manipulating the block hash.  We also note that the neighborhood depth upper limit makes occupying a neighborhood dicult. Additionally, the chunks/messages content is encrypted, therefore the contents link to its sender and receiver would not be revealed. Furthermore, it is very dicult for an attacker to distinguish a normal chunk from a PSS message (a Trojan chunk), further obfuscating the message.  Status  The Swarm team has implemented spooess overlay network addresses, which use the Ethereum blockhash (one block after the block that contains the node's chequebook transaction) as a source of randomness for overlay addresses, which strongly discourages address mining. Theoretically, however, Ethereum miners can still be bribed to mine addresses in a specic neighborhood by ltering addresses which do not lie in the victim nodes neighborhood. The current implemented mitigation makes that action prohibitively expensive and dicult to control, as it is dicult for the miner to mine two consecutive blocks. However, in order to fully resolve the issue, the Swarm team needs to make address mining impossible by implementing a better source of randomness for address derivation (e.g. beacon chain RANDAO in Eth 2.0), which is not available in Eth 1.0. Thus, we recommend that the Swarm team continue to explore new options as they become available to fully resolve the issue.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Swarm_Association_Bee_and_Bee_Clef_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Incorrect gcSizeChange Updates", "body": "  Location  pkg/localstore/mode_put.go#L136  Synopsis  When storing the chunk to local storage, garbage collection size is updated. However, it is updated twice in the wrong location.  Security Audit Report | Bee + Bee Clef | Swarm Association 26 November 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Impact  The garbage collection size will update to an incorrect size, resulting in distorted garbage collecting behavior.  Preconditions  The chunks upload mode is set to ModePutUpload.  Feasibility  Straightforward.  Technical Details  When chunks upload mode is set to ModePutUpload, gcSizeChange will be updated twice with  gcSizeChange += c.  Remediation  We recommend moving the second gcSizeChange update into the mode == storage.ModePutUploadPin branch case.  if mode == storage.ModePutUploadPin {  c, err = db.setPin(batch, item)  if err != nil {  return nil, err  }  gcSizeChange += c  }  Status  The Swarm team has implemented a remediation for the gcSizeChange update, as suggested.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Swarm_Association_Bee_and_Bee_Clef_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Access i.PinCounter Without Checking for Error", "body": "  Location  pkg/localstore/mode_set.go#L268  Synopsis  When a chunk is pinned to be excluded from garbage collection, the existing pin counter needs to be fetched from the pin index. The error from fetch is not checked before accessing the pin counter.  Impact  The program will panic and exit if there is an error from fetching the pin index(pinIndex).  Security Audit Report | Bee + Bee Clef | Swarm Association 26 November 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  There is an error (e.g. address not found) in the execution of fetch on the pin counter.  Feasibility  Straightforward.  Technical Details  In function setPin:  i, err := db.pinIndex.Get(item)  item.PinCounter = i.PinCounter  if err != nil {  \u2026  i.PinCounter is accessed before the error check. If there is an error, i.PinCounter would panic the program and exit.  Remediation  We recommend moving item.PinCounter = i.PinCounter down after the error check block.  Status  The Swarm team has responded and provided supporting evidence that this is a non-issue. In particular, shed.Index.Get returns an instance, not a pointer. Rather than panic on error, the default value of the pin counter on the item (zero) is used instead. We acknowledge and conrm that this issue is no longer valid.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Swarm_Association_Bee_and_Bee_Clef_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Wrong Tier When Postage Batch value=0", "body": "  Location  postage/batchstore/reserve.go#L193  Synopsis  When the postage batch value=0, the tier function returns the wrong tier (inner tier) instead of unreserved.  Impact  The wrong tier results in a wrong reserve size calculation, enabling an incorrect chunk allocation in the reserve.  Preconditions  The value of a postage batch is 0.  Technical Details  In the tier function, the tier is returned based on postage value compared to inner value and outer value of a reserve:  // x < rs.Inner || x == 0  if x.Cmp(rs.Inner) < 0 || rs.Inner.Cmp(big.NewInt(0)) == 0 {  Security Audit Report | Bee + Bee Clef | Swarm Association 26 November 2021 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   return unreserved  }  if x.Cmp(rs.Outer) < 0 { return inner  }  If x == 0,  tier would return inner value instead of unreserved (the correct tier).  Remediation  We recommend replacing  rs.Inner.Cmp(big.NewInt(0)) == 0  with  x.Cmp(big.NewInt(0)) == 0.  Status  The Swarm team has responded that the batch value is normalized value equal to cumulative payout per chunk plus the amount per chunk approved by the postage stamp smart contract, which will always be greater than 0 (except at epoch 0). As a result, we acknowledge and conrm that this issue is no longer valid. However, a related issue with very small batch value was identied while investigating this issue (see Issue G).  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Swarm_Association_Bee_and_Bee_Clef_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Blackhole (Censorship) Attacks", "body": "  Location  pkg/pushsync/pushsync.go#L256  pkg/pushsync/pushsync.go#L269  Synopsis  A malicious/censoring forwarder node can forge a receipt message that says that a chunk was stored in its destination when in reality it was dropped or ignored.  Impact  This could lead to lost chunks in the network and an attacker node gaining an illegitimate reward.  Preconditions  A victim node must send a chunk to a destination, which is dropped by a malicious forwarder node in a forwarding route.  Security Audit Report | Bee + Bee Clef | Swarm Association 26 November 2021 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  Moderate. A forwarder node is incentivised not to forward the chunk and claim the reward. Alternatively, a single owner chunk could be censored if somehow the attacker knows its a feed chunk, even without incentive.  Technical Details  An attacker node receives a chunk from another node. The attacking node drops or discards the chunk and passes back a forged receipt indicating that the chunk was stored successfully. The attacking node would then be eligible to claim a reward via the SWAP protocol.  Remediation  We recommend implementing a change where the uploader and forwarder (who caches the chunk incentivised by SWAP) can verify uploading/forwarding (push-sync) by retrieving a chunk through an alternative route after a successful forwarding within a random amount of time. If the retrieval fails, the node can push/sync the cached chunk through an alternative route.  Status  The Swarm team has responded that implementing the suggested remediation is non-trivial due to the cost and the signicant required change to the architecture, in addition to making syncing slow and unreliable. They note that guaranteeing disjoint path traversal for retrieval and push is complex and dicult to achieve. In addition, the Swarm team does not want to introduce cross protocol dependency (relying on the forwarder) as it would introduce additional complexity. Instead, they are working towards identifying and implementing solutions that would result in a more reliable syncing process that is less susceptible to manipulation (i.e. the uploader veries the upload and resends chunk via a disjoint path if the verication fails). We acknowledge their decision and agree that the proposed solution would be sucient, as long as the disjoint path is not blocked by a blackhole attack. Our suggested remediation is an extension of this approach. Given that a solution has yet to be implemented and veried by our team at this time, this issue remains unresolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Swarm_Association_Bee_and_Bee_Clef_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Batches With a Small Batch Value May Enter the Batch Store", "body": "  Location  postage/batchservice/batchservice.go#L33  master/src/PostageStamp.sol#L109  Synopsis  A batch with a small batch value might enter the batch store, since there is no zero or  amount per chunk value check in the postage stamp contract, causing other valid batches to be marked (queued) for eviction once the nodes reserve capacity is reached.  Impact  Valid batches will be marked (queued) for eviction when the nodes reserve capacity is reached.  Preconditions  A batch with a zero or very small balance per chunk is purchased and created in the postage stamp contract.  Security Audit Report | Bee + Bee Clef | Swarm Association 26 November 2021 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  As batch value is normalized value equal to cumulative payout per chunk plus amount per chunk approved by the postage stamp contract, since there is no zero or small amount per chunk value check in the postage stamp smart contract so a batch with a very small  amount per chunk value might enter the batch store, increasing the reserve radius. This would result in other valid batches being marked (queued) for eviction when the nodes reserve capacity is reached. The newly added small value batch will also be marked for eviction in the subsequent blocks. Once it is evicted, the reserve radius has to decrease again, and the previous queued valid batches will be dequeued (unmarked) from being evicted (this has not been implemented and the Swarm team has indicated that they are actively working on it).  Mitigation  We recommend not adding batches that have a value equaling total cumulative payout (amount per chunk =0) or batches that are going to expire (small amount per chunk value) within the next couple of blocks.  Remediation  We recommend allowing the batches with a zero or small amount per chunk value to enter the batch store, which increases the reserve radius. However, reserve radius should decrease once the batch with small values is evicted, and previous queued valid batches should be dequeued (unmarked) from being evicted.  Status  The Swarm team has applied a stop gap to prevent adding batches that have a value equaling total cumulative payout or batches that are going to expire within the next couple of blocks. The mitigation has been implemented and merged with the master branch. In addition, the postage stamp smart contract will also be updated to block the 0 value batch(_initialBalancePerChunk = 0) in the next iteration.  Our team agrees that this is an effective mitigation as long as the price event on-chain can be accurately tracked (which is updated every \u00bd block), the price is not updated too frequently (it is currently updated manually once the network capacity is reached), and is least intrusive to the existing nodes. Given that a full remediative is still in progress, this issue remains partially resolved at the time of this verication.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Swarm_Association_Bee_and_Bee_Clef_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A:  Swift Memory Security Might Compromise Private Key Deletion", "body": "   Location   Function  deleteKeyPair()  in  /TezosKit/Crypto/EllipticCurveKeyPair/EllipticCurveKeyPair.swift   Synopsis   According to the expected behavior of the Swift programming language, function  deleteKeyPair()  might not fully erase the footprint of the private key in storage. This behavior in Swift is designed so that  some parts of the memory are not controlled by the developers. In particular, copies of memory can be  created at runtime that are uncontrollable and untrackable. Moreover, the operating system can move and  copy memory without hindrance. As a result, this might allow an attacker to read the private key from  RAM.   Impact   If successful, an attacker is able to access a private key and has full control over the wallet and its funds.   Feasibility   Low. Since locating the private key footprint in the RAM is difficult, it would also be difficult to carry out  such an attack in a real world application. However, this is a general concern that has also been noted in  the  Apple Security Development Checklist .   Mitigation   Since this issue is based on the expected behavior of Swift, we recommend that the development team  research potential mitigation strategies that align with industry best practices.   Status   Since research for a mitigation strategy by the development team drew inconclusive results, our team  suggested adhering to  Apple's Security Development Checklists , specifically as it pertains to the  following:   Scrub (zero) user passwords from memory after validation:  Passwords must be kept in memory for the  minimum amount of time possible and should be written over, not just released, when no longer needed.  It is possible to read data out of memory even if the application no longer has pointers to it.   Security Audit Report | TezosKit | Tezos Foundation 8 May 2020 by Least Authority TFA GmbH   4   This audit makes no statements or warranties and is for discussion purposes only.        Notifying implementers of TezosKit about security best practices adequately mitigates the issue, at this  point. As a result, a comment alerting that there is a secret key stored in memory when using the  Wallet  class has been  added to the code , linking to Apples best practice suggestions. However, we are not  certain this will be an appropriate long-term solution as this is a fundamental issue with SWIFT and it is  hoped that it will be addressed at that level.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_TezosKit_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Undefined Behavior in the Tez Class", "body": "   Location     /TezosKit/Common/Models/Tez.swift   Synopsis   The  Tez  class uses  bignums  to represent the native token of the Tezos currency but can be initialized  with  init(_ balance: double) , which accepts negative values and results in undefined behavior.   Impact   We are not aware of any attack that can be based on this behavior. However, the type  Tez  does not  behave according to the Michelson specifications, outlined in  Michelson: the language of Smart Contracts  in Tezos  and  Michelson Reference , which might lead to various unexpected problems with calculations.    Feasibility   The problem may arise whenever a developer wants to subtract a certain amount of  Tez  from another  Tez  and uses negative  Tez  and addition to achieve that.     Technical Details   Suppose a user has 2.1  Tez  and wants to subtract 1.999999  Tez  from this. The computation is 2.1  Tez  -  1.999999  Tez  = 0.100001  Tez . However, since  init(_ balance: double)  accepts negative  Tez , the  user can execute something like the following:   let tez1 = Tez(2.1)   let tez2 = Tez(-1.999999)   let result = tez1 + tez2   This gives the undefined value  result = 1,-899999  which is not a number. This happens because  tez2 is the non number \u2018-1.-999999.   Remediation   Prevent initialization with negative  Tez . According to the Michelson specifications, the type  Tez  should  only be able to store positive values.    Status   A  remediation strategy has been implemented  so that the  Tez  class now uses  BigUInt  instead of  BigInt  internally to represent  Tez  decimals in addition to ensuring that the initializer  init(_  balance: double)  fails on any attempt to initialize a negative amount of  Tez .   Security Audit Report | TezosKit | Tezos Foundation 8 May 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.        Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_TezosKit_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C:  TezosKit Does Not Support Unbounded  nat  and  int  types", "body": "   Location   /TezosKit/Common/Michelson/IntMichelsonParameter.swift   Synopsis   According to the Michelson specifications, the types  nat  and  int  are unbounded and the size of the  actual instances is only controlled by storage and gas cost. However, this is not reflected in TezosKit as it  mixes both types and represents them internally as the Swift signed integer type  Int . This is equivalent to  Int_32  on 32-bit platforms and  Int_64  on 64-bit platforms.   Impact   Since the TezosKit implementation of both  nat  and  int  is bounded by 32/64 bit signed integers, it is not  possible to send parameters or read storage of those types from/to on-chain Tezos Smart contracts that  exceed the storage capacities of Swifts  Int  type, leading to various boundary errors. For example, it is  not possible to write the number 9,223,372,036,854,775,808 into a  nat   type  storage of any Tezos Smart  contract using TezosKit.    Remediation   Implement the  IntMichelsonParameter  class using  bignum  instead of  Int  internally. This does not  lead to overflow errors, as the storage of Michelson Smart Contract is bounded by storage and gas costs.     Status   A  remediation strategy has been implemented  so that the  IntMichelsonParameter  class is now split  into two representations:  IntMichelsonParameter  and  NatMichelsonParameter  of the Michelson  types  int  and  nat . In addition,  BinInt  and  BigUint  can now be used to account for big numbers.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_TezosKit_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Hex Seeded Key Initializer is Hard Coded to Ed25519 Curve", "body": "   Location   Initializers in  /TezosKit/Common/Models/Wallet.swift   Synopsis   We found a bug that the curve value was hard coded, despite giving a choice for the user to select a  curve from three choices: Ed25519, Secp256k1 and P256. As a result, the function did not respect  the parameters selected by the user and forced the wallet to use the Ed25519 curve in all cases.   Impact   The user believes they have selected a particular elliptic curve and, as a result, believes they have selected  different security properties.   Remediation   A  commit has been added which resolves this  by making the selection take effect. As a result, when the  wallet or other application uses the  SecretKey  struct, it will initialize the  SecretKey  struct with the   Security Audit Report | TezosKit | Tezos Foundation 8 May 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.          signing curve that is passed into the  init()  function, rather than having Ed25519 hard coded as the only  signing curve that the struct would be initialized with.   Status   The above remediation was implemented prior to the completion of the security audit and delivery of the  audit report.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_TezosKit_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: No Restriction Preventing Transfer to Unapproved Recipient", "body": " (Known Issue)  Location  /Endaoment-V2-Smart-Contracts/src/Entity.sol#L251  Synopsis  The Endaoment team identied a vulnerability, which violates the business requirement that tokens can only move between entities and that any transfer outside of the Endaoment V2 smart contract system, unless performed by an Admin in adherence to strict conditions, is a violation of the legal regulations governing 501(c)(3) entities. This could result in the loss of the tax-exempt status of the Endaoment organization, preventing business operations from continuing. The system of smart contracts is intended to enforce this requirement.  The transfer function is intended to be used by a fund manager to transfer donated funds to approved recipients within the Endaoment system. To execute the transfer, the function calls the internal function _transferWithFeeMultiplier, which performs the transfer of balances from the fund address to the recipient address. However, no check is performed to verify that the recipient is an approved account. As a result, a fund manager could transfer funds outside of the Endaoment system, breaking the requirement that is intended to be enforced by the smart contracts.  Impact  A transfer of funds by a fund manager to an address outside of the Endaoment system could jeopardize the tax-exempt status of the organization.  Preconditions  The transfer function is used with a recipient address that is outside the Endaoment system.  Feasibility  Straightforward.  Security Audit Report | Endaoment v2 Smart Contracts | Endaoment 20 July 2022 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  A check in the internal function _transferWithFeeMultiplier must be performed to verify that the recipient address of the transfer operation is an approved entity.  Status  The Endaoment team implemented an additional check to prevent the funds from being sent to an entity that is not approved by Endaoment.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Endaoment_V2_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Secret Used to Encrypt Shares Sent Over Network", "body": "  Location  src/cryptography/utils.ts#L72-L79  src/app.ts#L395  Synopsis  The Capsule team uses a 16-byte random userHandle to derive a keypair, which is then used in the portal code (out of scope) to encrypt shares that are sent to the server. The userHandle is stored as a username in the navigator.credentials API user agent solution and is used to generate a PublicKeyCredential. The response of navigator.credentials.get contains the username. This response object is sent to the server to the biometrics/verify API endpoint.  Impact  Since the secret that was used to encrypt the shares is sent to the server, which also receives the encrypted share, the server has the opportunity to have the users part of the secret. Any attacker that was  Security Audit Report | Signing and Permissioning Toolkit | Capsule 13 February 2024 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   able to observe the network trac will know the secret as well. Consequently, if an attacker has the opportunity to obtain the users share, this could result in the loss of funds.  Preconditions  An attacker would need to have access to the encrypted share and be able to listen in on the network trac, transmitting the credentials to the server.  Technical Details  By encrypting the share with a key derived from a 16-byte random value called userHandle, the userHandle becomes a secret that needs to be protected with the same effort as the share itself. The goal of sending the share to the Capsule server is to provide a recovery method for the user. However, in such a situation, the userHandle is needed for the recovery. As a result, the key management problem of the share is not solved but shifted to the userHandle, thus introducing new attack vectors.  Remediation  We recommend refraining from sending user shares over the network.  Status  The Capsule team has made changes, such that the userHandle eld is not sent to the server.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue B: A Malicious Actor Can Terminate the Recovery Process", "body": "  Location  src/app.ts#L910  Synopsis  The users/cancel-recovery endpoint is used to terminate an active recovery process. The only parameter that is accepted by the endpoint is the email of the user, whose process is to be terminated. The email is publicly known information, so a malicious actor could use this endpoint to terminate a users recovery.  Impact  This could be used by a malicious user to interrupt processes and spam the network. Moreover, it could even prevent a user from performing a successful recovery and lock them out of their funds.  Preconditions  A malicious actor would need to know the users email, in addition to knowing that they have started a recovery process.  Mitigation  We recommend implementing an authentication mechanism to verify that a legitimate user is trying to end the process.  Status  The Capsule team has acknowledged the nding but stated that this is an intentional product decision. The team noted that adding authentication at this layer risks a user being locked out of having access to the recovery ow with no recourse, whereas rate-limiting, support intervention, and other measures can be  Security Audit Report | Signing and Permissioning Toolkit | Capsule 13 February 2024 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   employed to mitigate an attackers attempt to perform a Denial of Service (DOS) attack on an active recovery process.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Non-Uniform Private Key Generation", "body": "  Location  capsule/src/transmissionUtils.ts#L18  src/transmission/transmissionUtils.ts#L9-L11  Synopsis  The uploadKeyshare function calls keyFromPrivate instead of genKeypair from the elliptic npm package without preventing non-uniform key sampling.  Impact  A non-uniform distribution of private keys will result in some private keys being more likely, thus reducing the security of the cryptographic operations and giving attackers leverage when attacking encrypted secrets.  Technical Details  When a private key is derived in elliptic curve cryptography, it should be a random number smaller than the group order n and larger than zero. In this case, a random 32-byte number is generated, and a private elliptic curve key is then generated from it. This results in a modulo bias where some private key values are more likely than others. In the case of the elliptic npm package, the genKeyPair function performs the correct checks before any randomness is chosen as private keys.  Remediation  We recommend switching to a maintained cryptographic library as described in Issue H. When implementing this switch, we recommend adhering to the recommended use of the dependency, thereby avoiding any biases in key sampling.  Status  The Capsule team stated that this key is only used to encrypt and shorten the temporary passkey link for the user and that it is a one-time link, which is not used to manage funds. The Capsule team additionally updated the code to remove the bias by using the privateToPublic function from @ethereumjs/util.  We examined the changes implemented in the codebase and veried that the code segment at the time of review is used for encrypting links only.  Verication  Resolved.  Security Audit Report | Signing and Permissioning Toolkit | Capsule 13 February 2024 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Security Groups and Security Group Rules Are Both Used for", "body": " Trafc Access Control  Location  security/main.tf  Synopsis  Both security groups and security group rules are being used for resource access control purposes.  Impact  Using both solutions in a Virtual Private Cloud (VPC) could lead to undened behavior. Both of these resources were added before AWS assigned a security group rule unique ID, and they do not work eciently in all scenarios using the description and tag attributes, which rely on the unique ID. The aws_vpc_security_group_ingress_rule resource has been added to address these limitations and should be used for all new security group rules.  Preconditions  If there is conict between a group and a rule, there is no way to guarantee the order in which they will be enforced.  Feasibility  A misconguration is likely to occur. For example, the allow_ssh group and the ecs_cluster_ssh_security_group_rule group rule have conicting CIDR blocks specied.  Remediation  We recommend refraining from using both solutions simultaneously and using, instead, aws_vpc_security_group_ingress_rule and aws_vpc_security_group_egress_rule in a VPC.  Status  The Capsule team stated that while both security groups and security group rules are used, security group rules for egress rules are not associated with security groups that have egress rules dened inline, and security group rules for ingress rules are not associated with security groups that have ingress rules dened inline. The Capsule team is therefore not concerned with overlap issues. As a result, the team does not consider this Issue to be urgent and plans to make updates to use aws_vpc_security_group_ingress_rule/aws_vpc_security_group_egress_rule in the future.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue E: HTTP Trafc to Services Is Allowed", "body": "  Location  Examples (non-exhaustive):  security/main.tf#L200  security/main.tf#L481  Security Audit Report | Signing and Permissioning Toolkit | Capsule 13 February 2024 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   security/main.tf#L257  security/main.tf#L313  Synopsis  HTTP trac is allowed through the load balancers responsible for trac to services such as the MPC computation.  Impact  Allowing HTTP trac to services leaves them vulnerable to a plethora of attack vectors related to unencrypted trac, such as MPC protocol messages being intercepted by unintended participants.  Preconditions  The trac would need to be intercepted by a malicious party.  Remediation  We recommend only allowing HTTPS trac or redirecting HTTP to HTTPS.  Status  The Capsule team has resolved this Issue by disabling the HTTP trac.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue F: Sensitive Flag Is Not Set To True for Secret Variables", "body": "  Location  ecs/variables.tf  Synopsis  Password variables in the ecs module do not have the sensitive ag set to true.  Impact  The variables will be echoed to the user upon applying terraform after the planning step, which should be avoided for secrets, such as passwords.  Remediation  We recommend setting the sensitive ag to true for secret variables to prevent them from being echoed.  Status  The Capsule team has updated the ag as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue G: Egress Trafc Is Allowed to Any Instance", "body": "  Location  security/main.tf#L142  Security Audit Report | Signing and Permissioning Toolkit | Capsule 13 February 2024 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  Currently, there is a security group to allow all egress trac to any instance it is attached to.  Impact  Security groups are stateful, so this practice could lead to compromisation of the infrastructure.  Remediation  We recommend refraining from using this group and, instead, ne-graining the egress rules to each instance, as needed.  Status  The Capsule team has removed the security group as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue H: Usage of Unmaintained Cryptographic Library", "body": "  Location  package.json#L27 (e.g. here: src/transmission/transmissionUtils.ts#L2C24-L2C24)  main/capsule/package.json#L111  capsule/src/transmissionUtils.ts  Synopsis  For elliptic curve operations, the elliptic npm library is used. This library is unmaintained, as highlighted in the Github Issues 308 and 251. It was also not audited by an independent third party.  Impact  An unmaintained cryptographic library dependency performing fundamental elliptic curve operations poses a risk in case of attacks on the elliptic curves used.  Remediation  We recommend updating the elliptic curve dependency to a maintained and audited cryptographic library.  Status  The Capsule team has switched to the ECIES hybrid encryption library by Celo.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue I: Missing Domain Separation for Session Identier", "body": "  Location  taurus-group-multi-party-sig  internal/core/core.go#L43-L61  Security Audit Report | Signing and Permissioning Toolkit | Capsule 13 February 2024 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  This Issue is based on issues KS-SBCF-F-03 and KS-SBCF-F-07 from the Kudelski Security Audit Report for the multi-party-sig library, which the current implementation is also based on. In the multi-party-sig library, the session identier remains constant for different executions of the protocol, and since the issue found by Kudelski Security was not remediated for the library, the application layer needs to set the session identier to be unique. However, this does not happen in the application layer for Capsule.  Impact  A non-unique session identier allows for a malicious party to replay messages from other executions of the protocol or carry out replay attacks of the zero-knowledge proofs.  Remediation  We recommend setting the session identier to be unique for this application in the application layer.  Status  The Capsule team is using the protocol ID as a session identier, which is uniquely generated before the MPC protocol interaction starts.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue J: Update and Replace Vulnerable Dependencies", "body": "  Location  go.mod  go.sum  Synopsis  Our team identied issues with the dependencies implemented in the codebase.  Technical Details  We found the following dependency vulnerabilities in the Capsule codebase:   CVE-2023-3978 Golang HTML: Golang HTML package XSS vulnerability due to improper input  validation   CVE-2023-40591 go-ethereum: Possible research exhaustion on memory  Remediation  We recommend following a process that emphasizes secure dependency usage to avoid introducing vulnerabilities to the Capsule codebase, which includes:   Manually reviewing and assessing currently used dependencies;  Upgrading dependencies with known vulnerabilities to patched versions with xes;  Replacing unmaintained dependencies with secure and battle-tested alternatives, if possible;  Pinning dependencies to specic versions, including pinning build-level dependencies in the  respective le to a specic version;   Only upgrading dependencies upon careful internal review for potential backward compatibility  issues and vulnerabilities; and  Security Audit Report | Signing and Permissioning Toolkit | Capsule 13 February 2024 by Least Authority TFA GmbH  16  This audit makes no statements or warranties and is for discussion purposes only.    Incorporating an automated dependency security check into the CI workow, such as gosec or  nancy.  Status  The Capsule team has updated the go-ethereum dependency and is no longer using the HTML package.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue K: Sensitive API Calls Are Not Restricted", "body": "  Location  src/app.ts#L1355  src/app.ts#L1545-L1597  Synopsis  Specic sensitive API methods related to user management are not restricted to the internal network.  Impact  Calls to API methods can be made by unauthorized users.  Remediation  We recommend using IAM tags to restrict the invocation of methods to authorized users.  Status  The Capsule team stated that they currently use basic authentication on all API calls intended to be called from other internal services. Additionally, the team noted that the addition or switch over to using IAM groups instead would not offer any additional protections beyond this and would potentially add complexity or make it more dicult to spot issues. As a result, the team has decided not to implement the recommended remediation.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue L: DKL+19 Does Not Support Key Refresh (Second Review)", "body": "  Location  key-storage/blob/main/main.go#L191  key-storage/blob/main/main.go#L199  mpcService/mpcService.go#L158  mpcNetwork/mpcNetwork.go#L146  signer/signer.go#L172  internal/core/core.go#L63  Security Audit Report | Signing and Permissioning Toolkit | Capsule 13 February 2024 by Least Authority TFA GmbH  17  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The handler for the API endpoint for key refreshing does not check whether the key to refresh is a CGG+21 key or a DKL+19 key. Instead, it assumes the key is a CGG+21 key and attempts to run the key refresh protocol for that scheme. However, DKL+19 does not support key refreshing.  Impact  This Issue will result in the key refresh failing, potentially affecting keys stored on the server.  Preconditions  The user would need to start a key refresh.  Feasibility  Straightforward.  Remediation  We recommend aborting with an error if the key is a DKL+19 key.  Status  The Capsule team has updated the functions to call an update to the DKL+19 protocol with a key refresh functionality, implemented by Taurus Group in PR68. However, at the time of verication, our team noted that this update had not been documented. We recommend documenting this DKL+19 edit.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/capsule_signing_and_permissioning_toolkit_updated_2/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Minting Process Is Susceptible to Ination / Sandwich Attacks", "body": "  Location  contracts/CErc20.sol#L53  contracts/CToken.sol#L310  contracts/CErc20InterestMarket.sol#L154  Synopsis  When a user mints CTokens, the exchangeRateStoredInternal function is eventually called, which checks the totalSupply of tokens in circulation. If the totalSupply is zero, the exchangeRateStoredInternal function uses the initial exchange rate; otherwise, it applies the formula: exchangeRate = (totalCash + totalBorrows - totalReserves) / totalSupply  At the initiation of a pool, if the pool is empty, an attacker can front run the rst depositor and deposit a small amount. Consequently, due to the manner in which solidity handles rounding, the depositor could end up with zero CTokens.  Note that this attack is inherited by the fork of the Compound Protocol and is leveraged to exploit different projects.  Impact  This Issue could result in a depositor losing their shares and the attacker owning the totalSupply.  Preconditions  This attack can occur if the pool is empty at initiation, and an attacker has sucient funds to execute the attack.  Technical Details  An attacker mints a small amount of CTokens (e.g. 100e4 wei) using the mint function and then transfers a large amount of underlying tokens (e.g.1e18 wei) directly to the CToken contract. As a result, the depositor mints, but obtains zero CTokens. The attacker would then own all the minted cTokens and have the ability to redeem them.  Remediation  We recommend preventing the pools from being empty. For example, one option could be to perform the rst deposit in the same transaction as the deployment, thus preventing a malicious actor from front running it. However, given that such a remediation requires special attention and would need to be repeated multiple times, another solution would be to hard code a mint of some tokens to the zero address directly in the smart contract.  Status  The Fungify team acknowledged this Issue and decided to mint and burn at deployment to prevent it.  Verication  Resolved.  Security Audit Report | Smart Contracts | Fungify 10 January 2024 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/fungify_smart_contracts_updated_final-audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: doNFTTransferOut Deterministically Returns the Last NFT", "body": "  Location  contracts/CErc721.sol#L684  Synopsis  Although users are aware that they will be unable to reclaim the exact NFT that they supplied, it is possible for a malicious user to inspect the pools and retrieve a desired NFT since doNFTTransferOut always returns the last NFT in the array.  Impact  An attacker could retrieve a desired NFT.  Preconditions  The attacker would need to have provided an NFT before the desired one was supplied.  Feasibility  Straightforward.  Remediation  We recommend that the Fungify team implement either the Prevrandao opcode (fork >= paris) or the Chainlink VRF to obtain a random number and retrieve a random NFT.  Status  The Fungify team acknowledged the Issue but stated that the Last-In First-Out (LIFO) method was by design and that users may receive different NFTs than the one they supplied to the pool.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/fungify_smart_contracts_updated_final-audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Remove KV Root Tokens Following Setup Process in Production", "body": " Environments  Location  key-vault/blob/v0.1.11-rc/cong/vault-init.sh  Synopsis  Root tokens should be used only during the initial setup process. Currently, the root tokens are not revoked once the setup process is complete.  Impact  The likelihood of an attack is unknown. However, in the event that the preconditions are met, the impact of the attack would be signicant.  Preconditions  An attacker successfully acquires access to one of the root tokens.  Technical Details  If exposed, root tokens allow an attacker to have full control over the vault. This exposes all secrets stored in the vault. HashiCorp Vault documentation also recommends revoking the root token once the vault system has transitioned from development phase to production.  Security Audit Report | Staking Wallet | Blox 17 March 2021 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  As per the HashiCorp Vault documentation, setup up authentication methods and policies necessary to allow administrators and users to acquire more limited tokens, then revoke the root token once the setup process is done.  Status  The Blox team has revoked the root token upon completion of the HashiCorp Vault setup, as suggested.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Blox_Staking_Wallet_Final_Audit_Report.pdf ", "labels": ["LeastAuthority"]}, {"title": "Issue B: Save Tokens Securely in a Token Helper", "body": "  Location  key-vault/blob/v0.1.11-rc/cong/vault-init.sh  Synopsis  In the current implementation of Blox, tokens are stored in the le system in an unencrypted state, which leaves them exposed for attacks.  Impact  The likelihood of an attack is unknown. However, in the event that the preconditions are met, the impact of the attack would be signicant.  Preconditions  An attacker successfully acquires access to the machine running the vault server le system.  Technical Details  If an attacker gains access to the le system, they can access the unencrypted tokens which may lead to potential exposure of secrets stored in the vault.  Remediation  Implement/utilize a token helper to store, retrieve and manage vaults tokens. HashiCorp Vault documentation provides details on implementing a proper token helper.  Status  The Blox team has implemented the suggested remediation so that the root tokens are no longer stored in the le system. Instead, root tokens are passed as variables to subsequent subprocesses and then removed upon completion of the vault setup.  Verication  Resolved.  Security Audit Report | Staking Wallet | Blox 17 March 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Blox_Staking_Wallet_Final_Audit_Report.pdf ", "labels": ["LeastAuthority"]}, {"title": "Issue A: ERC20 Implementations  Approve()  Susceptible to Front-Running", "body": "   Location   https://github.com/centrifuge/tinlake-erc20/blob/master/src/erc20.sol#L85    Synopsis   There are a few places in the Tinlake system that rely on the transfer of approved tokens. It may be  possible that some of these transfers could be done in such a way that the approver is left with an  unexpected balance. This depends on the ability or requirement of the approver to update their balance. If  this case is present then this issue recorded within   [REC19]   may be of relevance:    An ERC20 security issue, known as the \"multiple withdrawal attack\", was raised on GitHub and has  been open since November 2016. The issue concerns ERC20's defined method  approve()  which  was envisioned as a way for token holders to give permission for other users and dapps to  withdraw a capped number of tokens. The security issue arises when a token holder wants to  adjust the amount of approved tokens from  N  to  M  (this could be an increase or decrease). If  malicious, a user or dapp who is approved for  N  tokens can front-run the adjustment transaction to  first withdraw  N  tokens, then allow the approval to be confirmed, and withdraw an additional  M  tokens.   Impact   High. Possible loss of tokens.   Preconditions   There must be an approval adjustment that is vulnerable to this attack.    Feasibility   Approval adjustments that could be vulnerable must be able to be acted upon by the approved party and  must be able to be spent quickly enough to make this feasible. An example of this may be in the lender  contract that mints tokens based on an approved currency amount. However, we are unsure if balance  adjustments to the approval can be made to incentivise the lender into acting on minting or burning in  favor of receiving or redeeming more currency than was expected.     Security Audit Report | Tinlake Contracts + Actions | Centrifuge 7 April 2020  by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.        Technical Details   Full details of this attack, along with a number of approaches to mitigation, is contained in   [REC19] .   Mitigation   Enforce approval balance is set to 0 before adjusting an approval or CAS approved to eliminate the  possibility that the approved amount of a token is ever less or more than expected. See the paper linked in  the technical details for more in-depth mitigation details.    In addition, create detailed documentation of every token transfer that uses this method to ensure that  there are no cases where a party may conceal the intended approval amount of a token.   Status   The Centrifuge team has acknowledged the existence of the multiple withdrawal attack within the  approve()  function and have decided not to deviate from the MakerDAO DAI stablecoin ERC 20  implementation that also includes this attack vector.    We strongly encourage the Centrifuge team to examine every possible way that a tokens approved  amount to a spender, whether user or contract, might need to be adjusted and whether or not it could be  possible for the multiple withdrawal attack to cause any amount of tokens to be spent unexpectedly. If  understanding every possible scenario that a tokens approval may need to be adjusted is not possible,  then we encourage the Centrifuge team to implement the suggested safety method to prevent unknown  or unforeseen situations.     Verification   Unresolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Tinlake_Contracts_Actions_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Incorrect Equality Checks", "body": "   Location   https://github.com/LeastAuthority/tinlake/blob/89adc6386e5e8bae73f88d6e2a92bb70f6c8f7df/src/borr ower/pile.sol#L66   https://github.com/LeastAuthority/tinlake/blob/89adc6386e5e8bae73f88d6e2a92bb70f6c8f7df/src/borr ower/pile.sol#L77   Synopsis   The condition  now <= lastUpdated  can never be less than  now . This requirement is placed on  decDebt()  and  debt() , and given that  lastUpdated  is not initialized and defaults to 0,  these  functions can not be called until after  file()  sets it to now. Given that any subsequent call to  incDebt()  or  debt()  will always be after now unless within the same block, these functions may only  be called in the same block that  file()  is called. There is no documentation on the intended behavior of  these checks.   The condition  now >= lastUpdate  seems to be an unnecessary check as  lastUpdate  can only be set  to  now,  where  now  can either be within the current block and equal to  lastUpdated, or from a future  block and always greater than  lastUpdated .   Impact   The use of the less than operator will never be used. Without documentation as to why it is used, this will  lead to confusion in understanding this functionality.    Security Audit Report | Tinlake Contracts + Actions | Centrifuge 7 April 2020  by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.          Remediation   The intended equality check might be  now == lastUpdated   for  debt()  and  incDebt() , to ensure  that a function is called within the same block. Document the purpose of this check.   Status   A  commit that changes the equality check  to the suggested remediation of  == rather than <=  has  been added.   Verification   Resolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Tinlake_Contracts_Actions_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Outdated Compiler Versions", "body": "   Synopsis   A number of contracts are using an outdated pragma. Some are as low as 0.4.23, such as the  dapphub/ds-note contract. In most other cases, the pragma is set to 0.5.3, which is still over a year behind  the current release.   Impact   The outdated compiler version can subject contracts to security issues fixed in newer compiler versions.   Remediation   Update all contracts to use the latest version 0.5.16 or 0.6.2 (at the time of this report).   Status   Commits have been accepted throughout the codebases, including the DS-Note dependency, which  enforce any build to use solidity >=0.5.15.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Tinlake_Contracts_Actions_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Ambiguous NULL Ownership", "body": "   Location   https://github.com/LeastAuthority/tinlake-auth/blob/master/src/auth.sol#L23   Synopsis   The ability to drain the ownership of a contract to 0 owners is an ambiguous way to disable functionality.  Auth is used similar to a 1 of N multisig, where wards may be added or removed and only one ward is  required to execute a function modified with Auth. It could become possible for the removal of all wards  from the state by calling  deny() . This would leave the contracts that depend on this authentication in an  unusable state.   Impact   All contracts that rely on the authentication could become null and unusable.   Security Audit Report | Tinlake Contracts + Actions | Centrifuge 7 April 2020  by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.          Preconditions   The last owner or ward of the authenticated contract must deny themselves access by accident in order  for a contract that relies heavily on authentication to lose control, where or when it was not intended to  lose all ownership.   Remediation   Add a minimal amount of state that tracks the amount of wards that own a contract and ensure that it is  intentional if the amount of wards becomes 0. Add a function that explicitly declares the intended  functionality of removing all wards is to remove all functionality from a ward controlled contract.    Status   The Centrifuge team has stated that they are aware of the possibility that total ownership of a contract or  functionality could be inadvertently removed. However, they note that this is an unlikely edge case, as an  owner must remove all other owners and then lastly remove themselves. As a result, the Centrifuge team  does not intend to implement the suggested remediation as they consider the ability to remove all owners  from the contract with the  deny()  function an intended feature. We encourage the Centrifuge team to be  explicit about when and where it is intended to remove all owners to prevent any accidental cases, which  could potentially cause irreparable damage.    Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Tinlake_Contracts_Actions_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Shelf Issue Function May Be Re-entered", "body": "    Location   https://github.com/LeastAuthority/tinlake/blob/develop/src/borrower/shelf.sol#L112   Synopsis   Issue()  in  Shelf.sol  calls the  ownerOf()  function of a supplied NFT. If a custom NFT is provided to  this function, the  ownerOf()  function may call back to  issue()  and update the state of the shelf  contract in unexpected ways.    Impact   There may be a case that an NFT is vetted and contains a custom malicious  ownerOf()  that will register  many NFT loans to the shelf contract. There may be other unintended state manipulations from  ownerOf() .   Remediation   Modify  ownerOf()  with  view  so that it is unable to make state updates.   Status   A  commit that modifies  ownerOf()  to be a view function and can no longer alter state upon re-entry has  been added to the NFT contract.     Verification   Resolved.   Security Audit Report | Tinlake Contracts + Actions | Centrifuge 7 April 2020  by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.        ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Tinlake_Contracts_Actions_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Division By Zero Is Unchecked In Safe Math", "body": "   Location   https://github.com/LeastAuthority/tinlake-math/blob/master/src/math.sol#L34   Synopsis   Safe division requires checking that there is no division by zero. While the default behavior of Solidity is to  revert in this case as of compiler version 0.4.0, it reverts using an invalid opcode rather than a gas  preserving revert. The safeDiv provided in the math library for Tinlake does not do any checks for zero  division.   Impact   Any call to safe division that may divide by zero will throw an opcode that does not provide information as  to what happened and deplete the gas provided to the transaction.   Remediation   Place a require statement in  safeDiv  that ensures the divisor must be greater than zero, and supply an  error message if this is not the case.   require(y > 0, Division by zero);   Status   The  pull request to the safe math library  now requires that division by zero is not possible and an error  message is supplied.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Centrifuge_Tinlake_Contracts_Actions_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Updating Ownership of Solidity Fiat Token to Mistaken Address", "body": "   Location   https://github.com/atomex-me/atomex-erc20-solidity/blob/fe568c33dfffce6c495faf71af8a11ce6dad00f 1/contracts/FiatTokenV1.sol#L53    Synopsis   In the Solidity fiat token implementation, updating the owner of the token may provide a mistaken address  that is not controlled by the organization that is intended to control the token. The  transferOwnership()  function checks that the address provided as the new owner is not zero.  However, if an incorrect address is provided to this function, then control of the token will be lost.    Impact   High. The impact of this mistake is significant as control of the token will be lost if an address is provided  for which the organization does not have a corresponding private key.   Preconditions   An accidental address must be authorized by an Ethereum transaction from the current valid owner of the  fiat token.   Feasibility   The likelihood of providing an account that is incorrect during the transfer of ownership is low. Transfer of  ownership of a fiat token may not happen frequently or may be controlled by a multisig account where  many individuals must agree that the new account is accurate.   Mitigation   A two step method to transfer ownership, while costing a bit of extra gas, could prevent a rare case where  ownership is transferred to an account that is not controlled by the intended organization. This process  would have two functions that would be called to transfer ownership. The first step is to propose a new  owner, modified to have access only by the current owner. This will store the potential new owner in the  token contracts state. The second step is to call a function that accepts the new owner that is modified to  only have access to the new owners account. As a result, if the account being updated to is not  controlled, the current owner may still reverse the mistake and try again.   Status   The  Ownable.sol  contract has been  updated with the suggested mitigation . The contract now has the  ability to propose and accept ownership transfers with the functions  proposeOwner()  and  acceptOwnership() .    Verification   Resolved.    Security Audit Report | Atomex Smart Contracts | Tezos Foundation 6 May 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.        ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_foundation_Atomex_Smart_Contracts_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Atomic Swap (Tezos) and FA1.2 Contracts Have Unclear or Absent", "body": "  Error Messages   Location   https://github.com/atomex-me/atomex-fa12-ligo/blob/142c29346d010301dcb1f930d46ccd0d98a462b3 /src/atomex.ligo   https://github.com/atomex-me/atomex-michelson/blob/82f452d1ea4d0263b7a4eaab782a6e02b06bcaf 3/src/atomex.tz    Synopsis   Empty strings instead of a reason for a failed transaction should be provided are present in multiple  locations of the FA1.2 contract. For example, the contract will fail with an empty string if a user attempts  to redeem before the timeout or tries to redeem with an incorrect secret seed. The FA1.2 contract also  makes use of deprecated functions which generate highly cryptic error messages on failure.   Although the Atomic Swap (Tezos) contract has error messages, further clarification about the cause of  the error is recommended. For example, if the source of the transaction fails, the check on atomex.tz line  79 results in a message stating wrong sender address\" without further explanation on the issue.   Impact   When a transaction executes in a way that will fail, the client software or initiator of the transaction may  have a difficult time identifying the failure case. While this does not create an immediate security  problem, it could cause client software or users to be unable to take appropriate actions to correct a  mistake.   Remediation   Provide the appropriate corresponding reasoning for failures as opposed to empty strings.   Status   This suggested remediation has been implemented and the  Atomic Swap (Tezos)  and   FA1.2   contracts  now have clear error messages for expected failure modes.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_foundation_Atomex_Smart_Contracts_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Inconsistencies In Contract Modifier Requirements", "body": "   Location   https://github.com/atomex-me/atomex-solidity/blob/e5d4c03b4bcd735a0cb456cd99ec6d68cfbb98de/c ontracts/AtomicSwap.sol#L91   https://github.com/atomex-me/atomex-erc20-solidity/blob/fe568c33dfffce6c495faf71af8a11ce6dad00f 1/contracts/AtomicSwap.sol#L150 0   https://github.com/atomex-me/atomex-fa12-ligo/blob/142c29346d010301dcb1f930d46ccd0d98a462b3 /src/atomex.ligo#L40-L47   https://github.com/atomex-me/atomex-michelson/blob/82f452d1ea4d0263b7a4eaab782a6e02b06bcaf 3/src/atomex.tz#L29    Security Audit Report | Atomex Smart Contracts | Tezos Foundation 6 May 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.            Synopsis   The modifiers for how a function should restrict the access to the function body are not consistent  among the different contract implementations. For example:    The Atomic Swap (Ethereum) contract does not check that the provided  participant  is   non-zero;    The Atomic ERC-20 contract checks that the  participant  is non-zero;    The FA1.2 contract checks that only the  participant  is not the source of the transaction; and   The Atomic Swap (Tezos) contract only checks that the  participant  exists and has proper   typing.    Impact   The intended requirements for the participants of a swaps address are not clear. Some contracts have  strict requirements for address validation while others do not, which implies that some contracts lack  guarantees that a participant address is the intended address. Without stricter requirements, an  accidental address could be provided and go unnoticed. This could lead to a case where a redemption is  not possible on one end of the swap, while it is possible on the other.   Preconditions   A mistaken participant address must be supplied.   Feasibility   This is only moderately feasible as any given party may witness the mistake and not complete a swap and  await a refund.   Remediation   Ensure that all participant address requirements are satisfied in each implementation of the swaps  contracts.    For the Atomic Swap (Ethereum) and ERC-20 contracts, ensure that there is a check for a non-zero  address provided.    Status   Following a refactor by the Atomex team, the  Atomic Swap (Ethereum)  contract has been updated to  include a check to ensure that non-zero addresses are present in the participant parameter, making this  consistent with the edge case checking done in the  ERC-20 contracts .    After further discussion with the Atomex team in which they state that the only undesirable address in the  parameter is the sender, we agree the  Atomic Swap (Tezos)  and  FA1.2  contract checks are adequate and  do not need to be consistent or present in the initialization functions of the Atomic Swap (Tezos)  contract.     Verification   Resolved.   Security Audit Report | Atomex Smart Contracts | Tezos Foundation 6 May 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.      ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_foundation_Atomex_Smart_Contracts_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: FA1.2 Contract Makes Use of Many Deprecated or Undocumented", "body": "  Functions     Location   https://github.com/atomex-me/atomex-fa12-ligo/blob/142c29346d010301dcb1f930d46ccd0d98a462b3 /src/atomex.ligo    Synopsis   The FA1.2 contract makes use of a number of functions that are deprecated in official PascaLIGO  documentation, or are entirely absent from the latest version of it.    Impact   Deprecated and undocumented functions, especially when used to avoid error handling, can behave in  ways that are hard to predict or may change over time. In cases of failure, the above functions will often  generate cryptic and unhelpful error messages. For the functions with no documentation, it is impossible  to have confidence in the behavior of the function, especially for edge cases or in future updates of the  PascaLIGO compiler.   Technical Details   In many cases, these are functions that have the potential to fail, but avoid handling the failure. For  example,  get_entrypoint  will fail if pointed to a contract without the specified entrypoint with a  confusing error message such as bad address for get_entrypoint (%transfer). The PascaLIGO reference  suggests  Tezos.get_entrypoint_opt , which requires explicit handling of the failure case. In the case  of the function  get_force , it seems to be entirely absent from the PascaLIGO documentation.   Mitigation   In general, we noticed the following deprecated functions, and provide suggested replacements:   Deprecated Function   get_entrypoint   transaction   size   source   get_force   Status   Replacement   Tezos.get_entrypoint_opt   Tezos.transaction   Bytes.length   Tezos.source   Big_map.find_opt   This issue has been resolved by  removing references to deprecated functions .   Verification   Resolved.   Security Audit Report | Atomex Smart Contracts | Tezos Foundation 6 May 2020 by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.        ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_foundation_Atomex_Smart_Contracts_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Mnemonic Encryption Password Has No Constraints", "body": " [StakingPower Wallet]  Location  The following code execution path demonstrates the password conrmation text being passed directly through to the key derivation function without any validation:  Mina-StakingPower-Wallet/lib/new_user_onboard/screen/encrypt_seed_screen.dart: 74  Mina-Signer-SDK/lib/sdk/mina_signer_sdk.dart:33  Mina-Signer-SDK/lib/encrypt/crypter.dart:36  Synopsis  There are no constraints on the user-chosen password (e.g., length, character diversity, non-dictionary words, etc.). This makes it possible for a user to choose a weak password, increasing the feasibility of compromise of the data encrypted with its derived key.  Impact  If the mnemonic seed is compromised, all keys derived from it are compromised. This means an attacker would have full control over (i.e., able to sign transactions on behalf of) all accounts derived from that mnemonic seed.  Preconditions  An attacker would have to obtain the shared_preferences .xml or NSUserDefaults .plist le.  On Android, SharedPreferences data is stored on the lesystem, which could be exltrated by a rogue application or an unauthorized user, given physical access to the device. On iOS, NSUserDefaults and .plist les are not accessible to rogue applications, except in the cases where the device has been jailbroken or rooted.  Feasibility  With the availability of powerful hardware like CPUs, GPUs, and FPGAs on the cloud, it is not dicult to brute force the key for various classes of weak passwords (e.g., low entropy, dictionary words, and others), particularly since SHA-256 is inexpensive on CPU resources (see Issue D).  Obtaining the shared preferences le, however, likely requires that the device has been successfully attacked previously. For example, as previously described, this could be done by means of physical access or a rogue application. Rogue applications have been historically identied in multiple application stores.  Security Audit Report | Mina Signer SDK + StakingPower Wallet | Mina Foundation 21 September 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  Mina uses hierarchical deterministic wallets according to BIP44 to structure their wallet data in a client-agnostic way.  shared_preferences data is protected by lesystem user access control only and is stored in plain-text XML.  Mitigation  We recommend adding messaging to the EncryptSeedScreen widget that informs users of password best practices, the risk of choosing a weak password, and the risks of using a rooted device.  Remediation  We recommend adding password strength estimation to the form validation and prevent users from choosing weak passwords.  Status  The StakingPower Wallet team has added the password_strength package as a dependency and integrated it into the UI to show the user a password strength estimation based on length, characters used, and a top 10,000 dictionary.  Although this estimation is being done and presented to the user, it is not preventing the submission of weak passwords. In order to fully resolve the issue, we recommend that the StakingPower Wallet team prevent users from choosing weak passwords.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Mina-Foundation-Mina-Signer-SDK-StakingPower-Wallet-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Opening Arbitrary URLs of Unknown Origin [StakingPower", "body": " Wallet]  Location  The following code execution path demonstrates how these values are used from when they are received from Staketab to when they are passed into url_launcher:  Mina-StakingPower-Wallet/lib/stake_provider/blocs/stake_providers_bloc.dart:42 ,47,48  Mina-StakingPower-Wallet/lib/stake_provider/blocs/stake_providers_entity.dart: 6,60  Mina-StakingPower-Wallet/lib/stake_provider/screen/stake_providers_screen.dart :104,163,176,233  Mina-StakingPower-Wallet/lib/global/global.dart:63  Synopsis  The Staketab API is used to retrieve a list of staking providers. The URLs from the website eld are used as-is in the application's provider list as link destinations.  Security Audit Report | Mina Signer SDK + StakingPower Wallet | Mina Foundation 21 September 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Impact  A staking provider website value could open and pass data to other installed applications via Intents on Android and Universal Links on iOS.  Preconditions  One or more provider website values returned from the Staketab APIs use a scheme, which is supported by an installed applications intent-lters or universal links, on Android or iOS, respectively.  Feasibility  Staketab claims to receive URLs from provider representatives, which they manually verify internally before committing to the database, making this unlikely.  Technical Details  The url_launcher Flutter plugin is used by the application to open these URLs.  On Android, url_launcher uses the Intent system. By default, it uses an implicit intent with the Intent.ACTION_VIEW action, depending on intent resolution to open the appropriate application (see intents-lters guide).  On iOS, url_launcher uses UIApplication#openURL at FLTURLLauncherPlugin.m:118. This means that URLs can open and pass data to other installed applications via universal links.  Mitigation  We recommend adding a warning for end users, which explains that they are navigating to an untrusted resource and the associated risks.  Remediation  We recommend ltering provider website URL values to, at most, those which use specic, known schemes (e.g. HTTPS).  Alternatively, we recommend setting the forceWebView and forceSafariVC options to true.  Status  The StakingPower Wallet team has implemented a warning dialog, which includes a warning message and the URL itself. This dialog makes it so that users must conrm that they wish to navigate to a given URL.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Mina-Foundation-Mina-Signer-SDK-StakingPower-Wallet-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Account Metadata is Not Encrypted at Rest [StakingPower Wallet]", "body": "  Location  my_accounts/screen/create_account_screen.dart:183  my_accounts/screen/edit_account_screen.dart:166  new_user_onboard/screen/encrypt_seed_screen.dart:82  wallet_home/screen/wallet_home_screen.dart:168  Security Audit Report | Mina Signer SDK + StakingPower Wallet | Mina Foundation 21 September 2021 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  With the exception of the mnemonic seed, data stored by the application using the shared_preferences plugin is not encrypted. This unnecessarily exposes sensitive metadata in the event that a device is compromised.  Impact  Account metadata may be leaked, resulting in de-anonymization of the target user as well as disclosing the number of accounts managed by the wallet, their addresses and balances, and with which staking provider(s) (if any) each is staked.  Preconditions  An attacker would have to obtain the shared_preferences .xml or NSUserDefaults .plist le.  On Android, SharedPreferences data is stored on the lesystem which could be exltrated by a rogue application or an unauthorized user given physical access to the device.  On iOS, NSUserDefaults and .plist les are not accessible to rogue applications, except in the cases where the device has been jailbroken or rooted.  Feasibility  Obtaining the shared_preferences le likely requires that the device has been successfully attacked previously (e.g. by means of physical access or a rogue application). Rogue applications have historically been identied in multiple application stores.  Technical Details  The shared_preferences Flutter plugin uses Androids SharedPreferences on Android and NSUserDefaults on iOS to persist data to disk on a per application basis. The wallet is storing all persisted data as JSON-encoded strings in an .xml or .plist le on Android or iOS, respectively.  Remediation  We recommend encrypting all persisted data (except for the salt).  Status  The StakingPower Wallet team has replaced their usage of the shared_preferences plugin with flutter_secure_storage, which ensures that all data stored by the wallet is encrypted at rest. Additionally, automated migration has been included for existing installations.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Mina-Foundation-Mina-Signer-SDK-StakingPower-Wallet-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Key Derivation Function is Insecure [Mina Signer SDK]", "body": "  Location  Mina-Signer-SDK/lib/encrypt/crypter.dart#L37  Mina-Signer-SDK/lib/encrypt/kdf/sha256_kdf.dart  Security Audit Report | Mina Signer SDK + StakingPower Wallet | Mina Foundation 21 September 2021 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  An AES-256 encryption key is derived from a user password for the purpose of encrypting the mnemonic seed. This key derivation function utilizes the SHA-256 hashing function, which is not a suciently secure algorithm for this purpose.  Impact  Leakage of all plaintext of an encrypted wallet is possible, including the wallet seed. This leads to the attacker being able to author transactions and steal funds.  Preconditions  The attack requires access to the encrypted wallet data (e.g. by reading the memory of a stolen device).  Feasibility  Cracking weak password hashes is a process that can be radically optimized (e.g. using FPGAs). While these require some know-how and upfront investment, they allow very high guess rates compared to their costs.  Technical Details  The SHA-256 hash function is, for multiple reasons, not an appropriate algorithm for deriving keys from passwords. Firstly, hash functions are not key derivation functions. They serve different purposes, even though key derivation functions usually are constructed from hash functions. Secondly, when deriving keys from passwords, memory-hard functions should be used, in order to make brute force attacks infeasible. Note that SHA-256 can be executed and parallelized not only on computers, but also on FPGAs, resulting in a signicantly lower power per guess ratio, which in turn leads to lower operating cost per guess ratio. Memory-hard functions help because they can not be parallelized well on FPGAs, GPUs, or specialized hardware.  Moving the burden of choosing a password that is secure with a simple key derivation function like HKDF to the user ignores that many users will not follow best practices when selecting a password. Entering passwords on phones can be tricky and prone to mistyping, which incentivizes users not to choose good passwords, which may in turn lead to insecure wallets. Additionally, the time needed to correctly enter a suciently secure password for a regular key derivation function is much longer than the time needed for a more secure password hashing function to run, leading to a net slowdown of the user. A memory-hard function key derivation function is more secure if the user chooses a weak password.  Remediation  We recommend using the Argon2id key derivation function, with the memory parameter set to 64MB, parallelism set to 4, and iteration count to 3.  Status  The StakingPower Wallet team has updated the MinaCryptor classs encrypt and decrypt methods to use Argon2id for key derivation and XChaCha20Poly1305 for encryption by default. It falls back to the original method when decrypting for backwards compatibility.  Verication  Resolved.  Security Audit Report | Mina Signer SDK + StakingPower Wallet | Mina Foundation 21 September 2021 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Mina-Foundation-Mina-Signer-SDK-StakingPower-Wallet-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Mnemonic Exposed Through Clipboard [StakingPower Wallet]", "body": "  Location  new_user_onboard/screen/recovery_phrase_screen.dart#L87  Synopsis  The mnemonic phrase used to derive the wallet keys is accessible to the rest of the applications on the device via Clipboard. Clipboard is a global object that is accessible across application security boundaries. Any applications that are watching Clipboard will be able to see the mnemonic when the user copies it to Clipboard.  Impact  With access to the mnemonic, an attacker would be able to clone the wallet and take over all of its assets.  Preconditions  An application monitoring Clipboard when the mnemonic is copied. This is not an unlikely scenario, as many applications are known to do this by design. As of iOS 14, iOS noties users whenever another application accesses Clipboard. For an application to be targeting the mnemonics specically, a users phone would need to already have a malicious application targeting the StakingPower Wallet installed.  Feasibility  Clear APIs for viewing Clipboard are available for iOS and Android developers. Creating a Clipboard monitoring application would not be dicult. However, a more dicult task would be to compromise the phone of a Mina user. Additionally, if the user is using an iPhone with version of iOS >= 14, they would be notied when another application accessed Clipboard, alerting them that the mnemonic had been accessed.  Remediation  We recommend not allowing the mnemonic to be saved to Clipboard. Instead, we suggest requiring users to write down the mnemonic in a place off of the lesystem of their device.  Status  The StakingPower Wallet team has created an intermediary step that warns the user of the dangers involved with using Clipboard. In order to remediate this issue, we recommend preventing the ability for the user to copy to Clipboard, as the current approach transfers the risk to the user and leaves the issue unresolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Mina-Foundation-Mina-Signer-SDK-StakingPower-Wallet-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Weak PBKDF2 Parameters [Mina Signer SDK]", "body": "  Location  lib/encrypt/kdf/pbkdf2_kdf.dart  Synopsis  The parameter conguration of the PBKDF2 does not adhere to accepted standards. A SHA-1 HMAC is used with 100 iterations and returns a 32 byte key with 16 byte salt. Current OWASP recommendations  Security Audit Report | Mina Signer SDK + StakingPower Wallet | Mina Foundation 21 September 2021 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   specify over 300,000 iterations using SHA-256 HMAC for FIPS-140 compliance. As of 2016, NIST recommends a minimum of 10,000 iterations. For reference:   5 Authenticator and Verier Requirements: https://pages.nist.gov/800-63-3/sp800-63b.html#sec5  Password Storage Cheat Sheet:  https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html  Parameter Choice for PBKDF2: https://cryptosense.com/blog/parameter-choice-for-pbkdf2  However, even with sucient iterations, PBKDF2 can be eciently parallelized and therefore does not provide a strong protection against brute-force attacks.  Impact  If an attacker can crack the Key Derivation function, they will be able to decrypt the seed key, allowing them to compromise the wallet.  Preconditions  An attacker would need to have access to the encrypted seed key, as well as specialized hardware to launch the attack.  Mitigation  We recommend vastly increasing the iterations. Since the NIST recommendations are also old by modern standards, the current OWASP recommendation of 300,000 iterations is a more robust solution if PBKDF2 is used.  Remediation  We recommend replacing PBKDF2 with a memory-hard function (see Issue D).  Status  The StakingPower Wallet team has deprecated the use of PBKDF2 and replaced it with a memory hard key derivation function using flutter_sodium, using flutter ffi, Argon2id (v13) and XChaCha20Poly1305ietf. The parameters for Argon2id password hashing are a memory limit of 128M, 3 iterations, and an output length of 32, and parallelism set to 1.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Mina-Foundation-Mina-Signer-SDK-StakingPower-Wallet-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Substandard Encryption Algorithm [Mina Signer SDK]", "body": "  Location  encrypt/aes/aes_cbcpkcs7.dart  Synopsis  The CBC mode of operation does not provide any authentication on its own. That means that it is malleable in that it is possible to change the ciphertext in such a way that it can decrypt to a different, valid-looking plaintext. A better approach would be to use authenticated encryption (e.g. libsodiums secretbox or AES with the GCM mode or operation).  Impact  The attacker could modify the seed and there are scenarios where this may lead to loss of the key. For example, if the attacker has physical access to the phone but is unable to crack the password, they may replace the parts of seed. The attacher then returns the phone and the owner transfers money to the  Security Audit Report | Mina Signer SDK + StakingPower Wallet | Mina Foundation 21 September 2021 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   account. This results in the attacker knowing parts of the seed, which may result in making a successful guess of the rest of the seed.  Preconditions  An attacker would need to have access to the encrypted seed and the ability to change it.  Remediation  We recommend using an authenticated encryption algorithm like libsodiums secretbox or AES-GCM.  Status  The StakingPower Wallet team has replaced the AES-CBC encryption algorithm with XChaCha20Poly1305ietf, which is an authenticated cipher.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Mina-Foundation-Mina-Signer-SDK-StakingPower-Wallet-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue H: Wallet Screen Not Protected Against Screen Recording", "body": " [StakingPower Wallet]  Synopsis  On Android and some versions of iOS, the user or an application may record videos or individual frames from the StakingPower Wallet application.  The data displayed by the StakingPower Wallet is critical to both the security of the application and the privacy of the user. This data includes the mnemonic phrase, which is displayed during wallet key pair generation, and at any time after that in the backup screen. A leak of the mnemonic passphrase is a critical breach of the security of the wallet. Additionally, the wallet displays user account balance and transaction history, of which a malicious screenshot could leak private user data.  Private user data must be secured and protected from access by other applications running on the mobile device.  Impact  A malicious application accessing an image of the mnemonic phrase could result in loss of all wallet funds. In addition, account balance or transaction history leaks are a breach of user privacy.  Preconditions  The user must make a screenshot, and grant other applications access to the screenshot. Alternatively an application that has access to the contents of the screen (e.g. a screen recording application) would be required.  Feasibility  The feasibility of such an attack depends on the specic phone and operating system (OS).  On iOS 10 or newer, there is no API for an application to use to access the screen of another application, so this attack vector is not applicable. However, if the attacker plants a malicious application with access to the photo gallery on the device and the user makes a screenshot of the seed phrase or other private information, it is possible for the application to access it.  On Android, the MediaProjection API can be used to record the contents of the screen. The user has to explicitly consent to the access, and during the duration of the screen recording, an icon is shown. This  Security Audit Report | Mina Signer SDK + StakingPower Wallet | Mina Foundation 21 September 2021 by Least Authority TFA GmbH  16  This audit makes no statements or warranties and is for discussion purposes only.   icon represents wireless transmission of the screen contents to a projector or ChromeCast and may not be immediately identiable as a screen recording icon. Additionally, any application with access to the les of the user can access all screenshots.  Mitigation  We recommend that measures to prevent or mitigate the impact of screenshots be taken, as detailed below.  Android  On Android, we recommend setting FLAG_SECURE on the application window and ensuring that no private content is shown in other windows. For more information, we suggest referring to this blog post about vulnerabilities of weak screenshot protection. It appears in the past the techniques used to prevent screen capture in Flutter have occasionally failed, however, the easiest way to enable it may be the flutter_windowmanager package. However, we do recommend testing the setup on multiple devices and Android versions to verify that the packages function correctly.  iOS  On iOS, there is no API to prevent screenshots, which makes mitigating this issue more dicult. In some instances, the only thing that can be done is to remind the user that taking screenshots of the seed means making it available to other applications. In other cases, such as the seed generation screen, stronger measures could be taken. In this case, the iOS event UIApplicationUserDidTakeScreenshotNotication can be handled to display a notice to the user that the action is not secure, and to generate and display a new seed. With this approach, instead of preventing the screenshot of a seed that is used, using a seed that is screenshot is prevented. ScreenShieldKit also warrants mention in this case as a potential resource for preventing screenshots.  Status  The StakingPower Wallet team has implemented a mix of prevention and notication strategies to prevent unnoticed capturing of sensitive information.  Android  On Android, the client protects the contents of the screen showing sensitive information using FLAG_SECURE. While the screen can still be recorded using adb on some devices, this vector is usually not available to attackers.  iOS  On iOS, screenshots on such screens are detected and the user is warned.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/Least-Authority-Mina-Foundation-Mina-Signer-SDK-StakingPower-Wallet-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A:  [ReitBZ Security Token]  setAdministrator  Function Does Not", "body": "  Handle Typos    Location   btg-ReitBZ-token/src/Lorentz/Contracts/BTG/Token/Impl.hs#L94   Synopsis   A safeguard against typos in the  setAdministrator  function does not exist.   Impact   If the admin is changed to an invalid or unknown address, the contract becomes essentially useless.   Preconditions   We have not identified functionality in the dashboard to call  setAdministrator  so we assume that a  custom multisig package or byte string will be created to initialize the functionality that may contain a bad  address.    Technical Details   The  setAdministrator  function does not double check the validity of the new admin. If a typo or  uncontrolled address is inserted, the contract is permanently lost. Extended features are gas-expensive  and are prone to error as well (specifically checking the data length of provided address).    Remediation   It has been suggested by Ethereum that the client does proper checks or that there be some VM level  checking on format of address.    Consider creating a two step update process that would propose an update to the ownership of the  contract. After that transaction is confirmed, the token could require the proposed address to accept the  new ownership. This would catch any updates to incorrect or malformed state.   Status   The two step update process has been implemented by Tezos.   Security Audit Report | BTG Pactual | Tezos Foundation 13 March 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.          Verification   Resolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_BTG_Pactual_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: [ReitBZ Security Token] Unbounded Amount of Minted Coins", "body": "   Location   btg-ReitBZ-token/src/Lorentz/Contracts/BTG/Token/Impl.hs#L100   Synopsis   The  mint  function allows for an unbounded amount of minted coins.   Impact   This money is only received by the baker, while everyone else will need to store the large contract.   Technical Details   At the very least, the contract can be arbitrarily large in size (TB) and only bounded by the gas required for  minting.   Remediation   Modify the  mint  function to bound the amount of minted coins.   Status   A bound on the total amount of tokens that can be minted and modified has been implemented. Both  mint  and  mintBatch  functions check against that bound and fail if it is exceeded.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_BTG_Pactual_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: [ReitBZ Security Token] Potential for Front Running", "body": "   Location   btg-ReitBZ-token/src/Lorentz/Contracts/BTG/Token/Impl.hs#L66   Synopsis   The FA1.2 API for the  Approve  function can lead to ambiguity on behalf of the approver of their approved  amount of tokens.    For example, approver A allows a spender B ten tokens and goes offline. At some point in the future, B  spends five of the approved tokens and A does not witness this. A then decides to only allow the  spending of six tokens to B and calls the approve function to set the balance to zero before calling it  again to allow B to spend six tokens. If A did not witness the spend of five tokens from B at some point,  then B will have spent a total of eleven tokens while A thinks they were only approved to spend six. B may  also witness the incoming reset of the approve to zero tokens transaction and bribe a miner to include a  spend of ten tokens before this happens without A knowing.   Impact   As discussed in  ERC20 API: An Attack Vector on Approve/TransferFrom Methods , this can still lead to  front running attacks where it is not clear via blockchain references to the sender if the previous approval  had spent any of the total amount.    Security Audit Report | BTG Pactual | Tezos Foundation 13 March 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.            Preconditions   This exists in all standard FA1.2 tokens that implement  Approve .    Feasibility   This attack requires that the Approver does not have a good view of the current state of a token  contract. This could happen if their client is out of date, but it is not highly likely that an Approver will not  see an amount already spent. It is also possible for an approved address to bribe a miner to include their  spend before a reduction of their proved amount gets into the blockchain, however, this is also unlikely.   Technical Details   The FA1.2 Token standard implemented in this contract adds a layer of security to prevent a front running  attack on the  Approve  method. This is done by checking that the approval of any amount that is not  already zero is set to zero before adding more approved tokens. As documented by the FA1.2 spec, an  error is provided: UnsafeAllowanceChange - attempt to change approval value from non-zero to non-zero  was performed. The error will contain nat :previous value, where previous stands for the allowance value  upon the contract call.    Mitigation   Keeping state to handle this would be a better approach but may be out of the scope of the project. This  would represent the atomic solution mentioned in the document above. A miner being bribed to spend the  approval before revoking could still happen, but the approvers transaction would then fail to notify them  that the change cannot happen and an amount was already spent.   Status   An  approveCAS  function has been added and the current balance can be checked against what is  expected.     Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_BTG_Pactual_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: [ReitBZ Security Token] Looping Through Inputs", "body": "   Location   btg-ReitBZ-token/src/Lorentz/Contracts/BTG/Dividends/Impl.hs#L58   Synopsis   There are a few places that the contract is allowed to loop through an array and conduct some  operations. A Solidity equivalent reference to this can be found in this documentation on  Gas Limits and  Loops . While attempts can be seen to reduce the gas cost within these loops, the hard limit remains and  there is the potential of a stalled state when a transaction runs out of gas if this behaves the same as  Ethereum. Tezos transactions have a hard limit of 400,000 units of gas, and we found that each storage  call to the batched whitelist function requires 496 units. At 154 addresses, the contract call could stall if  the client does not reject this before submission to the network. Longer lists will lead to larger  transactions that may be harder to include in blocks if there is a heavy load on the network, and a larger  fee may need to be applied to fit the transaction in on time.    Security Audit Report | BTG Pactual | Tezos Foundation 13 March 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.          Impact   A stalled transaction could leave the state of updates using loops unknown for the client. The client may  believe that all updates were applied when not all of them made it into the contract state or attempt to  reapply the same update twice.   Feasibility   The client that is providing the list of users to be updated may be aware in advance by testing if a  transaction will run out of gas so this may not be necessary. The Solidity version of the contract code  mentions iterating off-chain to avoid this.   Mitigation   We suggest writing a unit test that attempts to enter 154 addresses into the  updateWhiteListBatched  function and dividend disbursement test the behavior of hitting the 400,000  gas unit limit.   Another approach would be to call a function that updates one account at a time in a loop off-chain, with  some state on-chain that marks if an account has been updated such that an off-chain loop can call many  times the same function without ever hitting a gas limit. If the off-chain client calls an update to the  function more than once, the contract state will prevent it from updating. This could function like a nonce  for preventing multisig replay of stale state.    Status   Invalid Issue. Tezos has responded that they have considered the loops thoroughly and have confirmed  that this issue has been handled due to the loops being bound and verifiable ahead of time. Incomplete  state updates are also not an issue with Tezos as it is with Ethereum smart contracts, since either a call  succeeds or fails leaving no partial updates when gas depletes.    Verification   Not Applicable.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_BTG_Pactual_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: [ReitBZ Security Token] Multisig Parameters Could Be Improperly", "body": "  Constructed   Location   https://gitlab.com/obsidian.systems/tq/tezos-token-dashboard/blob/c52e7f71ef3cdd2c3ea107d32 b76248bc490c8a8/backend/test/Main.hs   Synopsis   We did not identify any tests for the multisig wallet that could be used to control sensitive operations on  the token. If a generic multisig wallet is used, then signers may unknowingly process an unexpected  transaction.   Impact   The parameters may be improperly constructed before signing which could lead to signatures on  transactions that were not intended (i.e. an improper update address or call to an unexpected function). If  the multisig contract owns the token, this could cause total loss of control.   Technical Details   The contract allows for the generic multisig contract to control execution of generic functions on the  contract system. The inputs to this multisig signing will be Michelson code snippets that are hard to read.   Security Audit Report | BTG Pactual | Tezos Foundation 13 March 2020 by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.          We did not find any client side tools that will help the signers understand the code that is being proposed  to the multisig wallet.   Mitigation   The Tezos client offers basic commands to construct transactions like transfer and approve but custom  calls will need their own implementation. The clients should have a human readable method to construct  the multisig transactions. Consider using a  multisig wrapper contract  that only allows signing specific  parameters.   Status   The generic multisig contract has been replaced with a specialized wrapper, the  MultisigWrapper.hs.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_BTG_Pactual_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: [ReitBZ Security Token] Lack of Generic Multisig Tests", "body": "   Location   https://gitlab.com/obsidian.systems/tq/tezos-token-dashboard/blob/c52e7f71ef3cdd2c3ea107d32 b76248bc490c8a8/backend/test/Main.hs   Synopsis   No tests that confirm the intended functionality of the generic multisig contract itself were present in the  code. Since there are no tests on the multisig contract itself, it is assumed that tests exist elsewhere. It is  difficult to understand the functionality of the multisig contract without proper tests. There could be a  case where the contract is updated to null list, or a list with below the threshold of necessary signers.   Impact   The multisig contract will be the controlling address of the token and unexpected behavior can cause loss  of control of the token. If there is not a proper modifier to limit the ability of ownership change to prevent  the case where there are no owners of the multisig, then control will be lost.   Mitigation   We suggest writing proper tests on the multisig contract.   Status   The generic multisig has been replaced with a specific multisig wrapper that has been integrated into the  client. Most, but not all, of the properties that hold true for the generic multisig contract will hold true for  the wrapper as well. It is suggested that the difference be tested for correctness with either further audits  or formal verification.    Verification   Partially Resolved.   Security Audit Report | BTG Pactual | Tezos Foundation 13 March 2020 by Least Authority TFA GmbH   9   This audit makes no statements or warranties and is for discussion purposes only.          ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_BTG_Pactual_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Lisk-codec Unexpected Error", "body": "   Location   https://github.com/LeastAuthority/lisk-sdk/pull/2   https://github.com/LeastAuthority/lisk-sdk/blob/development/elements/lisk-codec/src/codec.ts#L104   https://github.com/LeastAuthority/lisk-sdk/blob/development/elements/lisk-codec/src/collection.ts#L2 25   Synopsis   Array type schema properties are assigned an empty object by default when no valid element data is  present. This causes a class of errors that aren't handled in the Lisk-codec module itself and would  therefore have to be handled by the caller.   Impact   As codec is used in multiple places (most notably in transaction and block handling), the impact depends  on whether this error is handled, and whether there are any resulting side-effects which might be desirable  to an attacker.   Preconditions   An attacker would have to operate a node and manipulate messages (e.g. transactions) to produce this  error. An attacker would also likely need to possess or have influence over significant stake in the  network to leverage this at higher levels (e.g. block forging), with a potentially greater impact.   Feasibility   This error is possible if an encoding schema with an array property exists.   Mitigation   Disclose this issue to SDK consumers where applicable.   Remediation   We suggest the following:    Remove the default array element object as mentioned  in the discussion on the GitHub PR ; and   Ensure this class of errors is handled in the codec module.   Security Audit Report | Lisk Project: Protocol Design + Implementation | Lisk Foundation 18 December 2020  by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.          Status   The Lisk team has  resolved this issue  by removing the initialization of empty objects in the code, which  fixes the described error and mitigates the issue as suggested. Additionally, a regression test was added.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Lisk_Project_Protocol_Design_and_Implemenation_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Lisk-core CLI Mnemonic Encryption", "body": "   Location   https://github.com/LeastAuthority/lisk-core/blob/development/src/commands/passphrase/encrypt.ts#L 25   https://github.com/LeastAuthority/lisk-sdk/blob/development/elements/lisk-cryptography/src/encrypt.ts #L168   https://github.com/LeastAuthority/lisk-sdk/blob/development/elements/lisk-cryptography/src/encrypt.ts #L115   Synopsis   PBKDF2, the algorithm used to derive the key used to encrypt the mnemonic, is purely CPU-bound and  therefore can be efficiently parallized. This opens an attack vector for searching a low-entropy password  space efficiently.   Impact   A successful attack would allow the attacker to sign arbitrary transactions on behalf of the target. In the  Lisk-core network, actions like token transfers and participation in distributed proof-of-stake could be  taken without the targets prior knowledge and without any recourse. In derivative networks, additional  actions which utilize account key signatures would also be impacted.   Preconditions   An attacker would need access to the encrypted mnemonic as persisted (cipher-text, salt, iv, etc.), as well  as to significant, yet realistic, computational resources.     Feasibility   The preconditions imply some prior successful attack, which makes this issue less likely to be exploited,  although still possible. To increase the speed and chance of success, an attacker would likely require  substantial hardware acceleration and/or compute resources (e.g. GPUs, FPGAs, or ASICs).   Technical Details   PBKDF2  is being used to derive an AES-256-GCM encryption key from a potentially low-entropy password.  That key is then used to encrypt a BIP39 mnemonic. This facilitates file-system persistence of the  mnemonic without the need to persist (and secure) an additional key.   The use of password-based key derivation here is a reasonable solution for this case. AES-256-GCM for  encryption is a reasonable choice for this use case as well. PBKDF2 however, is purely CPU-bound. This  makes it vulnerable to hardware-acceleration-based attacks, especially in the face of a well incentivized  and resourceful attacker. Using a memory-hard function prevents this.   Security Audit Report | Lisk Project: Protocol Design + Implementation | Lisk Foundation 18 December 2020  by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.          Mitigation   We suggest the following mitigation approaches:    End users could manually secure their encrypted mnemonic with an additional layer of encryption   when not in use; or    The application could estimate the strength of the password and reject ones that are obviously   weak; or    End users could store their encrypted mnemonic on an external device and/or cold storage when   not in use.   Remediation   Use the more modern password-based key derivation algorithm  argon2 .  Node bindings to the argon2  reference implementation are available under very permissive licenses (MIT, Apache2/CC0).   Argon2  comes in multiple flavours. Since in this use-case GPU-accelerated attacks are more of a  concern than side-channel attacks, the variant  Argon2d  should be used. Section 4 of the  Argon2 draft  RFC  discusses parameter choice and describes a procedure for choosing them optimally.   Status   The Lisk team has responded that they acknowledge that there are better options for the encryption of the  mnemonic passphrase, however, they intend to continue using the PBKDF2 algorithm. They note that it is  currently used extensively in well-established projects and the risk of the attack is low. As a result, they do  not consider the benefit of implementing a new algorithm to outweigh the cost at the present time.  Nonetheless, they have indicated that implementing  argon2  has been added to their backlog.   However, they have included in their documentation a reminder to  users to always secure their  passphrase with a strong password.  Although this helps to mitigate the issue, we suggest further action  be taken to mitigate the issue in the interim.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Lisk_Project_Protocol_Design_and_Implemenation_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Account Key Derivation", "body": "   Location   https://github.com/LeastAuthority/lisk-core/blob/development/src/commands/account/create.ts#L30   https://github.com/LeastAuthority/lisk-sdk/blob/development/elements/lisk-cryptography/src/keys.ts#L 27   https://github.com/LeastAuthority/lisk-sdk/blob/development/elements/lisk-cryptography/src/keys.ts#L 23   https://github.com/LeastAuthority/lisk-sdk/blob/development/elements/lisk-cryptography/src/hash.ts#L 26   Synopsis   As described  here  in the Lisk Protocol documentation, account keys are derived by extracting the entropy  from a BIP39 mnemonic to seed an Ed25519 keypair. This extraction is done using a single application of  the SHA-256 algorithm. However, SHA-256 is a hash function and does not provide the properties of an  extractor. Although no attacks are known against this use case in general, it is not a recommended   Security Audit Report | Lisk Project: Protocol Design + Implementation | Lisk Foundation 18 December 2020  by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.        cryptographic design. Instead, an extractor such as HKDF-Extract should be used to avoid the  unnecessary risk for such an attack.    Impact   The derived keys are used to sign network transactions. If compromised, an attacker could sign arbitrary  transactions on behalf of the target. In the Lisk-core network, actions like token transfers and  participation in delegated-proof-of-stake could be taken without the targets prior knowledge and without  any recourse. In derivative networks, additional actions which utilize account key signatures would also  be impacted.   Feasibility   No efficient attacks are publicly known.   Technical Details   SHA-256 is a hash function, not an extractor. If youre extracting keys, the best practice is to use an  extractor. HKDF is a simple, efficient and provably secure extract-then-expand key derivation function.  Many libraries allow running only the extract phase of the KDF, which suffices in this case. The HKDF  extract phase takes two inputs: the input keying material IKM and a salt. The purpose of the salt is not to  grow the search space, but to randomize the extraction procedure. Therefore, a single 256 bit salt should  be chosen at random by the developers and hard-coded in the application.   Remediation   Use HKDF to derive the account key from the mnemonic. Use the mnemonic as input keying material and  a random salt that was generated by the developers and hard-coded into the application.   We understand that this is a breaking change for account keys. One migration path could be to operate  two accounts in parallel, one of them SHA-based and one HKDF-based, and transfer all assets from the  SHA-based account to the HKDF-based account. Then, the SHA-based account would need to be  monitored for new incoming transactions, and received assets would need to be forwarded to the  HKDF-based account. We recommend generating a new mnemonic for the HKDF-based account, because  doing otherwise would constitute a form of key reuse.   Status   The Lisk team responded that they do not intend to implement a remediation for this issue, as they  consider the required account migration and added account management effort to be unacceptable at  this time. We recommend that the Lisk team reconsider resolving this issue in the future, especially if  there is a more convenient opportunity when making other updates to the project.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Lisk_Project_Protocol_Design_and_Implemenation_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: [utils]   Nonce  Function Uses an Insecure Random Number", "body": "  Generator   Location   https://github.com/ecadlabs/taquito/blob/master/packages/taquito-utils/src/taquito-utils.ts#L134-L141   Synopsis   The utility function   Nonce  uses JavaScripts built-in  Math.random() , which is not a secure source of  entropy - a widely known design property of most JavaScript implementations since the 1990s.   Impact   Low/Unknown. Nonces are not generally required to be cryptographically secure, only pseudorandom, due  to the simple requirement that they should not be reused with the same key. The purpose of this utility  function is not immediately clear, as it is not found elsewhere in the packages that are in scope for this  audit.   Remediation   Change the function to use the browsers native cryptography implementation in order to ensure that a  secure source of entropy is used.   const toHexString = bytes => {     bytes.reduce((str, byte) => str + byte.toString(16)   Security Audit Report | Taquito | Tezos Foundation 19 June 2020 by Least Authority TFA GmbH   4   This audit makes no statements or warranties and is for discussion purposes only.        .padStart(2, '0'), '');   };   export const  Nonce = (length: number): string => {     return toHexString(crypto.getRandomValues(new Uint8Array(length)));   };   Status   The development team has removed the addressed   Nonce  function.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Taquito_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: [remote-signer] Signature Not Validated Upon Receipt of", "body": "  Response   Location   https://github.com/ecadlabs/taquito/blob/master/packages/taquito-remote-signer/src/taquito-remote-si gner.ts    Synopsis   The client requests the server to sign a message specifying the public portion of the keypair to be used.  However, when the server responds with the signature, the client does not verify it.   Impact   Low. If the signing server is compromised or otherwise contains a bug, it can return invalid signatures.  This may cause interruptions in the proper function of the client when other components or software  makes an attempt to verify the signature.   Preconditions   Compromise of the signing server.   Remediation   Given that the client knows the public key hash that corresponds to the private key it wishes the server to  sign the message with, the server should respond with the fully qualified public key. Furthermore, the  client should check it against the public key hash that it knows and use the public key to verify that the  signature returned from the server is valid.   Status   The development team implemented the remediation suggestion by adding a function that takes the  message bytes and signature from the remote signer and validates it against the public key. Additionally,  the function validates that the public key returned from the remote signer and the public key used to  initialize the public signer are identical.    Verification   Resolved.   Security Audit Report | Taquito | Tezos Foundation 19 June 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.          ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Taquito_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: [remote-signer] Missing Adequate Test Coverage", "body": "   Location   https://github.com/ecadlabs/taquito/blob/master/packages/taquito-remote-signer/src/taquito-remote-si gner.ts    Synopsis   There are no automated tests for the remote signer package, which may lead to future bugs and security  issues.   Impact   Low/Unknown. The lack of a testing baseline allows future changes to the package to introduce new bugs  and potential security vulnerabilities.   Remediation   Author a complete test suite to cover the existing remote-signer code end-to-end.   Status   The unit test coverage has been increased up to an acceptable ratio in the aforementioned package.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Taquito_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: [all] NPM Audit Found 47,000+ Known Vulnerabilities in", "body": "  Dependency Graph   Synopsis   The dependency versions listed in the existing package.json were automatically scanned by NPM,  revealing a very large number of known security issues. Due to the large number of issues, we did not  inspect each one individually and cannot speak to the effect these issues may or may not have on the  project.   Impact   High/Unknown. Since we did not inspect all 47,000 issues, we are not able to provide an impact  assessment. However, it is not feasible to maintain a secure codebase if dependencies are stagnant and  outdated, allowing for such a high number of potential issues.   Remediation   Performing an automatic upgrade using  NPM audit fix  and a manual upgrade for the remaining  packages that cannot be upgraded automatically was found to have no adverse impact on the existing  test suite.   Status   The vast majority of previously reported known vulnerabilities in dependencies have been resolved. The  development team has stated that they will proactively monitor and update dependencies moving  forward.    Verification   Resolved.   Security Audit Report | Taquito | Tezos Foundation 19 June 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.           ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Taquito_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: [utils] Michelson Parsing Functions are Insecure, Untested and", "body": "  Undocumented   Location   https://github.com/ecadlabs/taquito/blob/master/packages/taquito-utils/src/taquito-utils.ts#L157-L342    Synopsis   The functions  sexp2mic  and  ml2mic  in the  taquito-utils  package  are security concerns due to their  handling of important user inputs. In addition, they cannot be verified due to having no testing or  documentation of their intended behaviors. If these parsers are to convert Michelson expressions into the  official JSON representation , they currently handle many inputs incorrectly, such as proper representation  of integers, strings, or annotation. They also remove escaping on escaped inputs, which appears to be  unintended.   Additionally, these parsers do not attempt validate inputs and will not provide an error on basic syntactic  issues such as improperly nested parentheses or brackets. As a result, the functions cannot be used  safely and can be used to generate invalid and mangled outputs.   Furthermore, the construction and intended usage of these functions is confusing. It is unclear if  sexp2mic  and  ml2mic  are intended to have different behaviors or operate under different  circumstances. This is further complicated by how  ml2mic  will at times recurse into  sexp2mic  instead  of itself.    Impact   High/Unknown. It is unclear how these functions are expected to be used or how their results are  expected to be handled and, as a result, it is difficult to make accurate conclusions about the attack  surface. In cases where these functions are handling untrusted user input that has not been properly  sanitized, it is possible to imagine a malicious user exploiting them in order to generate Michelson JSON  that has radically different behavior from the input JSON string.    Remediation   At a minimum, the intended behavior of the functions should be properly documented. They should also  have comprehensive test coverage and follow the model of the local-forging integration tests, which  ideally compare against official values obtained via RPC.   As a suggestion, since writing secure and efficient parsers is challenging, it may be valuable to use a  parser generator or parser combinator library such as PEG.js with a typescript plugin, or tsPEG. This will  prevent many common mistakes, and result in code that is easier to write, read, maintain, and audit.   Status   The development team has stated that they intend to remove the specified functions and replace them  with the more complete and robust  michel-codec  package. While this has not been implemented at the  time of the verification review due to the effort required in constructing  michel-codec , the intended plan  should resolve the issue.    Verification   Unresolved.   Security Audit Report | Taquito | Tezos Foundation 19 June 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.            ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Taquito_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Flash Loan Attack (Known Issue)", "body": "   Location   /contracts/strategies/curve/CRVStrategyStable.sol     Synopsis   Using a flash loan, a contract is able to make a Harvest deposit while also manipulating the share price of  the underlying token, and then withdraw the deposit to make a profit, and steal from the other depositors  via the Harvest buffer.   Security Audit Report | Harvest Smart Contracts | Harvest Finance 17 February 2021 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.          Impact   Funds can be manipulated and withdrawn. A previous flash loan attack on Harvest Finance, which  occured on 26 October 2020, resulted in the theft of $33.6 million worth of funds, representing 3% of the  total value in the Harvest Finance protocol.   Preconditions   Harvest Finance supports strategies that invest in DeFi protocols whose price can be manipulated by a  flash loan.   Feasibility   Attacks utilizing flash loans are sometimes easy, depending on the approach taken, and interactions  between Harvest Finance and the DeFi protocol used by a strategy. As the Harvest Smart Contracts  incorporate other DeFi protocols, it is possible that new flash loan attacks will become feasible.   Technical Details   With the previous flash loan attack, the attacker took out a flash loan, and used it to acquire a large  amount of USDC and USDT. They then converted the USDT to USDC inside the curve yPool, increasing the  price of USDC within yPool. The attacker then deposited a large amount of USDC into Harvest Finance.  Due to the inflated price of USDC at the time, the share price relative to USDC had lowered and the  attacker obtained slightly more shares than usual. They then reversed their swap of USDT back to USDC  and withdrew from Harvest Finance. Since the USDC price had now returned to normal and the share  price increased, they were able to sell the shares back for slightly more than they brought them. This extra  amount was paid from the Harvest Finance buffer.   Remediation   Existing Remediation: Price Checkpointing   These attacks require a flash loan, which depends on multiple technical aspects of Ethereum  contracts, in addition to the ability to manipulate Vault share prices and get a positive financial  return. In response to the previous attack, the Harvest Finance team has designed the  remediation strategy described in the  Vault redesign document . When calculating a share  value, instead of using the current price (which may be manipulated via a flash loan), the  system compares the current price with the last price checkpoint and uses the minimum of the  two in the withdraw function and the maximum of the two prices in the deposit function. This  means that a price manipulation will not affect the share price. A flash loan will lose money, fail  to be repaid, and be reverted.    We agree that the Vault redesign should be sufficient to prevent flash loans from being used  against Harvest Finance. However, as noted in the  Vault redesign document , it negatively  affects user experience in that it causes a delay in transactions or a discrepancy in price:   As a consequence of the virtual price calculation, if an honest user deposits funds into a vault,  they should wait for at least one  doHardWork()  call before withdrawing, otherwise they will notice  a slight discrepancy between the deposited amount and the amount withdrawn.     Consequently, honest users would need to be aware of price checkpointing being used, in order to avoid  being subject to price discrepancies between the times in which  doHardWork  is called.   After exploring the issue during our review, we suggest several alternative ways flash loans could be  prevented in purely technical, non-economic ways, as detailed below.    Security Audit Report | Harvest Smart Contracts | Harvest Finance 17 February 2021 by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.            Alternative Potential Remediations   Restrict all contracts   The first possibility is to restrict all contracts, disallowing the use of a contract to invest in Harvest  Finance. A flash loan can only be made out to a contract and not an Externally Owned Account (EOA)  because the flash loan calls back to the recipient, who must repay the loan before it returns. An EOA can  call EVM functions but cannot itself be called, thus it is unable to receive flash loans except by deploying  a contract. While this remediation would prevent flash loan attacks, creating a system where no one can  use a contract to invest in Harvest Finance may be seen as too severe a limitation.   Two-step process   A second strategy is to target the synchronicity attribute of flashs loans, specifically, that they must be  repaid before the flash loan call returns. If a contract is not able to both deposit and withdraw within a  single transaction, it would be impossible to repay the flash loan, causing it to be reverted. In a  post-mortem blog post about the attack , the Harvest Finance team suggested using a commit-and-reveal  mechanism for deposits. In this case, a user would transfer funds into Harvest Finance in a single step  and then claim it in the next. As the Harvest Finance team points out, this has the negative side effect of  changing the user experience and API by requiring two transactions, as well as increasing gas costs.   However, simply requiring that a deposit and a withdrawal are in two separate blocks would interrupt  flash loans in the same way, but with the positive benefit of not altering the user experience. To  implement this method of resistance to a flash loan, a contract could keep a map of the address to the  block height of the last interaction with the contract and whether it was a deposit or withdrawal. If the  previous interaction was before the current block height, then the call is allowed to proceed, but if the  previous interaction equals the current block height, then the transaction is reverted. By requiring the  withdrawal after the deposit to be made in at least the next block, it will be impossible to use the contract  via a flash loan.   Return Funds At Deposit Price If Withdrawn Before  doDardWork  Call   Alternatively, there is another way to interrupt flash loans to prevent an attack. If the deposited funds are  withdrawn before  doHardWork  is called, it makes sense to simply return the funds at the price paid on  deposit. With a flash loan (or other price manipulation attacks), the deposit is made, then the attacker  performs a price manipulation, and then withdraws. Prior to calling  doHardWork , these funds are sitting  in the Vault and they have not done any  work.  If they are withdrawn before the funds have done anything,  they can simply be returned at the same price.    In the edge case where attackers deposit funds in multiple transactions during price changes but before  calling  doHardWork , a simple solution would be to record the price as the average of the two prices paid,  weighted by the amounts brought in each time. This is a simple calculation:    price_new = (price1*deposit1+price2*deposit2)/(deposit1+deposit2)    deposit_new = deposit1+deposit2    If they then withdraw both deposits, it is done at  price_new , and they get the same amount back as if  they had withdrawn  deposit1  before they made  deposit2 . Although it might seem necessary to record  this in a complicated data structure, this should be avoided in Ethereum contracts. The important thing is  that any funds that do not enter the actual DeFi exchange are withdrawn at the same price.   Verification   While we agree that the currently implemented price-checkpoint remediation should prevent flash loan  attacks, we recommend considering this last remediation option. By returning the funds at the price paid   Security Audit Report | Harvest Smart Contracts | Harvest Finance 17 February 2021 by Least Authority TFA GmbH   9   This audit makes no statements or warranties and is for discussion purposes only.        at deposit, it makes an attack uneconomical. The simplicity of using this price would not introduce the  complexities of determining legitimate and illegitimate prices, and without impacting the user experience  as a two step process requires. Furthermore, contracts depositing and withdrawing in the same  transaction would still work, but neither making a profit nor a loss.   Status   Not Applicable. The Harvest Finance team has informed us they have discontinued the strategies which  were vulnerable to price manipulations and have reverted to a previous code design that was out-of-scope  for our review. As a result of this decision, the code that is currently running in production has not been  audited by our team and we recommend it be reviewed for the presence of this or similar issues.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Harvest_Finance_Harvest_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Sandwich Attack (Known Issue)", "body": "   Synopsis   We believe this type of attack first surfaced in the form of front-running attacks against exchanges. The  creator of  Uniswap  has coined this  The Dark Forest  of Ethereum, where transaction ordering and the  public nature of the blockchain create front-running buy and sell attacks. In the context of Harvest  Finance, a sandwich attack is an attempt to manipulate prices and commit a similar attack to  Issue A  by  manipulating the price before  and  after the call to  doHardWork  (which encompasses the price  checkpoint), thus \"sandwiching\" the  doHardWork  transaction. Even if a remediation to  Issue A  prevents  price manipulations within a single transaction, it is still possible that one is performed over multiple  transactions.   As flash loans should no longer be possible after the  existing remediation  was implemented for  Issue A ,  the actor carrying out a successful sandwich attack needs to be a whale, that is, a market participant  with enough funds to make large transactions that move the market on their own. The whale knows about  these market movements ahead of other participants because they create them. Therefore, they can  profit from them by taking funds from other participants.    Impact   Funds can be manipulated and withdrawn.   Preconditions   A price checkpoint based mitigation to flash loans has been implemented and the attacker has enough  funds to move the market on their own.   Feasibility   This attack is feasible if the attacker has a large amount of funds and sufficient understanding of the  system. From the point of view of the attacker, there is also a risk associated with a sandwich attack,  which is not present in the case of a flash loan based attack. There are typically no guarantees that the  sandwich attack will not lose funds to arbitrage bots, since attacks cannot be conducted in the safety of  one transaction if the remediation in  Issue A  is in place. The attacker must broadcast a transaction that  gets mined before the  doHardWork  call and, since miners order transactions by gas price, this is as  simple as using a higher gas price. They must also make a second transaction with a lower gas price (and  there is a risk for them there that transactions will get chosen by miners instead).   Technical Details   With the price checkpoint remediation to  Issue A , a new price checkpoint is set when  doHardWork  is  called. A sandwich attack can be successful if an attacker is able to insert a price manipulation after this  transaction is observed but before it is mined, and then append another transaction that takes advantage  of the manipulation that is mined soon after the  doHardWork  transaction. The actual attack transactions   Security Audit Report | Harvest Smart Contracts | Harvest Finance 17 February 2021 by Least Authority TFA GmbH   10   This audit makes no statements or warranties and is for discussion purposes only.          would be similar to those used in  Issue A , with the only difference being that they are performed in  separate transactions, one inserted before the  doHardWork  call which sets the price checkpoint, and one  appended as soon as possible after it.   Mitigation   The Harvest Finance team has implemented a mitigation to this attack with a  New Vault Design , using a  price hint that is passed to the  doHardWork  call on the  Controller  contract. When calling  doHardWork , an expected price and acceptance ratio is checked, and if the measured price at the time  the contract is mined is outside that price by more than the acceptable ratio, then the transaction is  reverted. The price hint and ratio is chosen by Harvest governance before making the call. If there is an  unexpected change in price before the transaction is mined, it will be reverted. Thus, the most the attacker  could achieve is causing the doHardWork call to revert.   We consider this a mitigation (and not a remediation) because it reduces the impact but does not  eliminate the problem. Because an acceptance ratio is used, an attacker may still profit if their attack is  small enough. The  documented flash loan attack  used only a 1% price manipulation, while still extracting  a large amount, so this seems possible. This mitigation also has the downside that Harvest Finance now  carries the responsibility to approve prices. Choosing an acceptance ratio that is too small makes it easy  to block  doHardWork  (see  Issue C ), but choosing an acceptance ratio that is too high will make it easier  to make small but still profitable manipulations.   To strengthen this mitigation, it may be worth considering making the  doHardWork  call with a low gas  price. Paradoxically, this will make it more difficult to sandwich. It will still be easy to insert a transaction  before the doHardWork call, however, appending a transaction after it becomes more risky. Most  Ethereum users prefer to save money using the average gas price. If there are many other transactions in  the mempool using the same price, it becomes harder to insert the bottom layer of the sandwich. If  miners must choose between many transactions, then it's possible that transaction is bumped to the next  block. This significantly increases the arbitrage risk for the attacker.   Remediation   Direct Withdrawals   Another approach to fixing the sandwich attack would be to avoid tracking the price entirely. In the  Harvest Finance  post mortem blog post , a design is discussed whereby instead of calculating a share  price based on the current market price, the user simply withdraws the underlying asset and then  exchanges it themselves. By not involving the price, this completely avoids price manipulations. Notably,  this approach would be a very significant change to Harvest Finance.   This remediation could be improved by automating the exchange, but by using the actual exchange  contract rather than calculating an exchange rate. The documented attack used 17 million units to  manipulate the price, causing a 1% price manipulation, then withdrew 50 million units. However, if this 50  million unit withdrawal went through the actual exchange contract, it would have just caused another  price manipulation in the opposite direction. The outcome would depend on how the DeFi exchange in  question operates, but it would likely not be profitable for the attacker.    Random ordering of Ethereum transactions   The sandwich attack is possible because the ordering of Ethereum transactions is deterministic.  Transactions are selected by highest gas price, and then ordered from highest to lowest price in the  block. This makes front running possible. If miners chose to order transactions randomly, it would not be  possible to perform this attack, except as a miner. The ordering of transactions is not fixed in the  Ethereum specification, it is simply the default behavior of the clients to order them from highest to  lowest price. Changing this would not require a hard fork, but it would require campaigning to have this   Security Audit Report | Harvest Smart Contracts | Harvest Finance 17 February 2021 by Least Authority TFA GmbH   11   This audit makes no statements or warranties and is for discussion purposes only.        change made to clients and adopted by miners. This would prevent sandwich attacks for Harvest Finance,  and also eliminate front running attacks for a large number of Ethereum contracts. This is not a short  term fix, but it is also not mutually exclusive to the mitigation already implemented or the direct  withdrawal remediation suggested above.    Verification   We understand that possibly neither of these suggested remediations are immediately viable for the  Harvest Finance team, however, we encourage these to be considered as the system and the DeFi  ecosystem on Ethereum continue to grow.    Status   Not Applicable. The Harvest Finance team has informed us they have discontinued the strategies which  were vulnerable to price manipulations and have reverted to a previous code design that was out-of-scope  for our review. As a result of this decision, the code that is currently running in production has not been  audited by our team and we recommend it be reviewed for the presence of this or similar issues.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Harvest_Finance_Harvest_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Price Checkpoint DoS", "body": "   Location    /contracts/Controller.sol#L56-L76    Synopsis   This issue arises from the mitigation strategy of the  Vault redesign  for sandwich attacks, specifically the  Controller  contract calling  doHardWork  and the control over the expected slippage of price from the  Controller . If an attacker is able to predict the acceptable slippage of the  Controller , they may  attempt to front-run every  Controller  call to  doHardWork . The attacker must manipulate the price of  the assets such that the  Controller  transaction will revert for being outside of the acceptable limit. The  governance of Harvest Finance will attempt to reduce the allowed slippage percentage as much as  possible to prevent high slippage manipulations, but in doing so, they will make it easier to block  doHardWork  price checkpoints by making the percentage of slippage small and minimizing the amount  of manipulation needed to block the call.   Impact   An incorrect recorded price for an extended period of time could cause any deposits after the attack to be  withdrawn at an incorrect rate. However, if the  last remediation that we propose in Issue A  is  implemented, there will no longer be a price checkpoint that a DoS attack can affect. Such an attack  would only block the call to  doHardWork , which should reduce the profitability of engaging in a  checkpoint DoS attack.   Preconditions   The attacker must be able to front-run the  Controller s attempt to call  doHardWork . They must also  be able to manipulate the market to place the price hint outside of an acceptable range. Additionally, they  must be able to tolerate potential losses due to arbitrage for manipulating the price many times in a row.   Feasibility   While this attack is feasible, it presents risks to the attacker that may make it much more difficult to carry  out, since it requires both the capital to move prices frequently and the ability to time the sandwich in a  way that reduces the risk of arbitrage losses. It is also not clear how the attacker will weigh the cost of  the attack against the profit, as profit must be made from a stale price being recorded over a period of  time where prices will fluctuate naturally outside of the control of the attacker. This would require  constant scanning of the mempool to catch calls to  doHardWork , similar to the sandwich attack   Security Audit Report | Harvest Smart Contracts | Harvest Finance 17 February 2021 by Least Authority TFA GmbH   12   This audit makes no statements or warranties and is for discussion purposes only.          discussed in  Issue B , and would require a good deal of expenditure in transaction fees to always order  before Harvest Finance transactions. Generally, there is no guarantee that an attacker will have their  transactions ordered correctly and the Harvest Finance team intends to obfuscate the time when  doHardWork  is called, making it more difficult for selfish mining to ensure proper ordering.   Technical Details   The  Vault redesign document  states:   As a consequence of the virtual price calculation, if an honest user deposits funds into a vault, they  should wait for at least one  doHardWork()  call before withdrawing, otherwise they will notice a  slight discrepancy between the deposited amount and the amount withdrawn.\"   If the share price hint is small, this attack will be easier, but it is still possible to block  doHardWork  calls if  the attacker can tolerate moving the market price with a large amount of funding. The attacker would  need to make a deposit at a normally recorded price from a previous  doHardWork  call. Assuming that  the value of the shares fluctuates, the attacker would then continuously sandwich attack the  Controller  with a price slippage that is outside of its acceptable range. This will effectively block the  call to  doHardWork  and any update to the recorded price used to prevent flash loan attacks. This  blockage will lock the price in at an outdated value and increase the discrepancy mentioned in the  Vault  redesign document . As more deposits enter the strategy, this price discrepancy could be in favor of the  early deposit from the attacker.   Mitigation   While there are currently no industry standard best practices to address sandwich attacks, in this case,  the attack can only succeed if the attacker is able to perpetually block the price update at the  Controller  level. Harvest Finance could always call  doHardWork  with a high slippage amount, but a  front-running bot could detect this and commit a normal sandwich attack with a high slippage. In addition,  any mitigations for the previous sandwich attack ( Issue B ) should help in preventing this price checkpoint  DoS attack.    Controlling or purchasing a miner that can discover blocks at a rate that  doHardWork  needs to be called  could fully remediate this issue. Clearing a full block to ensure that no sandwich attacks will throw the  expected price out of range will ensure that the Harvest Finance team can have a successful transaction  to the  Controller  contract and update the price checkpoint. However, the cost for doing so may be  prohibitive to the organization and, as a result, this approach should be only considered as a potential  mitigation.   We recommend that the Harvest Finance team further explore the potential alternative remediations  outlined in  Issue A , specifically, the  remediation  that will return the funds to the attacker without affecting  the pool if it is called before  doHardWork . This will prevent flash loan attacks and will potentially remove  further profits that could be gained by delaying the price checkpoint, as there will be no need to price  checkpoint within doHardWork, thus reducing the incentive to DoS this function.    Status   Not Applicable. The Harvest Finance team has informed us they have discontinued the strategies which  were vulnerable to price manipulations and have reverted to a previous code design that was out-of-scope  for our review. As a result of this decision, the code that is currently running in production has not been  audited by our team and we recommend it be reviewed for the presence of this or similar issues.   Additionally, we note that the  Vault.sol  still has an option  allowSharePriceDecrease  which, if set  to false, causes the doHardWork function to revert if the share price decreases. This means that an   Security Audit Report | Harvest Smart Contracts | Harvest Finance 17 February 2021 by Least Authority TFA GmbH   13   This audit makes no statements or warranties and is for discussion purposes only.        attacker could block doHardWork, but only by manipulating the share price down. The Harvest Finance  Governance can unset this option.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Harvest_Finance_Harvest_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Funds are vulnerable to owning malicious assets", "body": "  Reported: 20/12/2017  Synopsis: A fund is exposed to risk that any owned asset is malicious. Any third-party contract, but especially assets, should be regarded as untrusted code.  Impact: It can become impossible to successfully call any method that iterates over held Assets: calcGav, redeemOwnedAssets, which affects performCalculations, calcSharePrice, executeRequest (to buy or sell shares). This effectively freezes the fund, although shares can still be transferred, as they are valid ERC223 tokens.  Since the risk of this vulnerability is that any asset is malicious, if a large amount of assets are held the risk increases significantly. Fund managers are likely to estimate their risk in proportion to the amount held, but this does not work like that. Holding any amount of a malicious asset means the entire fund is at risk of being frozen.  Preconditions: An attacker creates a ERC20/223 token with a backdoor that allows them to disable correct behaviour on any asset method, for example by making transfer or balanceOf throw, then they socially engineer fund managers into holding some of that asset. Its also possible to exploit this vulnerability by hacking an asset that the fund already holds. Although, it would be unlikely that an honestly written but hacked contract really fails in the worst way to trigger every precondition for this vulnerability. It would also be far easier to construct a backdoored asset, identify fund managers pursuing high-risk strategies and invite them to hold your malicious asset.  Feasibility: Since the main obstacle is just to socially engineering fund managers, and given that Melonport significantly lowers the barriers to becoming the manager of an investment fund, this attack seems highly feasible.  Technical Details: Melonport funds can hold up to 90 assets, each of these assets is a third party contract that must execute its own code as part of the normal fund operation. If a fund holds an asset that later stops behaving correctly, various fund functionality is disrupted. The malicious creator of an malicious asset would then force the fund manager to pay a ransom to regain access to their fund.  If EvilAsset#transfer returns false, then redeemOwnedAssets will call revert instead of succeeding, meaning investors cannot redeem fund assets. If EvilAsset#balanceOf throws an error then calcGav (gross asset value) will fail, which means the value of the fund cannot be calculated. If EvilAsset#approve fails, its not possible to trade that asset, but this does not affect the ability to trade other assets.   Mitigation: As the code stands, fund managers must be very careful to audit every asset they hold. To decrease the risk of holding malicious assets its advisable to hold fewer assets, as a chain is only as strong as its weakest link, so a shorter chain is probably stronger than a longer chain. This vulnerability does not disrupt the ability to transfer shares of the fund (since they are ERC223 tokens). If suspicious assets are held into by a high risk fund, and then shares in that fund are owned by the main fund, and the high risk fund is frozen by a malicious asset, then the main fund will still operate correctly. However this fund structure must be put in place before the malicious asset turns malicious.  Remediation: This vulnerability is difficult to remediate without increasing the complexity of the fund or giving the fund manager arbitrary power. The key is that it needs to be possible to operate the fund without calling any methods on the malicious asset. The simplest way to achieve this would be to give the fund manager the ability to disable or burn an asset- to just dump it out of the holdings, temporarily or permanently.  Permanently burning the asset by adding the asset to a list of assets that can now never be held again by the fund would mean the fund manager could not abuse this to manipulate the value of the fund, because the action being one-way would disincentive a rational fund manager from dumping a non-malicious asset.  Another remediation would be to have the ability to wrap any asset in a holding contract. This would be like a fund that only held one asset. It would enforce correct ERC223 behaviour, and ensure that its always possible to call transfer or balanceOf. If you called transfer on the holding contract, that would attempt to call transfer on the held asset. However, iif that failed, it would instead transfer a share of the holding contract, which could be redeemed if or when the held asset starts working again. This could also be useful for assets which possibly limit transfers in some way, such as, only after a given time.  Note: Its also possible that the other modules are malicious, but given that modules are selected only at the creation of the contract its somewhat a smaller risk.  Status: Partial remediation. Melonport chose a remediation whereby investors can call redeemOwnedAssets with a list of assets, where they forfeit assets not in the list. Although, this is a satisfactory remediation, there must be no iteration over the held assets (malicious assets must be fully excluded) otherwise the call will not succeed.  Verification: Still vulnerable. First attempt at remediation was a helpful but did not eliminate iteration over held assets.  ", "html_url": "https://leastauthority.com/melonport_security_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Funds are exposed to vulnerabilities in modules", "body": "  Reported: 20/12/2017  Synopsis: Functionality that is critical to Melonport funds are supplied by third-party modules selected by the fund manager. Any vulnerability in these modules can affect   Melonport funds using them. Therefore, it is critical that fund owners have the tools they need to make good security decisions.  Impact: Vulnerabilities in modules can effect fund functionality in various ways. Problems with risk management or compliance modules is unlikely to have catastrophic effects. Vulnerabilities in pricefeed or exchange modules could cause unprofitable trades to be made, or to manipulate the calculated value of the fund. Popular modules are likely to be high value targets.  Preconditions: A vulnerability exists in some module(s) used in one or more funds and someone exploits them. This includes potentially desirable features, such as upgradability and ownership of the module code.  Feasibility: Exploiting modules is likely to be difficult, but they are also high value. There have already been some improbably spectacular hacks of Ethereum contracts, so we must assume that it is indeed feasible.  Technical Details: There are many places vulnerabilities could be inserted and hidden in Ethereum contracts. For example, Solidity is a compiled language that should be deterministic, but there are various versions of the compiler which may apply different optimizations to save gas, creating different EVM contracts. If compilation is non-deterministic, its hard to detect trojans in the compiler, which is unlikely but would be devastating. Its also hard to detect a malicious EVM inserted after compilation, which would be easy to detect if compilation is deterministic and is checked. The Solidity code still needs to be audited and automated tools such as Oyente help, but they cannot detect if the contract is just malicious.  Mitigation: Each module requires careful auditing and this is time consuming and expensive. However, auditing tools can be created to make this easier, and there is information that can make this easier on auditors. In particular, we advise storing the Git commit of the module in the registry so that its possible for auditors to check deterministic compilation. This allows auditors to audit the Solidity code, and not the EVM.  It is probably a good idea to consider escape hatches to redeem a fund even if the pricefeed and other essential modules have failed. Some notable high profile attacks, such as the Parity attack by devops199, only resulted locked contracts. If an attacker caused a module pricefeed or exchange module to self destruct, the fund could not operate as normal. For example, if it redeemOwnedAssets didnt call allocateUnclaimedReward then it would not depend on any modules, and this would mean investors could get their shares out. They would have to exchange their share of the funds assets themselves, but they dont lose their money.  If an attacker gains total control over the exchange it may be possible for them to steal funds in some way. However, being able to redeemOwnedAssets will probably allow investors to save some of their money.   Remediation: Its not truly possible to fully remedy this problem. Although tooling can be created to assist evaluating the security of modules, fund managers need to understand the seriousness of selecting modules carefully and the benefit of having them be well audited.  Status: Storing git commit is implemented.  Verification: Mitigation of storing Git commit hash is verified.  ", "html_url": "https://leastauthority.com/melonport_security_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Funds are vulnerable to re-entrance from modules", "body": "  Reported: 20/12/2017  Synopsis: Melonport code largely designs to prevent re-entrance from calling contracts. Calls to modules, however, permit a malicious module to re-enter.  Impact: Module developers may be able to piggyback on users transactions and re-enter the contract. This could allow price feeds to front-run users, and/or manipulate fees.  Preconditions: A module developer must design a module to re-enter the fund contract. A fund manager must choose this malicious module when setting up the fund.  Feasibility: As with issues D and E, feasibility depends greatly on the user interface. If there is not a reliable way to identify the author of a module or audit the integrity of module code over time I would consider this attack feasible.  Technical Details: Fund.sol calls outside modules without validating results or taking steps to prevent re-entry from module code. This means that modules may re-enter the fund class, and update its state in advance of the results of the users call. For instance, the pricefeed module, when called in redeemOwnedAssets may hold assets in the fund, and may make a sale or purchase in advance of the users redemption of assets. The sale made by the price-feed would change the GAV of the fund, which would influence the users redemption and the managers fee.  Remediation: User interface must reflect that modules are potentially dangerous code. Fund managers must be aware that using modules made by third-party developers risks user funds. Modules listed on a public market should be made to undergo a third-party review process.  Status: Not addressed.  Verification: Not done, yet.   ", "html_url": "https://leastauthority.com/melonport_security_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Use of confusing module names", "body": "  Reported: 18/12/2017  Synopsis: Modules can be published with the same or similar names as a phishing attack, which may induce a fund manager to select a vulnerable or malicious module. Confusing names can also be used for injection attacks on pages that describe or let managers select modules.  Impact: Fund managers may be fooled into selecting insecure modules.  Preconditions: An attacker publishes a module that looks very similar to a popular module but is malicious, and hopes that a fund manager selects it for their fund.  Feasibility: The feasibility greatly depends on how the user interface presents modules. If there are inconsistencies in information about the modules throughout the module selection process, it could easily go unnoticed.  Technical Details: Module names can be an arbitrary binary value, assuming utf8 this can include values that look the same, but differ in ways not visually obvious, such as the zero width joiner character. Also, in other module systems vulnerabilities have been shown to arise because users forget punctuation in the module name, such as hyphens or underscore, or the exact capitalization is not used.  Mitigation: Module names should probably be restricted to safe ASCII characters, without punctuation. Its acceptable to show capitals and punctuation in the user interface but it should not be allowed to publish both an uppercase and lowercase version of the same name, or a hyphenated or non-hyphenated name. This mitigation could be applied in the user interface, which would just filter out and not display modules that have potentially confusing names, as long as it detects cases where the two versions of the same name are published and takes the displays the first published. It would be better if this was enforced on publish via the contract, from the perspective of being confidently audited, but this has the downside of having less chance to fix bugs.  A good search system would also help, because it can suggest the best modules, and detect typos where they probably meant something else. This could give the user a second chance to select the module they intended to select.  Remediation: It is very difficult to fully remedy this vulnerability, but with enough mitigation it would become a unprofitable attack vector.  Status: Not verified.  Verification: Not done, yet.   ", "html_url": "https://leastauthority.com/melonport_security_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue E: Reputation of module authors", "body": "  Reported: 14/12/2017  Synopsis: A different address is used to publish each module, making it difficult to acquire reputation as a module developer. The lack of a robust identity for module authors lowers the bar for impersonation attacks.  Impact: It is harder for fund managers to know whether they should trust a given module, which may lead them to using a vulnerable or malicious module.  Preconditions: Overwhelmed with choice, a fund manager chooses a module from a developer they recognise, but actually an attacker has made a malicious module that appears to be by someone else.  Feasibility: As with Issue C, feasibility depends greatly on the user interface. If there is not a reliable way to identify the author of a module, this attack is more feasible.  Technical Details: It is actually possible to publish multiple modules as the same address, but a map type is used to point from the publish address to the last module published, which implies that the module developer has only one module. This was done to avoid loops and module authors should just use a separate identity per module. This property is not actually used in another other Solidity code in the protocol repo, so it must be assumed that its used by the user interface.  In the mitigation of Issue B storing the Git commit hash and GitHub repo was implemented. This is a good move, but if there isnt a more robust way to identify the author of a module, a link back to this repo will probably end up in the UI and managers shopping for modules will click it. A link from a reputable GitHub repo should not be considered as positive proof of the reputation of the commit, since only the head of the master branch is really expected to be correct. An attacker could get a malicious commit onto a good repo by making a pull request that fixed a legitimate problem (or maybe just typo) but across several commits. In the malicious commit they would add a backdoor, but then in a good commit theyd remove it. When the maintainer evaluates the pull request they would not look at every individual commit, but at the difference between the master branch and all commits combined.  Remediation: Allow and encourage module authors to publish under from the same address consistently, or some way they can cryptographically sign their modules. Instead of tracking the last module published by an address, just have a list of modules which is iterated over when the UI reads from the contract state. Although iteration is slow, its not actually used inside the contracts (just the UI) so gas cost is not a concern.  Status: Not addressed.  Verification: Not done, yet.  ", "html_url": "https://leastauthority.com/melonport_security_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: [Plugin Beta] SES Realm Creation Enables the Error Stack", "body": "   Location   app/scripts/controllers/plugins.js   Synopsis   The creation of the SES root realm enables passthrough of the error stack.   Impact   In the event of a thrown exception, the stack trace from the sandboxed realm is leaked and could  potentially reveal information that was intended to be private.   Security Audit Report | MetaMask Plugin System + LavaMoat 4 March 2020  Least Authority TFA GmbH   4   This audit makes no statements or warranties and is for discussion purposes only.        Preconditions   The  errorStackMode  option is set to  allow .   Remediation   Disable the  errorStackMode  option or only enable it when MetaMask is known to be running in a  testing environment.   Status   There is a comment in the codebase to disable the error stack for production, however, the code currently  still has this enabled . The MetaMask team has stated their intention to make the error stack enabled by  an environment variable prior to pushing the code to production.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: [Plugin Beta] Restricted Method  submitPassword", "body": "    Location   app/scripts/controllers/permissions/restrictedMethods.js   Synopsis   The method  submitPassword  is restricted and noted in the code as needing to be removed for  production. There are still references to this method throughout other parts of the code indicating it may  still be exposed to plugins.   Impact   If granted to a plugin, it would be able to potentially impersonate MetaMask and ask the user to unlock  their wallet to intercept the users password.   Preconditions   The method is exposed to plugins.   Remediation   Ensure that the  submitPassword  method is not usable or grantable to plugins.   Status   The inclusion of the method  has not been removed , however, the MetaMask team has stated their  intention to remove it prior to pushing the code to production.   Verification   Unresolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: [Plugin Beta] Method  getState  Returns Potentially Sensitive Data", "body": "   Location   app/scripts/controllers/permissions/restrictedMethods.js   Security Audit Report | MetaMask Plugin System + LavaMoat 4 March 2020  Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.          Synopsis   The method  getState  returns the entire wallet state in a JSON representation, revealing potentially  sensitive information. It is noted in the code that it should be removed for production, however there are  still references to it.   Impact   If granted to a plugin, it would allow the plugin to view MetaMasks internal state which may hold sensitive  information that was not explicitly granted to the plugin.   Preconditions   The method is exposed to plugins.   Remediation   Ensure that the  getState  method is not usable or grantable to plugins.   Status   The inclusion of the method has  not been removed , however, the MetaMask team has stated their  intention to do so, as well as include tests around the functionality prior to pushing the code to  production.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: [Plugin Beta] Plugin State is Part of Main State", "body": "   Location   app/scripts/controllers/permissions/restrictedMethods.js   Synopsis   The method  updatePluginState  can be used to manipulate the application state.   Impact   Plugins may be able to take advantage of the shared state storage in order to manipulate other plugins or  the main extensions state.   Technical Details   More information and related issues:   https://github.com/MetaMask/metamask-snaps-beta/issues/88   https://github.com/MetaMask/metamask-extension/issues/7311   Remediation   Separate the state storage of plugins and the extension. Additional details and discussion is tracked in  the links included in the technical details section.   Status   Inclusion of the method  has not been removed . The MetaMask team has stated their intention to separate  the plugin state from the main state and verify that Starkware will not use too much storage prior to  pushing the code to production.   Security Audit Report | MetaMask Plugin System + LavaMoat 4 March 2020  Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.        Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: [Plugin Beta] Bypass SES by Modifying  global.process.env", "body": "  Properties   Location   app/scripts/controllers/plugins.js   Synopsis   It is possible for the variables  process.env.IN_TEST === 'true'  and  process.env.METAMASK_ENV  to be modified to bypass loading SES.   Impact   Plugins will no longer be executed within a sandbox and dependencies are no longer validated.   Preconditions   Check if  global.process.env.IN_TEST.   Technical Details   If a content script sets either  process.env.IN_TEST === 'true'  or  process.env.METAMASK_ENV  === 'test',  then SES will not be enabled.   Remediation   Use  Object.freeze(process.env).   Status   The  IN_TEST  global variable  condition is still present . The MetaMask team has stated their intention to  address the issue prior to pushing the code to production.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: [Plugin Beta]  opts[requiredField]  Will Return  true  if the", "body": "  Property is Declared but  undefined   Location   app/scripts/controllers/assets.js   Synopsis   Checking the  opts[requiredField]  will return  true  if the property is declared but  undefined .   Impact   Improperly validated actions can cause null reference exceptions and similar issues because  {foo:undefined}  will pass the check for  'foo' in bar  but not  typeof bar[foo] !==  'undefined'  or even just  !!bar[foo].   Security Audit Report | MetaMask Plugin System + LavaMoat 4 March 2020  Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.          Preconditions   `(foo in bar)`  returns true if  `bar[foo] === undefined` .   Remediation   Instead of  (!(requiredField in opts))  use  (typeof opts[requiredField] ===  'undefined') , as well as adding more sophisticated validation for the specific fields.   Status   The code in question has been removed or relocated, however, the  issue still exists elsewhere .   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: [LavaMoat] Prevent access to __ proto __ from  deepGet", "body": "   Location   https://github.com/LeastAuthority/lavamoat-browserify/blob/master/src/makeGetEndowmentsForConfi g.js#L60-L73    Synopsis   The  deepGet  method looks up user provided paths in the configuration object before it's actually running  inside of SES.    Impact   Unpredictable behavior.   Remediation   It should use  Object.hasOwnProperty  before checking the result so that it behaves more predictably.   Status   MetaMask  implemented a different resolution  than what was recommended by our team. Instead of using  hasOwnProperty,  it throws an error if any key in the path is  __proto__ , which resolved the issue.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue H: [LavaMoat] Exported Factory Function Can Return Shared Object", "body": "   Synopsis   Factory functions return a shared object if modules are cached.   Impact   If a factory function returns a shared object, that object can be modified by the receiver. Lavamoat@3.0.0  protects against this by not caching modules, however, Lavamoat@>=3.0.1 does not. Caching modules is  needed to support circular references in the dependency graph.   Technical Details   Caching modules or not is a tricky design issue; caching was introduced to support recursive cyclic  dependencies (If A depends on B, but B then depends on A). Completely removing caching would prevent   Security Audit Report | MetaMask Plugin System + LavaMoat 4 March 2020  Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.          shared accesses, if B and C depend on A, B gets Ab and C gets Ac and Ab !== Ac. It also means that  instanceof  checks would not work for comparing Ab with Ac. If a module is a subject of a cyclic  dependency, then it needs to be cached. Code to reproduce is available here:  https://gist.github.com/dominictarr/740ed01c63174ec1d932cca98f51c684   Remediation   If caching was disabled by default, it could be enabled only when cyclic dependencies are used.  Additionally, modules developers should be encouraged to  Object.freeze  their prototypes.   Another possibility that could avoid the need for configuration would be to pass a cache to the module  loader, such that a module had a cache of only its parent modules. If A, B and C require D, they all get their  own versions of D, but if X requires Y which requires X, Y gets the same X.   It is strongly recommended that module authors avoid cyclic dependencies. Having a helpful error on  loading a cyclic dependency is a better default behavior for LavaMoat.    Status   MetaMask has noted that this is an area of ongoing research in order to identify the best strategy to  mitigate this issue.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue I: [LavaMoat] Code Injection via Label in  wrapWithReturnCjsExports", "body": "   Location   src/generatePrelude.js   Synopsis   A module could bust out of the wrapper if they put a new line and JavaScript code into a file name. The  name is inserted into a line comment. If the file name contains a new line (which is allowable under unix),  the label will expand outside of the line comment and the next line will be actual runnable code, and will  see a different scope for module and exports as a result.   Impact   Modules could break out of the sandbox and run arbitrary code.   Remediation   Possible fixes:    JSON.stringify(label) new lines will be escaped   Remove the label altogether   It is possible that something else in the browserify system disallows unusual file names, but ensuring that  browserify never makes those changes is not as simple as sanitizing the name.   Status   The  wrapWithReturnCjsExports  function was modified  so that labels with newline characters will  cause it to throw an exception.   Security Audit Report | MetaMask Plugin System + LavaMoat 4 March 2020  Least Authority TFA GmbH   9   This audit makes no statements or warranties and is for discussion purposes only.        Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue J: [LavaMoat] Child Dependencies Can Access a Parent Modules", "body": "  Exports Before Harden is Applied   Synopsis   Agorics harden function recursively traverses a module and applies  Object.freeze  and wraps  functions so that another module cannot modify that object. However, harden is called  after  the module  returns, but any child modules are called  before  the module returns, thus child modules that have cyclic  dependencies on the parent have access to the parents exports before harden is called. See  Issue H .   Impact   Child modules that explicitly access a parent module could modify it.   Mitigation   Recursive dependencies should be avoided. Unfortunately, common JavaScript style module systems  currently just support cyclic dependencies silently.   Remediation   Require an explicit permission to get a cyclic reference to a parent module.   Status   MetaMask has noted that this is an area of ongoing research in order to identify the best strategy to  mitigate this issue.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-MetaMask-Plugin-System-LavaMoat-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Updates between Non-zero Allowances Can Result in Exploits", "body": "  Location  solidity/contracts/bank/Bank.sol#L122-L124  Synopsis  The process by which a user updates allowances from non-zero to non-zero can be susceptible to exploits.  When user A approves the transfer of N tokens to user B, and user A updates the allowance to M using the approve function, user B can deploy the approve transaction in the mempool and take M+N tokens by transferring N tokens just before the second approval with a higher gas price, and transferring M tokens after the second approval.  Impact  In this case, this issue could result in User B stealing User As M tokens.  Remediation  We recommend that the Keep Network team prevent updates between non-zero allowances. The user planning to update the approval from non-zero to non-zero must set the allowance to zero rst. As a result, the user can detect if the allowance was used by the approved user before the new approval. For example:  function approveBalance(address spender, uint256 amount) external {  require(!((amount!= 0) && (allowance[msg.sender][_spender] != 0)));  _approveBalance(msg.sender, spender, amount);  }  Security Audit Report | tBTC Bridge v2 | Keep Network 29 September 2022 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Keep Network team has added the require function as suggested to prevent the exploit.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_KeepNetwork_tBTC_Bridge_v2_Updated_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Bitcoin SPV Merkle Proofs Can Be Faked", "body": "  Location  Keep-Network-Bitcoin-Spv  Synopsis  Issue #192 in the summa-tx/bitcoin-spv repository provides a good summary of the Issue. An attacker can create a valid SPV proof out of a fake transaction. The attacker could use this SPV proof during the deposit ow to trick the Bridge into minting tokens that they could then withdraw.  Impact  If an attacker is able to fake an SPV transaction deposit, then the Bridge could be tricked into minting an unbacked balance of new tokens.  Preconditions  The attacker must successfully brute-force a hash and then use it in an SPV proof. Additionally, the tBTC Bridge v2 must be using a version of bitcoin-spv that does not check for the malformed Merkle proof that this attack uses.  Feasibility  This attack would be quite expensive upfront, requiring an estimated several million USD to carry out \u2014 depending on current market prices. Additionally, the hardware requirements would be substantial, likely requiring state-of-the-art miners capable of brute-forcing the necessary hashes in a reasonable time frame. However, depending on the price of Bitcoin, and as the Keep Network and its average wallet sizes grow, there will be a point where this attack will become protable after the initial costs.  Technical Details  Simple payment verication relies on Merkle proofs created with the previous transactions hash included to verify provenance. The problem is that bitcoin does not differentiate between inner nodes and leaf nodes in these proofs. As a result, a malicious actor can create a transaction with a brute-forced inner node in a Merkle proof that matches the expected values of another arbitrarily selected valid transaction. This requires brute-forcing a total of 72-bits of address space in order to compute the necessary bytes to make the constructed proof match. With this Merkle tree available, the attacker can submit a transaction with an arbitrary amount of Bitcoin to a victim SPV wallet. The transaction would be seen as a valid proof and the tBTC Bridge v2 would trigger a deposit, eventually minting tokens at an equal proportion to the amount in the malicious transaction. The attacker would then trigger a redemption process as soon as possible and retrieve a balance that they never actually owned.  Remediation  We can recommend two mitigations for this issue: A quick solution can be achieved by checking that every 64-bit node in the Merkle proof is not a valid transaction and either discarding it or further validating it with the knowledge that it is suspicious. Another more expensive approach is to send a Merkle proof of  Security Audit Report | tBTC Bridge v2 | Keep Network 29 September 2022 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   the coinbase transaction, along with the SPV proofs for the transaction, which would add sucient complexity to the address space necessary to brute-force to make this attack infeasible.  Status  The Keep Network team has implemented the validation and added tests to mitigate and prevent this attack.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_KeepNetwork_tBTC_Bridge_v2_Updated_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: _updateIntegrationProtectionStatus Does Not Check Whether", "body": " Integration Is Pre-registered  Location  contracts/Cube3GateKeeper.sol#LL60C14-L60C48  Synopsis  The _updateIntegrationProtectionStatus function does not check if the integration is preRegistered.  Impact  _updateIntegrationProtectionStatus can update the integration status that is not pre-registered through the protocol.  Remediation  We recommend adding checks to verify that a given integration is pre-registered with the protocol.  Status  The Cube3 team has added two different statuses for the integration state, which are checked by the functions preRegisterAsIntegration and complete2StepIntegrationRegistration to ensure that the integration is registered with the protocol before its authorized statuses are updated through the function _updateIngrationProtectionStatus.  Security Audit Report | Smart Contracts | Cube3 9 October 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/cube3_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Incorrect Parameter Passed in updateIntegrationProtectionStatus", "body": "  Location  contracts/Cube3RouterLogic.sol#L275  contracts/Cube3RouterLogic.sol#L286  Synopsis  The _updateIntegrationProtectionStatus function expects proxy as the rst parameter and implementation as the second. However, in the functions bypassIntegrationProtectionStatus and revokeIntegrationProtectionStatus, the rst parameter is passed as implementation and the second as proxy.  Impact  The mapping _integrationProtectionStatus function will not be updated as intended. Additionally, it will emit an event with incorrect parameters, which can affect off-chain services.  Remediation  We recommend passing the correct parameter to _updateIntegrationProtectionStatus.  Status  The Cube3 team acknowledged the nding but stated that it is no longer relevant. Therefore, we consider this Issue resolved.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/cube3_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Incorrect Cutting of Cube Secure Payload From Message Data", "body": "  Location  contracts/Cube3Integration.sol#L83-L88  Synopsis  cube3SecurePayload is intended to be added as the last parameter in any Cube3-protected function. In order to extract the calldata of the function being called, cube3SecurePayload should be cut from msg.data. In the current implementation, it is assumed that the structure of cube3SecurePayload in the msg.data is as follows:  payload offset <32> | payload length <32> | payload  Therefore, to cut cube3SecurePayload, it is assumed that 64 additional bytes (offset <32> + length <32>) should be cut from msg.data as well as payload. However, if there are other dynamic parameters preceding cube3SecurePayload, the payload offset will not precede the length but may be encoded elsewhere in msg.data. Hence, incorrect data will be cut from the end of msg.data.  Impact  An incorrectly cut cube3SecurePayload would result in unintended behavior.  Security Audit Report | Smart Contracts | Cube3 9 October 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  This Issue is likely if dynamic parameters precede cube3SecurePayload.  Remediation  We recommend changing the implementation to take into consideration the dynamic parameters preceding the cube3SecurePayload.  Status  The Cube3 team has resolved this Issue by cutting only 32 additional bytes (i.e. the length) from the end of msg.data, which will always precede the actual payload. Additionally, the team has modied the generation of payload off-chain to match the implemented x on-chain.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/cube3_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue D: An Already Protected Integration Can Be Re-Registered", "body": "  Location  contracts/Cube3GateKeeper.sol#L122-L125  Synopsis  The function preRegisterAsIntegration can pre-register an already-registered (protected) integration.  Impact  Re-registering a protected integration is unintended behavior, which might result in replacing an already protected integration.  Remediation  We recommend checking if an integration is already registered before pre-registering it to avoid replacing an already protected integration.  Status  The Cube3 team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/cube3_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Security of Truncated SHA256 in Address Generation", "body": "  Location  liquidity/keeper/liquidity_pool.go#L883  Synopsis  Each Tendermint Liquidity Pool requires a unique reserve account address to keep track of the funds deposited or withdrawn from the pool. At present, a SHA-256 hash function is used to ensure that different pools have unique reserve account addresses.  For example, for a pool with tokens tokenX and tokenY, and pool identier poolId, the reserve account address is computed as:  sdk.AccAddressFromHex(SHA256(denomX/denomY/poolId)[:40])  The SHA-256 hash output is truncated to 20 bytes (or 40   characters) before the account address is generated. This effectively reduces the security provided by the SHA-256 hashing algorithm. Although the address generation requires 20 bytes as the input, we recommend analyzing the security implications of using truncated SHA-256 outputs.  Security Audit Report | Cosmos SDK Liquidity Module | All in Bits 24 June 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Impact  It is possible for an attacker to identify input strings to the SHA-256 hash function, such that the rst 20 bytes of the output matches. The result is that two different liquidity pools, both possibly created by the attacker, could have the same reserve account address. This would directly impact the deposit, withdraw, and swap functionalities of these two pools in the Liquidity Module. The truncated SHA-256 is widely used in the Cosmos ecosystem for deterministic address generation, however, in the particular case of the Liquidity Module, the negative security implications of using truncated SHA-256 exceed the benet of simple address generation.  Remediation  80  While the likelihood of an attack is theoretically very small ( computations), we recommend conducting a thorough analysis of the security of the truncated SHA-256 hash function. The NIST provides guidelines on secure use of truncation in approved hash functions, such as SHA-256. We also recommend exploring alternative hash functions, such as Keccak, which allow variable output digest size. For example, we suggest exploring a combination of SHA-256 with RIPEMD-160 hash functions, which could provide better preimage and collision resistance. The SHA-256 and RIPEMD-160 combination is used in the generation of P2PKH addresses in Bitcoin [V17].  2  Status  The Tendermint team has responded that the SHA-256 truncation problem is not specic to the Liquidity Module and, as a result, they will not be making any changes. Given that our primary aim was to caution them about this, we consider the decision to leave the issue unresolved at the time of this verication to be acceptable.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tendermint_Cosmos_SDK_Liquidity_Module_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Linter Reports Errors", "body": "  Location  tendermint-liquidity/issues/2  Synopsis  There is a lint Make target which uses golangci-lint, an industry standard linting tool for Go. We found that the linter currently reports multiple errors. The Tendermint team has indicated that the linter results are not currently considered in their CI pipeline, however, they stated that they intend to remediate that.  Impact  golangci-lint runs a myriad of checks for common issues, which could have serious performance or critical security implications, depending on the specic error. We suggest referring to the linter documentation for additional information.  Feasibility  There is an increased risk that unlinted code is deployed, resulting from the absence of an important code step during the development process.  Security Audit Report | Cosmos SDK Liquidity Module | All in Bits 24 June 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  The lint Make target calls golangci-lint without a conguration le, which runs the default linters with their respective default congurations. However, it is not included in the GitHub Actions workow, which the Tendermint team is currently using for CI/CD.  Mitigation  We recommend the Tendermint team consider adding review requirements to the development process (e.g. two unique approvals to merge each PR). Until the linter is included in the CI pipeline, review should include running the linter and ensuring no errors are reported.  Remediation  We recommend the Tendermint team Include the linter in the CI pipeline and review all errors for potential security vulnerabilities.  Status  The Tendermint team has included the linter in the CI pipeline and xed all outstanding linter errors.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tendermint_Cosmos_SDK_Liquidity_Module_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Hashi System May Conrm Messages Without Meeting Threshold", "body": " of Adaptors  Location  contracts/ownable/ShuSo.sol#L77  contracts/ownable/ShuSo.sol#L103  contracts/ownable/ShuSo.sol#L216  Synopsis  ShuSho provides the functionality to add or remove adapters and reporters, and update the threshold. However, there is currently no way to do so in an atomic transaction. If a Hashi user sends a transaction concurrently with an administrator updating adapters, reports, and the threshold, the users transaction could interact with Hashi while it is in an inconsistent state.  Impact  If a Hashi administrator were to add new adaptors and reporters, and increase the threshold to suit the new conguration, a users concurrent transaction could be sandwiched between the administrators transactions, resulting in the users transaction running on Hashi while it has an inconsistently high or low  Security Audit Report | Hashi | Gnosis 18 July 2024 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   threshold. This could either result in hashes being conrmed when they should not have been, or not being conrmed when they should, depending on the order in which the concurrent transactions are executed on the EVM.  Preconditions  This Issue occurs when an administrator updates the Hashi conguration concurrently with a user calling the getHash function.  Feasibility  This scenario is somewhat likely to occur in the event of a Hashi conguration update, presuming that calls to the getHash function occur regularly.  Remediation  We suggest extending ShuSho.sol, such that adaptors, reportors, and the threshold can be updated atomically.  Status  The Gnosis team has provided a solution for the bridge tokens; however, the Issue still persists for the Hashi contracts.The Gnosis team has stated that ShuSho will not be used in the gnosis bridge migration  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/gnosis-hashi-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Gnosis Canonical Bridges May Allow Conrmation of Messages", "body": " Without Waiting for Agreement From a Sensible Quorum of Adaptors  Location  contracts/upgradeable_contracts/HashiManager.sol  Synopsis  This Issue relates to the same scenario reported in Issue A, but concerns HashiManager.sol in the tokenbridge-contracts. HashiManager provides the functionality to update adapters, reporters, and the threshold. However, there is no functionality to do so in an atomic transaction. If a user of Gnosis canonical bridges had their transaction executed on the EVM as the adaptors are updated and when the threshold is set, their transaction would interact with the bridge while Hashi is in an inconsistent state.  Impact  A message could be passed without a reasonable amount of adaptor conrmations, or a message could be denied from being passed despite a reasonable threshold of adaptors.  Preconditions  This Issue can occur when a user interacts with Gnosis canonical bridges concurrently with an administrator updating the Hashi conguration.  Feasibility  Presuming that the Gnosis canonical bridges are used regularly, it is likely that any time HashiManager.sol adaptors, reporters, or the threshold are updated, some user transactions may be executed on an inconsistently congured bridge.  Security Audit Report | Hashi | Gnosis 18 July 2024 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We suggest extending HashiManager.sol, such that adaptors, reporters, and the threshold can be congured in an atomic transaction.  Status  The Gnosis team has added the function setReportersAdaptersAndThreshold, which resolves the Issue. Additionally, the team has also added a new functionality with which a message that has been sent already can be resubmitted.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/gnosis-hashi-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Native Tokens May Be Locked in Hashi Contracts Indenitely", "body": "  Location  evm/contracts/Yaho.sol  evm/contracts/ownable/GiriGiriBashi.sol  Synopsis  Multiple functions within the Hashi codebase are payable. Due to miscongured transactions by a user, or subtle bugs in the current implementations, native tokens could end up locked in the Hashi contracts. Without the presence of a backup withdrawal mechanism, these funds could remain locked in the contracts indenitely.  Impact  A user interacting with the Hashi payable functions could have their native tokens locked in the contract.  Preconditions  A user would have to unwittingly send native tokens to a payable function.  Feasibility  Not likely to occur.  Remediation  For contracts with payable functions, we recommend implementing a generic withdrawal mechanism with appropriate access control to facilitate the withdrawal of funds in the event of mistakes or failures.  Status  The Gnosis team has acknowledged the issue. However, the issue remains unresolved at the time of verication.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/gnosis-hashi-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue D: HashiManger Can Be Congured With a Threshold of 0", "body": "  Location  contracts/upgradeable_contracts/HashiManager.sol#L23  Security Audit Report | Hashi | Gnosis 18 July 2024 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  In the function setReportersAdaptersAndThreshold, it is possible to pass an inappropriate threshold, such as 0 or 1.  Impact  An overly low threshold could lead to messages being conrmed without reaching a reasonable quorum of adaptor conrmations.  Preconditions  An administrator of the Gnosis canonical bridges would have to unwittingly pass an inappropriate value when setting the threshold.  Feasibility  As the incorrect conguration would be due to an unintentional action performed by an administrator, this Issue is not considered likely to occur. However, the risk scales with the frequency of conguration updates.  Technical Details  function setReportersAdaptersAndThreshold(address[] reporters, address[]  adapters, uint256 threshold)  external  onlyOwner  {  }  // missing threshold check  _setArray(N_REPORTERS, \"reporters\", reporters);  _setArray(N_ADAPTERS, \"adapters\", adapters);  uintStorage[THRESHOLD] = threshold;  Remediation  Upon setting the threshold, we recommend checking that the supplied parameter is a reasonable value. For example, contracts/ownable/GiriGiriBashi.sol#L219 checks that the threshold is greater than 50% of the count of adapters.  Status  The Gnosis team has acknowledged the issue. However, the issue remains unresolved at the time of verication.  Verication  Unresolved.  Security Audit Report | Hashi | Gnosis 18 July 2024 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/gnosis-hashi-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Lack of Generic Multisig Tests", "body": "   Location   /tezos-btc/contracts/MultisigGeneric.tz   /tezos-btc/src/Lorentz/Contracts/TZBTC/MultiSig.hs   Synopsis   Tests that confirm the intended functionality of the generic multisig contract were not present in the code.  Since there are no tests on the multisig contract itself, it is assumed that tests exist elsewhere. It is  difficult to understand the functionality of the multisig contract without proper tests.   Impact   The multisig contract will be the controlling address of the token and unexpected behavior can cause loss  of control of the token.   Mitigation   We suggest writing proper tests on the multisig contract.   Status   Multisig tests for various cases have been added, located at  test/Test/MultiSig.hs . There are a few  incorrect comments due to copy/paste from a previous test (Use Alice's public key but bob's secret.) at  Line 168, 206, 246.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Tezos-TzBTC-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Generic Multisig May Update Owner Set Improperly", "body": "   Location   /tezos-btc/contracts/MultisigGeneric.tz   Security Audit Report | TzBTC | Tezos Foundation 13 March 2020 by Least Authority TFA GmbH   4   This audit makes no statements or warranties and is for discussion purposes only.          Synopsis   Change_keys  allows for changing control of the multisig contract by changing the owner keys. The  /tzbtc/README.md points to a multisig contract with functionality to update the signing accounts  existing on the multisig where there could be issues with locking the contracts ownership out at the  multisig level.   Impact   Control will be lost if there is not a proper modifier to limit the ability of ownership change to prevent the  case where there are no owners of the multisig.   Preconditions   An improper call to update the owner set to a null set or a set below the threshold of necessary signers to  execute a block of code. It appears that the update function simply replaces state with the incoming  transaction. If a null set of keys is updated to that state the contract and everything it owns will render  useless.   Feasibility   This mistake could happen easily if no checks are provided.   Remediation   Consider adding checks to the  change_keys  function that will not allow for a null set or lower than  required threshold set of owners to be introduced.   Status   A new command called  deployMultisigContract  has been added and a corresponding eponymous  function in  src/Client/IO.hs  checks whether the passed threshold is a non-zero value and is lower  than or equal to the list of keys.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Tezos-TzBTC-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Multisig Parameters Could Be Improperly Constructed", "body": "   Location   /tezos-btc/contracts/MultisigGeneric.tz   /tezos-btc/src/Lorentz/Contracts/TZBTC/MultiSig.hs   Synopsis   We did not identify any tests for the multisig wallet that could be used to control sensitive operations on  the token. If a generic multisig wallet is used, then signers may unknowingly process an unexpected  transaction.   Impact   The parameters may be improperly constructed before signing which could lead to signatures on  transactions that were not intended (i.e. an improper update address). If the multisig contract owns the  token, this could cause total loss of control.   Security Audit Report | TzBTC | Tezos Foundation 13 March 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.        Feasibility   The client provides packages and documentation about ways to execute human readable multisig  transactions for each multisig function that the general contract wraps so that the likelihood of this  mistake happening is reduced.   Technical Details   The contract allows for the generic multisig contract to control execution of generic functions on the  contract system. The inputs to this multisig signing will be Michelson code snippets that are difficult to  read. We did not identify any client side tools that will help the signers understand the code that is being  proposed to the multisig wallet.   Mitigation   Consider using a  multisig wrapper contract  that only allows signing specific parameters.   Status   The generic multisig contract that allowed signers to act as a blockchain entity, executing arbitrary code,  has been replaced with a specific multisig contract that only executes what the wrapped contract  expects.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Tezos-TzBTC-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: TLS Private Key Is Not Zeroized", "body": "  Severity  Medium  Location  src/internal/tls.rs#L107  crates/lair_keystore_api/Cargo.toml#L23  Synopsis  An attacker that is able to access memory (e.g., accessing core dump and exploiting vulnerabilities such as Heartbleed) may be able to retrieve non-zeroized TLS private keys. This is possible due to two reasons:   rcgen is used without the zeroize feature; and  Sodokens buffer is created without new_mem_locked.  Impact  The leakage of cryptographic keys could result in the loss of security properties, such as condentiality and privacy.  Preconditions An attacker must be able to read memory regions that contain sensitive data.  Mitigation  We recommend enabling the zeroize feature for the rcgen crate and using new_mem_locked when creating Sodokens buffers.  Security Audit Report | Lair Keystore | Holo Ltd 23 September 2022 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Holochain team has implemented suggestions to zeroize the TLS private key.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/Least_Authority_Holo_Ltd_Lair_Keystore_Final_Audit_%20Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Incorrect Implementation of Zeroing Sensitive Data", "body": "  Location  Examples (non-exhaustive):  src/utilities.rs#L106-L109  src/olm/session/chain_key.rs#L33-L36  src/cipher/key.rs#L54-L60  src/megolm/inbound_group_session.rs#L221  src/sas.rs#L289  src/olm/account/mod.rs#L326  Synopsis  An attacker that is able to access memory (e.g. accessing core dump, using debuggers, and exploiting vulnerabilities such as Heartbleed) may be able to retrieve non-zeroized sensitive information in cleartext, including, but not limited to, private keys, chain keys, and AES keys.  While the zeroize crate is currently used for the main data structures of the library, zeroization is missing in a number of locations for arrays or is ineffective for types with value semantics.  Impact  The leakage of cryptographic keys could result in loss of security properties such as condentiality and privacy.  Security Audit Report | vodozemac | Matrix 30 March 2022 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  An attacker must be able to read memory regions that contain sensitive data.  Mitigation  We recommend rst identifying all instances where sensitive data must be zeroized, and then verifying that the data in each instance is appropriately zeroized. In addition, we recommend that attention be paid to peculiarities in several types in Rust, particularly to stack-allocated values, which require appropriate methods for zeroing data.  Status  The Matrix team has addressed the issue by adding Box wrappers as well as by putting secrets behind a Box to minimize the number of copying.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Weak Input Validation in bytes_raw Function", "body": "  Location  src/sas.rs#L247  Synopsis  The function bytes_raw will panic if the value of count argument is more than USIZE * 255.  Impact  This could result in a DoS attack.  Preconditions  An attacker must be able to set count to a value more than USIZE * 255.  Mitigation  We recommend propagating the error from the HKDFs expand function to the caller of the bytes_raw function.  Status  The Matrix team has propagated the error from HKDFs expand function.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Erroneous key_id Calculation in from_libolm_pickle if Number of", "body": " One-Time Keys is Zero  Location  src/olm/account/mod.rs#L398  Synopsis  An implementation error in the function from_libolm_pickle exists such that a missing assertion could cause the system to behave unexpectedly. In particular, a legacy pickle that contains zero key_ids  Security Audit Report | vodozemac | Matrix 30 March 2022 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   is decrypted using from_libolm_pickle. In the case where there are no one-time keys in a pickle, the key_id value will be 1 instead of 0.  Impact  After deserializing an input libolm pickle, an incorrect value of key_id is returned in the one_time_keys type. This could impact the logic of the system and cause unintended behavior leading to security vulnerabilities.  Mitigation  We recommend implementing an assertion that key_id must be equal to 0 if there are no one-time keys in the libolm pickle.  Status  The Matrix team has added an assertion to check if the number of one-time keys in the pickle is zero and increment the key_id only if the number of the keys is not zero.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Potential Overow of OneTimeKeys.key_id", "body": "  Location  src/olm/account/one_time_keys.rs#L81  Synopsis  The self.key_id variable of the u64 type is used to store and calculate the identication numbers of one-time-keys. While generating new one-time keys, each next identier is calculated as self.key_id += 1. This operation could potentially cause an overow.  Impact  An overow would most likely impact the logic of the system or cause a panic, which could lead to a denial of service.  Preconditions  To be successful, this would require the misuse of the generate function or a malicious initial key_id set by the untrusted server.  Mitigation  We recommend implementing appropriate safeguards, such as the wrapping addition.  Status  The Matrix team has added the wrapping addition.  Verication  Resolved.  Security Audit Report | vodozemac | Matrix 30 March 2022 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Potential Integer Underow in advance in megolm/ratchet.rs", "body": "  Location  src/megolm/ratchet.rs#L131  Synopsis  If h == 0 at the starting point of the loop, then unsigned i will be underowed. This could lead to attempts to access unallocated memory.  Impact  An underow or overow issue would most likely impact the logic of the system or cause a panic, which could lead to a denial of service.  Preconditions  Any set of circumstances where self.counter & mask == 0 would result in h == 0.  Mitigation  We recommend using the wrapping addition and reimplementing the logic of the loop such that the only allocated parts of memory are accessed.  Status  The Matrix team has reimplemented the loop logic as suggested.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Potential Integer Underow in advance_to in megolm/ratchet.rs", "body": "  Location  src/megolm/ratchet.rs#L194  Synopsis  In the current implementation, unsigned k will be underowed if the value of the loop variable j is equal to 0, which could lead to attempts to access unallocated memory.  Impact  An overow would most likely affect the logic of the system or cause a panic, which could cause a denial of service.  Preconditions  The value of variable j is equal to 0.  Mitigation  We recommend using wrapping subtraction and reimplementing the logic of the loop such that the only allocated parts of memory are accessed.  Status  The Matrix team has reimplemented the loop logic as suggested.  Security Audit Report | vodozemac | Matrix 30 March 2022 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Invalid Inbound Session can be Created Causing Unused", "body": " One-Time Keys Removal  Location  src/olm/account/mod.rs#L226-L228  src/olm/account/mod.rs#L207  Synopsis  In the function create_inbound_session, an invalid inbound session can be created by sending a pre-key message with an invalid ciphertext. Since authentication of the ciphertext inside the pre-key message is not performed, an attacker can create an invalid inbound session with the victims one-time key, which results in the removal of the unused one-time key after the sessions creation.  Impact  If the victims one-time key is used by an attacker thus removing it, an unsuspecting user using the same one-time key will not be able to communicate with the victim (e.g. create an inbound session).  Preconditions  An attacker creates a session with a victims one-time key and sends a pre-key message containing an invalid encrypted ciphertext.  Technical Details  In create_inbound_session, the receiving party receives a pre-key message, in which it looks for the private part of its one-time key and decodes the remote one-time key, the remote identity key, from which together with the private part of its one-time key derives a shared secret which computes the root key and chain key. Finally, the one-time key is removed.  However, the ciphertext in the pre-key message is not decrypted in accordance with the Olm specication. Consequently, an attacker can create a pre-key message with an invalid ciphertext (e.g. encrypted with an incorrect message key derived from an incorrect chain key).  This would allow the receiving party to create an invalid inbound session without correctly decrypting the ciphertext (derive the message key from the chain key, and correctly decrypt the ciphertext) and the one-time key would be removed unused. As a result, an unsuspecting user using the same one-time key will not be able to communicate (create an inbound session) with the victim because the one-time key is already removed.  Remediation  We recommend decrypting the ciphertext in the pre-key message when creating an inbound session, and only removing the one-time key if the ciphertext is decrypted successfully.  Status  The Matrix team has resolved the issue by decrypting the pre-key message at session creation and subsequently removing the one-time key that was used to create the inbound session.  Security Audit Report | vodozemac | Matrix 30 March 2022 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue H: Cannot Permanently and Explicitly Remove Old Ratchet State in", "body": " the Megolm Inbound Group Session  Location  src/megolm/inbound_group_session.rs  Synopsis  In the Megolm implementation inbound group session, the initial ratchet value (InboundGroupSession::initial_ratchet) can be used to decrypt historical messages (e.g. received past the corresponding point of time). If this value is compromised, an attacker can decrypt past messages, which were encrypted by a key derived from the compromised or subsequent ratchet values, breaking the cryptographic principle of forward secrecy.  There are functions to export and import the InboundGroupSession at a given message index, but there is no explicit way to remove the old ratchet value in a session.  Impact  An attacker can decrypt past messages that were encrypted by a key derived from the compromised earliest ratchet value (initial_ratchet) or subsequent ratchet values.  Preconditions  An attacker captures the initial_ratchet in a Megolm inbound group session.  Remediation  We recommend implementing a permanent and explicit way to remove previous ratchet state values in the Megolm inbound group session. The user of the library should be able to choose to remove or advance the previous initial ratchet value up to a more recent value.  Status  The Matrix team has added a function, advance_to, in inbound group sessions to permanently advance the session ratchet value to the given index. This removes the ability to decrypt messages that were encrypted with a lower message index than what is given as the argument.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue I: Keys in Memory Not Secure Against Swap Access and", "body": " Side-Channel Attacks  Synopsis  If the attacker has access to the users swap space or can mount side-channel attacks, they may have access (usually unreliable) to the memory of arbitrary processes, including those making use of vodozemac. Since keys are not protected while in memory, this may compromise their security.  Security Audit Report | vodozemac | Matrix 30 March 2022 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   Impact  This could result in leakage of secret keys, including identity keys, ephemeral keys (i.e. one-time keys or pre-keys), ratchet keys, as well as encryption and authentication keys. This in turn would undermine the condentiality and authenticity properties of Olm and Megolm.  Preconditions  The attacker has access to the swap of a user or the machine and operating system (OS) of the user is susceptible to side-channel attacks that undermine process separation.  Feasibility  The attacker would have to nd the keys in the pieces of the memory extracted. A successful attack depends on the specic system and the amount of data to be extracted. The attack is not straightforward, but possible in many circumstances.  Technical Details  Swap refers to space on the SSD/HDD reserved to store data that resides in memory while it is not needed. On some systems, it is also used for keeping the memory contents during hibernation (also known as suspend-to-disk), which means that memory contents are written to disk, where an adversary may have access to it.  Side-channel attacks describe a wide range of attacks. In this context, we specically refer to attacks like Meltdown and Spectre and Rowhammer, which allow one process to access memory regions allocated to another process with moderate accuracy.  Mitigation  We recommend the Matrix team further employ the mitigations implemented by OpenSSH. Here, keys are encrypted while not in use, using a key derived from a 16kB buffer lled with random data, only decrypted when needed and immediately disposed afterwards (i.e. zeroized). This hinders attackers, because they not only need to acquire the keys, but also the 16kB pre-key region in order to decrypt them. Since the probability of a read error increases as the amount of read data grows, having to read signicantly more data effectively reduces the success probability of this class of attacks.  In addition, users of applications using vodozemac should ensure that the operating system they use employs all available mitigations against attacks from the Spectre and Meltdown families. Additionally, they should make sure that they either do not use swap at all, or congure their system such that it is encrypted.  Status  The Matrix team has acknowledged the suggested mitigation would provide enhanced security, however, they have stated they will not implement the mitigation until a future date.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue J: MAC Tag Truncated to Insufcient Length", "body": "  Location  src/cipher/mod.rs#L30-L39  Security Audit Report | vodozemac | Matrix 30 March 2022 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  In the vodozemac implementation, HMAC-SHA256 tags are truncated to 8 bytes (i.e. 64 bits). However, according to the HMAC specication, they may only be truncated to half of the length of the underlying hash (128 bits in this case). Thus, the current implementation violates the recommendations from the HMAC specication.  Impact  An insucient tag length weakens the authentication scheme, which increases the probability of successfully modifying a ciphertext.  Preconditions  The attacker must be able to impersonate a sender on the underlying insecure channel. In the Matrix setting, home servers are able to perform such attacks.  Feasibility  The probability of an attacker guessing a tag for which the verication succeeds is relatively high probability, compared to those in other cryptographic settings. However, an attacker only gets one guess per message, so a brute-force attack is not possible with just one message.  , which is a  2  \u221264  Technical Details  A MAC tag allows the receiver to verify that the received data comes from the intended receiver (assuming the two are the only parties with access to the key). If the MAC tag becomes shorter, it becomes easier to guess the tag for which the validation succeeds. Typically, in cryptographic operations the security target of about 128 bits is chosen, and most parts of the system do in fact achieve it.  The truncation of the MAC reduces the security target to only 64 bits, falling short of best practices.  Remediation  We recommend updating the code to truncate to not less than 16 bytes or not at all. We acknowledge that this would require a protocol change, which is not unilaterally possible by the Matrix team in order to maintain compatibility with the larger Matrix ecosystem.  Status  The Matrix team responded that while they agree that modern security targets should be met, the changes in truncation of the MAC are inherited from the libolm implementation and would require a coordinated effort on the Matrix Protocol level to ensure compatibility between implementations. Additionally, the Matrix team assesses the probability of an attack resulting from the truncation of a MAC to 8 bytes as low.  We agree with the assessment by the Matrix team and understand that a change of the Matrix Protocol would be required for remediation of this issue. Nonetheless, we recommend coordinating a protocol change within the Matrix ecosystem and updating the MAC truncation.  Verication  Unresolved.  Security Audit Report | vodozemac | Matrix 30 March 2022 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-Matrix_vodozemac_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Malicious Contract Can Authorize as tx-sender", "body": "  Location  Examples (non-exhaustive):  BNS-V2.clar#L293  BNS-V2.clar#L397  Security Audit Report | BNS-v2 | Trust Machines 30 August 2024 by Least Authority TFA GmbH  4  This audit makes no statements or warranties and is for discussion purposes only.   BNS-V2.clar#L427  Synopsis  If an authenticated role (such as a name owner) calls a third contract, that contract could call a method on the BNS-v2 contract, be authenticated as representing tx-sender, and transfer names or change settings.  Impact  There are many functions in the contract that contain a check for a tx-sender, including, for example, the owner of a name, and also the namespace-import role for a namespace. All manager roles are checked against contract-caller and are, hence, not vulnerable. Additionally, unless a user calls the malicious contract again, it will not be possible to perform any action that requires multiple blocks, such as registering a name and then transferring it. The most damaging action would be to steal (transfer) names that the tx-sender owns, but the easiest attack would be to steal stx by buying names that the attacker has listed. The attacker could also perform malicious actions using almost any method available in the contract.  Preconditions  To steal a name, the malicious contract would need to know what names a potential victim owns. This could be recorded in a data structure that the attacker updates. The malicious contract must be able to perform any action within the transaction; therefore, the information it needs would have to be precongured.  Feasibility  The attack is technically straightforward, but it does require the victim to interact with a malicious contract. The exploit requires a phishing attack, and an \u2018airdrop is a likely bait.  Technical Details  When running a function on a Clarity contract, two variables representing the caller are set. The tx-sender is the account that initiates the transaction, and contract-caller is the entity that calls this particular contract. When an account P calls a contract C directly, then tx-sender will be P, and contract-caller will also be P. But if account P calls a contract B, which then calls C, then C will have tx-sender P and contract-caller B. When checking for the manager role, BNS-v2 consistently checks whether the manager is equal to the contract-caller. But when checking the namespace-import or name owner, BNS-v2 generally checks if the owner is equal to the tx-sender or the contract-caller. This means that if the owner calls a malicious contract, and that contract subsequently calls BNS-v2, the call will be authorized as the initiator of the call, the tx-sender, enabling them to perform any action that can be done by a name owner or a namespace-import role (the manager role is not vulnerable to this, as it is checked against contract-caller consistently).  Users can set post-conditions that abort the transaction if unexpected transfers occur (see the Mitigation section below). However, some authorized methods do not involve token transfers but may enable future transfers. For example, if the user has a post-condition preventing any of their owned tokens from changing, a malicious contract that gets authorized via a tx-sender check could still call list-in-ustx and list an owned name for a very low price. The attacker would then be able to purchase that name quickly and list it for sale again at a much higher price. The user would then be obliged to either buy their own name back or abandon it.  Even if the user mitigates this Issue by correctly using post-conditions, the attacker still has some options. For example, in an attack on an owner, the attacker could still access list-in-ustx and update-zonefile-hash. If the attack was on the namespace-import rule, the attacker could perform name-revoke, namespace-update-price, as well as namespace-freeze-price.  Security Audit Report | BNS-v2 | Trust Machines 30 August 2024 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   However, our team noted that there is only a single namespace-import role per namespace, so there will be fewer potential victims. Moreover, since a user who creates a namespace is more invested in the system, they are also likely to be more cautious with regards to general security practices.  Mitigation  Stacks users can set post-conditions that will abort a transaction if an unexpected transfer occurred (or if an expected one did not occur). This can be used to prevent the most damaging attacks (such as an attacker transferring a users name/token); however, they cannot protect against methods that do not actually transfer tokens (as explained in the Technical Details section above).  Stacks users can also protect themselves by using a proxy contract that was the owner of their names, and that called BNS-v2 using the as-contract function. In this case, as-contract sets the contract address as tx-sender for the call. The proxy contract would therefore be hard coded to only call BNS-v2; hence, a third contract attack would be impossible.  Ideally, stacks users should never call an untrusted contract with the same account that owns their names, or should check whether any contract they wish to interact with calls other contracts. However, our team notes that it is not realistic to expect all users to devote the time necessary to understand all the nuances of a contract they wish to use. If a security issue can be remediated by a technical solution, doing so is highly recommended (see the following Remediation section).  Remediation  In order to authorize a role, we recommend that contract-caller be checked instead of tx-sender.  Status  The BNS-v2 contract no longer uses tx-sender.  Verication  Resolved.  Security Audit Report | BNS-v2 | Trust Machines 30 August 2024 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   About Least Authority  We believe that people have a fundamental right to privacy and that the use of secure solutions enables people to more freely use the Internet and other connected technologies. We provide security consulting services to help others make their solutions more resistant to unauthorized access to data and unintended manipulation of the system. We support teams from the design phase through the production launch and after.  The Least Authority team has skills for reviewing code in multiple Languages, such as C, C++, Python, Haskell, Rust, Node.js, Solidity, Go, JavaScript, ZoKrates, and circom, for common security vulnerabilities and specic attack vectors. The team has reviewed implementations of cryptographic protocols and distributed system architecture in cryptocurrency, blockchains, payments, smart contracts, zero-knowledge protocols, and consensus protocols. Additionally, the team can utilize various tools to scan code and networks and build custom tools as necessary.  Least Authority was formed in 2011 to create and further empower freedom-compatible technologies. We moved the company to Berlin in 2016 and continue to expand our efforts. We are an international team that believes we can have a signicant impact on the world by being transparent and open about the work we do.  For more information about our security consulting, please visit https://leastauthority.com/security-consulting/.  Our Methodology  We like to work with a transparent process and make our reviews a collaborative effort. The goals of our security audits are to improve the quality of systems we review and aim for sucient remediation to help protect users. The following is the methodology we use in our security audit process.  Manual Code Review  In manually reviewing all of the code, we look for any potential issues with code logic, error handling, protocol and header parsing, cryptographic errors, and random number generators. We also watch for areas where more defensive programming could reduce the risk of future mistakes and speed up future audits. Although our primary focus is on the in-scope code, we examine dependency code and behavior when it is relevant to a particular line of investigation.  Vulnerability Analysis Our audit techniques include manual code analysis, user interface interaction, and whitebox penetration testing. We look at the project's website to get a high level understanding of what functionality the software under review provides. We then meet with the developers to gain an appreciation of their vision of the software. We install and use the relevant software, exploring the user interactions and roles. As we do this, we brainstorm threat models and attack surfaces. We read design documentation, review other audit results, search for similar projects, examine source code dependencies, skim open issue tickets, and generally investigate details other than the implementation. We hypothesize what vulnerabilities may be present and possibly resulting in Issue entries, then for each, we follow the following Issue Investigation and Remediation process.  Security Audit Report | BNS-v2 | Trust Machines 30 August 2024 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Documenting Results We follow a conservative and transparent process for analyzing potential security vulnerabilities and seeing them through successful remediation. Whenever a potential issue is discovered, we immediately create an Issue entry for it in this document, even before having veried the feasibility and impact of the issue. This process is conservative because we document our suspicions early even if they are later shown to not represent exploitable vulnerabilities. We generally follow a process of rst documenting the suspicion with unresolved questions, then conrming the issue through code analysis, live experimentation, or automated tests. Code analysis is the most tentative, and we strive to provide test code, log captures, or screenshots demonstrating our conrmation. After this, we analyze the feasibility of an attack in a live system.  Suggested Solutions We search for immediate and comprehensive mitigations that live deployments can take, and nally, we suggest the requirements for remediation engineering for future releases. The mitigation and remediation recommendations should be scrutinized by the developers and deployment engineers, and successful mitigation and remediation is an ongoing collaborative process after we deliver our Initial Audit Report, and before we perform a verication review.  Before our report, including any details about our ndings and the solutions are shared, we like to work with your team to nd reasonable outcomes that can be addressed as soon as possible without an overly negative impact on pre-existing plans. Although the handling of issues must be done on a case-by-case basis, we always like to agree on a timeline for a resolution that balances the impact on the users and the needs of your project team.  Resolutions & Publishing Once the ndings are comprehensively addressed, we complete a verication review to assess that the issues and suggestions are suciently addressed. When this analysis is completed, we update the report and provide a Final Audit Report that can be published in whole. If there are critical unaddressed issues, we suggest the report not be published and the users and other stakeholders be alerted of the impact. We encourage that all ndings be dealt with and the Final Audit Report be shared publicly for the transparency of efforts and the advancement of security learnings within the industry.  Security Audit Report | BNS-v2 | Trust Machines 30 August 2024 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.  ", "html_url": "https://leastauthority.com/trust-machines-bns-v2-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A:  SecureBytes  Does Not Prevent the Copying or Paging Out of Keys", "body": "   Location   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Common/SecureBytes.cs   Synopsis   SecureBytes  is a class that stores binary data in a way that aims to mitigate against an attacker reading  keys from memory. While the technique is not problematic, the functions that take the keys as arguments  are generally not compatible with this approach. Therefore, this approach is not as effective at mitigating  attacks as intended. In addition, we identified various places in the code where no security measures are  in place to store private keys, but plain  byte[]  is being used instead.   Impact   If the attacker manages to circumvent this current mitigation or is able to read private keys from insecure  byte[]  storage, they may gain access to wallet keys.    Preconditions   The operating system would need to page out the areas in memory that contain the key byte slices to a  pagefile and the attacker would need access to the file. The attacker would also need to be running code  on the device of the user. Depending on the security habits of the user and the design of the operating  system, it may suffice if the code of the attacker runs with user privileges.   Feasibility   The attacker would need to be able to analyze the pagefile or memory dump. This requires some  knowledge in the field of computer forensics.   Technical Details   C# has managed memory, which means that it is much easier to write memory-safe code. Memory safety  means that the possibility of double free, buffer overflows, and similar attacks is drastically reduced  through the use of a runtime. The memory is managed by the common language runtime (CLR). The CLR  may move or copy memory around, without the developer being able to prevent it, so perhaps surprisingly,  memory-safety introduces issues around the secrecy of the contents of the memory. This means that for  regular byte arrays, it is not possible to safely overwrite a key with zeroes. Additionally, memory may be  paged out to the pagefile at any time. This means that regular values stored in memory may be written to  disk.   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.        To address this issue for storing passwords in memory, Microsoft has added the  SecureString  class,  which stores a string such that is neither copied nor paged out. The Atomex team uses this class to write  SecureBytes , which securely stores binary data (such as keys) encoded as   in a  SecureString .  Although this is not a poor practice, the issue remains that all functions that use these keys for  cryptographic operations (e.g. key derivation, encryption or signing functions) are not able to use  SecureBytes .    Remediation   The  libsodium library  provides functions to allocate free memory that can not be paged out. There are  bindings to that library in C#, such as  NSec . We recommend using one of these to allocate unmanaged  memory before and overwrite it with zeros as well as free it after use.   Status   The Atomex team has changed  SecureBytes  to use memory allocated by libsodium. This mitigates  many of the possibilities to leak keys through memory dumping attacks. However, several cryptographic  operations still operate on plain byte arrays requiring keys to be converted to the less secure format, thus  creating an opportunity for moments of vulnerability. We recommend that further effort is invested in  finding and using, or possibly even implementing, operations that currently require insecure memory to  function, e.g. the BIP32-Ed25519 library.   Verification   Partially Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Atomex_Core_Library_and_Desktop_Client_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: BouncyCastle's Ed25519 Fork is Not Well-Maintained", "body": "   Location   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Cryptography/BouncyCastle/Ed25519.cs   Synopsis   The BouncyCastle  Ed25519  fork is out of date. Since the Atomex fork was made, more security checks  have been added to the original BouncyCastle code, specifically a low-order point check for all keys.  Furthermore, the code that has been forked is undocumented. As a result, given that BouncyCastle is  central to the security of the core library, it is critical that the code be regularly updated and maintained.    Impact   Issues in the cryptographic library used to create and verify signatures may be able to trick a wallet into  accepting invalid signatures, which are used to verify the validity of transactions.   Preconditions   Two preconditions are possible. First, the attacker may find a hole in the changes made to the  Ed25519  class by the Atomex team or, second, a security vulnerability in BouncyCastle is found and fixed, but not  merged by the Atomex team.   Feasibility   If the preconditions are met, an attacker with decent cryptographic knowledge would be able to attack  users. Significantly, in the case that a fix to a vulnerability in the BouncyCastle library is not merged into  Atomex, that vulnerability would be publicly visible.    Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.        Technical Details   BouncyCastle is a popular cryptographic library for Java and C#. However, the C# version appears to be  completely undocumented. The Atomex team has copied the class providing  Ed25519  signatures out of  the BouncyCastle project and made some changes.   The reason or purpose for the changes made and whether they are secure appears to be neither  documented nor discussed. Through extensive study of code, it becomes clear that the changes were  made because the API provided by BouncyCastle did not allow implementing BIP32-Ed25519  [KL17] , a  scheme for hierarchical deterministic (HD) wallets. Specifically, BouncyCastle only allows using the  256-bit seed value as a private key, but not the 512-bit key (called the  expanded  key in BIP32-Ed25519),  which is required by BIP32-Ed25519.   Forking and maintaining a library, particularly one that includes cryptography, requires a considerable  amount of work and responsibility. Instead of modifying a library to match the project requirements, a  more pragmatic approach would be to choose a better suited library. Since BouncyCastle does not appear  to meet other requirements of the library, the Atomex team implemented the  SecureBytes  class to  protect keys in memory. However, BouncyCastle is not able to work with this type, thus making the keys  they try to protect vulnerable.   Remediation   Given that maintaining a fork requires significant effort, instead of using BouncyCastle, we recommend  using the NSec cryptographic library to implement BIP32-Ed25519, in which the API allows deriving secret  (expanded) keys from a seed as a secret key for signing. While the change to support BIP32-Ed25519  keys is considerable, it is significantly smaller than the current changes to BouncyCastle. The library also  resolves the issues around protecting keys in memory against getting paged out by exposing the  respective libsodium functions. In addition, using NSec provides free secure memory.   Status   Considering the current unavailability of a cryptographic library which immediately implements both  secure key handling and signing using Ed25519 with keys that are derived hierarchically deterministically  according to to BIP32-Ed25519, the Atomex team has decided to maintain BouncyCastle by tracking and  including changes made upstream. However, the Atomex team did not provide a clear process for this  undertaking. Instead, they implemented several changes to the files copied out of the BouncyCastle  project, including having the code align with their own code style (i.e. whitespace,  var -style declarations,  curly braces around single-line for loops, etc.). Furthermore, the new code added by the Atomex team is  scattered throughout the file, instead of kept mostly separate, which would have helped comparability. As  a result, we recommend that in the absence of a clear process for tracking and maintaining the  remediation be implemented in order to resolve this issue.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Atomex_Core_Library_and_Desktop_Client_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: LiteDB's Encryption is Broken and Unreliable", "body": "   Location   https://github.com/atomex-me/atomex.client.core/tree/2cf279bfd4202e90b9534b0f797b428e9c7e3d87 /Atomex.Client.Core/LiteDb   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.        Synopsis   LiteDB is used to store wallet data on disk. The database has an encryption mode that is used by the  Atomex team. The security of the encrypted mode of LiteDB is severely flawed and can not be considered  secure.   Impact   An attacker may get access to the wallet data, including but not limited to, the secret values used in the  atomic swaps. The attacker may also change the client state by modifying the encrypted data in the  wallet. Combined with the vulnerabilities in  Issue D , this may also result in leakage of the wallet keys.   Preconditions   The attacker would need access to the encrypted LiteDB database. This is possible for any software  running on the disk with user privileges.   Feasibility   The attacker would need some understanding of applied cryptography at the same level as most  blockchain engineers. The attacker could catastrophically attack the encryption of LiteDB, compromising  the database in its entirety.   Technical Details   The encryption of LiteDB is based on AES-ECB, which is  known to be vulnerable  and should not be  considered secure. As a result, it should not be relied on for storing wallet data on disk. Furthermore, the  encryption is not authenticated, allowing the undetected modification of data. Additionally, the key  derivation process used to derive keys is PBKDF2 with only a thousand iterations. LiteDB also does not  specify which underlying function to use so the  default of HMAC-SHA1  is used ( SHA1 is broken and  should no longer be used ). As a result, this method does not provide sufficient protection against brute  force attacks.   Remediation   Rather than relying on LiteDBs encryption, encrypt the data manually before storing it. To do so, do not  use a password but an already strong key  K  instead. That key may be derived from a password, which we  discuss further in  Issue D .    To store an item I at address A in the database:   -  -  -  -  -  Compute the shadowed address   -  A = HMAC(K, addr || A)   Compute the encryption key for item I   -  K_I = HMAC(K, key || A)   Pick a 192 bit random nonce   -  N = rand(24)   Encrypt the item   -  I = secretbox_encrypt(K_I, I, N)   Store I at A   -  DB.Set(A, N || I)   To retrieve an item at address A in the database:   -  -  Compute the shadowed address   -  A = HMAC(K, addr || A)   Compute the encryption key for item I   -  K_I = HMAC(K, key || A)   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.      -  -  Get the nonce N and the encrypted item I from the database   - -  N || I = DB.Get(A)  where N is the first 24 bytes of the results and I is the rest   Decrypt the item   -  I = secretbox_decrypt(K_I, I, N)   Use the  secretbox  functions provided by a library that provides bindings to libsodium, such as NSec.  This algorithm not only provides confidentiality, but it will also detect if an attacker attempts to modify the  data.   Status   The Atomex team implemented manual encryption of all stored items based on AES256-GCM.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Atomex_Core_Library_and_Desktop_Client_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Key Derivations from Passwords are Insecure", "body": "   Location   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Wallet/UserSettings.cs#L17   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Common/SessionPasswordHelper.cs   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Wallet/HdKeyStorage.cs#L25   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Cryptography/Aes.cs#L12   Synopsis   There are several locations where keys are derived from passwords throughout the code base. However,  we do not see a consistent strategy as different approaches and parameters are utilized in different  places. None of the parameters chosen are sufficient against brute force attacks.   Furthermore, keys derived from passwords are used both for database encryption and secure key  storage. This constitutes a form of key reuse, which can lead to cryptographic vulnerabilities.   Impact   An attacker may be able to brute-force the encryption keys of the database and secure key storage or  perform related-key attacks on AES itself. In each case, they would be able to learn at least parts of the  plaintext data.    Preconditions   The attacker would need access to the encrypted wallet. This is possible for any software running on the  disk with user privileges.   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   9   This audit makes no statements or warranties and is for discussion purposes only.        Feasibility   For the brute-force attack, the attacker would need sufficient computational power. Due to the insufficient  technique currently being used, this would be inexpensive, especially considering the potential rewards.  For related key attacks, the attacker needs profound cryptanalysis knowledge.   Technical Details   Most of the key derivations from passwords in Atomex use PBKDF2, but with varying iteration counts.  LiteDB uses an iteration count of 1024 (e.g. very low compared to the  100,000 iterations that were used  by LastPass in 2011 ), and before the user password is passed to LiteDB, it is iteratively hashed with  SHA256 ten times. The encryption and key derivation of LiteDB is discussed in  Issue C , yet the purpose of  this is unclear. One possibility is that should LiteDB corrupt the key, the original password is not affected.  However, the issue remains that if the attacker knows the tenth hash, it is still possible to brute-force the  password.   The AES class uses a default iteration count of 52,768, however, when the class is used in the classes  UserSettings  and  HdKeyStorage , it is overridden with 1024. This value is much too low.   In general, PBKDF2 has the weakness that it is parallel. As a result, memory-hard hash functions should  be used for deriving keys from passwords. They significantly increase the cost of parallelization.   Furthermore, in some instances keys derived from passwords are reused while in other instances the  derived keys are different but related, because the only difference is the iterated hash before the  derivation. Instead, a single key should be derived from the password, from which further keys are derived  using a regular key derivation function like HKDF.   Remediation  Derive a single key  K pw  from the password using Argon2id or Balloon Hashing. To choose the parameters,  follow the recommendations in Section 4 of the  RFC draft for Argon2 . As a guidance, memory sizes of 32  and 64 MB are common today. For each part of the system that requires a key (e.g. database encryption  or HdKeyStorage), derive a key from that using  HMAC-SHA256 . Use  K pw  as the key and a label describing  the user of the key as the message. For example, the key for database encryption  K db  would be computed  as follows:   K db  = HMAC-SHA256(K pw , database encryption)   Status   The Atomex team implemented our recommendation and, as a result, the Argon2id is used to generate a  key from the user's password. Furthermore, the key is calculated from the main key using  HMAC-SHA256  for any encryption.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Atomex_Core_Library_and_Desktop_Client_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Default Block Confirmation Does Not Account For Blockchain", "body": "  Reorgs   Location   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Blockchain/Helpers/TransactionConfirmationHelper.cs   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   10   This audit makes no statements or warranties and is for discussion purposes only.        https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Blockchain/Ethereum/EthereumTransaction.cs#L20   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Blockchain/BitcoinBased/BitcoinBasedTransaction.cs#L18   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Blockchain/Tezos/TezosTransaction.cs#L19   Synopsis   Blockchain reorganizations are an issue that all applications must deal with. The default block  confirmation is set to one block in the Atomex core library, regardless of the underlying chain in  consideration. If the wallet is performing actions, and a chain reorganization occurs at a critical time of  the atomic swap, there could be a need for the wallet to recover and to rebroadcast a transaction or retry  a swap.   Preconditions   A wallet must be connected to a node that includes their transaction in a forked chain, and after one block  or more, the fork is reorganized to the canonical chain while transactions and actions taken by the client  have assumed that transactions are confirmed.    Feasibility   Blockchain reorganizations are more common on some chains than others. Given that they are frequent  in Ethereum due to low block time, this is likely to happen. Ethereum refers to these frequent forks as  ephemeral forks. While these forks are generally short, it may be possible that they are extended  unexpectedly.   Technical Details   Many checks before performing actions for swaps or other transactions are checked against a boolean  stored on the transaction called  isConfirmed . This boolean is set to  true  if the transaction has been  included in the blockchain and is greater than  DefaultConfirmations . With a default of one block of  confirmation, there are cases that a client is connected to a node that has not discovered a fork with a  heavier amount of observed work to it from other peers. If the state of a node the wallet is connected to is  not derived from the canonical chain, there is a chance that a transaction will be made and then later  removed due to a reorganization. The client database may get updated with a state that is now incorrect  and needs to be reconciled with the new fork. This might lead to very different swap outcomes (e.g. if a  timeout occurred on one branch and no time out on another).    Remediation   One approach would be to handle  DefaultConfirmations  differently for any chain and adhere to the  recommended minimum of blocks to wait before considering a transaction to be confirmed. The problem  with this approach is that there will be a longer delay on all transactions, which may affect the usability of  the Atomex swaps.   The other approach is to add checks to the core codebase. These additions would be checks for  reorganizations, database inconsistencies, and failed transactions over a longer period of time. The issue  with this approach is the added complexity to the implementation, however, this may be the safest route  and can be limited in scope to swaps within the default time span a swap may live, currently set at a  default time span of a maximum of 10 hours.   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   11   This audit makes no statements or warranties and is for discussion purposes only.      Status   The Atomex team has responded that the implementation of additional checks and tracking for  reorganizations is in progress. However, this effort was incomplete at the time of this verification.   Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Atomex_Core_Library_and_Desktop_Client_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Dropped Swaps Are Not Re-initiated or Re-accepted", "body": "   Location   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Swaps/SwapManager.cs#L451   Synopsis   It is unclear what occurs in the case that a swap is lost by the client software. There is a function in the  SwapManager  class called  RestoreSwap  that appears to address this occurrence, as it checks the state  of the swap and will attempt to act on it accordingly. If the swap is active, meaning that it has not yet  reached the default payment timeout, the code will do nothing as it is not implemented.   Impact   This is a low priority issue as these swaps have not yet had payments broadcast to them so no funds are  at risk of being lost. Therefore, this would only lead to inconsistencies in the swap clients when a swap is  lost and needs to be retried before payments are made. A client may be stuck on a particular swap until  the swap timeout without the ability to continue.   Preconditions   An initiator client creates a swap and loses it before sending it to their counterparty and now must resend  the swap, or a recipient of a swap loses their swap and should now respond when it is recovered.    Feasibility   This is not highly feasible as the swap should be lost before any broadcasts of payments are made.   Technical Details   If a swap payment has not yet been broadcast and the time is still within the swap's timeout timestamp, a  method should exist for recovering the swap or re-initiating it by sending the swap to the recipient or by  re-accepting a swap sent to the client. Currently, the implementation does nothing and leaves the swap  there until the end of the default payment time where it would then be removed.   Mitigation   Implement the missing logic for re-initiating swaps in the case that payments have not yet been  broadcast to the chain.   Status   The Atomex team has responded that this is a low priority task and have not addressed the issue at the  time of this verification.   Verification   Unresolved.   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   12   This audit makes no statements or warranties and is for discussion purposes only.        ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Atomex_Core_Library_and_Desktop_Client_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: API Shared Resources May Be Unstable", "body": "   Location   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Blockchain/Ethereum/EtherScanApi.cs#L24   Synopsis   On the Ethereum side, Atomex uses APIs for services such as Etherscan or Infura. These services have  rate limits that can be exceeded if clients overwhelm them with requests. And when these services are  overwhelmed, they have been known to be faulty and return timeouts.   On the Tezos side, services like  tzStats , or  Baking Bad  are used which do not enforce limits on the number  of calls or the amount of data one can query from the API. However, spam protection measures that limit  the number of connection attempts and HTTP calls over short time-frames are in place.    Impact   If the client wallets rely on a single blockchain service account and that account is open to take requests  from anyone, then the service could be rate limited and shut down or overwhelmed from general or  attacker traffic. This would block all wallets relying on that service from communicating with the  blockchain. This could come at opportune times for an attacker during the lifespan of a swap.   Preconditions   A large amount of traffic is sent to the services that the wallets rely on to interact with each chain,  causing the service to become overwhelmed and shut down for a period of time.   Feasibility   The stability of the blockchain API services has been known to be inconsistent for large amounts of  traffic making it likely that the use of the third-party service will experience failed requests.   Technical Details   The Etherscan API endpoint used has a  documented rate limit . The  Infura documentation  mentions that  all accounts have a rate limit and list how they score these limits. The recommended solution provided by  Infura is to reduce the amount of traffic if there is a rate limit response. In the Ethereum case, there are  two services to choose from if one is being faulty. An attack would need to send an excessive amount of  traffic to the services. If the services supplying the wallet are down for the default wait time for swap  redemption, an initiator of a swap may be able to deny their counterparty from responding in time.   Mitigation   Alert the services if you expect that your application will create a large amount of requests.   Remediation   Stand up nodes and infrastructure to support the Atomex application specifically and do not rely on third  parties that serve the community.   Status   The Atomex team has responded that they are working on their own infrastructure to address this issue  and have not addressed the issue at the time of this verification.   Verification   Unresolved.   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   13   This audit makes no statements or warranties and is for discussion purposes only.        ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Atomex_Core_Library_and_Desktop_Client_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue H: Hash Time Locked Contract (HTLC) Preimage Secret is Not Stored", "body": "  Safely in Memory   Location   https://github.com/atomex-me/atomex.client.core/blob/2cf279bfd4202e90b9534b0f797b428e9c7e3d8 7/Atomex.Client.Core/Core/Swap.cs#L97   Synopsis   The preimage of a swap secret is kept in the client in unprotected memory. If a client is compromised  before revealing the secret, this would allow a counterparty to be able to redeem a swap and cancel their  end before the other party can reveal and claim their swap.   Impact   Loss of swap funds as one party is able to derive the pre-image before it is revealed.   Preconditions   The attacker must be able to compromise the victim's computer and read the insecure preimage bytes  from memory.   Feasibility   This is not highly feasible as the preimage secret is only sensitive in the beginning of the swap and the  attacker must compromise the target machine.   Technical Details   A crucial component of an atomic swap protocol is the commit reveal stage of a secret. This secret  ensures that a counterparty is not able to redeem a locked amount of funds before the other party is able  to secure their side of the swap. For example, if A initiates a swap, they will lock funds into a contract with  the image of a secret. Party B will then not lock their side of the funds into a contract that requires  revealing the preimage to the image that A created and attempt to compromise A. This area is the primary  concern for the security of a swap. If B is able to deduce the image of the swap before the swap timeout  that A created, B may then redeem As lock without deploying Bs side of the swap contract.   Mitigation   Use a method such as those recommended in  Issue A  to ensure that the preimage is also kept in a secure  and encrypted state.   Status   The team responded with clarification that the client software will not be initiating atomic swaps,  therefore it is unnecessary to protect the secret in memory as by the time the client receives it from the  blockchain, the secret is meant to be public. This information makes this issue invalid.   Verification   Invalid Issue.   Security Audit Report | Atomex: Core Library + Desktop Client | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   14   This audit makes no statements or warranties and is for discussion purposes only.        ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Atomex_Core_Library_and_Desktop_Client_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Weak Fiat-Shamir Transformation Implemented in Various NIZKs", "body": "  Location  src/crypto-zkp/dlog_elgamal_com_proof.cpp  src/crypto-zkp/no_small_factor_proof.cpp#L53  src/crypto-zkp/no_small_factor_proof.cpp#L32  Security Audit Report | MPC-ECDSA Algorithm | Safeheron 19 October 2023 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   src/crypto-zkp/no_small_factor_proof.cpp#L33  src/crypto-zkp/pail/pail_aff_range_proof.cpp#L32  src/crypto-zkp/pail/pail_blum_modulus_proof.cpp#L58  src/crypto-zkp/pail/pail_dec_modulo_proof.cpp#L25  src/crypto-zkp/dlog_elgamal_com_proof.cpp#L27  src/crypto-zkp/dlog_elgamal_com_proof.cpp#L31  src/crypto-zkp/dlog_equality_proof.cpp#L26  crypto-zkp/pail/pail_dec_modulo_proof.cpp#L26-L28  Synopsis  The MPC-ECDSA algorithm, as specied in [CGG+21], utilizes NIZKs derived from Sigma Protocols using the Fiat-Shamir transformation. As explained in [DMW+23], many NIZKs require an implementation of the strong Fiat-Shamir transformation, which has to include every piece of information into the initial transcript of the hash function that is publically available to the verier after the rst round. However, we identied various instances in the code where a weak Fiat-Shamir transformation was used instead, breaking the soundness proof of [CGG+21] and hence making the system vulnerable to unforeseeable attack vectors.  Impact  Critical. The security of the MPC-ECDSA algorithm is critically dependent on the validity of the Sigma protocol relations, as described in section 6 of [CGG+21].  For example, in src/crypto-zkp/dlog_elgamal_com_proof.cpp#L70, the implementation transforms the Sigma Protocol from gure 24 in [CGG+21] into a NIZK. The code includes the prover message (A, N, B) of the rst round into the Fiat-Shamir transformation, giving the simulated verier challenge e = H(A||N||B). However, the public inputs L, M, X, Y and the generators g and h are not included in the hash. This breaks the adaptive knowledge soundness of the El-Gamal Commitment NIZK.  To illustrate, consider a malicious prover that can generate a valid NIZK without having a proper witness by choosing invertible eld elements z and u and group elements A, N, B, X, such that e = H(A||N||B) is invertible. The prover is then able to construct a simulated proof for the public inputs (L, M, X ,Y) by dening L = (g^z/A)^(1/e), Y = (h^u/B)^(1/e), and M = ((g^u\u00b7X^z)/N)^(1/e). Moreover, since the generator h is not included into the simulated verier challenge, it is possible for a malicious prover to transform a valid proof for generator h into a simulated proof for another generator h. In the linked locations, weak Fiat-Shamir transformations are applied in multiple locations. Consequently, it is a complex endeavor to reason about every potential attack vector.  Technical Details  In [CGG+21], the transformation of the Sigma Protocols from section 6 is abstracted by the introduction of a ZK-Module M (section 2.3.1), which takes a sigma model as input and computes a NIZK, assuming the existence of a hash function that behaves like a random oracle. This module describes in detail all data that is necessary to compute the strong Fiat-Shamir transformation of a Sigma Protocol, which, in general, must include a hash over every data that is known to the verier after the rst round of the Sigma protocol. It consists of a description of the underlying cryptographic system, the proof relation, every auxiliary input and the public inputs. However, the  Security Audit Report | MPC-ECDSA Algorithm | Safeheron 19 October 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   implementation deviates from this in multiple places. Inclusion of a description of the underlying cryptographic system and the proof relation is possible since the code allows for the inclusion of a \u2018salt value that can be initialized with the system's session identier (SID) or the key-specic sub-session identier (SSID). However, there are places in the code where this is not done correctly.  For example, the code does not include:   Initial messages (e.g. src/crypto-zkp/no_small_factor_proof.cpp#L53);  Public inputs (e.g. src/crypto-zkp/dlog_elgamal_com_proof.cpp#L27 or  crypto-zkp/pail/pail_aff_range_proof.cpp#L32);   Statement descriptions (e.g. src/crypto-zkp/dlog_elgamal_com_proof.cpp#L31 or  src/crypto-zkp/dlog_equality_proof.cpp#L26); and   Auxiliary inputs (e.g. crypto-zkp/pail/pail_dec_modulo_proof.cpp#L26-L28).  Remediation  The algorithms in [CGG+21] give a detailed description of what data should be included into each Fiat-Shamir transformation. We recommend updating the code, such that it initializes the salt eld of each NIZK with accurate SID, SSID, and AUX values to ensure that the cryptographic system, the proof relation, and any auxiliary values, such as the index, are represented as intended. In addition, we also recommend that the code include all public inputs, generators, and initial prover messages into the Fiat-Shamir hash.  Status  The Safeheron team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/safeheron_mpc_algorithm_updated_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Implementation Deviates From Protocol Description", "body": "  Location  crypto-zkp/pail/pail_dec_modulo_proof.cpp#L96  src/crypto-zkp/dln_proof.cpp#L69-L70  cmp/aux_info_key_refresh/round3.cpp#L67  cmp/aux_info_key_refresh/round0.cpp#L132  cmp/aux_info_key_refresh/round0.cpp#L137  crypto-zkp/pail/pail_aff_range_proof.cpp#L124  crypto-zkp/pail/pail_aff_range_proof.cpp#L125  crypto-zkp/pail/pail_blum_modulus_proof.cpp#L224  Synopsis  During our audit, we found that the implementation deviates from the specication described in [GG18] and [CGG+21].  Security Audit Report | MPC-ECDSA Algorithm | Safeheron 19 October 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Impact  High. The deviations that our team identied break the correctness of the MPC-ECDSA scheme and the security proof of [CGG+21].  Technical Details   The \u2018Paillier Decryption modulo q NIZK (Figure 30) requires the computation w = r * \\rho^e  mod N_0. However, the code implements w = r * \\rho^e mod N_0^2 (crypto-zkp/pail/pail_dec_modulo_proof.cpp#L96).   The \u2018Ring-Pedersen Parameters NIZK (Figure 17) requires the parameters h1 and h2 to be  elements from Z_N^*. However, a check is missing in the verier that conrms whether h1 and h2 are coprime to N (src/crypto-zkp/dln_proof.cpp#L69).   The \u2018Auxiliary Info. & Key Refresh algorithm (Figure 6, output) requires computing x_ij =  dec(C_ji) mod q and then checking that X_ij = g^x_ij. However, the implementation does not include the modular q operation. As a result, the denition of \\mu = (C^i_j * (1+N_i)^(-x_ij) )^(1/N) mod N^2 results in a different \\mu (cmp/aux_info_key_refresh/round3.cpp#L67).   The \u2018Auxiliary Info. & Key Refresh algorithm (Figure 6, round 1) requires computing the hash V_i, which includes the preimage of the two (uncompressed) curve points Y_i and B_i. Although both the x-coordinate and y-coordinate of each point need to be hashed, the code mistakenly hashes, twice, the x-coordinate of those points only (cmp/aux_info_key_refresh/round0.cpp#L130-L137).   The \u2018Paillier Encryption Range Proof ([GG18], A.3) requires the verier to check that s_1 is a value from Z_{q^3} and t_1 is a value from Z_{q^7}. However, the implementation checks for s_1 in [-q^3, q^3] and t_1 in [-q^7, q^7] (crypto-zkp/pail/pail_aff_range_proof.cpp#L124-L125).   The \u2018Paillier-Blum Modulus NIZK (Figure 16) requires the computation of elements z_i from Z_N. In the implementation, the verier checks that z_i is neither zero nor one. However, the way those numbers are constructed, the case z_i = 1 can potentially occur in a correct proof that the verier would then reject (crypto-zkp/pail/pail_blum_modulus_proof.cpp#L224).  Remediation  We recommend updating the implementation according to the specication.  Status  The Safeheron team has implemented the remediation as recommended (as shown here and here).  Verication  Resolved.  ", "html_url": "https://leastauthority.com/safeheron_mpc_algorithm_updated_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Session Identier Used Incorrectly", "body": "  Location  cmp/minimal_key_gen/round0.cpp#L89-L90  Synopsis  The sub-session identier (SSID) is used in the key generation algorithm instead of the session identier (SID).  Security Audit Report | MPC-ECDSA Algorithm | Safeheron 19 October 2023 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Impact  High. This results in a deviation from the paper and also compromises the key generation process since the SSID should only be generated afterwards.  Technical Details  The implementation in the [CGG+21] Protocol is divided into several parts \u2013 the key generation process, the auxiliary info and key refresh process, and the signing process. To ensure that these processes are coordinated, several identiers are instantiated. The overall session identier (SID, Figure 5, round 1) is set and passed during the key generation process. After that, the sub-session identier (SSID), which entails the SID, (SSID, Figure 7, round 1) is set and passed to the signing process. Once the signing process is over, the sub-session identier is erased.  In the ComputeVerify function in Round 1 of the Key Generation algorithm, an incorrect session identier is passed. Here, the SSID is passed instead of the SID, which poses problems for the correct coordination of processes.  Remediation  We recommend updating the ComputeVerify function, such that the SID is used instead of the SSID.  Status  The Safeheron team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/safeheron_mpc_algorithm_updated_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Incorrect Implementation of get_eth_balances_with_retry", "body": " Function  Location  orchestrator/gravity_utils/src/get_with_retry.rs#L23  Synopsis  The get_eth_balances_with_retry function calls web3.eth_get_balance to get an initial value. It then calls the web3.eth_block_number function, which returns the block number rather than the balance.  Impact  The caller would get an incorrect balance, affecting the logic of the system.  Mitigation  We recommend using web3.eth_get_balance function on the subsequent call of the get_eth_balances_with_retry function.  Security Audit Report | Gravity Bridge | Althea 11 April 2022 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Althea team has implemented the web3.eth_get_balance function, as suggested.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Althea_Gravity%20Bridge_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: The Minimum Number of Block Conrmations for Ethereum", "body": " Mainnet is Low  Location  orchestrator/orchestrator/src/ethereum_event_watcher.rs#L240-L257  Synopsis  The number of block conrmations for Ethereum mainnet used by the Gravity Bridge is 6. Consequently, the system is not processing blocks, as they are written to the chain, to update its state. Instead, it is implementing a delay and reading a block once it has been conrmed 6 times, or since 5 more blocks have been written to the chain.  Block nality is a crucial mechanism for blockchain and bridge safety. According to the overview.md denition, EthBlockDelay - Is an agreed upon number of Ethereum blocks all oracle attestations are delayed by. The current value being considered is 50 blocks. However, the EthBlockDelay variable and its value are noted only once in the overview.md and the codebase does not utilize such a constant or variable.  In the coded implementation, the function is named get_block_delay and the description of the function justies that the block conrmation should be equal to 6 blocks for Ethereum mainnet. The implementation also contains the following statement: The value used here for Ethereum is a balance between being reasonably fast and reasonably secure. A 6 block nality threshold for Ethereum mainnet is the absolute minimum and could potentially be ineffective in preventing race conditions and double spend attacks.  Impact  A low threshold of block conrmation could result in race conditions and double spend attacks against the Gravity Bridge, which could prevent the system from functioning as intended and lead to the loss of funds.  Feasibility  Since the Ethereum blockchain does not have a nality property, and reorganizations and forks occur regularly, attacks targeting non-repudiation properties are feasible if the number of block conrmations is low.  Remediation  We recommend increasing the block delay value for the Ethereum Mainnet to 12 blocks [R19], in adherence with best practice. We also recommend reconsidering block delay values for other testnets in scope.  Status  The Althea team has increased the block delay value to 13 blocks.  Security Audit Report | Gravity Bridge | Althea 11 April 2022 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Althea_Gravity%20Bridge_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Sensitive Information is Not Cleared", "body": "  Location  Examples (non-exhaustive):  orchestrator/gbt/src/orchestrator.rs  orchestrator/gbt/src/keys/register_orchestrator_address.rs  orchestrator/cosmos_gravity/src/send.rs  orchestrator/orchestrator/src/main_loop.rs#L45  module/cmd/gravity/cmd/eth_keys.go  module/x/gravity/types/ethereum_signer.go  Synopsis  If an attacker is able to access memory (e.g. accessing core dump, using debuggers, and exploiting vulnerabilities such as Heartbleed), the attacker may be able to retrieve non-zeroized sensitive information in cleartext, such as Ethereum or Cosmos private keys.  Impact  Leakage of Ethereum or Cosmos private keys could result in the loss of user funds.  Preconditions  An attacker must be able to read memory regions containing sensitive data.  Mitigation  We recommend performing zeroization for passwords, local secrets, private keys, authentication tokens, and other sensitive information. In Rust, we recommend using the zeroize crate to derive the zeroize-on-drop trait. In Go, we recommend using SetFinalizer and monitoring the current activities in that area for future improvements.  Status  The Althea team has responded that they plan to implement this mitigation in the future. However, at the time of the verication, the suggested mitigation has not been resolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Althea_Gravity%20Bridge_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: keys.json File Permissions Conguration is Insecure", "body": "  Location  orchestrator/gbt/src/config.rs#L39-L57  Security Audit Report | Gravity Bridge | Althea 11 April 2022 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The Orchestrator stores private keys in the keys.json le with 644 permissions. That le is stored in the .gbt directory with 755 permissions inside the user directory. These permissions give any user on the host access to read the private keys.  Impact  An attacker with access to the users le system can access the user's private keys.  Preconditions  An attacker must be able to have local or remote access to the users lesystem.  Feasibility  If the preconditions are met, the attacker would need to perform trivial actions in order to steal the private keys.  Mitigation  We recommend creating the keys.json le with 600 permissions.  Status  The Althea team has responded that they plan to implement this mitigation in the future. However, at the time of the verication, the suggested mitigation has not been resolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Althea_Gravity%20Bridge_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Returned Errors in Go are Not Checked", "body": "  Location  Examples (non-exhaustive):  gravity/keeper/pool.go#L194  gravity/module.go#L88  gravity/abci.go#L172  gravity/keeper/genesis.go#L120  gravity/keeper/msg_server.go#L49  gravity/types/msgs.go#L435  Synopsis  There are multiple instances in the Gravity Bridge module  code where returned errors are not checked and ignored. This may lead to undened behavior in the case when the result value is nil and the error is not nil but ignored.  The following is an example of the code where errors are not handled:  val, _ := sdk.ValAddressFromBech32(msg.Validator) orch, _ := sdk.AccAddressFromBech32(msg.Orchestrator) addr, _ := types.NewEthAddress(msg.EthAddress)  Security Audit Report | Gravity Bridge | Althea 11 April 2022 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   The idiomatic coding in Go suggests that the result of a function is unsafe until the error value is checked and then properly handled or propagated.  Impact  The failure to detect and report errors appropriately makes it dicult to identify bugs and implementation errors, which inhibits the implementation of correct functionality.  Mitigation  We recommend appropriately checking and handling or propagating all returned errors. In addition, we recommend integrating Go linters such as semgrep or golangci-lint with appropriate modules (e.g. ineffassign) and rules to check that all errors are handled correctly.  Status  The Althea team has responded that adding Go linters is in progress. However, it has not yet been fully implemented at the time of verication.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Althea_Gravity%20Bridge_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Block Height and Event Nonce Not Range-Checked in from_logs", "body": "  Location  orchestrator/gravity_utils/src/types/ethereum_events.rs#L533  orchestrator/gravity_utils/src/types/ethereum_events.rs#L202  Synopsis  In the Orchestrator implementation, the event_nonce and block_height must be checked to verify if they are constrained to 64 bits in the from_log function in the Ethereum events structs Erc20DeployedEvent and ValsetUpdatedEvent. The code should throw an error if any of these exceeds 64 bits, which is already being done for events like TransactionBatchExecutedEvent and SendToCosmosEvent.  Impact  In the le orchestrator/gravity_utils/src/types/ethereum_events.rs, the events emitted from the Ethereum blockchain are parsed to decode the type of the event and the individual elds as a part of the event. Therefore, this implementation is critical to conrm that the events are correctly parsed. There is no existing Ethereum Application Binary Interface (ABI) unpacking implementation. Thus, it is crucial for the methods in this le to work as expected.  For events like Erc20DeployedEvent and ValsetUpdatedEvent, a failure to check if the event nonce and the block height are valid 64-bit numbers could lead to unexpected behavior. Gauging the direct impact of the nonce and block height not being range constrained is non-trivial.  Remediation  We recommend adding the error conditions to Erc20DeployedEvent and ValsetUpdatedEvent. In addition, we recommend maintaining consistency in error reporting in the event that nonce or block height is a number greater than 64 bits for the Erc20DeployedEvent and ValsetUpdatedEvent events.  Security Audit Report | Gravity Bridge | Althea 11 April 2022 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Althea team has implemented checks for event_nonce and block_height except for this assignment.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Althea_Gravity%20Bridge_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Private Keys are Stored in Cleartext or Encrypted with a Hard", "body": " Coded Password  Location  orchestrator/gbt/src/config.rs#L118  module/cmd/gravity/cmd/eth_keys.go#L31  Synopsis  The Orchestrator and Gravity Bridge module components store private keys in the lesystem insecurely. The Orchestrator stores private keys in cleartext without any encryption. The Gravity Bridge module encrypts private keys with a hard-coded password that can be derived by anyone and cannot be changed by the user.  Impact  An attacker that is able to gain access to the lesystem can access the user's private keys and sign transactions transferring tokens between blockchains.  Mitigation  We recommend implementing encrypted storage for secp256k1 private keys in the lesystem for both components. In addition, we recommend that passwords adhere to industry standards such as the NIST guidelines on memorized secrets.  Status  The Althea team has responded that this issue is irresolvable given that in all POS networks, validator key security must be balanced against liveness. However, our team recommends that the security of private keys be prioritized and the suggested mitigation be implemented.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Althea_Gravity%20Bridge_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue H: Private Keys are Logged to Console", "body": "  Location  orchestrator/gbt/src/keys/register_orchestrator_address.rs  orchestrator/gbt/src/keys/register_orchestrator_address.rs  Synopsis  In the event that a user does not provide private keys, the system generates them and outputs them to console via a logging mechanism. Once complete, the keys cannot be controlled or cleared from the console by the user. However, the secret keys are not persisted in a log le.  Security Audit Report | Gravity Bridge | Althea 11 April 2022 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   Impact  An attacker that is able to gain access to the system can compromise the user's private keys.  Preconditions  An attacker must be able to have local or remote access to the system and be able to read logs outputted to the users console.  Mitigation    We recommend outputting the private keys into a le with 600 permissions located in the .gbt directory. In addition, we suggest outputting a log message containing the path to the le with the private keys and the shell command required to obtain them.  Status  The Althea team has responded that the implemented command generates private keys and those keys are provided to the user through the console by design. However, we believe that the security of the key generation mechanism could be effectively improved with the proposed mitigation.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Althea_Gravity%20Bridge_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: startPreSeal Function Can Be Called After Fundraising Plan Has", "body": " Been Successfully Ended  Location  filfi/LetsFilProcess.sol#L366  Synopsis  When a fundraising plan is successfully ended by either one of the functions, closeRaisePlan or raiseExpire, or due to staking, the _raiseSuc function is called to trigger the successful ending of the fundraising plan and start the sealing phase by changing the raiseState[planId] to RaiseState.Success. At this stage, the startPreSeal function calls for this fundraising plan should revert since the sealing period has started. However, an incorrect check at the start of the startPreSeal function allows the function to proceed.  Security Audit Report | Smart Contracts | FilFi 25 September 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Impact  Incorrect values for a fundraising plan may be set since the function assumes that it is the pre-sealing period.  Preconditions  For this Issue to occur, the fundraising plan must have been successfully ended.  Technical Details  require(raiseState[id] == RaiseState.Raising || raiseState[id] == RaiseState.Success, \"Process: state err.\");  Remediation  We recommend removing the check raiseState[id] == RaiseState.Success in the rst require statement in the startPreSeal function.  Status  The FilFi team has removed the aforementioned check.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/filfi_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: pushFinalProgress Function Can Be Called More Than Once", "body": "  Location  filfi/LetsFilProcess.sol#L401-L409  Synopsis  The pushFinalProgress function should be called one last time, two days after the sealing period ends for a particular fundraising plan. However, this function can be called more than once for the plan during the aforementioned period, resetting an already nalized sealing progress.  Impact  Already nalized states dependent on the sealing amount may be set to new values, resulting in unexpected behavior.  Preconditions  This Issue is likely if the pushFinalProgress function for a fundraising plan was already called once.  Remediation  We recommend preventing the function from being called more than once for a fundraising plan by adding the following check at the start of the function: require(!progressEnd[id], \"Final progress already pushed\");  Status  The FilFi team has added the recommended check.  Verication  Resolved.  Security Audit Report | Smart Contracts | FilFi 25 September 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/filfi_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Missing Check for the CommonType.FileAddress", "body": "  Location  filfi/LetsFilMiner.sol#L42  Synopsis  The function changeOwner(uint64 minerId, CommonTypes.FilAddress memory addr) lacks input validation for the address, due to which an address of arbitrary length can be passed.  Impact  An invalid address can be passed to FilAddress, which will set the invalid address for the owner and result in the loss of funds.  Remediation  We recommend using the validate function from utils/FilAddresses.sol#L63 to validate the address.  Status  The FilFi team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/filfi_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue D: getBalance Withdraws All the Balance of a Miner", "body": "  Location  filfi/LetsFilMiner.sol#L50  Synopsis  The function getbalance, which should be used to get the balance of a miner, withdraws all the available balance of a miner and moves it to the contract here.  Impact  When a miner attempts to verify their balance, they would inadvertently initiate a withdrawal of the available amount, which was not their intended action.  Remediation  We recommend removing the MinerAPI.withdrawBalance call from the function so that it only fetches the available balance.  Status  The FilFi team has removed the getBalance function.  Verication  Resolved.  Security Audit Report | Smart Contracts | FilFi 25 September 2023 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/filfi_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue E: Lack of Input Validation for the CreateRaisePlan Function", "body": "  Location  filfi/LetsFilRaiseFactory.sol#L67  Synopsis  There is no input validation for the function createRaisePlan, which can result in _raiseInfo.targetAmount or _nodeInfo.opsSecurityFund being zero.  Impact  1.  If _raiseInfo.targetAmount is zero, then the security deposit here will be zero as well, and raiser will be able to deposit zero as a security fund amount, as follows:  function paySecurityFund(uint256 id) public payable onlyRaiser  2.  If msg.value is not zero and nodeInfo.opsSecurityFund is zero then the storage provider (SP) will only have to pay spSafeSealFund. Additionally, if msg.value is zero and nodeInfo.opsSecurityFund is not zero, then the entire condition in the require function will not be true, which can trigger a revert.  Remediation  We recommend adding input validation for all the parameters present in the createRaisePlan function and implementing a check to verify that msg.value is not zero.  Status  The FilFi team has added zero checks for _raiseInfo.targetAmount, _raiseInfo.securityFund, _nodeInfo.opsSecurityFund and added the check to verify that msg.value is not zero.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/filfi_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue F: Insufcient Project Documentation and Code Comments", "body": "  Synopsis  The general documentation provided by the FilFi team was minimal. Robust and comprehensive documentation allows a security team to assess the in-scope components and understand the expected behavior of the system being audited. In addition, clear and concise user documentation provides users with a guide to utilize the application according to security best practices.  Additionally, the codebase lacks explanation in some areas. This reduces the readability of the code and, as a result, makes reasoning about the security of the system more dicult. Comprehensive in-line documentation explaining, for example, expected function behavior and usage, input arguments, variables, and code branches can greatly benet the readability, maintainability, and auditability of the codebase. This allows both maintainers and reviewers of the codebase to comprehensively understand the intended functionality of the implementation and system design, which increases the likelihood for identifying potential errors that may lead to security vulnerabilities.  Remediation  We recommend that the FilFi team improve the projects general documentation by creating a high-level description of the system, each of the components, and the interactions between those components. This  Security Audit Report | Smart Contracts | FilFi 25 September 2023 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   can include developer documentation and architectural diagrams. We additionally recommend expanding and improving the code comments within the components to facilitate reasoning about the security properties of the system.  Status  The FilFi team has decided not to improve the documentation and code comments at the current stage due to time limitations.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/filfi_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue G: Missing Test Suite", "body": "  Synopsis  Our team found no tests in the repository in scope. Sucient test coverage should include tests for success and failure cases, which helps identify potential edge cases, and protect against errors and bugs that may lead to vulnerabilities or exploits. A test suite that includes a minimum of unit tests and integration tests adheres to development best practices. In addition, end-to-end testing is also recommended to assess if the implementation behaves as intended.  Mitigation  We recommend that the FilFi team create a test suite for the FilFi smart contracts to facilitate identifying implementation errors and potential security vulnerabilities by developers and security researchers.  Status  The FilFi team has decided not to add a test suite at the current stage due to time limitations.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/filfi_smart_contracts_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Divestments With Zero XTZ Causes Tezos Error", "body": "  Known Issue B: XTZ to Token Ratio Can Be Manipulated During Operation  Known Issue C: Parameters to Liquidity Divestment Call are Ignored  Known Issue D: Users Able To Empty Token Reserves In Transfer  Known Issue E: High Initial Liquidity Causes Prohibitively Expensive Shares  Recommendations  About Least Authority  Our Methodology  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  2  This audit makes no statements or warranties and is for discussion purposes only.   Overview  Background  Least Authority performed a security audit of the QuipuSwap Smart Contracts for the Tezos Foundation. QuipuSwap is intended to provide an easy and ecient way to exchange tokens and XTZ on the Tezos blockchain in a wide variety of ways. The QuipuSwap Smart Contracts aim to allow users to add their tokens to exchange, invest liquidity, and potentially make a prot in a fully decentralized way. The current implementation supports both the FA1.2 and FA2 standards.  Project Dates   November 19 - December 18: Code review (Completed)  December 22: Delivery of Initial Audit Report (Completed)  February 1 - 10: Phase 1 Verication (Completed)  February 12: Delivery of Updated Audit Report (Completed)  March 5 - 8: Phase 2 Verication (Completed)  March 9: Delivery of FInal Audit Report (Completed)  Review Team   Phoebe Jenkins, Security Researcher and Engineer  Sajith Sasidharan, Security Researcher and Engineer  Nathan Ginnever, Security Researcher and Engineer  Coverage  Target Code and Revision  For this audit, we performed research, investigation, and review of the QuipuSwap Smart Contracts followed by issue reporting, along with mitigation and remediation instructions outlined in this report.  The following code repositories are considered in-scope for the review:   QuipuSwap: https://github.com/madsh-solutions/quipuswap-core  Specically, we examined the following Git revision for our initial review:  3c1ce6f63081059ccf7155cb9574a348aef43f78  For the initial verication and follow up review, we examined the Git revision:  f4daf9389b98eac4fb2d4326ce0647d4f4e0a6a4  For the nal verication, we examined the Git revision:  c0bd6b43bc9b3d98fb6887d946c999287c52555f  This repository was cloned for use during the audit and is linked for reference in this report:  https://github.com/LeastAuthority/quipuswap-core  All le references in this document use Unix-style paths relative to the projects root directory.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  3  This audit makes no statements or warranties and is for discussion purposes only.   Supporting Documentation  The following documentation was available to the review team:   README: https://github.com/madsh-solutions/quipuswap-core/blob/master/README.md  FA1.2 Standard (TZIP-7): https://gitlab.com/tzip/tzip/-/blob/master/proposals/tzip-7/tzip-7.md  FA2 Standard (TZIP-12): https://gitlab.com/tzip/tzip/-/blob/master/proposals/tzip-12/tzip-12.md  QuipuSwap Demo: https://quipuswap.com/  QuipuSwap Documentation: https://docs.quipuswap.com/  Areas of Concern  Our investigation focused on the following areas:   Correctness of the implementation;  Adversarial actions and other attacks on the contracts;  Potential misuse and gaming of the smart contracts;  Attacks that impacts funds, such as the draining or the manipulation of funds;  Mismanagement of funds via transactions;  Denial of Service (DoS) and security exploits that would impact the contracts intended use or  disrupt the execution of the contract;  Vulnerabilities in the smart contracts code;  Protection against malicious attacks and other ways to exploit contracts;  Inappropriate permissions and excess authority;  Data privacy, data leaking, and information integrity; and  Anything else as identied during the initial analysis phase.  Findings  General Comments  We commend the QuipuSwap development team for their achievements in implementing an ambitious system design. Additionally, we found that QuipuSwap utilized the Ligo language in interesting and innovative ways. Similar to other complex smart contract systems, QuipuSwap warrants further and ongoing analysis for potential vulnerabilities as applications in Decentralized Finance (DeFi) are rapidly evolving.  Review Scope  Our teams review of QuipuSwap covered the smart contracts system design and implementation, including conguration processes, deployment of the contracts, potential attacks resulting from the possibility for improper conguration and exploitation of the usage of lambdas, and the implementation of the standardized FA1.2 and FA2 interfaces. In addition, we examined common attack vectors against this functionality and veried the post-deployment operation of the Decentralized Exchange (DEX) contracts, such as the use of executing stored code.  Although the scope of the review was sucient, there are a few areas that have been identied throughout the report for further review and analysis. These include the use of oating point operations, the JavaScript dependencies, and the voting and veto functionality, along with a more broad exploration of the potential interactions between contracts, such as modelling them as nite state machines.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  4  This audit makes no statements or warranties and is for discussion purposes only.   System Design  Multi-stage Deployment  Our team has observed the QuipuSwap system design to be particularly complex in a number of ways. The system uses a multi-stage deployment process: it deploys the Factory contract, congures it by adding the desired functions, then uses it to deploy an additional DEX contract. This initial setup consists of different phases and relies on a number of steps being executed in a particular order, as opposed to issuing a single origination command for a typical deployment process. This process also increases the complexity of the implementation in several places, as it adds an additional level of abstraction to the code base (i.e. the contracts that are generated by the contracts found in the code base are being run as opposed to running the contracts themselves).  However, it is not clear if this multi-stage deployment process can be avoided, given the restrictions placed by Tezos on the amount of storage that can be used in a single transaction. Tezos contracts have hard-coded storage limits, which prove too low for the size of QuipuSwap contracts. Breaking up the process into multiple steps helps to ensure that each individual step stays below the storage limit. We recommend that the QuipuSwap development team explore future opportunities to simplify this approach if it is possible to do so.  Preprocessor Macros  Another source of increased complexity is the use of preprocessor macros, which congure functionality in individual components. While this design decision is warranted in that it helps avoid redundant and duplicated code throughout the system, the particular ways in which these macros are integrated throughout the code base cause the same lines of code to have different meanings in different contexts. This leads to increased diculty in reviewing or auditing the code, as a result, we suggest documenting all variations and the reasoning behind the design choices of those variations into a specication (Suggestion 1).  Token Voting Governance  The QuipuSwap Smart Contracts also use a governance system to control the baker. To our knowledge, token voting governance has not fully matured and may present incentivization challenges to effectively change state when needed. There may be a desire to extend token voting governance to other economic settings in pair contracts, which will also require careful incentive research. We encourage decentralized governance as an appealing solution to centralized power and vulnerability, which result from single points of failure. We recommend that the voting and veto functionality undergo more thorough and focused analysis.  Floating Point Operations  The oating point operations used in the QuipuSwap contracts might potentially lead to edge cases. They use arbitrary precision numbers, rounding operations, and divisions -- all of which are known to lack precision when done by computers. As a result, we recommend further manual analysis, testing, and verication of these computations.  Complex Contract Interactions  Due to the complexity of the system, more broadly exploring the potential interactions between the contracts by modelling them as nite state machines and using some form of invariant analysis would provide valuable insight into the overall security of the system.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Code Quality  We found that the code is well-organized and compartmentalized in a clean and logical way. The code has good test coverage for the intended scenarios and common failure cases. However, we recommend expanding test coverage to include all error cases. This allows for tests that purposefully fail when contracts execute them in order to determine if error conditions operate and catch problems as expected (Suggestion 4). We also suggest including additional test coverage for the functions in MetadataStorage (Suggestion 5).  Furthermore, tests in the QuipuSwap code base are currently run with npm. We recommend running tests with yarn, as it is expected to result in a less error-prone testing process (Suggestion 6). Finally, adding Continuous Integration (CI) to the development process would ensure tests are always run and help detect certain errors at an earlier stage of development (Suggestion 7). More extensive coverage of error cases allow developers and reviewers to understand both intended and unintended scenarios, thus reducing the risk of code errors that lead to security vulnerabilities.  Documentation  Due to the complexity of the system architecture, gaining a concise overview and deep understanding of the way in which individual functions work is not a simple, intuitive process. As a result, we suggest integrating additional code comments and documentation, as detailed below.  Some limited comments are present throughout the code base, however, additional and more extensive code comments would be benecial, particularly around the intent and usage of entry points and helpers (Suggestion 2). We found that error messages in the code report numeric codes, which can lead to a lack of clarity to what the error in question is and, as a result, makes troubleshooting the systems more challenging. We suggest clarifying the error message to include the causes of failure (Suggestion 3).  The existing project documentation is accurate and helpful. Nevertheless, given that certain design trade offs are required, resulting in increased system complexity, we recommend thoroughly documenting the overall system design and architecture, which would make the system more accessible to reviewers, contributors, and users of the code (Suggestion 11). In addition, better documentation of the interactions with other DeFi contracts would make the potential attack surfaces of such interactions more visible (Suggestion 9). Conducting and publishing more research on potential front-running attacks relating to Tezos would contribute towards mitigation against such attacks, even though it would not completely prevent their occurrence (Suggestion 10). As noted above, we recommend creating documentation that provides more detailed information on the intended behavior, functionality, states, and actions of the contracts, in order to facilitate a better understanding of the code by both security reviewers and contributors (Suggestion 1). Improvements to the documentation help to minimize potential human error as it relates to execution of the implementation, in addition to full comprehension by security reviewers of the code.  Dependencies  The QuipuSwap contracts are independent and self-contained such that they do not rely on external dependencies. However, we have identied several dependency concerns relating to the supporting JavaScript code used for testing and deploying the contracts. JavaScript package dependencies could be a security concern in this context, as there is no guarantee that all of them have been audited and maintained according to security best practices. We recommend that the JavaScript dependencies be further investigated and, where possible, well-known and previously audited dependencies should be used.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Additional Findings & Known Issues  Following the completion of the delivery of the Initial Audit Report, we conducted the Phase 1 Verication in which we identied one new issue and made one new suggestion.  We found that in the event that a shareholder does not interact with the contract for a period greater than thirty days, they would miss the opportunity for a reward, as the reward would not be updated with the correct frequency. As a result, we suggest tracking the number of reward cycles that have passed, so that calculating the missing reward is feasible and the opportunity for rewards can be retained (Issue A).  In addition, the QuipuSwap development team made signicant improvements to the documentation. We commend this effort and recommend including a proof-reading stage to the development of documentation, in order to eliminate grammatical errors, which would help ensure that information is being conveyed adequately, with clear and unambiguous denition (Suggestion 12).  Finally, upon request from the QuipuSwap team, we veried the resolutions to several known issues (Known Issues A - E) that were identied by the QuipuSwap team.  Specic Issues, Suggestions, & Known Issues  We list the suggestions found during the review, in the order we reported them. In most cases, remediation of an issue is preferable, but mitigation is suggested as another option for cases where a trade-off could be required.  ISSUES, SUGGESTIONS, & KNOWN ISSUES  STATUS  Issue A: Shareholders Lose Opportunity for Rewards if Not Interacting with  Resolved  Contract  Suggestion 1: Document the Specications of Contracts  Partially Resolved  Suggestion 2: Expand Code Comments  Suggestion 3: Better Dene Error Messages  Suggestion 4: Add Tests for Error Cases  Suggestion 5: Add Test Coverage for MetadataStorage  Suggestion 6: Implement Testing with yarn  Resolved  Resolved  Resolved  Resolved  Resolved  Suggestion 7: Add Continuous Integration to Development Process  Resolved  Suggestion 8: Consider using Formal Verication  Suggestion 9: Document Complex Contract Interactions  Unresolved  Resolved  Suggestion 10: Document Front-Running Attacks As They May Relate To  Resolved  Tezos  Suggestion 11: Document Overall System Architecture  Suggestion 12: Improve Documentation Readability  Resolved  Unresolved  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Known Issue A: Divestments With Zero XTZ Causes Tezos Error  Known Issue B: XTZ to Token Ratio Can Be Manipulated During\u2026  Resolved  Resolved  Known Issue C: Parameters to Liquidity Divestment Call are Ignored  Resolved  Known Issue D: Users Able To Empty Token Reserves In Transfer\u2026  Resolved  Known Issue E: High Initial Liquidity Causes Prohibitively Expensive Shares  Resolved  Issues  Issue A: Shareholders Lose Opportunity for Rewards if Not Interacting with Contract  Location  contracts/partials/MethodDex.ligo#L99  Synopsis  Every thirty days, a user is intended to receive a proper share of additional XTZ received from the delegation of the XTZ pool. This reward is provided to the user upon interaction with the contract, rather than calculated all at once. This is done to prevent a large gas cost being added to the operation for updating the reward information for all users. However, this means that a user would miss out on the reward if they do not interact with the contract for a period greater than thirty days, as the reward would not be updated with the correct frequency.  Preconditions  A user must be owed an award, but have not claimed that award via any actions with the contract that would trigger update_user_reward. Then, another reward cycle must pass, such that usually a user would be marked to receive another reward, but here the state would be unchanged due to the user already being marked.  Remediation  A possible solution would be to keep track of the number of reward cycles that have passed. If a user is several cycles behind, this will be reected in their number of shares being unchanged and would allow for calculating the missing reward.  Status  The QuipuSwap team has responded and noted that, due to the operation size limit in Tezos, they have simplied the rewards model in order to decrease complexity and mitigate baker rewards distribution issues inside the protocol. In implementing the new rewards system, they collect all the baker rewards and simple XTZ transfers on the contracts for 30 days (a single cycle) and then distribute them in the next 30 days, during which the contract collects the rewards for distribution in the next iteration. Once users receive share tokens, they begin to receive rewards proportionally to their shares in the pool. We have veried that the mechanism of dispersal has changed and is no longer subject to this issue.  Verication  Resolved.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Suggestions  Suggestion 1: Document the Specications of Contracts  Synopsis  The descriptions of major entry points contained in the README le can be considered an informal specication. However, expanding the documentation to provide more detailed information about actions that the contracts are expected to perform, intended behavior and functionality, and any illegal and/or unauthorized inputs and states they should be handling would facilitate a better understanding of the code.  Mitigation  We recommend documenting a specication of the QuipuSwap system, particularly specifying the calculations for and invariants in the following actions:   Invest liquidity;  Divest liquidity;  Conversions between tokens;  Rewards;  Withdrawals of prots;  DEX functions;  Token functions;  Vote; and  Veto.  Status  A signicant amount of documentation has been added, providing helpful information on the available functions and the possible circumstances which may result in failure.  It would additionally useful to document both the FA2 and the FA1.2 contracts, in order to easily assess the implementations adherence to the respective specications. This is of particular importance for the FA2 contracts since the FA2 standard (TZIP-12) has not yet been nalized, thus it is critical to understand what version of the specication is in use for the implementation.  Verication  Partially Resolved.  Suggestion 2: Expand Code Comments  Location  update_owner and update_metadata in contracts/main/MetadataStorage.ligo  middle_dex, middle_token, and use_default in contracts/partials/Dex.ligo  wrap_transfer_trx, set_dex_function, and set_token_function in contracts/partials/Factory.ligo  get_token_metadata_registry and update_operators in contracts/partials/MethodFA12.ligo  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_QuipuSwap_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Shareholders Lose Opportunity for Rewards if Not Interacting with", "body": "  Resolved  Contract  Suggestion 1: Document the Specications of Contracts  Partially Resolved  Suggestion 2: Expand Code Comments  Suggestion 3: Better Dene Error Messages  Suggestion 4: Add Tests for Error Cases  Suggestion 5: Add Test Coverage for MetadataStorage  Suggestion 6: Implement Testing with yarn  Resolved  Resolved  Resolved  Resolved  Resolved  Suggestion 7: Add Continuous Integration to Development Process  Resolved  Suggestion 8: Consider using Formal Verication  Suggestion 9: Document Complex Contract Interactions  Unresolved  Resolved  Suggestion 10: Document Front-Running Attacks As They May Relate To  Resolved  Tezos  Suggestion 11: Document Overall System Architecture  Suggestion 12: Improve Documentation Readability  Resolved  Unresolved  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Known Issue A: Divestments With Zero XTZ Causes Tezos Error  Known Issue B: XTZ to Token Ratio Can Be Manipulated During\u2026  Resolved  Resolved  Known Issue C: Parameters to Liquidity Divestment Call are Ignored  Resolved  Known Issue D: Users Able To Empty Token Reserves In Transfer\u2026  Resolved  Known Issue E: High Initial Liquidity Causes Prohibitively Expensive Shares  Resolved  Issues  Issue A: Shareholders Lose Opportunity for Rewards if Not Interacting with Contract  Location  contracts/partials/MethodDex.ligo#L99  Synopsis  Every thirty days, a user is intended to receive a proper share of additional XTZ received from the delegation of the XTZ pool. This reward is provided to the user upon interaction with the contract, rather than calculated all at once. This is done to prevent a large gas cost being added to the operation for updating the reward information for all users. However, this means that a user would miss out on the reward if they do not interact with the contract for a period greater than thirty days, as the reward would not be updated with the correct frequency.  Preconditions  A user must be owed an award, but have not claimed that award via any actions with the contract that would trigger update_user_reward. Then, another reward cycle must pass, such that usually a user would be marked to receive another reward, but here the state would be unchanged due to the user already being marked.  Remediation  A possible solution would be to keep track of the number of reward cycles that have passed. If a user is several cycles behind, this will be reected in their number of shares being unchanged and would allow for calculating the missing reward.  Status  The QuipuSwap team has responded and noted that, due to the operation size limit in Tezos, they have simplied the rewards model in order to decrease complexity and mitigate baker rewards distribution issues inside the protocol. In implementing the new rewards system, they collect all the baker rewards and simple XTZ transfers on the contracts for 30 days (a single cycle) and then distribute them in the next 30 days, during which the contract collects the rewards for distribution in the next iteration. Once users receive share tokens, they begin to receive rewards proportionally to their shares in the pool. We have veried that the mechanism of dispersal has changed and is no longer subject to this issue.  Verication  Resolved.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Suggestions  Suggestion 1: Document the Specications of Contracts  Synopsis  The descriptions of major entry points contained in the README le can be considered an informal specication. However, expanding the documentation to provide more detailed information about actions that the contracts are expected to perform, intended behavior and functionality, and any illegal and/or unauthorized inputs and states they should be handling would facilitate a better understanding of the code.  Mitigation  We recommend documenting a specication of the QuipuSwap system, particularly specifying the calculations for and invariants in the following actions:   Invest liquidity;  Divest liquidity;  Conversions between tokens;  Rewards;  Withdrawals of prots;  DEX functions;  Token functions;  Vote; and  Veto.  Status  A signicant amount of documentation has been added, providing helpful information on the available functions and the possible circumstances which may result in failure.  It would additionally useful to document both the FA2 and the FA1.2 contracts, in order to easily assess the implementations adherence to the respective specications. This is of particular importance for the FA2 contracts since the FA2 standard (TZIP-12) has not yet been nalized, thus it is critical to understand what version of the specication is in use for the implementation.  Verication  Partially Resolved.  Suggestion 2: Expand Code Comments  Location  update_owner and update_metadata in contracts/main/MetadataStorage.ligo  middle_dex, middle_token, and use_default in contracts/partials/Dex.ligo  wrap_transfer_trx, set_dex_function, and set_token_function in contracts/partials/Factory.ligo  get_token_metadata_registry and update_operators in contracts/partials/MethodFA12.ligo  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  Further clarications on the intent and usage of the main entry points and helpers functions would assist in reasoning about these functions and would limit the potential for misinterpreting their intended function.  Mitigation  We recommend adding or expanding code comments for the main entry points and helpers functions.  Status  Comments have been added to provide background information and context for much of the functions. In larger functions, such as launch_exchange in Factory.ligo, intermediate comments that have been added to allow for an easy understanding of the intended behavior.  Verication  Resolved.  Suggestion 3: Better Dene Error Messages  Location  Uses of failwith(01)and similar in:  contracts/partials/Factory.ligo  contracts/partials/MethodFA12.ligo  Synopsis  The current error messages resulting from failures report numeric codes, which do not make explicitly clear the reason for the error in question. Instead, a system using transparent error messages would facilitate easier understanding and troubleshooting of the failure.  Mitigation  We recommend implementing more transparent and informative error messages, such as explicit error strings or descriptions of the cause of the failure.  Status  The error messages have been updated and more clearly dened, providing the user with information such as where the failure occurred and the reasoning for its occurrence.  Verication  Resolved.  Suggestion 4: Add Tests for Error Cases  Location  /test  Synopsis  For each use case, tests are currently run for a single successful scenario and check for expected values when the system is used as intended, but are absent for expected failures.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   For example, the test for swapping tokens does a single swap and checks that the expected tokens are moved in the correct way. This could be expanded to encompass several scenarios where failure is expected, such as attempting to swap tokens that do not exist for the pair, trying to swap Tezos in a token only swap, or trying to swap amounts that are not aligned with the provided liquidity.  Finally, comprehensive test coverage helps to identify simple errors and prevents functionality from breaking when new code changes are introduced into the implementation, which minimizes the potential for errors leading to security vulnerabilities.  Mitigation  Create tests that will purposefully fail when the contract executes them, in order to explore if error conditions operate and catch problems as expected.  Status  The test suite has been updated, including a number of expected failure cases along with correct functioning under intended usage.  Verication  Resolved.  Suggestion 5: Add Test Coverage for MetadataStorage  Location  /test  Synopsis  The test suite does not exercise functions implemented in contracts/main/MetadataStorage.ligo.  Mitigation  Expand test coverage to exercise functions in contracts/main/MetadataStorage.ligo.  Status  Tests have been added to cover the MetadataStorage contract, including both successful expected behavior and failure cases.  Verication  Resolved.  Suggestion 6: Implement Testing with yarn  Synopsis  Running tests via npm run test has been an error-prone process. Our team made several attempts to run npm run test in a variety of environments, including local and cloud virtual machines, different operating systems, and Docker. In each of these instances, npm failed to install certain dependencies necessary in order to run the test suite. The QuipuSwap development team suggested using yarn test (present in pull request 11 of QuipuSwaps GitHub project) as an alternative to npm run test, which has worked as a more suitable alternative.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation  Switch to yarn for running tests.  Status  The test suite has been updated and now runs using yarn.  Verication  Resolved.  Suggestion 7: Add Continuous Integration to Development Process  Synopsis  The QuipuSwap project on GitHub lacks CI to run tests on new commits in the project. Implementing CI helps to prevent certain classes of issues early on in the development process.  Mitigation  Use CI to automatically run tests on new commits to the GitHub repository.  Status  QuipuSwap now utilizes Github Actions for continuous integration for all contracts.  Verication  Resolved.  Suggestion 8: Consider using Formal Verication  Location  contracts/partial/Factory.ligo  Synopsis  Since QuipuSwap performs computations that involve arithmetic rounding and arbitrary precision numbers, formal verication of those specic computations may help prevent a subclass of correctness issues. We recognize that formal verication will not be able to detect and prevent all classes of security and correctness issues, as focusing only on safety properties of specic areas of execution may not be able to fully dene complex state machines or their interaction with other contracts. Logic issues may still arise even with extensive formal verication as illustrated by the recent Aave vulnerability.  Mitigation  We recommend that formal verication be considered for QuipuSwap. Projects similar to QuipuSwap, such as Uniswap and Dexter, have been formally veried. At this time, we do not have a particular recommendation for a specic formal verication tool or approach, however, we recommend that various approaches be further investigated.  Status  The QuipuSwap development team is investigating formal verication for Quipuswap, and will reassess the possibility of utilizing it at a later stage in the project. They have stated that they agree it is an important step for ensuring the validity and correctness of contracts on the Tezos blockchain.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Unresolved.  Suggestion 9: Document Complex Contract Interactions  Synopsis  Explicit documentation on how the QuipuSwap exchange may interact with other DeFi contracts would make the potential attack surfaces of such interactions visible.  For example, if a contract relies on the QuipuSwap exchange rates for a price feed as an oracle, they may be attacked by price manipulations if price checkpoints and the ability to time weight the price feed is not present. This attack could be facilitated with a ash loan.  Mitigation  We suggest documenting the capabilities of other projects to use the QuipuSwap platform and the mitigation methods that it provides, if applicable, against known DeFi oracle price manipulation attacks.  Status  The documentation has been updated so that it provides some insights into the limitations of QuipuSwap, alongside its features and  expected interactions with the larger DeFi ecosystem. The documentation includes additional information on the various participants that make up a QuipuSwap exchange and their interactions.  Verication  Resolved.  Suggestion 10: Document Front-Running Attacks As They May Relate To Tezos  Synopsis  Issues associated with bots attempting to order transactions in sandwich attacks (front-running and back-running) and other front-running attacks have been prevalent in the Ethereum DeFi ecosystem. Front-running is dicult to address in Ethereum, or arguably any open ledger, due to anonymity/pseudo-anonymity, the predictable nature of transaction ordering in the client, public nature of the memory pool of transactions, and the inability to obfuscate the contract code.  Mitigation  This is an interesting problem that may have different consequences on the Tezos ledger than the Ethereum ledger. We suggest doing more research in the area of front-running attacks on the Tezos ledger and referencing the latest known research on the Ethereum ledger, specically related to sandwich attacks. While this research does not provide a solution to sandwich attacks that are free from user experience tradeoffs, documenting the challenge on the QuipuSwap DEX as it relates to the sandwich attack would be a rst step towards mitigation.  Status  The QuipuSwap development team provided existing papers investigating the possibility of front-running attacks and an analysis of the QuipuSwap governance system. Though the existence of these documents resolves this issue, we recommend including them in the QuipuSwap documentation to make them more easily accessible.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  Suggestion 11: Document Overall System Architecture  Synopsis  In addition to the existing documentation on the API endpoints, documenting the high-level functionality of the system as a whole and how it is expected to be used would help explain some under-documented functionality (e.g.what problems voting is intended to solve) to end users, security reviewers, and potential developers.  Mitigation  We recommend accompanying the architectural diagram with a less-technical introduction to the project and its goals, as well as a high-level description of the different functionality and how it is expected to work within the system.  Status  The QuipuSwap online documentation has been updated to provide additional information on the system architecture, including architecture diagrams, high-level entity interaction diagrams, and QuipuSwap's smart contract API.  Verication  Resolved.  Suggestion 12: Improve Documentation Readability  Location  https://docs.quipuswap.com/  Synopsis  The documentation and code comments have a number of grammatical errors, which may result in confusion about the intended meaning. For example, the Prices and Fees section has a lot of helpful information, but the process of understanding it is slowed due to assumptions of knowledge and terminology, and grammatical errors adding further ambiguity.  Mitigation  Adding a proof-reading stage to the development of documentation, optimally by a technical reader who is not working on the QuipuSwap project, would help ensure that information is being conveyed adequately, with clear and unambiguous denition.  Status  Improvements to the documentation readability have not been made at the time of this verication. We encourage the QuipuSwap team to adopt documentation best practices, as suggested, in order to improve readability and understanding of their system.  Verication  Unresolved.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Known Issues  Known Issue A: Divestments With Zero XTZ Causes Tezos Error  Location  contracts/partials/MethodDex.ligo#L569  Synopsis  If a user calls divest_liquidity with a small number of shares, such that the amount of XTZ returned would be zero, Tezos generates an error message due to an empty transaction.  Remediation  Prevent divestments from amounting to zero XTZ, which will prevent this condition from being raised and avoid triggering the undened behavior.  Status  Users have been prevented from withdrawing if the divested XTZ is equal to zero.  Verication  Resolved.  Known Issue B: XTZ to Token Ratio Can Be Manipulated During Operation  Location  contracts/partials/MethodDex.ligo#L569  Synopsis  When the user divests liquidity, the price of the token will almost always need to be truncated down, which will cause the ratio, or the invariant, to change over time. This can cause the token to effectively increase in value. There could also be the opposite effect such that, when divesting liquidity, the amount of shares is so small that the amount of tokens withdrawn would be zero. Compounding many operations of withdrawing XTZ without withdrawing tokens could result in dramatic changes in ratio.  Remediation  Preventing the withdrawal of tokens when the number of tokens divested would be zero prevents the situation where the ratio change could be dramatic, with many compounding operations.  Since oating point operations will always be imperfect, changes of value during divestment are unavoidable. For example, whether withdrawing 2.1 and 2.9 tokens, it will be rounded down to 2.0 tokens. The value  of XTZ lost in this operation  could be a large difference depending on the ratio. While this could be accepted as standard operation of the contract, a check could be put in place to ensure that this difference does not exceed a specic threshold.  As the invariant is updated after operations that modify the XTZ in reserve, this should not cause a desynchronization with the value of the token during contract operation. In general, we do not believe that this value should skew too much in any one direction. Many operations are present that modify the ratio in various directions and there will be nancial incentives that correct this over time.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   Status  A check has been added to prevent the withdrawal of XTZ without tokens. Currently, there are no checks in place regarding the divergence implicit with divesting liquidity, however, we do not consider this to present negative security implications.  Verication  Resolved.  Known Issue C: Parameters to Liquidity Divestment Call are Ignored  Location  contracts/partials/MethodDex.ligo#L569  Synopsis  Calls to divest_liquidity accept min_tez and min_tokens parameters, but no check is performed to ensure the divested amount conrms to the users expectation.  Remediation  Add checks to ensure that the XTZ and tokens being divested are equal to or greater than the specied values.  Status  The divest_liquidity function now includes a check to make sure the divested amounts conrm to the users expectation.  Verication  Resolved.  Known Issue D: Users Able T", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_QuipuSwap_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Shareholders Lose Opportunity for Rewards if Not Interacting", "body": " with  Resolved  Contract  Suggestion 1: Document the Specications of Contracts  Partially Resolved  Suggestion 2: Expand Code Comments  Suggestion 3: Better Dene Error Messages  Suggestion 4: Add Tests for Error Cases  Suggestion 5: Add Test Coverage for MetadataStorage  Suggestion 6: Implement Testing with yarn  Resolved  Resolved  Resolved  Resolved  Resolved  Suggestion 7: Add Continuous Integration to Development Process  Resolved  Suggestion 8: Consider using Formal Verication  Suggestion 9: Document Complex Contract Interactions  Unresolved  Resolved  Suggestion 10: Document Front-Running Attacks As They May Relate To  Resolved  Tezos  Suggestion 11: Document Overall System Architecture  Suggestion 12: Improve Documentation Readability  Resolved  Unresolved  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Known Issue A: Divestments With Zero XTZ Causes Tezos Error  Known Issue B: XTZ to Token Ratio Can Be Manipulated During\u2026  Resolved  Resolved  Known Issue C: Parameters to Liquidity Divestment Call are Ignored  Resolved  Known Issue D: Users Able To Empty Token Reserves In Transfer\u2026  Resolved  Known Issue E: High Initial Liquidity Causes Prohibitively Expensive Shares  Resolved  Issues  Issue A: Shareholders Lose Opportunity for Rewards if Not Interacting with Contract  Location  contracts/partials/MethodDex.ligo#L99  Synopsis  Every thirty days, a user is intended to receive a proper share of additional XTZ received from the delegation of the XTZ pool. This reward is provided to the user upon interaction with the contract, rather than calculated all at once. This is done to prevent a large gas cost being added to the operation for updating the reward information for all users. However, this means that a user would miss out on the reward if they do not interact with the contract for a period greater than thirty days, as the reward would not be updated with the correct frequency.  Preconditions  A user must be owed an award, but have not claimed that award via any actions with the contract that would trigger update_user_reward. Then, another reward cycle must pass, such that usually a user would be marked to receive another reward, but here the state would be unchanged due to the user already being marked.  Remediation  A possible solution would be to keep track of the number of reward cycles that have passed. If a user is several cycles behind, this will be reected in their number of shares being unchanged and would allow for calculating the missing reward.  Status  The QuipuSwap team has responded and noted that, due to the operation size limit in Tezos, they have simplied the rewards model in order to decrease complexity and mitigate baker rewards distribution issues inside the protocol. In implementing the new rewards system, they collect all the baker rewards and simple XTZ transfers on the contracts for 30 days (a single cycle) and then distribute them in the next 30 days, during which the contract collects the rewards for distribution in the next iteration. Once users receive share tokens, they begin to receive rewards proportionally to their shares in the pool. We have veried that the mechanism of dispersal has changed and is no longer subject to this issue.  Verication  Resolved.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Suggestions  Suggestion 1: Document the Specications of Contracts  Synopsis  The descriptions of major entry points contained in the README le can be considered an informal specication. However, expanding the documentation to provide more detailed information about actions that the contracts are expected to perform, intended behavior and functionality, and any illegal and/or unauthorized inputs and states they should be handling would facilitate a better understanding of the code.  Mitigation  We recommend documenting a specication of the QuipuSwap system, particularly specifying the calculations for and invariants in the following actions:   Invest liquidity;  Divest liquidity;  Conversions between tokens;  Rewards;  Withdrawals of prots;  DEX functions;  Token functions;  Vote; and  Veto.  Status  A signicant amount of documentation has been added, providing helpful information on the available functions and the possible circumstances which may result in failure.  It would additionally useful to document both the FA2 and the FA1.2 contracts, in order to easily assess the implementations adherence to the respective specications. This is of particular importance for the FA2 contracts since the FA2 standard (TZIP-12) has not yet been nalized, thus it is critical to understand what version of the specication is in use for the implementation.  Verication  Partially Resolved.  Suggestion 2: Expand Code Comments  Location  update_owner and update_metadata in contracts/main/MetadataStorage.ligo  middle_dex, middle_token, and use_default in contracts/partials/Dex.ligo  wrap_transfer_trx, set_dex_function, and set_token_function in contracts/partials/Factory.ligo  get_token_metadata_registry and update_operators in contracts/partials/MethodFA12.ligo  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  Further clarications on the intent and usage of the main entry points and helpers functions would assist in reasoning about these functions and would limit the potential for misinterpreting their intended function.  Mitigation  We recommend adding or expanding code comments for the main entry points and helpers functions.  Status  Comments have been added to provide background information and context for much of the functions. In larger functions, such as launch_exchange in Factory.ligo, intermediate comments that have been added to allow for an easy understanding of the intended behavior.  Verication  Resolved.  Suggestion 3: Better Dene Error Messages  Location  Uses of failwith(01)and similar in:  contracts/partials/Factory.ligo  contracts/partials/MethodFA12.ligo  Synopsis  The current error messages resulting from failures report numeric codes, which do not make explicitly clear the reason for the error in question. Instead, a system using transparent error messages would facilitate easier understanding and troubleshooting of the failure.  Mitigation  We recommend implementing more transparent and informative error messages, such as explicit error strings or descriptions of the cause of the failure.  Status  The error messages have been updated and more clearly dened, providing the user with information such as where the failure occurred and the reasoning for its occurrence.  Verication  Resolved.  Suggestion 4: Add Tests for Error Cases  Location  /test  Synopsis  For each use case, tests are currently run for a single successful scenario and check for expected values when the system is used as intended, but are absent for expected failures.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   For example, the test for swapping tokens does a single swap and checks that the expected tokens are moved in the correct way. This could be expanded to encompass several scenarios where failure is expected, such as attempting to swap tokens that do not exist for the pair, trying to swap Tezos in a token only swap, or trying to swap amounts that are not aligned with the provided liquidity.  Finally, comprehensive test coverage helps to identify simple errors and prevents functionality from breaking when new code changes are introduced into the implementation, which minimizes the potential for errors leading to security vulnerabilities.  Mitigation  Create tests that will purposefully fail when the contract executes them, in order to explore if error conditions operate and catch problems as expected.  Status  The test suite has been updated, including a number of expected failure cases along with correct functioning under intended usage.  Verication  Resolved.  Suggestion 5: Add Test Coverage for MetadataStorage  Location  /test  Synopsis  The test suite does not exercise functions implemented in contracts/main/MetadataStorage.ligo.  Mitigation  Expand test coverage to exercise functions in contracts/main/MetadataStorage.ligo.  Status  Tests have been added to cover the MetadataStorage contract, including both successful expected behavior and failure cases.  Verication  Resolved.  Suggestion 6: Implement Testing with yarn  Synopsis  Running tests via npm run test has been an error-prone process. Our team made several attempts to run npm run test in a variety of environments, including local and cloud virtual machines, different operating systems, and Docker. In each of these instances, npm failed to install certain dependencies necessary in order to run the test suite. The QuipuSwap development team suggested using yarn test (present in pull request 11 of QuipuSwaps GitHub project) as an alternative to npm run test, which has worked as a more suitable alternative.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation  Switch to yarn for running tests.  Status  The test suite has been updated and now runs using yarn.  Verication  Resolved.  Suggestion 7: Add Continuous Integration to Development Process  Synopsis  The QuipuSwap project on GitHub lacks CI to run tests on new commits in the project. Implementing CI helps to prevent certain classes of issues early on in the development process.  Mitigation  Use CI to automatically run tests on new commits to the GitHub repository.  Status  QuipuSwap now utilizes Github Actions for continuous integration for all contracts.  Verication  Resolved.  Suggestion 8: Consider using Formal Verication  Location  contracts/partial/Factory.ligo  Synopsis  Since QuipuSwap performs computations that involve arithmetic rounding and arbitrary precision numbers, formal verication of those specic computations may help prevent a subclass of correctness issues. We recognize that formal verication will not be able to detect and prevent all classes of security and correctness issues, as focusing only on safety properties of specic areas of execution may not be able to fully dene complex state machines or their interaction with other contracts. Logic issues may still arise even with extensive formal verication as illustrated by the recent Aave vulnerability.  Mitigation  We recommend that formal verication be considered for QuipuSwap. Projects similar to QuipuSwap, such as Uniswap and Dexter, have been formally veried. At this time, we do not have a particular recommendation for a specic formal verication tool or approach, however, we recommend that various approaches be further investigated.  Status  The QuipuSwap development team is investigating formal verication for Quipuswap, and will reassess the possibility of utilizing it at a later stage in the project. They have stated that they agree it is an important step for ensuring the validity and correctness of contracts on the Tezos blockchain.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Unresolved.  Suggestion 9: Document Complex Contract Interactions  Synopsis  Explicit documentation on how the QuipuSwap exchange may interact with other DeFi contracts would make the potential attack surfaces of such interactions visible.  For example, if a contract relies on the QuipuSwap exchange rates for a price feed as an oracle, they may be attacked by price manipulations if price checkpoints and the ability to time weight the price feed is not present. This attack could be facilitated with a ash loan.  Mitigation  We suggest documenting the capabilities of other projects to use the QuipuSwap platform and the mitigation methods that it provides, if applicable, against known DeFi oracle price manipulation attacks.  Status  The documentation has been updated so that it provides some insights into the limitations of QuipuSwap, alongside its features and  expected interactions with the larger DeFi ecosystem. The documentation includes additional information on the various participants that make up a QuipuSwap exchange and their interactions.  Verication  Resolved.  Suggestion 10: Document Front-Running Attacks As They May Relate To Tezos  Synopsis  Issues associated with bots attempting to order transactions in sandwich attacks (front-running and back-running) and other front-running attacks have been prevalent in the Ethereum DeFi ecosystem. Front-running is dicult to address in Ethereum, or arguably any open ledger, due to anonymity/pseudo-anonymity, the predictable nature of transaction ordering in the client, public nature of the memory pool of transactions, and the inability to obfuscate the contract code.  Mitigation  This is an interesting problem that may have different consequences on the Tezos ledger than the Ethereum ledger. We suggest doing more research in the area of front-running attacks on the Tezos ledger and referencing the latest known research on the Ethereum ledger, specically related to sandwich attacks. While this research does not provide a solution to sandwich attacks that are free from user experience tradeoffs, documenting the challenge on the QuipuSwap DEX as it relates to the sandwich attack would be a rst step towards mitigation.  Status  The QuipuSwap development team provided existing papers investigating the possibility of front-running attacks and an analysis of the QuipuSwap governance system. Though the existence of these documents resolves this issue, we recommend including them in the QuipuSwap documentation to make them more easily accessible.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  Suggestion 11: Document Overall System Architecture  Synopsis  In addition to the existing documentation on the API endpoints, documenting the high-level functionality of the system as a whole and how it is expected to be used would help explain some under-documented functionality (e.g.what problems voting is intended to solve) to end users, security reviewers, and potential developers.  Mitigation  We recommend accompanying the architectural diagram with a less-technical introduction to the project and its goals, as well as a high-level description of the different functionality and how it is expected to work within the system.  Status  The QuipuSwap online documentation has been updated to provide additional information on the system architecture, including architecture diagrams, high-level entity interaction diagrams, and QuipuSwap's smart contract API.  Verication  Resolved.  Suggestion 12: Improve Documentation Readability  Location  https://docs.quipuswap.com/  Synopsis  The documentation and code comments have a number of grammatical errors, which may result in confusion about the intended meaning. For example, the Prices and Fees section has a lot of helpful information, but the process of understanding it is slowed due to assumptions of knowledge and terminology, and grammatical errors adding further ambiguity.  Mitigation  Adding a proof-reading stage to the development of documentation, optimally by a technical reader who is not working on the QuipuSwap project, would help ensure that information is being conveyed adequately, with clear and unambiguous denition.  Status  Improvements to the documentation readability have not been made at the time of this verication. We encourage the QuipuSwap team to adopt documentation best practices, as suggested, in order to improve readability and understanding of their system.  Verication  Unresolved.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Known Issues  Known Issue A: Divestments With Zero XTZ Causes Tezos Error  Location  contracts/partials/MethodDex.ligo#L569  Synopsis  If a user calls divest_liquidity with a small number of shares, such that the amount of XTZ returned would be zero, Tezos generates an error message due to an empty transaction.  Remediation  Prevent divestments from amounting to zero XTZ, which will prevent this condition from being raised and avoid triggering the undened behavior.  Status  Users have been prevented from withdrawing if the divested XTZ is equal to zero.  Verication  Resolved.  Known Issue B: XTZ to Token Ratio Can Be Manipulated During Operation  Location  contracts/partials/MethodDex.ligo#L569  Synopsis  When the user divests liquidity, the price of the token will almost always need to be truncated down, which will cause the ratio, or the invariant, to change over time. This can cause the token to effectively increase in value. There could also be the opposite effect such that, when divesting liquidity, the amount of shares is so small that the amount of tokens withdrawn would be zero. Compounding many operations of withdrawing XTZ without withdrawing tokens could result in dramatic changes in ratio.  Remediation  Preventing the withdrawal of tokens when the number of tokens divested would be zero prevents the situation where the ratio change could be dramatic, with many compounding operations.  Since oating point operations will always be imperfect, changes of value during divestment are unavoidable. For example, whether withdrawing 2.1 and 2.9 tokens, it will be rounded down to 2.0 tokens. The value  of XTZ lost in this operation  could be a large difference depending on the ratio. While this could be accepted as standard operation of the contract, a check could be put in place to ensure that this difference does not exceed a specic threshold.  As the invariant is updated after operations that modify the XTZ in reserve, this should not cause a desynchronization with the value of the token during contract operation. In general, we do not believe that this value should skew too much in any one direction. Many operations are present that modify the ratio in various directions and there will be nancial incentives that correct this over time.  Security Audit Report | QuipuSwap Smart Contracts | Tezos Foundation 9 March 2021 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   Status  A check has been added to prevent the withdrawal of XTZ without tokens. Currently, there are no checks in place regarding the divergence implicit with divesting liquidity, however, we do not consider this to present negative security implications.  Verication  Resolved.  Known Issue C: Parameters to Liquidity Divestment Call are Ignored  Location  contracts/partials/MethodDex.ligo#L569  Synopsis  Calls to divest_liquidity accept min_tez and min_tokens parameters, but no check is performed to ensure the divested amount conrms to the users expectation.  Remediation  Add checks to ensure that the XTZ and tokens being divested are equal to or greater than the specied values.  Status  The divest_liquidity function now includes a check to make sure the divested amounts conrm to the users expectation.  Verication  Resolved.  Known Issue D: Users A", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_QuipuSwap_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Data Is Stored Unencrypted in localstorage", "body": "  Location  src/utils/localStorage.ts  Synopsis  The SafeRoots Snap uses localstorage property to store application-specic data (namely, the authenticated-address and theme). The data is stored unencrypted in plaintext format.  Impact  Storing sensitive information in local storage is not advisable, as any user with local machine privileges or any browser extension with enough permission can potentially bypass or access the stored data.  Preconditions  This Issue is likely if an attacker gains access to the lesystem with enough privilege or if a malicious browser extension with enough permission is installed.  Remediation  We recommend always encrypting application-specic data and metadata stored in localStorage with a strong encryption scheme, as recommended by the National Institute of Standards and Technology (NIST) in [Dworkin07]. MetaMasks snap_getentropy function can be utilized as a source of entropy to create the encryption secret key, as it is both Snap and user account specic.  Alternatively, we recommend reevaluating the overall design of the system, such that it better utilizes the security features provided by the MetaMask Snaps API. This can be achieved by moving some of the sensitive dApp components that handle the storage of data and authentication into the Snaps execution environment. This approach would allow the dApp to utilize all of the security features provided by MetaMask's Snap API, in addition to allowing developers to impose restrictions by conguring permissions within a sandboxed execution environment.  Status  The Saferoot Snap development team has changed the design of the system by eliminating the need for localStorage. Instead, the team currently solely relies on the backend to fully manage session-based authentication.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/staging_labs_saferoot_snap_final_audit_report_least-authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Usage of Vulnerable Dependencies", "body": "  Location  packages/site/package.json  Security Audit Report | MetaMask Snap | Staging Labs 28 August 2023 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  Analyzing package.json for dependency versions using npm audit shows that the dependencies used in the MetaMask Snap have 9 reported known vulnerabilities (2 Moderate, 6 High, 1 Critical).  Impact  Using unmaintained dependencies or packages with known vulnerabilities may lead to critical security vulnerabilities in the codebase.  Remediation  We recommend following a process that emphasizes secure dependency usage to avoid introducing vulnerabilities to the MetaMask Snap and to mitigate supply chain attacks, which includes:   Manually reviewing and assessing currently-used dependencies;  Upgrading dependencies with known vulnerabilities to patched versions with xes;  Pinning dependencies to secure versions when upgrading vulnerable dependencies to secure  ones, including pinning build-level dependencies in the package.json le to a specic version;   Only upgrading dependencies upon careful internal review for potential backward compatibility  issues and vulnerabilities; and   Including Automated Dependency auditing reports in the projects CI/CD workow.  Status  According to the npm audit, some of the dependencies used are still considered vulnerable, despite the fact that the Saferoot Snap development team updated them to the latest versions. Since the team has implemented a dependency management process and included it in their development workow, we consider this Issue resolved.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/staging_labs_saferoot_snap_final_audit_report_least-authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Key Generation Entropy Source Fallback to  Math.random()", "body": "   Location   https://github.com/LeastAuthority/bls-keygen/blob/master/src/index.ts#L12   https://github.com/bcoin-org/bcrypto/blob/master/lib/js/random.js#L21-L22   https://github.com/bcoin-org/bcrypto/blob/master/lib/js/random.js#L157-L167   Synopsis   BLS key generation uses a third party library, bcrypto, to create the key. Bcryptos  randomBytes()  function unsafely and silently falls back to using  Math.random()  as the entropy source instead of native  crypto  based on the inclusion of a property in the global scope.   Impact   Critical.  Math.random()  is not a cryptographically secure random number generator and its use for  anything outside of testing significantly compromises the integrity of generated keys.   Preconditions   An attacker would need to have exploited some type of script injection vulnerability - either XSS, malicious  extensions, or rogue dependency.    Feasibility   Low-Medium. The feasibility of such an attack largely depends on the deployment of the code. If running  as a regular web application, the attack surface may be much wider than if running as a browser  extension with its own global context. In addition, many other factors such as browser, extensions  installed, and other factors may radically change the feasibility of this attack for better or worse.   Technical Details   Assuming access to the global scope, an attacker could then nullify the global  crypto.getRandomValues()  function (or if the user is running the application in a  browser that does  not yet support the WebCrypto API ). As a result, the library will automatically and silently fallback to using  Math.random()  if the attacker also satisfies the check  !process.browser &&  process.env.NODE_TEST === '1' .    Security Audit Report | Utility Libraries | ChainSafe 23 March 2020 by Least Authority TFA GmbH   4   This audit makes no statements or warranties and is for discussion purposes only.        It is true that if an attacker already has access to the global scope they could likely wreak more havoc  than merely reducing the integrity of the RNG used for keygen, perhaps overriding  crypto.getRandomValues()  to return a static private key they control. However, an attack such as  this is far more likely to be noticed sooner than more covertly reducing the entropy used to generate many  users keys.   Mitigation   We have opened a  ticket upstream with bcrypto  to remove the use of  Math.random()  from the  conditional path in the module and place that testing code in the test suite instead. This would at least  prevent the silent compromise of the entropy source by manipulation of the global object.    In the meantime, and perhaps in addition to such an upstream fix, calling  Object.freeze(window.crypto)  to prevent other scripts from attempting to override the  getRandomValues  method. Additionally, having your own check for WebCrypto support is a good path.  Using the same check that bcrypto uses:   const crypto = global.crypto || global.msCrypto;    const HAS_CRYPTO = crypto && typeof crypto.getRandomValues ===  'function';   Performing this check before calling  randomBytes()  and throwing an exception or using SJCL or  another crypto library if no crypto support exists is a good patch until something is done upstream.   Remediation   Ultimately, this issue is about being resilient to script injection attacks. This is an area of active research,  but great progress has been made with SES (Secure EcmaScript), such as  Secure EcmaScript Shim  and  LavaMoat . Remediation of this issue boils down to further developments and stability in these (and  perhaps other) projects, browser-native secure execution sandboxes, etc.   Status   This issue was also reported  upstream in bcrypto  and was  fixed in bcrypt o . As a result,  Math.random() will no longer be a possible fall back path in the case of global scope tampering.  Tampering with global variables will now lead to an exception instead of possible silent compromise of  the entropy source for keys.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-ChainSafe-Utility-Libraries-Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Missing Check in addConsent Function", "body": "  Location  contracts/ConsentRegistry.sol#L17-L23  Synopsis  It is possible to register a consent with zero consentHash. However, it is not possible to activate or deactivate a consent with zero consentHash.  Impact  A valid consent may be added by mistake, with a zero consentHash, which is not possible to activate. In this case, activateConsent would revert with an error message.  Preconditions  The consentHash passed to the addConsent function is zero.  Mitigation  We recommend implementing a check in the addConsent function to prevent the adding of a consent with zero consentHash.  Status  The Data Lake team implemented a check, which reverts on zero consentHash.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/221222_Data_Lake_Consents_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Potential Single Point of Failure with Hardcoded Matrix Servers", "body": "    Location   beacon-sdk/src/transports/P2PCommunicationClient.ts    Synopsis   The current implementation relies on a single, hard coded Matrix server to mediate communication  between all applications using the functionality of Beacon SDK. This represents a single point of failure  and, as a result, if this server goes offline (e.g. to perform routine maintenance), this will result in a loss of  functionality for all Beacon-enabled applications.    In addition, relying on a single server prevents utilizing the redundant messaging functionality of Beacon,  leaving this behavior effectively untested.     Security Audit Report | Beacon SDK | Tezos Foundation 8 October 2020 by Least Authority TFA GmbH   4   This audit makes no statements or warranties and is for discussion purposes only.          Impact   If the hard coded Matrix server goes offline, all applications using this library would be unable to  communicate.   Mitigation   An initial approach to mitigate this issue would be to add additional redundant servers that are hosted by  the Beacon SDK development team. While this will make the operation much less fragile, it places an  increased amount of responsibility on the development team to ensure that multiple servers are always  up, running properly, and well maintained.    In addition to this approach, it would be useful to allow users of the Beacon SDK to supply additional  Matrix servers that they wish to use for redundancy or alternative servers they wish to maintain  themselves. This would assist in sharing or shifting the responsibility of server uptime to multiple parties  and that decentralization will result in a more stable and secure operation.    Status   The Papers team has issued a  commit  addressing this issue. As a result, both the  WalletClient  and  DAppClient  are configurable so that users are able to provide custom Matrix server URLs. If a custom  URL is not provided, the Beacon SDK will use the predefined default Matrix server URL.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Beacon_SDK_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Provided Tezos Networks Could Run Over Unsecured HTTP", "body": "    Location   src/types/beacon/Network.ts   Synopsis   When a user  provides a custom configuration for connecting to a Tezos node , this connection can be  specified to take place over HTTP. Since this communication is unencrypted, it could be read over the  network and could be subject to man-in-the-middle attacks without authentication.    Impact   In the most severe cases with HTTP, traffic could be intercepted by a third party, providing invalid  responses and making the application believe that some actions have taken place when they have not.  This is likely to cause applications to end up in undefined states, unless special precautions have been  taken to avoid this.    Preconditions   End-user provides a URL using the HTTP protocol, rather than HTTPS.    Mitigation   The following mitigation strategies are possible:    Ensure that provided URLs do not begin with  http:// ; or   Do not allow users to provide the protocol for URLs, instead forcing HTTPS.   Security Audit Report | Beacon SDK | Tezos Foundation 8 October 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.        Remediation   Add a unit test for this specific case and ensure failure in the case of a provided URL using the HTTP  protocol.    Status   The Papers team has issued a  commit  partially addressing this issue.    The Beacon SDK  documentation  has been updated to recommend that prospective developers should  check and warn users whenever an insecure Tezos node RPC URL is being used.    However, the Papers team has chosen not to enforce the use of HTTPS, given that developers may want  to enable local testing of applications using Beacon SDK, utilizing the HTTP protocol, and setting up a  secure connection would require considerable effort. As a result, we recommend that the Papers team  implement warnings in the User Interface (UI) when an insecure Tezos node RPC URL is being used, in  order to make developers and end users aware of potentially insecure communication.   Verification   Partially Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Beacon_SDK_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Avoid Conversion Operations on Generated Keys", "body": "    Location   beacon-sdk/src/utils/crypto.ts   Synopsis   Beacon SDKs encrypted messages system involves generating a cryptographic key of one type  (ed25519), and then converting it to a different type (curve25519) under certain situations. The  conversion between ed25519 and curve25519 keys is not considered to be well defined and the libsodium  documentation itself advises against doing this:  https://doc.libsodium.org/advanced/ed25519-curve25519    Impact   While the impact is unclear, the behavior does not appear to be considered or well-defined. As a result, the  consequences may potentially range from signatures forged by an attacker to an attacker being able to  compute a shared Diffie-Hellman secret they do not have a private key for, but observed messages  signatures.   Mitigation   Rather than converting from ed25519 keys to curve25519 keys when encryption needs to be performed, a  curve25519 key can be generated instead, alongside the initial ed25519 key with the  crypto_kx_seed_keypair  function in libsodium. Having a separate dedicated key for signing will  avoid any potential issues that could arise from this conversion.   Remediation   Ensuring that the  crypto_sign_ed25519_sk_to_curve25519  and  crypto_sign_ed25519_pk_to_curve25519  keys are not present in the codebase and using a  specifically generated key pair instead.    Security Audit Report | Beacon SDK | Tezos Foundation 8 October 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.        Status   Due to the added complexity of using two seperate keypairs, the Papers team has chosen not to  implement the mitigation of this issue and decided to keep the current implementation instead. We  suggest that the Papers team reconsider implementing the mitigation or remediation in the future.    Verification   Unresolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Beacon_SDK_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Use of a Cryptographically Insecure RNG", "body": "   Location   beacon-sdk/src/utils/generate-uuid.ts   Synopsis   The Globally Unique Identifier (GUID) uniqueness relies on the underlying Random Number Generator  (RNG).  generateGUID()  generates GUIDs using the browser cryptographically strong RNG. However, it  uses JavaScripts  Math.random()  when this functionality is unavailable.  Math.random()  is not a  secure source of entropy and its usage should be avoided in such cases.   Impact   Implementation of  Math.random()  does not have sufficient entropy and leaves an opportunity for  collisions. This is important because among other things, the GUID is used to create the initial key pairs.   Remediation   Utilize crypto API to generate the seeds instead of using  Math.random() , or replace the  generate-uuid.ts  code with a call to  a well-maintained, cross-platform, and a cryptographically  strong RNG utilizing library to generate GUID/seed (i.e. uuid.js).   Status   The Papers team has issued a  commit  addressing this issue. As a result, the Beacon SDKs  generateGUID()  function now always uses libsoduims  randombytes_buf() , which is considered a  secure RNG.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Beacon_SDK_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Low Test Coverage on Security Critical Packages", "body": "    Location   All locations (client, transports, managers, matrix-client, utils/crypto.ts)   Synopsis   The automated testing coverage is insufficient and may lead to future bugs and security issues. Certain  areas of complexity, such as the cryptographic utility functions, would benefit from having lower-level unit  tests to ensure correct the behavior of individual functions.   Impact   The low overall testing coverage may lead to mergers of faulty code changes and potential security  vulnerabilities.    Security Audit Report | Beacon SDK | Tezos Foundation 8 October 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.          Mitigation   We recommend following the npm-generated coverage reports and ensuring that all present classes and  methods have associated tests. The test suite should be incorporated into a continuous integration  system such as  Travis CI  to allow early detection of bugs upon changes made to the Beacon SDKs code  base.     Remediation   Use of  npm test s coverage reports is helpful in determining what code is not being covered in the  existing test suite and helps determine if any existing coverage has become inadequate.     Status   The Papers team has issued a  commit , which significantly increases the overall unit test coverage ratio.  The unit tests added cover critical security hotspots. We recommend that the Papers team maintain a  good unit test coverage ratio as they implement new features and add more code.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Beacon_SDK_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Deposited Tokens Can Be Redeemed", "body": "  Location  contracts/InternalMarket/InternalMarket.sol#L71-L73  contracts/GovernanceToken/GovernanceToken.sol#L205-L207  contracts/GovernanceToken/GovernanceToken.sol#L358-L370  contracts/RedemptionController/RedemptionController.sol#L55-L60  Synopsis  It is possible to redeem tokens bought from the internal or external markets, and/or tokens with an expired redemption period. Tokens bought from the internal market can be withdrawn after being offered to the internal market for seven days. After this period, these tokens can be redeposited. NEOK tokens bought from the external market can be simply deposited.  Deposited tokens can be settled after a specic period by calling the settleTokens function in the GovernanceToken smart contract. In a series of function calls, new tokens are minted to the depositor address and, eventually, the afterMint function in the RedemptionController smart contract will be called. This function adds the minted amount to the depositors mint budget \u2013 the amount which can be redeemed.  Contributors could continuously withdraw and deposit the same tokens to gain unlimited redemption balance. Although this contributor would not be able to redeem more than their GovernanceTokens holdings balance, it enables the redemption of tokens without offering them to the internal market rst. Contributors could redeem tokens received from internal or external sources easily, and activate their expired tokens by periodically withdrawing and depositing the same tokens.  Impact  This Issue enables circumventing intended restrictions on the NOEKGov token redemption, and bypassing the internal market, which contradicts the business requirements of the system.  Preconditions  In order for this Issue to occur, the user should at least be a contributor.  Mitigation  Mitigating this Issue requires further consideration and could require breaking changes. We recommend preventing the settleTokens function from eventually calling the afterMint function by adding appropriate checks.  An alternative option is to mint the tokens to one of the smart contracts \u2013 rather than the depositors address \u2013 then transfer the amount from the smart contract to the depositor. For example, one of the smart contracts could be the InternalMarket smart contract.  Status  The NEOKingdom DAO team has stopped calling the afterMint function from the _afterTokenTransfer function. Instead, the function is currently called from the mint function inside the GovernanceToken smart contract, thus preventing the calling of the afterMint function when tokens are being settled.  Security Audit Report | Smart Contracts | NEOKingdom DAO 25 September 2023 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/neokingdom_dao_smart_contracts_final_audit_report_updated/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Unsettled Deposits Can Be Locked", "body": "  Location  contracts/InternalMarket/InternalMarket.sol#L71-L73  contracts/GovernanceToken/GovernanceToken.sol#L205-L207  Synopsis  It is possible for a user to deposit (wrap) zero external tokens using the deposit function in the InternalMarket smart contract. When settling tokens using the settleTokens function in the GovernanceToken smart contract, the internal function _settleTokens uses an iteration to settle a list of unsettled deposits. In each iteration, it checks if the amount to be settled is greater than zero. If the condition fails, the iteration will stop.  Impact  Due to the aforementioned check, if a user deposits zero NEOK tokens in addition to their previously unsettled tokens, previously unsettled tokens will be locked.  Preconditions  The user must add a zero token deposit to other unsettled token deposits.  Technical Details  function _settleTokens(address from) internal virtual {  for (uint256 i = depositedTokens[from].length; i > 0; i--) {  DepositedTokens storage tokens = depositedTokens[from][i - 1];  if (block.timestamp >= tokens.settlementTimestamp) {  if (tokens.amount > 0) {  super._mint(from, tokens.amount);  tokens.amount = 0;  } else {  break;  }  }  }  }  Security Audit Report | Smart Contracts | NEOKingdom DAO 25 September 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend preventing zero deposit amounts by adding a check in the deposit function.  Status  The NEOKingdom DAO team has added the check for zero amounts as suggested.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/neokingdom_dao_smart_contracts_final_audit_report_updated/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Missing Modier Preventing the Update of Non-Existent", "body": " Resolutions  Location  contracts/ResolutionManager/ResolutionManagerBase.sol#L257-L264  contracts/ResolutionManager/ResolutionManagerBase.sol#L119-L126  Synopsis  The function _updateResolution does not have the exists modier to prevent the update of resolutions that do not exist.  Impact  This Issue could result in the creation of another resolution rather than updating an existing one.  Preconditions  This Issue is likely if the resolutionId passed to the function does not exist.  Remediation  We recommend adding the exists modier to the function to verify whether the resolution exists.  Status  The NEOKingdom DAO team has added the modier to check for resolutionId.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/neokingdom_dao_smart_contracts_final_audit_report_updated/", "labels": ["LeastAuthority"]}, {"title": "Issue D: The Status of InternalMarket or ShareholderRegistry Can Be Set", "body": " to Contributor Status  Location  contracts/ShareholderRegistry/ShareholderRegistry.sol#L65-L70  contracts/Voting/Voting.sol#L147-L152  Synopsis  The RESOLUTION_ROLE, which is currently controlled by a Multi-Sig, can be set by the DEFAULT_ADMIN_ROLE to any address. Additionally, the RESOLUTION_ROLE can set the status of InternalMarket or ShareholderRegistry to the CONTRIBUTOR_STATUS and then delegate their  Security Audit Report | Smart Contracts | NEOKingdom DAO 25 September 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   potential voting power to an arbitrary contributor using the delegateFrom function in the Voting smart contract.  Impact  The ShareholderRegistry smart contracts shares and InternalMarkets governance tokens are counted as voting power. Consequently, these voting powers might potentially be misused since they can be delegated to any contributor.  Remediation  Even though the setting of the aforementioned state changes may go through a resolution process, we still recommend that the smart contract self-guard against this by preventing the setting of a status for the aforementioned contracts.  Status  The NEOKingdom DAO team has added a check to prevent setting a status if the address is a contract. However, this x will prevent the setting of a status for valid contributors if the contributor address is a Multi-Sig address.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/neokingdom_dao_smart_contracts_final_audit_report_updated/", "labels": ["LeastAuthority"]}, {"title": "Issue E: settleTokens Function Mints Extra NEOK Tokens to the", "body": " GovernanceToken Smart Contract (Known Issue)  Location  contracts/GovernanceToken/GovernanceToken.sol#L366-L378  contracts/GovernanceToken/GovernanceTokenBase.sol#L60  Synopsis  The settleTokens function in the GovernanceToken smart contract can be used to settle deposited tokens, after waiting for a specic period, once the deposit is complete.  When the function is called after the specic waiting period, it internally calls the _mint function in the GovernanceTokenBase smart contract to mint new NEOKGov tokens to the depositor. However, this function mints new external (NEOK) tokens to the GovernanceToken smart contract, additionally to the NEOKGov tokens minted to the depositor. This is unnecessary, extra minting since NEOK tokens had already been deposited.  Impact  Even though the tokens are not minted to the depositor address but to the GovernanceToken smart contract instead, it will break the 1:1 ratio of NEOK and NEOKGov tokens, resulting in more NEOK tokens in the circulation.  Preconditions  This Issue can occur when external tokens are deposited to be substituted with NEOKGov tokens.  Security Audit Report | Smart Contracts | NEOKingdom DAO 25 September 2023 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Status  The NEOKingdom DAO team found this Issue during the audit and remediated it by refraining from calling the _mint function in the GovernanceTokenBase smart contract and, instead, minting NEOKGov tokens directly to the depositor in the settleTokens function.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/neokingdom_dao_smart_contracts_final_audit_report_updated/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Poseidon Hash Function Needs More Rounds", "body": "  Location  src/hash/poseidon.rs  Synopsis  In Plonky2, the Poseidon hash function is implemented with 8 full rounds and 22 partial rounds, resulting in a total of 118 S-boxes for the 128-bit security margin. According to best practices and guidelines as noted in [S21], this number of rounds for Poseidon is sucient for 128-bit security. However, it is possible to reduce this security level by applying an interpolation attack, which is dened in [BBL+22]. In section 4.3 of this research paper, the authors conduct a complexity analysis for this attack by assuming r is the total number of rounds for Poseidon and t is the degree of S-Boxes. In this case, the security level for the Poseidon hash function is equal to \ud835\udc51*log(\ud835\udc51)*(log(\ud835\udc51) + log(\ud835\udc5d))*log(log(\ud835\udc51))) where d=t^(r-2), which is the degree of the univariate polynomial, and p is the eld size. In Plonky2, t=7, r=30.  Hence, the complexity is approximately equal to 2^95. This is not enough for 128-bit security.  Impact  This attack detailed in the research would reduce the expected security of the Poseidon hash function and, by extension, the overall security of the system.  Remediation  To achieve a higher security level, we recommend that the Polygon Zero team either increase the total number of rounds for Poseidon, or the degree of S-Boxes. According to the calculations in [BBL+22], Poseidon should have at least 42 rounds for the 128-bit security level.  Status  The Polygon Zero team stated that they target 100-bits of security and therefore consider 95-bits as reasonably secure. Their main problem with resolving the issue is that increasing rounds would result in nontrivial changes to the protocol, as it would affect the arity of the circuit. Since different teams have different security estimations, the Polygon Zero team prefers to do more analysis in order to get a better understanding of which estimate is the most appropriate.  Moreover, the Polygon Zero team said that since the authors of the reinforced concrete hash function in the paper [GKL+21] are working on a variant of the hash function that supports the Goldilocks eld, they might switch to this hash function in the future.  To increase transparency for users, the Polygon Zero team added a brief note into their README in order to highlight the 95-bits of security as a potential risk.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/polygon_zero_plonky2_final-audit-report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Wrong Denition of DTH_ROOT in FieldExtension for Base Fields", "body": "  Location  src/extension/mod.rs#L84  Security Audit Report | Plonky2 | Polygon Zero 8 December 2022 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  Implementations of the FieldExtension trait require the denition of a public constant DTH_ROOT, such that DTH_ROOT^D=1 (hence DTH_ROOT is a d-th root of unity) for the extension degree D. However, in the case of D=1, the constant DTH_ROOT is incorrectly dened as DTH_ROOT=0.  Impact  The DTH_ROOT of extension degree 1 is used to incorrectly represent DTH_ROOT in extension degrees 2, 3 and 5 (see here, here, and here). Hence, all generic representations of the FieldExtension trait use a wrong denition of DTH_ROOT, which might result in incorrect computations.  Remediation  We recommend that the Polygon Zero team dene DTH_ROOT = 1.  Status  The Polygon Zero team implemented the recommended remediation.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/polygon_zero_plonky2_final-audit-report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Validity of Event Data Received by handleValidatorAddedEvent Is", "body": " Not Checked  Location  operator/validator/event_handler.go#L32  Synopsis  The smart contracts registerValidator function can be used to trigger events. However, the validity of the event data received by the handleValidatorAddedEvent function is not checked. As a result, a malicious actor can send multiple ValidatorAddedEvent events and add several invalid (nonexistent) validators. The unchecked data is stored in the smart contract and an event is emitted to operator nodes.  Impact  The function does not check for the validity of the passed events data. Consequently, if the storage is limited, the node can be overloaded, which results in legitimate validators not being added.  This Issue could also be exploited for DoS attacks that could potentially bring the server down.  Preconditions  The storage capacity of the server must be limited for an attacker to be able to overload it with invalid validators.  For DOS attacks, no preconditions are needed.  Feasibility  Straightforward.  Remediation  We recommend checking the validity of the ValidatorAddedEvent events validator. We also recommend setting maximum limits for the number of validators that can be added per unit of time, and based on the storage capacity of the server.  Security Audit Report | Secret Shared Validator (SSV) | Blox 21 September 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Blox team stated that such attacks (DoS attacks and overloading the server with invalid validators) are unlikely, as they would be very expensive to execute. The malicious actor would have to pay a transaction fee for every invalid validator they want to add.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/blox_ssv_implementation_updated_least-authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Missing Validation on OperatorIds Array Size", "body": "  Location  operator/validator/utils.go#L60  Synopsis  There is no validation performed for the array size of OperatorIds. A malicious actor could perform a DoS attack by sending a large array size in, for example, a ValidatorAddedEvent event, causing the loop to run for a long period of time. Alternatively a numerous number of events could be sent with a normal array size (Issue A), creating a DoS attack vector. The smart contracts registerValidator function can be used to trigger such an event. Alternatively, an attacker can nd a way to send an event to the Blox node using another compromised function or without even going through the smart contract at all.  Impact  Enough requests can deplete the servers resources and cause unintended behavior.  Feasibility  Straightforward.  Remediation We recommend adding a check to verify that arrays are not larger than the smart contract's registerValidator function standard (13 operators).  Status  The Blox team has added a check to prevent the operator's array length from exceeding 13 items.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/blox_ssv_implementation_updated_least-authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Unsafe Dependency Used", "body": "  Location  blob/master/go.mod  Synopsis  During our manual review of the codebase, our team found that the Decoder function of the gob package is being used. The Decoder function only performs basic sanity checks on decoded input sizes.  Security Audit Report | Secret Shared Validator (SSV) | Blox 21 September 2023 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Impact  If an input with a large size is passed to the function, it may deplete the server's resources and cause unintended behavior.  Remediation  We recommend wrapping the Decoder function with a condition to set a maximum size for inputs.  Status  The Blox team has added a limit on the input size that is passed to the Decoder function.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/blox_ssv_implementation_updated_least-authority/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Blox Node Does Not Sync With Contract", "body": "  Location  cli/operator/node.go#L149  Synopsis  In the development environment, the Blox node retrieves events from a local le (for testing purposes) instead of syncing with the smart contract. The code does not check the environment in which it is running, rather only uses the le, if it is available. If the le gets deployed to the production server, the node will not sync with the smart contract.  Impact  Actions taken due to unintended or malicious events could prevent the network and the consensus protocol from functioning as intended.  Preconditions  For this Issue to occur, the events le should be deployed to the server.  Feasibility  If the precondition is met, it would be relatively straightforward to execute the attack.  Remediation  We recommend restricting the loading of the local events le to the development environment by wrapping it with a condition.  Status  The Blox team has added a ag in newly created databases that indicates whether the local le is set. If the node is restarted with values different from what is persisted, it would crash with an error.  Verication  Resolved.  Security Audit Report | Secret Shared Validator (SSV) | Blox 21 September 2023 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/blox_ssv_implementation_updated_least-authority/", "labels": ["LeastAuthority"]}, {"title": "Issue E: Event Handler Ignores Errors in Executing Duty or Timeout", "body": " Handlers  Location  protocol/v2/ssv/validator/events.go#L23  protocol/v2/ssv/validator/events.go#L29  Synopsis  As part of processing a network message, the handleEventMessage function is called, which in turn calls the respective handler either for validating or handling a timeout. These handlers could return an error. However, such an error would only be logged instead of being propagated to the message processing function that called it. This could lead to the loss of messages, and logs, unnoticed with the exception of the logs.  Impact  This Issue could result in a false positive on messages that have failed to be processed successfully.  Remediation  In case of an error, we recommend returning the error received from the OnTimeout or OnExecuteDuty functions from the handleEventMessage.  Status  The Blox team has implemented the remediation as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/blox_ssv_implementation_updated_least-authority/", "labels": ["LeastAuthority"]}, {"title": "Issue F: Missing Check on Quorum for the RoundChange Justication", "body": "  Location  protocol/v2/qbft/instance/prepare.go#L84-L97  dafny/spec/L1/node_auxiliary_functions.dfy#L673  Synopsis  The function getRoundChangeJustification in the qbft/instance/prepare.go le does not check that the set of constructed Prepare messages is of size quorum. This is a deviation from the QBFT formal verication code, and the Issue has been also previously reported in an audit on the Blox SSV specication.  Impact  Low. The function returns a set of valid Prepare messages that is attached to a RoundChange message to justify the round change by the operator. As specied in the QBFT code, the operator needs to check the size of the set here. Not checking this can lead to sending a RoundChange message that is not accepted by other operators, which could, in turn, lead to liveness issues. Since the proposer for a higher round requires quorum-many valid RoundChange messages, this can lead to a state in which the operators do not nd consensus, and liveness is not reached.  Security Audit Report | Secret Shared Validator (SSV) | Blox 21 September 2023 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  In order for this Issue to occur, an operator has to perform a round change. In addition, the operator should have reached the Prepare stage, during which the operator receives quorum-many Prepare messages, and sets the values LastPreparedValue and LastPreparedRound prior to the round change.  Feasibility  The requirement of having received quorum-many Prepare messages makes the scenario unlikely, and it is dicult to exploit the missing check for an attack.  Remediation  We recommend adding the check.  Status  The Blox team has implemented the HasQuorum function from the QBFT package to verify whether quorum size is reached.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/blox_ssv_implementation_updated_least-authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Fee Distribution Bug [Identied by Wrap Protocol]", "body": "  Location  ligo/minter/fees.mligo#L48  Synopsis  In the method generate_tx_destitinations in the minter contract, there is a fold on the token list to generate the transfer and update the internal ledger accordingly.  However, the folder function was updating the ledger on the ledger instance in the closure context, instead of doing it on the accumulated ledger given as a parameter as intended. As a result, only the balance of the last token visited was updated.  Impact  A signer could have claimed its reward several times, until the actual minter balance in the FA2 token smart contract was depleted.  Security Audit Report | Wrap Protocol Smart Contracts | Tezos Foundation 24 May 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  This issue could have been avoided with a less naive unit test (i.e. testing for several tokens at once instead of testing for only one token), which was the case for other folds elsewhere in the smart contract.  Additionally, a linter could have detected that the accumulator was not used in the folder function. However, such tools do not currently exist in the Tezos ecosystem.  The issue can thus be resolved by xing the coding error.  Status  The Bender Labs team has corrected this simple coding bug, thus resolving this issue.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Wrap_Protocol_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Usage of Vulnerable Dependencies", "body": "  Location  /go.mod  Synopsis  Analyzing the code using the go list -json -deps | nancy sleuth command shows three vulnerable dependencies used in the Key Vault.  Our team also identied multiple outdated dependencies by running the command go list -u -m -json all.  Impact  Using dependencies or packages with known vulnerabilities exposes the Key Vault to attacks that could result in the exltration of sensitive data.  Preconditions  A vulnerable dependency or a new vulnerable update to an already existing dependency gets installed in the project.  Remediation  We recommend following a process that emphasizes secure dependency usage to avoid introducing vulnerabilities to the Key Vault, which includes:   Manually reviewing and assessing currently used dependencies;  Upgrading dependencies with known vulnerabilities to patched versions with xes;  Only upgrading dependencies upon careful internal review for potential backward compatibility  issues and vulnerabilities; and   Including Automated Dependency auditing reports in the projects CI/CD workow.  Status  The Blox team has addressed all the vulnerable dependencies except for go-ethereum. Running the command go list -u -m -json all shows the remaining outdated dependencies.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/Blox_Staking_Wallet_Second%20_Review_Final_Audit_Report_Least_Authority_0323.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Error Is Not Returned", "body": "  Location  /key-vault/e2ereturn nil, nil/e2e_api_calls.go#L101  Security Audit Report | Staking Wallet 2nd Review | Blox 30 August 2022 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  In the function Sign on line 99, the following expression is evaluated:  req, err := http.NewRequest(http.MethodPost, targetURL, bytes.NewBuffer(body))  The variable err handles any errors this NewRequest could contain. After that, the next line evaluates whether this err variable has an error or not:  if err != nil  If this is true, then there is an error. Therefore, it should be returned in the next line. The issue is that the value that is returned is nil:  return nil, nil  This ow is incorrect, as the expected result should return the error value for further error handling.  Impact  This could generate errors for this module of the application, and it might result in a low to medium impact. If this error is not handled, it could cause performance issues or even break the ow of the application.  Preconditions   Sending a corrupt HTTP Post Body when trying the Signing function.  Having a targetURL that is not available.  Remediation  We recommend following this simple remediation by changing the return statement on line 101 to:  return nil, err  Status  The Blox team has updated the return statement as suggested.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/Blox_Staking_Wallet_Second%20_Review_Final_Audit_Report_Least_Authority_0323.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: PBKDF2 Vulnerable to Dictionary Attacks", "body": "  Location  key-manager/encryptor/keystorev4/encryptor.go  Synopsis  Although the application supports both Scrypt and PBKDF2 key derivation functions, PBKDF2 is set as the default. This key derivation function is known to be insuciently secure, as it is vulnerable to dictionary attacks. As a result, we recommend a more modern and secure password hashing function and suggest that the Blox team consider using Argon2 as a key derivation function. Argon2 is a GPU and memory-hardened password hashing algorithm that is well-supported in Go.  Impact  A PBKDF2 derived encryption key that is compromised would lead to the loss of user funds.  Security Audit Report | Staking Wallet 2nd Review | Blox 30 August 2022 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  The user uses the default key derivation function to derive an encryption key from a user-selected password.  Mitigation  We recommend removing the default PBKDF2 and adding the Argon2id encryption key derivation algorithm instead.  Status  The Blox team has updated the default to use Scrypt instead of PBKDF2, which we consider suciently more secure than PBKDF2.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/Blox_Staking_Wallet_Second%20_Review_Final_Audit_Report_Least_Authority_0323.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: API Connection Certicates Not Checked", "body": "  Location  /e2e/e2e_api_calls.go  Synopsis  The httpClient variable used to create requests to the Key Vault explicitly allows a TLS connection to be insecure through the use of the ag:  TLSClientConfig: &tls.Config{  InsecureSkipVerify: true,  }  Impact  Having an insecure communication channel to the vault could cause attacks such as eavesdropping (MiTM) or even result in a certicate getting replaced on the server-side (vault server) and trusting this certicate by default.  Preconditions  A vault is set up with a self-signed certicate or without a TLS connection at all.  Feasibility  An attacker could examine the connection to the vault and determine easily that an insecure connection can be leveraged for malicious purposes.  Mitigation  A user could easily establish a secure TLS connection with a Lets Encrypt certicate in the vault instance and set it to reject insecure or unveried TLS connections.  Remediation  We suggest implementing changes in the code that encourage users to set a secure TLS connection in the vault server by changing the InsecureSkipVerifyag to false, in the event that it is not the default setting.  Security Audit Report | Staking Wallet 2nd Review | Blox 30 August 2022 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Blox team acknowledged the issue and stated that since they address Key Vault instances by IP, and incoming requests to Key-Vault do not contain sensitive information, this will be postponed to a future post-audit release. As such, the issue remains unresolved at the time of verication.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/Blox_Staking_Wallet_Second%20_Review_Final_Audit_Report_Least_Authority_0323.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: No Provision to Handle Compromise of Shared MTG Key", "body": " [Compound & Pando]  Location  Compound: audit/deploy/config.node.yaml.tpl#L31  Pando: cmd/pando-worker/README.md (and examples of conguration les at https://gist.github.com/yiplee/0d41b232c93dbb8048d0fd30951d967b)  Synopsis  In Compound and Pando, for each node, key pairs are generated outside of the protocol. For example, in Compound one key pair is unique to each node and used for signing transactions. Another key pair is shared among the MTG nodes, and is used for the process of encrypting and decrypting data stored in the memo eld. Key pairs along with other secrets are stored unencrypted in the config.yaml le of each MTG node. We found no processes in place to deal with the compromise, revocation, or unplanned change of keys.  As part of the key revocation process, nodes using the public key of a key pair will need to be informed that the public key may no longer be used. New keys must be generated in instances of a member node leaving the group, the keys becoming compromised, a newly discovered security vulnerability having an impact on the security of the keys, or the lifetime of the key has been reached.  In the event of a key compromise, the compromised key must be revoked and the node operators must manually receive a new keypair. User notication and key replacement becomes more complex as the system scales. The key revocation and replacement process must include a security assessment of data encrypted by the compromised key.  Impact  In the case that an unexpected key replacement is required, and is not executed in a timely and well coordinated manner, nodes using revoked keys could be severed from the MTG network, and the MTG could potentially be destabilized, putting users at risk.  Preconditions  An attack would require access to the machine running the node, and access to the config.yaml le.  Security Audit Report | Compound + Pando | Fox One 10 September 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  All cases of unplanned key changes, as previously mentioned, will result in this issue.  Remediation  We recommend using specialized key management tooling which automates the creation, storage, and replacement of keys in a secure manner.  Status  The Fox One team has responded that they do not intend to resolve this issue at this time due to system constraints. As a result, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_FoxOne_Compound_Pando_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Security Roadmap Nonexistent [Compound & Pando]", "body": "  Synopsis  A clear and transparent security roadmap conveys concisely how the risks and concerns that can impact nancial protocols are being addressed. The Compound and Pando protocols have the potential to accumulate and control signicant amounts of funds. Thus, there are many security risks to different aspects of these systems. We identify three different categories of risks that surround such systems:   Technical risks: Faulty implementation of the system, usage of dependencies, inter-node communication, attacks targeting the Compound or Pando infrastructure causing service interruption, hijacking of trusted MTG nodes, and tampering with oracles servers.   Economic risks: Exploits of the economic model of Compound and Pando and how the protocols  react to blackswan events.   Third-party security failure risks: Failures of third-party services utilized by Compound and Pando,  such as the Mixin Network or the oracles used to fetch market information.  Systems like Compound and Pando would benet from having a publicly accessible and comprehensive security roadmap that can increase trust by the community and broaden user adoption.  Impact  The impact of the risks can include, but is not limited to, users loss of funds, system interruption, and the protocol losing adoption.  Mitigation  Systems similar to Compound and Pando, such as MakerDao, have publicly accessible security roadmaps that demonstrate what has been done and what is planned for improving the securing of these critical systems. Compound and Pando can benet from adopting a similar approach to the security of their protocol.  To increase the overall security of the protocols, we recommend creating a publicly accessible security roadmap and including the following components:   Develop and document a security roadmap for Compound and Pando;  Publish Compound and Pando code bases as open source;  Include multiple audits by different security teams in the security roadmap;  \u25cb Mixin Network and MTG \u25cb mixin-sdk  Security Audit Report | Compound + Pando | Fox One 10 September 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   \u25cb Oracle Component \u25cb Pando Rings Web \u25cb Pando Leaf Web   Plan audits at appropriate milestones in the development roadmap of both protocols; and  Participate in bug bounty programs.  Status  The Fox One team has responded that they do not intend to resolve this issue at this time due to system constraints. As a result, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_FoxOne_Compound_Pando_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Protocol Specications Nonexistent [Compound & Pando]", "body": "  Location  Compound: design.md  Pando: design.md  Synopsis  Compound  The implementation of Compound for Mixin is inspired by the Compound Protocol by Compound Finance. The Compound Protocol is a smart contract for Ethereum for borrowing and supplying assets. Since the underlying machinery of Mixin Network differs strongly from the Ethereum Virtual Machine and Ecosystem, our team recommends thorough documentation and analysis of the Compound Protocol in the setting of Mixin Network.  Pando  Pandos design is inspired by MakerDao and Synthetix, very complex systems with carefully balanced incentives and governance mechanisms to ensure that the systems remain stable and free from exploitation. To inspire user trust and provide assurance in the system, it is critical to provide a clear protocol specication of how the system is intended to behave, and to verify through 3rd party security teams that the code is working in accordance with the specication. For comparison, see MakerDAO's protocol specication.  Impact  Compound & Pando  Our team found that the Compound and Pando design document provided for this security review to be insucient. A usable protocol specication must specify all of the functionality in detail, provide rationale for why each function is necessary, and explain how it all ts together. To facilitate verication of code compliance, the specication must be comprehensive, detailed, and specic. A specication is complete enough if it can enable a software developer to create an implementation of the system without any other source of guidance.  Bugs and vulnerabilities in large and complex systems such as Pando and Compound for the Mixin Network are dicult to nd, and the probability of implementation errors going unnoticed is high. Ideally, bugs should be identied at the protocol layer before code is written. A well-written specication facilitates reasoning about the protocol design independent of its implementation. The specication is a  Security Audit Report | Compound + Pando | Fox One 10 September 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   prototype written in prose so that its design can be discussed, argued about, and rened at a high level of abstraction. Like an architectural blueprint, it enables design problems to be addressed at a high level before they become expensive at the implementation level.  Remediation  Compound  We recommend writing a technical specication for the Compound Protocol for the Mixin Network according to industry standard best practices. See A practical guide to writing technical specs, the Compound Protocol Whitepaper, and the Compound Protocol specications by Compound Finance for guidance and inspiration.  Pando  We recommend writing a technical specication for the Pando protocol according to industry standard best practices. See A practical guide to writing technical specs and the MakerDAO specications for guidance and inspiration.  Status  The Fox One team has responded that they do not intend to resolve this issue at this time due to system constraints. As a result, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_FoxOne_Compound_Pando_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Secrets Are Shared and Persist in Plain Text [Compound & Pando]", "body": "  Location  Compound:  audit/deploy/config.node.yaml.tpl#L31  audit/deploy/config.node.yaml.tpl#L26  Pando:  cmd/pando-worker/README.md (and examples of conguration les at https://gist.github.com/yiplee/0d41b232c93dbb8048d0fd30951d967b)  Synopsis  To deploy an MTG node, the config.yaml conguration le is used, which contains the two sets of public and private keys and the PIN number for the wallet that is associated with the node, all in plain text.  Impact  An attacker gaining access to the private keys or the node wallet PIN number can gain unauthorized access to assets or information and spoof any of the nodes in the MTG.  Preconditions  After deployment, if the conguration les remain on the system unencrypted or with liberal access rights, the secret information could become compromised.  Security Audit Report | Compound + Pando | Fox One 10 September 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation  We recommend restricting the access rights on the conguration le or consider using a keystore and removing secret information from the conguration le.  Remediation  We recommend developing a secrets management process to include cryptographic keys, passwords, and PIN numbers to deploy secrets securely. This includes having a secrets management infrastructure in the build, deploy, and production phases.  Status  The Fox One team has responded that they do not intend to resolve this issue at this time due to system constraints. As a result, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_FoxOne_Compound_Pando_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Use of Unauthenticated Encryption Mode [Compound & Pando]", "body": "  Location  Compound:  pkg/aes/aes.go#L35  pkg/aes/aes.go#L56  Pando:  pkg/aes/aes.go#L35  pkg/aes/aes.go#L56  Synopsis  The Compound and Pando protocols utilize the AES-CBC mode, while the AES-GCM authenticated-encryption mode is known to be more secure.  Impact  CBC mode is vulnerable to padding oracle attacks by utilizing arbitrary values leaked by the oracle while checking a messages correctness. While Galois/Counter Modes are impervious to such attacks, they handle encryption and validate data integrity, thus also providing protection against data tampering.  Technical Details  Both Compound and Pando utilize AES-CBC mode. Example:  func Encrypt(data []byte, key, iv []byte) ([]byte, error) {  ckey, err := aes.NewCipher(key)  if nil != err {  return nil, err  }  Security Audit Report | Compound + Pando | Fox One 10 September 2021 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   encrypter := cipher.NewCBCEncrypter(ckey, iv)  AES-CBC can be vulnerable against Bit-Flipping attacks as explained in Bit Flipping Attack on CBC Mode.  Remediation  We recommend utilizing AES with a Galois/Counter Mode AES-GCM based authenticated encryption algorithm.  Status  The Fox One team has responded that they do not intend to resolve this issue at this time due to system constraints. As a result, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_FoxOne_Compound_Pando_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Input Not Checked When Adding or Removing PKCS #7 Padding", "body": " [Compound & Pando]  Location  Compound:  pkg/aes/aes.go#L10-L15  pkg/aes/aes.go#L17-L26  Pando:  pkg/aes/aes.go#L10-L15  pkg/aes/aes.go#L17-L26  Synopsis  Neither the adding PKCS #7 padding nor the removing PKCS #7 padding functions check the input in both Compound and Pando repositories. It is possible to input data of incompatible size in regard to block size into the removing PKCS #7 padding function, which can result in problems decrypting content in AES in CBC mode.  Impact  In its current usage, the adding PKCS #7 padding function is only used in test cases. Although it is a helper function, it should still be implemented correctly in case functionalities of the system are expanded in the future.  The removing PKCS #7 padding function is used in pkg/mtg/encrypt.go#L17 for decryption of business data and the memo eld. Since this comes through the network, input should be checked to stay functional. While in pkg/mtg/encrypt.go#L17 the compatibility to block size is checked, this should be done at the stage of removing padding, in addition to checks for emptiness.  Preconditions  To exploit this issue, incompatibly padded data can be sent through the network, which would be tested for decryption. Since no input checks when removing the padding follow, decryption errors may occur.  Security Audit Report | Compound + Pando | Fox One 10 September 2021 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  For adding a padding, no checks on block size are implemented. It is possible that the input block size is negative or too big.  For removing a padding, no checks are implemented. It is possible to input data of zero length, or that data is not passed compatible with block size. This could also result in problems in AES encryption and decryption in CBC mode in later stages or in future references to this function.  Remediation  We recommend checking the input before adding and removing padding.  Status  The Fox One team has responded that they do not intend to resolve this issue at this time due to system constraints. As a result, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_FoxOne_Compound_Pando_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Excess Centralization [Compound & Pando]", "body": "  Synopsis  The design of Compound and Pando relies on seven MTG nodes. A four-node quorum is required to validate transactions.  Impact  The impact can include, but is not limited to, a loss of users funds, price and market manipulation, and service interruption depending on the number of nodes out of the total number of nodes involved going rogue.  Preconditions  A minimum of M MTG nodes out of N MTG nodes getting hacked and taken over or a minimum of M MTG nodes out of N MTG nodes colluding.  Technical Details  The quorum is implemented via an M-of-N multi-signature scheme. Our team was unable to verify that the node operators are independent and approximate that there is a high risk of collusion between the MTG members. Collusion risk aside, an attacker would only need to compromise four machines to compromise the entire system. By comparison, the Ethereum distributed ledger comprises more than 5,000 nodes.  Mitigation  We recommend the Fox One team have an open access policy that allows more nodes to join both Pando and Compound MTG networks. This would provide more safety as more nodes join the network, thus increasing the required number of nodes to collude to cause a negative impact.  Status  The Fox One team has responded that they do not intend to resolve this issue at this time due to system constraints. As a result, the issue remains unresolved at the time of this verication.  Verication  Unresolved.  Security Audit Report | Compound + Pando | Fox One 10 September 2021 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "http://leastauthority.com/static/publications/LeastAuthority_FoxOne_Compound_Pando_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Zero-ll Buffers Are Used To Hold Secrets", "body": "  Location  snap/src/Encryption.service.ts#L19  snap/src/Encryption.service.ts#L57  Synopsis  When using the Buffer number constructor, memory space is reserved without initializing it with zeroes. Instead, the allocated buffer retains whatever data was present in memory at that moment.  Impact  This Issue could result in the leakage of sensitive data.  Technical Details  The content of the newly created Buffer will be the residual of whatever value was held by that memory space before, if not zero-lled.  Remediation  We recommend always zero-lling Buffers that contain sensitive information or secrets after usage.  Status  The Blockchain Lab team has implemented the recommended remediation.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/blockchain_lab_masca_metamask_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: The Crypto Subtle Key Is Marked as Extractable", "body": "  Location  snap/src/Encryption.service.ts#L24C7-L24C11  snap/src/Encryption.service.ts#L58  Synopsis  The ag that allows the keys to be exported is set to true. As a result, the crypto subtle key is marked as extractable. Our team did not observe any use case that may call for exporting the CryptoKey. Therefore, allowing it to be exported unnecessarily opens a new attack vector.  Security Audit Report | Masca MetaMask Snap | Blockchain Lab 6 September 2023 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Impact  This Issue can result in the leakage of sensitive data and secrets.  Remediation  We recommend turning the key into an unextractable to reduce the attack vector here and here.  Status  The Blockchain Lab team has implemented the recommended remediation.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/blockchain_lab_masca_metamask_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Users Can Still Execute Security-Critical Actions Without Being", "body": " Prompted  Location  snap/src/UI.service.ts#L50  snap/src/UI.service.ts#L29  Synopsis  The implementation uses force boolean to prevent users from circumventing displayed pop-ups for even friendly applications selected by the user. However, it is not used in any of the snapConfirm or snapAlert calls.  Impact  This Issue can lead to users executing security-critical actions without being prompted.  Remediation  We recommend that force booleans be used for critical actions, such as the state export.  Status  The Blockchain Lab team has updated the implementation to force a notication display and obtain user consent even when notications are turned off by the user for friendly dApps.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/blockchain_lab_masca_metamask_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue D: The Key Utilized for the Encryption Does Not Meet Security Best", "body": " Practice Requirements  Location  snap/src/Encryption.service.ts#L20  Synopsis  Our team found that the entropy provided by MetaMasks snap_getentropy is being used directly as a secret value for an AES-GCM encryption in which the key derivation function is not utilized.  A key derivation function turns any source of entropy into a key in a deterministic and secure manner and  Security Audit Report | Masca MetaMask Snap | Blockchain Lab 6 September 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   increases resistance to a variety of password-cracking attacks, such as brute-force attacks. Using a key derivation function (KDF) is generally recommended for better security and key management.  Impact  The strength of the encryption algorithm could be compromised, making the system more susceptible to password cracking attacks, such as brute-force attacks.  Remediation  For deriving a key from the entropy, we recommend utilizing the Argon2id function library implemented with a memory parameter of 64 MB, and following the recommendations explained in [BKJ20]. Additionally, an iteration count (called OPSLIMIT by sodium) of 3 should be used. It is important to note that a longer processing time provides better protection against brute-force attacks.  Mitigation  If the Blockchain Lab team is unable to use Argon2 then, as a last resort, we recommend using PBKDF2 to derive secret values from user-supplied passwords, in accordance with the OWASP recommendations.  Status  The Blockchain Lab team stated that they faced some issues when integrating Argon2id into their systems and therefore chose to use PBKDF2. Additionally, the team increased the iterations by six times from the default of 100K. However, our team recommends that the Blockchain Lab team continue to monitor the security of PBKDF2 and switch to stronger KDF, as described in the Remediation section.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/blockchain_lab_masca_metamask_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Secret Key Exposure", "body": "  Location  chrome-extension://ffmccdpbokklglpamkcddkcaghgbpgni/index.html#/settings/secre t-key  Synopsis  The Stacks Wallet Extension is vulnerable to a clickjacking attack. A malicious web page can load the extension in a hidden iframe while monitoring the navigator.clipboard object, leading to the exposure of a users secret key phrase when they are logged into the wallet.  Impact  An attacker can use the secret key phrase to initialize a different extension and take control of all the assets in the wallet.  Preconditions  The victim must be logged into the wallet while visiting a malicious page. If the victim clicks on a malicious item in the page, the Copy to Clipboard button will be triggered, and the secret key phrase will be available to the attacker in the navigator.clipboard object.  Feasibility  The attack is easy to create, although the user would need to visit the malicious site and perform a single action. Given that an attacker is highly incentivized, they would be motivated to reach as many potential victims as possible.  Technical Details  The Copy to Clipboard button will store the secret key phrase in plaintext in the navigator.clipboard object. A malicious site can run a function that checks the contents of this object periodically, and if it  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   recognizes a valid key phrase, it can then exltrate the key phrase to a remote location without the victim being aware.  The clickjacking attack facilitates getting the key phrase into the clipboard. As a result, while it can be considered a stage in the overall attack, mitigating clickjacking attacks will not solve the problem of the key phrase being stored in the navigator.clipboard object.  Mitigation  Protection against clickjacking attacks is traditionally implemented by utilizing the X-Frame-Options HTTP Header. Since the extension pages are not loaded from an HTTP server, research by the Hiro team can be conducted to assess how this could be implemented in the context of a browser extension. Utilizing Content Security Policies (CSP) that prevent framing resources would be a possible solution.  To protect against the clipboard attack, it would be best to prevent the key phrase from ever being accessible to the clipboard available to the browser. One solution is to disable selection of the text and force users to download a le. Another option would be to investigate if the clipboard object can be disabled for that page entirely. This latter option might prove unfeasible, as users will want to be able to copy and paste addresses.  Status  This issue was reported to and discussed with the Hiro team during the audit. The Hiro team released a patch adding the frame-ancestors CSP direction, thus resolving this issue. Our team veried the changes and the clickjacking portion of the exploit is no longer possible.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Malicious Browser Extensions Can Steal Sensitive Data", "body": "  Synopsis  Any extension installed on the users browser has access to privileged APIs that allow for the execution of arbitrary Javascript on a Blockstack application page that bypasses the SOP and gives access to sensitive application-specic data stored in local storage. This includes the transitKey, appPrivateKey, decentralizedID, and wallet address. The appPrivateKey is used for signing transactions as well as encrypting user application data on chain.  Impact  A successful attack of this type can result in de-anonymizing a user, decrypting data stored on chain, and forging JWT for use in other attacks (Issue E; Issue F).  Preconditions  Another browser extension is installed in the same browser where the Stack Wallet Extension is used. This can occur because either a user has installed a malicious extension or in the event that the browser was previously compromised and an extension was installed without their knowledge.  Feasibility  The attack is trivial to perform because any browser extension can be compromised in this way. Moreover, the potential for signicant reward motivates potential attackers to allocate resources to an attack of this type, or create browser extensions specically targeting typical users of the Stack Wallet Extension.  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  Chrome extensions have access to several privileged APIs that are not restricted by the SOP that otherwise sandboxes the domain. The chrome.tabs.executeScript() API can be leveraged from an extension to read local storage. With knowledge of a tabs ID gathered using the chrome.tabs.query() API, an extension can execute the following to steal the appPrivateKey for a particular TAB_ID:  chrome.tabs.executeScript(TAB_ID, {code: \"(function() {return JSON.parse(localStorage.getItem('blockstack-session')).userData.appPrivateKey })()\"},  (resp) => {  console.log(resp)})  Mitigation  Given the absence of a secure enclave in Chrome, attacks of this type are dicult to mitigate against. Solving this problem may prove exceedingly dicult in the current environment. However, exploitation requires a previous compromise of the browser thus largely depends on the end-users own security practices.  A mechanism to prevent this attack in the short-term would be to advise users to use dedicated browsers without extensions. If it is found to be possible to move the data stored in localstorage into the wallet sandbox, this could solve the exposure problem, but would then create new problems of how to build trust relationships between application and wallet code. We recommend this short-term mitigation and suggest that a longer term remediation be pursued in conjunction.  Remediation  As there is no clear remediation path, we recommend the Hiro team revisit their security architecture design (Suggestion 11) so it is a secure framework for constructing the application.  Status  The Hiro team has responded and acknowledged that they are aware of this issue. Given that remediating this issue would require considerable changes to the protocol design, they will continue to consider a long term strategy by revisiting their security architecture design and have stated their intent to  notify users of best practices (i.e. using a dedicated browser) when using Stacks applications. At the time of this verication, the suggested mitigation and remediation remain unresolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Same Key Used for Signing and Encryption", "body": "  Location  auth/src/messages.ts#L204  auth/src/messages.ts#L108  Synopsis  The transit key pair is used to sign and encrypt data. A more secure practice is to use a separate encryption key pair and to sign the corresponding public key using the signing key. Similarly, the  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   appPrivateKey is used to both sign transaction request JWTs and encrypt application specic data on-chain.  Impact  In the event that encryption using the transit key is broken, the appPrivateKey would be leaked, severely undermining the security of the protocol.  In the event that signing using the appPrivateKey is broken, an attacker would be able to issue transaction requests.  In the event that encryption using the appPrivateKey is broken, an attacker would be able to decrypt encrypted on-chain application data.  Preconditions  The attacker would have to break the joint security of ECDSA and ECIES.  Feasibility  While [DLP+11] shows that the ECDSA and ECIES are jointly secure, the assumptions the security analysis is based upon are very strong. Therefore, the results of that paper do not provide the condence that is expected for this class of algorithm.  Technical Details  The discrete logarithm problem is the dicult problem underlying several cryptographic schemes, including most elliptic curve cryptography. This presents the possibility to reuse key material between different algorithms. However, it is not always clear whether this is secure practice. Additionally, different key uses often require different key lifecycles, which is not possible if the same key material is used. The fact that this need has not been identied as of yet does not mean that this is not an issue. Often, such requirements only come up as applications mature.  While there is a security proof available for the joint security of ECIES and ECDSA [DLP+11], the proof makes use of the random oracle model and the generic group model, both very strong (and therefore undesirable) assumptions.  Remediation  We recommend using distinct keys for signing and encryption, in addition to including the public key in the signed authentication request so the relation can be veried.  Status  The Hiro team has acknowledged this issue and are considering changes to the protocol in order to adhere to key management best practices. At the time of this verication, the suggested remediation remains unresolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Secret Keyphrase Stored in Cleartext in Memory", "body": "  Location  Browser memory  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The secret key phrase is stored in the memory of the browser in cleartext. Attackers that are able to dump the memory of the extensions process will be able to steal the secret key phrase and take control of a wallet.  Impact  With knowledge of the secret key phrase, an attacker can instantiate a clone of the wallet and gain control of all of its assets.  Preconditions  An attacker will need to be able to dump the memory from the extensions process. This would require either physical access to the browser or a post-exploitation condition on the victims machine.  Feasibility  The attack is trivial to perform if the preconditions listed above are satised. Given the incentive for attackers, common malwares could incorporate a check to dump memory from browsers and search for strings in the format of a secret key phrase for exltration.  Technical Details  With the extension open in the browser, open Chrome Developer Tools, select Memory, click Take Snapshot, and then Save. With the downloaded le, run the strings command, and for quick results grep for a word in the secret key phrase to view in clear text.  Mitigation  While removing the key phrase from memory entirely is not possible, it is recommended that the key phrase be encrypted when not immediately in use, and that neither the encrypted key phrase nor encryption key be stored in a text format that will appear in the output of the strings command. We recommend using a binary object instead. While this would not prevent the key from appearing in a binary search, it would create signicant obstacles for an attacker to overcome.  Status  The Hiro teams current solution takes steps towards preventing the mnemonic from being easily identied in memory, but does not address the issue of the mnemonic being retrievable by running the strings command on a Heap Snapshot. By encoding as ASCII Hex, the mnemonic will now be identiable as being a   string beginning with 0x, and containing 12 or 24 space characters, identied as the byte 20 in Hex. Since ASCII   is easily converted into plaintext, this solution transfers the problem into a different encoding.  In order to implement a more robust mitigation, we recommend the following steps: In the stringToHex function, a binary buffer is created and then turned into a   string. If the toString(\u2018 ) method is omitted, the wallet would store the mnemonic in a binary buffer, which would have a different  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   representation on the Heap than a string, and therefore unlikely to appear in the output of the strings command.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Incorrect Use of JWTs", "body": "  Location  chrome-extension://ffmccdpbokklglpamkcddkcaghgbpgni/index.html#/transaction?re quest=  common/hooks/use-wallet.ts#L133  encryption/src/wallet.ts#L39-L46  components/transactions/stx-transfer-details.tsx#L7  Synopsis  The keys backing the tokens do not have any trust associated with them. In the instance of transitKey, this is because it was only just generated (and could have potentially been generated by anyone). In the case of applicationSecretKey, this is because other extensions can read it from localStorage (see Issue B).  Additionally, the JWT signature is not validated when processing authentication transaction requests.  Impact  A malicious browser extension can take advantage of the wallet messaging system to invoke a transaction without knowledge of the appPrivateKey. If the user conrms the transaction, an incorrect JWT signature does not prevent the transaction from succeeding. This would allow an attacker to perform an attack against Issue F even in the absence of the vulnerability documented in Issue B.  Additionally, a malicious browser extension can inject itself into a Blockstack application, hijack the authentication UI, receive the appPrivateKey from the wallet extension, decrypt it, authenticate it to the wallet and exltrate the key.  Feasibility  Medium. An attacker does not need to provide a valid signature for the JWT, and can use the signature of an arbitrary request generated either in code or online. Malicious browser extensions will have access to the signing key, and can create a valid signature by using the jsontokens npm package.  Breaking sign-in using malicious authentication requests is not immediately possible due to messaging restrictions implemented using browser security mechanisms. These browser security mechanisms only protect against attacks coming from web pages. If the browser is in a post-compromise state, a malicious extension can easily bypass these restrictions.  Technical Details  The index.html#/transaction?request=<JWT> route in the extension takes a JWT in the request parameter. The message of the JWT is loaded into the extension popup as trusted data. While the presence of the JWT signature is required, it was found that the message body could be changed with arbitrary values without altering the signature with no impact on the success of the transaction.  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  16  This audit makes no statements or warranties and is for discussion purposes only.   Similarly, the code handling authentication requests does not verify the validity of the tokens.  Mitigation  Given the absence of a secure enclave in Chrome, attacks of this type are dicult to mitigate against. Solving this problem may prove exceedingly dicult in the current environment. However, exploitation requires a previous compromise of the browser thus largely depends on the end-users own security practices.  A mechanism to prevent this attack in the short-term would be to advise users to use dedicated browsers without extensions. If it is found to be possible to move the data stored in localstorage into the wallet sandbox, this could solve the exposure problem, but would then create new problems of how to build trust relationships between application and wallet code. We recommend this short-term mitigation and suggest that a longer term remediation be pursued in conjunction.  Remediation  As there is no clear remediation path, we recommend the Hiro team revisit their security architecture design (Suggestion 11) so it is a secure framework for constructing the application.  Status  JWTs are now signed and internal components are checked for accuracy, with one exception related to the stxAddress. Validating signatures for transaction requests means that only parties with access to the appPrivateKey can create valid transaction requests. This issue is considered partially resolved as the exposure of the appPrivateKey to other extensions means that the parties with access to the key are still potentially unknown.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Transactions are Over-Writeable by Malicious Extensions", "body": "  Location  chrome-extension://ffmccdpbokklglpamkcddkcaghgbpgni/index.html#/transaction?re quest=  Synopsis  A malicious extension can listen for the stacksTransactionRequest DOM event and immediately trigger another event with a different JWT that will override the pop-up window with an attacker controlled transaction. This occurs because the window.open() method will return a previously opened window if the window name is the same on subsequent calls. As the name of the extensions pop-up is hardcoded, the same popup window will always be overwritten with the latest transaction request.  Impact  An unsuspecting user may be tricked into conrming a transaction they did not intend, sending their coins to an attacker controlled address. The use of JWTs offer no protection against this attack as an attacker can create a valid JWT with the appPrivateKey (Issue B; Issue E).  Preconditions  The users browser would need to have been compromised with a malicious browser extension capable of injecting Javascript code into the Stacks Wallet Extension applications tab.  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  17  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  Medium. A users browser must be in a post-compromise state with a malicious extension listening for DOM events and a user must not double check the transaction before conrming. Despite these mitigating circumstances, the incentive of a successful attack will motivate attackers to compromise browsers en masse.  Technical Details  A malicious extension can execute the following code to overwrite the popup window for an arbitrary JWT on the tab with identier TAB_ID.  let req = SOME_JWT;  let payload = 'function newReq() {'+  {detail:{transactionRequest: \"'+req+'\" }});'+  'evt = new CustomEvent(\"stacksTransactionRequest\",  'document.dispatchEvent(evt);'+  '}'+  'document.addEventListener(\"stacksTransactionRequest\", (evt) =>  chrome.tabs.executeScript(TAB_ID, {code: payload});  newReq());'  Remediation  We recommend appending a collision resistant hash to the window name used in the window.open() function. This will prevent the same pop-up window from being recycled by the attacker and will notify the user that a problem exists.  Status  The Hiro team has responded that they have further investigated this issue and found that a malicious extension does not need to overwrite any existing transaction request, but can also create one. The Hiro team has also stated that remediating this issue requires core protocol design changes, which they are currently evaluating. At the time of this verication, the suggested remediation remains unresolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: stxAddress in JWTs is Not Veried", "body": "  Location  chrome-extension://ffmccdpbokklglpamkcddkcaghgbpgni/index.html#/transaction?re quest=  Synopsis  The stxAddress in a transaction request is not checked to match the sending address.  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  18  This audit makes no statements or warranties and is for discussion purposes only.   Impact  An attacker would need no knowledge of the stxAddress of the victim prior to creating a request for use in another attack. It should be noted that the address of the user is available in localStorage per Issue B.  Remediation  When processing the transaction request, we recommend ensuring that the stxAddress matches the address of the wallet.  Status  The stxAddress is now checked in the decodeToken function. However, if the stxAddress is omitted, no check is performed. It is unclear whether a transaction would possibly not have a sending address and what the use case for this situation is. Bypassing the check by omitting the stxAddress would make an attackers job easier. We recommend a more secure solution of implementing a strict check that requires the stxAddress to be present and correct.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue H: Use of Improper Promise Handling", "body": "  Location  app/src/auth.ts#L77  Synopsis  An error thrown by provider.authenticationRequest might not be caught by its encapsulating try-catch block. This is not the recommended approach to handle exceptions in JavaScript and TypeScript, as detailed in MDN Web Docs.  Impact  An improper handling of an asynchronous code execution may lead to unintended exception handling, as the wrong execution ow could result in the code not behaving as intended. For example, returning wrong errors could prevent users from quickly identifying bugs.  Remediation  We recommend using the promise.then and promise.catch methods, which is the asynchronous equivalent of a try-catch block when calling provider.authenticationRequest to handle errors.  Status  provider.authenticationRequest now properly handles exceptions that may be thrown as per the recommendation of MDN Web Docs.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue I: Authenticator Ignores Parts of Request", "body": "  Location  common/hooks/use-wallet.ts#L120  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  19  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The application domain is inferred from the redirect URL instead of using the appDomain eld of the request, allowing inconsistent requests to be accepted. A more cautious and precise approach would be to validate the consistency of the request, and then use the application domain explicitly specied in the authentication request.  Impact  While we did not identify a way to exploit this issue, a request that uses inconsistent URLs should be considered invalid and rejected, in order to guarantee that no part of the code can be subject to application domain confusion attacks.  Technical Details  The signicance of the application domain in the Stacks Wallet Extension is comparable to that of the origin in web applications. Confusing the access control systems of the Stacks Wallet Extension about this value may result in attacks where a malicious application poses as one application to parts of the extension. As a result, it is important to verify for consistency with the redirect URL and the manifest URL.  Remediation  We recommend verifying whether the URLs in the request are consistent and use the appDomain value as the application domain.  Status  The Hiro team has removed the additional appDomain function parameter and all metadata is now derived from the authentication request. This is an effective measure to prevent inconsistencies and the possibility of confusion attacks.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue J: Custom Implementations of Common Cryptographic Algorithms", "body": "  Location  encryption/src/ec.ts#L271  encryption/src/ec.ts#L94  encryption/src/ec.ts#L336  encryption/src/wallet.ts#L52  Synopsis  Elliptic Curve Integrated Encryption Scheme (ECIES) and Authenticated Encryption (AE) are common cryptographic primitives. As a result, the custom implementation of common cryptographic algorithms is necessary and may result in serious errors.  Impact  Secret keys as well as other condential information could be leaked due to errors in the implementation, severely undermining the security of the Stacks Wallet Extension.  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  20  This audit makes no statements or warranties and is for discussion purposes only.   Preconditions  A critical aw in the implementation needs to exist and be identied by a malicious actor.  Feasibility  The existing code is relatively straightforward and no mistakes were identied in this audit. However, future changes may introduce new, unknown vulnerabilities.  Technical Details  Implementing cryptographic systems is prone to subtle, yet catastrophic mistakes and can be avoided by making use of well known and more secure alternatives. In this instance, use of an existing cryptography library would limit the attack surface resulting from custom implementations of common cryptographic algorithms.  Since encryption and signing keys should be separated (see Issue C), the algorithm used to choose the encryption key can be chosen more freely.  Remediation  We recommend using the wasm-compiled libsodium.js. For ECIES, we recommend using libsodiums crypto_box_seal and crypto_box_seal_open functions. These provide the security of ECIES as well as a stable and well-maintained code base. For AE, we recommend using sodiums secretbox functions.  Status  The Hiro team has responded they are evaluating how to safely update their libraries to use libsodium.js. At the time of this verication, the suggested remediation remains unresolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue K: Management and Maintenance of Dependencies", "body": "  Location  packages/app/package.json  packages/app/package.json#L79  Synopsis  Running npm audit revealed that security advisories were published for several dependencies and the use of automated tools found numerous vulnerabilities in the existing dependencies. In addition, the valid-url dependency has not been maintained for eight years and has several open issues on GitHub.  Impact  The large number of reported vulnerabilities were an obstacle in verifying the impact as our team was unable to review each vulnerability due to time constraints. Using unmaintained dependencies may lead to critical vulnerabilities in the code base. For example, the unmaintained valid-url dependency may allow invalid URLS to pass validation resulting in XSS attacks.  Remediation  For proper management and maintenance of dependencies, we recommend the following:  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  21  This audit makes no statements or warranties and is for discussion purposes only.    Manually audit and upgrade dependencies, in order to avoid unmaintained dependencies known  issues. This would require extensive testing to ensure there are no backward compatibility issues introduced by upgrading dependencies.   Include the automated dependency auditing into the CI workow or enable Dependabot on  GitHub, which automatically noties developers about published security advisories relevant to the code base.   Act on published advisories and update dependencies when xes are released.  Status  All dependencies used by the Stacks Wallet Extension have been pinned to versions with no known vulnerabilities in security advisories. Furthermore, the Hiro team has added a Github action which runs Yarn Audit to automatically notify developers of issues discovered in existing or newly introduced dependencies.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue L: Non-Compliant use of HD Derivation BIP-44 Paths", "body": "  Location  wallet-sdk/src/derive.ts#L81  Synopsis  The rst segment of the BIP-32 derivation path used by the Stacks Wallet Extension (44) indicates that this is a BIP-44 derivation. However, the rest of the derivation path does not match the BIP-44 specication. In addition to not complying to the specication, this version is less secure since account keys are not derived using hardened derivation.  Impact  This method of derivation leads to incompatibilities with other wallets. In the event that one account key is compromised, it becomes signicantly more feasible to also compromise other account keys than with the derivation in the original BIP-44 specication.  Preconditions  An attacker needs a single account secret key and the public key and chain code of the key with derivation path m/44/5757/0/0 in order to learn the secrets of all accounts.  Feasibility  Medium.  Technical Details  The Stacks Wallet Extension uses the BIP-32 derivation path m/44/5757/0/1/$i for the account with index $i. The rst segment of the path (44) indicates that this is a BIP-44 derivation. However, in BIP-44, the third segment is used to specify which account is used. In addition, hardened derivation is used on this level and, as a result, the derivation path should be m/44/5757/$i/0 (or m/44/5757/$i/1 for change addresses).  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  22  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation  We recommend making the account key derivation hardened. While this results in being less compliant, since this level is not hardened in BIP-44, it prevents the issue of leakage of parent keys from unhardened subkeys.  Additionally, we recommend the Hiro team stop using 44 in the rst segment and specify their own standard.  Remediation  We recommend adhering to the BIP-44 specication and use the third segment for accounts, using hardened derivation.  Status  The Hiro team has responded they are investigating changes to the key derivation logic while maintaining backward compatibility. At the time of this verication, the suggested mitigation and remediation remain unresolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue M: HD Derivation Uses BIP-44 Paths for Non-Wallet Keys", "body": "  Location  wallet-sdk/src/derive.ts#L9  Synopsis  The Stacks Wallet Extension uses the BIP-44 derivation tree for non-wallet keys, specically for the key used to encrypt the conguration before uploading to Gaia Hub. This does not comply with the intended use of keys in the BIP-44 derivation tree, and may lead to future attacks.  Impact  Possible interaction between the encryption of the conguration and the derivation of address keys by wallets adhering to BIP-44, constituting key reuse and possibly leading to the loss of security guarantees.  Preconditions  A BIP-44 compliant wallet for STX must be used alongside conguration encryption for Gaia and an attack on the joint security of ECDSA and ECIES would need to be found (similar to Issue C). The former largely depends on the behavior and security practices of the user. The latter requires signicant cryptographic knowledge and resources by the attacker.  Feasibility  Using a separate BIP-44 compliant wallet next to the Stacks Wallet Extension is likely not very common. See Issue C in regards to the joint security of ECDSA and ECIES.  Technical Details  The BIP-44 derivation tree is intended only for wallet keys. However, the Stacks Wallet Extension also derives keys used to encrypt the conguration before uploading to Gaia Hub. As noted, this does not comply with the intended use of keys in the BIP-44 derivation tree. Disagreement and ambiguity about the purpose of the key leads to key reuse across primitives, and key reuse across primitives may lead to failing security guarantees.  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  23  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend using the m/888/ tree for non-wallet derivations. This tree appears to be only used by the Stacks Wallet Extension and, as a result, this is a secure approach given that internal conicts and inconsistencies are ruled out.  Status  The Hiro team has responded they are investigating improved methods to generate non-wallet keys while maintaining backward compatibility. At the time of this verication, the suggested remediation remains unresolved.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue N: Use a More Secure Password-Based Key Derivation Mechanism", "body": "  Location  common/hooks/use-wallet.ts#L133  Synopsis  The Stacks Wallet Extension currently makes use of PBKDF2, which is a purely CPU-bound key derivation function. This class of algorithms has been advised against for several years due to negative security implications.  Impact  In this instance, the Stacks Wallet Extension may accept messages with a correct signature, created using a key under the control of the attacker.  Preconditions  The attacker needs to be able to circumvent other security restrictions on cross-tab messaging by the browser.  Feasibility  Attacks on browsers are not uncommon, but can usually be quickly patched. The feasibility mostly depends on the users update regimen and information from the development team.  Technical Details  It is feasible to signicantly speed up dictionary attacks on CPU bound hashes (e.g., using FPGAs) because the task is easily parallelizable. As a result, using CPU-bound key derivation for passwords has been advised against in favor of memory-hard functions like Argon2. These are more dicult to parallelize, because RAM and fast access to it is expensive to build in hardware.  Remediation  Argon2 comes in multiple variants optimized for different attack models, but the balanced Argon2id variant would be well suited in this instance. Section 4 of the Argon2 RFC provides a procedure for choosing good parameters for specic use cases. When deciding on the maximum allowed time the derivation is allowed to take place, keeping in mind that it is slower in the browser, there is still a speedup for an attacker who tries to brute-force it using native code.  We recommend making use of key derivation functions based on memory-hard functions such as Argon2, which is a more favorable and secure alternative.  Security Audit Report | Stacks Wallet Extension | Hiro 29 April 2020 by Least Authority TFA GmbH  24  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Hiro team has updated the extension to use the Argon2id memory hard hash function in place of PBKDF2. The parameters chosen are reasonable and the migration of existing wallets to use keys derived from Argon2 takes place automatically during the rst unlocking of the wallet following the update.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Hiro_Stacks_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Check For WETH Address In The Receive Fallback", "body": "  Location  contracts/core/PendleRouter.sol#L55  Synopsis  The receive fallback has no implementation in PendleRouter.sol. In Uniswap, this is utilized to ensure that if ETH is being sent to the router, it must come from the wrapped ETH contract. All ETH must be  Security Audit Report | Pendle Protocol Smart Contracts | Pendle Finance 4 June 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   wrapped in order to work and it may be reasonable that users might not wrap their ETH and attempt to send it to the router.  Impact  Without a fallback implementation, ETH could be locked on the router.  Feasibility  Given that wrapped ETH is intended to work with AMMs, this could be feasible.  Remediation  We recommend providing a check that if ETH is sent to the smart contract that it is coming from the WETH contract only. If this is not required, we recommend removing the unnecessary code.  assert(msg.sender == WETH); // only accept ETH via fallback from the WETH contract  Status  The check of msg.sender == WETH has been implemented.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Pendle_Protocol_Pendle_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: claimLpInterests Potentially Blocked by High Gas Cost", "body": "  Location  core/abstract/PendleLiquidityMiningBase.sol#L288  core/abstract/PendleLiquidityMiningBase.sol#L236  Synopsis  Too many expiries are added every time a liquidity provider stakes LP tokens,causing the function to be potentially blocked by high gas cost  Impact  Too many expiries may cause the loop in claimLpInterests to increase the gas cost to the block gas limit, blocking the call and preventing the liquidity provider from claiming interests.  Feasibility  This is feasible, however, it is unlikely that a liquidity provider creates greater than ~100 expiries  Technical Details  A liquidity provider stakes LP tokens and expiries are added:  newLpHoldingContract = _addNewExpiry(expiry, xyt, marketAddress);  When calling claimLpInterests(), interests are settled in a loop across all expiries:  for (uint256 i = 0; i < userExpiries[msg.sender].expiries.length; i++) { _interests = _interests.add(_settleLpInterests(userExpiries[msg.sender].expiries[i], msg.sender)); }  Security Audit Report | Pendle Protocol Smart Contracts | Pendle Finance 4 June 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation We recommend limiting the number of expiries from which a user can claim interests, based on the gas cost of claiming one expiry interest.  Remediation  A possible remediation is to implement a functionality allowing the liquidity provider to claim interests from specic expiries. The liquidity provider can then clear expiries one by one until they can claim all remaining expiries with the usual method.  Status  The Pendle team changed redeemLpInterests to be claiming interests for a single expiry.  However,  in _settleLpInterests, there is no validity check of expiry data (only available in _updateParamL).. As a result, we recommend moving the validity check to _settleLpInterests, continue to refactor, and look for redundancies and errors.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Pendle_Protocol_Pendle_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: No Return Value Check for Transfer of Random ERC-20 Token", "body": "  Location  contracts/periphery/Withdrawable.sol#L56  Synopsis  ERC-20 token transfer calls do not have a wrapper to anticipate the event that a token interface does not adhere to the standard of reverting in the case of failure. A  missing return value bug  may arise leading to older tokens becoming locked on the contract.  Impact  Tokens not adhering to the ERC-20 specication may be locked on any contract utilizing Withdrawable.sol.  Preconditions  A token that does not conform to the standard that Pendle protocol expects is deposited and cannot be later withdrawn.  Feasibility  Some tokens that are in use still adhere to a standard that does not return a value. A list of them is provided in the Medium article on the missing return value bug.  Remediation  We recommend using a standard safe transfer wrapper, such as the one used by Uniswap or provided by  OpenZeppelin , which will anticipate interfaces with no return value and still allow their utilization.  Status  The Pendle team has implemented OpenZeppelin's safeTransfer function for token withdrawal, which has also been added to other transfer functions throughout the system for further protection.  Security Audit Report | Pendle Protocol Smart Contracts | Pendle Finance 4 June 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Pendle_Protocol_Pendle_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: updateParamL is Called Twice Within _settleLpInterests in", "body": " _beforeTokenTransfer  Location  core/abstract/PendleMarketBase.sol#L795  core/abstract/PendleMarketBase.sol#L756  Synopsis  _settleLpInterests is called twice in _beforeTokenTransfer, called twice. updateParamL is to update interests data when interests are settled, and it is called rst in the rst _settleLpInterests, and then is called again in the second _settleLpInterests, before any Pendle token transfer.  in which _updateParamL is  Impact  Redundant code is executed increasing gas costs of the operation and decreasing readability.  Preconditions  Any Pendle token is transferred including XYT, OT, and the Lp token.  Mitigation  We recommend setting a time interval limit between two _updateParamL calls. If time between the two calls is less than the limit, _updateParamL will return no error.  Remediation  We recommend separating update interests logic from the settle interests function (_settleLpInterests).  Status  The Pendle team has implemented a mechanism to only updateParamL() after the interest has increased by a %, so _updateParamL is called only once in _beforeTokenTransfer.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Pendle_Protocol_Pendle_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: updateParamL is Missed in addMarketLiquidityDual (Known Issue)", "body": "  Location  core/abstract/PendleMarketBase.sol#L262  Synopsis  When called, updateParamL updates interests data and should be called whenever the total amount of liquidity provision changes. addMarketLiquidityDual changes the total amount of liquidity provision, but does not call updateParamL.  Security Audit Report | Pendle Protocol Smart Contracts | Pendle Finance 4 June 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   Impact  Interests data is not updated when the total amount of liquidity provision changes.  Preconditions  addMarketLiquidityDual is called.  Remediation  We recommend adding UpdateParamL in addMarketLiquidityDual.  Status  This issue was identied and resolved by the Pendle team during the security audit. In resolving the issue, the Pendle team made a change such that updateParamL() must be called in the beginning of addMarketLiquidityDual (while minting protocol fees in _mintProtocolFee()).  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Pendle_Protocol_Pendle_Smart_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Password and Seed Phrase in Cleartext in Memory When Browser", "body": " Extension Wallet Unlocked  Location  blank-deposit/infrastructure/GenericVault.ts#L74  src/controllers/AppStateController.ts#L93  Synopsis  When the Blank Wallet browser extension is unlocked, the password and seed phrase are kept in cleartext in the memory, which can be captured in the memory dump by the browsers DevTools. The password can then be captured by an attacker that gains control of the browser extension wallet.  Impact  An attacker captures the password and seed phrase, resulting in gaining control of the browser extension wallet, which may result in a total loss of user funds.  Preconditions  The attacker gains physical control of the browser extension wallet when unlocked and dumps the memory from the browser.  Technical Details  The password is required to unlock the browser extension wallet. Once it has been unlocked, the password is stored in the memory and the seed phrase is decrypted using the password from the vault. The password and seed phrase are then saved in the memory to use later to derive the root key. The password and seed phrase are both stored in cleartext. Once the memory is dumped by the browsers DevTools, they are exposed. The memory dump enncompasses the following steps: open Chrome Developer Tools, select Memory, click Take Snapshot, and then Save. With the downloaded le, run the strings command and, for quick results, grep for a word in the password and seed phrase to view in clear text.  Mitigation  We recommend removing the password from the memory after the browser extension wallet is unlocked. The password is not required after unlocking the browser extension wallet to make transactions. When the password is required again for other operations (e.g. import notes, network change, and others), the password can be re-entered by the user.  In addition, we recommend storing the root key together with the seed phrase in the vault so that when the browser extension wallet key (derived from the root key) is required to sign a transaction, it is read from the decrypted vault and the seed phrase is not required to derive it, which exposes the cleartext seed phrase to the memory. A root key is more dicult to identify in a memory dump than a seed phrase.  Status  The Blank team has decided against requiring that the user re-enter their password when vault unlocks are needed, due to the signicant user experience implications. To slightly decrease the impact of the  Security Audit Report | Blank Wallet Browser Extension | Blank 22 September 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   cleartext password, they have decided to hash the password (with browser extension wallet ID as salt) to secure other programs against dictionary attacks, for which the user might use the same password. Hashed passwords are more dicult to identify than cleartext passwords once memory is leaked, however, they are still vulnerable to brute-force attack on weak passwords (Issue C). For root key derivation, the Blank team has decided against making changes due to other security concerns and are instead adhering to MetaMask's eth-keyring controller approach. We acknowledge that the current resolution has slightly decreased the vulnerability of cleartext passwords in memory and has the minimum impact on the user experience. However, the changes implemented by the Blank team only partially resolve the issue, since the hashed password is still in the memory and the aforementioned brute-force attack of a weak password is still feasible.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/210922_Blank_Blank-Wallet-Browser-Extension_Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Check for Pending Permission Error May Cause Unintended Flow", "body": "  Location  src/controllers/PermissionsController.ts#L295-L302  Synopsis  The code segment below checks for pending permission requests coming from a specic origin, in which case it throws an error and stops the process.  if (  !Object.values(requests).every((request) => {  request.origin !== origin;  })  Since the statement request.origin !== origin; is surrounded by brackets with no return statement, its value is ignored which renders the whole check useless.  Impact  It is dicult to determine the extent of the impact of bypassing this check, however, it could affect user experience or disrupt the functionality of specic features in the browser extension wallet, resulting in unforeseen security critical consequences.  Remediation  We recommend implementing one of the following remediations:  1. Remove the brackets surrounding the conditional statement; or 2. Add a return statement to x the issue.  Status  The Blank team has implemented the suggested remediation by replacing the every method from the Array prototype with a for...in loop.  Verication  Resolved.  Security Audit Report | Blank Wallet Browser Extension | Blank 22 September 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/210922_Blank_Blank-Wallet-Browser-Extension_Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Import Deposit Note Does Not Work on Network Change", "body": "  Location  blank-deposit/tornado/TornadoService.ts#L210  Synopsis  When changing the browser extension wallet connection to a supported network such as Goerli, the imported deposit note must be reconstructed for the target network. In the current implementation, the import ag isImported is not set for other networks other than the default (mainnet). As a result, importNotes does not work.  Impact  The deposit note imported will not be reconstructed for the target network when changing the network, preventing the release of previously deposited user funds from Tornado Cash.  Preconditions  The network is changed from the default network to another supported network when the browser extension wallet is imported using the seed phrase.  Technical Details  const { isImported, isInitialized } =vault.deposits[name as  AvailableNetworks];  if (isImported && !isInitialized) {  this.importNotes();  }  isImported is not set in the deposit vault state for the non-default network (mainnet) and importNotes will not run when the network is set to an alternative target network.  Mitigation  We recommend adding the isImported ag to the deposit vault state for all networks.  Status  The Blank team has added the isImported ag to the deposit vault state.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/210922_Blank_Blank-Wallet-Browser-Extension_Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Low Entropy Passwords Allowed", "body": "  Location  routes/setup/PasswordSetupPage.tsx#L16  Synopsis  When setting up the Blank Wallet browser extension, the password validation in the user interface (UI) allows for a password length minimum of only eight characters. Additionally, password validation allows  Security Audit Report | Blank Wallet Browser Extension | Blank 22 September 2021 by Least Authority TFA GmbH  11  This audit makes no statements or warranties and is for discussion purposes only.   for a number of weak forms of passwords, such as dictionary words, repetitive letters, and sequential characters.  Although browser extension wallet users are provided a password strength estimate in the UI, this feature is only informational to encourage users to create secure passwords. However, this bar does not enforce any particular level of password strength and users have the ability to choose insuciently secure passwords.  Preconditions  A machine that the browser extension wallet is installed on is compromised.  Impact  An attacker gains full access to a users account by brute-forcing an insecure password, which may result in total loss of user funds.  Feasibility  Easy. Password attacks are increasingly common. Furthermore, it may be that Blanks anonymous withdrawals feature is an additional incentive to conduct such an attack.  Technical Details  Password entropy is given by the following formula:  \ud835\udc38  =  \ud835\udc3f  *  \ud835\udc59\ud835\udc5c\ud835\udc542(\ud835\udc45)  where:  R - Size of the pool of unique characters from which we build the password (in this case, a-z, A-Z, and 0-9)  L - Password length (i.e. the number of characters in the password; in this case, 8)  An 8-character mixed case password that includes a numeral contains approximately 48 bits of entropy and would take under a day to compromise, at a very conservative rate of 10 billion guesses/second (1 trillion password guesses per second speeds or more are not uncommon, depending on cores and machines used). A dictionary word, prior breached password, or sequential/repeating password would crack nearly instantaneously.  According to zxcvbn documentation, a password should have a minimum of approximately 1e10 bits of entropy to be considered \"safely unguessable\" from an o\ufb04ine attack with user-unique salting but a fast hash function like SHA-1, SHA-256, or MD5.  Mitigation  We recommend increasing the requirement of password entropy and disallowing passwords that are easy to guess.  We recommend following the NIST Guidelines, which are industry standard rules and best practices for handling passwords when building memorized secret authenticators.  Remediation  We recommend using the dropbox/zxcvbn library for a password composition policy intended to prevent the use of passwords obtained from previous breaches, common passwords, and passwords containing repetitive or sequential characters, as recommended by the NIST guidelines. We suggest requiring that all passwords meet zxcvbns strength rating of 4.  Security Audit Report | Blank Wallet Browser Extension | Blank 22 September 2021 by Least Authority TFA GmbH  12  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Blank team is using a library which implements the zxcvbn package and has added a validation step to the UI that requires the user to choose a password strength of at least 3, which is categorized as safely unguessable.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/210922_Blank_Blank-Wallet-Browser-Extension_Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue E: Network Name Error Causes Wallet Import Failure", "body": "  Location  blank-deposit/tornado/TornadoNotesService.ts#L474  Synopsis  In getNextUnderivedDeposit, the network name is always incorrectly set to the default network (Homestead) by retrieving the network provider.  Impact  The wrong network name prevents the imported deposit note from being reconstructed, causing the import of deposit notes to fail. This prevents the user from retrieving unspent deposit notes and to perform withdrawals.  Technical Details  In getNextUnderivedDeposit:  const { name: network, chainId } = this._networkController.getProvider().network;  network will always be the default mainnet name (Homestead) instead of the correct network name  const depEv = await this._tornadoEventsDb.getDepositEventByCommitment(  network as AvailableNetworks,  currencyAmountPair,  deposit.commitmentHex,  );  } catch (error) {  console.error('Unable to check if deposit has been spent');  spent = undefined;  }  The deposit event search will fail with the wrong network name, which will cause the import of the deposit note to fail.  Security Audit Report | Blank Wallet Browser Extension | Blank 22 September 2021 by Least Authority TFA GmbH  13  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation  We recommend deriving the network name by  const { chainId } = this._networkController.getProvider().network;  network = getNetworkFromChainId(chainId)  Status  The Blank team has implemented the suggested mitigation, which has resolved the network name error resulting in wallet import failure.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/210922_Blank_Blank-Wallet-Browser-Extension_Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue F: Double-Spend of Deposit Note With Same ChainId on Different", "body": " Blockchains  Location  blank-deposit/tornado/config/paths.ts#L66  utils/constants/networks.ts  Synopsis  The deposit notes derivation path is derived from a chainId and currency amount pair. The note could be identical if there are two blockchains which have the same chainId, resulting in the possibility for double-spending attacks on different chains.  Impact  A deposit note could be double spent on different blockchains resulting in a loss of user funds.  Preconditions  Different blockchains with the same chainId would be required for this to occur.  Technical Details  In getDerivationPath, the deposit notes derivation path is generated by  `${BASE_PATH}/${chainId}'/${derivation}`  const derivation = BLANK_DEPOSITS_DERIVATION_PATHS[currency][amount];  Supported network(chainId) is added explicitly in a congure le. In the case of networks on different blockchains that have the same chainId, the derivation path would be the same , as a result the note would be the same in case of depositIndex is also the same across different chains.  Mitigation  We recommend adding a blockchain ID (e.g. hash of blockchain name) to the derivation path of the deposit note, preventing chainId conicts between different blockchains.  Status  The Blank team has indicated that no action has been taken and responded with the following:  Security Audit Report | Blank Wallet Browser Extension | Blank 22 September 2021 by Least Authority TFA GmbH  14  This audit makes no statements or warranties and is for discussion purposes only.   Given that currently, adding a new network requires manual changes and that the blockchains that will likely add in the feature are EVM based, their chainId will be different responding to what is specied in EIP-155. We can later on, if needed, change the derivation to use an arbitrary integer and use the same as the chainId for the already supported networks.  We acknowledge that manual network addition and EVM based chains can currently guarantee a unique chainId. Since the Blank team has indicated that they will implement a new derivation method in the future as needed, we consider this issue to be resolved.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/210922_Blank_Blank-Wallet-Browser-Extension_Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue G: Browser Extension Wallet Allows for Message Signing Without", "body": " Explicit User Conrmation  Location  extension-background/src/controllers/BlankProviderController.ts#L233  extension-background/src/controllers/BlankProviderController.ts#L628  Synopsis  Two related vulnerabilities have been identied where explicit user conrmation is not needed to sign a message:  Part 1: The Blank team identied an issue in BlankProviderController, where an external site can call the JSON-RPC method eth_sign through the provider, which would immediately trigger the browser extension wallet signing a message, without prompting the user for conrmation.  Part 2: The Blank team brought this issue to our attention, after which we identied the following additional vulnerability:  In the window management method called stateWatch in the BlankProviderController, SIGNING is declared as a watch-state but the state update does nothing while signing a message. This implies that the user is not prompted before signing a message.  Impact  These vulnerabilities are critical as they imply that an external provider can sign any message on behalf of a user without the user explicitly conrming.  Technical Details  Both of these are similar, as they relate to signing an EIP-712 message without user conrmation.  Part 1: Call the JSON-RPC method eth_sign through the provider, which would immediately trigger the browser extension wallet signing a message, without prompting the user for conrmation.  Part 2: SIGNING is a watch-state but the state update does nothing while signing a message.  Security Audit Report | Blank Wallet Browser Extension | Blank 22 September 2021 by Least Authority TFA GmbH  15  This audit makes no statements or warranties and is for discussion purposes only.   Mitigation For Part 1, the Blank team has prevented the ability of BlankProvider to sign messages by removing the eth_sign method from the BlankProvider as a x. Alternatively, they can ensure that the user is asked for approval before signing by a provider.  Remediation  The Blank Team has planned on properly implementing message signing, with user conrmations, in order to address Part 1.  For Part 2, we recommend changing the watchState called SIGNING to check if the user has approved signing of a message and then in checkWindows it can be conrmed that the signing was correctly approved.  Status  The Blank team has removed the eth_sign method since it may be used to sign a transaction. Additionally, they have added support for other signature methods (eth_signTypedData, eth_signTypedData_v1, eth_signTypedData_v3, eth_signTypedData_v4 as per EIP-712, and eth.personal.sign) with proper user conrmation implemented.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/wp-content/uploads/2021/09/210922_Blank_Blank-Wallet-Browser-Extension_Final-Audit-Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Use Check-Effects-Interactions Pattern", "body": "  Location  master/contracts/Staking.sol#L169-L180  Synopsis  In the staking contract, the state that updates the balances of removed tokens from staking happens after the transfer function call. If a malicious token is used for staking, it may re-enter and drain the tokens held by the staking contract before the state updates. This state is intended to ensure that the reward calculation of the staker does not over-withdraw.  Impact  If a malicious token is used in the staking protocol, the token funds stored on the staking contract may be drained.  Preconditions  A staking token must be used that has a malicious transfer function designed to specically drain the stake from this specic staking contract.  Feasibility  This is most certainly not feasible as the tokens that are planned to be used will be audited or known to not contain malicious transfer code.  Remediation  Use the recommended check-effects-interactions pattern from the Solidity documentation on preventing re-entrance attacks.  Status  Resolved. The withdraw function has now been updated and additionally the team applied the check-effects-interactions pattern to the staking function for extra caution.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Fractal_Staking_and_Claims_Registry_Smart_Contracts_Final_Audit_Summary_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: APY Calculation Fix (Found By Fractal Team)", "body": "  Location  master/contracts/CappedRewardCalculator.sol  Synopsis  There was a problem with the `Staking.currentAPY` calculation.  The function currently returns the APY for the following period of time: (now, now + 1 day). It was unclear if this was the intended time frame or if (now - 1 day, now + 1 day) was.  Before the start date it should either return 0 or revert. Or it should just return the rst days APY. But its always starting from uint currentReward = calculateReward(startDate, current, amount); which gives you an unpredicted result. Because you expect a 1-day reward, but startDate - current will be lower than 1 day and always changing.  Impact  Since this function was added at last minute, and is purely for informative purposes only (to display an estimated APY on the staking UI, with no actual consequences to the staking calculations themselves), its  Security Audit Report | Staking and Claims Registry Smart Contract | Fractal 8 May 2021 by Least Authority TFA GmbH  4  This audit makes no statements or warranties and is for discussion purposes only.   full behaviour was not properly thought out. Given that this is meant for UI purposes, the scope of this change is outside of the audit itself.  Remediation  After the teams discussing, the desired output is:  Before startDate, it should have the same result as if it were called exactly at `startDate`. So rather than returning `0`, we must show what the estimated APY will be once it starts  The range (now, now + 1 day) is correct, as we want to provide an answer to \"what will be my APY should I stake right now?\"  Status  Resolved. Ensuring that, if using the view before the start, that the current date is moved forward to the start date will give this view function the consistency that they desire.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Fractal_Staking_and_Claims_Registry_Smart_Contracts_Final_Audit_Summary_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: No Calls to SnapsRegistry:updateBlockedSnaps Found", "body": "  Location  src/snaps/SnapController.ts#L953  Synopsis  The SnapsRegistry:updateBlockedSnaps is exposed to the MetaMask system to update the blocked Snaps list and disable any Snaps that have been deemed dangerous by the MetaMask team. However, no calls were found to update the blocked list and block currently installed Snaps in the Snaps Monorepo, the Extension, or the Core repository. Because of this, if a Snap is installed and later becomes blocked, the system designed to protect the user from the blocked Snap is not being activated.  Impact  A blocked Snap will remain active in a users wallet after it has been blocked.  Preconditions  A Snap would need to be installed before it is added to the blocked list.  Remediation  We recommend making the extension perform the call SnapsRegistry:updateBlockedSnaps at reasonable intervals.  Status  The MetaMask team has resolved this Issue by calling the updateBlockedSnaps function when the snapsController is initialized during startup. This leaves the possibility that a Snap could be running in a user environment even after being ocially blocked, but only either until the browser is closed by the user or the background service worker is terminated by the browser. We consider this a reasonable update interval for the blocked Snaps.  Verication  Resolved.  Security Audit Report | MetaMask Snaps Extension | ConsenSys Software, Inc. 8 September 2023 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/metamask_snaps_extension_integration_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Usage of Vulnerable Dependencies", "body": "  Location  package.json  Synopsis  Analyzing package.json for dependency versions using npm audit shows 20 vulnerable dependencies (18 Moderate, 2 High).  Impact  We cannot assess the exact impact of using vulnerable dependencies unless we evaluate the reported advisories. However, due to the security measures imposed by MetaMasks utilization of SES and LavaMoat, the impact is minimized.  Remediation  We recommend following a process that emphasizes secure dependency usage to avoid introducing vulnerabilities to the XMTP wallet. By removing known vulnerabilities, new potential issues will be easier to identify and address.  We suggest the following mitigation strategies:   Manually assessing and regularly monitoring and maintaining security-critical dependencies;  Using commit hashes instead of release number tags to point to the latest releases, as needed;  Updating dependencies when security issues and bugs are detected and/or xed; and  Pinning updated dependency versions to releases compatible with the XMTP Snap in order to  avoid breaking the codebase upon automatic dependency upgrades.  Status  The XMTP team xed most of the vulnerable dependencies, but a few are part of the site package and are transitive dependencies from Gatsby that seem to have no patched version (all moderate severity). Additionally, the team noted that the site package is not part of the build process for the actual Snap and is purely a demonstration application.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/xmtp_metamask_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue B: XMTP Snap Uses Clients Operating System Time To Determine", "body": " Expiry of Keys  Location  packages/snap/src/authorizer.ts  Synopsis  The XMTP Snap uses JavaScripts Date object to determine the expiry of imported keys. The Date object uses the clients operating system (OS) as a source, which can be easily manipulated by simply changing the OS time.  Security Audit Report | XMTP | MetaMask Snap 18 August 2023 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   Impact  Client-provided information may be unreliable, potentially allowing users to deceive the authorization mechanism.  Remediation  We recommend refraining from using the Date.now function to create timestamps that are used for authorization. Instead, we suggest using an external time server as a source for time information.  Status  The XMTP team acknowledged the nding but stated that they will not implement the remediation for the following reasons:  1. This vulnerability cannot be exploited to give new origins access to the XMTP Snap. It can only be used to extend access for a previously authorized origin. It also cannot be exploited to extract the XMTP secrets from the Snap without some other exploit. This greatly limits the usefulness of an attack; In order to exploit this vulnerability, an attacker would have to obtain enough permissions to modify the system time. Hence, the pre-conditions are non-trivial since broad access to the user's machine is required; and  2.  3. The suggested remediation would require that the XMTP team request networking permission in their Snap (which they do not currently need/request) to get the current time from a trusted time server.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/xmtp_metamask_snap_final_audit_report_least_authority/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Key Derivation Function Used for Passwords is Trivially", "body": " Parallelizable  Location  tally-extension/background/services/keyring/encryption.ts#L77-L96  Synopsis  The Tally browser extension wallet currently makes use of PBKDF2, which is a purely CPU-bound key derivation function. This class of algorithms has been considered insuciently secure for several years because it is embarrassingly parallelizable.  Impact  The limitations of PBKDF2 may result in leakage of vault contents (i.e. mnemonics and secret keys) which can then be compromised by an attacker and result in loss of user funds.  Preconditions  The attack requires access to the encrypted vaults and this could happen through multiple vectors. A malicious website extension would need to circumvent browser security measures. A regular program running with user permissions usually can access the browser prole and, thus, all extension data.  Feasibility  The feasibility of the attack depends on the strength of the password. Argon2 provides security benets particularly for weak passwords, which could realistically be guessed by brute force.  Technical Details  PBKDF2 is a function that derives keys from passwords and the function iteratively calls a normal hash function (in this case SHA256). This means it has a tight loop and only requires a small amount of memory. This can be eciently parallelized and even implemented on an FPGA or an ASIC with relatively minimal effort.  The newer class of memory-hard hash functions avoids this problem by accessing a large amount of memory, which is always cost prohibitive to implement in hardware.  Remediation  We recommend using the memory-hard Argon2id function, instead of the currently implemented PBKDF2. In Section 4 of the Argon2 RFC, guidance is provided for the choice of parameters. We suggest selecting t=3 iterations, p=4 lanes and m=2^(16) (64 MiB of RAM), 128-bit salt, and 256-bit tag size (i.e. the second recommended option).  In addition, we suggest performing the computation in WebAssembly (e.g. using the argon2-browser package).  Status  The Tally team has chosen not to resolve this issue at this time, as they are unsure of the maturity of Argon2. However, we maintain our recommendation of using Argon2id instead of PBKDF2. Agron2 has been declared winner of the Password Hashing Competition in 2015, and the argon2-browser package is compiled from the reference c implementation. It has undergone scientic research since publication. This leads us to believe that it is suciently tested for production, while also addressing the mentioned problems of PBKDF2.  Security Audit Report | Tally Browser Extension Wallet: Key Handling | YLVIS, LLC 18 March 2022 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-YLVIS_LLC_Tally_Browser_Extension_Wallet_Key_Handling_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: No Provision for Old Vaults to be Deleted or Updated", "body": "  Location  tally-extension/background/services/keyring/storage.ts#L54-L88  Synopsis  Every time encrypted data in the Tally browser extension wallet is modied, the new version is stored alongside all old versions. The old versions are kept in order to provide a recovery path in the event that an unexpected issue or error occurs. However, there are cases when deleting old vaults is desirable (e.g. when changing the password or deleting an account).  Impact  This may result in the leakage of private key material or proof of control over an account that has been deleted. This could lead to loss of funds or impact plausible deniability of deleted account data.  Preconditions  The attack requires access to the encrypted vaults (i.e. UI access to the browser or access to the lesystem with user privileges). In addition, one of two things must hold, depending on the scenario. If the user changes their password after noticing it is compromised, the attacker must also know the compromised password. They can then access the private keys as they were before the password was changed.  If the user deleted an account and claims they have never been the owner of that account, the attacker could compel the user to provide the password and decrypt previous vaults, which would prove their control over the account.  Feasibility  If the preconditions hold, the attack is trivial.  Technical Details  In the key handling code, vaults are encrypted containers that store the secret wallet information, such as keys and mnemonics. When the secret wallet information is changed, a new vault is created and added to the data store, instead of overwriting the existing contents. This means that all previous vaults remain in the database. A user who deliberately makes destructive changes to their vault, such as changing the password or deleting an account, would expect that the old data does not remain on the device.  Remediation  We recommend implementing one of the two following remediations:   Provide a function that clears all encrypted vaults, or a ag to overwrite all existing vaults in the  next update; or   Provide a function that updates previous vaults, either for re-encrypting with a new key, or to  sanitize vaults from data that is being deleted.  Status  The Tally team has responded that they will not be addressing this issue at this time because they are concerned about accidental loss of key material. The missing of intended key disposal is a signicant security risk, and we consider accidental disposal of keys to be a manageable risks. For example, integrity  Security Audit Report | Tally Browser Extension Wallet: Key Handling | YLVIS, LLC 18 March 2022 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   checks could be added to make sure that the new vault data is not corrupted. Therefore, we still recommend implementing one of the suggested remediations.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-YLVIS_LLC_Tally_Browser_Extension_Wallet_Key_Handling_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Version of @ethersproject/wallet Not Pinned", "body": "  Location  hd-keyring/package.json  hd-keyring/src/index.ts#L160  Synopsis  In the hd-keyring repository, the package.json le requires the @ethersproject/wallet package to be version 5.4.0 or higher. However, the documentation for the package recommends pinning the package because future versions might break the code due to the renaming of the function _signTypedData.  Impact  Future versions of the @ethersproject/wallet package might not work with the current version of the code, leading to broken builds for hd-keyring.  Remediation  We recommend pinning the @ethersproject/wallet to a specic version, such that hd-keyring can be built reliably, even when @ethersproject/wallet has renamed the function.  Status  The Tally team issued a commit and @ethersproject/wallet is now pinned to version 5.4.0 as recommended.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority-YLVIS_LLC_Tally_Browser_Extension_Wallet_Key_Handling_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Unsafe Random Usage", "body": "    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_TRON_Protocol_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Eclipse Attacks On TRON Nodes", "body": "    Suggestion 1: Unused Code Should Be Removed   STATUS   Resolved   Resolved   Resolved   Suggestion 2: Secure Upgrade Instructions   Unresolved   Suggestion 3: Review SonarQube Code Linter Results   Partially Resolved   Suggestion 4 : DataWord Mutability Might Lead to Unexpected Behavior    Unresolved   Non-Finding A: Review of EthereumJ Known Deserialization CVE   Reported   Non-Finding B: Send Blocks to Corrupt Nodes Internal  DB   Reported   Issues   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_TRON_Protocol_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Unsafe Random Usage", "body": "    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_TRON_Protocol_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Eclipse Attacks On TRON Nodes", "body": "    Suggestion 1: Unused Code Should Be Removed   STATUS   Resolved   Resolved   Resolved   Suggestion 2: Secure Upgrade Instructions   Unresolved   Suggestion 3: Review SonarQube Code Linter Results   Partially Resolved   Suggestion 4 : DataWord Mutability Might Lead to Unexpected Behavior    Unresolved   Non-Finding A: Review of EthereumJ Known Deserialization CVE   Reported   Non-Finding B: Send Blocks to Corrupt Nodes Internal  DB   Reported   Issues   Issue A: Unsafe Random Usage   Location   java-tron/framework/src/main/java/org/tron/core/zen/address/SpendingKey.java   Security Audit Report | TRON Protocol | TRON 6 March 2020 by Least Authority TFA GmbH   4   This audit makes no statements or warranties and is for discussion purposes only.                Synopsis   Random classes are not cryptographically strong and the numbers chosen are not completely random  because a definite mathematical algorithm is used to select them.    Impact     Compromise of the secure generation of  SpendingKey .   Feasibility   Moderate. An attacker would have to control the system elements (system time) used to seed the  Random number generator. This would require a side channel where the attacker has installed malware  on the target.   Technical Details   It is not safe to use Random class for tasks that require a high level of security. Furthermore, this code  creates a Random object and uses it to generate but one random number at a time. Random numbers are  guessable, especially since the only usage spotted of this method is using a magic number of (0) as a  seed value.   Mitigation   Replace the Random class usage with a  java.security.SecureRandom  instead and avoid allocating  a new  SecureRandom  for each random number needed.   Remediation   Use  SecureRandom  for all tasks that require a high level of security. In case of using  Random  class,  initialize the  Random  object once, and then call  nextBytes()/nextInt()... etc each time a new  random number is needed.   Status   The unsafe  Random  object has been replaced with a correct  SecureRandom  object usage. As a result,  our suggested remediation has been fully implemented.   Verification   Resolved.   Issue B: Eclipse Attacks On TRON Nodes   Location   java-tron/framework/src/main/java/org/tron/common/overlay/discover/node/statistics/NodeStatistics.j ava   Synopsis   NodeStatistics.getReputation()  does not verify if connected nodes forward traffic correctly and  transactions are received by the network.   Impact   The value of  maxActiveNodes  can be filled up with adversarial nodes that can censor incoming and  outgoing traffic, leading to a DOS on the node and Super Representative. In particular, this vulnerability  can be chained or used as a preparation for other types of attacks for Super Representative or exchanges.   Security Audit Report | TRON Protocol | TRON 6 March 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.            Preconditions   Due to the implementation of the  maxActiveNodesWithSameIp = 2  cap, an attacker needs 15  different IP addresses to control a node's view of the TRON VM. After a node is restarted, the attacker  must fill up the node's connection pool before any non-malicious connections are established. If a node is  running, an attacker can use the reputation metrics in  getScore()  to establish connections to a node  with a high score (e.g. high  p2pHandShake.count, low discoverMessageLatency ). As a result,  CheckConnectNumberTask  would remove non-adversarial peers with lower reputation over time.   Feasibility   Low to moderate probability that enough of the peer nodes can be controlled by the attacker to  manipulate the blockchain state of the target VM. In terms of cost, this attack could be conducted for very  little using cloud-based VPS services like AWS, where an attacker can easily spin up many hosts for this  purpose.   Mitigation   Implement whitelisting for node connections and establish and drop connections randomly to make it  harder for an attacker to consistently control a victim nodes view.   Remediation   A regression test could consist of a node initialized with a full connection pool, where all connections do  not forward any outgoing traffic. Mitigation strategies can be measured by the time the node requires to  establish and hold a connection to a non-malicious fraction of the network (e.g. containing a validator  majority).    Status   java-tron implemented the following three strategies to mitigate the aforementioned issue:   1. Provide a whitelisted list of trusted nodes;  2. Randomly drop and establish connections to inactive nodes with exclusion to trusted nodes; and  3. Restricting the number of incoming connections from the same IP address to one.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_TRON_Protocol_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Malicious Token Attack", "body": "  Location  An attack demonstrating the vulnerability is found in test/Issue A.ts.  Synopsis  UniswapTrader trusts the balanceOf and transfer methods of ERC-20 tokens to behave correctly. A maliciously designed token can trick UniswapTrader into allowing more tokens to be sold than were bought, rewarding the attacker with VanillaGovernanceTokens.  Impact  An attacker can execute the attack at low cost, repeating as often as desired to obtain an unlimited number of VanillaGovernanceTokens. This will increase the supply of VanillaGovernanceTokens in circulation and potentially lower their value for other token holders.  Preconditions  The attacker must create a malicious token and list it on Uniswap before executing trades via VanillaRouter.  Feasibility  The attack is straightforward and can be carried out easily.  Technical Details  In order to receive VanillaGovernanceTokens,a trader must make a protable trade. The degree to which a trade is judged protable is dependent on the number of tokens sold. The protability of a trade in which the number of tokens sold is greater than the number previously bought (i.e. at a comparable price) increases as the delta between the number of tokens bought and sold increases.  Security Audit Report | Vanilla Smart Contracts | Equilibrium 23 March 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   With honest tokens, this attack is not possible. The strategy for tricking VanillaRouter with a malicious token consists of the following steps:  1. Buy a certain number (n) of tokens normally. 2. Change the behavior of the ERC-20 token so that before the next trade the balanceOf method  will return 0.  3. Buy more tokens. The UniswapTrader._buyInUniswap method computes the number of  tokens purchased as the difference between the post-trade balance and the pre-trade balance. In normal conditions, the pre-trade balance will be n but the attack has articially set it to 0, inating the perceived number of tokens to be the equal to the post-trade balance.  4. Change the behavior of the ERC-20 token so that, during the next trade, it will allow a transfer  amount that exceeds the balance.  5. Sell the inated perceived number of tokens and receive unearned  VanillaGovernanceTokens.  Mitigation  VanillaRouter can protect itself immediately from this attack by allowing the trade of only whitelisted tokens. It is worth considering to audit tokens for whitelisting in a similar way that Bskt has implemented for their platform.  Remediation  It may be possible to reduce exposure to the trusted balanceOf method by utilizing the return value of Uniswaps swapExactETHForTokens instead of using swap when buying tokens. Further investigation would be required in order to determine whether this eliminates the vulnerability.  UniswapTrader._sellInUniswap should perform its own check to make sure that no more tokens are being sold in a transaction than have been previously purchased rather than relying on the ERC-20 token to enforce this.  Status  The Equilibrium team has addressed the vulnerability by amending the contract to only issue rewards for whitelisted tokens, in accordance with the recommended mitigation.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Equilibrium_Vanilla_Contracts_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A:  Inappropriate Memoization of Function Call Loading a Contract", "body": "   Location   /thanos-wallet/src/lib/thanos/contract.ts   Synopsis   The function  loadContract  is memoized, thus it only executes once for a particular set of arguments  and all subsequent calls will return the same value. Since this is a function that returns the details of a  contract on the Tezos blockchain, there is external state changing between the calls to this function,  which will not be reflected by the object returned by the call to  loadContract . Without a thorough   Security Audit Report | Thanos Wallet | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   5   This audit makes no statements or warranties and is for discussion purposes only.          understanding of how Taquito is managing the internals of this object since this functionality is  undocumented, it is difficult to fully understand the potential security implications.     Impact   The inappropriate memoization may fail to reflect certain changes within the contract, depending on the  implementation of the wallet interface and specific Taquito implementation details. As a result, this could  cause users to miss updates in contract state between transactions.    Technical Details   Initially, our team was concerned that the memoization would prevent users from seeing updates in the  wallet balance after transactions. While it appears that this is not the case, it is only because Taquitos  ContractAbstraction   getStorage  method issues an RPC, which seems to compensate in our tests.  However, this raises two points:    1. This memoization function appears to offer little benefit, since calls to the Tezos blockchain will   always need to be made.    2. Memoizing this function makes it extremely difficult to ensure that parts of the Thanos Wallet   codebase are functioning properly, as the side effects required in order for it to function properly  are caused by undocumentated implementation details in Taquito.   Remediation   In general, memoization should only be used on pure functions (i.e. functions that have no side effects  and do not depend on any external state). Since the  loadContract  function depends on external state  (the state of the wallet contract on Tezos), this memoization has the potential to cause the function to  return incorrect values.   Given that there appears to be minimal benefit to memoizing this function and it adds a great deal of  complexity to understanding its operation, we recommend removing this functionality. Furthermore, it  should be assured that all memoization is occurring only on functions that have no side effects and no  dependency on external state.    Status   After talking with the Thanos team, we learned that the state being depended on was the structure of the  contract, rather than the value, which is not something that is subject to change and can let us view it as a  pure function in this instance. However, with the memoization functionality, we had additional concerns  about the technical details of memoizing complex objects that were then modified after retrieval. Since it  appears that the chosen memoization library does not perform deep copies of objects by default, care  must be used if the  WalletContract  object returned is modified, especially if it is being accessed in a  parallel manner. However, due to the design of Thanos, the only mutation being performed is requesting  that the  WalletContract  update its storage to reflect the latest state of the Tezos blockchain, and as  such seems safe.    The Thanos team implemented a  fix  by utilizing a library called  micro-memoize  which is better equipped  to handle promised memoization. Additionally, we have found that Taquito has confirmed in a  news  announcement  that accessing storage issuing a new call to the Tezos blockchain is a deliberate and  advertised design decision. Finally, after discussion with the Thanos team we better understand the  design concerns that warrant the memoization, and recognize that this reduces overhead by only  retrieving the schema for a contract a single time, while wanting to perform storage retrieval optimization  many times after.   With this in mind, and with the improved handling of complicated values the new library offers, we believe  this issue has been resolved.   Security Audit Report | Thanos Wallet | Tezos Foundation 24 September 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.      Additionally, we would recommend that an integration test be added to ensure that this operation remains  stable. If in future designs of the Thanos wallet, more operations that modify internal state end up being  performed on the cached  WalletContract  object, consider having the memoization library clone that  object before returning it to prevent some tricky bugs.     Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Thanos_Wallet_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B:  Auditing Package Dependency Shows a High Number of", "body": "  Vulnerabilities   Location   thanos-wallet/package.json   Synopsis   Analyzing  package.json  for dependency versions using Yarn Audit shows that dependencies used have  662 reported known vulnerabilities (653 Low; 2 Moderate; 7 High).    Impact   Due to the large number of issues reported, we were not able to inspect all of them individually. As a  result, it is difficult to assess the potential impact of using these dependencies in their current version.  However, it should be noted that this may result in exposure to security vulnerabilities.   Remediation   Upgrade dependencies with an automatic upgrade tool. Running  yarn upgrade  resolves all of the  reported vulnerable dependencies except for one dependency used by Taquito with low severity. We were  unable to fully verify that no new issues were introduced upon the dependency upgrade due to the  absence of a test suite. We recommend that these upgrades be re-evaluated for potential issues after the  test suite is added to the code base (see  Suggestion 4 ).   In case of an issue introduced due to compatibility with an upgraded dependency version, use  Selective  Dependency Resolution  after reviewing package.json.   Status   The Thanos team issued a  commit  which upgraded or resolved all reported vulnerable dependencies.  Running an automatic dependency audit shows no vulnerable dependencies used.    Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Thanos_Wallet_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Sensitive Data Not Cleared Upon Locking", "body": "  Location  src/background/APIService.js  Synopsis  The local password can be extracted after locking due to insucient state clearing.  Impact  With access to the locked extension, an attacker can interact with the browser extension and extract the password from the internal state of the background script. This password can be used to decrypt the keystore, which stores the private key.  Preconditions  The attack requires an opportunity to interact with the extension, which requires physical access to the machine. Alternatively, a means of control of the inputs to the browser extension would be needed, which would require successful exploitation of the machine beforehand.  The extension must be opened and unlocked, and then locked again, storing the password in memory.  Security Audit Report | Auro Wallet Extension | Mina Foundation 6 August 2021 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  If the preconditions hold, the attack is feasible using the Chrome DevTools, which are part of every Chrome installation.  Technical Details  The password is stored in the memStore of the APIService. The internal state of this object can be inspected using the Chrome DevTools.  Remediation  We recommend clearing the password upon locking, which entails deleting the password from the memStore object.  Status  The Auro Wallet team has updated all code paths that lock the wallet, such that all sensitive data is deleted from the memStore.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Mina_Foundation_Auro_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Encryption Library Provides Insufcient Security for Low-Entropy", "body": " Passwords  Location  src/background/APIService.js#L12  Synopsis  The browser-passworder encryption library uses the PBKDF2 key derivation function using a SHA hash, which is purely CPU-bound. This means brute-force attacks can be sped up relatively easily using ASICs and FPGAs.  Impact  A successful brute force attack on the password based encryption compromises the private key.  Preconditions  The attacker has access to a locked, encrypted wallet.  Feasibility  Moderately feasible. The attack requires access to a hardware implementation (ASIC or FPGA) of PBKDF2-HMAC-SHA256. The initial investment for an FPGA implementation is low to moderate.  Technical Details  The browser-passworder encryption library uses PBKDF2 to derive a key from a password. PBKDF2 is a standard for iterated invocation of a keyed hash function. The function used in browser-passworder is HMAC-SHA256. This function is purely CPU-bound, and can therefore be sped up using specialized hardware that has little memory. Such hardware is not very expensive and very energy ecient. In order to protect against brute-force attacks carried out with the help of such devices, a memory-hard function should be used. This makes brute-force attacks based on specialized hardware infeasible, because they require access to a considerable amount of fast memory. This increases both the hardware cost and the amount of energy required for the derivation, which minimizes the gap to the eciency of CPUs.  Security Audit Report | Auro Wallet Extension | Mina Foundation 6 August 2021 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend using the Argon2id function for deriving keys from passwords. There are two possible approaches:  1. Provide a patch to browser-passworder to support Argon2id (see this GitHub Issue). 2. Derivation and encryption manually.  For deriving a key from the password, we recommend this Argon2id function library implemented with a memory parameter of 64 MB. Additionally, an iteration count (called OPSLIMIT by sodium) of 3 should be used. It is important to note that a longer processing time provides better protection against brute-force attacks.  For encryption of the browser extension storage, we recommend using the secretbox functions from libsodium.  Status  The Auro Wallet team has added code for a new encryption system based on Argon2id and AES-GCM. They also added automatic migration logic, in order to convert encrypted wallets in the old format to the new format. The security parameters of the Argon2 invocation t the use case. For the base64 conversion, a well-maintained, web-compatible implementation of the Buffer object from Node.js is being used.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Mina_Foundation_Auro_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue C: Memo Allows GraphQL Injections", "body": "  Location  pages/StakingTransfer/index.js#L150-L156  pages/Send/index.js#L354-L360  background/api/gqlparams.js#L55-L156  Synopsis  The input elds from the Send and Staking screens are inserted into the GraphQL mutation strings without validation or sanitization. If a user inserts a double-quote () character into a memo eld, they can end the GraphQL eld that constrains the results and insert additional GraphQL code.  Impact  There are several strings that, when entered as a Memo string, result in the submission of an invalid transaction, which would be rejected by the Mina Network. We did not nd a string that would result in a changed destination or amount.  Preconditions  The attacker is able to choose the contents of the memo eld.  Feasibility  Depending on the context, this is very feasible. For example, a merchant may require a specic memo for matching the payment to the order. This may not be a deliberate attack, however, most strings containing quotes will fail.  Security Audit Report | Auro Wallet Extension | Mina Foundation 6 August 2021 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Technical Details  The memo eld can be lled with arbitrary text. This text will then simply be inserted into the GraphQL mutation string, between two quotation marks. Since that text can also contain quotation marks, the structure of the GraphQL mutation can be escaped and thereby modied. This is referred to as GraphQL injection.  In this case, we did not nd a way to perform an attack with a very strong outcome, because the signature, which is also included in the mutation, is only valid for the correct data. Therefore, we only found attacks which resulted in failed transactions.  Such injections can be prevented by properly using the GraphQL named mutations and variables features.  Remediation  We recommend adhering to the best practice guidelines provided in the GraphQL documentation. Steps to avoid GraphQL injections include:   Use accepted naming conventions and avoid conventions where a mutation is named  MyMutation;   Use variables instead of inserting strings directly;  Mutations must be a static string; and  Remove the startFetchMyQuery function, then map the proper values to these variables using  the variables parameter of fetchGraphQL.  Status  The Auro Wallet team has updated the code such that the generation of query and mutation strings is minimized (e.g. through the use of GraphQL variables), which prevents GraphQL injections of any kind.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Mina_Foundation_Auro_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue D: Password Prompts on an Unlocked Wallet Can be Circumvented", "body": "  Location  src/popup/pages/SecurityPwdPage/index.js  src/background/APIService.js#L60  Synopsis  All password prompts that are presented when the wallet is already unlocked can be circumvented, since the wallet password is stored in the background script state, which can be accessed using the Chrome DevTools.  Impact  A user may not notice that it is possible to extract the private key from any unlocked wallet and, given this false sense of security, may be less careful than is warranted. This may lead to the compromise of their secret key and/or mnemonic, or the change of the password by an attacker.  Preconditions  The wallet must be unlocked.  Security Audit Report | Auro Wallet Extension | Mina Foundation 6 August 2021 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Feasibility  The password can be easily extracted.  Technical Details  The password is stored in the memStore of the APIService. The internal state of this object can be inspected using the Chrome DevTools. Unfortunately, this is an inherent limitation of the execution environment and cannot be prevented.  In order to decide on what action is to be taken in order to reduce the risk of leaking the secret key and seed, two attack scenarios have to be considered, as detailed below.  First, consider a scenario where the password prompt remains in the wallet and a user believes it is secure. The user temporarily (because the user trusts the security of the password prompt) gives an attacker access to the wallet UI, and afterwards checks that no transactions were made. An attacker who is aware of this weakness and has experience with web extension development and debugging will be able to extract the secret key without the user noticing.  Second, consider a scenario where the password prompt is removed. The user is aware that they should not leave the wallet unlocked, but due to a lapse in operational security, the user leaves it open during a window of opportuning where the attacker has access to the wallet. The attacker does not need specialized knowledge to export the secret key.  The action to be taken is a trade-off between these risks. Both are real risks and an evaluation needs to happen in the context of the application and user base, which is ultimately a decision to be made by the software vendor.  Mitigation  One mitigation is to lock the wallet during these password prompts. Whenever an attacker rst tries to export the keys through the UI (instead of immediately going for a DevTools-based attack), the wallet would be locked and the attack prevented. This would prevent UI-based attacks and secure the password prompt. However, it would still be vulnerable to attacks where the attacker immediately uses the DevTools to exltrate the secret key or seed.  The user should, if possible, use a hardware wallet, as they categorically prevent the accessing and exltration of secret keys. If that is not possible in the specic context of the user, the user should be very careful not to leave the wallet unlocked.  Status  The Auro Wallet team has decided not to implement the mitigation as they feel this would reduce the usability of the application. Specically, if the mitigation is implemented and the user aborts the password prompt when attempting to view the mnemonic, they could not go back to the home screen without unlocking the wallet again. We encourage the Auro Wallet team to continue to evaluate solutions to resolve this issue. We also recommend that the Auro Wallet team recommend users to utilize a hardware wallet.  Verication  Unresolved.  Security Audit Report | Auro Wallet Extension | Mina Foundation 6 August 2021 by Least Authority TFA GmbH  10  This audit makes no statements or warranties and is for discussion purposes only.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Mina_Foundation_Auro_Wallet_Extension_Final_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Scrypt Parameters are Swapped", "body": "   Location   https://github.com/LeastAuthority/go-eth2-wallet-encryptor-keystorev4/blob/master/encrypt.go#L32-L33    Synopsis   The  r  and  p  parameters of Scrypt password based key derivation function appear to be swapped. In the  above code,  r  is defined as 1 and  p  is 8.   Impact   While  p = 8  is harmless,  r = 1  would result in making the Key Derivation Function (KDF) weak. The  parameter  r  is directly proportional to the width of the innermost core hash functions width and also  determines the iteration count of the core hash function. The memory usage and CPU time is directly  proportional to  r . As a result,  making  r  small increases the Scrypts weakness.   Security Audit Report | ethdo | Ethereum Foundation 17 November 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.          Preconditions   The attacker has access to the wallet files or gains access to the computer running the wallet.   Technical Details   Making  r  = 1 instead of the recommended value of 8 result in it requiring less memory and less CPU.  Attackers can employ more memory and CPU to crack passwords derived from such a Scrypt  implementation than on an equivalent function with  r  = 8.   Mitigation   Until this is fixed, existing users should choose longer and non-dictionary word passwords.   Remediation   Make  r = 8  and  p = 1 .   It should be noted that both  x/crypto/scrypt docs  and   RFC 7914  recommend  r = 8 ,  p = 1 .   Status   The  ethdo  team has issued a  commit  which changes the scrypt parameters to  r = 8  and  p = 1 , thus  resolving this issue according to the suggested remediation.   Verification   Resolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_ethdo_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Using Unencrypted Connection to Ethereum Endpoint", "body": "   Location   https://github.com/LeastAuthority/ethdo/blob/0746fa304851f0c63955911270447fe2257b7cd0/cmd/ro ot.go#L369    Synopsis   Passing  WithInsecure()  value to the  grpc.Dial  function returns a  DialOption  value which  disables transport security for the client connection.   Impact   This leaves some of the  beacon chain  communications with the Ethereum network vulnerable to  man-in-the-middle (MITM) attacks, thus exposing data to unintended receivers.    Preconditions   In order for the attack to take place, the  ethdo  client and the Ethereum beacon node need to run on  separate computers.   Feasibility   Any attacker with network access may be able to sniff the unencrypted data exchange.    Technical Details   Using Golangs  grpc   package with the  DialOption   WithInsecure ()  for the Client results in an  unencrypted connection.   Security Audit Report | ethdo | Ethereum Foundation 17 November 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.        Mitigation   Users may configure the  ethdo  client to only connect to the Ethereum beacon node running on the  localhost .    Remediation   Utilize Gos  gprc   to add a layer of encryption (e.g. Transport Layer Security) compatible with the  Ethereum network for the communication between Ethereum node and  ethdo .    Status   The  ethdo  team has responded to this issue with an update where  ethdo  displays a warning if insecure  http connections are made to a non-localhost computer running the Ethereum beacon node. In addition, a  command line option called  allow-insecure-connections  has been introduced to allow user  consent prior to making an insecure connection.    Ethereum 2.0 will soon support a secure REST-based API for beacon nodes. The  ethdo  team stated that  they will pursue this issue with the Ethereum team and will implement a fix once secure REST-based API  for beacon nodes usage is available.    Verification   Partially Resolved.    ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Ethereum_Foundation_ethdo_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue A: Misuse of Window.open Makes the dApp Vulnerable To Reverse", "body": " Tabnabbing Attacks  Location  src/utils/share.ts#L12C1-L12C1  components/UniversalSearch/UniversalSearch.tsx#L196  src/hooks/useOpenExplorerTab.ts#L26  Synopsis  The current implementation of the dApp uses window.open to access external websites. If an attacker injects malicious code into that website, they can rewrite the source page and substitute it with a phishing website. This type of attack is known as reverse tabnabbing.  Impact  With a reverse tabnabbing attack, the user who initially opens the original and correct webpage is unlikely to notice the webpage has been replaced with the phishing website. As a result, the user will likely share sensitive data with the phishing website, or connect their wallets to it. This could lead to a complete loss of funds or sensitive/private data leakage.  Preconditions  There are two preconditions that must be met for the attack to be successful:  Security Audit Report | Core Web | Ava Labs 21 May 2024 by Least Authority TFA GmbH  5  This audit makes no statements or warranties and is for discussion purposes only.   1. The page that is linked from the target must contain malicious code that utilizes the location  property in the opener object sent by the the window.open function, as follows:  <script> if (window.opener) { window.opener.location = \"https://www.phishingsite.ps\"; } </script>  2. noopener, noreferrer should not be passed to the window.open function in the dApp.  Feasibility  If the preconditions are met, the attack is trivial.  Remediation  We recommend, for all instances of window.open, that the noopener, noreferrer parameter be passed as a third parameter for the window.open function, as shown below: window.open(url, target, 'noreferrer, noopener');  Status  The Ava Labs team has introduced the openWindowSecurely function to the codebase, which follows secure properties and uses them to access external sites.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/least-authority-ava-labs-core-web-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Missing Sanitization on Inputs Makes the dApp Vulnerable to XSS", "body": " Attacks  Location  Example (non-exhaustive):  utils/search/contentfulCreateFuseSearch.ts#L11  utils/generateOpenApiClient/generateOpenApiClient.ts#L64  components/UniversalSearch/UniversalSearch.tsx#L213  services/dapp/dappService.ts  Synopsis  Inputs of the system, such as text elds, API responses, data coming from the smart contract or the connected wallet, and fs package reading les stored on the server are not sanitized. Data coming from an external resource should not be trusted, as it could carry malicious codes that can affect the safety of the system.  Impact  Receiving data from untrusted sources opens an attack vector for different kinds of Cross Site Scripting (XSS) attacks.  Preconditions  A malicious actor would have to take over the server or inject malicious code in it.  Security Audit Report | Core Web | Ava Labs 21 May 2024 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Remediation  We recommend that the Ava Labs team sanitize and validate data coming from untrusted sources to verify that it does not contain any malicious codes that could affect the system, and conrm that the data obtained aligns with their expectations. We suggest using the DomPurify package for sanitization.  Status  The Ava Labs team has added input sanitization in places that are not already sanitized by React/JSX.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/least-authority-ava-labs-core-web-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue C: Imprecise Calculations", "body": "  Location  src/utils/calculatePercentageChange.ts#L1  Synopsis  The utility function calculates its return value by subtracting variables of the number type.  Impact  Since this is a utility function that may be used in sensitive calculations where precision is paramount, this could lead to incorrect calculations due to precision errors.  Remediation  We recommend using the toPrecision or the BigInt library.  Status  The Ava Labs team has started using the big data type from the Big.hs library to perform calculations.  Verication  Resolved.  ", "html_url": "https://leastauthority.com/least-authority-ava-labs-core-web-updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A: Mnemonics Copied to Clipboard", "body": "  Location  app/components/MnemonicScreen.tsx#L69  app/utils/DeviceTools.ts  Synopsis  The mobile wallet currently has a feature, which allows the user to copy the mnemonics to clipboard. On many devices, the clipboard can be accessed by all the applications within the system.  This Issue has already been reported in the previous Audit Report (Issue E) our team delivered on January 30, 2023 and has not been resolved. It is still our belief that the copying of the mnemonics to the clipboard is a security risk. Hence, we report this Issue again in this report.  Impact  With access to the clipboard, a malicious application on the system could store the mnemonics and send the data through the network to an attacker-controlled endpoint in order to gain access to the users funds.  Preconditions  This Issue is possible if:   On Android 9: The attacker controls a malicious application on the users device, and the user  uses the copy-to-clipboard functionality; or   On other Devices: The user uses the copy-to-clipboard functionality and opens a malicious  application controlled by the attacker.  Feasibility  If the preconditions are met, the attack is simple. The attacker has to detect mnemonics (for example, using regular expressions) or simply exltrate all clipboard contents.  Technical Details  On Android, the ClipboardManager can be utilized, and a listener can be used to listen for clipboard changes. Starting at Android 10, only currently active applications and the congured keyboard can access the clipboard at any time. From Android 12 (API level 31) on, the user is notied if an application accesses the clipboard, but applications can process this information nonetheless. The Core Wallet application supports Android 9 and higher, so Android 9 devices are still susceptible.  Mitigation  We suggest displaying a warning when the copy button is clicked that advises the user to only open a trusted application for storing the mnemonic and then immediately return to the Core Wallet application and press the enter button. This event can then be used to put a non-sensitive string in the clipboard (empty or xed string).  Remediation  We recommend removing the copy-to-clipboard feature and encouraging users to physically write down the mnemonics instead.  Security Audit Report | Avalanche Mobile Wallet Security Audit (2nd Review) | Ava Labs 12 April 2024 by Least Authority TFA GmbH  6  This audit makes no statements or warranties and is for discussion purposes only.   Status  The Ava Labs team has added functionality to display a warning before a user can copy the mnemonics to clipboard. This warning informs users of the risks of copying the mnemonics. Additionally, the team noted that the copy to clipboard functionality is a functionality that is typically offered by most mobile wallets and removing it would require a user experience tradeoff. While we recognize that this is a broadly used feature, our team still recommends refraining from sharing sensitive material in the clipboard, or, at a minimum, overwriting them after a period of time to limit exposure to other applications or accidental reveal to third parties by the user.  Verication  Partially Resolved.  ", "html_url": "https://leastauthority.com/ava_labs_avalanche_mobile_wallet_security_audit2nd-review_updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue B: Unchecked Security Level Endangers Key Material", "body": "  Location  app/contexts/EncryptedStoreProvider.tsx  Synopsis  The Core Wallet application requires a minimum API level of 28 (Android 9). Hence, while using the react-native-keychain wrapper for the Keystore functionality, the usage of a hardware-backed keystore is not guaranteed. Android 9 only requires a trusted execution environment (TEE) when a ngerprint sensor is present. Therefore, the availability of secure, trusted hardware cannot be assumed for all the devices the Core application is used on.  Impact  If an attacker is able to extract keys from a software-backed keystore, they could extract stored secrets from devices.  Feasibility  This kind of attack is likely if keys can be extracted from a software-backed keystore, which can occur if there is a vulnerability in the operating system and a functioning exploit for it. Another attack vector might emerge if the device storage is dumped using physical access to the device. This requires more dedicated hardware and specialized skills, but might be possible even when the operating system itself remains uncompromised.  Remediation  We recommend that the functionality provided by the react-native-keychain be implemented to check the available security level. This method can be used to determine whether a hardware-backed keystore is available. If this is not the case, we recommend that a password (as opposed to a 6-digit pin) be required for the application and used to derive a key with Argon2id,which can then be used to encrypt inputs to the keystore functionality. Additionally, we recommend implementing password throttling, increasing the wait time between each failed password/pin input attempt. This mitigates the limited entropy a 6-digit pin provides.  Status  Since the percentage of users affected by this is considerably small, the Ava Labs team has decided not to implement this remediation. Additionally, the Ava Labs team has implemented password throttling in the application. However, our team believes that because device percentages can be subject to change, the security level should be checked, and users should be informed if security assumptions of the Core Wallet application do not hold on their device.  Security Audit Report | Avalanche Mobile Wallet Security Audit (2nd Review) | Ava Labs 12 April 2024 by Least Authority TFA GmbH  7  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Unresolved.  ", "html_url": "https://leastauthority.com/ava_labs_avalanche_mobile_wallet_security_audit2nd-review_updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue C: The Module redux-persist-transform-encrypt Does Not Use", "body": " Authenticated Encryption  Location  package.json  Synopsis  Core uses the module redux-persist-transform-encrypt for encrypting the data stored in the Redux store. However, that module only encrypts the data with AES-CBC and does not provide any other means of authenticating the ciphertexts. Therefore, an attacker can tamper with the ciphertext without being detected.  Impact  An attacker can modify the application state.  Preconditions  The attacker would need read and write access to the ciphertext, which is stored in the private data folder of the application. This requires circumventing or breaking the security model of the operating system.  Feasibility  If the preconditions are met, the attack can be executed reliably and does not require special tooling.  Technical Details  The Cipher Block Chaining Mode (CBC mode) of operation is malleable, which means that given a ciphertext, it is possible to generate a second ciphertext that decrypts to a meaningful message when decrypted with the same key.  For this reason, usually an encryption scheme that provides authenticated encryption (AE) or authenticated encryption with associated data (AEAD) is used. These include AES-GCM, NaCl secretbox (i.e. ChaCha20-Poly1305), or the Encrypt-then-MAC pattern.  Since rooting an Android device or jailbreaking an Apple device inherently circumvents or breaks the security model of the operating system, these devices are likely at a higher risk of being vulnerable.  Mitigation  We suggest warning users in the jailbreak screen that authenticated data may be modied without detection.  Remediation  We recommend forking or patching the redux-persist-transform-encrypt module to use an authenticated encryption scheme.  Status  The Ava Labs team stated that they are exploring the possibility of implementing AES-GCM in the future. They are currently using an encrypt-then-mac scheme that uses a secret key string as input to AES-CBC, and correctly derives a separate key as input to HMAC.  Security Audit Report | Avalanche Mobile Wallet Security Audit (2nd Review) | Ava Labs 12 April 2024 by Least Authority TFA GmbH  8  This audit makes no statements or warranties and is for discussion purposes only.   Verication  Resolved.  ", "html_url": "https://leastauthority.com/ava_labs_avalanche_mobile_wallet_security_audit2nd-review_updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue D: Wallet Can Be Deleted Without Authentication", "body": "  Location  screens/drawerNoWallet/NoWalletDrawerView.tsx#L63  development/app/AppHook.ts#L51  Synopsis  The wallet data can be deleted without entering the wallet pin/password.  Impact  Attackers with physical access to the device can access the application and delete the wallet, which could result in users being locked out and unable to retrieve their funds. Attackers can also achieve this goal by deleting the application via the system settings \u2013 although this is not possible with managed devices.  Preconditions  Attackers would need physical access to the device, and the walletstate should be empty.  Feasibility  If the preconditions are met, the attack is trivial.  Technical Details  When the wallet state is empty but a wallet exists, the Enter Wallet button is shown on the Watchlist screen. In this state, the sidebar navigation offers the option to delete the wallet without authentication.  Remediation  We recommend requiring the wallet to ask for user authentication before user data is deleted to ensure that wallet data is only deleted if proper user authentication is provided.  Status  The Ava Labs team stated that in their security model, an attacker with physical access to the unlocked device is not considered. Although we nd this to be reasonable, our team noted that such assumptions have to be communicated to the user in order for them to be able to consider it in their own threat model. Additionally, the Ava Labs team noted that in the event that an attacker with physical access to the device deletes the application, this nding becomes invalid. While our team agrees with this reasoning, we recommend that due diligence be undertaken since this nding could be combined with other exploits and thus provides a different attack vector to the sole deletion of the application.  Verication  Determined Non-Issue.  ", "html_url": "https://leastauthority.com/ava_labs_avalanche_mobile_wallet_security_audit2nd-review_updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue E: Mobile Wallet Does Not Enforce User Consent To Establish", "body": " Websocket Connection  Location  services/walletconnectv2/WalletConnectService.ts  Security Audit Report | Avalanche Mobile Wallet Security Audit (2nd Review) | Ava Labs 12 April 2024 by Least Authority TFA GmbH  9  This audit makes no statements or warranties and is for discussion purposes only.   Synopsis  The application does not require consent for the initial opening of a websocket connection to the pairing wallet but will receive the session request information through the websocket connection and afterwards present a customized screen (including, for example, a custom image for the dApp, the network, and a selection method for the accounts). This allows malicious applications on the same device or malicious websites to start a websocket communication channel without the user noticing.  Our team has already identied and reported this Issue in our previous Audit Report (Issue A), which we delivered on January 30, 2023, and it has since not been resolved.  Impact  Given that there is a vulnerability in the code handling the RPC requests over the websocket or the websocket libraries used, an attacker may be able to use those to, for example, gain access to private or secret information, or render the Core Wallet application unusable.  Preconditions  An attacker would either need to control a malicious application on the same device or be able to have the user open a website controlled by the attacker that can then send a deeplink to the application.  Feasibility  This attack would require another vulnerability in how RPC requests are handled or how websocket connections are handled by the underlying operating system. Therefore, an attack at this point is unlikely, yet still possible.  Remediation  Before the initial session request is performed via the WalletConnect library, we recommend showing a generalized screen whenever a dApp connection is attempted. Hereby, the user would be informed that a dApp connection attempt is about to occur and should attempt to retrieve the rst set of information. While this is not ideal in terms of user experience, it mitigates the risk of potential vulnerabilities being exploited without the user noticing.  Status  The Ava Labs team has acknowledged the nding but decided against implementing the recommended remediation in favor of a better user experience. The Ava Labs team additionally noted that they have several measures in place to prevent messages from unknown senders.  Verication  Unresolved.  ", "html_url": "https://leastauthority.com/ava_labs_avalanche_mobile_wallet_security_audit2nd-review_updated-final-audit-report/", "labels": ["LeastAuthority"]}, {"title": "Issue A:  Personalization of any  asset_type  Generator and the  randomness_base", "body": "  Generator is Equal    Location   Definition of  fixed_base_generators[FixedGenerators::ValueCommitmentValue]  and  fixed_base_generators[FixedGenerators::ValueCommitmentRandomness]  in file  zcash_primitives/src/jubjub/mod.rs   Synopsis   Since it must be guaranteed that no  asset_type  generator has a discrete log relation to the  randomness_base  generator, the implementation must ensure that the derivation of the  asset_type  generator from the  asset_type  identifier is different then the derivation of the  randomness_base  generator from its group hash preimage. Otherwise, an attacker might be able to use the  randomness_base  generator itself as an  asset_type  generator.   The Metastate team has stated that they are aware of this and have correctly accounted for it by  introducing the two different personalisations  VALUE_COMMITMENT_GENERATOR_PERSONALIZATION  and  VALUE_COMMITMENT_RANDOMNESS_PERSONALIZATION  for domain separation between the  asset_type  generators and the  randomness_base  generator. However, due to a small coding error,  the value  fixed_base_generators[FixedGenerators::Value CommitmentValue]  was  changed, such that it uses the wrong constant, while the value   Security Audit Report | Multi-Asset Shielded Pool | Metastate AG (Audit Funded by Tezos Foundation) 18 August 2020 by Least Authority TFA GmbH   6   This audit makes no statements or warranties and is for discussion purposes only.            fixed_base_generators[FixedGenerators::ValueCommitmentRandomness]  remains  unchanged.   Impact   If an attacker is able to compute a 32 byte preimage  A  of the  randomness_base  generator  R, then (A,R)  serves as a valid  asset_type  (identifier, generator)-pair with a known discrete log relation (the trivial  one) to the  randomness_base . This would break the binding property of the homomorphic Pederson  commitment.    Feasibility   The feasibility of the attack depends on the way in which the  randomness_base  generator is computed.  It is not of any practical concern, as long as the obvious preimage of the  randomness_base  generator is  not of size 32 byte (as explained in the Technical Details section), or if different personalizations are used.   Technical Details   According to function  group_hash in zcash_primitives/src/group_hash.rs , the  randomness_base generator is computed as:    Params::new()  .hash_length(32)  .personal(VALUE_COMMITMENT_GENERATOR_PERSONALIZATION)  .to_state().  .update(GH_FIRST_BLOCK)  .update(br)  .finalize()   Where GH_FIRST_BLOCK is 64byte and r is one byte. If we assume that the first BLAKE2s hash happens  to be a point on the Jubjub curve, then an asset_type generator is computed from its associated  asset_type identifier as:   Blake2sParams::new()  .hash_length(32)  .personal(VALUE_COMMITMENT_GENERATOR_PERSONALIZATION)  .to_state().  .update(identifier)  .finalize()   From this follows that, since  hash_state.update(A).update(B)  and  hash_state.update(A||B)  result in the same hash, the concatenated string  identifier:=(GH_FIRST_BLOCK||br)  is a valid  preimage of the randomness_base generator. However, that string is of size 65 byte, which violates the  assumption that an identifier must be of size 32 byte. Since the size of the identifier is checked in the  circuit, any identifier of size > 32 byte is invalid.   Remediation   Use the personalization  VALUE_COMMITMENT_RANDOMNESS_PERSONALIZATION  in the definition of  fixed_base_generators[FixedGenerators::ValueCommitmentRandomness] .    Status   VALUE_COMMITMENT_RANDOMNESS_PERSONALIZATION is now used in the definition of  fixed_base_generators[FixedGenerators::ValueCommitmentRandomness].   Security Audit Report | Multi-Asset Shielded Pool | Metastate AG (Audit Funded by Tezos Foundation) 18 August 2020 by Least Authority TFA GmbH   7   This audit makes no statements or warranties and is for discussion purposes only.                In addition, following the audit, all personalizations used in the circuits were changed to support domain  separation from the original Sapling protocols personalizations. These changes have not been audited by  our team and we suggest they be reviewed in a future audit.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Multi_Asset_Shielded_Pool_Audit_Report.pdf", "labels": ["LeastAuthority"]}, {"title": "Issue B: Cofactor Not Cleared in Value Commitment Calculation", "body": "    Location   https://github.com/joebebel/librustzcash/blob/joe/zcash_proofs/src/sapling/mod.rs#L35:L37   Synopsis   To compute the value balance in order to include it in the circuit, the value is computed in the exponent of  the value commitment generator. However, the cofactor is not cleared in function  compute_value_balance, which is necessary in this construction using the Jubjub curve.   Impact   By not having the cofactor cleared, it is possible that the system is vulnerable to a small subgroup attack,  which might leak three bits of information. Additionally, this leads to inconsistency in the codebase, as  well as inconsistency with the Sapling implementation, which might result in the inability to generate  correct proofs.    Technical Details   Due to the relation of the project to the Zcash Sapling circuit implementation and the use of the Jubjub  curve, it is helpful to also clear the cofactors of the generators created.   In modern cryptography, there exists a gap between provable security and practical cryptography. Within  cryptographic protocols and their implementations, it is often required to operate with elliptic curves of  prime order. In practice, used elliptic curves are not of prime order but have a low-order subgroup and a  high-order subgroup and the order of the whole group being of the form of  h*p  with  p  a large prime and  h  a small integer. The integer h is often called the cofactor. This can lead to a small subgroup attack as  presented by Lim and Lee .    In such groups,  G  with subgroup  H  of prime order  p  and order of  G  being  h*p  with  h  being a small  non-prime (i.e.,  h=r*s  with small prime  r ), there could exist an element P such that the order of P is  r*k  with integer  k . In  <P> , it would then be possible to solve the discrete logarithm problem. To make sure the  generator used in this case does not fall into  <P>  but rather into H, it is recommended to clear the  cofactor, meaning scalar multiplying  h*P  so that all resulting possible elements are actually cleared of  having the risk of small order.    This problem can also be identified for the Jubjub curve. The order of the Jubjub curve is  8*p  with prime  p , as a result, it is necessary to investigate the components for the generator in Jubjub and clear the  generator used in the protocol for computations of the value commitment.    Remediation   Clear the cofactor in function  compute_value_balance  for  value_commitment_generator  through  scalar multiplication with the cofactor.   It is also possible, for simplification, to have a potential  value_commitment_generator_uncleared  function without having the cofactor cleared and a  value_commitment_generator_cleared  function   Security Audit Report | Multi-Asset Shielded Pool | Metastate AG (Audit Funded by Tezos Foundation) 18 August 2020 by Least Authority TFA GmbH   8   This audit makes no statements or warranties and is for discussion purposes only.                with having the cofactor cleared in  zcash_primitives/src/primitives.rs  to clarify the usage instead of  clearing the cofactor manually where needed.    Status   The value balance calculation in  zcash_proofs/src/sapling/mod.rs  now clears the cofactor of the value  commitment generator.   Furthermore, in order to prevent errors in the future, the Metastate team is considering a type system for  uncleared and cleared generators, in addition to clearing cofactors as soon as possible, consistent  documentation of uncleared and cleared generators in the code, and changes to a consistent notation of  asset generator and value balance generator in documentation and code. However, these changes have  not been implemented.   Verification   Resolved.   ", "html_url": "https://leastauthority.com/static/publications/LeastAuthority_Tezos_Foundation_Multi_Asset_Shielded_Pool_Audit_Report.pdf", "labels": ["LeastAuthority"]}]